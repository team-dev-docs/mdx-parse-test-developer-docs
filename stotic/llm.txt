Below is all the contents of our docs: 



 This is the content for the doc README.md 

 # developer-docs 🚧

Our open source documentation is under construction. Refer to our [website](https://www.speakeasy.com/docs) for up-to-date docs!


 This is the content for the doc api-design/caching.mdx 

 ---
description: Learn how to use HTTP caching to make APIs more efficient and sustainable.
---

# Caching API Responses

import { Callout } from "~/components";

API caching can save servers some serious work, cut down on costs, and even help reduce the carbon impact of an API. However, it is often considered an optimization rather than what it truly is: an integral part of API design. 

A fundamental part of REST is APIs declaring the "cacheability" of resources. When working with HTTP there are many amazing caching options available through HTTP Caching; a series of standards that power how the entire internet functions. This can be used to design more useful APIs, as well as being faster, cheaper, and more sustainable.

## What is HTTP caching?

HTTP caching tells API clients (like browsers, mobile apps, or other backend systems) if they need to ask for the same data over and over again, or if they can use data they already have. This is done with HTTP headers on responses that tell the client how long they can "hold onto" that response, or how to check if it's still valid.

This works very differently from server-side caching tools like Redis or Memcached, which cache data on the server. 

HTTP caching happens on client-side or on intermediary proxies like Content Delivery Networks (CDNs), acting as a proxy between the client and the server and storing responses for reuse whenever possible.

Think of server-side caching as a way to skip application work like database calls or outgoing HTTP requests, by fetching precomputed results from Redis or Memcached. HTTP caching reduces traffic and computational load further, by reducing the number of requests that even reach the server, and by reducing the number of responses that need to be generated.

## How does it work?

HTTP caching is driven by cache headers. In its most simple form, when an API sends a response, it includes instructions that tell the client and other network components like CDNs if they are allowed to cache the response, and if so for how long.

The guide on [API responses](/api-design/responses) briefly introduced the `Cache-Control` header:

```http
HTTP/2 200 OK
Content-Type: application/json
Cache-Control: public, max-age=18000

{
  "message": "I am cached for five minutes!"
}
```

Here the server is telling the client (and any cache proxies) that they can cache this response for 5 minutes, and they can share it with other clients too. This means that a client can use this data for up to 5 minutes without checking back with the server, and when that time has expired it will make a new request.

Fetching data, processing it, and sending it back to the client takes time and resources. Even when all of those processes are as optimized as possible, if the data hasn't changed, why bother repeating these requests? Instead of wasting resources answering the same requests over and over again, the server could be processing more useful requests, saving energy, and save money by scaling down unnecessary server capacity.

### Cache-Control

Defined in [RFC 9111: HTTP Caching](https://www.rfc-editor.org/rfc/rfc9111), this header sets out the rules. It tells clients what to do with the response:

- `Cache-Control: max-age=3600` — The client can use this data for up to an hour (3600 seconds) without checking with the server.
- `Cache-Control: no-cache` — The client must check with the server before using the cached copy.
- `Cache-Control: public` or `private` — Defines whether just the client or everyone (like proxies) can cache it.

These directives can be combined in various combinations for more control, with handy advanced options like `s-maxage` for setting how long data should live on shared caches like CDNs.

Some simple APIs will only use `Cache-Control` to manage caching, but there's another powerful tool in the cache toolbox: `ETag`.

### ETag

ETags (short for "Entity Tags") are like a fingerprint for a particular version or instance of a resource. When the resource changes, the ETag will change. No two versions of a resource should have the same ETag, and the ETag is unique to the URL of the resource.

When a server sends a response, it can include an ETag header to identify that version of the resource:

```http
HTTP/2 200 OK
Content-Type: application/json
ETag: "abc123"

{
  "message": "Hello, world!"
}
```

Then when a request is reattempted for whatever reason, the client sends a request with the ETag in the `If-None-Match` header. Doing this basically says "Only download the response if the ETag is different to this".

```http
GET /api/resource HTTP/2
If-None-Match: "abc123"
```

- If the server responds with `304 Not Modified`, it tells the client, "That response is still good. Nothing has changed since then, so no need to download it again."
- If the data has changed, the server returns the new data with a new ETag.

This is especially helpful for large responses that don't change often, especially when combined with `Cache-Control`. Sending `Cache-Control` and `ETag` lets the client confidently reuse the data for a while without even needing to send a HTTP request to the server, then after that time it can switch to doing a check for changes instead of downloading the whole response again.

All of this is done without the client needing to know anything about the data, or how it's stored, or how it's generated. The server will handle it all, and the client will just keep requesting the data, allowing the cache-aware HTTP client to do the heavy lifting.

## Using Cache-Control and ETags in code

Let's add these headers to a basic Express.js API to see how it might look on the server-side.

```js
const express = require('express');
const app = express();

app.get('/api/resource', (req, res) => {
    const data = { message: "Hello, world!" }; // Simulated data
    const eTag = `"${Buffer.from(JSON.stringify(data)).toString('base64')}"`;

    if (req.headers['if-none-match'] === eTag) {
        // Client has the latest version
        res.status(304).end();
    } else {
        // Serve the resource with cache headers
        res.set({
            'Cache-Control': 'max-age=3600', // Cache for 1 hour
            'ETag': eTag
        });
        res.json(data);
    }
});

app.listen(3000, () => console.log('API running on http://localhost:3000'));
```

The ETag is generated by hashing the data, then the server checks if the client has the latest version. If it does, it sends a `304 Not Modified` response, otherwise it sends the data with the `ETag` and `Cache-Control` headers.

In a real codebase, would be doing something like fetching from a datasource, or computing something that takes a while, so waiting for all of that to happen just to make an ETag is not ideal. Yes, it avoids turning that data in JSON and sending it over the wire, but if the API is going to ignore it and send an `304 Not Modified` header with no response, the data was loaded and hashed for no reason. 

Instead, an ETag can be made from metadata, like the last updated timestamp of a database record.

```js
const crypto = require('crypto');

function sha1(data) {
  const crypto.createHash('sha1').update(data).digest('hex');
}

const trip = Trips.get(1234);

const eTag = `"${sha1(trip.updated_at)}"`;
```

This example creates a SHA1 hash of the updated time, which will automatically change each time the record is updated. No need to specify the name of the Trip resource, or even mention the trip ID, because an ETag is unique to the URL and that is already a unique identifier.

When working with resources that have their own concept of versioning, why not use that version number as an ETag instead of creating one from something else.

```js
const trip = Trips.get(1234);

const eTag = `"${trip.version}"`;
```

```http
HTTP/2 200 OK
Content-Type: application/json
ETag: "v45.129"
```

Regardless, ETags are brilliant and easy to reconcile. If clients don't use them, it doesn't have any effect, but if they do use a HTTP client with [cache middleware](https://apisyouwonthate.com/blog/http-client-response-caching/) enabled then both the client and the server can save a lot of time and resources.

## Public, private, and shared caches

Using `Cache-Control` headers its possible to specify whether the response can be cached by everyone, just the client, or just shared caches. This is important for security and privacy reasons, as well as cache efficiency.

- `public` — The response can be cached by everyone, including CDNs.
- `private` — The response can only be cached by the client.
- `no-store` — The response can't be cached at all.

<Callout title="NOTE" variant="info">
  <p>
    When a response contains an `Authorization` header, it's automatically marked as `private` to prevent sensitive data from being cached by shared caches. This is another reason to use standard auth headers instead of using custom headers like `X-API-Key`.
  </p>
</Callout>

## Which resources should be cached?

Some people think none of the data in their API data is cacheable because "things might change." It's rare that all data is so prone to change that HTTP caching cannot help. All data is inherently out of date before the server has even finished sending it, but the question is how out of date is acceptable?

For example, a user profile is not likely to change particularly often, and how up to date does it really need to be? Just because one user changes their biography once in a year doesn't mean that all user profiles need to be fetched fresh on every single request. It could be cached for several hours, or even every day.

When talking about more real-time systems, one common example is a stock trading platform. In reality, most trading platforms publish a new public price every 15 minutes. A request to `/quotes/ICLN` might return a header like `Cache-Control: max-age=900`, indicating the data is valid for 900 seconds. Even when clients are "polling" every 30 seconds, the network cache will still be able to serve the response for 15 minutes, and the server will only need to respond to 1 in 30 requests.

Some resources might genuinely change every second, and depending on the traffic patterns network caching could still be helpful. If 1,000 users are accessing it simultaneously then network caching will help significantly reduce the load. Instead of responding to 1,000 individual requests per second, the system can reuse a single response per second. This would be a 99.9% reduction in server load, and a 99.9% reduction in bandwidth usage.

A safe default for most data is to apply some level of `max-age` caching (such as 5 minutes, an hour, a day, or a week, before it needs to be refreshed) paired with an ETag to check for fresh data past that time if the response is large or slow to generate. The introduction of ETags to an API can increase confidence in using longer cache expiry times.

## Designing cacheable resources

All new APIs should be designed with cachability in mind, which means thinking about how to structure resources to make them more cacheable. The changes needed to make an API more cacheable are often the same changes that make an API more efficient and easier to work with.

### Resource composition

One of the largest problems API designers face is how to sensibly group data into resources. There's a temptation to make fewer resources so that there are fewer endpoints, with less to document. However, this means larger resources, which become incredibly inefficient to work with (especially when some of the data is more prone to change than the rest).

```http
GET /invoices/645E79D9E14
```

```json
{
  "id": "645E79D9E14",
  "invoiceNumber": "INV-2024-001",
  "customer": "Acme Corporation",
  "amountDue": 500.00,
  "amountPaid": 250.00,
  "dateDue": "2024-08-15",
  "dateIssued": "2024-08-01",
  "datePaid": "2024-08-10",
  "items": [
    {
      "description": "Consulting Services",
      "quantity": 10,
      "unitPrice": 50.00,
      "total": 500.00
    }
  ],
  "customer": {
    "name": "Acme Corporation",
    "address": "123 Main St",
    "city": "Springfield",
    "state": "IL",
    "zip": "62701",
    "email": "acme@example.org",
    "phone": "555-123-4567"
  },
  "payments": [
    {
      "date": "2024-08-10",
      "amount": 250.00,
      "method": "Credit Card",
      "reference": "CC-1234"
    }
  ]
}
```

This is a very common pattern, but it's not very cacheable. If the invoice is updated, the whole invoice is updated, and the whole invoice needs to be refreshed. If the customer is updated, the whole invoice is updated, and the whole invoice needs to be refreshed. If the payments are updated, the whole invoice is updated, and the whole invoice needs to be refreshed. 

We can increase the cachability of most of this information by breaking it down into smaller resources:

```http
GET /invoices/645E79D9E14
```

```json
{
  "id": "645E79D9E14",
  "invoiceNumber": "INV-2024-001",
  "customer": "Acme Corporation",
  "amountDue": 500.00,
  "dateDue": "2024-08-15",
  "dateIssued": "2024-08-01",
  "items": [
    {
      "description": "Consulting Services",
      "quantity": 10,
      "unitPrice": 50.00,
      "total": 500.00
    }
  ],
  "links": {
    "self": "/invoices/645E79D9E14",
    "customer": "/customers/acme-corporation",
    "payments": "/invoices/645E79D9E14/payments"
  }
}
```

Instead of mixing in payment information with the invoice, this example moves the fields related to payment into the payments sub-collection. This is not only makes the invoice infinitely more cacheable, but it also makes space for features that are often used in an invoice system like payment attempts (track failed payments) or partial payments. All of that can be done in the Payments sub-collection, and each of those collections can be cached separately.

The customer data is also moved out of the invoice resource, because the `/customers/acme-corporation` resource already exists and reusing it avoids code duplication and maintenance burden. Considering the user flow of the application, the resource is likely already in the browser/client cache, which reduces load times for the invoice.

This API structure works regardless of what the data structure looks like. Perhaps all of the payment data are in an `invoices` SQL table, but still have `/invoices` and `/invoices/{id}/payments` endpoints. Over time as common extra functionality like partial payments is requested, these endpoints can remain the same, but the underlying database structure can be migrated to move payment-specific fields over to a `payments` database table. 

Many would argue this is a better separation of concerns, it's easier to control permissions for who is allowed to see invoices and/or payments, and the API has drastically improved cachability by splitting out frequently changing information from rarely changing information. 

### Avoid mixing public and private data

Breaking things down into smaller, more manageable resources can separate frequently changing information from more stable data, but there are other design issues that can effect cachability: mixing public and private data. 

Take the example of a train travel booking API. There could be a Booking resource, specific to a single user with private data nobody else should see. 

```http
GET /bookings/1234
```

```json
{
  "id": 1234,
  "departure": "2025-08-15T08:00:00",
  "arrival": "2025-08-15T12:00:00",
  "provider": "ACME Express",
  "seat": "A12"
}
```

In order for a user to pick their seat on the train, there could be a sub-resource for seating:

```http
GET /bookings/:my_booking_ref/seating
```

```
{
  "my_seat": "A12",
  "available_seats": [
    "A1", "A2", "A3", "A4", "A5", "A6", ...
  ]
}
```

Creating the seating sub-resource like this will make a unique seating chart for every single user, because "all the seats" and "this users seat" have been mixed together. These responses could still be cached, but it would have to be a `private` cache because the generic information has been "tainted" with data unique to each user. 10,000 users would have 10,000 cache entries, and the chance/impact of them being reused would be rather small, so there isn't much benefit to filling the entire cache with all this.

Consider breaking this down into two resources:

- `GET /bookings/:my_booking_ref` - See booking details, including current seat.
- `GET /trips/:trip_id/seats` - List seat availability on the train.
- `PUT /bookings/:my_booking_ref` - Update booking (eg to reserve a seat).

By moving the seat information to the booking resource, the seating availability becomes generic. With nothing personalized about it at all, the resource can be cached for everyone who is trying to book a seat on this train.

There is no downside to caching this data, because it is the same for everyone. Even if it changes, it's easy to grab the latest data from the server and suggest the user select another seat if it's no longer available. This allows the seat availability to be cached for a long time, and only worry about refreshing the plan if the `PUT` request fails because a seat is no longer available.

## Content Delivery Networks (CDNs)

HTTP caching works well when clients use it, and many do automatically, like web browsers or systems with caching middleware. But it becomes even more powerful when combined with tools like [Fastly](https://www.fastly.com/) or [Varnish](https://www.varnish-software.com/products/varnish-cache/). 

These tools sit between the server and the client, acting like intelligent gatekeepers:

![A sequence diagram showing a Client, Cache Proxy, and Server. A web request travels from client to proxy, then is sent on to the server, showing a "cache miss". The response then travels back from the server to the cache proxy, and then is sent to the client](./assets/httpcachemiss.png)

![A sequence diagram showing a Client, Cache Proxy, and Server. A web request travels from client to proxy, but does not go to the server, showing show a "cache hit". The response is served from the cache proxy to the client without involving the server](./assets/httpcachehit.png)

Client-caching like this is certainly useful, but the real power of caching comes when API web traffic is routed through a caching proxy. Using hosted solutions like Fastly or AWS CloudFront, this could be a case of changing DNS settings. For self-hosted options like Varnish, instead of pointing DNS settings to a hosted solution somebody will need to spin up a server to act as the cache proxy. 

Many API gateway tools like Tyk and Zuplo have caching built in, so this functionaity may already be available in the ecosystem and just need enabling.

## Save emissions (and money) with HTTP caching

The Internet (and it's infrastructure) is responsible for [4% of global CO2 emissions](https://www.bbc.com/future/article/20200305-why-your-internet-habits-are-not-as-clean-as-you-think), and with [83% of web traffic coming from APIs](https://www.akamai.com/newsroom/press-release/state-of-the-internet-security-retail-attacks-and-api-traffic), it becomes critical to consider the carbon impact of new APIs.

Each unnecessary API request costs server resources, bandwidth, and energy. That energy comes with a carbon footprint, whether it's from a data center powered by renewable energy or not.

## Summary

By reducing redundant requests, HTTP caching can:

- Cut down on server load (lowering hosting costs).
- Reduce network traffic (lowering bandwidth fees).
- Minimize energy consumption (a win for the environment).

Imagine millions of users no longer making unnecessary requests for unchanged data. Designing APIs to be cache-friendly from the start not only benefits the environment but also leads to faster, more efficient, and user-friendly APIs. It's a win-win: better performance for users, lower operational costs for providers, and a positive impact on the planet.

Next time a new API is being designed, ask the question: How much of this data do I really need to serve fresh each time, and how much of this can be cached with a combination of `Cache-Control` and `ETag` headers?

## Further Reading

- [MDN: HTTP Caching](https://developer.mozilla.org/en-US/docs/Web/HTTP/Caching)
- [ETags: What are they and how to use them?](https://www.fastly.com/blog/etags-what-they-are-and-how-to-use-them)
- [What is Cache Control?](https://www.fastly.com/blog/cache-control-wild)


 This is the content for the doc api-design/collections.md 

 ---
description: Learn how to use resources and collections for a REST API, getting stuck into some real world examples, using links to get between them all, and some pitfalls to avoid.
---

# Returning resources & collections of data

In the context of REST/HTTP APIs, a resource represents a specific piece of data or object that can be accessed via a unique URI (Uniform Resource Identifier). This could be anything: a user, a blog post, a product, or an order. Whereas a collection is a group of resources. It’s a list or set of all the items of a particular type.

## Structuring URLs for resources & collections

Retrieval of resources and collections both use the `GET` operation. Established convention is to have a unique base URL for each type of resource in an API: `/invoices`, `/transactions`, etc. 

To retrieve the entire collection of resources, a `GET` request is made to that URL: `GET /invoices`. 

```http
GET /invoices
```

```json
[
  {
    "id": "645E79D9E14",
    "invoiceNumber": "INV-2024-001",
    "customer": "Acme Corporation",
    "amountDue": 500.00,
    "dateDue": "2024-08-15"
  },
  {
    "id": "646D15F7838",
    "invoiceNumber": "INV-2024-002",
    "customer": "Monsters Inc.",
    "amountDue": 750.00,
    "dateDue": "2024-08-20"
  }
]
```

To retrieve a specific resource within that collection, a slightly different
endpoint exists: `GET /invoices/645E79D9E14`. In this case, the ID `645E79D9E14`
is a unique identifier for a specific invoice.

```http
GET /invoices/645E79D9E14
```

```json
{
  "id": "645E79D9E14",
  "invoiceNumber": "INV-2024-001",
  "customer": "Acme Corporation",
  "amountDue": 500.00,
  "dateDue": "2024-08-15",
  "dateIssued": "2024-08-01",
  "items": [
    {
      "description": "Consulting Services",
      "quantity": 10,
      "unitPrice": 50.00,
      "total": 500.00
    }
  ],
  "links": {
    "self": "/invoices/645E79D9E14",
    "customer": "/customers/acme-corporation",
    "payments": "/invoices/645E79D9E14/payments"
  }
}
```

The resource contains loads of data, including the customer name, an array of
items on the invoice, various dates, and how much of the invoice is left to be
paid.

It also has `"links"`, which can be related resources, collections, which could
be related data, or could be available actions foe the resource. For example, a
`"pay"` link which signals a payment can be made, a `"send"` link which helps
consumers send an invoice, or the example here which contains a `"payments"`
link to also allows for payments to be made, but also supports viewing a list of
partial and failed payments.

## What is a collection

A collection can be considered a special type of resource, which is a list of a
specific type of resource. For example, a collection of invoices, a collection
of products, or a collection of users.

Usually the API returns some basic information about each resource in the
collection, like title, id, and the sort of information an application might
want to show on a webpage showing the list. Then the links allow a client to
load up more data for each resource it's interested in.

## How do HTTP methods fit in

REST APIs typically use standard HTTP methods to interact with resources and
collections:

**GET:** Retrieve data.

- `/posts` - Get a collection of all blog posts.
- `/posts/abc1` - Get a single blog post by its ID.

**POST:** Create a new resource.

- `/posts` - Add a new blog post to the collection.

**PUT:** Replace an entire existing resource.

- `/posts/abc1` - Update the blog post with ID abc1.

**PATCH:** Update part an existing resource.

- `/posts/abc1` - Update the blog post with ID abc1.

**DELETE:** Remove a resource.

- `/posts/abc1` - Delete the blog post with ID abc1.

APIs are about a whole lot more than just CRUD, but when thinking about
collections and resources this is a simple way it really helps to think about
how these operations map to the data and actions available.

## Best practices

### URI structure

The structure of URIs in REST APIs is crucial for consistency and readability.
Here are some common conventions.

**Nouns over Verbs**: URIs typically use nouns (like /posts) rather than verbs
(like `/getPosts`), because HTTP methods (GET, POST, etc.) already imply the
action.

**Pluralization:** Collections are usually plural (e.g.: `/posts`), while
resources are identified with a unique identifier (e.g.: `/posts/abc1`).

**Minimal Data in Collections:** When retrieving a collection, APIs often return
minimal information about each resource to save bandwidth and speed up
responses. This allows consumers to quickly scan the collection and then retrieve more
detailed information if needed.

```http
GET /posts
```

``` json
[
    {
        "id": "abc1",
        "title": "Understanding REST APIs",
        "author": "Bob Doe",
        "link": "/posts/abc1"
    },
    {
        "id": "def2",
        "title": "Introduction to HTTP Methods",
        "author": "Sally Smith",
        "link": "/posts/def2"
    }
]
```

There's plenty of debate about how much detail to put in collections and how
much to put in resources, but the key is to keep it simple and consistent.

Putting everything in the collection would bloat the list view horrendously,
wasting time, money, and carbon emissions stressing the infrastructure passing
around massive JSON payloads with content that may not even be needed right now.

Trimming them down to a bare minimum could then force consumers to make an
unreasonable number of requests to get even the most basic data.

Some API designers go as far as putting no information at all in their
collections, because it can all be fetched directly from the resources. This
helps make the responses a lot more [cachable](/api-design/caching) because if
any of the data does change for any of the resources then the collections do not
need to be purged from the cache to maintain consistency.

```http
GET /posts
```

```json
[
    {
        "link": "/posts/abc1"
    },
    {
        "link": "/posts/def2"
    }
]
```

There is no one simple answer here, but using a bit of common sense and talking
to consumers about their use cases should usually help find the right balance.

In general, it's a sensible default to aim for a reasonable middle-ground, where
summary data is in the collection: name, ID, status, and a few key bits of
data that consumers are the most likely to need when they're building an index of data.

Then if consumers need more data, they can go fetch it, and with modern day
HTTP/2 & HTTP/3 this does not have as many performance burdens as it used to.
Especially when API caching is implemented with quality API design then slimming down collections can
even lead to better performance than trying to squash everything into the collection.

### Linking to related resources

Collections linking to resources is helpful, letting clients follow various
links throughout an API like a user browsing a website. Resources can link
to other related resources and collections, which might be data but could also
be considered "actions", all handled through the same conventions.

```http
GET /posts/abc1
```

```json
{
    "id": "abc1",
    "title": "Understanding REST APIs",
    "author": "Jane Doe",
    "content": "This is a detailed tutorial on REST APIs...",
    "datePublished": "2023-10-01",
    "links": {
        "self": "/posts/abc1",
        "author": "/authors/jane-doe",
        "comments": "/posts/abc1/comments"
    }
}
```

In this response:

- The `self` link points to the resource itself, like a canonical URL, which is
  a handy convention for knowing where something came from, whether that's a
  JSON blob that has been saved in a database without the headers, or providing
  one location to call back to if this was a temporary action which cannot be
  repeated. 

- The `author` link points to the resource representing the author of the post
  because it's quite likely clients will want to load that. Nobody will need to
  load every author for every post because HTTP caching will kick in, and makes
  no sense to squash that data into the post resource.

- The `comments` link points to a collection of comments related to this post if
  consumers want to load that, and any application loading that up is going to want to
  do it after it's got the post showing to users, so it doesn't matter if it
  loads later.

Splitting up API data into multiple endpoints that can be grabbed if needed is
really handy, upgrading a REST API from basically a set of functions which grab
some data, into an Object-Relational Mapping (ORM) where relationships can be
navigated easily, but going one step further and focusing on actions turns the API into 
essentially a state machine over HTTP.

## Don't confuse resource design & database design

A key aspect of API design is not tying API resources and collections directly
to the underlying database. Database needs to change and adapt rapidly as data
structures change, but APIs needs to evolve slowly (or not at all).

The more tied an API becomes to an internal database structure, the more they're
going to more often API consumers are going to have to rewrite their
applications.

**Normalization will change over time:** An invoice resource might contain a
`customer` object, even though it is in a separate database table. That could be
INNER JOIN'ed in the background (for those using SQL). Then if that query starts
to get really slow, the database could reduce the level of normalization and
bring that customer name directly into the `invoices` table (which is going to
help maintain proper historical accuracy if the customer changes their name).

**There could be pivot tables involved which don't need to be exposed:** Linking
tree planting `sites` to all of the tree `species` might involve a
`sites_species` database but that doesn't mean the API should have a
`/sites_species` table.

There's lots to think about, but the quick point here is to avoid letting
database design influence resource design too heavily. Clients should always
come first.

## Real-World Examples

**GitHub API**

When retrieving a list of repositories, each repository item includes a url
field that links to the full details of that repository.

```http
GET /users/octocat/repos
```

```json
[
  {
      "id": 1296269,
      "name": "Hello-World",
      "url": "https://api.github.com/repos/speakeasy-api/Hello-World"
  }
]
```

**Twitter API**

When retrieving a user's timeline, each tweet includes a URL that links to the specific tweet details.

```http
GET /statuses/user_timeline.json?screen_name=speakeasydev
```

```json
[
  {
      "created_at": "Wed Oct 10 20:19:24 +0000 2018",
      "id": 1050118621198921728,
      "text": "Just setting up my Twitter. #myfirstTweet",
      "url": "https://api.twitter.com/1.1/statuses/show/1050118621198921728.json"
  }
]
```

**Stripe API**

Stripe has a collection which is a bit different, instead of returning a JSON array directly in the response, it wraps it in an object with a data property:

```http
GET /v1/charges
```

```json
{
  "object": "list",
  "url": "/v1/charges",
  "has_more": false,
  "data": [
    {
      "id": "ch_3MmlLrLkdIwHu7ix0snN0B15",
      "object": "charge",
      "amount": 1099,
      "amount_captured": 1099,
      "amount_refunded": 0,
      "application": null,
      "application_fee": null,
      "application_fee_amount": null,
      "balance_transaction": "txn_3MmlLrLkdIwHu7ix0uke3Ezy",
      "billing_details": {
        "address": {
          "city": null,
          "country": null,
          "line1": null,
          "line2": null,
          "postal_code": null,
          "state": null
        },
        "email": null,
        "name": null,
        "phone": null
      },
      "calculated_statement_descriptor": "Stripe",
      "captured": true,
      "created": 1679090539,
      "currency": "usd",
      "customer": null,
      ... snip because its HUGE...
    }
    {...}
    {...}
  ],
}
```

They do this so they can add in various other bits of metadata, but much of this
metadata comes down to pagination which can be handled other ways (like popping
pagination into Links headers), so this practice is somewhat dying out.

## Best Practices

Returning resources and collections in a logical and consistent way is tough at
first, but there are standards and best practices that can help avoid common
mistakes.

## Using a "Data Envelope"

One common convention used by many popular APIs (like the Stripe example above)
is to wrap data in some sort of "envelope", which is a common term for putting
it into another object so there's a bit of room for metadata.

```json
{
  "data": [
    {
      "id": 123,
      "name": "High Wood",
      "lat": 50.4645697,
      "lon": -4.4865975
      "created_at": "2022-10-24T12:00:00Z"
    },
    {
      "id": 456,
      "name": "Goytre Hill",
      "lat": 52.1356114,
      "lon": -3.5975258
      "created_at": "2024-12-01T09:00:00Z"
    }
  ],
  "meta": {
    "rate-limit": 100,
    "next": "/places?page=2"
  }
}
```

This was really popular for a long time, but we don't need to do this anymore,
because most of that metadata would be better off in a response header.

The move to headers may in part be down to HTTP/2 adding [HPAK header
compression](https://blog.cloudflare.com/hpack-the-silent-killer-feature-of-http-2),
meaning it is more efficient to use headers for anything that's sensible to use
them for, and more standards are popping up to move these concepts out of custom
implementations in JSON and elsewhere, and move them into headers.

For example, instead of putting rate limiting data into `meta`, the [`RateLimit`
header](https://www.ietf.org/archive/id/draft-ietf-httpapi-ratelimit-headers-08.html),
can be used, and instead of putting `pagination` into the response, why not use
the `Links` header.

```http
HTTP/2 200 OK
Content-Type: application/json
Cache-Control: public, max-age=18000
RateLimit: "default";r=100;t=60
Link: <https://api.example.com/places?page=1&size=10>; rel="first",
      <https://api.example.com/places?page=3&size=10>; rel="next",
      <https://api.example.com/places?page=100&size=10>; rel="last"

[
  {
    "id": 123,
    "name": "High Wood",
    "lat": 50.4645697,
    "lon": -4.4865975
    "created_at": "2022-10-24T12:00:00Z"
  },
  {
    "id": 456,
    "name": "Goytre Hill",
    "lat": 52.1356114,
    "lon": -3.5975258
    "created_at": "2024-12-01T09:00:00Z"
  }
]
```

This probably looks easier to work with in some ways, and harder to work with in
some ways, but it's more performant, and any complexity can be deferred to
standard libraries and packages which handle all of this for API consumers
automatically.

## Data Format Standards

Instead of creating custom formats it may be easier for API developers and
consumers alike to use an existing "data format" standard.

- [CollectionJSON](http://amundsen.com/media-types/collection/format/)
- [HAL](http://stateless.co/hal_specification.html)
- [JSON:API](https://jsonapi.org/)
- [OData](https://www.odata.org/)
- [Siren](https://github.com/kevinswiber/siren)

Using any of these can avoid the "bikeshedding" (arguments about pros and cons
of each minor choice), and more importantly it will open the doors to more
standard tooling on both the client-side and server-side.

## Summary

**Use Consistent Naming:** Stick to conventions like using plural nouns for
collections. It shouldn't matter, but it drives people mad.

**Keep it Simple:** Start with basic endpoints and add complexity only when
necessary. It's easier to add things to an API if they're needed later, than
take them away once they're in production.

**API model is not a database model:** Do not try and recreate the database
model over HTTP because it will be a big waste of time, and be almost
immediately wrong anyway, which will make clients upset.


 This is the content for the doc api-design/data-formats.md 

 # Formatting API data

A request body (and a response body) will have a `Content-Type`, and that
content type will tell tools how the data is formatted so it can be converted
into something meaningful in whichever programming language is being used.

## JSON: The Modern Standard

JSON has become the de facto standard for API requests because it:

- Supports native data types (numbers, booleans, null)
- Allows nested structures
- Is human-readable
- Has excellent tooling support

Example of complex JSON request:

```json
{
  "place": {
    "name": "Central Park",
    "location": {
      "lat": 40.785091,
      "lon": -73.968285
    },
    "features": ["park", "landmark"],
    "isAccessible": true,
    "capacity": null
  }
}
```

## XML: Ye Oldé Standard

Any modern API will support JSON. Occasionally they will support XML as well.

XML is relict of the early internet. It dominated web APIs in the 2000s with
standards like SOAP and XML-RPC, but was largely displaced by JSON in the 2010s
due to JSON's simplicity and natural fit with JavaScript. Today, XML persists
mainly in legacy systems, enterprise SOAP services, and specific domains like
publishing (DocBook), feed syndication (RSS/Atom), and configuration files
(Maven, Android manifests).

JSON is a lot easier to work with than XML, and it is a lot easier to read. It
is also more compact, which is important when sending data over the wire.

An example of a bunch of different data types in JSON.

```json
{
  "place": {
    "id": 1,
    "name": "This is a bunch of text.",
    "is_true": false,
    "maybe": null,
    "empty_string": ""
  }
}
```

This same data in XML.

```xml
<places>
    <place>
        <id>1</id>,
        <name>This is a bunch of text.</name>
        <is_true>0</is_true>
        <maybe />
        <empty_string />
    </place>
</places>
```

Basically, in XML, _everything_ is considered a string, meaning integers,
booleans, and nulls can be confused. Both `<maybe />` and `<empty_string />`
have the same value, because there is no way to denote a `null` value either.
Gross.

## Form Data: Legacy Format

Form Data uses the `application/x-www-form-urlencoded` mime type, and is helpful
when accepting web forms from a browser using the `<form>` HTML tag. This was
very popular decades ago, but with modern web applications using more
single-page applications (SPAs) and mobile apps to speak JSON natively, it is
something most people just don't bother with anymore.

It's not just that it's old, it's cumbersome to work with, and suffers from a
lack of data types like XML but with even more awkward syntax.

Everything is a string. To handle a boolean a client has to send `1` or `0`,
which will be read as `"1"` or `"0"`. Some would suggest sending `property=true`, but that is
a literal `"true"` string which can be confusing to deal with.

```http
POST /checkins HTTP/1.1
Host: api.example.org
Content-Type: application/x-www-form-urlencoded

place_id=1&message=This%20is%20a%20bunch%20of%20text.&with_friends[]=1&with_friends[]=2&with_friends[]=3
```

This is a bit of a mess, as the message needs to be "URL encoded" and the
`with_friends` is an array with awkward syntax. On top of that it's not clear
what the data types are. It is also a bit of a pain to work with on the
server-side, as the data needs to be parsed and spit up properly, then converted
to the correct data types.

For comparison, the same data in JSON is a lot easier to work with.

```http
POST /checkins HTTP/1.1
Host: api.example.org
Content-Type: application/json

{
  "place_id": 1,
  "message": "This is a bunch of text.",
  "with_friends": [1, 2, 3]
}
```

This is a JSON object, and it is easy to see what is going on. The `place_id` is
an integer, the `message` is a string, and `with_friends` is an array of
integers.

## Multipart Form Data: An Occasionally Helpful Nightmare


Multipart forms are a way to send data in multiple parts as a single HTTP request, often used in REST APIs for handling mixed types of data, such as JSON and binary files (e.g., images or documents). Unlike standard form submission, where data is encoded as application/x-www-form-urlencoded, multipart forms use the multipart/form-data encoding, which allows for the inclusion of both text and file content in the same request.

This is particularly useful for endpoints that need to process metadata (e.g., JSON) alongside uploaded files. Each part of the form is separated by a boundary string and includes headers that describe the content type and disposition of the part.

```http
POST /checkins HTTP/1.1
Host: api.example.org
Content-Type: multipart/form-data; boundary=----WebKitFormBoundary7MA4YWxkTrZu0gW

------WebKitFormBoundary7MA4YWxkTrZu0gW
Content-Disposition: form-data; name="metadata"
Content-Type: application/json

{
  "place_id": 1,
  "message": "This is a bunch of text.",
  "with_friends": [1, 2, 3]
}
------WebKitFormBoundary7MA4YWxkTrZu0gW
Content-Disposition: form-data; name="file"; filename="example.jpg"
Content-Type: image/jpeg

[Binary data of the image file]
------WebKitFormBoundary7MA4YWxkTrZu0gW--
```

This is either confusing or brilliant depending on perspective, but it's
generally a massive pain to work with. 


## Best Practices

### 1. Stick to JSON wherever possible

Work out which content type (or types) are actually needed, and _stick to that_.
95% of the time, that's JSON.

Some want to add CSV or HTML "just in case", and others want to add all the fun
new formats like BSON or MessagePack because they're "quicker" (without doing
basic optimizations on their code/database which would likely yield more
meaningful performance gains). That might be a bit of fun, but it's all adding a
maintenance burden and expecting too much of clients.

Start with JSON and wait for a big client to ask for a specific format, then
weigh it up against the cost of supporting it.

### 2. Avoid multipart forms

There are a few reasons to avoid this. It's hard to document, weird to handle
partial errors, and generally confuses beginners trying to work with an API. 

An SDK can hide some of the complexity, but that won't solve the awkward race
conditions that pop up creating something from the first "part", then the second
or third part fails, rolling back database transactions after emails have
already gone out. 

Designing an API for the least experienced user is not necessarily the goal, but
making things unnecessarily complex isn't the plan either, so stick with "one
endpoint does one thing". File uploads can be handled with other more targeted
endpoints.


 This is the content for the doc api-design/errors.mdx 

 ---
description: "Design useful API errors to save clients time."
---

import { Callout } from "~/components";

# Returning informative API Errors

When building an API it's natural to put most of the focus into building a
beautiful "happy path" where nothing goes wrong. Developers often don't like to
consider the failure cases, because of course everything is going to work out
just fine, so errors are often not designed with the same care as the rest of
the API.

Errors in an API are not just an edge-case, they are a crucial part of the
functionality, and should be treated like a core feature to be proudly shared
and documented with users. Failing clearly and concisely is arguably more
important than any other aspect of API design.

Errors should:

- Be as detailed as possible.
- Provide context as to exactly what went wrong, and why.
- Help humans find out more information about the problem.
- Help computers decide what to do next.
- Be consistent across the API.

## HTTP Status Codes

The journey to great errors starts with [status
codes](/api-design/status-codes). Status code conventions exist to specify what
category of error has occurred, and they are a great way to help developers
make decisions automatically based on the status code, like automatically
refreshing access tokens on a `403`, or retrying the request on a `500`.

Learn more about [HTTP Status Codes](/api-design/status-codes), and how to use
them effectively.

## Application Errors

HTTP status codes only set the scene for the category of issue that has
occurred. An error like `400 Bad Request` is generally used as a vague catch-all
error that covers a whole range of potential issues. 

More information will be required to help developers understand what went wrong,
and how to fix it, without having to dig through logs or contact the support
team. 

Error details are useful for:

1. humans - so that the developer building the integration can understand the issue.
2. software - so that client applications can automatically handle more situations correctly.

Imagine building a carpooling app, where the user plans a trip between two
locations. What happens if the user inputs coordinates that which are not
possible to drive between, say England and Iceland? Below is a series of
responses from the API with increasing precision:

```http
HTTP/1.1 400 Bad Request
```

A not very helpful error response, the user will have no idea what they did
incorrectly.

```http
HTTP/1.1 400 Bad Request

"error": {
    "message": "Trip is not possible, please check start/stop coordinates and try again."
}
```

This message could be passed back to the user which will allow them to figure
out how to address the issue, but it would be very difficult for an application
to programmatically determine what issue occurred and how to respond.

```http
HTTP/1.1 400 Bad Request

"error": {
    "code": "trip_not_possible",
    "message": "Trip is not possible, please check start/stop coordinates and try again."
}
```

Now this includes data that can help our users know what's going on, as well as
an error code which let's them handle the error programmatically if they would
like to.

So, we should always include both API error messages, as well as API error
codes. Let's take a closer look at the best practices for each of these.

## API error messages

API error messages should be clear, concise, and actionable. They should provide
enough information for the developer to understand what went wrong, and how to
fix it.

Here are a few best practices for API error messages:

- **Be Specific**: The error message should clearly explain what went wrong.
- **Be Human-Readable**: The error message should be easy to understand.
- **Be Actionable**: The error message should provide guidance on how to fix the issue.
- **Be Consistent**: Error messages should follow a consistent format across the API.

## API error codes

The use of an error code is well established in the API ecosystem. However,
unlike status codes, error codes are specific to an API or organization. That
said, there are conventions to follow to give error codes a predictable
format.

![Screenshot of Stripe.com API documentation's "Error Codes" page, which explains how "error codes" are added to provide extra information on top of HTTP status codes.](./assets/stripe-error-codes.png)

Stripe's error codes have a nice easy to understand structure. Each error has a
code which is a string, and a message which is a string, and that string is
documented online so it can be understood, or reported to support.

```http
HTTP/1.1 400 Bad Request

{
  "error": {
    "code": "trip_too_short",
    "message": "This trip does not meet the minium threshold for a carpool or 2 kilometers (1.24 miles)."
  }
}
```

This makes it easy for developers to react programatically to the error too:

```typescript
if (error.code === 'trip_too_short')
```

## Complete Error Objects

Include a `code` and a `message` puts an error message off to a great start, but
there's more to be done to turn errors into a handy feature instead of just a
red flag.

Here's the full list of what an API error should include:

- **Status Code**: Indicating the general category of the error (4xx for client errors, 5xx for server errors).
- **Short Summary**: A brief, human-readable summary of the issue (e.g., "Cannot checkout with an empty shopping cart").
- **Detailed Message**: A more detailed description that offers additional context (e.g., "It looks like you have tried to check out but there is nothing in your cart").
- **Application-Specific Error Code**: A unique code that helps developers programmatically handle the error (e.g., `cart-empty`, `ERRCARTEMPTY`).
- **Links to Documentation**: Providing a URL where users or developers can find more information or troubleshooting steps.

Some folks will build their own custom format for this, but let's leave that to
the professionals and use existing standards: [RFC 9457 - Problem Details for
HTTP APIs](https://www.rfc-editor.org/rfc/rfc9457.html). This is being used by
more and more API teams.

```json
{
  "type": "https://signatureapi.com/docs/v1/errors/invalid-api-key",
  "title": "Invalid API Key",
  "status": 401,
  "detail": "Please provide a valid API key in the X-Api-Key header."
}
```

This example of an error from the [Signature
API](https://signatureapi.com/docs/errors) includes a `type`, which is basically
the same as an error code, but instead of an arbitrary string like
`invalid-api-key` the standard suggests a URI which is unique to the API (or
ecosystem): `https://signatureapi.com/docs/v1/errors/invalid-api-key`. This does
not have to resolve to anything (doesn't need to go anywhere if someone loads it
up) but it _can_, and that covers the "link to documentation" requirement too.

![API Documentation for the SignatureAPI, with an explanation of what the error is, what happened, and how to fix it](./assets/errors-documentation.png)

Why have both a `title` and a `description`? This allows the error to be used in
a web interface, where certain errors are caught and handled internally, but
other errors are passed on to the user to help errors be considered as
functionality instead of just "Something went wrong, erm, maybe try again or
phone us". This can reduce incoming support requests, and allow applications to
evolve better when handling unknown problems before the interface can be
updated.

Here's a more complete usage including some optional bits of the standard and
some extensions.

```json
HTTP/1.1 403 Forbidden
Content-Type: application/problem+json

{
 "type": "https://example.com/probs/out-of-credit",
 "title": "Not enough credit.",
 "detail": "The current balance is 30, but that costs 50.",
 "instance": "/account/12345/msgs/abc",
 "balance": 30,
 "accounts": ["/account/12345", "/account/67890"]
}
```

This example shows the same `type`, `title`, and `detail`, but has extra bits.

The `instance` field allows the server to point to a specific resource (or endpoint)
which the error is relating to. Again URI could resolve (it's a relative path to
the API), or it could just be something that does not necessarily exist on the
API but makes sense to the API, allowing clients/users to report a specific instance
of a problem with more information that "it didn't work...?".

The `balance` and `account` fields are not described by the specification, they
are "extensions", which can be extra data which helps the client application
report the problem back to the user. This is extra helpful if they would rather
use the variables to produce their own error messages instead of directly
inserting the strings from `title` and `details`, opening up more options for
customization and internationalization.

## Best Practices

Handling errors in API design is about more than just choosing the right HTTP
status code. It's about providing clear, actionable information that both
developers, applications, and end-users of those applications can understand and
act upon.

Here are a few more things to think about when designing errors.

### 200 OK and Error Code

HTTP 4XX or 5XX codes alert the client, monitoring systems, caching systems, and
all sorts of other network components that something bad happened.

**The folks over at CommitStrip.com know what's up.**

![This monster has got his API responding with HTTP Status 200 OK despite the request failing.](./assets/errors-200-ok.jpeg)

Returning an HTTP status code of 200 with an error code confuses every single
developer and every single HTTP standards-based tool that may ever come into
contact with this API. now or in the future.

Some folks want to consider HTTP as a "dumb pipe" that purely exists to move data up and
down, and part of that thinking suggests that so long as the HTTP API was able to respond then thats a 200 OK.

This is fundamentally problematic, but the biggest issue is that it delegates
all of the work of detecting success or failure to the client code. Caching tools will cache the error. Monitoring tools 
will not know there was a problem. Everything will look absolutely fine despite mystery weirdness happening throughout the system. Don't do this!

### Single or Multiple Errors?

Should an API return a single error for a response, or multiple errors?

Some folks want to return multiple errors, because the idea of having to fix one
thing, send a request, fail again, fix another thing, maybe fail again, etc.
seems like a tedious process.

This usually comes down to a definition of what an error is. Absolutely, it
would be super annoying for a client to get one response with an error saying
"that email is in a bad format" and then when they resubmit they get another
error with "the name you sent has unsupported characters". Both those validation
messages could have been sent at once, but an API doesn't need multiple errors
to do that.

The error there is that "the resource is invalid", and that can be a single
error. The validation messages are just extra information added to that single
error.

```json
{
  "type": "https://example.com/probs/invalid-payload",
  "title": "The payload is invalid",
  "details": "The payload has one or more validation errors, please fix them and try again.",
  "validation": [
    {
      "message": "Email address is not properly formatted",
      "field": "email"
    },
    {
      "message": "Name contains unsupported characters",
      "field": "name"
    }
  ]
}
```

This method is preferred because it's impossible to preempt things that might go
wrong in a part of the code which has not had a chance to execute yet. For
instance, that email address might be valid, but the email server is down, or
the name might be valid, but the database is down, or the email address is
already registered, all of which are different types of error with different
status codes, messages, and links to documentation to help solve each of them
where possible.

### Custom or standard error formats

When it comes to standards for error formats, there are two main contenders:

**RFC 9457 - Problem Details for HTTP APIs**

The latest and greatest standard for HTTP error messages. There only reason not
to use this standard is not knowing about it. It is technically new, released in
2023, but is replacing the RFC 7807 from 2016 which is pretty much the same
thing.

It has a lot of good ideas, and it's being adopted by more and more
tooling, either through web application frameworks directly, or as "middlewares"
or other extensions.

This helps avoid reinventing the wheel, and it's strongly recommended to use it
if possible.

**JSON:API Errors**

[JSON:API](https://jsonapi.org/) is not so much a standard, but a popular
specification used throughout the late 2010s. It focuses on providing a common
response format for resources, collections, and relationships, but it also has a
decent [error format](https://jsonapi.org/format/#errors) which a lot of people
like to replicate even if they're not using the entire specification.

**Pick One**

There has been a long-standing stalemate scenario where people do not implement
standard formats until they see buy-in from a majority of the API community, or
wait for a large company to champion it, but seeing as everyone is waiting for
everyone else to go first nobody does anything. The end result of this is
everyone rolling their own solutions, making a standard less popular, and the
vicious cycle continues.

Many large companies are able to ignore these standards because they can create
their own effective internal standards, and have enough people around with
enough experience to avoid a lot of the common problems around.

Smaller teams that are not in this privileged position can benefit from
deferring to standards written by people who have more context on the task at
hand. Companies the size of Facebook can roll their own error format and brute
force their decisions into everyones lives with no pushback, but everyone on
smaller teams should stick to using simple standards like RFC 9457 to keep
tooling interoperable and avoid reinventing the wheel.

### Retry-After

API designers want their API to be as usable as possbile, so whenever it makes
sense, let consumers know when and if they should come back and try again., and if so, when. The
`Retry-After` header is a great way to do this.

```http
HTTP/1.1 429 Too Many Requests
Retry-After: 120
```

This tells the client to wait two minutes before trying again. This can be a
timestamp, or a number of seconds, and it can be a good way to avoid a client
bombarding your API with requests when it's already struggling.

Learn more about [Retry-After on MDN](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Retry-After).

<Callout title="NOTE" variant="info">
  <p>
    Help your API consumers out by{" "}
    <a href="/docs/runtime/retries">enabling retry logic</a> in your Speakeasy
    SDK.
  </p>
</Callout>


 This is the content for the doc api-design/file-uploads.mdx 

 ---
description: > 
  Learn how to design file uploads in an API.
---

# File Uploads

File uploads can be confusing to work with at first because it takes a bit of a
mental shift to think about. 

Firstly, a file is usually not just a file, it also has metadata needs to go
with it and that can be hard to keep track of.

Secondly, it is not really a file upload, simply a resource or collection of
resources with a `Content-Type` of something other than the usual JSON or XML.

## URL design 

To visualize how file uploads could be designed into an API, let's see how
images could be added for two different use-cases.

A user could have an avatar sub-resource, which might look like this:

```
/users/<username>/avatar
```

This can then be uploaded and retrieved on the same URL, making it a consistent
API experience with any other type of resource. 

Multiple images could be needed for product thumbnails, and that can be a
sub-collection of the product.

```
/product/<uuid>/thumbnails
```

A collection of resources could be available, and a particular thumbnail could
be retrieved or deleted using regular semantics like `GET` and `DELETE` on the
particular resource URL.

```
/product/<uuid>/thumbnails/<image-uuid>
```

## POST or PUT

There is no particular [HTTP method](/api-design/http-methods) specific to file
uploads, instead we use the appropriate hTTP method for the resource or
collection being worked with.

For the example of a single avatar for each user, the URL is already known, and
it does not make any difference whether this is the first avatar they have
uploaded, or they have remade the same request 10 times in a row after an
intermitted internet connection messed up the first few. This should use a
`PUT`, because that means "The end result should be this, regardless of what is
there right now."

```
PUT /users/<username>/avatar
```

When working with a collection, the URL of the resource is not known until it
has been created. For this reason a `POST` would be more appropriate.

```
POST /product/<uuid>/thumbnails
```

How these uploads work could vary depending on the use case, so let's look at
the most popular methods.

## Different methods of file upload

There are a few popular approaches to file uploads in APIs:

1. Uploading a file by itself, like adding an avatar for an existing user.
2. Uploading a file with metadata in the same request, like a video file with a title, description, and geodata.
3. Importing a file from a URL, like a user's avatar from Facebook.

It's not entirely unreasonable to consider an API using all of these approaches
for different use cases throughout the API depending on the specifics. Lets
learn how these things work, and talk about when to use one over the other.

### Method A: Direct file uploads

When no metadata is needed to be uploaded with a request, a direct file upload
is beautifully simple.

- Uploading a CSV of emails being imported to send a tree sponsorship email to.
- A new logo for a funding partner.
- A replacement avatar for a user profile.

In all of these situations, the file is the only thing that needs to be uploaded
and they also have a handy content type that can go right into the HTTP request
to let the API know what's coming.

```http
PUT /users/philsturgeon/image HTTP/2
Authentication: Bearer <token>
Content-Type: image/jpeg
Content-Length: 284

<raw image content>
```

Any file can be uploaded this way, and the API can infer the content type from
the `Content-Type` header. The API can also infer the user from the token, so 
the request does not need to include any user information.

The API will then save the file, and return a response with a URL to the file
that was uploaded. This URL can be used to access the file in the future, and
can be used to link the file to the user that uploaded it.

The response here will have a simple body:

```json
{
  "url": "https://cdn.example.org/users/philsturgeon.jpg",
  "links": {
    "self": "https://example.org/api/images/c19568b4-77b3-4442-8278-4f93c0dd078",
    "user": "https://example.org/api/users/philsturgeon"
  }
}
```

That `user` was inferred from the token, and the `url` is the resulting URL to
the avatar that has been uploaded. Normally this would be some sort of Content
Delivery Network (CDN) URL, but it could be a direct-to-S3 URL, or a URL to a Go
service that handles file uploads. It's up to you, but its good to split off
file uploads to a separate service to keep your API servers free to do more
impactful work than serving files.

### Method B: Upload from URL

Depending on how the client application works, uploading from a file might not
be the preferred approach. A common pattern is mobile clients uploading user
images directly from the photo libraries on the mobile device, and the web teams
were pulling avatars from Facebook or Twitter profiles after they have done a
"social login" flow.

This is common because its harder for the web application to access the raw
content of a file using just browser-based JavaScript. At some point a server
needs to be involved to read that, so whether they have uploaded via cloudinary
or some other upload service, the API server is going to need to take a URL and
download the file.

The same endpoint that handled the direct upload can serve this same logic, with
the `Content-Type` header changed to `application/json` and the body of the
request containing a URL to the file.

```http
PUT /users/philsturgeon/image HTTP/2
Authentication: Bearer <token>
Content-Type: application/json

{
  "url" : "https://facebook.com/images/dfidsyfsudf.png"
}
```

The API will then download the file from the URL, save it, and return a response
with a URL to the file that was uploaded. This URL can be used to access the file
in the future, and can be used to link the file to the user that uploaded it.

```json
{
  "url": "https://cdn.example.org/users/philsturgeon.jpg",
  "links": {
    "self": "https://example.org/api/images/c19568b4-77b3-4442-8278-4f93c0dd078",
    "user": "https://example.org/api/users/philsturgeon"
  }
}
```

Supporting both might not be necessary, but if they are, just support both the
image types you need and the JSON alternative of that. HTTP makes that
incredibly easy to do thanks to being able to switch `Content-Type`.

### Method 3: Separate metadata resource

The above examples are great for simple file uploads, but what if you need to
upload metadata with the file? This is where things get a bit more complex. 

One approach would be multipart forms, but they're pretty complex to work with
and not ideal for large files. If sending a massive video file, you don't want
to have to send the title, description, and tags in the same request as the
video file. If the video file upload fails, you'll have to re-upload the video
file and all of the metadata again.

The way YouTube handles uploads via API are an interesting examples of splitting
out metadata and a video file. They use a two-step process which focuses on
metadata first, which allows for the metadata to be saved and the video can then
be retried and uploaded without losing the metadata.

The YouTube Data API (v3) approach to [Resumable
Uploads](https://developers.google.com/youtube/v3/guides/using_resumable_upload_protocol)
works like this.

First, they make a POST request to the video upload endpoint with the metadata
in the body of the request:

```http
POST /upload/youtube/v3/videos?uploadType=resumable&part=snippet,status HTTP/1.1
Host: www.googleapis.com
Authorization: Bearer <token>
Content-Length: 278
Content-Type: application/json; charset=UTF-8

{
  "snippet": {
    "title": "My video title",
    "description": "This is a description of my video",
    "tags": ["cool", "video", "more keywords"],
    "categoryId": 22
  },
  "status": {
    "privacyStatus": "public",
    "embeddable": true,
    "license": "youtube"
  }
}
```

The response then contains a `Location` header with a URL to the video upload endpoint:

```http
HTTP/1.1 200 OK
Location: https://www.googleapis.com/upload/youtube/v3/videos?uploadType=resumable&upload_id=xa298sd_f&part=snippet,status,contentDetails
Content-Length: 0
```

Then to upload the video it's back to direct file uploads. The video file can be
uploaded to the URL provided in the `Location` header, with the content type set
to `video/*`:

```http
PUT https://www.googleapis.com/upload/youtube/v3/videos?uploadType=resumable&upload_id=xa298sd_f&part=snippet,status,contentDetails HTTP/1.1
Authorization: Bearer AUTH_TOKEN
Content-Length: <file length>
Content-Type: video/mp4

<BINARY_FILE_DATA>
```

What's cool about this approach, is that URL _could_ be part of your main API,
or it _could_ be a totally different service. It could be a direct-to-S3 URL,
Cloudinary, or some other service that handles file uploads. 

Larger companies will be more prone to building a service to handle such files
coming in, whilst smaller teams might want to keep things simple and let their
API do the heavy lifting. The larger the file, the more likely you'll want to
split that off, as having your API handle these huge files - even if the uploads
are chunked - will keep the HTTP workers busy. Maintaining those connections
might slow down a Rails-based API for a long time, for example, so having
another service would help there.

## Best practices

### Check Content-Type and Content-Length

It is worth noting that the `Content-Type` header is not always reliable, and
you should not trust it. If you're expecting an image, you should check the
first few bytes of the file to see if it is a valid image format. If you're
expecting a CSV, you should check the first few lines to see if it is a valid
CSV. **Never trust input.**

The only thing worth mentioning on that request is the addition of
`Content-Length`, which is basically the size of the image being uploaded. A
quick check of `headers['Content-Length'].to_i > 3.megabytes` will let us
quickly reply saying "This image is too large", which is better than waiting
forever to say that. Sure, malicious folks could lie here, so your backend code
will need to check the image size too. **Never trust input.**

Protecting against large files is important, as it can be a denial of service
attack. If you allow users to upload files, they could upload a 10GB file and
fill up your disk space. This is why it's important to check the size of the
file before writing it to disk. 

To make sure it seems to be the right type, and to make sure it's not too large,
you can read the file in chunks. This can be done with a simple `File.open` and
`File.read` in Ruby, or similar in other languages. The file is read in chunks,
and then written to a file on disk. This is a good way to handle large files, as
you're not trying to load the whole file into memory at once.

```ruby
def update
  if headers['Content-Type'] != 'image/jpeg'
    render json: { error: 'Invalid content type' }, status: 400
    return
  end

  if headers['Content-Length'].to_i > 3.megabytes
    render json: { error: 'File is too large' }, status: 400
    return
  end

  file = File.open("tmp/#{SecureRandom.uuid}.jpg", 'wb') do |f|
    f.write(request.body.read)
  end

  # Do something with the file
end
```

### Securing File Uploads

Allowing file uploads can introduce all sorts of new attack vectors, so it's worth being very careful about the whole thing. 

One of the main issues with file uploads is directory traversal attacks. If you allow users to upload files, they could upload a file with a name like `../../etc/passwd`, which could allow them to read sensitive files on your server.

Uploading from a URL could allow for [Server-Side Request Forgery (SSRF)](https://owasp.org/API-Security/editions/2023/en/0xa7-server-side-request-forgery/) attacks, where an attacker could upload a file from a URL that points to a sensitive internal resource, like an AWS metadata URL, or something like `localhost:8080` which allows them to scan for ports on the server.

The [OWASP File Upload Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/File_Upload_Cheat_Sheet.html) has a lot of good advice on how to secure file uploads, including:

- Limiting the types of files that can be uploaded.
- Limiting the size of files that can be uploaded.
- Storing files in a location that is not accessible via the web server.
- Renaming files to prevent directory traversal attacks.
- Checking the file type by reading the first few bytes of the file.
- Checking the file size before writing it to disk.
- Checking the file for viruses using a virus scanner.

## Summary

Think about what sort of file uploads are needed, how big the files are, where
they're going, and what sort of clients will be using the API. 

The YouTube approach is a bit complex, but a combination of 1 and 2 usually take care of the
job, and help avoid complicated multipart uploads. 

As always, build defensively, and never trust any user input at any point. 


 This is the content for the doc api-design/filtering-responses.mdx 

 ---
description: Learn how to filter collections in a REST API.
---

# Filtering Collections

When building a REST API, the ability to filter potentially large collections of
data is essential, and sorting can reduce a huge amount of work for both the
client and server.

## What is Filtering?

Filtering allows API users to request only the data they need, "filtering out"
irrelevant things on the server-side instead of making them do it themselves on
the client-side. Reducing the amount of data you're returning and transferring
reduces server resources and improves performance, which reduces carbon
emissions and saves money.

## How to Filter

The most straightforward way to filter resources is by using query parameters.
These are appended to the URL to refine the results of an API request. For
example:

```bash
GET /products?category=books&price_lt=20
```

In this case, the request filters products where the `category` is "books", and
the `price` field is less than 20. The query string is easy for both the API
designer and users to understand, making it a natural choice for filtering data.

Naming conventions and deciding if or how to use operators will vary depending on
the implementation, but there are a few common practices and standards to consider.

### Simple Filtering

Starting with the most basic, you can filter by a single parameter using a query
parameter with a sensible name.

```bash
GET /products?category=books&status=available
```

In these examples, the query parameter `category` or `status` is used to remove
any products that don't match those exact values. 

The query parameters in some APIs might be a little busy, as there could be not
just sorting and pagination, but people do things changing output structures,
selecting which properties should be returned, or all kinds of functionality
which are not filtering.

To avoid confusion, it's a good idea to use a consistent naming scheme, like
`filter_category` or better yet a "filter array", e.g.:

```bash
GET /products?filter[category]=books&filter[status]=available
```

This makes it clear that these are filtering parameters, keeping it separate from
pagination, sorting, or any response modifiers which may be present.

Sometimes, users want to combine multiple filters. This is generally done by
adding more parameters to the URL: 

```bash
GET /orders?filter[status]=shipped&filter[customer_id]=123
```

Using multiple filters is always considered a logical `AND` and the filters
should be combined. Supporting a logical `OR` is trickier to represent in a
query string, but one common convention is to allow multiple values for a single
parameter with a comma-separated list:

```bash
GET /products?category=books,electronics
```

This would return products in either the "books" or "electronics" categories.

### Declaring Operators

Simple value matching is the most common form of filtering, but it might not be
enough depending on the use-cases clients expect. For example, filtering for books with a
price of `20` will ignore any books that cost `19.99`, which is probably not
very helpful.

```bash
GET /products?filter[price]=20
```

To solve this you can use operators to specify the type of comparison, like
"less than", "greater than", or "not equal". These are usually implemented with
suffixes or specific words added to the parameter name. For example, `GET
/products?price_gt=50` would retrieve products where the price is greater than
50. Other common operators include:

- `_lt` for less than (e.g., `price_lt=20`)
- `_gt` for greater than (e.g., `price_gt=100`)
- `_gte` and `_lte` for greater than or equal to, and less than or equal to, respectively.

Some people are tempted to try and use operators as a prefix for the value, like
`GET /products?price=<20` but that gets fairly awkward if you try less than or
equal: `GET /products?price=<=20`, everything needs to be escaped, and its
impossible to read.

Sticking with the filter array approach, you can make this a little more
readable:

```bash
GET /products?filter[price][lt]=20
GET /products?filter[price][gt]=99
GET /products?filter[price][gte]=100
```

This is a little more verbose, but it's much easier to read and understand.

### Advanced Filtering

Instead of trying to invent your own approach, there are standards that can be
used to make this easier for everyone, like
[FIQL](https://datatracker.ietf.org/doc/html/draft-nottingham-atompub-fiql-00),
[RSQL](https://github.com/jirutka/rsql-parser), or
[OData](https://www.odata.org/getting-started/basic-tutorial/#queryData).

As an example, OData is a widely used standard that provides a consistent way to
query and manipulate data. It uses a specific syntax for filtering, which might
look like this:

```bash
GET /products?$filter=category eq 'books' and price lt 50
```

Here, `$filter` is the standard keyword for filtering, and `eq` is used for
equality, while `lt` means less than. You can combine multiple filters using
`and`, just like in the example above. 

FIQL is a compact, text-based query language used for filtering. It uses
operators such as `==` for equality, `!=` for not equal, `<` and `>` for less
than and greater than, and `;` for AND logic. For example, a FIQL filter might
look like this:

```bash 
GET /products?filter=category==books;price<20
```

This is a concise way to express complex filtering logic, making it useful for
more advanced APIs.

Another option is RSQL, which is a slightly more modern version of FIQL that is gaining popularity:

```bash
GET /products?filter=category==books,price<50
```

RSQL uses a comma to separate filters, which is a little more readable than the
semicolon and doesn't need to be URL encoded. It can make some amazing queries
like `last_name==foo*,(age=lt=55;age=gt=5)`.

Whichever of these formats you pick will have pros and cons, but the most
important thing is to pick a standard instead of reinventing the wheel so you
can leverage existing libraries and tools on both the client-side and the
server-side. It's important to reuse existing tools for things like this instead
of wasting infinite time building and maintaining your own custom solutions
instead of solving genuine problems for your users.

## What is Sorting?

What order should you return resources in a collection? 

- Oldest first or newest first? 
- Alphabetical based on the name?
- Highest price to lowest price?

Whatever you pick at first may be a sensible default, but it's likely that users
will want to change this.

For APIs, sorting is the process of arranging resources in a specific order
based on user inputs. 

## How to Sort

Sorting is usually done with a query parameter:

```bash
GET /products?sort=name
```

This sorts products by the `name` property, and by default that will be in ascending order.

Most APIs will also allow clients to specify the order, which is usually done with another query parameter:

```bash
GET /products?sort=price&order=desc
```

Here if we just had `sort=price` it would be reasonable to assume the client
wanted the cheapest results, but if we're looking for the most expensive 
products, we can add `order=desc` to return the most expensive first.

This convention is very closely related to the SQL `ORDER BY` clause, which
takes a database property and an order in exactly the same way. Unlike a
database query your API does not have to allow clients to sort by every single
property, you could restrict to a few common use-cases and make sure they are
well optimized.

## Best Practices

### Consistency and Documentation

When designing filters for your REST API, it's important to make sure they are
intuitive and consistent. Use clear, descriptive names for your parameters. For
example, `price_lt` is much easier to understand than something vague like
`lower_price`. Providing solid documentation is equally important—developers
should be able to quickly find information on the available filters and how to
use them.

### Validation and Error Handling

Validation is also critical. If a user tries to apply a filter with invalid data
(like `price=abc`), your API should return a helpful error message rather than
just failing silently or returning incorrect results. Be sure to handle edge
cases as well, such as empty values or invalid characters in the query string.

_Learn more about [error handling in REST APIs](/api-design/responses/errors)._

### Performance Considerations

The more you allow clients to customize their requests, the harder it becomes to
set up caching rules and optimize database queries that might be produced. 

Anyone using an SQL database will know that the more complex the query, the
harder it is to optimize. If you're allowing clients to send in completely
arbitrary queries, it's going to be very hard to optimize your database because
you wont know what indexes to create. You are left retroactively optimizing
popular usages, which might be ok for an internal API used by a limited number
of colleagues who can warn you, but is a nightmare for teams maintaining public
APIs where an API could be brought down by a single user launching a new
product.

Rate limiting can help, but it's worth questioning: what is the purpose of this
API? 

Generally an API is not meant to be a database-over-HTTP, so if you feel
like you're starting to recreate SQL or some other query language, you might be
going down the wrong path. There are databases which can be used over HTTP that
do not require you to create a database, like FaunaDB, Firebase, or DynamoDB,
which might be a better fit.

### URL Design

Sometimes a filter could or should have been a different endpoint, a
different parameter, or a different way of structuring the data. 

If the clients have asked for the ability to show off some "Hot Bargains",
instead of telling clients to pick numbers based on price with `GET
/products?price_lt=20&sort=price`, you could use `GET /products/bargains`.

Cachability is improved, because you can set a 24 hour network cache on that
which will be shared by all clients. 

Consistency is improved, because the web and iOS versions of the same
application aren't going to pick slightly different numbers for what is
considered a bargain.

## Conclusion

Filtering is a powerful tool for API designers, allowing users to request only
the data they need. By using query parameters, operators, and standard query
languages, you can create a flexible and intuitive filtering system that meets
the needs of your users, without going overboard and confusing everyone or
making the API wildlife inefficient and unstable. 

When in doubt, start simple, and add things later. It's always easier to add new
parameters, endpoints, and additional ways of doing things, than it is to take
them away later.


 This is the content for the doc api-design/http-methods.md 

 # Using HTTP methods

We learned about URLs in _[What is a URL?](./what-is-a-url.md)_ which is how an
API defines its "resources". If an API request were a sentence, the URL would be the noun. In this section, we'll cover the verbs of API requests: HTTP methods.

```curl focus:1[1:3]
GET /places?lat=40.759211&lon=-73.984638 HTTP/1.1
Host: api.example.org
```

Sometimes people will suggest HTTP methods are optional, or they they're just noise, and everything would be better off done as purely a `GET` or `POST`. This is a bit of a misunderstanding of how HTTP works, and how the web works, and leads to all sorts of trouble down the line.

Conventions may seem arbitrary, but they are important to follow because **your API does not exist in a vacuum**. Conventions allow disparate tools that do not have direct knowledge of each other to work together seamlessly. If you start breaking these conventions, you're going to need to build all of your own tools, and that's a lot of work.

With that in mind, let's dive into the core HTTP methods and best practices for using them in your API.

## `GET`: Fetching Resources

`GET` is the most common HTTP method, and is used for fetching data. It is the
default method for most browsers, as it is used for fetching web pages, images,
stylesheets, and scripts. It is also used for fetching data from APIs.

`GET` is "idempotent", meaning that if you made the same get call over and over
again, You can expect the same outcome every time. If you `GET` the resource, but the request fails or times out, and you `GET` it again, the end result is that you got it. Nothing was deleted, or removed, or changed in any lasting way, so if this thing is got a bunch of times it is the same as being got once.

```curl
GET /places?lat=40.759211&lon=-73.984638 HTTP/1.1
Host: api.example.org
```

### Best Practices for `GET` requests

- Idempotent: Identical requests get identical outputs.
- No request body: `GET` requests can *technically* have a body, but a lot of frameworks and tooling will start acting a bit wonky, so just avoid it. There's almost always a better way to do what you're trying to do.
- Caching: You can and should enable caching for the response of `GET` requests, but you need to be careful about how you do it. If the data changes frequently, you might want to set a short cache time, or use a cache-busting technique.
- Safe: `GET` requests should not change the state of the server. They should only be used to retrieve data.

## `POST`: Creating Resources

`POST` requests are typically used for creating new resources or triggering actions that change server state. Unlike `GET`, `POST` is not idempotent - sending the same POST request multiple times may create multiple resources or trigger multiple actions.

`POST` does not necessarily have to represent a resource creation. You could use to signify the triggering of an event: the sending of an email, paying an invoice, etc. But it should result in that action being executed every time you make a request.

### `POST` examples

Creating a new location resources:

```curl
POST /places HTTP/1.1
Host: api.example.org
Content-Type: application/json

{
  "name": "High Wood",
  "lat": 50.464569783,
  "lon": -4.486597585
}
```

Triggering an email send:

```curl
POST /emails/send HTTP/1.1
Host: api.example.org
Content-Type: application/json

{
  "to": "Phil",
  "subject": "Hello",
  "body": "Hi Phil, how are you?"
}

```

### Best Practices for `POST` requests

- Not idempotent
- Includes a request body
- Cannot be cached by default
- Used for resource creation and non-idempotent actions

## `PUT`: Complete Resource Updates

Often incorrectly associated with being an "edit" action, PUT is designed for idempotent updates where the request contains the complete resource representation. This means that if you `PUT` the same data multiple times, the resource will be in the same state each time.

Some developers get hung up about is this a "create or update" action. Their concern comes from a misplaced sense that HTTP verbs should correspond to a specific CRUD (create, read, update, delete)action. That is not the case. `PUT` is the REST equivalent of an upsert operation in a database. If the resource exists, it will be updated. If it does not exist, it will be created.

### `PUT` examples

An example of this would be an image upload. An API might have the ability to
upload an image for a user, which is probably a profile image. A request with
`PUT /users/jane/image` and a body of the image contents (or a JSON
payload with a URL) could then provide the image. It does not matter if the user
already had an image or not, if the request is a success they will have one. If
the upload fails that is fine, another request can be made, and it will be
overridden.

```curl
PUT /users/jane/image HTTP/1.1
Host: api.example.org
Content-Type: image/jpeg

[Binary image data]
```

### Best Practices for `PUT` requests

- Idempotent: Multiple identical requests result in the same final state
- Complete resources: Must include the complete resource representation
- Treat as upsert: Can create or update resources
- Useful for uploads and full resource replacements

## `PATCH`: Partial Resource Updates

`PATCH` allows clients to send partial modifications to a resource. Unlike `PUT`, which requires sending the complete resource, `PATCH` only needs to contain the changes to be applied.

`PATCH` is not idempotent, so if you `PATCH` a resource, and the request
fails, you cannot just retry the request as you could with a `PUT`. The server
might have already made some changes, and retrying the request could result in a
different outcome.

```curl
PATCH /users/phil

{
  "image_url": "https://cdn.example.org/fancy-headshot.png"
}
```

How exactly PATCH works can vary depending on which data format you're using. If it's `JSON` then there are two popular approaches: [JSON Patch](https://tools.ietf.org/html/rfc6902) and [JSON Merge Patch](https://tools.ietf.org/html/rfc7396).

JSON Merge Patch is what most people will want to use for general APIs, as it is
simple to use.

### `PATCH` Example

```json
{
  "title": "Goodbye!",
  "author" : {
    "givenName" : "John",
    "familyName" : "Doe"
  },
  "tags":[ "example", "sample" ],
  "content": "This will be unchanged"
}
```

A user agent wishing to change the value of the "title" member from
"Goodbye!" to the value "Hello!", add a new "phoneNumber" member,
remove the "familyName" member from the "author" object, and replace
the "tags" array so that it doesn't include the word "sample" would
send the following request:

```http
PATCH /my/resource HTTP/1.1
Host: example.org
Content-Type: application/merge-patch+json

{
  "title": "Hello!",
  "phoneNumber": "+01-123-456-7890",
  "author": {
    "familyName": null
  },
  "tags": [ "example" ]
}
```

The resulting JSON document would be:

```json
{
  "title": "Hello!",
  "author" : {
    "givenName" : "John"
  },
  "tags": [ "example" ],
  "content": "This will be unchanged",
  "phoneNumber": "+01-123-456-7890"
}
```

### Best Practices for `PATCH` requests

- Not idempotent
- Contains only the fields to be modified
- More flexible than PUT for updates
- Supports different patch formats (JSON Patch, JSON Merge Patch)

## `DELETE`: Removing Resources

Aptly named, the `DELETE` method is used to remove resources from the system. It's intended to be idempotent because deleting a resource multiple times should have the same effect as deleting it once. However, some APIs do not implement it that way so a second attempt to delete the same thing will get a 404. This is not ideal, but it is common.

### `DELETE` Example

```curl
DELETE /places/123 HTTP/1.1
Host: api.example.org
```

### Best Practices for `DELETE` requests

- Keep delete idempotent.
- Usually doesn't include a request body
- Should return appropriate status codes (204 No Content or 200 OK)

## Less Common HTTP Methods

While most APIs primarily use GET, POST, PUT, PATCH, and DELETE, several other HTTP methods serve specific purposes:

### HEAD

- Identical to GET but returns only headers, no body
- Perfect for checking if a resource exists or has been modified
- Useful for validating links or checking file sizes before download

Example:

```http
HEAD /articles/123 HTTP/1.1
Host: api.example.org

HTTP/1.1 200 OK
Last-Modified: Wed, 15 Oct 2024 12:00:00 GMT
Content-Length: 12345
```

### OPTIONS

- Returns information about available communication options
- Most commonly used for CORS preflight requests
- Can provide information about allowed methods

Example:

```http
OPTIONS /api/articles HTTP/1.1
Host: api.example.org

HTTP/1.1 200 OK
Allow: GET, POST, HEAD, OPTIONS
Access-Control-Allow-Methods: GET, POST
```

### TRACE

- Used for diagnostic purposes
- Returns the exact request received by the server
- Helpful for debugging proxy issues
- Often disabled for security reasons

### CONNECT

- Used to establish tunnel connections through HTTP proxies
- Primarily used for HTTPS connections through proxies
- Rarely implemented in standard APIs

These methods are less frequently used but can be valuable for specific use cases like debugging, CORS handling, and proxy management.

## Best Practices

### 1. Use Methods as Intended

Don't force everything through POST or GET. Each method has its purpose:

- GET for retrieval
- POST for creation and non-idempotent actions
- PUT for complete resource replacement (upsert)
- PATCH for partial resource updates
- DELETE for removal

### 2. Consider Caching Implications

- GET requests should be cacheable when appropriate
- Include proper cache headers
- Ensure POST, PUT, PATCH, and DELETE invalidate caches as needed

### 3. Handle Race Conditions

With `PUT` & `PATCH` requests, be aware of potential race conditions:

```
# Client A reads resource
GET /resources/123

# Client B reads resource
GET /resources/123

# Client B's update overwrites A's changes
PUT /resources/123 {...}

# Client A updates resource
PUT /resources/123 {...}
```

Both clients were trying to update a single instance of a resource, but little do they know they are overwriting one another. This is on the server to handle, and there are a few ways to do it.

- Use timestamps for last modified
- Use optimistic locking with version numbers
- Implement ETags for concurrent updates

### 4. `PUT` vs. `PATCH`

Oftentimes an API will only support one of these methods. We **strongly** recommend supporting both, unless you have a very specific reason not to. `PUT` is great for full updates, but `PATCH` is more flexible and can be more efficient for partial updates.

## Remember

HTTP methods aren't just syntax - they're core to how the web works. Using them correctly makes your API:

- More predictable for clients
- Easier to cache
- Compatible with existing tools
- Easier to maintain and scale

Your choice of HTTP method communicates intent and behavior to both developers and tools, so choose wisely and consistently.


 This is the content for the doc api-design/index.mdx 

 ---
title: API design guide
description: "Learn how to design an API that is easy to use, easy to understand, and easy to maintain."
---

import { APIDesignCards } from "~/features/api-design/recipes";

<APIDesignCards />

 This is the content for the doc api-design/pagination.mdx 

 ---
description: "API Pagination is a common pattern for managing large data sets in APIs. This guide covers the basics of API pagination and best practices."
---

import { Callout } from '~/components'

# Paginating API responses

Pagination is a crucial concept that needs to be understood and designed into a
REST API before its built. It is often forgotten about until it's too late and
API consumers are already integrating with the API, so it's important to get
stuck into doing things the right way early on.

## What is API Pagination?

At first it's easy to image that collections only have a few hundred records.
That not be too taxing for the server to fetch from the database, turn into
JSON, and send back to the client, but as soon as the collection is getting into
thousands of records things start to fall apart in wild and unexpected ways. 

For example, a coworking company that expected to mostly host startups of 10-50
people, but then Facebook and Amazon rock up with ~10,000 employees each, and
every time somebody loads that data the entire API server crashes, along with
every application that uses it, and every application that uses that.

Breaking down a large dataset into smaller chunks helps to solve this, and it
works a lot like pagination does in the browser: when searching on a functioning
search engine like Duck Duck Go or Ecosia, the results are broken down into page
1, page 2... page 34295. It doesn't just throw every single result into the
browser in the worlds longest slowest web response, forcing computer fans to
whir until they snap out as it tries to render infinite HTML to the screen.

This is pagination in action, and pagination in an API is exactly the same idea.
Much like web pages it is done with query string parameters on a GET request.

```
GET /items?page=2
```

The main difference is that the client is not seeing a list of buttons in HTML,
instead they are getting metadata or links in the JSON/XML response. How exactly
that looks depends on which pagination strategy is picked, and there are a few to
choose from with their own pros and cons.

## Choosing a Pagination Strategy

To help pick a pagination strategy, let's look at some examples and talk through
the pros and cons.

1. Page-Based Pagination
2. Offset-Based Pagination
3. Cursor-Based Pagination

### Page-Based Pagination

Page-based pagination uses `page` and `size` parameters to navigate through pages of data.

```
GET /items?page=2&size=10
```

This request fetches the second page, with each page containing 10 items maximum.

There are two main ways to show pagination data in the response.

```json
{
  "data": [
    ...
  ],
  "page": 2,
  "size": 10,
  "total_pages": 100
}
```

This is pretty common, but forces the client to know a whole lot about the
pagination implementation, which could mean some guesswork (which could be
guessed wrong), or reading a whole lot of documentation about which bit goes
where and what is multiplied by whom.

The best way to help the client is to give them links, which at first seems
confusing but it's just
[HATEOAS](https://apisyouwonthate.com/blog/rest-and-richardson-maturity-model/)
(Hypermedia As The Engine Of Application State), also known as Hypermedia
Controls. 

It's a fancy way of saying "give them links for things they can do
next" and in the context of pagination that means "give them links to the next
page, the previous page, the first page, and the last page."

```json
{
  "data": [
    ...
  ],
  "meta": {
    "page": 2,
    "size": 10,
    "total_pages": 100
  },
  "links": {
    "self": "/items?page=2&size=10",
    "next": "/items?page=3&size=10",
    "prev": "/items?page=1&size=10",
    "first": "/items?page=1&size=10",
    "last": "/items?page=100&size=10"
  }
}
```

Whenever there is a `next` link, an API consumer can show a `next` button, or
start loading the next page of data to allow for auto-scrolling. 

If the `next` response returns data, it will give a 200 OK response and they can
show the data. 

If there is no data then it will still be a 200 OK but there will be an empty
array, showing that everything was fine, but there is no data on that page right
now. 

**Ease of Use**

- Pro: Simple to implement and understand.
- Pro: Easy for users to navigate through pages.
- Pro: UI can show page numbers and know exactly how many pages there are.
- Pro: Can optionally show a next/previous link to show consumers if there are more pages available.

**Performance**

- Con: Involves counting all records in the dataset which can be slow and hard to cache depending on how many variables are involved in the query.
- Con: Becomes exponentially slower with more records. Hundreds are fine. Thousands are rough. Millions are horrendous.

**Consistency**

- Con: When a consumer loads the latest 10 records, then a new record is added
to the database, then a user loads the second page, they'll see one of those
records twice. This is because there is no such concept as a "page" in the
database, just saying "grab me 10, now the next 10" does not differentiate which
records they actually were.

### Offset-Based Pagination

Offset-based pagination is a more straightforward approach. It uses `offset` and
`limit` parameters to control the number of items returned and the starting
point of the data, which avoids the concept of counting everything and dividing
by the limit, and just focuses on using offsets to grab another chunk of data.

```
GET /items?offset=10&limit=10
```

This request fetches the second page of items, assuming each page contains a
maximum of 10 items, and does not worry itself with how many pages there are.
This can help with infinite scrolls or automatically "importing" lots of data
one chunk at a time.

There are two main ways to show pagination data in the response.

```json
{
  "data": [
    ...
  ],
  "meta": {
    "total": 1000,
    "limit": 10,
    "offset": 10
  }
}

```

Or with hypermedia controls in the JSON:

```json
{
  "data": [
    ...
  ],
  "meta": {
    "total": 1000,
    "limit": 10,
    "offset": 10
  },
  "links": {
    "self": "/items?offset=10&limit=10",
    "next": "/items?offset=20&limit=10",
    "prev": "/items?offset=0&limit=10",
    "first": "/items?offset=0&limit=10",
    "last": "/items?offset=990&limit=10"
  }
}
```

**Ease of Use**

- Pro: Simple to implement and understand.
- Pro: Easily integrates with SQL `LIMIT` and `OFFSET` clauses.
- Pro: Like page-based pagination this approach can also show next/previous buttons dynamically when it's clear there are more records available.
- Con: Does not help the UI build a list of pages if they want to show "Page 1, 2, ... 20." They can awkwardly do maths on the total / limit but it's a bit weird.

**Performance**

- Con: Can become inefficient with large datasets due to the need to scan through all previous records.
- Con: Performance degradation is significant as the offset increases.

**Consistency**

- Con: The same problems exist for offset pagination as page pagination, if
more data has been added between the first request and second being made, the same record could show up in both pages.

**See this in action**

- [YouTube Data API](https://developers.google.com/youtube/v3/guides/implementation/pagination)
- [Reddit API](https://www.reddit.com/dev/api/)

### Cursor-Based Pagination

Cursor-based pagination uses an opaque string (often a unique identifier) to
mark the starting point for the next subsection of resources in the collection.
It's often more efficient and reliable for large datasets.

```
GET /items?cursor=abc123&limit=10
```

Here, `abc123` represents the last item's unique identifier from the previous
page, this could be a UUID, but it can be more dynamic than that.

APIs like Slack will base64 encode information with a field name and a value,
even adding sorting logic, all wrapped up in an opaque string. For example,
`dXNlcjpXMDdRQ1JQQTQ=` would represent `user:W07QCRPA4`. 

Obfuscating the information like this aims to stop API consumers hard-coding
values for the pagination, which allows for the API to change pagination logic
over time without breaking integrations. The consumers can simply pass the
cursor around to do the job, without worrying about what it actually involves.

It can look a bit like this:

```json
{
  "data": [...],
  "next_cursor": "xyz789",
  "limit": 10
}
```

To save the client even having to think about cursors (or knowing the name of
the query parameters for cursor or limit), links can once again save the day:

```json
{
  "data": [
    ...
  ],
  "links": {
    "self": "/items?cursor=abc123&limit=10",
    "next": "/items?cursor=xyz789&limit=10",
    "prev": "/items?cursor=prevCursor&limit=10",
    "first": "/items?cursor=firstCursor&limit=10",
    "last": "/items?cursor=lastCursor&limit=10"
  }
}
```

**Ease of Use**

- Pro: API consumers don't have to think about anything and the API can change the cursor logic.
- Con: Slightly more complex to implement than offset-based pagination.
- Con: API does not know if there are more records available after the last one in the dataset so has to show a next/previous link which may return no data. (You can grab limit+1 number of records to see if it's there, but that's a bit of a hack which could end up being slower. Benchmarks are your friend.)

**Performance**

- Pro: Generally more efficient than offset-based pagination depending on the data source being used.
- Pro: Avoids the need to count records to perform any sort of maths which means larger data sets can be paginated without suffering exponential slowdown.

**Consistency**

- Pro: Cursor-based pagination data remains consistent in more scenarios, even if new data is added or removed, because the cursor acts as a stable merker identifying a specific record in the dataset instead of "the 10th one" which might change between requests.

**See it in action**

- [Twitter API](https://developer.twitter.com/en/docs/twitter-api)
- [Instagram Graph API](https://developers.facebook.com/docs/instagram-api/)
- [Slack API](https://slack.engineering/evolving-api-pagination-at-slack/)

### Choosing a strategy

Choosing the right pagination strategy depends on the specific use case and
dataset size.

Offset-based pagination is simple but may suffer from performance issues with
large datasets. 

Cursor-based pagination offers better performance and consistency for large
datasets but come with added complexity. 

Page-based pagination is user-friendly but shares similar performance concerns
with offset-based pagination.

Using links instead of putting metadata in the response allows for more
flexibility over time with little-to-no impact on clients.

## Where Should Pagination Go?

In all of these examples there's been the choice between sending some metadata
back for the client to construct their own pagination controls, or sending them
links in JSON to avoid the faff.

Using links is probably the best approach, but they don't have to go in the
JSON response. Instead use the more modern approach: [RFC 8299: Web
Linking](https://www.rfc-editor.org/rfc/rfc8288).

```http
Link: <https://api.example.com/items?page=1&size=10>; rel="first",
      <https://api.example.com/items?page=3&size=10>; rel="next",
      <https://api.example.com/items?page=100&size=10>; rel="last"
```

Popping them into HTTP headers seems like the cleaner choice instead of
littering responses with metadata. It's also a slight performance putting
this into headers because HTTP/2 adds [header compression via
HPAK](https://blog.clou4986dflare.com/hpack-the-silent-killer-feature-of-http-2).

As this is a common standard instead of a convention, [generic HTTP clients like
Ketting](https://apisyouwonthate.com/blog/ketting-v5-hypermedia-controls/) can
pick this information up to provide a more seamless client experience.

Either way, pick the right pagination strategy for the data source, document it
well with a dedicated guide in API documentation, and make sure it scales up
with a realistic dataset instead of testing with a handful of records as assuming it scales

Adding or drastically changing pagination later could be a whole mess of
backwards compatibility breaks.

<Callout title="NOTE" variant="info">
  <p>Pagination can be tricky to work with for API clients, but Speakeasy SDKs can help out. Learn about <a href="/docs/runtime/pagination">adding pagination</a> to your Speakeasy SDK.</p>
</Callout>


 This is the content for the doc api-design/parameters.md 

 # Sending request parameters

There are all sorts of options that can be sent to an API endpoint and figuring out where to put things can be tricky at first.

Let's look at the four options.

## Path Parameters

Given the URL `/collections/shoes/products?sort=date&size=10&color=red` the
"path" is the `/collections/shoes/products`, and slashes separate bits of a URL,
some of which are static and some are variables. In this example `shoes` is a
variable that could be swapped for another collection on the e-commerce store,
e.g: `hats`. 

There is no concept of a "path parameter" in HTTP RFCs, this is purely a
convention, but it's common as API design terminology.

## Query Parameters

That same URL example has "query parameters" defined in the query string:
`/collections/shoes/products?sort=date&size=10&color=red`, which starts at, and
includes, the `?`: `?sort=date&size=10&color=red`. 

This string can be parsed into `[sort: 'date', size: '10', color: 'red']`. 

These options generally cover filtering, sorting, and pagination.

- Filtering: `?brand=Samsung&inStock=true`.
- Sorting: `?sort=date&sortBy=desc`.
- Pagination: `?page=2&limit=10` or `?cursor=abc123`.

They should never be used for anything destructive, or break the rules of the
method they're being used in (e.g. modify data on a GET), but they can have
other uses.

Some people use query strings for other purposes like changing the response data
that will come back, like using `GET /articles/123?include=comments` to squeeze
a bunch of comments data into the article response. This was considered best
practice in early 2010s but much like "image sprites" and "CSS combination" it's
now generally a bad practice, aided with improvements to HTTP/2 and HTTP/3.

Everything is a string because the whole URL is a string. Typed languages often
allow you to define types that these values should be converted to, so `size=10`
can become `10` instead of `"10"`, and `inStock=true` can become a proper `true`
instead of a literal string `"true"`.

**HTTP Headers**

HTTP Headers (also known as HTTP Header Fields) are metadata for a request, that
can have a wide variety of impacts across the API and various network components
along the way. You may have spotted this in the same code above.

```
Content-Type: application/json
```

That lets the API know that the message contains JSON.

```
Accept: application/json
```

That lets the API know we'd like JSON back too, if it can, we're ready for it.

```
If-Modified-Since: Wed, 30 Oct 2024 10:58:31 GMT
```

Only bother returning any data if its changed since then, otherwise just let us
know it's the same and save server resources.

These standard request headers are defined by Internet Engineering Task Force
(IETF) in [RFC 9110](https://www.rfc-editor.org/rfc/rfc9110) and [RFC
9111](https://www.rfc-editor.org/rfc/rfc9111), and various other complimentary
RFCs. They cover an amazingly wide functionality set, including: authorization,
caching, CORS, security, redirects, compression, and localization.

You _can_ define your own headers, but it's important to avoid replicating
standard functionality with custom headers. People do odd things like the
`MyCompany-API-Key` when they could use the standard `Authorization` header.
Various network components like cache proxies will know what to do with an
`Authorization` and will respond accordingly (changing the way caching works to
avoid leaking data to others), but you will need to somehow teach those network
components what to do with a custom `MyCompany-API-Key`.

Custom headers should be limited to handy but non-vital information, like trying
out a new beta feature hiding behind a feature flag.

```
Acme-Feature-Toggle: beta-feature=true
```

For everything else, there's the request body.

 This is the content for the doc api-design/rate-limiting.mdx 

 ---
description: Keep APIs running smoothly by controlling how many requests clients can make.
---

Rate limiting is the art of trying to protect the API by telling "overactive" API
consumers to calm down a bit, telling clients to reduce the frequency of their
requests, or take a break entirely and come back later to avoid overwhelming the
API. 

## Why bother with rate limiting

The main reason for rate limiting is to keep an API running smoothly and fairly.
If all clients could fire off requests as fast as they like, it's only a matter
of time before something breaks. A spike in traffic (whether accidental or
malicious) can overwhelm servers, leading to slowdowns, crashes, or unexpected
high infrastructure costs.

Rate limiting is also about fairness. If there are loads of users accessing an
API, it's important to make sure one consumers mistakes do not affect another. For
public APIs, it's about making sure no one user can hog all the resources. For
businesses, this could be different limits for free and various paid tiers to
make sure profit margins are maintained.

## How does API rate limiting work?

How can an API know when a client is making too many requests? That's where rate
limiting comes in. Rate limiting is a system that tracks the number of requests
made by a particular target (based on IP address, API key, user ID, or other
headers), within a defined time window.

The way this is implemented can vary, but the general process is the same:

- *Request Received* - A client makes a request to the API, asking for some data or
  to perform an action.
- *Identify the client* - The system identifies the client making the request,
  usually by looking at the IP address, API key, or other identifying
  information.
- *Check usage history* - The system checks how many requests the client has
  made in the current time window, and compares it to the limit.
- *Allow or deny the request* - If the client has made too many requests, the
  system denies the request with a `429 Too Many Requests` [status
  code](/api-design/status-codes). If the client is within the limit, the
  request is processed as normal.

## Different rate limiting strategies

There are a few different strategies for rate limiting, each with its own
advantages and disadvantages. 

![](./assets/rate-limiting-strategies.gif)

- **Token bucket:** the system has a bucket of tokens, and each request consumes
  a token. Tokens are added to the bucket at regular intervals, 100 tokens a
  minute, or 1,000 tokens per hour. If there are no tokens left, the request is
  denied. Clients are rewarded for taking time out and accrue more tokens as they
  do. This can lead to a lot of sudden bursts of activity, but should generally
  keep an average amount of traffic going through the system.

- **Fixed window:** the system sets a fixed limit for a specific time window. For
  example, "Make 100 requests per minute." This is the most common approach, but
  it can lead to very "lumpy" API traffic, where many clients are making the
  maximum number of requests at the start of a minute. This means an API can be stressed at the
  start of each minute and bored for the rest of it.

- **Sliding log:** instead of using the same time windows for all clients, the
  system sets a maximum number of requests for any 60 second period. This avoids
  the lumpy traffic concerns of many clients all maxing out at the start of the
  window, then doing nothing for the rest of it, as they would all have their
  own windows starting and stopping at different times depending on their usage.

- **Sliding window:** is a dynamic approach, adjusting limits based on real-time
  traffic patterns to optimize system performance and ensure fair access for
  all. This can be more complex to implement, but it can lead to a more
  efficient use of resources and a better experience for API consumers.

## Different limit targets

There are a lot of choices to be made when it comes to rate limiting, and the
first is: who or what are we trying to limit? Here are a few common targets
for rate limiting:

- **User-specific rate limits:** Identifying a user by their API key or user ID and
  setting a rate limit for that user. This is useful for ensuring that no single
  user can overwhelm the API and slow it down for others.

- **Application-specific rate limits:** Identifying an application by its API
  key and setting a rate limit for that application. This is useful for ensuring
  that a misconfigured application cannot affect stability for other
  applications.

- **Regional rate limits:** Manage traffic from different geographic regions, to
  make sure an API can continue to service critical regions, whilst still
  allowing other regions to access the API.

### Implementing rate limiting in HTTP

Rate limiting can be implemented at various levels, from the network layer to the
application layer. For HTTP APIs, the most common approach is to implement rate
limiting at the application layer with HTTP "middlewares" that keep track of these things, 
or API gateways which handle rate limiting like Zuplo, Kong, Tyk, etc. 

Wherever the rate limiting is implemented, there are a few standards that can be leveraged to 
avoid reinventing the wheel. 

The first is to return a HTTP error with a [status
code](/api-design/status-code) of `429 Too Many Requests` (as defined in [RFC
6585](https://www.rfc-editor.org/rfc/rfc6585.html)). This tells the client that
they've exceeded the rate limit and should back off for a while.

```http
HTTP/2 429 Too Many Requests
```

Instead of leaving the client to guess when they should try again (likely leading to lots of poking and prodding adding more traffic to the API), the `Retry-After` header can be added to a response with a number of seconds, or a specific time and date of when the next request should be made.

```http
HTTP/2 429 Too Many Requests
Retry-After: 3600
```

Why not also add some [proper error response](/api-design/errors) to explain why
the request was rejected, for any API consumer developers not familiar with
these concepts.

```http
HTTP/2 429 Too Many Requests
Content-Type: application/json
Retry-After: 3600

{
  "error": { 
    "message": "Rate limit exceeded",
    "code": "rate_limit_exceeded",
    "details": "You have exceeded the rate limit for this API. Please try again in 1 hour."
  }
}
```

Doing all of this makes it clear to the client that they have entered a rate
limit, and give them the information they need to know when they can try again,
but there is more that can be done to make this more user friendly.

### Rate limit headers

Documenting the rate limit in the response headers can help API consumers to
understand what's going on. There are various conventions for headers to help
consumers understand more about what the rate limiting policy is, how much of
the limit has been used, and what is remaining.

GitHub for example uses the `X-RateLimit-Limit`, `X-RateLimit-Remaining`, and
`X-RateLimit-Reset`.

Twitter uses `X-Rate-Limit-Limit`, `X-Rate-Limit-Remaining`, and
`X-Rate-Limit-Reset`. 

Similar but different, which causes all sorts of confusion. Designing an API to
be the most user friendly means relying on standards instead of conventions, so
it's worth looking at the [RateLimit header draft
RFC](https://datatracker.ietf.org/doc/draft-ietf-httpapi-ratelimit-headers/)
which outlines one new `RateLimit` header to cover all those use cases and a few more.

The following example shows a `RateLimit` header with a policy named "default",
which has another 50 requests allowed in the next 30 seconds.

```
RateLimit: "default";r=50;t=30
```

The `RateLimit` header focuses on the current state of the various quotes, but
it doesn't provide information about the policy itself. The same draft RFC also
outlines a `RateLimit-Policy` header which can be used to provide information
about how the policy works. 

This example shows two policies, "default" and "daily". The "default" policy has
a quota of 100 requests and a window of 30 seconds, while the "daily" policy has
a quota of 1000 requests and a window of 86400 seconds (24 hours).

```http
RateLimit-Policy: "default";q=100;w=30,"daily";q=1000;w=86400
```

Combining these two headers can provide a lot of information to API consumers to
know what the rate limits are, how much they have used, and when they can make
more requests. 

This can be a bit of work to set up, but it allows API consumers to interact
with an API more effectively, with less frustration, and keep everything running
smoothly. 

### Alternatives to Rate Limiting  

Some people argue that rate limiting is a blunt tool. It can be frustrating for
users who hit the limit when they're trying to get work done.

Poorly configured rate limiting can be fairly arbitrary. 

Consider an API that could theoretically handle 1000 requests per second. 

If there are 1000 users, each with a rate limit of 1 request per second, the API
would be maxed out. 

If that same API with 1000 users and only two of them are using up the their
maximum quotas, then the API could absolutely handle the load, and the API is
sitting their underutilized sitting around waiting for potential activity which
wont come. 

Not only is that a waste of server resources (hardware, electricity, CO2
emissions), but it's also frustrating for those users who are constantly being
told to calm down when they could be using the API to handle more activity;
activity which could be profitable.

One alternative approach is known as **backpressure**. This is a more dynamic
system which tells clients to ease up when the system is under strain, with a
`503 Service Unavailable` response with a `Retry-After` header. This could be
applied to the entire API, to specific users, or even specific endpoints that
are more resource intensive.

Quota-based systems are another alternative. Instead of measuring requests per
second or minute, users are assigned a monthly allowance. This works well for
subscription-based APIs, where users pay for a certain amount of access. If they
make a mistake and use up their quota too quickly, they can buy more, and other
API consumers can still access the API. This lends itself better to auto-scaling
up (and back down) based on number of active users and usage.

### Final Thoughts  

Rate limiting begins as a technical safeguard for an API (which makes managing
it easier) but ensures nobody is hogging resources (which keeps users happily
using the product). 

It's worth thinking about where and how to implement it, how to communicate it,
and how to make it as user-friendly as possible. It's not always simple for
junior developers to figure out how to work with rate limiting and they might
not know all the HTTP status codes and headers. The more tooling you can provide
to assist your users with responding to your rate limiting, the better. 



 This is the content for the doc api-design/request-body.mdx 

 ---
description: "Best practices and common patterns for API requests."
---

import { CodeWithTabs } from "~/components/codehike/CodeTabs";

# Sending request data

Understanding how to properly structure and handle request data is crucial for building robust APIs. This guide covers best practices and common patterns for working with API request data.

## URL Structure

Every API request starts with a URL that identifies the resource and any query parameters:

```http
GET /api/v1/places?lat=40.759211&lon=-73.984638 HTTP/1.1
Host: api.example.org
```

Key components:

- Resource path: Identifies what you're interacting with.
- Query parameters: Filter, sort, or modify the request.
- API version: Often included in the path.

## Request Bodies

Requests can also have a ' request body', which is a payload of data being sent
the API for processing. It is very frowned upon for `GET` but expected for
`POST`, `PUT`, and `PATCH`. The request body can be in a variety of formats, but
the most common are JSON, XML, and form data.

```http
POST /places HTTP/1.1
Host: api.example.org
Content-Type: application/json

{
  "name": "High Wood",
  "lat": 50.464569783,
  "lon": -4.486597585
}
```

This `POST` request to the `/places` endpoint is trying to add a new place to
the API, once again using a JSON body. The `Content-Type` header lets the server
know to expect JSON data, so it can parse the body and create a new place with
the name "High Wood" and the coordinates `50.464569783, -4.486597585`.

So far the examples of HTTP requests and responses have been using text, but in
reality they are just a series of bytes. The text is just a human-readable
representation of the bytes, and the tools that interact with the API will
convert the text to bytes before sending it, and convert the bytes back to text
when receiving it.

Most of you will interact with APIs using a programming language, and the code
to send a request will look something like this:


<CodeWithTabs>
    ```typescript !!tabs main.js
    import axios from 'axios';

    const response = await axios.post('https://api.example.org/places', {
      name: 'High Wood',
      lat: 50.464569783,
      lon: -4.486597585,
    });
    ```

    ```python !!tabs main.py
    import json
    import requests

    headers = {
        'Content-Type': 'application/json',
    }
    payload = {
        'name': 'High Wood',
        'lat': 50.464569783,
        'lon': -4.486597585,
    }
    req = requests.post(
      'https://api.example.org/places',
      data=json.dumps(payload),
      headers=headers
    )
    ```

    ```php !!tabs main.php
    $client = new Guzzle\Http\Client('https://api.example.org');

    $headers = [
        'Content-Type' => 'application/json',
    ];
    $payload = [
        'name' => 'High Wood',
        'lat' => 50.464569783,
        'lon' => -4.486597585,
    ];
    $req = $client->post('/places', [
      'headers' => $headers,
      'json' => $payload,
    ]);
    ```

    ```ruby !!tabs main.rb
    conn = Faraday.new(
      url: 'https://api.example.org',
      headers: { 'Content-Type' => 'application/json' }
    )

    response = conn.post('/places') do |req|
      req.body = {
        name: 'High Wood',
        lat: 50.464569783,
        lon: -4.486597585,
      }.to_json
    end
    ```
</CodeWithTabs>

HTTP tooling is essentially the same thing no matter the language. It's all
about URLs, methods, body, and headers. This makes REST API design a lot easier,
as you have a "uniform interface" to work with, whether everything is following
all these set conventions already.

Requests like `POST`, `PUT`, and `PATCH` typically include data in their body.

```http
POST /places HTTP/1.1
Host: api.example.org
Content-Type: application/json

{
  "name": "High Wood",
  "lat": 50.464569783,
  "lon": -4.486597585
}
```

This area is yours to do with as you want. There's a lot of freedom in how you
structure your data, but there are some best practices to follow which you can
learn more about in the [API Collections & Resources](/api-design
api-collections) guide.

### Request Body

The request is body is where the majority of "domain specific" data (things
specifically about your organization or API) will go. To understand more about
request bodies, we need to learn about data formats.

## Best Practices

### 1. Keep Request & Response Data Consistent

Maintain the same structure for data going in and out of your API. You want to
strive for predictability and consistency in your API design. When a user sends
a `POST` request to create a new resource, they should get back a response that
looks like the resource they just created. If a user updates a resource, the
response should return the new state of the updated resource.

```json
// POST Request
{
  "name": "High Wood",
  "lat": 50.464569783,
  "lon": -4.486597585
}

// Response
{
  "id": 123,
  "name": "High Wood",
  "lat": 50.464569783,
  "lon": -4.486597585,
  "created_at": "2024-10-24T12:00:00Z"
}
```

More on this in the [API Responses](/api-design/responses) guide.


 This is the content for the doc api-design/responses.mdx 

 ---
description: Creating clear, consistent API responses is crucial for building usable APIs. This guide covers essential patterns and best practices for API responses.
---

import { Callout } from '~/components'

# Designing API responses

The API response is the most important part of the entire API. 

- Did the API consumer ask a question? They need that answer.
- Did the API consumer ask to transfer £1,000,000? They need to be confident
that went well.
- Did the API consumer make a mistake? Tell them how to fix it so they can get
back to making you money.

Creating clear, consistent API responses is crucial for building usable APIs.
This guide covers essential patterns and best practices for API responses.

## Anatomy of an API Response

An API response is primarily made up of a status code, headers, and a response body,
so let's look at each of those parts in turn.

### Headers

Just like requests allow API consumers to add HTTP headers to act as metadata for the request, APIs and other network components can add headers to a response.

```http
HTTP/2 200 OK
Content-Type: application/json
Cache-Control: public, max-age=18000
RateLimit: "default";r=50;t=30

{
  "title": "something"
}
```

This is a successful request, with some JSON data as highlighted by the `Content-Type` header. The API has also alerted the API consumer that this is cacheable so they don't need to ask for it again for 5 hours, and explained that the client is running a little low on their rate limiting policy with only 50 more requests allowed in the next 30 seconds.

API responses contain lots of useful metadata in the headers, but data is going to be in the response body.

### Response Body

You should strive to keep response consistent and well-structured, with minimal nesting and correct use of data types.

```json
{
  "id": 123,
  "name": "High Wood",
  "location": {
    "lat": 50.464569783,
    "lon": -4.486597585
  },
  "created_at": "2024-10-24T12:00:00Z",
  "links": {
    "reviews": "/places/123/reviews"
  }
}
```

It's pretty common to add an `id` of some sort, often data will have dates, and
relationships and available actions can be linked allowing API consumers to easily
find related information without going on a scavenger hunt.

### Status Codes

So far we've only looked at success, but how do we know if something
has worked or not? 

You could look at the response body and try to figure it out, and for years
people were doing silly things like setting `{ "success": true/false }` in their
response body to give people a hint, but as always there's a far better way
defined in the HTTP spec which covers loads more use-cases and works out of the
box with loads of tools: HTTP Status Codes.

A status code is a number and a matching phrase, like `200 OK` and `404
Not Found`. There are countless status codes defined in the HTTP RFCs and
elsewhere, and some big companies have invented their own which became common
conventions, so there's plenty to choose from.

Arguments between developers will continue for the rest of time over the
exact appropriate status code to use in any given situation, but these are the
most important status codes to look out for in an API:

#### 2XX is all about success

Whatever the API was asked to do was successful, up to the point that the
response was sent. A `200 OK` is a generic "all good", a `201 Created` means
something was created, and a `202 Accepted` is similar but does not say anything
about the actual result, it only indicates that a request was accepted and is
being processed asynchronously. It could still go wrong, but at the time of
responding it was all looking good at least up until it was put in the queue.

The common success status codes and when to use them:

* **200** - Generic everything is OK.
* **201** - Created something OK.
* **202** - Accepted but is being processed async (for a video means.
encoding, for an image means resizing, etc.)
* **204** - No Content but still a success. Ideal for a successful `DELETE` request, for example.

Example success response

```http
HTTP/1.1 200 OK
Content-Type: application/json

{
  "user": {
    "id": 123,
    "name": "John Doe"
  }
}
```

#### 3XX is all about redirection

These are all about sending the calling application somewhere else for the
actual resource. The best known of these are the `303 See Other` and the `301
Moved Permanently`, which are used a lot on the web to redirect a browser to
another URL. Usually a redirect will be combined with a `Location` header to
point to the new location of the content.

#### 4XX is all about client errors

Indicate to your clients that they did something wrong. They might have
forgotten to send authentication details, provided invalid data, requested a
resource that no longer exists, or done something else wrong which needs fixing.

Key client error codes:

* **400** - Bad Request (should really be for invalid syntax, but some folks.
use for validation).
* **401** - Unauthorized (no current user and there should be).
* **403** - The current user is forbidden from accessing this data.
* **404** - That URL is not a valid route, or the item resource does not exist.
* **405** - Method Not Allowed (your framework will probably do this for you.)
* **406** - Not Acceptable (the client asked for a content type that the API does not support.)
* **409** - Conflict (Maybe somebody else just changed some of this data, or status cannot change from e.g: "published" to "draft").
* **410** - Gone - Data has been deleted, deactivated, suspended, etc.
* **415** - The request had a `Content-Type` which the server does not know how to handle.
* **429** - Rate Limited, which means take a breather, sleep a bit, try again.

#### 5XX is all about service errors

With these status codes, the API, or some network component like a load
balancer, web server, application server, etc. is indicating that something went
wrong on their side. For example, a database connection failed, or another
service was down. Typically, a client application can retry the request. The
server can even specify when the client should retry, using a `Retry-After` HTTP
header.

Key server error codes:

* **500** - Something unexpected happened, and it is the API's fault.
* **501** - This bit isn't finished yet, maybe it's still in beta and you don't have access.
* **502** - API is down, but it is not the API's fault.
* **503** - API is not here right now, please try again later.

As you can see, there are a whole bunch of HTTP status codes. You don't need to try and use
them all, but it is good to know what they are and what they mean so you can use
the right one for the job.

You have two choices, either read the [full list of status codes from the
IANA](https://www.iana.org/assignments/http-status-codes/http-status-codes.xhtml),
or swing by [http.cats](http://http.cat/) and see what the cats have to say
about it.

### Using Status Codes

```ts
import axios, { AxiosError } from 'axios';

async function makeHttpRequest() {
  try {
    const response = await axios.get('https://example.com/api/resource');
    console.log('Response:', response.data);
  } catch (error) {
    if (! axios.isAxiosError(error)) {
      console.error('An unexpected error occurred:', error);
      return;
    }
    const axiosError = error as AxiosError;
    if (axiosError.response?.status === 401) {
      console.error('You need to log in to access this resource.');
    } else if (axiosError.response?.status === 403) {
      console.error('You are forbidden from accessing this resource.');
    } else if (axiosError.response?.status === 404) {
      console.error('The resource you requested does not exist.');
    } else {
      console.error('An error occurred:', axiosError.message);
    }
  }
}

makeHttpRequest();
```

Now you can warn API consumers of fairly specific problems. Doing it way is
cumbersome, but there's plenty of generic libraries with various extensions and
"middlewares" that will help auto-retry any auto-retriable responses,
automatically cache cachable responses, and so on.

<Callout title="NOTE" variant="info">
  <p>Avoid confusing your API consumers by <a href="/docs/runtime/retries">enabling retry logic</a> in your Speakeasy SDK.</p>
</Callout>

## Best Practices

### 1. Keep Status Codes Appropriate & Consistent

It's important to keep status codes consistent across your API, ideally across your entire organization. 

This is not just for nice feels, it helps with code reuse, allowing consumers to
share code between endpoints, and between multiple APIs. 

This means they can integrate with you quicker, and with less code, and less maintenance overhead.

### 2. Keep Request & Response Bodies Consistent

Sometimes API developers end up with divergent data models between the request
and the response, and this should be avoided whenever possible. 

Whatever shape you pick for a request, you should match that shape on the response.

```json
// POST /places 

{
  "name": "High Wood",
  "lat": 50.464569783,
  "lon": -4.486597585
}
```

```json
// GET /places/123

{
  "id": 123,
  "name": "High Wood",
  "lat": 50.464569783,
  "lon": -4.486597585,
  "created_at": "2024-10-24T12:00:00Z"
}
```

You can see that some differences, like `id` or `created_at` dates on the
response but not the request. That's OK, because they can be handled as
"read-only" or "write-only" fields in the API documentation and generated code,
meaning they are using the same models just ignoring a few fields depending on
the context.

The problem often comes from various clients having a word with the API
developers about "helping them out", because some library being used by the iOS
app would prefer to send coordinates as a string and they don't want to convert
them to a decimal for some reason. Then the API team wanted to have the
responses wrapped into objects to make it look tidy, but the React team said it
would be too hard to get their data manager to do that, so the request skipped
it.

```json
// POST /places

{
  "name": "High Wood",
  "lat": "50.464569783",
  "lon": "-4.486597585"
}
```

```json
// GET /places/123

{
  "id": 123,
  "name": "High Wood",
  "location": {
    "lat": 50.464569783,
    "lon": -4.486597585
  },
  "created_at": "2024-10-24T12:00:00Z"
}
```

Aghh!

This sort of thing causes confusion for everyone in the process, and whilst any
one change being requested might feel reasonable, when a few of them stack up
the API becomes horrible to work with. 

Push back against request/response model deviations. It's not worth it.

### 3. Return detailed errors

Just returning a status code and a message is not enough, at the bare minimum
add an error message in the JSON body that adds more context. 

```
HTTP/2 409 Conflict
Content-Type: application/json

{
  "error": "A place with that name already exists."
}
```

This is better than nothing but not ideal. Other information needs to be added
to help with debugging, and to help the API client differentiate between errors.

There is a better way: [RFC 9457](https://tools.ietf.org/html/rfc9457) which
defines a standard way to return errors in JSON (or XML).

```http
HTTP/2 409 Conflict
Content-Type: application/problem+json

{
  "type": "https://api.example.com/probs/duplicate-place",
  "title": "A place with that name already exists.",
  "detail": "A place with the name 'High Wood' already exists close to here, have you or somebody else already added it?",
  "instance": "/places/123/errors/<unique-id>",
  "status": 409
}
```

More on this in the [API Errors](/api-design/responses/errors) guide.

## Best Practices

### 1. Keep Status Codes Appropriate & Consistent

It's important to keep status codes consistent across your API, ideally across your entire organization. 

This is not just for nice feels, it helps with code reuse, allowing consumers to
share code between endpoints, and between multiple APIs. 

This means they can integrate with you quicker, and with less code, and less maintenance overhead.

### 2. Keep Request & Response Bodies Consistent

Sometimes API developers end up with divergent data models between the request
and the response, and this should be avoided whenever possible. 

Whatever shape you pick for a request, you should match that shape on the response.

```json
// POST /places 

{
  "name": "High Wood",
  "lat": 50.464569783,
  "lon": -4.486597585
}
```

```json
// GET /places/123

{
  "id": 123,
  "name": "High Wood",
  "lat": 50.464569783,
  "lon": -4.486597585,
  "created_at": "2024-10-24T12:00:00Z"
}
```

You can see that some differences, like `id` or `created_at` dates on the
response but not the request. That's OK, because they can be handled as
"read-only" or "write-only" fields in the API documentation and generated code,
meaning they are using the same models just ignoring a few fields depending on
the context.

The problem often comes from various clients having a word with the API
developers about "helping them out", because some library being used by the iOS
app would prefer to send coordinates as a string and they don't want to convert
them to a decimal for some reason. Then the API team wanted to have the
responses wrapped into objects to make it look tidy, but the React team said it
would be too hard to get their data manager to do that, so the request skipped
it.

```json
// POST /places

{
  "name": "High Wood",
  "lat": "50.464569783",
  "lon": "-4.486597585"
}
```

```json
// GET /places/123

{
  "id": 123,
  "name": "High Wood",
  "location": {
    "lat": 50.464569783,
    "lon": -4.486597585
  },
  "created_at": "2024-10-24T12:00:00Z"
}
```

Aghh!

This sort of thing causes confusion for everyone in the process, and whilst any
one change being requested might feel reasonable, when a few of them stack up
the API becomes horrible to work with. 

Push back against request/response model deviations. It's not worth it.

### 3. Return detailed errors

Just returning a status code and a message is not enough, at the bare minimum
add an error message in the JSON body that adds more context. 

```
HTTP/2 409 Conflict
Content-Type: application/json

{
  "error": "A place with that name already exists."
}
```

This is better than nothing but not ideal. Other information needs to be added
to help with debugging, and to help the API client differentiate between errors.

There is a better way: [RFC 9457](https://tools.ietf.org/html/rfc9457) which
defines a standard way to return errors in JSON (or XML).

```http
HTTP/2 409 Conflict
Content-Type: application/problem+json

{
  "type": "https://api.example.com/probs/duplicate-place",
  "title": "A place with that name already exists.",
  "detail": "A place with the name 'High Wood' already exists close to here, have you or somebody else already added it?",
  "instance": "/places/123/errors/<unique-id>",
  "status": 409
}
```

More on this in the [API Errors](/api-design/api-errors) guide.


 This is the content for the doc api-design/security.md 

 ---
description: Designing for API security from the ground up.
---

# Designing for API security

Creating an API is like opening a door to the outside world. Who is allowed
through, what they can carry, and where they're allowed to go is incredibly
important. In this guide we'll see how design choices made early on impact the
security of an API once it's built. 

Many API security problems come down to coding errors or misconfigured
infrastructure, but this guide focuses more on the foundational API design
decisions that effect the security of an API from day one.

## Why care about API security

APIs often protect sensitive data or critical functionality. Whether it's a
payment gateway, a medical records system, or a social media app, an API needs
to be designed with security in mind to protect both the organization and its
users.

API security breaches in 2022 caused losses worth [$12–$23
billion](https://www.darkreading.com/application-security/api-security-losses-billions-complicated)
in the US and [$41–$75 billion
globally](https://techwireasia.com/2022/06/api-vulnerabilities-costing-businesses-up-to-us75-billion-annually/).

To pick just a few examples, since the introduction of General Data Protection
Regulation (GDPR), Amazon Europe were fined €746m in 2021, Meta was fined €1.2bn
in 2023, and - to show it's not just tech giants - Marriott International (a
hotel chain) got stuck with a £20m fine in 2022.

More countries and regions strengthening privacy laws along the lines of GDPR:
California Consumer Privacy Act (CCPA), Canada's Personal Information Protection
and Electronic Documents Act (PIPEDA), and Brazilian General Data Protection Law
(LGPD).

Even if data breaches and leaks don't result in hefty fines, the reputational
damage that comes with leaking customers private information can be a big issue,
so it's important to do everything possible to keep APIs secure.

Let's walk through some key security concepts in API design to see how
decisions can make or break an API's defenses before it's even built.

## Principle #1: Design with the least privilege

**Every API consumer should only have access to what they need and nothing more.**

Imagine designing an API for an e-commerce platform. A customer should be
able to view their order history, but not other customers' orders. 

Similarly, a "staff" user might need access to refund functionality but shouldn't
necessarily see sensitive payment details. 

**What Could Go Wrong**: Failure to verify this could lead
to Insecure Direct Object References (IDOR), a common flaw where attackers can
manipulate identifiers to access data they shouldn't.

**Design Decision**: The first issue to make sure endpoints are protected with
access controls, restricting the the specific user, or to a user with the right
role.

```http
GET /orders/{orderId}
Authorization: Bearer {access_token}
```

The application should verify that the `orderId` belongs to the authenticated
user, unless the user has a role like `admin`. 

Refund logic and payment details can be split onto their own endpoints:

```http
POST /orders/{orderId}/refund
Authorization: Bearer {staff_access_token}
```

```http
GET /orders/{orderId}/payments
Authorization: Bearer {admin_access_token}
```

This allows staff handle refunds, but does not leak sensitive credit card
information to as many people within the company, whilst still making it
possible to escalate customer problems to a higher access user. 

Better yet, **the payments collection is not even on the API**, it's something only
viewable in an admin backend system thats protected with a firewall and VPN.

## Principle #2: Always validate input

**Inputs should be treated as untrusted, even if the API is "internal" or
"private".**

Any incoming API traffic could be compromised in some way, even if it's
considered to be a trusted source. 

An API could suddenly become public: either intentionally when infrastructure
teams move things around, or accidentally when somebody de-compiles an iOS
application or sniffs traffic to find an API that people thought was hidden. 

Even if an API is firewalled off from public traffic, another API or service
could have been hacked giving them access to the protected API.

It's best to treat everyone with suspicion, and validate all inputs as strictly
as possible. 

**What Could Go Wrong**: Malicious data could be introduced, or private
information leaked, leading to any number of issues. People could delete invoice
payment records and updating payment details to trigger a second payment to the
wrong person. They could change passwords for users so they can log in as them
to access information and processes not even available in the API.

**Design Decision**: Set strict rules for which properties are editable, which
can be returned, and set strict validation rules for these properties. 

This can be described in OpenAPI early on utilizing `readOnly`, `writeOnly`,
`required`, setting `additionalProperties: false`. [Learn more about
additionalProperties](https://www.speakeasy.com/guides/openapi/additionalproperties).
This means when the API is developed the OpenAPI can be used for integration
testing to poke and prod to see if extra properties can sneak though. 

Comical examples of this was somebody hacking GitHub and Rails to update the
`created_at` date to have the year 3012. This attack is known as Bender from the
Future (a reference to TV show Futurama) and made the concept of "Mass
Assignment" popular. Whitelist which specific properties should be allowed to be
written/read in planning documents and OpenAPI, and either use that OpenAPI
document for validation and serialization, or test against it once they've built
the API.

## Principle #3: Keep secrets out of the URL

Sensitive information like API keys or tokens should never appear in URLs.

Let's say an API allows filtering resources:

```http
GET /products?search=blue&apiKey=my-secret-key
```

**What Could Go Wrong**: Logs, browser history, and proxies often store URLs. If
an API key or sensitive data is passed in the URL, it's at risk of exposure.

**Design Decision**: Always pass sensitive data through headers or the body of
the request, not the URL. The body will be encrypted when HTTPS is used, but the
URL is not.

```http
GET /products?search=blue
Authorization: Bearer my-secret-key
```

Using `Authorization` has the added benefit over generic custom headers like
`X-API-Key` because it will alert HTTP caching tools to not reuse this response
for other users by default. 

This is not simply about authorization though, there are lots of other
"sensitive" things which should not go into the URL. Email addresses, social
security numbers, anything that should not be leaked to the public in general.
Pop it in the body instead.

A `GET` method generally should not have a HTTP request body (behavior is
undocumented, support is inconsistent, generally unadvisable), but the [`QUERY`
draft RFC](https://httptoolkit.com/blog/http-search-method/) could be solution
we're all looking for.

## Principle #4: Limit one-time URLs

Logins and file uploads often involve allowing a user to pass in a URL, which
will then be downloaded or redirected to. 

```http
POST /products/{productId}/images
Authorization: Bearer {access_token}
Content-Type: application/json

{
  "import_url": "http://hopefully-innocent-website.com/something.jpg"
}
```

**What Could Go Wrong**: THis can be a big source of problems for an API, even
if the use case is something small and simple like importing an avatar for a
user. THe URL could be:

- A malicious file the API is being asked to download.
- A very large file the API will run out of resources trying to download.
- Intercepted by a malicious actor on an infected network to change the DNS of
  that URL to another server which is malicious.

**Design Decision**: The API design for image uploads could be changed to take a
HTTP request with the image directly.

```http
POST /products/{productId}/images
Authorization: Bearer {access_token}
Content-Type: image/png

<image data>
```

People could still try to upload malicious files directly, but its easier to
scan the incoming request body for problems and reject it. This can be done on
the API gateway or via other threat detection like Cloudflare.

With an API gateway in place, if this request is problematically large the
gateway will reject the request without consuming any resources at all on the
API server.

Malicious users on an infected network could still be messing with DNS settings,
but they would have to mess with the API in question - which should have proper
HTTPS setup and be much harder for them to do. Compared to their ability to mess
with `http://hopefully-innocent-website.com/` which may not be set up so well.

## Principle #5: Don't help competitors steal data

Using auto-incrementing IDs as identifiers in an API makes it incredibly easy
for malicious actors to glean insights into potentially sensitive data a
business might not want to expose, or allow outright theft of an entire dataset.

A startup tracking street art around the world (think Banksy, Bragga, and
smaller artists) built an amazing unique database of user-generated photographs
and locations of all sorts of graffiti, sculptures, installations, etc. 

This data was not available anywhere else on the Internet, but their website
relied on two API endpoints:

```http
GET /artworks/234
GET /users/6138
```

**What Could Go Wrong**: Looking at the URL `GET /users/6138`, its not too hard
to assume I can look at `GET /users/1`. If that shows me data, I can reasonably
assume they have at least 6138 users, but to find the total I can easily make a
script that `id+1` and counts every HTTP status 200 to show me how many users
are in the system. It can also counts things like 404 or 410, to give a accurate
number of how many active users versus inactive users, leaking a "churn rate"
which could be embarrassing in the press of scare off investors.

Using the same approach a client can hit `GET /artworks/1` and loop through with `id
+ 1` to grab a hold of all that data, which helped that company populate their
own database, making a new competitor quite easily, and with a slightly better
app as they didn't have to spend time or money building the dataset in the first
place. This put the original startup out of business.

**Design Decision**: There are non-incremental or "hard to guess" system of
identifiers instead. Standards like
[UUID](https://www.rfc-editor.org/rfc/rfc9562.html) or
[Snowflake](https://en.wikipedia.org/wiki/Snowflake_ID) instead.

Instead of having `/artworks/1` and `/artworks/2`, design the API to use UUID:

```http
GET /artworks/c1b07800-b001-4ba9-8372-e0260cf25242
GET /artworks/4e44cf4a-fbe0-4630-983f-ccd55b7e4870
```

There is no way for anyone to glean from this how many resources the API has, or
guess the next one, without brute forcing the API with infinite arbitrary
requests...

## Principle #6: Rate limiting and throttling

Prevent abuse by controlling how frequently clients can interact with an API.

Consider a public API endpoint for retrieving weather data:

```http
GET /weather?city=London
```

**What Could Go Wrong**: Without rate limiting, a single client could make
thousands of requests per second, overloading API servers and possibly causing
a denial of service (DoS).

**Design Decision**: Implement rate limiting at the design level. Define
thresholds for various user roles:

- Free users: 100 requests per hour
- Paid users: 1,000 requests per hour

Communicate these limits clearly in API documentation and return appropriate
status codes like `429 Too Many Requests` when limits are exceeded. 

Learn more about [rate limiting](/api-design/rate-limiting).

## Principle #7: Security through obscurity is not enough

An e-commerce platform for online stores (shops) provides a listing page with
the revenue charts for their hosted shops. Inspecting the browser requests, an
attacker can identify the API endpoints used as a data source for those charts
and their pattern: `/shops/{shopName}/revenue_data.json`. Using another API
endpoint, the attacker can get the list of all hosted shop names. With a simple
script to manipulate the names in the list, replacing {shopName} in the URL, the
attacker gains access to the sales data of thousands of e-commerce stores.

With `/shops/{shopName}/revenue_data.json` clients could access all the
sales. Even if its a special UUID for the shop, that might be good until
somebody shares that UUID or another developers exposes the uuids elsewhere not
realizing they're being used as security... Use proper auth for things that need
to be hidden or it will be exposed.

## Open Web Application Security Project (OWASP)

OWASP is an online community that produces freely available content to help
organizations avoid making costly security mistakes with their software.

The [OWASP API Security Project](https://owasp.org/API-Security/) helps focus
specific on risks and problems that can effect insecure APIs, and illustrating
how these risks may be mitigated. To make sure an API is secure as possible,
it's worth reading through the [OWASP API Security Top 10: 2023
Edition](https://owasp.org/API-Security/editions/2023/en/0x00-header/) and
keeping up to date with new editions when they're released.

## Tooling

Much of this advice and more can be applied to an OpenAPI automatically to help
whole teams make good decisions early on in the API design process. 

- [Vacuum](https://quobix.com/vacuum/) via the built in [OWASP Ruleset](https://quobix.com/vacuum/rules/owasp/).
- [Spectral](https://github.com/stoplightio/spectral) with the [Spectral OWASP Ruleset](https://github.com/stoplightio/spectral-owasp-ruleset).

## Summary

API security isn't a bolt-on; it's a mindset. By making deliberate design
choices around authentication, authorization, data handling, and rate limiting,
many of the pitfalls outlined here and in the OWASP API Security Top 10 can be avoided.

Remember, every design decision is a trade-off. Security measures often add
complexity or impact usability. The goal is to strike the right balance,
keeping the needs of both API consumers and the business in mind. 

There's no need to go to massive massive and intrusive lengths to secure
information that is fine out in the public, but it is important to establish
good practices for limiting interactions for more sensitive data. 

Maybe this means creating more than one API.


 This is the content for the doc api-design/status-codes.md 

 # Using HTTP status codes

Arguments between developers will continue for the rest of time over the
exact appropriate code to use in any given situation, but these are the
most important status codes to look out for in an API, and their accepted meanings:

HTTP status codes can convey a lot of assumptions, but they cannot possibly
cover all situations, so it's important to add something for the human
developers to see what's wrong.

## 2XX is all about success

Whatever the client tried to do was successful, up to the point that the
response was sent.

* **200** - Generic everything is OK.
* **201** - Created something OK.
* **202** - Accepted but is being processed async (for a video means.
encoding, for an image means resizing, etc.).
* **204** - No Content but still a success. Used for a DELETE request, for example.

Example success response

```http
HTTP/1.1 200 OK
Content-Type: application/json

{
  "user": {
    "id": 123,
    "name": "John Doe"
  }
}
```

## 3XX is all about redirection

These are all about sending the calling application somewhere else for the
actual resource. The best known of these are the `303 See Other` and the `301
Moved Permanently`, which are used a lot on the web to redirect a browser to
another URL. Usually a redirect will be combined with a `Location` header to
point to the new location of the content.

## 4XX is all about client errors

Indicate to clients that they did something wrong. They might have
forgotten to send authentication details, provided invalid data, requested a
resource that no longer exists, or done something else wrong which needs fixing.

There are a lot of status codes for client failures, but here are the most
common ones to be found see in API responses:

- *400 Bad Request* - The request was invalid or cannot be served. The exact error should be explained in the error payload.
- *401 Unauthorized* - The request requires an authentication token.
- *403 Forbidden* - The server understood the request, but is refusing it or the access is not allowed.
- *404 Not Found* - There is no resource behind the URI.
- *405 Method Not Allowed* - The request method is known by the server but has been disabled and cannot be used.
- *406 Not Acceptable* - The requested media type is not supported.
- *408 Request Timeout* - The server timed out waiting for the request.
- *409 Conflict* - The request could not be completed because of a conflict.
- *410 Gone* - The resource is no longer available and will not be available again.
- *412 Precondition Failed* - The server does not meet one of the preconditions that the requester put on the request.
- *413 Content Too Large* - The request body is larger than limits defined by server. The server might close the connection or return an `Retry-After` header field.
- *414 URI Too Long* - The URI requested by the client is longer than the server is willing to interpret.
- *415 Unsupported Media Type* - The request entity has a media type which the server or resource does not support.
- *416 Range Not Satisfiable* - The client has asked for a portion of the file, but the server cannot supply that portion.
- *417 Expectation Failed* - The server cannot meet the requirements of the `Expect` request-header field.
- *418 I'm a Teapot* - The Network Working Group were particularly bored one day and did an April fools joke.
- *429 Too Many Requests* - The user has sent too many requests in a given amount of time.

Example error response:

```http
HTTP/1.1 400 Bad Request
Content-Type: application/json

{
  "errors": [
    {
      "code": "VALIDATION_ERROR",
      "message": "Email address is not properly formatted",
      "field": "email"
    }
  ]
}
```

## 5XX is all about service errors

With these status codes, the API, or some network component like a load
balancer, web server, application server, etc. is indicating that something went
wrong on their side. For example, a database connection failed, or another
service was down. Typically, a client application can retry the request. The
server can even specify when the client should retry, using a `Retry-After` HTTP
header.

Key server error codes:

- *500 Internal Server Error* - The server has encountered a situation it doesn't know how to handle.
- *501 Not Implemented* - The request method is not supported by the server and cannot be handled.
- *502 Bad Gateway* - The server, while acting as a gateway or proxy, received an invalid response from the upstream server.
- *503 Service Unavailable* - The server is not ready to handle the request.
- *504 Gateway Timeout* - The server, while acting as a gateway or proxy, did not receive a timely response from the upstream server.

Example error response:

```http
HTTP/1.1 500 Internal Server Error
Content-Type: application/json

{
  "errors": [
    {
      "code": "SERVER_ERROR",
      "message": "Something went wrong on our end"
    }
  ]
}
```

There are a whole bunch of HTTP status codes and it's not important to try and
use them all, but it is good to know what they are so the right one can be used
for the job.

To learn more about HTTP status codes, either read the [full list of status codes from the
IANA](https://www.iana.org/assignments/http-status-codes/http-status-codes.xhtml),
or swing by [http.cats](http://http.cat/) and see what the cats have to say
about it.

## Best practices 

### Ambiguity in error code?

The `404` status code is drastically overused in APIs. People use it for "never
existed", "no longer exists", "you can't view it" and "deactivated", which is
way too vague. That can be split up into `403`, `404` and `410` for different
meanings.

If you get a `403`, this could be because the requesting user is not in the
correct group to see the requested content. Should the client suggest you
upgrade your account somehow? Are you not friends with the user whose content
you are trying to view? Should the client suggest you add them as a friend?

A `410` on a resource could be due to the resource being deleted, or it could be
due to the user deleting their entire account.

Sometimes being more specific about these different use-cases can help, but
sometimes it can leak sensitive information. For example, GitHub prefer to
return a `404` for a private repository that you do not have access to, instead of
a `403`, because a `403` would confirm the existence of the repository. You maybe
don't want people knowing that github.com/acme/your-secret-repo exists, so it's
better to not give out any hints.


 This is the content for the doc api-design/urls.md 

 ---
description: Learn how the Uniform Resource Locator works within a HTTP/REST API.
---

# Structuring URLs

A **URL** (Uniform Resource Locator) is like an postal address on the internet. Just as a postal address tells the postal service where to deliver mail, a URL tells your browser where to go to find a specific website, page, or resource in a way that both humans and computers can understand.

```
https://www.example.org/products/shoes?size=10&color=red
```

At first glance, this may seem complicated, but it's essentially a set of instructions for reaching a specific location on the web, with each word, doc, slash, and other punctuation meaning something in particular.

## The Parts of a URL

Let's break down this URL to understand how each part works, and have a look at URLs in general, before we get stuck into URLs specifically in the context of an API.

### 1. Protocol (Scheme)

```
https://
```

The **protocol** tells your browser how to communicate with the server that hosts the website. The most common protocols are:

- **HTTP** (Hypertext Transfer Protocol): This is the standard protocol used for loading web pages.
- **HTTPS** (HTTP Secure): This is the secure version of HTTP, meaning the data exchanged between your browser and the server is encrypted to increase security of data transfer.

These days most people are using HTTPS for everything. Google prefers HTTPS in search rankings. Using HTTP for an API is advised against strongly. It requires setting up a certificate which used to be expensive, but thanks to projects like [Let's Encrypt](https://letsencrypt.org/) it became free, quick, and relatively easy, to the point where most web hosting offers it by default, `https://` has become the defacto standard.

### 2. Domain Name

```
www.example.org
```

The domain name points your browser to the server where the website is hosted so that users can access the content without having to find and remember long complicated IP addresses.

The **domain name** identifies the website you want to visit. It consists of:
- **Subdomain** (optional): The `www` here is a common subdomain used for websites.
- **Second-level domain (SLD)**: `example`, which is the core part of the domain name.
- **Top-level domain (TLD)**: `.com`, which represents the organization type (`.gov`, `.edu`, `.mil`) the country (`.uk`, `.fr`), or the purpose (`.info`, `.blog`, `.earth`).

### 3. Path

```
/products/shoes
```

The **path** indicates the specific page or resource you're trying to access within the website. It works like an internal "room" in a building—after reaching the site (the building), the path tells you where to go inside. In this case, `/products/shoes` leads to a page showing shoes for sale.

### 4. Query String

```
?size=10&color=red
```

The **query string** is used to send extra information to the website, often to filter or customize what you want to see. In this example, `size=10&color=red` asks the website to show red shoes in size 10.

Query strings start with a `?` and are followed by **key-value pairs** that are separated by `&`. This helps the server return exactly what you're asking for.

## How URLs Work in the Browser

When you enter a URL into your browser or click a link, here's what happens behind the scenes:

1. **Request**: Your browser sends an **HTTP request** to the server at the domain (e.g., `www.example.org`). It uses the protocol (HTTP or HTTPS) to communicate.
2. **Process**: The server checks the **path** (e.g., `/products/shoes`) to find the correct resource (in this case, a web page about shoes).
3. **Response**: If the server finds the resource, it sends back an **HTTP response** containing the content (e.g., a web page, an image, or a file). If the resource doesn't exist, you might get an error, like "404 Not Found."

The URL is the full address your browser needs to complete these steps, making it a crucial part of how you access information online.

## URLs in REST APIs: A Gateway to Resources

In the world of **REST APIs**, URLs are not just for webpages but also for identifying and interacting with specific resources across the API, across an organization, or across the entire Internet. APIs are used by systems and applications to communicate with each other, and URLs act as a unique identifier for that resources, as well as acting as an address with to find more information.

Here's an example of how URLs work in REST APIs:

```
https://api.example.org/collections/shoes/products?sort=date&size=10&color=red
```

This may look similar to a regular web URL, and it absolutely is. All the same concepts existing in an API as in a general website, because the Internet is built using the same principles as a REST API. In an API, each part of the URL has a specific purpose for data exchange.

### 1. Protocol

```
https://
```

Just like with a regular website, the **protocol** specifies whether the communication should be secure (HTTPS) or not (HTTP). A website might redirect `http://` requests to `https://`, but for an API it's better to simply reject requests as they could be leaking sensitive information like authentication tokens, passwords, or other private information.

### 2. Domain

```
api.example.org
```

The **domain** points to the API server that you're communicating with. Many APIs use a subdomain like `api` to distinguish the API service from the main website.

You might have one API subdomain `api.example.org` for a single API, or multiple subdomains for different services `stats.api.example.org` or `servicename.example.org`. Alternatively you might decide to host the API on the main domain and use a path for the API `example.org/api/`. 

It doesn't matter much these days. Splitting web traffic between two different domains - e.g.: `www.example.org` and `api.example.org` had some pretty sizable performance concerns back in the HTTP/1.x days, as browsers would have to do DNS resolution and connection establishment repeatedly adding latency to the web request, but in a HTTP/2 (and HTTP/3) world this is no longer relevant, but some people have strong preferences based on historical reasons or infrastructure requirements.

### 3. Path

```
/collections/shoes/products
```

In a REST API, the **path** refers to a specific **resource** on the server. This e-commerce API is representing Collections and Products, and products can be assigned to collections, giving us the following structure:

- `/collections` refers to a list of collections.
- `/collections/shoes` refers to the **shoes** collection in particular. This is not defined in code, but is known as a "path parameter" allowing you to look up `shoes` in the database.
- `/collections/shoes/products` refers to the products in the shoes collection.

This allows API consumers to interact with the API in a structured way, and to access the data they need reliably in a predictable and generally optimizable way.

There are a few names for different parts of the path when used for a REST API.

1. `/users` this is known as a **Collection**.
1. `/users/<id>` this is a **Resource**.
1. `/users/<id>/posts` this is a **Sub-Collection**.
1. `/users/<id>/posts/<post-id>` this is a **Sub-Resource**.

Having sub-collections and sub-resources is known as "nesting", and you want to limit nesting as much as possible. It can feel neat and sensible at first, but it's easy to get carried away and people do things like `/users/<id>/orders/<order-id>`. This is not only unnecessary and complicated, but can lead to a few awkward problems.

**Resources are not strictly dependent on their parent:** The hierarchy becomes restrictive when sub-resources can exist independently or relate to multiple entities. For instance, an `order` might belong to a `user`, but you may also need to access `orders` independently or through other entities (like `products` or `shops`).

**Excessive Depth:** Deeply nested resources can lead to complex, hard-to-manage URL structures. For example:

```
/users/123/orders/456/products/789/reviews/1011
```

This URL indicates a very rigid hierarchy where reviews are always tied to a product that is tied to an order for a user. If your use case changes, or if you want to access reviews independently (e.g., by searching for reviews across all products or orders), this rigid hierarchy becomes unwieldy.

**Loss of Flexibility:** As your application evolves, you might need to interact with resources in ways that don’t fit the original hierarchy. Overly strict nesting forces clients to always traverse through the parent resources, even when it's unnecessary or illogical for certain operations. For example, fetching an order might not always need to be tied to a user, especially if your system grows to allow for admin views where orders are retrieved without needing the user context.

**Duplication of Resources:** If a resource belongs to multiple parents, nesting creates redundant endpoints. For example a sub-resource like this:

```
/users/123/orders/456
/shops/789/orders/456
```

The order belongs to both a user and a shop, forcing you to maintain multiple endpoints for the same resource. This increases code complexity, and makes network caching confusing and inconsistent. There's no reason to litter the URL with irrelevant parent data, that sub-resource example could just be: 

```
/orders/456
```

Instead of using sub-collections, we can use a "top-level collection" with query parameters.

```
/orders?user-id=123
/orders?shop-id=789
```

### 4. Query Parameters

```
?sort=date&size=10&color=red
```

In REST APIs, **query parameters** are used to refine the data you're requesting, allowing for [filtering & sorting](/api-design/filtering-responses.mdx), and [pagination](/api-design/pagination).

- `size=10` asks the server to return 10 products.
- `color=red` asks the server to return only red products.
- `sort=date` asks the server to return the products sorted by date.

The first query parameter is demarcated with a `?`, and subsequent query parameters are separated by `&`.

Filtering can be done for related content too, with id's or other criteria being passed in: 

```
/orders?user-id=123&status=pending
```

Query string parameters are handy, but the more an API uses, the harder it is to [cache](/api-design/caching). There is no right or wrong number of query parameters to use, just try to weigh up the value of the functionality they will offer, against the performance cost they may incur. 

### Summary

A URL is like an address that tells your browser or application where to find a resource on the internet or an API. In a web context, URLs help us navigate to specific pages, while in REST APIs, they act as powerful tools for accessing and manipulating data.

By understanding the different parts of a URL—protocol, domain, path, and query parameters—you can better navigate the web and use APIs to retrieve or update information in a precise, structured way. 


 This is the content for the doc api-design/versioning.mdx 

 ---
description: Learn how to manage API versioning and evolution to ensure smooth transitions and backward compatibility for clients.
---

import { Callout } from "~/components";

# Versioning & Evolution

Once an API has been designed, built, deployed, and integrated with by various
consumers, changing the API can be very difficult.

**Additive Changes**: Adding new endpoints, adding new properties to a response,
or introducing optional parameters are non-breaking changes, and can typically
be done without significant issues.
  
**Breaking Changes**: Removing or renaming endpoints, removing required fields,
or changing response structures are considered breaking changes. These have
the potential to disrupt existing client applications, resulting in errors and
loss of functionality. Clients, especially paying customers, may face the
expense and time-consuming task of adapting their code to accommodate these
changes.

For effective management of changes, developers must navigate versioning and
evolution of APIs carefully, ensuring that client integrations are not
negatively impacted. Let's explore these challenges in more detail.

## When are API changes an issue

Some APIs are built purely to service a single application. This might be a
backend for a web application, handled by a single full-stack developer or team
that manages both the frontend and the API. In this case, changes aren't as
problematic because both the frontend and backend can be updated simultaneously,
ensuring that there's no risk of breaking integration.

In most cases APIs are consumed by multiple clients, ranging from other teams
within the same organization to external customers. This introduces
complexities:

- **Internal Clients**: Even when the consumers are within the same
  organization, changes may require coordination, especially if the API is used
  by different teams working on separate services. The timing of updates and
  changes can cause delays or disruptions.

- **External Clients**: If the API is being used by third-party clients,
  particularly paying customers, changes can become even more difficult.
  External clients may resist updates due to the effort and risk involved in
  modifying their integrations. A major change could result in lost business,
  dissatisfaction, or churn.

When API consumers are not in sync with the development team, managing
versioning becomes essential to ensure smooth transitions.

## Why APIs need to change

Has anyone ever released any software then thought: "That's perfect, no change
needed"?

Probably not. APIs evolve over time like any other software, whether it's due to
changing business requirements, feedback from users, or the need to adopt new
technologies. APIs are rarely “perfect” and immutable.

Just like software versioning, APIs also require a versioning system to
accommodate changes. Developers use version numbers to signify changes in the
API contract, allowing consumers to choose which version of the API they wish to
use. This ensures backward compatibility for existing clients while introducing
improvements and fixes in newer versions.

With most software users can have any version running, with multiple versions of
the software running on various users computers at once. Common conventions,
including [Semantic Versioning](https://semver.org/), use three numbers: major,
minor, and patch, so some users might be running 1.0.0 whilst others run 1.0.2
and eventually some may be on 2.1.3.

Breaking changes might look like:

- A change to the endpoint structure.
- Adding a new required field.
- Removing a field from a response.
- Changing the behavior of an endpoint.
- Changing validation rules.
- Modifying the response format (e.g.: implementing a standard data format like JSON:API).

If any of this is done, a new API version may be required to avoid breaking existing clients.

## Versioning an API

API versioning involves assigning a version number or identifier to the API,
essentially creating multiple different APIs which are segmented in some clear
way so that the consumer can specify which version of the API they wish to
interact with.

There are countless ways people have tried to solve this problem over time, but
the two main approaches are:

### URL versioning

URL versioning is one of the most common approaches. It involves including a
version number in the URL, segmenting the API. Typically, only a major version
is used, as seen in this example:

```http
GET https://example.com/api/v1/users/123
```

```json
{
	"id": 123,
	"first_name": "Dwayne",
	"last_name": "Johnson"
}
```

In this example, `v1` refers to the version of the API, and its whatever the
resource was designed at first. 

As the API grows a new version is introduced to accommodate changes separate
from the first version.

```http
GET https://example.com/api/v2/users/3a717485-b81b-411c-8322-426a7a5ef5e6
```

```json
{
	"id": 123,
	"full_name": "Dwayne Johnson",
	"preferred_name": "The Rock"
}
```

Here, the v2 endpoint introduces a few notable changes: they phased out
auto-incrementing IDs as per the [security advice](/api-design/security),
ditched the [fallacy of people having two
names](https://www.kalzumeus.com/2010/06/17/falsehoods-programmers-believe-about-names/),
and helped people put in a preferred name to show publicly instead of forcing
everyone to publicize their legal name. Great, but this is a big change. 

If this change was deployed on the `/v1` version it would have broken most
clients usage, they would see 404 errors using the old IDs, and the fields have
changed so validation failures would occur.

As this is being run simultaneously under `/v2`, both can be used at once. This
allows clients to migrate at their own pace, and for the API to be updated
without breaking existing clients.

### Media-type versioning

Instead of embedding the version number in the URL, media type versioning places
the versioning information in the HTTP `Accept` header. This allows for more
flexible management of the API contract without altering the URL structure.

```http
GET https://example.com/api/users/123
Accept: application/vnd.acme.v2+json
```

```json
{
	"id": 123,
	"full_name": "Dwayne Johnson",
	"preferred_name": "The Rock"
}
```

In this case, the client specifies the version they want by including the
`Accept` header with the version identifier (e.g.:
`application/vnd.acme.v2+json`). The advantage is that the API URL remains
clean, and the versioning is managed through the HTTP headers.

This approach is less common than URL versioning, and has a few downsides. It's a
bit more complex to implement, and it's not as easy to see which version of the
API using.

## API evolution as an alternative

While versioning is a popular solution to API changes, **API evolution** is an
alternative focuses on maintaining backward compatibility and minimizing
breaking changes. Instead of introducing entirely new versions, API developers
evolve the existing API to accommodate new requirements, but do so in a way that
doesn't disrupt clients.

API evolution is the concept of striving to maintain the "I" in API, the
request/response body, query parameters, general functionality, etc., only
breaking them when absolutely necessary. It's the idea that API
developers bend over backwards to maintain a contract, no matter how annoying
that might be. It's often more financially and logistically viable for the API
developers to bear this load than dumping the workload onto a wide array of
consumers.

### API evolution in practice

To work on a realistic example, here's a simple change that could come up:

> The property `name` exists, and that needs to be split into `first_name` and `last_name` to support Stripe's name requirements.

A minor example, but removing name and making all consumers need to change all code to use the two new fields would be a breaking change. There are ways to retain backwards compatibility.

Most web application frameworks commonly used to build APIs have a feature like "serializers", where database models are turned into JSON objects to be returned, with all sensitive fields removed and any relevant tweaks or structure added. 

The database might have changed to use `first_name` and `last_name`, but the API does not need to remove the name property. It can be replaced with a "dynamic property" which joins the first and last names together and returns it in the JSON.

```ruby
class UserSerializer 
  include FastJsonapi::ObjectSerializer

  attributes :name, :first_name, :last_name
    "#{object.first_name} #{object.last_name}" 
  end 
end
```

```http
GET https://api.example.com/users/123
```

```json
{
  "id": 123,
  "name": "Dwayne Johnson",
  "first_name": "Dwayne",
  "last_name": "Johnson"
}
```

When a `POST` or `PATCH` is sent to the API, the API does not need to think about a version number to notice that `name` is being sent. IF name is sent it can be split, and if first_name and last_name are sent it can handle as expected.

```ruby
class User < ApplicationRecord
  def name=(name)
    self.first_name, self.last_name = name.split(' ', 2)
  end
end
```

A lot of changes can be handled with new properties, and supporting old properties indefinitely, but at a certain point that becomes cumbersome enough to need a bigger change.

When an endpoint is starting to feel a bit clunky and overloaded, or fundamental relationships change, an API rewrite can be avoided by evolving the API with new resources, collections, and relationships.

### Changing the domain model

In the case of [Protect Earth's](https://www.protect.earth/), a reforestation and rewilding charity, the Tree Tracker API needed some fundamental change. It used to focus on tracking trees that were planted, recording a photo and coordinates, and other metadata to allow for sponsoring and funding tree planting.

There's a `/trees` resource, and `/orders` has a `plantedTrees` property, but the charity expanded beyond trees to sowing wildflower meadows, rewetting peat bogs, and clearing invasive species. Instead around adding `/peat`, and `/meadows` resources, the API became more generic with a `/units` collection.

Removing `/trees` or `plantedTrees` would break customers, and that would stem the flow of funding. API evolution focuses on adding new functionality without breaking existing clients, so instead of removing the `/trees` endpoint, the API now supports both `/units` and `/trees`, with the `/trees` resource simply filtering the `/units` based on the `type` field:

```http
GET https://api.protect.earth/trees
```

```json
{
  "id": 123,
  "species": "Oak",
  "location": {
    "latitude": 42.0399,
    "longitude": -71.0589
  }
}
```

```http
GET https://api.protect.earth/units
```

```json
{
  "id": 123,
  "type": "tree",
  "species": "Oak",
  "location": {
    "latitude": 42.0399,
    "longitude": -71.0589
  }
}
```

This allows existing developers to continue using the `/trees` endpoint while new developers can use the `/units` endpoint. The API evolves to support new functionality without breaking existing clients.

What about the `/orders` having `plantedTrees` on them? Removing this property would be a breaking change, so a backwards compatible solution is needed, and with API evolution there are countless options.

It's possible to add both an old and a new property, allowing clients to migrate at their own pace. This can be done by adding a new `allocatedUnits` property to the `/orders` resource, while keeping the old `plantedTrees` property:

```http
GET https://api.protect.earth/orders/abc123
```

```json
{
  "id": "abc123",
  "organization": "Protect Earth",
  "orderDate": "2025-01-21",
  "status": "fulfilled",
  "plantedTrees": [
    {
      "id": 456,
      "species": "Oak",
      "location": {
        "latitude": 42.0399,
        "longitude": -71.0589
      }
    }
  ],
  "allocatedUnits": [
    {
      "id": 456,
      "type": "tree",
      "species": "Oak",
      "location": {
        "latitude": 42.0399,
        "longitude": -71.0589
      }
    }
  ]
}
```

However, for orders with 20,000 trees this means there will be 40,000 items across those two sub-arrays with both of them being identical. This is a bit of a waste, but really this is helping to highlight an existing design flaw. Why are these sub arrays not [paginated](/api-design/pagination), and why are units being embedded inside orders?

They are different resources, and its far easier to treat them as such. API evolution gives us a chance to fix this.

There is already an `/units` endpoint, let's use that.


```http
GET https://api.protect.earth/orders/abc123
```

```json
{
  "id": "abc123",
  "organization": "Protect Earth",
  "orderDate": "2025-01-21",
  "status": "fulfilled",
  "unitType": "peat",
  "links": {
    "units": "https://api.protect.earth/units?order=abc123"
  }
}
```

That way, the order resource is just about the order, and the units are about the units. This is a more RESTful design, and it's a better way to handle the relationship between orders and units.

Where did "plantedTrees" go? It's moved behind a switch. It will only show up on orders for trees, and all other unit types can be found on the `units` link which benefits from full pagination.

### Deprecating endpoints

All this flexibility comes with a tradeoff, it's more work to maintain two endpoints, because there may be performance tweaks and bug reports that need to be applied to both. It's also more work to document and test both endpoints, so it can be a good idea to keep an eye on which endpoints are being used and which aren't, and remove the old ones when they're no longer needed.

Old endpoints can be deprecated using the `Sunset` header. 

```http
HTTP/2 200 OK
Sunset: Tue, 1 Jul 2025 23:59:59 GMT
```

Adding a `Sunset` header to `/trees` will communicate to API consumers that the endpoint will be removed, and if it's done with sufficient warning and with a clear migration path, it can lead to a smooth transition for clients.

Further details can be provided in the form of a URL in a `Link` header and the `rel="sunset"` attribute.

```
HTTP/2 200 OK
Sunset: Tue, 1 Jul 2025 23:59:59 GMT
Link: <https://example.org/blog/migrating-to-units>; rel="sunset"
```

This could be a link to a blog post or an upgrade guide in documentation.

### Deprecating properties

Deprecating properties is a little more difficult, and generally best avoided whenever possible. It's not possible to use `Sunset` to communicate a property going away as it only applies to endpoints, but OpenAPI can help.

OpenAPI v3.1 added the `deprecate` keyword, to allow API descriptions to communicate deprecations as an API evolves.

```yaml
components:
  schemas:
    Order:
      type: object
      properties:
        plantedTrees:
          type: array
          items:
            $ref: '#/components/schemas/Tree'
          deprecate: true
          description: >
            An array of trees that have been planted, only on tree orders.
            *Deprecated:* use the units link relationship instead.
```

This will show up in the documentation, and can be used by SDKs to warn developers that they're using a deprecated property. 

Removing the `plantedTrees` property from the API entirely could be done, but it's a breaking change, and it's best to avoid breaking changes whenever possible. 

A better option is to stop putting the `plantedTrees` property into new orders starting on the deprecated date, and leave it on older orders.

Another change being added to the API is the concept of orders expiring, because companies should have got their data out of the API within six months, otherwise the information is archived to reduce wasting emissions as database expands. If `plantedTrees` is not added to new orders, and eventually orders archive, then eventually it will be gone completely and can be removed from code.

### API design-first reduces change later

Some APIs have kept their v1 API going for over a decade, which suggests they probably didn't need API versioning in the first place.

Some APIs are on v14, because the API developers didn't reach out to any stakeholders to ask what they needed out of an API and just wrote loads of code, rushing to rewrite it every time a new consumer came along with slightly different needs instead of finding a solution that worked for everyone.

Doing more planning, research, upfront API design, and prototyping can cut out the need for the first few versions, as many of those come from not getting enough user/market research done early on. This is common in startups that are moving fast and breaking things, but it can happen in any size business.

## Summary

When it comes to deciding between versioning and evolution, consider how many consumers will need to upgrade, and how long that work is likely to take. If it's two days of work, and there are 10 customers, then that's 160 person-hours. With 1,000 customers, that's 16,000 person-hours. 

At a certain point it becomes unconscionable to ask paying customers to all do that much work, and it's better to see if it could be handled with a new resource, new properties, or other backwards compatible changes which can slowly phase out their older forms over time, even if its a bit more work.


 This is the content for the doc blog/5-potential-use-cases-for-Arazzo/index.mdx 

 ---
title: "5 potential use cases for Arazzo"
description: "Discover how Arazzo simplifies API workflows, enhances AI accuracy, and streamlines development, security, and testing."
image: "/media/5-potential-use-cases-for-Arazzo.png"
date: 2025-01-22
authors:
  - name: Bill Doerrfeld
  - image_url: "/media/author-headshots/bill.jpeg"
tags:
  - OpenAPI
featured_image: "/media/5-potential-use-cases-for-Arazzo.png"
---

import { Callout } from "~/components";

Digital interactions often involve sequences of API calls to achieve goals like user authentication, booking a flight, or ordering a product online. These multi-step workflows rely on passing parameters between various services, with each step dependent on the outcome of preceding API calls. Although API-based workflows are commonplace, they typically aren't formally documented, hindering repeatability and developer experience.

Enter [Arazzo](https://github.com/OAI/Arazzo-Specification), a new specification from the [OpenAPI Initiative](https://www.openapis.org/) that can be used to describe an interconnected series of API calls and their dependencies. Announced in [mid-2024](https://youtu.be/EQaGHjMIcD8?si=CxVLfxyLAn7cESM2), Arazzo is on [version 1.0.1](https://github.com/OAI/Arazzo-Specification/pull/318) at the time of writing. 

Italian for "tapestry," Arazzo is aptly named since it can be used to weave together sequences of API calls to illustrate a specific business pattern. Although new on the scene, the API community is excited about the potential of using Arazzo to standardize deterministic workflows for various use cases.

There are countless examples of interlinked API sequences out there, and defining them could greatly boost API-driven development. From better articulating common customer flows to empowering quality engineers and optimizing AI agents, there is a fountain of [possibilities for using Arazzo](https://nordicapis.com/3-example-use-cases-for-arazzo-descriptions/). Below, we'll explore a handful of possible use cases and how they could benefit developer consumers and their end business objectives.

## 1. Making AI more deterministic

AI has become a household technology. Yet, large language models (LLMs) are still prone to inaccuracies and hallucinations. Plus, autonomously integrating with APIs and performing interconnected interactions still poses a challenge. This is in part due to a lack of repeatable machine-readable API-related semantics for LLMs.

Arazzo could be used to apply more deterministic API processes to AI agents. By ingesting OpenAPI specifications and Arazzo definitions, an AI could understand what operations are available and what workflows they should invoke to perform common actions. This could greatly empower AI agents with greater context, optimize their behaviors, and help reduce errors and randomness.

For example, consider an LLM-powered AI assistant within an online food ordering system. Suppose a user asks it to 're-order my last Thai dinner.' An AI could invoke an Arazzo description related to reordering, detailing all the required steps, such as order look-ups, availability and balance checks, and payment processing, to set up and initiate a reorder.

## 2. Simplifying multi-endpoint libraries

Have you ever read an OpenAPI definition? The average API has 42 endpoints, and these YAML or JSON files can become pretty unwieldy, with thousands of lines and metadata that are often irrelevant to an individual use case. To make matters more complicated, many workflows call APIs from disparate sources, including internal and external services.

Arazzo could be used to greatly abstract complexity for developers by helping to document and generate workflows around common business functions. Rather than fully describing every endpoint and method in an API, Arazzo could help generate [higher-level SDKs](https://speakeasy.hashnode.dev/apis-vs-sdks-why-you-should-always-have-both) that are multi-endpoint and use-case-specific. 

For instance, consider a developer tooling company that offers recruiting software as a platform. Suppose a common functional use case is to recruit a candidate that matches certain criteria. Well, an Arazzo workflow could document how to search for a user, check they are free for work, initiate outreach in the system, and update the status to `contacted`. It could even automate external calls for background checks or pull in public social media information.

Arazzo could deterministically describe the API calls and parameters required to achieve this process. These libraries could even combine interactions across various APIs, greatly streamlining the developer experience.

## 3. Demystifying authorization flows

Modern applications don't just authenticate the user — they make sure the user has the correct permissions. Behind the scenes, APIs typically require authorization flows using OpenID Connect and OAuth, involving back-and-forth exchanges between the requesting client, an API gateway, and an external identity server. 

Arazzo could be used to formulate a sequence of calls for an [OAuth service](https://github.com/OAI/Arazzo-Specification/blob/main/examples/1.0.0/oauth.arazzo.yaml), making a process like [refreshing an access token](https://github.com/OAI/Arazzo-Specification/blob/main/examples/1.0.0/oauth.arazzo.yaml) more transparent and repeatable. 

For example, the OAI provides an example of using Arazzo to describe a [Financial Grade API (FAPI) profile](https://github.com/OAI/Arazzo-Specification/blob/main/examples/1.0.0/FAPI-PAR.arazzo.yaml), which is a common flow for PSD2 open banking scenarios. Defining this could streamline how developers implement financial security flows, removing some guesswork from the picture. That said, the authentication aspect of OAuth flows are often unspecified and will depend on the exact configurations of the identity server. 


## 4. Automating end-to-end API testing

The standards for digital experiences are high, meaning quality assurance or site reliability engineers have their work cut out for them. API testing takes this to a whole new level since so much can go wrong with a programmatic interface that is continually updated and versioned. It takes a broad range of routine tests to ensure APIs are stable. From functional testing to performance testing, reliability testing, validation testing, security testing, chaos engineering, linting, and more. 

QA engineers often create Postman Collections that save API calls, but wouldn't it be nice to automate API testing? Arazzo could greatly aid [end-to-end testing](https://www.speakeasy.com/post/e2e-testing-arazzo) to ensure sequences of API calls are fully functional and meet service-level agreements, bringing efficiency benefits to the testing process.

Consider engineers working within a healthcare company — these folks could use Arazzo workflows to automate regulatory compliance checks. For instance, a conformance testing workflow could test whether a system violates regulations around data sharing across regional boundaries when passed certain geographic-specific parameters.

## 5. Standardizing patterns in unified APIs

Unified APIs take the integration hassle out of aggregating tens, if not hundreds, of software systems and endpoints for similar domains. For instance, take Avage API for construction software, Argyle for payroll services, Duffel for airline booking, or Plaid for integrating with bank data. Many more unified APIs exist for categories like CRM, cloud storage, accounting, and more.

Unified APIs could greatly benefit from Arazzo since they already define common user experiences across software domains. There are many common, repeatable pathways within a particular domain. For instance, a unified CRM API could create an agnostic workflow for adding a new qualified lead to a CRM system. Actionable flows for standard processes like this could improve the unified API integration developer experience.

## Optimizing working with Arazzo

It's good to note that Arazzo's actual utility will hinge on whether the API tooling ecosystem embraces it. Part of this will be making working with Arazzo more streamlined. Similar to API definition linting tools, the same thing for Arazzo is emerging, enabling you to validate that the Arazzo specification is correct. Speakeasy has open-sourced one such parser for this very purpose, [`speakeasy lint arazzo`](https://www.speakeasy.com/docs/speakeasy-reference/cli/lint/arazzo). Such tools will help API providers and API management platforms integrate Arazzo more easily into their pipelines and offerings.

## Let's see what the builders build

By defining common workflows, Arazzo could greatly reduce the mean time for integrations and help standardize complex descriptions typically housed in PDFs or Word documents outside of official API documentation. For developers, it can generate useful onboarding information to create more interactive, "living" workflow documentation.

Beyond the examples above, there are countless other [potential use cases](https://nordicapis.com/3-example-use-cases-for-arazzo-descriptions/) for Arazzo specifications. The Arazzo Specification repository also includes use cases such as securing a loan at a [buy now pay later](https://github.com/OAI/Arazzo-Specification/blob/main/examples/1.0.0/bnpl-arazzo.yaml) (BNPL) platform, or [applying coupons to a purchase](https://github.com/OAI/Arazzo-Specification/blob/main/examples/1.0.0/pet-coupons.arazzo.yaml). 

Arazzo is the first of its kind — a standard with growing industry momentum to denote composite API workflows around specific business goals. From an end consumer perspective, the standard could usher in more predictable [AI agents](https://thenewstack.io/its-time-to-start-preparing-apis-for-the-ai-agent-era/) and better cross-platform customer experiences. For developers, Arazzo could streamline stitching together common request patterns, demystify security flows, and make testing easier. 

A lot is hypothetical now, but the future is looking bright for this new standard. Now, it's just up to the builders to build.


 This is the content for the doc blog/announcing-easysdk-generator.mdx 

 ---
title: "Announcing: EasySDK Generator"
description: "A SDK generator that improves upon the OpenAPI service. Speakeasy is able to handle typing correctly & is opinionated about what makes for a good SDK."
image: "/media/announcing-easysdk-generator.png"
date: 2022-08-31
authors:
  - name: Sagar Batchu
  - image_url: 'https://uploads-ssl.webflow.com/62ccd7b208cab0723d026273/62cdf303b28bf9598d7a6b63_sagar_headshot-p-500.jpeg'
tags:
  - Product Updates
featured_image: "/media/announcing-easysdk-generator.png"
---

## What We’ve Built

We’re excited to announce that we are publicly launching an [SDK generator](#) that improves upon the [OpenAPI service](https://github.com/OpenAPITools/openapi-generator).  In our view the biggest problem with the OpenAPI generator was that it produced client libraries that were untyped and unopinionated. That’s why last week we focused on building a generator that is able to handle typing correctly and is opinionated about what makes for a good SDK:

- **Low-dependency** - To try and keep the SDK isomorphic (i.e. available both for Browsers and Node.JS servers), we wrap axios, but that’s it.This is intended to be idiomatic typescript; very similar to code a human would write; with the caveat that the typing is only as strict as the OpenAPI specification.
- **Static Typing** - At this point static typing is everywhere. So wherever possible, we generate typed structures, construct path variables automatically, pass through query parameters, and expose strictly typed input / output body types.
- **Language idiomatic & opinionated** - There’s value in being neutral, but we felt like there is more value in being opinionated. We’ve made choices for how things like Pagination, Retries (Backoff/Jitter etc), Auth integrations, should be handled in the SDK.

## Why We Think SDKs Are Important

A good developer experience means flattening the learning curve by meeting developers where they already; that’s why every company with an [API platform](/post/why-an-api-platform-is-important/) should strive to offer SDKs for integrating with their APIs.  Language-idiomatic SDKs improve user productivity by removing the need for writing the boilerplate required to send API requests and parse response objects.  Companies that offer SDKs get faster adoption, spend less time troubleshooting, and provide an overall better developer experience.

We look forward to hearing from the community what they think of the service. We’d love to know what else people would want to see included in an SDK, and what languages we should support next.


 This is the content for the doc blog/api-auth-guide/index.mdx 

 ---
title: "Guide to API Auth & A Novel Approach"
description: "A deep dive on the approaches to API Auth, and a novel approach we tried."
keywords: [api, api key management, api key, api auth, auth, shared secrets, signed tokens, oauth2, developer experience, devex, dx]
image: "/media/guide-api-auth.png"
date: 2023-01-20
authors:
  - name: Thomas Rooney
  - image_url: "/media/author-headshots/thomas.jpeg"
tags:
  - API Advice
  
featured_image: "/media/guide-api-auth.png"
---

## API Authentication Overview

If you're selling an API Product, one of the first decisions you're going to have to make is how to authenticate your users. This decision, once made, is hard to go back upon; any significant change will require user action to keep their integration working.

This blog post is intended to be a guide to the different API Authentication methods in common use, and the tradeoffs to consider between them, generally categorized into the following 3 metrics.

* **Time to API Call**
* **Ease of API Producer Implementation**
* **Ease of API Consumer Integration**

This post is inspired by work we recently undertook at Speakeasy (API DevEx tooling company) to build an API Key authorization flow that integrates into any API Gateway, and allows users to self-service and rotate their keys. For this project we evaluated all the standard approaches to authentication before deciding on a novel approach: signed tokens as API Keys, but with 1 signing key per API key. What follows are a deep dive on the typical methods, as well as our approach.

## Types of Authentication

Authenticated APIs require some way of identifying the client making the request, so that the API provider can authorize the requests to be processed, and identify the subset of data that can be accessed.

From an API Consumer perspective, the flow is usually:

1. You get a **Secret Key** from the service (e.g. in an authenticated Web UI).
2. You store that **Secret Key** somewhere securely, such that your application can access it.
3. You use that **Secret Key** within your application logic to authenticate with the API.

This is incredibly simple, and hence has great Developer Experience (DX).

However, from an API Producer Perspective, it's not so simple. There are choices you need to make about how the **Secret Key** is implemented which greatly impacts the Security Model of your application. Once you have users in production, Machine to Machine (M2M) authentication is hard to change, assuming you don’t want to break existing integrated users. Therefore, choose wisely:

1. **Opaque Token / Shared Secrets**
2. **Public / Private Key Pairs**
3. **OAuth 2.0 Secrets**
4. **Signed Tokens (one Signing Key)**
5. **Signed Tokens (many Signing Keys)**

Let’s look at the advantages and disadvantages of each approach…

### Opaque Tokens / Shared Secrets

An _Opaque Token_ is a _Shared Secret_ that is used to authenticate a client. It is _Opaque_ in that there is no message to read: all you can do with it is look up its existence in a centralised store (e.g. a database), and then, if it exists, you know who the user is.

This is functionally the same as a password, except that it is ideally generated by a process which ensures the entropy of the token is high enough that it is entirely unguessable.

Assuming this token is passed into the API in the `Authorization` header, from an API Consumer perspective, accessing the API is as simple as:

```sh
curl https://api.example.com/v1/endpoint
  --header "Authorization ${API_KEY}"
```

From an API Producer perspective, there's a few more moving parts, but it's usually pretty trivial to implement:

```mermaid
sequenceDiagram
  participant API Consumer[Bob]
  participant API
  participant Authorization Server
  rect rgba(0, 0, 0, 0.05)
  note over API Consumer[Bob],Authorization Server: Configure Key
  API Consumer[Bob]-->>API: AUTHORIZED SESSION [Bob] with [API]
  API-->>API Consumer[Bob]: 
  API Consumer[Bob]->>API: Request New Secret Key
      Note right of API: Generate some random bytes.<br>Render bytes as [Secret Key]
  API->>Authorization Server: Store [Bob, [Secret Key]]
  Authorization Server-->>API: Success
  API-->>API Consumer[Bob]: [Secret Key]
  end
  rect rgba(0, 0, 0, 0.05)
  note over API Consumer[Bob],Authorization Server: Authorized API Request
  API Consumer[Bob]->>API: [Req] with [Secret Key]
  API->>Authorization Server: Who is this? [Secret Key]
  Authorization Server-->>API: Bob
      Note right of API: Process Request under context Bob
  API-->>API Consumer[Bob]: [Resp]
  end
```

* **Time to API Call**: As Fast as it gets.
* **Ease of API Consumer Integration**: Very Easy
* **Ease of API Producer Implementation**: Very Easy
* **Other Considerations**:
  * Often Difficult to integrate into an API Gateway
  * Any validation requires a lookup where-ever these are stored. If you solely store them in the DB, this means that all lookups require a DB Read, which can cause additional latency to every request.

### OAuth 2.0 Secrets

```mermaid
sequenceDiagram
  participant API Consumer[Bob]
  participant API
  participant Authorization Server
  rect rgba(0, 0, 0, 0.05)
  note over API Consumer[Bob],Authorization Server: Configure Key
  API Consumer[Bob]-->>API: AUTHORIZED SESSION [Bob] with [API]
  API-->>API Consumer[Bob]: 
  API Consumer[Bob]->>API: Request New oAuth Application
      Note left of API: Generate some random bytes.<br>Render bytes as [Client ID], [Client Secret]<br>(AKA Secret Key). 
  API->>Authorization Server: [Bob, [Secret Key]]
  Authorization Server-->>API: Success
  API-->>API Consumer[Bob]: [Secret Key]
  end
  rect rgba(0, 0, 0, 0.05)
  note over API Consumer[Bob],Authorization Server: Authorized API Request
  API Consumer[Bob]-->>Authorization Server: SECURE SESSION [Unknown] with [Authorization Server]
  Authorization Server-->>API Consumer[Bob]: 
  API Consumer[Bob]->>Authorization Server: GET /oauth/token with [Secret Key]
    Note left of Authorization Server: Lookup [Secret Key] as Bob<br>Generate short-lived JWT with {"sub":"Bob"} claims
  Authorization Server-->>API Consumer[Bob]: JWT["Bob"]
  API Consumer[Bob]-->>API: SECURE SESSION [Unknown] with [API]
  API-->>API Consumer[Bob]: 
  API Consumer[Bob]->>API: [Req] with header "Authorization Bearer \${JWT["Bob"]}"
      Note left of API: Process Request under context Bob
  API-->>API Consumer[Bob]: [Resp]
  end
```

OAuth is commonly associated with user authentication through a social login. This doesn't make sense for API applications, as the system authenticates and authorizes an application rather than a user.

However, through the Client Credentials Flow ([OAuth 2.0 RFC 6749, section 4.4](https://tools.ietf.org/html/rfc6749#section-4.4])), a user application can exchange a **Client ID**, and **Client Secret** for a short lived Access Token.

In this scenario, the **Client ID** and **Client Secret** pair are the **Shared Secret** which would be passed to the integrating developer to configure in their application. In the OpenID Connect (OIDC) protocol, this happens by making a request to the **/oauth/token** endpoint.

```sh
TOKEN=$(curl --header "Content-Type: application/x-www-form-urlencoded" \
  --request POST \
  --data "grant_type=client_credentials" \
  --data "client_id=CLIENT_ID" \
  --data "client_secret=CLIENT_SECRET" \
  https://auth.example.com/oauth/token | jq -r '.access_token')

curl --header "Authorization Bearer $TOKEN" \
  https://api.example.com/v1/endpoint
```

* **Time to API Call**: Slow.
* **Ease of API Consumer Integration**: Difficult
* **Ease of API Producer Implementation**: Difficult
* **Other Considerations**:
  * Can enable additional use-cases, such as granting third party systems the capability to make API calls on behalf of your users.

### Public/Private Key Pairs

A Public Private Key Pair allows for a user to hold a secret and the server to validate that the user holds a secret, without the server ever holding the secret. For the purpose of authenticating users, this mechanism has the lowest attack surface : i.e. it is the most secure.

```mermaid
sequenceDiagram
  participant API Consumer[Bob]
  participant API
  participant Authorization Server
  rect rgba(0, 0, 0, 0.05)
  note over API Consumer[Bob],Authorization Server: Configure Key
  API Consumer[Bob]-->>API: AUTHORIZED SESSION [Bob] with [API]
  API-->>API Consumer[Bob]:  
  Note right of API Consumer[Bob]: Generate Public/Private Key Pair
  API Consumer[Bob]->>API: Send Public Key
  API->>Authorization Server: Store [Bob, [Public Key]]
  Authorization Server-->>API: Success
  API-->>API Consumer[Bob]: Success 
  end
  rect rgba(0, 0, 0, 0.05)
  note over API Consumer[Bob],Authorization Server: Authorized API Request  
  API Consumer[Bob]-->>API: SECURE SESSION [Unknown] with [API]
  API-->>API Consumer[Bob]: 
  API Consumer[Bob]->>Authorization Server: Hello, I am Bob
  Note left of Authorization Server: Generate Random Number [NONCE]
  Authorization Server-->>API Consumer[Bob]: Hello Bob, please sign [NONCE]
  Note right of API Consumer[Bob]: Sign [NONCE] with Private Key as [PROOF]
  API Consumer[Bob]->>Authorization Server: [PROOF] 
  Note left of Authorization Server: Validate [NONCE] signature using [Public Key[Bob]]
  Authorization Server-->>API Consumer[Bob]: Success. [Session Token]
  API Consumer[Bob]-->>API: AUTHORIZED SESSION [Bob] with [API] via [Session Token]
  API-->>API Consumer[Bob]: 
  end
```

The cost and complexity of building and maintaining a Public/Private Key Authentication mechanism, without exposing the Private Key, opening up replay attacks, or making a mistake in implementation somewhere can be high.

If you're selling an API to multiple consumers, it's unlikely that it will be as trivial as the following `curl` to invoke the API that you want; as the integrating system will need to understand the protocol you choose. There are also complexities regarding the certificate lifecycle, and the need to either manage certificate rotation, or pin (hardcode) each certificate into the system.

```sh
# mTLS via curl: Should you be looking to grant unscoped access to a specific API Route to trusted consumers,
#   this can usually be configured by some API Gateway products in infrastructure configuration. 
curl --cacert ca.crt \
     --key client.key \
     --cert client.crt \
     https://api.example.com/v1/endpoint
```

* **Time to API Call**: Slow.
* **Ease of API Consumer Integration**: Difficult
* **Ease of API Producer Implementation**: Difficult
* **Other Considerations**:
  * Severity of the public key being leaked is functionally zero -- no intermediary system holds enough data to make/replay requests except the original sender.

### Signed Tokens as API Keys

A Signed Token is secret; in the same way that a Shared Secret is secret. 

However, due to standardization of technologies, it is starting to become commonplace to use long-lived Signed Tokens, in the form of JWTs (JSON Web Tokens), as API Keys. This enables the following pattern: 

```sh
curl --header "Authorization Bearer ${API_KEY}"\
     http://api.example.com/v1/endpoint 
```

```mermaid 
sequenceDiagram
  participant API Consumer[Bob]
  participant API
  participant Authorization Server
  rect rgba(0, 0, 0, 0.05)
  note over API Consumer[Bob],Authorization Server: Configure Key
  API Consumer[Bob]-->>API: AUTHORIZED SESSION [Bob] with [API]
  API-->>API Consumer[Bob]: 
  API Consumer[Bob]->>Authorization Server: Request New Secret Key
      Note left of Authorization Server: Make JWT[Secret Key] with Signing Key [K] via: <br>SIGN({"sub": Bob, "exp": 3 months}, K).
  Authorization Server-->>API Consumer[Bob]: [Secret Key]
  end
  rect rgba(0, 0, 0, 0.05)
  note over API Consumer[Bob],Authorization Server: Authorized API Request
  API Consumer[Bob]-->>API: SECURE SESSION [Unknown] with [API]
  API-->>API Consumer[Bob]: 
  API Consumer[Bob]->>API: [Req] with header "Authorization Bearer \${JWT["Bob"]}
  API->>Authorization Server: Check JWT["Bob"]
    Note left of Authorization Server: Validate JWT[Secret Key] with Signing Key [K]
  Authorization Server-->>API: Success
      Note left of API: Process Request under context Bob
  API-->>API Consumer[Bob]: [Resp]
  end
```

* **Time to API Call**: Fast.
* **Ease of API Consumer Integration**: Simple
* **Ease of API Producer Implementation**: Simple
* **Other Considerations**:
  * Difficult to revoke tokens: either a whitelist/blacklist is used (in which case, little advantage exists over shared secrets), or the signing key must be rotated.
  * Easy to add complexity through custom claims into the token, which can lead to complexity migrating tokens into a new form.
  * Easy to block requests from reaching application servers through an API Gateway and Asymmetric Keys (split into Private JWTs and Public JWKs).

### Our Approach: Signed Tokens as API Keys, but 1-Signing-Key-Per-API-key

There are 3 problems with the Signed Tokens as API Keys pattern:

1. Revoking a key is hard: it is very difficult for users to revoke their own keys on an internal compromise.
2. Any compromise of the Signing Key is a compromise of all keys.
3. API Gateways can't usually hook into a whitelist/blacklist of tokens.

To tackle these, we can do three things:

1. Use Asymmetrically Signed JWTs, storing and exposing a set of Public Keys via a JWKS (JSON Web Key Set) URI.
2. Sign each Token with a different Signing Key; burn the Signing Key immediately afterwards.
3. Ensure that API Gateways only retain a short-lived cache of JWKS (the Public Key to each Signing Key).

```mermaid
sequenceDiagram
  participant API Consumer[Bob]
  participant Authorization Server
  participant API
  rect rgba(0, 0, 0, 0.05)
  note over API Consumer[Bob],API: Configure Key
  API Consumer[Bob]-->>Authorization Server: AUTHORIZED SESSION [Bob] with [Authorization Server]
  Authorization Server-->>API Consumer[Bob]: 
  API Consumer[Bob]->>Authorization Server: Request New Secret Key [K]
      Note left of Authorization Server: Create a new Signing Key Pair [K]<br> (e.g. EdDSA Certificate with High Entropy)<br>Sign [Bob] with [K["PrivateKey"]] as [Secret Key]<br>Store [Bob, K["PublicKey"]]<br>Burn K["Private Key"]       
  Authorization Server-->>API Consumer[Bob]: [Secret Key]
  end
  rect rgba(0, 0, 0, 0.05)
  note over API Consumer[Bob],API: Authorized API Request
  API Consumer[Bob]-->>Authorization Server: SECURE SESSION [Unknown] with [Authorization Server]
  Authorization Server-->>API Consumer[Bob]: 
  API Consumer[Bob]->>Authorization Server: [Req] with header "Authorization Bearer \${JWT["Bob"]}"
    Note left of Authorization Server: Decode["Secret Key"] into JWT<br>Lookup Bob["Public Key"] via JWT.KID<br>Validate ["Secret Key"] matches Public Key["KID"]
  Authorization Server->>API: [Req], [Bob]
      Note left of API: Process Request under context Bob
  API-->>Authorization Server: [Resp]
  Authorization Server-->>API Consumer[Bob]: [Resp]
  end
```

This gives us a flow that's very similar to a shared secret, but with the advantage that:

* Revoking a key is easy: the Public Key just needs to be removed from the JWKS and caches invalidated.
* There is no Signing Key to compromise ; all Authorization Server state can be public.

With the tradeoff:

* Any API Gateway that validates a JWT must be able to regularly fetch JWKS (and cache them) from the Authorization Server.
* After creating/revoking a key, there will be a short time delay (we generally configure this to be 15 seconds) whilst the key propagates into all API Gateway JWK caches.
* More compute is required when constructing the Initial API Key; due to the generation of a public/private key pair.
* You need to give the API Gateway application cluster slightly more memory to keep all Public Keys (1 per API key) in memory.

import portal_url_1 from './assets/auth-clip.mp4'

  <video controls={false} loop={true} autoPlay={true} muted={true} width="100%" alt="Auto-clip">
    <source src={portal_url_1} type="video/mp4" />
  </video>

#### In Practice: Envoy / Google Endpoints / EspV2

Envoy is a proxy server that is used to route traffic to a backend service. We ran extensive tests with ESPV2 (Envoy Service Proxy V2) and Google Endpoints, and found/validated the following performance characteristics as the number of keys increased. 

```yaml
# Espv2 is configured with an OpenAPI specification to use an external JWKs URI to validate incoming API Keys
securityDefinitions:
  speakeasy_api_key:
    authorizationUrl: ""
    flow: "implicit"
    type: "oauth2"
    x-google-issuer: "https://app.speakeasy.com/v1/auth/oauth/{your-speakeasy-workspace-id}"
    x-google-jwks_uri: "https://app.speakeasy.com/v1/auth/oauth/{your-speakeasy-workspace-id}/.well-known/jwks.json"
    x-google-audiences: "acme-company"
```

We ran benchmarks of up to 1138688 API keys, structured as public/private 2048-bit RSA keypairs with a single RS256 Signed JWT-per-JWK, using a 8GiB Cloud Run managed Espv2 instance. At this key size and at ~100 requests/second, we observed a peak of ~37% utilization of memory, with ~7% utilized at no API keys. This implies an 8GiB EspV2 instance should scale to ~3M API Keys at this request rate.

This also implies that this mechanism will scale with Envoy RAM with a minor deviation in maximum latency, to the degree of ~3.5ms additional maximum request latency every 8192 API keys. The average additional latency introduced by large numbers of API keys is affected to a much lesser degree, ~0.2ms every 8192 API Keys.

![envoy-scaling.png](./assets/envoy-scaling.png)

Given most API Applications have less than 3M API Keys active at any given time, this approach, in our belief, combines the best of both worlds: Public/Private Key Crypto, with the ease of an API Key.


 This is the content for the doc blog/api-design/index.mdx 

 ---
title: "Designing your API: Find the RESTful sweet spot"
description: "Learn to make practical API design decisions that will help you create a better developer experience."
keywords:
  [
    api,
    api design,
    sdk,
    developer experience,
    devex,
    dx,
    openapi,
    rest,
    rest api,
    restful,
    restful api,
    swagger,
  ]
image: "/media/guide-api-design.png"
date: 2025-01-01
authors:
  - name: Sagar Batchu
  - image_url: "/media/author-headshots/sagar.jpeg"
tags:
  - API Advice

featured_image: "/media/guide-api-design.png"
---

import { Callout } from "~/components";

<Callout title="API Design Guide" variant="success">
  <p>If you're looking for a more comprehensive guide to API design, you can read our <a href="/api-design">REST API Design Guide</a>.</p>
</Callout>

What we call RESTful APIs today often refer to JSON over HTTP, which is an offspring of the RESTful APIs Roy Fielding defined in his [dissertation](https://ics.uci.edu/~fielding/pubs/dissertation/fielding_dissertation_2up.pdf) in 2000. Back then, JSON was still just an idea, and the web was still in its infancy. The constraints Fielding defined in his dissertation were a reaction to the state of the web at the time, but they remain relevant to the web today. Rather than co-opting the term RESTful, JSON-over-HTTP APIs could have benefited from a new term that acknowledges their differences from Fielding's REST. 

Alas, the term RESTful stuck, and here we are. This article will explore what it means to be RESTful in 2025, why it matters, and how to find the sweet spot between adhering to RESTful principles and following established practices.

First, let's clarify the difference between RESTful APIs and REST-like APIs.

# Designing your API: Find the RESTful sweet spot

Fielding's original REST model defines six architectural constraints, liberally summarized as follows:

1. **Client-server architecture**: This separation allows the client and server to evolve independently as long as the interface doesn't change.
2. **Statelessness**: Each request from the client contains all the information the server needs to fulfill that request, easing server workload and improving scalability.
3. **Cacheability**: Responses are explicitly labeled as cacheable or non-cacheable, which helps reduce client-server interactions and improves performance.
4. **Uniform interface**: This constraint is broken into four subconstraints.
   - **Resource identification**: Resources are identified in requests, typically using URIs.
   - **Resource manipulation through representations**: Resources are manipulated through representations, such as JSON or XML.
   - **Self-descriptive messages**: Messages include all the information needed to understand them.
   - **Hypermedia as the engine of application state (HATEOAS)**: Responses include links to related resources, allowing clients to navigate the API dynamically.
5. **Layered system**: A client should be unable to tell whether it is connected directly to the end server or to an intermediary along the way.
6. **Code on demand (optional)**: Servers can extend client functionality by transferring executable code, like Java applets or client-side scripts.

Adherence to these constraints distinguishes a truly RESTful API from one that is REST-like.

## How most REST-like APIs adhere to REST constraints

If you're building a modern API, you're likely adhering to some of the REST model's constraints, even if you're not following them all to the letter. The key is to understand the principles behind REST and apply them in a way that makes sense for your use case.

### ✅ Client-server architecture: Followed by most REST-like APIs

In the context of APIs, this means that the client and server communicate over a network, with the server providing resources and the client consuming them. This separation is central to RESTful design and may be why the term "RESTful" was adopted for APIs that follow this pattern.

```mermaid
sequenceDiagram
    participant Client
    participant Server
    Client->>Server: Request
    Server->>Client: Response
```

### ✅ Statelessness: Followed by most REST-like APIs

Statelessness means that each request from the client to the server must contain all the information needed to fulfill that request. This constraint simplifies server logic and improves scalability by allowing servers to handle requests independently.

Most APIs follow this constraint by requiring clients to include all necessary information in each request.

```mermaid
sequenceDiagram
    participant Client
    participant Server
    Client->>Server: GET /orders/123
    Server->>Client: 200 OK { "order": { "id": 123, "status": "shipped" } }
```

### ✅ Cacheability: Followed by most REST-like APIs

Cacheability allows responses to be explicitly labeled as cacheable or non-cacheable, reducing the need for repeated requests to the server. By specifying cacheability, APIs can improve performance and reduce server load.

Most APIs follow this constraint by including cache-control headers in their responses.

```mermaid
sequenceDiagram
    participant Client
    participant Cache
    participant Server
    Client->>Cache: GET /orders/123
    Cache->>Server: GET /orders/123
    Server->>Cache: 200 OK { "order": { "id": 123, "status": "shipped" } }
    Cache->>Client: 200 OK { "order": { "id": 123, "status": "shipped" } }
    Client->>Cache: GET /orders/123
    Cache->>Client: 200 OK { "order": { "id": 123, "status": "shipped" } }
```

The first request retrieves the order from the server and caches it. The subsequent request is served from the cache, reducing the load on the server.

### ⚠️ Uniform interface: Partially followed by most REST-like APIs

The uniform interface constraint is seen by many as the heart of REST. It defines a standard way to interact with resources, making APIs more discoverable and easier to use. This constraint is often broken down into four sub-constraints:

✅ **Resource identification**: Resources are identified in requests, typically using URIs. Followed by most APIs.

✅ **Resource manipulation through representations**: Resources are manipulated through representations, such as JSON or XML. Followed by most APIs.

⚠️ **Self-descriptive messages**: Messages include all the information needed to understand them. Through the use of media types, APIs can achieve this sub-constraint. Partially followed by most APIs.

❌ **Hypermedia as the engine of application state (HATEOAS)**: Responses include links to related resources, allowing clients to navigate the API dynamically. Rarely followed by APIs.

The last two sub-constraints of uniform interfaces are often the most challenging to implement and are frequently omitted in practice.

HATEOAS, in particular, is a powerful concept that applies extremely well to web APIs that serve human users. For example, HTML returned by a web server contains links that users can click to navigate the web.

Take this HTML response as an example:

```bash
curl --header "Accept: text/html" https://api.example.com/orders/123
```

```html
<!doctype html>
<html>
  <head>
    <title>Order 123</title>
  </head>
  <body>
    <h1>Order 123</h1>
    <p>Status: Shipped</p>
    <a href="/orders/123">View Order</a>
    <a href="/customers/456">View Customer</a>
  </body>
</html>
```

In this case, the links are clickable, allowing users to navigate the API by following them. This is the essence of HATEOAS.

Contrast this with a JSON response:

```bash
curl --header "Accept: application/json" https://api.example.com/orders/123
```

```json
{
  "id": 123,
  "status": "shipped",
  "links": [
    { "rel": "self", "href": "/orders/123" },
    { "rel": "customer", "href": "/customers/456" }
  ]
}
```

In this example, the response includes links to the order itself and the customer who placed the order. By following these links, a client can navigate the API without prior knowledge of its structure. In practice, an SDK or client library would need to be aware of these links to provide a similar experience. From a developer experience perspective, this can be challenging to implement and maintain.

Instead of implementing HATEOAS, many APIs rely on documentation to inform developers how to interact with the API. While this approach is more common, it lacks the dynamic nature of HATEOAS.

### ✅ Layered system: Followed by most REST-like APIs

The layered system constraint allows for intermediaries between the client and server, such as proxies or gateways. This separation enhances scalability and security by isolating components and simplifying communication.

Most APIs follow this constraint by permitting intermediaries between the client and server.

```mermaid
sequenceDiagram
    participant Client
    participant Proxy
    participant Server
    Client->>Proxy: Request
    Proxy->>Server: Request
    Server->>Proxy: Response
    Proxy->>Client: Response
```

Since API requests are stateless and contain all the information needed to fulfill them, intermediaries can forward requests without needing to maintain session state. This is especially useful for load balancing and security purposes.

### ⚠️ Resource-oriented architecture: Followed by some REST-like APIs

Each of the constraints above contributes to a resource-oriented architecture, where resources are identified by URIs and manipulated through representations. This architecture makes APIs more predictable and easier to use by following standard resource interaction patterns.

Most APIs follow this constraint by organizing their resources into collections and items, with standard methods for interacting with them.

This pattern is often reflected in an API's URL structure, where resources are presented as nouns, and instead of using verbs in the URL, API actions are represented by HTTP methods. For example:

- `GET /orders`: Retrieve a list of orders.
- `POST /orders`: Create a new order.
- `GET /orders/123`: Retrieve order 123.
- `PUT /orders/123`: Update order 123.
- `DELETE /orders/123`: Delete order 123.

Many API design guidelines recommend using resource-oriented URLs to make APIs more intuitive and easier to use. We'll explore this in more detail later in the article.

### ❌ Code on demand: Rarely used in the context of APIs

We'll skip this constraint for now, as it's optional and rarely implemented in practice outside hypermedia-driven APIs.

## Why adherence matters

Is this a cargo cult, or do these constraints actually matter? They do, and here's why:

### The principle of least astonishment

There is a big difference between delighting users and surprising them. The principle of least astonishment states that the behavior of a system should be predictable and consistent.

When your API behaves in a predictable way, like sticking to the standard ways of using HTTP methods and formats, you're making it easy for developers to use. They shouldn’t have to spend hours figuring out quirky behaviors or unexpected responses - that just leads to headaches and wasted time.

### Scalability

Scalability is essential when designing APIs that need to handle varying loads and growth over time. Adhering to REST principles inherently supports scalability in several ways:

- **Statelessness**: Without the need to maintain session state, servers can handle requests independently, making it easier to scale horizontally.
- **Cacheability**: REST APIs explicitly label responses as cacheable. This reduces the server load, as cached responses can be reused from previous requests.
- **Layered system**: REST architecture allows the deployment of intermediary servers, such as load balancers and cache servers, which isolate client requests from direct backend processing.

### Maintainability

The constraints of the REST model naturally lead to a design that is easier to update and manage:

- **Resource-oriented design**: By focusing on resources rather than actions, APIs become more modular and logically structured.
- **Independent client and server evolution**: The client-server separation supported by REST allows both sides to evolve independently.

## Quantifying REST adherence

[The Richardson Maturity Model](https://martinfowler.com/articles/richardsonMaturityModel.html) provides a framework for evaluating an API's compliance with RESTful principles. This model outlines four levels of RESTfulness, each building on the previous one, allowing you to assess and improve your API's design objectively:

### Level 0: The swamp of POX (Plain Old XML)

At this base level, APIs typically rely on a single URI and use HTTP merely as a transport protocol. There is little to no differentiation in the use of HTTP methods, and operations tend to be defined solely by the payload. This resembles the remote procedure call over HTTP (RPC over HTTP) protocol, where the rich set of HTTP features, like methods and status codes, are underutilized.

An example of a Level 0 API might be:

```bash
curl -X POST https://api.example.com/api.aspx?method=createOrder -d "..."
```

### Level 1: Resources

The first step towards RESTfulness is exposing resources via distinct URIs. At Level 1, APIs start organizing data into resources, often with a collection-item structure, making the API more resource-oriented. Each resource, such as `/orders` or `/customers`, typically represents a collection of items, with individual resources accessible by identifiers like `/orders/{orderId}`.

An example of a Level 1 API might be:

```bash
# Retrieve a list of orders
curl -X POST https://api.example.com/orders

# Retrieve order 123
curl -X POST https://api.example.com/orders/123
```

Note how the API is starting to use URIs to represent resources, but the use of POST for retrieval is not ideal.

### Level 2: HTTP verbs

At this level, RESTful APIs progress by using HTTP methods (like GET, POST, PUT, and DELETE) to perform operations on resources. Level 2 APIs respect the semantics of these verbs, leveraging the full power of HTTP to perform operations that are predictable and standardized. For example, GET retrieves data, POST creates new resources, PUT updates existing resources, and DELETE removes them.

An example of a Level 2 API might be:

```bash
# Retrieve a list of orders
curl -X GET https://api.example.com/orders

# Retrieve order 123
curl -X GET https://api.example.com/orders/123

# Create a new order
curl -X POST https://api.example.com/orders -d "..."

# Update order 123
curl -X PUT https://api.example.com/orders/123 -d "..."

# Delete order 123
curl -X DELETE https://api.example.com/orders/123
```

### Level 3: Hypermedia controls (HATEOAS)

HATEOAS distinguishes Level 3 APIs from the rest. At Level 3, responses include hypermedia links that offer clients dynamic navigation paths within the API. This allows for discoverability directly embedded in API responses, fostering a dynamic interaction model in which clients can follow links to escalate through states or access related resources.

## Evaluating your API's RESTfulness

To evaluate the RESTfulness of your API, consider the following questions:

1. Level 1: Are resources uniquely identified by URIs?

   For example, `/orders/123` uniquely identifies an order resource.

2. Level 2: Are all URLs resource-oriented, and do they use standard HTTP methods?

   For example, URLs should use GET to retrieve resources, POST to create new resources, PUT to update existing resources, and DELETE to remove resources.

   None of your endpoint URLs should contain verbs or actions. For example, neither `/cancelOrder` nor `/orders/123/cancel` is resource-oriented,.

3. Level 3: Do responses include hypermedia links for dynamic navigation?

   For example, a response might include links to related resources, allowing clients to navigate the API without prior knowledge of its structure.

## The RESTful sweet spot

We believe the RESTful sweet spot lies somewhere between Level 1 and Level 2 of the Richardson Maturity Model. This is where most APIs can find a balance between adhering to RESTful principles and practicality. 

In case it wasn't crystal clear from the previous sections, we think HATEOAS isn't practical or relevant for most APIs. It was a powerful concept when the web was young, and APIs were meant to be consumed by humans.

Here's what we recommend:

1. **Embrace resource-oriented design**: Think in terms of resources rather than actions. Identify the key resources in your API domain and structure your endpoints around them.

   This ensures your API is predictable and intuitive, making it easier for developers to understand and use.

   ✅ Good: Use resource-oriented URLs like `/orders` and `/customers`.

   ```yaml openapi.yaml
   paths:
     /orders: # Resource-oriented
       get:
         summary: Retrieve a list of orders
       post:
         summary: Create a new order
     /orders/{orderId}: # Resource-oriented
       get:
         summary: Retrieve order details
       patch:
         summary: Update an order
       put:
         summary: Replace an order
       delete:
         summary: Delete an order
   ```

   ❌ Bad: Don't use action-based URLs like `/cancelOrder`.

   ```yaml openapi.yaml
   paths:
     /cancelOrder: # Not resource-oriented
       post:
         summary: Cancel an order
   ```

   ✅ Compromise: Use sub-resources like `/orders/{orderId}/cancellations`.

   If you must include actions in your URLs, consider using sub-resources to represent them as resources in their own right.

   ```yaml openapi.yaml
   paths:
     /orders/{orderId}/cancellations: # Resource-oriented
       post:
         summary: Create a cancellation for an order
   ```

   ✅ Less ideal compromise: Use top-level actions like `/orders/{orderId}/cancel`.

   ```yaml openapi.yaml
   paths:
     /orders/{orderId}/cancel: # Resource-oriented with action
       post:
         summary: Cancel an order
   ```

2. **Use standard HTTP methods wisely**: Choose the appropriate method for each operation - GET for retrieval, POST for creation, PATCH for partial updates, PUT for complete updates or replacement, and DELETE for removal. Ensure your API follows the semantics of these methods.

   This allows developers to predict how operations will behave based on the HTTP method. It also implies idempotency, safety, and cacheability where applicable.

   An operation is considered **safe** if it doesn't modify resources. It is **idempotent** if the result of performing it multiple times is the same as performing it once. It is **cacheable** if the response can be stored and reused.

   ```yaml openapi.yaml
   paths:
     /orders:
       get: # Safe, idempotent, cacheable
         summary: Retrieve a list of orders
       post: # Unsafe, potentially idempotent, not cacheable
         summary: Create a new order
     /orders/{orderId}:
       get: # safe, idempotent, cacheable
         summary: Retrieve order details
       patch: # unsafe, potentially idempotent, not cacheable
         summary: Update an order
       put: # unsafe, idempotent, not cacheable
         summary: Replace an order
       delete: # unsafe, idempotent, not cacheable
         summary: Delete an order
   ```

3. **Document thoroughly with OpenAPI**: Instead of relying on HATEOAS for dynamic navigation, use OpenAPI to provide comprehensive documentation for your API. OpenAPI allows you to define your API's structure, endpoints, methods, parameters, and responses in a machine-readable format. This ensures clarity and type safety for developers using your API.

### How targeting SDK generation enables better API design

While you're designing your API, consider how it will be consumed by developers. If you're providing an SDK or client library, you can optimize your API design to make SDK generation easier and more effective, and you may find the optimized design also leads to a more RESTful API.

We often see APIs with action-based URLs like `/orders/{orderId}/cancel` or `/orders/{orderId}/refund`. While partially resource-oriented, these URLs include actions as part of the URL.

Firstly, these URLs are not as maintainable as resource-oriented URLs. If you decide to allow multiple cancellations for an order - for example, when an order is restored after being canceled and then canceled again - you may wish to represent cancellations as resources in their own right. This would lead to URLs like `/orders/{orderId}/cancellations/{cancellationId}`. Alternatively, you may wish to allow partial refunds, leading to URLs like `/orders/{orderId}/refunds/{refundId}`.

Secondly, these URLs are not as predictable as resource-oriented URLs. Developers may not know which actions are available for a given resource, leading to a reliance on documentation or trial and error.

From a design perspective, this could look like the following:

```yaml openapi.yaml
paths:
  /orders/{orderId}/cancellations:
    post:
      summary: Set the order status to cancelled
  /orders/{orderId}/refunds:
    post:
      summary: Create a refund for the order
      requestBody:
        content:
          application/json:
            schema:
              type: object
              properties:
                amount:
                  type: number
                  minimum: 0
                  maximum: 100
```

Then, in a future version of your API, you could introduce cancellations and refunds as resources in their own right:

```yaml openapi.yaml
paths:
  /orders/{orderId}/cancellations:
    get:
      summary: Retrieve a list of cancellations for the order
    post:
      summary: Create a new cancellation for the order
  /orders/{orderId}/cancellations/{cancellationId}:
    get:
      summary: Retrieve a specific cancellation for the order
  /orders/{orderId}/refunds:
    get:
      summary: Retrieve a list of refunds for the order
    post:
      summary: Create a new refund for the order
  /orders/{orderId}/refunds/{refundId}:
    get:
      summary: Retrieve a specific refund for the order
```

This approach allows you to evolve your API over time without breaking existing clients.

## Going beyond RESTful principles

While adhering to RESTful principles is essential, it's also important to consider the practicalities of API design. Here are some detailed topics we'll explore in future articles:

1. [**Pagination**](/api-design/pagination): How to handle large collections of resources. Should you use offset-based pagination, cursor-based pagination, or something else?
2. [**Filtering and searching**](/api-design/filtering-responses): How to allow clients to filter and search resources efficiently.
3. [**Error handling**](/api-design/errors): How to communicate errors effectively and consistently.
4. **Versioning**: How to version your API while maintaining backward compatibility.
5. **Security**: How to secure your API using authentication and authorization mechanisms.
6. **Rate limiting**: How to protect your API from abuse by limiting the number of requests clients can make.
7. **Webhooks**: How to implement webhooks for real-time notifications.

Be sure to check back for more insights on API design.


 This is the content for the doc blog/api-experts-akshat-agrawal.mdx 

 ---
title: "API Experts - APIs That Build APIs"
description: "Akshat Agrawal, API product manager, discusses how to PM an API and how to reduce the 'time to wow' of your API."
keywords: [api, openapi, swagger, akshat agrawal, skyflow, security, compliance, privacy tech, developer experience, devex, dx, sdk generation, sdk]
image: "/media/api-experts-akshat-agrawal.png"
date: 2022-09-15
authors:
  - name: Nolan Sullivan
  - image_url: 'https://uploads-ssl.webflow.com/62ccd7b208cab0723d026273/62cdf9e45dcbb4d20be59f5f_head.jpeg'
tags:
  - API Advice
featured_image: "/media/api-experts-akshat-agrawal.png"
---

### TL;DR

- Spend time thinking about your API taxonomy. Talk to users to make sure the language you use matches with how they understand your product.
- Sometimes you need to build endpoints that deviate from the long-term vision of your API to deliver value to clients. That’s okay, just always have a plan to bring things back into alignment down the road.
- Even if you’re building an API product, some tasks are more easily solved with a UI, be strategic about what you ask user’s to do via API and know where a UI is important.
- For a good DevEx, relentlessly focus on minimizing your time to ‘wow’.
- If you’re PM’ing an API product, you need to build with your API to uncover the points of friction.

## Introduction

_Akshat Agrawal, is an MBA candidate at Harvard Business School. Prior to pursuing an MBA, Akshat worked as a senior product manager at_ [_Skyflow_](https://www.skyflow.com/)_. Skyflow is a data vault accessible via an API interface. Akshat was an early product hire at the company and was tasked with building and refining the MVP of Skyflow’s API interface._ _Prior to joining Skyflow, Akshat worked as a PM for Google Stadia, Google’s next generation cloud gaming platform._

**_Can you let people know what Skyflow does?_**

Of Course. So, Skyflow is a Data Vault delivered as an API. There's a lot packed in that sentence, so let me break it down a little bit. First of all, what is a Data Vault? This is an emerging category of data infrastructure. Instead of sticking your sensitive and non-sensitive  data into the same database, which is traditionally how companies have been operating, the emerging paradigm is to create a separate construct called a Data Vault, specifically designed for you to store and compute sensitive data. Sensitive data includes things like PII and KYC (know your customer data), basically anything you wouldn't want breached.

Skyflow provides data vaults that have all the bells and whistles you’d want: encryption, key rotation, data governance, data redaction, field masking, all of that is baked in. It is a totally managed service that we deploy within our cloud for most of our customers. Then the way that developers interact with the data stored in the vault is through an API. So at Skyflow the API is a big part of the product, in some sense it is the product. The API is used for the entire lifecycle of interaction with your data vault, from creating the data vault, to specifying the schema to actually reading, writing, deleting data from the vault, as well as computing on that data, sharing that data, configuring governance rules. It's all meant to be done via API.

**_What does API development look like at Skyflow? Who is responsible for releasing APIs publicly?_**

Yeah, that's a good question. Well as you might expect, as a startup the API development process isn't perfect. When I was at Skyflow, we were definitely still figuring it out. But in general, there are a couple of key steps. First is designing the taxonomy (structure) of the API. This is a bit of a nuance to Skyflow’s business, but because we are a data platform, we actually don't have a fixed schema. It's up to the customer to define what their schema looks like. You know, how they want to arrange their tables and columns. And that makes it very different from your typical REST-based API. We had to design an API that was generic enough to be able to serve whatever data schema our customers designed. And so this really exacerbates the taxonomy problem. We had to make sure that we were really thoughtful with the terms we used to describe our resources. We had to make sure that the structure of the API made intuitive sense and that whenever we add a new endpoint it’s a natural extension of the existing taxonomy.  

So step 1 was getting the right structure for the endpoints and parameters. Then step 2 would be the actual development, including testing and telemetry for the API. Then step 3 would be rollout. Depending on the nature of the API, we might offer it as a beta; and test with certain customers. We’d assess whether there were any back-compat issues that needed to be accounted for. Then last step, we would prepare the documentation. That is super important.  We were rigurious with making sure that the documentation is up to date. There’s nothing worse than stale documentation. And that, roughly, is the full scope of the API development process.

**_How does Skyflow ensure that publicly released APIs are consistent?_**

It starts with establishing a literal rulebook for API development, and getting the whole team to buy into using it. We created guidelines which contained rules about how APIs are named, how parameters are named, standard semantics, expected functionality, all that kind of stuff. Ironing out those rules enables developers building new endpoints to get it mostly right on the first go. That’s really important for development velocity.

Building the rulebook isn’t a one-time activity, our API best practices document was ever-evolving. As time has gone on, we’ve gotten to something pretty prescriptive. So now, if you want to add a new endpoint, you should be able to get it pretty close to perfect just by adhering to the things in the document.  And that rulebook is actively maintained by our API excellence committee.

**_If I were to ask a developer building public APIs at Skyflow what their biggest challenge was, what do you think they would say?_**

Well like I said. I think how you describe your API resources is important.  And one specific challenge for Skyflow was maintaining intelligibility across clients and user personas. As an example, some users might call it consistency, while other user’s called it quorum, and still other people might call it something else. It can be really challenging for them to understand the product when it’s presented in unfamiliar terms. That challenge is not technical. It's more organizational and logistical, and it’s especially hard when you're in startup mode. You've got tight deadlines and customers asking for endpoints that need to be shipped quickly. So really balancing the cleanliness and excellence of the API against time constraints and organizational constraints is really hard. And it’s all compounded by the fact that your APIs can't really change easily once you launch them.

**_What about the challenges facing the developers who consume Skyflow’s APIs?_**

We are a security and privacy product and there’s some problems that can create for the developer experience. As an example, a lot of APIs can afford giving users a static key, but for Skyflow that's not the case. We have to take extra steps to make sure interactions with the API are safe.

We use a jwt token, which you have to dynamically generate and that jwt token contains all the scopes and permissions that define what data you can interact with.The whole process of generating that token, and getting authenticated to the API is non trivial.  You have to get a credentials file with a private key, then run a script on it to generate a token, then you include that token in your API requests. Asking users to perform all those steps creates friction. We saw we had a lot of drop off along the usage path, especially for developers who were just trying the API for the first time.

To address that issue, we built a trial environment into our dev portal.  We auto-generate a personal access token that users can use to experiment with the API. But in production, we want to stick with that really robust, secure mechanism.

## API architecture Decisions

**_Skyflow’s public APIs are RESTful, Can you talk about why you decided to offer Restful APIs over say, GraphQL?_**

I think for our use case, specifically, GraphQL is actually a good option, we are trying to appeal to developers at other tech companies. But ultimately it’s still a bit ahead of the market. I think GraphQL is really cool, but you know, compared to REST, it’s not as easy to understand or as commonly known by developers. So REST still felt like a natural starting point. GraphQL could always be added in the future.

**_If someone was designing their API architecture today, what advice would you give them?_**

Yeah, totally. I think API security is something everyone should spend more time on.  APIs are the attack vector for a lot of the data breaches which are happening today. It's really hard to secure the entire surface of your API because unlike traditional services, which are running in a confined environment, APIs try to be universally accessible. I wish I had some more concrete advice, but if you’re a startup, spend time discussing it as a team.

## PM’ing APIs

**_What’s it like being a product manager working on an API product?_**

I do think, relative to other PM roles, you need to be more technical. That being said, it shouldn't be a barrier for most people. If you’re at the point where you can make an API request, then you can probably develop and grow into the role. So I definitely would tell people to not let the fear of not being an engineer discourage you.

Like any good PM, you should be a consumer of your own product. And for an API product, that means you need to use your API. That's the real way that you figure out where the friction points are. And when I say use, I mean really build with your product.  Of course, you can get out Postman, get an API token and make an API call. But when you actually go to build something, you start to discover all these little thorns. I built with our API from day one.I had little side projects. In the case of Skyflow, that helped me identify that the definition of the schema was a pain. It was quite difficult to do via API. So we actually built a web UI that could do the schema definition. So, yeah, the TLDR is you have to build stuff with your API.

And of course not specific to an API per say, but at the end of the day, making your early customers and partners successful is the most important thing, so let that guide you. Oftentimes, we would have to make hard trade-offs, keeping the shape of the API completely standard vs. giving a client specific functionality they needed. If you’re PM’ing an API, your challenge will lie in eventually bringing everything back into a state of alignment. You're managing an ever expanding body of endpoints and functionality and so you really need to be thinking about the long-term. How will we hurtle the cattle and bring the endpoints back into a clean shape as a cohesive product?

**_What were the KPIs that you tracked against for your product area?_**

I focused a lot on developer experience. The most important metric that I tracked was our user's average time to ‘wow’. For a lot of API products, ‘wow’ will be the first successful API request. The time from when you click ‘get started’ to when you make that first successful API request, we put a lot of effort into trimming that time down. And it can’t just be the sum of every step of the process: getting your credentials to the account, setting up your data vault, authenticating a token, creating a well formed API request, sending it debugging. You also need to account for the time where your user is stuck or inactive. They don't see anything in the documentation, so they give up and come back to it in a day. Because the documentation is part of your product. Reaching out to support and waiting for support to get back to me, that counts against time to wow.

Through a combination of working on authentication, onboarding, documentation, API design, we were actually able to get that down to minutes. For developers, short time to ‘wow’ inspires confidence. And it has a sort of dopamine effect. We feel good when we get that 200 after sending the API request. I don't know about you, but anytime I start to use a new API. I have this sense of foreboding. I’m just waiting to run into an error or stale docs or something like that. And when it just works the first time, it's an amazing feeling.

## _DevEx for APIs_

**_What do you think constitutes a good developer experience?_**

There's a lot of things that go into creating a good developer experience, but I would say that at the end of the day it boils down to productivity. A good developer experience is when developers can be productive. This is not just for APIs, this is for all dev tools. It's all about productivity. A lot of studies show with the proliferation of SaaS tools, Cloud Tools, microservices, new architectures, developer productivity has kind of hit rock bottom. There’s just so much to account for. The amount of hours that developers spend doing random stuff besides just writing and testing good code is way off the mark. The proliferation of APIs should have big benefits in the long term, but currently developers are losing a lot of time understanding partner APIs, looking for documentation, debugging, dealing with authentication.

So when it comes to APIs, a good developer experience is one that makes developers maximally productive when developing atop your API. Unlike most products, with an API you want your users spending as little time as possible with your API.  It's not their job to spend a lot of time on your API. They're just using your API to get something done. So you really want them kind of in and out the door, so to speak.

## Closing

**_A closing question we like to ask everyone: any new technologies or tools that you’re particularly excited by? Doesn’t have to be API related._**

That's a good question. And I think a big part of being at grad school is my desire to explore that fully. I've been really deeply in the world of security, privacy, data and fraud for the last few years. I'm excited to see what else is out there. One thing that's really interesting to me right now is climate tech. I think there's just so much scope for software to make an impact in mitigating climate change and so I'm really excited to explore that space more.


 This is the content for the doc blog/api-experts-clarence-chio.mdx 

 ---
title: "API Experts - APIs to Fight Fraud"
description: "Clarence Chio, the CTO of Unit21, discusses how the company expanded their product from a pure web app to include a very popular API interface."
keywords: [api, openapi, swagger, clarence chio, unit21, fintech, banking, fraud, developer experience, devex, dx, sdk generation, sdk]
image: "/media/api-experts-clarence-chio.png"
date: 2022-09-20
authors:
  - name: Nolan Sullivan
  - image_url: 'https://uploads-ssl.webflow.com/62ccd7b208cab0723d026273/62cdf9e45dcbb4d20be59f5f_head.jpeg'
tags:
  - API Advice
  
featured_image: "/media/api-experts-clarence-chio.png"
---

### TL;DR

- Tech writing teams are often papering over the gaps created by immature API development processes.
- As businesses grow, the complexity of managing even simple API changes grows exponentially.
- Designing an API is no different from building any product. The question of what framework you use should be dictated by the requirements of your users.
- Don’t build an API just to have one. Build it when you have customer use cases where an API is best suited to accomplishing the user’s goal.
- Good devex is when your services map closely to the intention of the majority of your users.
- The mark of good devEx is when you don't have to rely on documentation to achieve most of what you're trying to do.

## Introduction

[_Clarence Chio_](https://www.linkedin.com/in/cchio/)_, is the CTO and one of the co-founders of Unit21._ [_Unit21_](https://www.unit21.ai/) _is a no-code platform that helps companies fight transaction fraud. Since the company started in 2018 it has monitored over $250 billion worth of transactions, and been responsible for preventing over $1B worth of fraud and money laundering._ _In addition to his work on Unit21, Clarence is a Machine Learning lecturer at UC Berkeley and the author of_ [_“Machine Learning & Security”_](https://www.oreilly.com/library/view/machine-learning-and/9781491979891/)

## API Development @ Unit21

**_What does API development look like at Unit21? Who is responsible for releasing APIs publicly?_**

API development is a distributed responsibility across the different product teams. Product teams build customer-facing features which take the form of dashboards in the web interface, API endpoints, or both. So generally, every product team maintains their own sets of API endpoints defined by the scope of the product vertical that they're working on.

But the people that make the decisions defining best practices and the consistency of how our APIs are designed is typically the tech leads working on our data ingestion team.  As for who maintains the consistency of how APIs are documented and presented to our customers, that is our technical writing team.

**_How come the data ingestion team owns API architecture is that just a quirk of Unit21 engineering? Is there any resulting friction for API development in other parts of the engineering organization?_**

Yeah, the reason for this is pretty circumstantial. Most of the API usage that customers engage with are the APIs owned by our data ingestion team. We’re a startup and we don’t want too much process overhead, therefore we just let the team that owns the APIs with the most engagement, maintain the consistency and define what the API experience should be.

As for friction with other parts of the org, it's largely been okay. I think the places of friction aren’t specifically related to having designated a specific product team to be the owner. A lot of the friction we’ve had was down to lack of communication or immature processes.

A common example is when the conventions for specific access patterns, or query parameter definitions aren’t known across the org. And if the review process doesn't catch that, then friction for the user happens. And then we have to go back and clean things up. And we have to handle changing customer behavior, which is never fun. However, it's fairly rare and after a few incidents of this happening, we’ve started to nail down the process..

**_What is Unit21’s process to ensure that publicly released APIs are consistent?_**

There is a strenuous review process for any customer facing change, whether it's on the APIs or the dashboards in the web app. Our customers rely on us to help them detect and manage fraud so our product has to be consistent and reliable.

The API review process has a couple of different layers. First we go through a technical or architectural review depending on how big the changes; this happens before any work is done to change the API definitions.. The second review is a standard PR review process after the feature or change has been developed. Then there’s a release and client communication process that's handled by the assigned product manager and our technical writing team. They work with the customer success team to make sure that every customer is ready if there’s a breaking change.

**_If I were to ask a developer building public APIs at Unit21 what their biggest challenge was, what do you think they would say?_**

It's probably the breadth of coverage that is growing over time. Because of the variance in the types of things that our customers are doing through our API and all the other systems and ecosystems that our customers operate in, every time we add a new API the interactions between that API and all the other systems can increase exponentially.

So now the number of things that will be affected if, for example, we added a new field in the data ingestion API is dizzying. A new field would affect anything that involves pulling this object type. Customers expect to be able to pull it from a web hook from an export, from a management interface, from any kind of QA interface, they want to filter by it, and be able to search by it. All those things should be doable. And so the changing of APIs that customers interact with frequently cause exponentially increasing complexity for our developers.

**_What are some of the goals that you have for Unit21’s API teams?_**

There's a couple of things that we really want to get better at. And by this, I don’t mean a gradual improvement on our current trajectory, but a transformational change. Because the way we have been doing certain things hasn't been working as well as I’d like.  The first is the consistency of documentation.

When we first started building our API's out, we looked at all the different types of spec frameworks, whether it was Swagger or OpenAPI, and we realized that the level of complexity that would be required if we wanted to automate API doc generation support would be too much ongoing effort to be worthwhile. It was a very clear answer. But as we continue to increase the scope of what we need to document and keep consistent, we realized that now the answer is not so clear.

Right now this issue is being covered over by our technical writing team working very, very closely with developers. And the only reason this work is because our tech writer is super overqualified. She's really a rock star that could be a developer if she wanted to. And we need her to be that good because we don't have a central standardized API definition interface; everything is still defined as flask routes in a Python application. She troubleshoots and checks for consistency at the time of documentation because that’s where you can never hide any kind of inconsistency.

But this isn’t the long term solution, we want to free up our tech writers for differentiated work and fix this problem at the root.  We’re still looking into how to do this. We’re not completely sold on Swagger or OpenAPI, but if there are other types of interfaces for us to standardize our API definition process through, then potentially, we could find a good balance between achieving consistency in how our APIs are defined & documented and the efforts required from our engineering team.  But yeah, the biggest goal is for more documentation consistency.

## API architecture Decisions

**_When did you begin offering APIs to your clients, and how did you know it was the right time?_**

When we first started, we did not offer public APIs. We first started, when we realized that a lot of our customers were evolving use cases that needed a different mode of response from our systems. Originally, we would only be able to tell them that this transaction is potentially fraudulent at the time of their CSV, or JSON file being uploaded into our web UI, and by then the transaction would have been processed already. In many use cases this was okay, but then increasingly, many of our customers wanted to use us for real time use cases.  

We developed our first set of APIs so that we could give the customer near real time feedback on their transactions, so that they could then act on the bad event and block the user, or block the transaction, etc. That was the biggest use case that pushed us towards the public API road. Of course, there's also a bunch of other problems with processing batch files. Files are brittle, files can change, validation is always a friction point. And the cost of IO for large files is a big performance consideration.

Now we’re at the point where more than 90% of our customers use our public APIs. But a lot of our customers are a hybrid; meaning they are not exclusively using APIs. Customers that use APIs also upload files to supplement with more information. And we also have customers that are using our APIs to upload batch files; that's a pretty common thing for people to do if they don't need real time feedback.

**_Have you achieved, and do you maintain parity between your web app and your API suite?_**

We don't. We actually maintain a separate set of APIs for our private interfaces and our public interface. Many of them call the same underlying back end logic. But for cleanliness, for security, and for just a logical separation, we maintain them separately, so there is no parody between them in a technical sense.

**_That’s a non-standard architecture-choice, would you recommend this approach to others?_**

I think it really depends on the kind of application that you're building. If I were building something where people were equally likely to interact through the web as through the API, then I think I would definitely recommend not choosing this divergence.  

Ultimately, what I would recommend heavily depends on security requirements. At Unit21 we very deliberately separate the interfaces, the routes, the paths between what is data ingestion versus what is data exfiltration. That gives us a much better logical separation of what kinds of API routes we want to put into a private versus public subnet, and what exists and just fundamentally does not exist as a route in a more theoretically exposed environment. So ultimately, it's quite circumstantial.

For us, I would make the same decision today to keep things separate. Unless there existed a radically different type of approach to API security. I mentioned earlier there were a couple of things that we would like to do differently. One of them is something along this route. We are starting to adopt API gateways and using tools like Kong to to give us better control over API access infrastructure, and rate limiting. So it’s something that we're exploring doing quite differently.

**_Unit21’s public APIs are RESTful, Can you talk about why you decided to offer Restful APIs over say, GraphQL?_**

I think that designing an API is very similar to building any other product that's customer facing, right? You just need to talk to users. Ask yourself what would minimize the friction between using you versus a competitor for example. You should always aim to build something that is useful and usable to customers. For Unit21 specifically, the decision to choose REST was shaped by our early customers, many of whom were the initial design partners for the API. We picked REST because it allowed us to fulfill all of what the customers needed, and gave them a friendly interface to interact with.

I've been in companies before where GraphQL was the design scheme for the public facing APIs. And in those cases the main consumer persona of the APIs were already somewhat acclimatized to querying through GraphQL. Asking people that haven't used GraphQL to start consuming a GraphQL API is a pretty big shift. It's a steep learning curve, so you need to be really thoughtful if you’re considering that.

**_Also, you’ve recently released webhooks in beta, what was the impetus for offering webhooks, and has the customer response been positive?_**

That's right. Actually, we’ve had webhooks around for a while, but they hadn't always been consistent with our API endpoints. We recently revamped the whole thing to make everything consistent, and that’s why it’s termed as being ‘beta’. Consistency was important to achieve because, at the end of the day, it's the same customer teams that are dealing with webhooks as with the push/pull APIs. We wanted to make sure the developer experience was consistent.  And since we made the shift to consistency, the reaction has been great, customers were very happy with the change.

## Developer Experience

**_What do you think constitutes a good developer experience?_**

Oof this is a broad question, but a good one. All of us have struggled with API Docs before; struggled with trying to relate the concept of what you're trying to do with what the API allows you to do. Of course, there are some really good examples of how documentation can be a great assist between what is intuitive and unintuitive. But I think that a really good developer experience is when the set of APIs maps closely to the intention of the majority of the users using the API, so that you don't have to rely on documentation to achieve most of what you're trying to do.

There are some APIs like this that I've worked with before that have tremendously intuitive interfaces.  In those cases, you really only need to look at documentation for exceptions or to check that what you're doing is seen. And I think those APIs are clearly the result of developers with a good understanding of not only the problem you're trying to solve, but also the type of developers who will be using the API.

## Closing

**_A closing question we like to ask everyone: any new technologies or tools that you’re particularly excited by? Doesn’t have to be API related._**

Yeah, I think there's a bunch of really interesting developments within the datastream space.  This is very near and dear to what we're doing at Unit21. A lot of the value of our company is undergirded by the quantity and quality of the data we can ingest from customers.

We're currently going through a data architecture, implementing the next generation of what data storage and access looks like in our systems, and there's a set of interesting concepts around what is a datastream versus what is a database. And I think we first started seeing this become a common concept with K sequel, in confluent, Kafka tables etc. But now with concepts like rocks set with, snowflake and databricks all releasing products that allow you to think of data flowing into your system as both a stream and a data set. I think this duality allows for much more flexibility. It’s a very powerful concept, because you no longer have to think of data as flowing into one place as either, but it could be both supporting multiple different types of use cases without sacrificing too much of performance or storage.


 This is the content for the doc blog/api-experts-jack-reed.mdx 

 ---
title: "API Experts - APIs that Move Money"
description: "Jack Reed, software engineer at Increase, discusses how the company has built out APIs that helps people build banks."
keywords: [api, openapi, swagger, jack reed, increase, fintech, banking, developer experience, devex, dx, sdk generation, sdk]
image: "/media/api-experts-jack-reed.png"
date: 2023-01-04
authors:
  - name: Nolan Sullivan
  - image_url: 'https://uploads-ssl.webflow.com/62ccd7b208cab0723d026273/62cdf9e45dcbb4d20be59f5f_head.jpeg'
tags:
  - API Advice
  
featured_image: "/media/api-experts-jack-reed.png"
---
## TL;DR

- It’s great to have an industry standard like OpenAPI for API development, but the flexibility in the spec has made true consensus elusive.
- If you’re building an SDK, the goal is to make it as easy as possible for users to make their first request.
- When you’re building in a regulated space, it’s important to offer a sandbox to help customers build quickly and safely.
- At Stripe, maintaining the [API platform](/post/why-an-api-platform-is-important/) required a large team. In the last couple years this API DevEx space has started to take off and democratize API product quality. It’s a welcome development for people who care about this type of stuff.

## Introduction

_Jack Flintermann Reed is an engineer at [Increase](https://increase.com/), a company that provides an API which enables developers to build a bank. Jack spends his time thinking about how to make the [Increase API](https://increase.com/documentation/api#api-reference) enjoyable for customers to use, and scalable for the Increase team to develop. Before he joined Increase, Jack was a staff engineer at Stripe._

## APIs at Increase

**Increase offers a REST API to developers, how did you decide that was the right interface?**

At one point we tried offering both a REST API and a GraphQL API but we found operating the GraphQL API to be challenging and ended up winding it down. There was a cognitive overhead for the user that was hard to overcome: like, welcome to our GraphQL API, here are all the libraries you're gonna have to install before you get started. And you know, GraphQL libraries across different programming languages have really varying quality. The Ruby GraphQL client is okay for example, but other languages not so much. And then, client aside, you need to learn all these new concepts before you can even do what you want. For users it’s like, “I just want to make an ACH transfer here.”
And that’s the really nice thing about REST. Every single language has an HTTP client built into it. There is no stack required to get started. It is really simple. You can play with a lot of REST APIs in the browser’s URL bar if you want to. And that makes getting started with documentation and integration a lot simpler. So the barrier to entry is lowest on REST. And, that's not to say it doesn't come with plenty of issues of its own, which I'm sure we will get into. But we think it’s what is right for us right now.
Ultimately, one of the reasons we had to give up on GraphQL is we realized that because of the level of DevEx we wanted to give users, we only had the bandwidth to do one public API really well, and so we were forced to pick. I suppose that is one of the main reasons Speakeasy exists, right?

**Yes it is. And to explicitly state something that I think you're implying, the developer tools that are needed to support a REST API and a Graph QL API, are fairly distinct?**

I think so. And again it’s partially down to the maturity of the technology. For example, when we think about the SDKs that we want to offer to our users, one of the things that we feel pretty strongly about is not having any dependencies. And that's just not possible with a GraphQL API. Like, you're not going to write your own GraphQL client, you're going to bundle something in. But that exposes you to problems where there could be a version conflict with the client you've pinned yourself to.

And with REST, it's at least possible to avoid that problem. We've recently written a Ruby SDK for our API, and we're pretty happy that it’s got no external dependencies.

**Are you versioning your API, do you plan to?**

We don't version the API yet. We are small enough that we just haven't had to do it. We inevitably will have to, but I'm trying to delay it for as long as possible. It's a lot of work, and there's just not a canonical way to do versioning. So I'm cheating by just making it a problem for my 2023 self.
We do occasionally deprecate things, but we're close enough to our users right now that we can just reach out to them. And for us right now, we're in a phase where the API is mostly additive, we're still building out the core resources. The deprecations we’ve done have been at the API method level. It’s easy enough for us to handle. The real nightmare is when you want to take out this field from this API response. And you have no idea if anyone is relying on it or not.

That's the one that sucks. And fortunately, we haven't had to do that. And we are trying really hard to not have to do that. A good way to save yourself trouble is by being really conservative about what you put in your API to begin with.

That's our approach right now, we want users to pull features out of the API. Yes we have the data, we obviously could expose that field, but until a few people are asking us for it, we are not going to put it into the API.

## Thoughts On OpenAPI

**Do you like OpenAPI? Does your team maintain an OpenAPI spec?**

I'm glad it exists, we publish an open API spec. And it is going to be the foundation of all of the stuff that you and I are talking about right now. We’re going to generate our documentation and clients from our OpenAPI spec. That said, I think it's extremely difficult to work with. So, I'm glad that there is a standard, but I wish the standard were better.

I think OpenAPI has taken this nice big-tent approach where anyone can describe their API with OpenAPI. But there are some crazy APIs out there, right? And so there are a million features inside OpenAPI.

I’ve been working in the API space for a while and it took me some pretty serious effort to try and understand OpenAPI and how to get started. There are a lot of features you could use, but there’s no easy way to separate out the set of features that you should use.

One example that I always harp on is null. If I have a nullable parameter, there's at least four ways to represent that in OpenAPI 3.1. But not every library implements the full OpenAPI specification, so the tools and libraries that I want to have consume my spec might only support a certain way to represent null. So while it's all well and good that you can represent null 4 different ways, if you actually use two of them, none of your tooling will work. And that type of opinionated information is extremely hard to pin down.

**Do you generate your OpenAPI spec from code?**

Yeah, we have this cool library we use internally, I’m pretty proud of it. If I had infinite time, I think there's probably a great little framework that could be pulled out of this. 
Increase is written in Ruby, and we use [Sorbet](https://sorbet.org/) from Stripe (a type checker for Ruby). We’ve built a Domain-Specific Language, you might've seen other companies do something similar, where you can write API methods using a declarative syntax. You say, this API takes a parameter called, “name”, and it's a string, and this one takes “age”, it's an integer. And this library then goes and produces a couple of outputs. On the one hand, it gives you an OpenAPI spec. Then on the other, it handles all the shared application concerns around parsing requests: error messages, type suggestions, etc. Everything you don't want to force individual developers at Increase to be thinking about. It will spit out into the application, a parsed, strongly-typed, parameters object.
And so, the developer experience is pretty nice for folks at Increase. If you add a parameter, it just shows up in the docs and the SDKs without you having to do anything, which is the dream. It’s an all in one generator for artifacts.

## How Does Increase Think About DevEx

**You mentioned earlier that one of the guiding principles in your SDK generator development was limiting dependencies. What other principles do you have for SDK development?**

We want to make it very easy to write your first request. And to achieve that, the majority of the library should be type definitions. It should list out the API methods and each of those should have a nice type definition that makes it easy to autocomplete when you’re working. Then there's the other piece of the SDK, sort of the core, which actually handles making the requests. That should be very tunable, and ultimately, swappable.

I worked at Stripe before coming to Increase. And at Stripe, when we were integrating with an external service, we’d rarely use the official SDK, because of all the things, like internal service proxies, that we would need to configure in order to safely get requests out of the stripe infrastructure. It would have been really nice to say, we have our own way of making HTTP requests, and I'm happy to write adapter code to conform to your interface; I'll just kind of ram it into your type definition. That would have been the sweet spot for us, and that experience has influenced our approach at Increase. We have written it to be the kind of SDK we would have wanted to integrate with.

If people are interested in this stuff, there's [a really fantastic blog](https://brandur.org/articles) by a developer I used to work with at Stripe, Brandur. He’s a prolific writer and often dives deep on the minutiae of good API design. If people haven't read it, they should.

**What about DevEx for APIs? What’s most important?**

There's a lot of different things that go into it. The first piece is documentation, trying to make your system legible to others. Good documentation focuses on the concepts you need to know, without overwhelming you with information.

I think at Increase, we do an okay job of this right now, but it’s one of the things I most want to improve about our own product. We’ve got the API reference, which is great - it's the index at the back of the encyclopedia, but it's not enough. It’s really important to know the typical path for building an integration with your API and then communicate: “here are the five things you're going to want to go and touch first.” I think that initial communication is more important than almost anything else to me when it comes to the experience of using an API.
And again, I'm a major type system enthusiast. And that’s because when you get it right with your developer tooling, your documentation can just flow into the developer’s text editor. And to me, that's the dream experience. But it takes a lot of work to get there.

That’s all concerning understanding the API, and doing the initial integration. There’s also the ongoing operation of the integration code. And that’s about answering questions like: How do I see what I've done? Did I make a mistake? How do I debug my mistake?  That's where tools that enable you to see the requests you've made are really useful.

It’s hard to say what specifically constitutes a great developer experience, but a lot goes into it, and, fortunately for developers, the bar for what great means gets higher every year. Tools are getting better.

**Are there other companies that you look to as a north star when building DevEx?**

So, obviously Stripe gets a lot of praise for being the first company here. They were so much better than anything else at the time they started. And I think if you look back at the things that they did, a lot of them were really small touches. Things like copy/paste for code examples, right? Small, but really nice. Another one was, if you misspell an API parameter, giving you an error message that suggests the correct spelling. It's not rocket science. But those little things add up into something really nice.  I'm obviously really biased because I worked there, but I still think Stripe is the best. I learned a lot from my time there, so it’s still the company I model after most. 
Besides Stripe, I wouldn’t say there’s one company that is necessarily a North Star. I have a loose list of peer companies. When I'm doing research, it’s usually because I’m grappling with the fact there’s a lot of under-specified things in building REST APIs and I want to see how others have handled it before I make a decision. I’m not interested in features or clever things that they’ve done that I want to copy, it’s more about checking whether there is consensus on a topic. If there is a consensus, I want to follow the precedent so that it is not surprising to our users. However, I'm usually disappointed. There often isn’t consensus on the way to do basic features in REST APIs. Which is funny and sad.

Incidentally, that's one of the nice things about GraphQL. They tell you how to do everything. It’s very proscriptive.

**How is the value of Increase’s investment in DevEx measured? Are there metrics you want to see improve?**

It's not really obvious, it's much more of a qualitative metric. We open a Slack channel for every new user, and we stay pretty close to them during the integration. We're not quite looking over their shoulder, but if we could, we would. And so, we're pretty sensitive to how that kind of first experience goes. We try to get feedback from pretty much everybody who goes through it. And so, it’s just things that we see mainly. Like if everyone is running into a similar stumbling block, we prioritize removing it. It's not like there's a KPIs dashboard on a wall. It’s things we see in conversations with users every day. It scales pretty well if the whole team pitches in on working with users. Slack Connect is a pretty great tool.

## Increase’s Journey

**You guys are a startup, but you’ve been investing in your API’s DevEx from the get go. Was that a conscious decision?**

Yeah, again, It's pretty informed by our experiences at Stripe. It’s also a consequence of the space we work in. We offer a set of banking APIs, and traditionally banking API integration is pretty laborious. With a traditional bank, it'll be an extended contracting phase, then you get to a signed contract, and finally you’ll get this PDF for docs. And then the integration involves sending files back and forth between FTP servers. It’s not fun.
And so as a startup in the space, our goal is to make the integration timeline as short as possible, and as dev-friendly as possible. Even in the cases where we need a signed contract before a user can go live in production, we enable their development team to build while that’s being sorted.

**Ya, please expand on that a bit more. As a banking API there’s inevitably compliance. How do you guys balance integration speed with compliance?**

It depends on the use case - we can get most companies live in production very quickly. And then there are some that require more due diligence. That's where tooling like an API sandbox is helpful. With a sandbox, you can build your whole integration. The dashboard experience looks and feels real, and so you can just build out what you need while the legal stuff is handled.

We’ve learned that it takes a lot of work to make a good sandbox. We have to do a lot of weird things to simulate the real world. For example, in the real world there's several windows throughout the day when the federal government processes ACH transfers and they go through. So if a developer makes an ACH transfer in the sandbox, what do we do? Should we simulate that happening immediately, or wait like the real world. There’s not always a right answer. We actually built a simulation API, where you can simulate real world events in all kinds of tunable ways. And so that has been fascinating. It made us re-architect a fair amount of code to get it working.

## Closing

**In the longer term, are there any big changes you think are coming to the way people interact with APIs?**

Haha I think this question is above my paygrade. It's not quite the lens through which I think about things… But, I guess one thing that is interesting is how many companies are starting to pop up in this API DevEx space. It seems like there were zero people working on this stuff two, three years ago. Now there's a few.

Before I joined Increase, I was thinking I might start a company of my own in the space. One of the ideas I was kicking around was a platform for webhook delivery. I've seen a bunch of new startups doing that over the interim 2 years.

I think that’s cool. The size of the team that maintained these things at Stripe was big. It required a lot of manual work. And so it's cool to see that level of API product quality being democratized a little bit. Like I said, I think the quality bar will continue to rise, and it has risen. But, today, it's still a pain. It still takes a lot of work, you really have to care about it. I'm hoping it becomes a little bit easier to buy off the shelf as time goes on.


 This is the content for the doc blog/api-experts-mathias-vagni/index.mdx 

 ---
title: "API Experts - APIs to Support your Customers"
description: "Mathias Vagni, Plain's CTO & Co-founder discusses API-first development and the novel DevEx they've built to support their API."
keywords: [api, graphql, mathias vagni, plain, customer support, react, react embeds, developer experience, devex, dx]
image: "/media/api-experts-mathias-vagni.png"
date: 2023-01-31
authors:
  - name: Nolan Sullivan
  - image_url: 'https://uploads-ssl.webflow.com/62ccd7b208cab0723d026273/62cdf9e45dcbb4d20be59f5f_head.jpeg'
tags:
  - API Advice
  
featured_image: "/media/api-experts-mathias-vagni.png"
---

## TL; DR

- Building your API to be public (without private endpoints) pays huge dividends in the form of extensibility for your customers.
- GraphQL requires some extra legwork to cover the basics, but comes in handy for supporting more advanced UIs and apps.
- The Plain team is not only working on their APIs’ DevEx, but is trying to make it easy for customers to build their own API endpoints.
- For smaller companies, the qualitative feedback on your developer experience is more useful than tracking metrics.

## Introduction to Plain

**To warm up, could you give a brief overview of [Plain](https://plain.com/) and what y’all are building?**

Plain is the customer support tool for developer tools.

My co-founder Simon and I both found that existing customer service platforms were really hard to integrate with and fundamentally not built for engineering led products. Their APIs were afterthoughts tacked on and dumbed down to be made public. Their data models and workflows assumed that they were the primary store of customer data vs your own databases. These assumptions just didn’t make sense, especially in the developer tools vertical.

We wanted to build a customer service platform that is incredibly easy for developers to build with. The inspiration came from our experiences at Deliveroo (food delivery) and Echo, an online pharmacy. All of Plain is built API-first, meaning the API we make available to users is identical to the API we use internally. This means that there are no restrictions with what you can do programmatically. Anything you can do in Plain, you can do via the API. By dog-fooding our API this way, we end up constantly working on making it easier to build with and integrate Plain into your own systems.

## Architecture of the Plain API

**How does being API-first impact product development? Move fast and break things doesn’t work so well for APIs right?**

Yeah, we have virtually no private surface area, which is a challenge since it means that everything we build is exposed. Things that are traditionally quite easy are harder, for example deprecating an endpoint, but the rewards are massive.

You have to move a bit slower at the beginning, especially when you're conceiving a new feature. It forces you to think quite carefully as to where you put logic and where you ‘encode’ your opinions if that makes any sense. For example, [our data model](https://docs.plain.com/data-model) is something that is integral and is set in the API. A less clear cut case is certain opinions around how you should work as someone providing support to users. We do our best to make sure that opinions are more in our UI and the Plain app, and the API remains more generic.

As a result of this, we definitely have more in depth conversation around API design than you would normally see at an early stage startup. The payoff though is huge. When we onboard customers, and our platform is missing certain features, they are able to extend and just build the features themselves.

As an example, we had one customer using Discord to manage their community. We didn't offer a Discord integration. So they built it. It’s super cool, now they’re able to talk to users in Discord and sync it to Plain. That's where you reap the benefits of an API first approach.

**One of the first decisions an API company needs to make is REST or GraphQL, Plain is GraphQL-based. What persuaded you that GraphQL was best?**

We realised early on that most companies want to use customer support APIs to automate only small parts of their workflow. For example when they have an issue in their back-end they might want to proactively reach out to that customer and so they might open a ticket. In these early stages of companies, the requirements for customer support tooling are quite simple so we were very tempted to use REST. For simple API calls REST is typically way easier.

However at the same time we learnt that many people were looking for a productivity focused, power user friendly, support app. This is especially true for engineers as a demographic. Given this, GraphQL seemed like a much better fit. For building complex applications the schema stitching required by REST can be very painful and it was something we were keen to avoid.

Ultimately weighing both of these conflicting requirements we went for GraphQL. We felt like if we start with a GraphQL API, we could always add a REST layer on top later. The reverse would be more difficult to do in a performant way.

**I’ve spoken to some other founders who started with GraphQL, before switching to REST. One of their criticisms was that the ecosystem of GraphQL tooling left a lot to be desired. Yes, What has your experience been?**

There are some things that are great. And then there are some things that you expect to be good, but are terrible. For basic apps, where you just want to make some queries and run some mutations, you're going to have a great time. You make some GraphQL files, generate all of your types. It can even generate clients for you. There's lots of libraries that take care of things like caching and normalisation, definitely in the React ecosystem, but also in others. So that's all fine.

I think, where you start running into GraphQL weirdness and where the ecosystem leaves a lot to be desired is in terms of some more basic elements like error handling and complex input types. With REST APIs a 401 is an unauthorized request, you don’t need to explain that to anyone. And because you are not restricted to a type system you can do things that are just plain awkward in GraphQL (e.g. union input types).

**How do you handle errors in GraphQL then?**

Unlike REST, GraphQL is multileveled so certain problems become harder. Suddenly, you might be in a situation where the user has top level permissions to get something, but then doesn’t have permission for one of the nested elements. The way that you handle that error is DIY. There’s no (good) convention to follow.

We made some good and bad decisions in our early days. What helped was that very early on, we decided to write our own linting rules. GraphQL has an inbuilt tool that essentially parses the GraphQL schema when a request comes in, and with this, you can write rules to lint your schema. We write our schema first, so the linters enforce convention before any API code is actually written. And it’s not just syntactical errors, our linters enforce things like, every mutation must return an error, an error must be of this type, etc. It’s served us really well, because it means that we have very few debates on PRs around repeated API design topics.

**What’s been the client reaction to the GraphQL API?**

It's interesting. I think the more complex the use case, the happier users are with GraphQL. There's obviously still a bit of a gap between GraphQL and REST when it comes to awareness, and we do encounter companies who want to use Plain where the engineers have never worked with GraphQL, beyond reading blog posts. It's definitely a barrier, but not insurmountable; it just requires a little bit more hand holding. We help customers through this by giving them code examples and instructions on how to make GraphQL requests, how our errors work, that kind of thing.

Overall, we’ve found that as long as you’ve put work into developer experience and consistent API design, developers will pick things up quickly. And we are militant about the consistency and experience of our API. As an example, we provide incredibly thorough error messages, which is something that developers love. Once they start building they quickly realise: “Okay, this is solid.”

## Plain’s API DevEx

**That's a good segue. What additional tooling do you give to users to support API integration? What tooling improvements are you looking to make?**

Before we dive in, it's worth knowing that there are two ways you build with Plain. There is the GraphQL API, which we've been talking about, but there’s also something we call [Customer Cards](https://docs.plain.com/adding-context/customer-cards). They are really interesting, because they’re the inverse of the traditional way that other support tools work. Instead of our customers calling us and syncing data (when the support tool is the primary source of truth), our users provide a URL, which we call to fetch *your* customer data which is then loaded up within the Plain UI.

![customer-card image](./assets/customer-card.png)

This means that when your support team is helping someone they instantly have access to context from your own systems about the customer they are trying to help. What account tier they are, what their recent activity has been, how much they're paying you every month, etc.

We want that data to continue to live in our customers systems, so for the product to work, we need to help our customers construct an API endpoint which we can call. We’ve put in quite a bit of work into the DX of Customer Cards but I think our developer experience is a work in progress. It’s a fairly novel workflow, so it’s harder to do well than when trying to document an API.

import portal_url from './assets/customer-card-playground.mp4'

  <video controls={false} loop={true} autoPlay={true} muted={true} width="100%" alt="customer card playground">
    <source src={portal_url} type="video/mp4" />
  </video>

**How have you been trying to solve it so far?**

I think we've made some good steps. We’ve built a playground that can assist users while they’re building which is quite nice, but there's definitely more to do. This data transfer is async. It's happening all the time. And so error handling and the developer experience here is actually a lot more challenging than a traditional API. We have to provide a lot more visibility on errors and monitoring. We need to know if you responded with something wrong, and why it was wrong. We then need to notify you that it was wrong and persist it so that you can fix it. The same goes for timeouts and anything else that’s unexpected. It’s complicated and we’ve not totally solved this experience.

**Do you offer SDKs for the Plain API?**

We haven't yet, but we plan on it. We’ve been relying on every ecosystem having its own stack, for generating GraphQL tooling. But we plan on offering SDKs to make integration easier, and to make errors easier to understand and parse. We really want to get to a place where, for a simple use case, you don’t have to deal with GraphQL at all. If you look at how Slack does it, it’s very good. No one is actually making raw Slack API calls, right? They're all using the client and the playground provided to visually work out how to construct messages and do things with bots and so on.

**Any other DevEx challenges that you’re tackling?**

I think on the API side, we’ve covered it, we really just want to make it easier and easier to integrate and use Plain. It's our raison d’être, I don’t think we’ll ever ‘finish’ working on DevEx

Outside of our API, we also have [a chat solution](https://docs.plain.com/support-channels/chat/overview), and we’ve spent a lot of time thinking about the DevEx there. If you’re using a React app and you want to embed chat into your product, it’s a UI-level integration, and that has its own challenges. If you look at how most support tools or chat providers allow you to embed, it's through a script tag. You add a tag, and a floating button appears on the bottom right. And that's your chat. In our world, we wanted to allow chat to be a bit more embeddable, to essentially look like it's part of your product and deeply look like its native. To do that, we've built a React package.

It’s been a tough nut to crack. Everyone has such specific expectations of how your embed should behave. And you're confronted with the multitude of different stacks and approaches people take. People do things that are super delightful, but unexpected. And that's where the complexity comes in when you are trying to deliver that seamless Developer Experience.

**Are there metrics you track to measure impact of the work on your API’s DevEx?**

Not yet, we're still so focused on every customer that metrics don’t really make sense yet. We track all the feedback we get meticulously. Even slight grievances with our API or our integrations we discuss thoroughly. That's a scale thing, largely.

What's also interesting is, by focusing on developer tools as a customer base, the feedback we get is really, really good. You get feedback similar to when an in-house engineer reports a bug. So. much. detail. So yeah, for us, feedback has generally been very, very specific and high quality.

## What’s the Plan for 2023

**What’re you most excited for in the coming year?** Plain is now in a really cool place where we have moved on from the basics and are now getting really deep into some of the hard problems within customer support. For example, right now we're looking at managing triaging and SLA and complex queue management. It's going to bring with it, a whole host of other API integrations, to enable users to be in control of their support queues and prioritise some customer issues over others, and so on. I really can't wait to share our solution here.

We’re also going to be growing the team ([we’re hiring!](https://plain-public.notion.site/Help-us-power-support-for-the-world-s-best-companies-7ea2f1a4cc084b96a95141a30e136b5b)) and onboard many more customers - it’s going to be an exciting year for Plain!


 This is the content for the doc blog/api-landscape.mdx 

 ---
title: "The Speakeasy API Landscape"
description: "Our thoughts around the day-to-day challenges facing developers on the ground as they build and manage their APIs."
image: "/media/api-landscape.png"
date: 2022-06-30
authors:
  - name: Sagar Batchu
  - image_url: 'https://uploads-ssl.webflow.com/62ccd7b208cab0723d026273/62cdf303b28bf9598d7a6b63_sagar_headshot-p-500.jpeg'
tags:
  - API Advice
  
featured_image: "/media/api-landscape.png"
---

Two weeks ago Postman published their [**API Platform Landscape**](https://blog.postman.com/2022-api-platform-landscape-trends-and-challenges/). They’ve done a great job highlighting some of the organizational challenges faced by companies building APIs.  We at Speakeasy wanted to chip in with our own two cents. Specifically, we wanted to highlight the day-to-day challenges facing developers on the ground when they’re building and managing APIs.

Our thoughts have been shaped after spending a lot of time over the past 6 months talking to developers about their experiences building & managing APIs. To put some numbers behind it, my cofounder Simon and I have spent a combined 70 hours interviewing over 100 developers about their experiences. All of that goes into our work at Speakeasy, and in the spirit of openness, we wanted to share our learnings with everyone else. So, without further ado, here’s what we have learned…

## Trends

### Developers want good UX

We touched on this in an earlier post, but developers are increasingly demanding that the tools they use have a great UX.  Tools should largely abstract away complexity without becoming a black box.  This doesn’t mean just throwing a GUI in front of the terminal. Developers want tools that are embedded in their existing workflows. This may mean that a tool intended for developers needs to have multiple surface areas. Features may exist as a CLI, VS Code extension, Git Action, Web app, React Embeds, API endpoint, etc. DevEx should prioritize helping the user accomplish their task with minimum friction and deviation from their existing workflows, and be flexible on where/how that feature is exposed to users.

### A “Design-first” approach has limits

The “Design-first” approach to APIs is often presented as a virtue, to be contrasted with the dirty sin of a code-first approach (implementing the API without formal design).  Most companies will claim they follow a purely design-first approach, however talking to developers on the ground, we found a much more nuanced reality.  In fact, it’s almost always a mix of the two.  Many teams confessed that they felt writing the whole Open API spec was a tedious exercise for little gain. In their weaker moments they would often forgo the full open API standard in the beginning in order to get started faster, then they would go back and generate it later for the purpose of documentation.

### Different API frameworks for different jobs

GraphQL, gRPC, Websockets, are all hot on the block, meanwhile RESTful still constitutes the vast majority of APIs (80+%). Although the twitter debates continue to rage and there will always be champions for different paradigms, we see things eventually settling into a comfortable coexistence.  Websockets are great for real time applications, gRPC is great for microservice architectures, GraphQL is a great choice when you control both the client and the data source, and REST is great when you are/will be working with external consumers.  We expect that in 5 years time it will be very normal for companies to be using all of the above as part of their technical architecture.

### API Platform teams are choosing to build on top of the best

Thanks to a tight labor market and the Cambrian explosion in 3rd party dev tools, platform teams have switched tactics when it comes to how they support application developers. In the past, internal teams struggled with the sisyphean mandate of trying to handroll an entire scaffolding to support their companies development. We’re seeing a new trend emerge, where lean platform orgs have the mandate to pick the best vendor products available, and stitch them together to create something tailored to their own business’s needs.  This helps to keep the company’s resources focused on the creation of differentiated value for their customers.

## Challenges developers face

### API testing is still limited

When it comes to exhaustive testing of an API, there can be a dizzying number of parameter permutations to consider.  So, while it’s great that developers have tools that let them easily mock an ad hoc API request, creation of a test suite for production APIs can be a major pain point.  Similarly, test suites for internal microservices (understandably) don’t get the same attention as endpoints used by external clients. However, oftentimes the external endpoints rely on a collection of microservices to work. It can be hard to effectively test the external endpoint if there’s no corresponding test suite for the microservices it relies on. If behavior changes is it because something in the external endpoint changed, or one of the underlying microservices?

### API usage is hard to grok

Which customers use this API? Can this old version be deprecated? Is anyone still using this parameter?  All common questions developers ask, all unnecessarily difficult to answer. The lucky developers have Datadog dashboards and full sets of logs in warehouses.  However, many developers lack this sort of reporting infrastructure.  [**It’s a big up front investment to set up, and an expensive ongoing cost**](https://www.linkedin.com/feed/update/urn:li:activity:6945789783235338240/).  Small orgs can’t justify the upfront time investment, and even larger orgs often go without for internal endpoints.  The result is that developers lack an API-centric view where they could easily get a real understanding of how their API is being used in the wild.  This makes it difficult for new developers to quickly grok how the API endpoints are used by consumers, how they work internally, and what to consider when working to evolve the API.

### APIs are stuck on v1

When companies roll out an API, they will confidently put v1 in the API path. This is to highlight that in the future, they will be evolving the API and rolling out a new version, v1.1 or maybe even a v2 someday.  Often though, the API never moves past v1.  Now, this could be because the developers who built the API were oracles with perfect foresight and the API has never needed to be changed. In that case, hats off.  More commonly though, the APIs failure to ever evolve is a byproduct of a broken platform behind the scenes.  In conversations we heard devs say over and over, “We know it’s going to be painful down the road, we’re trying not to think about it.” Without a robust platform providing scaffolding, versioning APIs is a near impossible task. Teams opt to live with the pain of never updating their APIs. In cases where the team gets really desperate, they may change the behavior of the v1 API and brace themselves for the storm of angry client emails.

### Every problem with APIs is exacerbated for internal APIs

It’s been 20 years since [**Jeff Bezos’s (in)famous platformization memo**](https://chrislaing.net/blog/the-memo/). At this point, most software companies have formally adopted a microservice architecture mandate; there’s no doubt that companies are chock-a-block with services. The problem is that microservices tend to get micro-resource allocation when it comes to their tooling.  All the problems we discussed: grokking usage, exhaustive testing, service evolution, are exacerbated for internal APIs. This leads to stale documentation, unintended breaking changes, and unexpected behavior.  Left to fester, it can create a culture where developers become reluctant to trust that a service works as described. They will spend time interfacing with internal teams to make sure that the service works as they expect.  Loss of trust in reliability has real costs in terms of developer’s productivity.

### Developers lack support from the wider org

APIs are an inherently technical product. They are built by developers, and they are consumed by developers. It’s therefore understandable why organizations have siloed all aspects of managing APIs to their development teams.  But if you consider that APIs are a product line for many businesses, that is foolish. APIs require customer support, and product marketing and all the same resources as a conventional software product.  When API development teams are left to handle all these aspects of product development on their own, they either: 1) do it poorly because it’s not their expertise, or 2) don’t have time to develop new features, because their time is sucked up by other management concerns.


 This is the content for the doc blog/api-ops-usage-monitoring/index.mdx 

 ---
title: "API Ops - The Difficulties In Monitoring API Usage"
description: "API monitoring shouldn't be difficult. Speakeasy gives you the proper tooling to reduce API management pain. Learn how we can improve your API monitoring."
image: "/media/api-ops-usage-monitoring.png"
date: 2022-05-23
authors:
  - name: Nolan Sullivan
  - image_url: 'https://uploads-ssl.webflow.com/62ccd7b208cab0723d026273/62cdf9e45dcbb4d20be59f5f_head.jpeg'
tags:
  - API Advice
featured_image: "/media/api-ops-usage-monitoring.png"
---

When building & managing APIs, understanding usage and monitoring for changes is critical to success.  The following post summarizes my experience working on LiveRamp’s web APIs (2016-2018). I will go through the tooling & processes we used to diagnose and triage issues with our APIs (~6 billion requests/day), as well as the gaps in tooling I wished were filled. I hope that other people working on API operations find this useful, and share what has worked well for them.

Before diving in, I’m fully aware that in software, citing experiences from 4 years ago is often an exercise in exploring the ancient past; pace of change and improvements typically render anything older than 2 years null and void.  Given the way APIs and microservices have moved from the periphery to foundational components of the modern tech stack over the last 10 years, the expectation would be that the way APIs are built and managed would’ve correspondingly undergone significant change.  And yet, the primary tooling for monitoring, detecting and troubleshooting APIs doesn’t seem to have evolved much during my hiatus from the space.  People are by and large still using the same set of tools as they were back in 2016.

## Overview of Tooling

Our team was a laboratory for experimentation within the business, and consequently we had our hands on some of the best tools available. Consequently we got exposure to some of the most commonly used tools.  When I began working with the team, our logging/monitoring setup was:

- **Cloud Provider**: AWS
- **Logging infrastructure**: Kinesis Firehose
- **Data Warehouse**: Redshift/Athena/S3
- **Analysis & Insights**: Kibana & Datadog

By the time I stopped working with the web APIs team, the setup was:

- **Cloud Provider**: GCP
- **Logging infrastructure**: Gazette ([**the precursor to Estuary’s Flow**](https://docs.estuary.dev/))
- **Data Warehouse**: BigQuery
- **Analysis & insights**: Grafana & Datadog

Regardless of the stack used, the tools did what they were intended to do. More interesting to me is what the tooling couldn’t do and the operational processes we developed to cope with that lack of tooling.

## Plugging the gaps with Process

Logging infrastructure was great for alerting us that something was amiss, but diagnosing and triaging the issue was an APIOps activity that was largely manual.  To help ourselves we developed processes to categorize issues, and then respond accordingly:

![Issues categories with impact, frequency, and description.](./assets/api-ops-usage-monitoring-image-01.png)

Here’s an overview of how we would diagnose issues…

![A diagram of how issues are resolved.](./assets/api-ops-usage-monitoring-image-02.png)

Rather than beat a dead horse by reiterating the exact text in the flow chart, I want to dive into dealing with breaking change issues. I will give some specific advice for proactively mitigating these types of issues, what the challenges are and what the gap in tooling is.

### Breaking change to an upstream dependency

- **Note:** In the microservices world we’re all living in, it’s very likely that an external service relies on a dozen or more internal microservices to function.  The typical software business might have hundreds or thousands of microservices.  For most, it’s not realistic to invest in the same level of tooling as they do for external API endpoints (logging, dashboarding). It’s therefore entirely possible, dare I say likely, that a microservice team is unaware that external APIs are dependent on their service.
- **How to diagnose**: All that in mind, these can be tricky to diagnose. The first sign will be an anomaly in your traffic patterns. Figure out when the anomaly first appeared, get as specific a time if you can (hopefully you’ll be able to find a step change). First check to make sure that the anomaly doesn’t line up with a push by your own team.  Next you need to figure out if an upstream dependency is the cause.
- **How to triage**: You could take time to dive into the code to test dependencies, but for the sake of speed, I recommend making a list of the teams responsible for the microservices your team depends on. Reach out to each team to check if any of them made a change around the time the anomaly appeared. If there’s a match, ask them to rollback their change so you can see whether the rollback fixes the problem.  After client impact has been mitigated, take the time to dive in and figure out where/how the dependency broke.
- **Advice**: For improved speed, I recommend maintaining a list of the dependencies, and the owning teaming for each. This will allow you to move faster when it matters most.  As I mentioned above, a lot of team’s lack the tooling that would be required to mitigate issues like this.  

### Breaking change to the API itself

- **Note:** Breaking changes in themselves are not necessarily a problem if you are properly versioning your API ([**Brandur Leach wrote a great piece on versioning**](https://stripe.com/blog/api-versioning)).  In this case, I’m referring to accidental breaking changes, which are definitely a problem.
- **How to diagnose**:  Fastest way to spot them is if you notice a spike in error codes and it corresponds with a release your team made to production.  Unfortunately, not all breaking changes trigger spikes in errors.  The problem may only manifest when two API calls are used in sequence, see if there’s any kind of unexpected change in the overall traffic patterns (e.g. drop in total calls to an endpoint).
- **How to triage**: If an anomaly in the data corresponds with a push to production, then rollback the change ASAP.  Even if you haven’t diagnosed the exact error, the priority is client stability.  Later once you have made a diagnosis, address the issue, and test very carefully before pushing to prod again. You will owe your customers an explanation, write out what caused the error, and the steps the team is taking to make sure the issue never reoccurs.
- **Advice**: Again this is a hard one.  If you’re not doing versioning, then do versioning before your client’s leave you.  Integration testing is also definitely your friend. Similar to upstream breaking changes, feels like there’s a tooling gap here that could be better addressed (discussed below).

## The Gaps as I see it

As I said earlier, it strikes me that the development of these processes was in order to cope with a lack of tooling.  There are a few things that it would be great to have, which aren’t available today.  My hope is that in time Speakeasy is able to help devs make steps in addressing some of these gaps.

1. **API-centric monitoring:** The entire process for troubleshooting I layed out is dependent on making a not insignificant investment in logging and dashboarding infrastructure.  Without these, understanding usage is difficult and the surfacing of issues is likely to come in the form of an angry email from your client. It’s always struck me that we were extremely fortunate to have been able to make that investment in a robust logging infrastructure, complete with relevant dashboards and automated alerting.  At Speakeasy we believe there should be something more API-native and developer-first. Devs should be able to drop-in a couple lines of code and get something that works out of the box. This would provide smaller teams the same level of insight into usage as large companies. Who’s using which API version, is the integration healthy, are there anomalies?
2. **API Developer Guardrails:** Most unintentional breaking changes follow similar patterns: adding a required field, changing the response structure, changing a method or resource name, etc. Introducing some guardrails that could sense check changes for common mistakes would go a long way towards helping devs avoid costly client errors.  It’s something that a lot of big companies have, that is often too expensive for a smaller org to develop internally.
3. **API Dependency Mapping:** I mentioned how it can be useful to maintain a list of the dependencies an API depends on.  That’s really a stop gap measure. It would be better if this could be automatically tracked, and what would be even better is if there was tooling which made it easy for microservices to understand the usage of their services, so they could track use by external services.

I’m really curious about how much overlap there is between my experience and those of other people. Would love to hear what off-the-shelf tools other people have used to manage their API operations, and what processes people have developed internally to cope with the lack of tooling.


 This is the content for the doc blog/apis-for-global-shipping.mdx 

 ---
title: "API Experts - Shipping APIs for Global Shipping"
description: "Find out how Flexport is building an API platform to make global trade easy for everyone."
keywords: [api, openapi, swagger, eric chung, flexport, logistics, shipping, developer experience, devex, dx, sdk generation, sdk]
image: "/media/api-experts-eric-chung.png"
date: 2022-10-27
authors:
  - name: Nolan Sullivan
  - image_url: 'https://uploads-ssl.webflow.com/62ccd7b208cab0723d026273/62cdf9e45dcbb4d20be59f5f_head.jpeg'
tags:
  - API Advice
featured_image: "/media/api-experts-eric-chung.png"
---

### TL;DR

- Platformization efforts can start off as a single team mandate, but you need to figure out how to scale them into an org wide mandate to be successful.
- For larger companies with an acquisition strategy, an API platform can be the difference between a successful or a failed integration with an acquired business.
- Public API teams often evolve into having a DevEx mandate. Making users successful in using your API isn't narrowly focused on documentation.
- For a good DevEx, focus on eliminating the need for any interaction with customer support.

## Introduction

**_Could you explain what you & your team are responsible for?_**

I'm a Senior Engineering Manager of Flexport’s Public API team, which also goes by the moniker of ‘Developer Platform’. Those two things are related because the API platform serves as the foundational piece of our external developer experience. We're a 2.5-year-old team, and we’re looking to greatly expand our scope to become the horizontal tooling provider for all the internal Flexport engineering teams who publish and maintain APIs, and enable them to give external non-Flexport developers a superior industry-leading experience.

[**On flexport.com, if you open the “Developers” menu item**](https://developers.flexport.com/s/?_ga=2.155367484.687997278.1658178205-206804922.1658178205) – everything listed there is built by, or supported by my team in partnership with teams across our entire Technology organization.

## APIs At Flexport

**_What are the key goals for the API platform team?_**

A key goal for the company is to become more API-first – as our Executive leadership has said, “The vision is to build the technology platform to make global trade easier. We will open up more and more capabilities for anybody in the world to use”; [**we are building the API platform for internal developers, partner developers, as well as 3rd party developers**](https://www.freightwaves.com/news/flexport-to-open-platform-for-third-party-app-developers). That’s the strategic product vision my team seeks to achieve, so internal and external application developers can build on Flexport’s tech platform. I think this story will sound familiar to many companies: APIs will only increase in importance as a lever for Flexport’s future growth and scale.

A key goal for my team is to increase end-to-end automation for internal and external API developers, which will, in turn, increase API creation and adoption. We’re always thinking about ways that we can empower these engineering teams to expose their services externally, as easily and quickly as possible – while giving them access to the critical functionality needed to run a great API. That means taking care of everything from observability, telemetry, monitoring, testing, scalability and reliability, through to hosting developer portals, documentation, developer tutorials, code samples and OpenAPI schema creation.

**_What is the value of having the API Platform?_**

It’s all about increasing efficiency and throughput for internal teams, our customers and ultimately growing the business. Flexport constantly launches new product lines; APIs are critical for letting teams build products quickly and allowing partner developers to create engaging apps to delight our customers. Our API platform enables the internal teams to develop and maintain APIs faster, and deliver the consistency external developers deserve.

It's worth mentioning that, because we are a large company, Flexport does make acquisitions and strategic partnerships with other tech companies. When we’re making an acquisition or building a new partnership, our APIs facilitate the integration and a frictionless customer journey.

**_You mentioned before that Flexport is ‘becoming’ API-first. Can you tell us about what Flexport is evolving from?_**

Flexport is a company that was founded in 2013. We started off delivering much of our service via web apps, though our public API usage has steadily increased over time. As our customer-base has grown, we’ve added more clients and partners who require enterprise-level platform integrations via API and want to embed Flexport functionality in their own software applications, which is why APIs have become a major focus as we seek to aggressively automate all aspects of the vast global supply chain which includes many operational tasks from origin to destination.

To seed the process of evolving from the monolith to a more flexible SoA/microservice architecture, API ownership was driven by my team as a consolidated initiative. That’s why my team directly maintains a portion of Flexport’s public APIs. That was good for getting started, though we sought out a more scalable solution for the long-term. APIs are merely a different interface for accessing the same set of entities and operations that Flexport’s web apps and internal APIs offer; therefore, each product team should own their corresponding APIs in a federated model. We’re nearly done with this transition; each individual product team is starting to own the REST APIs in their vertical domain.

Going forward, my team’s role will be to focus more on their enablement, maintaining consistent REST patterns, observability, automation, testing, monitoring and providing a world-class experience to our internal and external devs who call our public API; though when business priorities necessitate, we can still quickly mobilize our resources to directly implement new APIs on behalf of domain teams to help accelerate delivery. Our goal is public API feature parity with the functionality available in our web apps.

Flexport’s own application and platform integration developers are major consumers of our public APIs currently and we will continue to build and launch customer applications on top of our public APIs; there are a number of exciting apps and new APIs in various stages of development that our customers are going to love.

**_What type of tooling has your team rolled out to the teams at Flexport_**

Yeah, good question. Networking and security optimizations were some of the first things we tackled. Then we partnered with other teams to standardize infrastructure, identity management, and so forth. Next, we focused on building a comprehensive API best practice guide: from the networking layer, down to what the routes look like along with modeling new personas. We want to make sure the look and feel of Flexport's APIs reflect REST standards. We also developed opinionated guidance about things like pagination, sorting, filtering, resource structure, URI, versioning and Documentation. We’ve launched Flexport’s [**Developer Portal**](https://developers.flexport.com), in addition to our [**API reference**](https://apidocs.flexport.com).

So now, these templates and guidance are all documented for Flexport teams, and we are turning our attention to making implementation as turnkey as possible. Self-service is our northstar; both for the internal Flexport developer publishing and consuming APIs, and also, for the external developers we serve. We have rolled out 24x7 public API service health monitoring with our [**API status page**](https://status.flexport.com) and are proud to consistently exceed our uptime availability target.

## Developer Experience

**_You mentioned your team has a larger DevEx mandate. How did you grow from API ownership to DevEx ownership?_**

This is a pattern I’ve seen at other companies I’ve worked at as well. It’s common to start with a public API enablement team that has a fairly broad charter. At my previous job, we were building a lot of those frameworks and platforms for the businesses, which the different business units and teams could all leverage, and the end goal is always to make sure that the APIs have a cohesive customer experience across all the different product lines. And then that goal naturally expands from cohesive API experience to cohesive developer experience across the whole external surface.

**_What do you think constitutes a great developer experience?_**

I've been professionally working on public API and developer platform enablement / DevEx for almost a decade. I’ve collaborated with a lot of developer advocates and partnered with many folks building incredible industry-leading developer platforms. One of the things that is essential to a great developer experience is frictionless self-service. In a given year you should not need to talk to a human being via phone or email in order to successfully build applications on a strong technology platform. You only have one chance to make that positive first impression. And if you say, ‘Hey, you must talk to a human being to get your account verified’, most developers won't come back, especially if you're not really a well-known entity. I’d also avoid having a paywall. There are metrics that show that having a paywall in front of an API will cause your developer conversion to drop significantly. I recommend using a rate-limited free tier for developers to use in order to increase adoption.

Another part of self-service is the documentation. [**You need to have very good and accurate documentation for developers**](https://apidocs.flexport.com/). You should provide code samples, SDKs, example applications, and [**status pages**](https://status.flexport.com/). My opinion is that the best you can provide is a sandbox for developers to actually interact with live. But you should make an effort to provide documentation in various formats. Written first and foremost, but some people respond better to video tutorials. We want to provide API consumers self-service access to metrics and usage dashboards, logs, errors and other configurations across production and non-production environments.

Lastly, you want to make sure the surface area is consistent and follows standards. For me personally, when I start using an API and I can see that they haven’t implemented best practices, I will question whether the company is reliable. For example, if the API isn’t rate-limited then that makes me think that they don’t really think things through. So, make sure you are embracing those best practices from the beginning.

## Improving APIs

**_What are some of the KPIs your team tracks against?_**

Of course we look at uptime, since availability of our services is table stakes. We then look at active users over a given timeframe, usually monthly or weekly for our business. We track the active users (MAUs), latency (p99, p95, p90, etc.), volume of requests, uptime availability and error rate for each endpoint, and also the emitted web hooks. Those are the most basic metrics that are universal across the teams. Every team may have its own additional KPIs that they care about as well depending on what their team’s specific business objectives are.

**_What are the main challenges facing developers building public APIs at Flexport?_**

Our public APIs are not quite at feature parity with our internal capabilities. Our push to automate API operations will help improve our API development velocity as we strive for public API feature parity.

On that topic, a lot of our tooling and processes around APIs are still more manual – multiple manual steps, reviews and synchronous activities are required to get an API exposed externally. That’s what a developer would mention as the primary opportunity. For my team, bringing automation to many different concerns, across such a large surface area of APIs is definitely a huge opportunity.

Another topic we are navigating is better defining the responsibilities of platform teams like mine vs. the domain teams that build the API business logic. Today it can be fuzzy, though for the most part ownership is clear. Who is responsible for latency, performance monitoring and load testing? How do we help domain teams even be aware of performance concerns and become more sensitive to it? Customer delight is our primary goal and we drive towards this relentlessly.

**_How about a developer integrating with Flexport APIs? What are their main challenges?_**

We frequently receive requests for enhancements to our API and developer platform experience, and due to where we are in our API journey, we get a lot of requests from customers to expose more functionality via our public API. As I said before, our APIs aren’t at parity with our web app interfaces and internal APIs yet. So that's definitely the most common request, to expose more internal functionality via our public APIs; to accomplish this we need to work broadly across our Tech org.

## API Architecture

**_If someone was designing their API architecture today, what advice would you give them? How would you approach using REST or GraphQL?_**

Yes, this is a good question, and one I've been asked ever since I joined Flexport and started managing APIs. What I would say is that there is no right answer, you need to build with your customer in mind to delight the customer and deliver high-value business impact. At Flexport we are working in freight forwarding; we're the leading technology disruptor in the supply chain logistics space. While the sector is digitizing, the rate of B2B digitization may be slower than some B2C industries, say Finance & Fintech.

Many of our partners in the space have been operating for much longer than Flexport. We do not have customers asking us for public GraphQL right now. That may happen in the future, and if there was a compelling customer use case we would consider it, though for our current customers and partners, REST endpoints and webhooks satisfy their requirements. If you’re in a space that is catering to developers who are asking for it, GraphQL might be worth considering. At my previous company we had some GraphQL public APIs though the customer demand was overwhelmingly for REST.

## Closing

**_A question we like to ask everyone: any new technologies or tools that you’re particularly excited by?_**

I'm curious about AR and VR. We have held a couple of hackathons and for one of those hackathons, I built a VR treasure hunting game. Flexport is a mix of people; some of us are from the logistics, supply chain and freight industry, while others have not actually worked in this domain. There are people at Flexport who have never had the opportunity to visit a working port, or been on a container ship. So I built a little VR game in 2 days so that people could visually explore those different locations. In the game, you are on the hunt for personal protective equipment (PPE) aboard container ships, since during that hackathon, we were at the beginning of the COVID-19 pandemic and Flexport via [**Flexport.org**](https://www.flexport.org/) was making a big push to [**ship PPE to frontline responders**](https://www.flexport.com/blog/the-drive-to-mobilize-ppe-flexport-raises-usd7-9m-to-move-medical-supplies/) where we raised over $8 million. You can play the game at [**eesee.github.io/justflexit**](https://eesee.github.io/justflexit/)


 This is the content for the doc blog/apis-vs-sdks-difference/index.mdx 

 ---
title: "APIs vs. SDKs: Key Differences, Use Cases, and Best Practices"
description: "Explore the core differences between APIs and SDKs, learn real-world use cases, and discover best practices for seamless integration and faster development."
date: 2025-01-13
image: "/media/api-vs-sdks.png"
authors:
  - name: Emre Tezisci
  - image_url: "/media/author-headshots/emre.jpeg"
tags:
  - API Advice
featured_image: "/media/api-vs-sdks.png"
---
# APIs vs. SDKs: Understanding the Differences and Practical Applications

In the interconnected world of modern software, APIs (Application Programming Interfaces) and SDKs (Software Development Kits) are indispensable tools. APIs act as the bridges that allow different applications to communicate and share data, while SDKs provide developers with the toolkits they need to build upon these APIs efficiently. Choosing whether to use an API directly or leverage an SDK is a crucial decision that can significantly impact a project's timeline and overall success. This guide will clarify the distinctions between APIs and SDKs, explore their common use cases, and outline best practices for both.

---

## Quick-Reference Summary

Here’s a brief table that highlights the fundamental differences between APIs and SDKs at a glance:

| **Aspect**               | **API (Application Programming Interface)**                                       | **SDK (Software Development Kit)**                                         |
|--------------------------|-----------------------------------------------------------------------------------|----------------------------------------------------------------------------|
| **Definition**           | A set of rules and protocols for communication between software components        | A bundle of tools, libraries, and documentation to accelerate development  |
| **Scope**                | Focuses on how to send and receive data (often via HTTP/HTTPS)                    | Provides prebuilt code, testing frameworks, and platform-specific support  |
| **Implementation Detail**| Requires developers to handle requests, responses, and error handling manually    | Abstracts complexities with prewritten methods and classes                 |
| **Platform Dependency**  | Typically platform- and language-agnostic (REST, GraphQL, gRPC, etc.)             | Often tied to a specific language or ecosystem (Android SDK, iOS SDK, etc.)|
| **Use Case**             | Ideal for lightweight integration, direct control, or cross-platform scenarios    | Best for rapid development, built-in best practices, and platform-specific features |

---

## What Are APIs?

An **Application Programming Interface (API)** is a set of rules, protocols, and definitions that enable different software components to communicate. It acts as a “contract,” specifying how requests and data exchanges occur between systems, such as a client application and a remote server.

APIs serve as fundamental building blocks in modern software. They allow developers to leverage sophisticated services (e.g., payment gateways, location services) without building them from scratch. Internally, APIs make it easier for teams to create modular, scalable applications by standardizing communication between different components and services.

### Popular API Approaches

- **REST (Representational State Transfer):** REST is the most widely used approach for creating APIs, primarily due to its simplicity and compatibility with HTTP. It dictates structured access to resources via well-known CRUD (Create/Read/Update/Delete) patterns. A common pattern in modern web development is to create a front-end written in React or a similar framework, which fetches data from and communicates with a back-end server via a REST API.
- **GraphQL:** GraphQL is a newer API technology that enables API consumers to request only the data they need. This reduces bandwidth required and improves performance, and is particularly suitable in situations where a REST API returns large amounts of unnecessary data. However, GraphQL is more complex to implement and maintain, and users need to have a deeper understanding of the underlying data models and relationships in order to construct the right queries.
- **gRPC (Google Remote Procedure Call):** gRPC is a high-performance, open-source framework designed for low-latency and highly-scalable communication between microservices. gRPC is strongly-typed, which helps catch errors earlier in the development process and improves reliability. However, gRPC ideally requires support for HTTP/2 and protocol buffers, which many web and mobile clients may not support natively. Also note that far fewer developers are familiar with gRPC than REST, which can limit adoption. For these reasons, gRPC is mainly used for internal microservice communications.

In summary, REST remains the most popular API technology due to its simplicity and widespread adoption. GraphQL and gRPC are popular for specific use cases.

---

## What Are SDKs?

A **Software Development Kit (SDK)** is a comprehensive collection of tools, libraries, documentation, and code samples that streamline application development on a specific platform or for a specific service. While an API defines how to interact with a service, an SDK provides ready-made resources to speed up that interaction.

Key components of SDKs include:
- **Pre-Written Libraries**: Reduce boilerplate by offering out-of-the-box methods and classes  
- **Development Utilities**: Provide testing frameworks and debugging tools  
- **Platform-Specific Resources**: Include documentation, guides, and environment setup instructions

For example, the **Android SDK** includes compilers, emulators, libraries, and tutorials, allowing developers to build Android apps with minimal friction.

---

### Why Do SDKs Add Value to API Integrations?

Without an SDK, you must manually handle HTTP requests, parse responses, implement error handling, manage authentication, and maintain the correct sequence of API calls. SDKs solve many of these pain points by:

- **Development Efficiency**: Simplify method calls (e.g., `client.placeOrder(...)` instead of manually constructing endpoints and payloads).  
- **Type Safety & Consistency**: Strongly-typed interfaces reduce integration errors.  
- **Maintenance Benefits**: Common patterns and best practices are baked into the libraries.  
- **Change Management**: Many SDKs transparently handle minor API updates under the hood.

---

## How Do APIs Compare With SDKs in Practice?

### Example: Direct API Integration

To highlight these differences, let’s look at an example of what integrating with an e-commerce API might look like, first without an SDK and then with one. The use case will be enabling a new customer to place an order. This requires fetching information about the product being ordered, creating a new customer, and creating the order itself.

**First, here’s what integrating might look like without an SDK:**

```typescript
const fetch = require('node-fetch');

const apiKey = 'your_api_key';
const baseUrl = 'https://api.ecommerce.com/v1';
const headers = {
  'Authorization': `Bearer ${apiKey}`,
  'Content-Type': 'application/json'
};

const productName = 'Awesome Widget';
const customer = {
  firstName: 'John',
  lastName: 'Doe',
  email: 'john.doe@example.com'
};
const quantity = 2;

async function placeOrder(productName, customer, quantity) {
  try {
    // Step 1: Get product information
    const productResponse = await fetch(`${baseUrl}/products`, { headers });

    if (productResponse.status !== 200) {
      throw new Error(`Could not fetch products. Status code: ${productResponse.status}`);
    }

    const productData = await productResponse.json();
    const product = productData.products.find(p => p.name === productName);

    if (!product) {
      throw new Error(`Product '${productName}' not found.`);
    }

    // Step 2: Create a new customer
    const customerResponse = await fetch(`${baseUrl}/customers`, {
      method: 'POST',
      headers,
      body: JSON.stringify({ customer })
    });

    if (customerResponse.status !== 201) {
      throw new Error(`Could not create customer. Status code: ${customerResponse.status}`);
    }

    const customerData = await customerResponse.json();
    const customerId = customerData.customer.id;

    // Step 3: Place the order
    const orderResponse = await fetch(`${baseUrl}/orders`, {
      method: 'POST',
      headers,
      body: JSON.stringify({
        order: {
          customerId,
          items: [
            {
              productId: product.id,
              quantity
            }
          ]
        }
      })
    });

    if (orderResponse.status !== 201) {
      throw new Error(`Could not place order. Status code: ${orderResponse.status}`);
    }

    console.log('Order placed successfully!');
  } catch (error) {
    console.error(`Error: ${error.message}`);
  }
}

placeOrder(productName, customer, quantity);
```

Note that the API consumer would need to construct all this code themself. They would need to refer to the API documentation to figure out which APIs should be called, what the response data structures look like, which data needs to be extracted, how to handle auth, what error cases might arise and how to handle them.

**What You Manage Manually:**
- Constructing requests and headers  
- Parsing responses  
- Handling errors for each call  
- Managing authentication  
- Sequencing the calls to ensure proper workflow

**Now here’s the SDK version of this code. Using an SDK, the same functionality can be achieved with much greater ease:**

```typescript
const { EcommerceClient } = require('ecommerce-sdk');

const apiKey = 'your_api_key';
const client = new EcommerceClient(apiKey);

const productName = 'Awesome Widget';
const customer = {
  firstName: 'John',
  lastName: 'Doe',
  email: 'john.doe@example.com'
};
const quantity = 2;

async function placeOrder(productName, customer, quantity) {
  try {
    await client.placeOrder(productName, customer, quantity);
    console.log('Order placed successfully!');
  } catch (error) {
    console.error(`Error: ${error.message}`);
  }
}

placeOrder(productName, customer, quantity);
```

Notice how much simpler and concise it is. Authentication is handled automatically with the developer just needing to copy in their key. Pre-built functions mean the developer doesn’t need to parse through pages of API docs to stitch together the required calls and associated data extraction themselves. Error handling and retries are built-in.

Overall, a far easier and superior experience.

**Advantages of Using an SDK:**
- **Dramatically Reduced Code Complexity**: Fewer lines of code and clearer logic flow  
- **Automatic Authentication and Error Handling**: The SDK’s internal routines handle retries, rate limits, and token refreshes  
- **Built-in Best Practices**: Consistent data structures and naming conventions  
- **Faster Onboarding**: Less time spent referencing raw API docs

---

## What’s the difference between SDKs and APIs?
APIs and SDKs serve distinct yet complementary roles in software development. **APIs** provide the underlying communication protocols and offer broad flexibility, while **SDKs** wrap these protocols with ready-to-use libraries and best practices that make development faster and more consistent. In summary, APIs & SDKs are symbiotic. Let’s talk about coffee to draw the analogy better.

You can think of APIs as the fundamental, bare metal interfaces that enable applications or services to communicate. In our analogous example, APIs are like going to a coffee shop and getting a bag of beans, a grinder, a scale, filter paper, a coffemaker/brewer, kettle, and an instruction guide. Good luck making a delicious brew!

SDKs on the other hand are critical to enabling APIs to reach their full potential, by providing a rapid, ergonomic way to access the API’s underlying functionality. In our coffee example, SDKs are more akin to telling a skilled barista “I’d like a latte please”. The barista does all of the work of assembling the ingredients, and you get to focus on the end result.

## API and SDK best practices

Now we know what APIs and SDKs do, what should you keep in mind as you’re building them, to ensure they fulfill the promises we’ve outlined above?

Here are some “gotchas!” to watch out for when building awesome APIs:

- **Design carefully:** It can be extremely difficult to get users to change how they use an API once it’s in production. Avoiding unnecessary breaking changes, where possible, will save you many headaches and irate users later.
- **Documentation:** In addition to an “API reference” that details every endpoint and response, consider creating a “usage guide” that walks users through how to use APIs in sequence to accomplish certain tasks.
- **Authentication:** Creating and sending users API keys manually works fine for an MVP, but has obvious security and scalability challenges. An ideal solution is to offer a self-service experience where end-users can generate and revoke keys themselves. For more on API auth, [check out our guide](/post/api-auth-guide).
- **Troubleshooting and support:** Users will inevitably run into issues. It’s easy for members of the team to quickly get inundated with support requests. Try to provide self-service tools for troubleshooting API issues, such as logging and monitoring, and community support channels.

Building great SDKs presents a different set of considerations. Keep these in mind if you want to offer a great SDK to your users:

- **How stable is the underlying API?** If the API is undergoing frequent changes, it might be particularly challenging to manually keep the SDKs up-to-date and in sync with the API.
- **Creation and maintenance cost:** Creating native language SDKs for all your customers’ preferred languages can be a huge hiring and skills challenge. Each language SDK also has to be updated every time the API changes – ideally in lockstep to avoid the SDK and API being out of sync. This is time-consuming and costly. Many companies have deprecated or scaled back their SDKs after misjudging the work required.
- **Testing and validation:** Plan for thorough testing of the SDKs across different platforms and languages, including unit tests, integration tests, and end-to-end tests, to ensure the SDKs are reliable and compatible with the API.
- **Documentation:** Provide clear examples and code snippets in each language to make the SDKs easy to use and understand.
---

## Simplify SDK Generation with Speakeasy

While the benefits of providing SDKs are clear, creating and maintaining them across multiple languages can be a significant undertaking. It requires specialized skills, substantial development time, and ongoing effort to keep SDKs in sync with API changes. This is where Speakeasy comes in.

Speakeasy is a platform that **automatically generates high-quality, idiomatic SDKs** from your API specification. Our solution helps you:

*   **Reduce Development Time and Costs:** Eliminate the need to manually write and maintain SDKs. Speakeasy handles the heavy lifting, freeing up your team to focus on core product development.
*   **Ensure SDK Quality and Consistency:** Our generated SDKs are built to follow industry best practices. Speakeasy offers comprehensive, automated testing, ensuring reliability and a consistent developer experience across all supported languages. Each generated SDK comes with:
    *   **Comprehensive Test Coverage:** We provide a wide range of tests, including unit, integration, and end-to-end tests, to validate every aspect of the SDK's functionality.
    *   **Automated Test Execution:** Our platform automatically runs these tests whenever your API specification changes, providing immediate feedback on any potential issues.
*   **Keep SDKs in Sync with API Changes:** Speakeasy automatically regenerates your SDKs whenever your API specification is updated, guaranteeing that your SDKs are always up-to-date.
*   **Improve Developer Experience:** Provide developers with easy-to-use, well-documented SDKs that accelerate integration and enhance their overall experience. Each generated SDK comes with extensive, ready-to-publish documentation:
    *   **Interactive Code Examples:** Developers can see real code examples in their preferred language, making it easier to get started.
    *   **Clear and Concise Explanations:** Our documentation is designed to be easy to understand, even for complex API interactions.
    *   **Automatically Updated:** Documentation is regenerated alongside the SDKs, ensuring consistency and accuracy.
*   **API Insights:** Speakeasy provides detailed insights into your API's usage and performance. Our platform helps you track key metrics, identify areas for improvement, and ensure the reliability of your API.

**How it Works:**

1.  **Provide Your API Specification:** Share your OpenAPI or other supported API specification with Speakeasy.
2.  **Configure Your SDKs:** Select the languages you want to support and customize the look and feel of your SDKs, including configuring authentication methods.
3.  **Generate and Publish:** Speakeasy automatically generates your SDKs, runs comprehensive tests, creates detailed documentation, and makes them available for download or through package managers.

Stop spending valuable time and resources on manual SDK development. Let Speakeasy handle the complexities of SDK generation, testing, and documentation so you can focus on building great APIs and delivering exceptional developer experiences. [Learn more about Speakeasy's SDK generation platform](https://www.speakeasy.com/docs/introduction).

**Get started today, [book a demo with us](https://www.speakeasy.com/book-demo).**


 This is the content for the doc blog/auth-for-embedded-react-components/index.mdx 

 ---
title: "How to Handle Auth for Embedded React Components"
description: "Learn how to handle Auth for products that are being delivered as react embeds."
image: "/media/auth-for-embedded-react-components.png"
date: 2022-10-20
authors:
  - name: Nolan Sullivan
  - image_url: https://uploads-ssl.webflow.com/62ccd7b208cab0723d026273/62cdfe8c07de4e15f4df107d_5-alexa-headshot.jpg
tags:
  - Building Speakeasy
featured_image: "/media/auth-for-embedded-react-components.png"
---

## Use case & requirements

More and more developer products are being delivered as react embeds. We recently built out our infrastructure to support delivery of Speakeasy as a series of embedded react components. Why embedded components? The embedded components enable our customers to include Speakeasy functionality in their existing developer portals, surfacing their API request data to their users.

Because our embeds are exposing API data to our customers’ users, authentication is a critically important feature to get right. In this blog post I will walk through how we decided to implement authentication for our embedded react components, in the hope it helps someone else building react embeds that handle data.

The elevator-pitch for this feature is: our users should be able to safely embed _our_ widgets into _their_ web applications. The list of requirements for this feature looks something like this:

1. **Data Segmentation:** Because our customers’ web applications may be user-facing, our customers need to be able to dictate _what_ portion of the data gets rendered into the components.
2. **Manageable:** Customers need to be able to restrict access to someone who was previously authenticated.
3. **Read Only:** Embeds might be exposed to people who shouldn’t be able to modify the existing state (upload an OpenAPI schema or change API labels, for example), so they should have restricted permissions.

The **TL;DR** is that we evaluated two authentication options: API Keys, and Access Tokens. We ended up going with access tokens. Although they were more work to implement we felt they provided superior flexibility. Read on for the details of the discussion.

## How to Solve - Option 1: API Key?

At the point that we were initially discussing this feature, we already had the concept of an api-key, which permits programmatic access to our API. An obvious first question is whether or not we could re-use that functionality to authenticate users of the embedded resources. Let’s imagine what that might look like in the use case of our react embeds.

![Speakeasy react embeds example.](./assets/auth-for-embedded-react-components-image-01.png)

That was easy! But does it meet our requirements?

1. **Data Segmentation:** Maybe, but it would take some work. We’d need to have some means of relating an api-key with a customer, but that’s not too bad.
2. **Manageable:** Again, maybe. What happens when an api key needs to be revoked: unless a separate api key is produced for each user (imagine that one customer has multiple people using the embedded component), everyone using the newly-revoked token loses access. If a separate api key _is_ produced for each user, then the api-key becomes state that needs to be held, somewhere, and since Speakeasy isn’t a CRM, that’s now a table in _your_ database that _you_ need to manage.
3. **Read Only:** Not yet. We’d need to add some functionality to the api keys to distinguish between read-only and write-capable api keys.

### How does this live up to our requirements?

Could work, but would require some work to meet the requirements. Maybe we can do better.

## How to Solve - Option 2: Access Token

What would a separate “embed access token” implementation look like? Let’s take a look at what tools we’ve already built that we might take advantage of.

- We know that our sdk is in your API
- We know we have the concept of a customer ID
- We also know that you know how we’re identifying your customers (you assigned the customerID to each request)
- We know that you probably already have an auth solution that works for you.

From the looks of it, we don’t really need to understand who your users are or how you assign customerIDs to requests, and chances are, you don’t want another service in which to manage your customers, because you probably have that logic somewhere already. Since the authentication logic _for_ your API is probably reliably available _from within_ your API, we just need to make it easy for you to give that authentication result to us.

This is where we can take advantage of the Speakeasy server-side sdk that is already integrated into your API code, because it’s authenticated with the Speakeasy API by means of the api key (which is workspace specific).

```typescript
// Endpoint in api server with speakeasy sdk integration
controller.get("/embed-auth", (req, res)  => {
    const authToken = req.headers["x-auth"];
    const user = userService.getByAuthHeader(authToken);

    const filters = [{
      key: "customer_id",
      operator: "=",
      value: user.companyId
    }];

    const accessToken = speakeasy.getEmbedAccessToken(filters)
    res.end(JSON.stringify({ access_token: accessToken}));
});
```

That takes care of understanding _how_ to segment the data, but how do we actually make that work? There are myriad reasons that you might want to control the scope of data exposed to your customers. We already have a filtering system for the Speakeasy Request Viewer. If we build the access token as a JWT, we can bake those filters _into_ the JWT so that they cannot be modified by the end-user, and we can coalesce the filters from the JWT and the URL, maintaining the existing functionality of the Speakeasy Request Viewer filtering system.

Putting this all together, the resulting flow looks like:

1. You authenticate the user
2. You translate the result of authentication into a series of filters
3. You pass the filters into some method exposed by the Speakeasy sdk
4. We encode those filters into a JWT on our server
5. You return that JWT to your React application.

### How does this live up to our requirements?

1. **Data Segmentation:** Yeah, beyond even just by customer ID.
2. **Manageable:** JWTs are intentionally ephemeral. We already have logic to refresh JWTs for our Saas platform that we can re-use for the embed access tokens.
3. **Read Only:** This can be implemented with an additional JWT claim alongside the filters.

### Loose ends

Requiring a new endpoint in your API to get the embedded components (option 2) working _is_ more work (potentially split over teams) than api-key based authentication. The consequence is that the endpoint has to be deployed _before the embedded component can even be tested._ To ameliorate this disadvantage, we added a **Create Access Token** button directly in our webapp, which generates a short-lived access token that can be hard-coded in the react code for debugging, testing, or previewing.

![Create embed tokens direclty in the webapp.](./assets/auth-for-embedded-react-components-image-02.png)

## Final Conclusion

Access Tokens take a little more setup, but it’s considerably more flexible than the original api key idea. It also works with whatever authentication flow you already have, whether it’s through a cloud provider or your hand-rolled auth service. Additionally, because JWTs are ephemeral and can’t be modified, this solution is more secure than the api-key method, which would require manual work to revoke, whereas the moment that a user can’t authenticate using your existing authentication, they can no longer authenticate with a Speakeasy embedded component.


 This is the content for the doc blog/build-terraform-providers/index.mdx 

 ---
title: "Building a SaaS API? Don't Forget Your Terraform Provider"
description: "Speakeasy is ready to help SaaS platforms reach Terraform users"
keywords: [terraform, terraform provider, api, openapi, swagger, sdk generation, go, golang, go sdk, golang sdk, developer experience, devex, dx]
image: "/media/build-terraform-providers-2.png" 
date: 2023-07-04
authors:
  - name: Thomas Rooney
  - image_url: "/media/author-headshots/thomas.jpeg"
tags:
  - Terraform
featured_image: "/media/build-terraform-providers-2.png"
---

# Building a SaaS API? Don't Forget Your Terraform Provider

Replacing custom integrations with Terraform cuts down on errors, simplifies infrastructure management, makes infrastructure changes easier to version, and saves developers hours of repeatedly clicking around hundreds of different dashboards.

Most users are familiar with Terraform DevOps functions: Launching web servers, managing databases, and updating DNS records on AWS, GCP, and Azure.

But Terraform's adoption is growing far beyond infrastructure and it's time we free this sleeping giant from its reputation as a cost center. Instead, we see Terraform as a strategic ally and driver of revenue for most SaaS platforms through the offering of a provider.

Terraform with its provider plugin ecosystem can serve as a robust interface between your SaaS API and your users, allowing for a more integrated, efficient, and scalable developer experience. It's not just about deploying servers and managing databases anymore; it's about creating a unified and streamlined workflow for your users, reducing complexities, and unlocking new use cases.

Terraform already helps your users solve their infrastructure problems:

| Infrastructure Problem | Terraform Solution |
|---|---|
| Inconsistent environments | Promotes consistency across dev, staging, and production environments. |
| Managing multicloud infrastructure | Provides a unified framework for managing GCP, AWS, Azure, and more. |
| Scalability challenges | Automates provisioning and management of resources, aiding scalability. |
| Wasted cloud resources | Includes modules to estimate infrastructure cost and scale down unused resources. |
| Resource orchestration | Automatically handles dependencies between infrastructure resources. |
| Auditing and versioning of infrastructure | Enables version control and auditing of infrastructure. |

Speakeasy makes it straightforward to create API surface areas that provide exceptional developer experience to your users. That includes SDKs in 7+ popular languages, but it also means [Terraform providers](/docs/create-terraform). We help you meet your users where they already are - the Terraform registry.

But first, let's start with some background.

## What is Terraform?

Terraform is an open-source infrastructure-as-code (IaC) tool developed by HashiCorp. IaC is essential in modern DevOps practices as it allows for consistent and repeatable deployments, minimizing the risks and tedium of manual configurations.

By describing their desired infrastructure in a declarative language called HCL (HashiCorp Configuration Language), teams can version, share, and apply infrastructure definitions using Terraform.

The most basic building blocks of Terraform configurations are Terraform providers.

## What Is a Terraform Provider?

A Terraform provider is a plugin that allows Terraform to manage a given category of resources. Providers usually correspond to specific platforms or services, such as AWS, Azure, GCP, or GitHub. Each provider defines and manages a set of resource types—for example, an AWS provider might handle resources like an AWS EC2 instance or an S3 bucket.

When you're writing your Terraform configuration files, you define what resources you want and which provider should manage those resources. The provider is then responsible for understanding API interactions with the given service and exposing resources for use in your Terraform scripts.

In practical terms, this means that providers translate the HCL code that users write into API calls to create, read, update, delete, and otherwise manage resources on these platforms. By using providers, Terraform users can manage a wide variety of service types.

The most widely used Terraform plugin registry is the [HashiCorp Terraform registry](https://registry.terraform.io/). Launched in 2017, the registry [has now surpassed 3,000 published providers](https://www.hashicorp.com/blog/hashicorp-terraform-ecosystem-passes-3-000-providers-with-over-250-partners).

## Terraform Beyond Infrastructure

While Terraform's primary function remains infrastructure management, its use cases extend beyond the traditional scope. In addition to managing servers, databases, and networks, Terraform can be used to manage higher-level services and applications, including SaaS products.

Let's look at a few examples of Terraform providers for SaaS platforms:

### LaunchDarkly Terraform Provider

[LaunchDarkly](https://launchdarkly.com/) is a continuous delivery platform that enables developers to manage feature flags and control which users have access to new features. For each new feature your team builds, you add a feature flag and gradually release the feature to your users based on certain criteria. Now imagine a situation where you want to test a feature flag in development, staging, QA, and then finally release it in production. Your team would need to log in to the LaunchDarkly dashboard each time to manage these flags across the different environments, which can be a time-consuming process.

The [LaunchDarkly Terraform provider](https://registry.terraform.io/providers/launchdarkly/launchdarkly/latest/docs) allows developers to automate the process of creating, updating, and deleting feature flags across different environments, reducing manual effort, minimizing human error, and increasing efficiency in their workflows. It's a clear win for developer productivity and reliability of the deployment process.

### Checkly Terraform Provider

[Checkly](https://www.checklyhq.com/) enables developers to monitor their websites and APIs, offering active monitoring, E2E testing, and performance metrics. It provides essential insights into uptime, response time, and the correctness of your web services.

Imagine a situation where your organization has multiple services, each with different endpoints. Managing these services and ensuring they all maintain a high level of performance can be a daunting task. You may also require your developers to use Checkly headless browser testing or screenshot features in development, staging, and other environments. You'd need to log in to the Checkly dashboard each time to set up or adjust monitoring configurations, a process that could become tedious and time-consuming, especially in large-scale environments.

The [Checkly Terraform provider](https://registry.terraform.io/providers/checkly/checkly/latest/docs) simplifies this process by allowing developers to automate the configuration and management of checks and alerts. Instead of manually configuring each check via the Checkly dashboard, developers can define them directly in their Terraform configurations. This means checks can be versioned, shared, and managed just like any other piece of infrastructure.

### Other SaaS Terraform Providers

-  [PagerDuty](https://registry.terraform.io/providers/PagerDuty/pagerduty/latest/docs): Developers benefit from the PagerDuty Terraform provider by being able to automate the set up and management of incident response procedures, providing a consistent, repeatable, and efficient way to manage complex operational environments.
-  [Salesforce](https://registry.terraform.io/providers/hashicorp/salesforce/latest/docs): The Salesforce Terraform provider allows administrators to programmatically manage Salesforce users. This provider is released by Hashicorp and may have been released to scratch their own itch while administering Salesforce, but it is a clear indication that Terraform has at least some usage outside of development teams.
-  [Fivetran](https://registry.terraform.io/providers/fivetran/fivetran/latest/docs): With the Fivetran Terraform provider, users can automate the set up and management of data connectors, allowing for easy and efficient integration of various data sources with their data warehouse in a version-controlled manner.
-  [GitHub](https://registry.terraform.io/providers/integrations/github/latest/docs): GitHub users benefit from its Terraform provider by being able to automate repository management, actions, teams, and more, streamlining workflows and improving efficiency across their development teams.

Admittedly, the lines between SaaS and infrastructure are blurred for some of these, but the examples above are only a fraction of what's available on the registry.

## Why Users Choose Terraform Over API Integration

All the SaaS platforms in our examples above have full-featured and well-documented APIs with accompanying SDKs. Chances are, if you're not using Terraform in your organization yet, you may come across some utility code in your repositories performing regular calls to one of these ubiquitous platforms' APIs.

We touched on a couple of examples where Terraform enables teams to configure services for use with different environments in the development lifecycle. This unlocks new use cases, and may even increase many users' spending after automation negates the labor cost of configuring ephemeral environments.

Furthermore, it seems the availability of good Terraform providers is already starting to factor into SaaS purchasing decisions.

Organizations that are audited as part of certification often have strict disaster recovery requirements. Terraform providers with full API coverage could enable these organizations to recover their SaaS configurations without any manual work.

This benefit also applies when organizations are required to keep track of configuration updates. If a SaaS platform does not have strict auditing built in, a client could use Terraform with version control, thereby creating an audit trail.

## Which SaaS Products Are Good Candidates for Terraform?

With the benefits we mentioned in mind, we can try to identify traits that would make a SaaS platform a suitable candidate for Terraform integration.

-  **Configurable resources:** SaaS platforms that offer configurable resources like users, roles, policies, projects, or servers are good candidates. If a resource's configuration can be described in code, it can be managed by Terraform.
-  **Multiple environments:** Platforms that need to maintain consistent configurations across multiple environments (like dev, test, staging, and production) are well-suited for Terraform, as it simplifies the creation and management of these environments.
-  **Frequent changes:** If your SaaS product requires frequent changes to its configuration, it may benefit from a Terraform provider. With its plan/apply cycle, Terraform allows users to preview changes before applying them, reducing the risk of unintentional modifications.
-  **Scaling needs:** SaaS platforms that need to manage resources at scale can also benefit from Terraform. It allows for managing many resources consistently and efficiently, reducing the risk of manual errors and inconsistencies.
-  **Automatable tasks:** If your platform's tasks can be automated via API calls, then a Terraform provider would be a good fit. Terraform excels in automating infrastructure management tasks and reduces the need for manual intervention.
-  **Security and compliance needs:** For SaaS platforms that need to enforce certain security configurations or compliance standards, Terraform can ensure these requirements are consistently met across all resources.
-  **Integrations with other cloud services:** If your SaaS platform frequently integrates with other cloud services, having a Terraform provider can make these integrations easier and more efficient by leveraging Terraform's extensive provider ecosystem.

Even if a SaaS platform doesn't check all these boxes, there might still be significant value in offering a Terraform provider, especially as Terraform's adoption is growing rapidly.

## What About Internal Tools and Interfaces?

Terraform providers are especially useful for building internal tools, where they provide your internal developers an AWS-like experience while managing internal resources.

By offering a Terraform provider to internal users, organizations can provide a consistent, standardized interface for managing internal resources. This standardization reduces the learning curve and complexity for developers, as they can use the same Terraform commands and concepts they're already familiar with from managing public cloud resources.

The benefits we mentioned earlier also apply to internal tools: Better collaboration, version control, reduced errors, and less time configuring services using manual interfaces.

## Why SaaS Companies Don't Publish Terraform Providers

Clearly, publishing a Terraform provider could benefit most SaaS providers, so why don't we see more companies maintaining Terraform providers for their APIs?

We won't mince words here: Publishing a Terraform provider is difficult.

Telling SaaS development teams to _“just publish a Terraform provider”_ would be misguided at best.

![If only it was as easy as drawing an owl](./assets/owl.jpg)

Developing and maintaining a Terraform provider requires a significant investment in terms of time, resources, and expertise. You need an in-depth understanding of the SaaS platform's API, the Terraform ecosystem, and the Go programming language.

Add to this the fact that many APIs change significantly over time. If an API changes frequently, it can require a significant effort to keep its Terraform provider up to date.

Even if creating and maintaining a provider is within a SaaS company's abilities, there might be hesitance to take on an additional support commitment. We understand that it could feel like you're adding another layer to an already complex problem and users will expect some manual help. We argue that the simplicity of HCL lends itself to much easier support engineering, as declarative configuration is simpler to lint automatically, read, debug, and rewrite.

Terraform is well suited for self-help users, as the documentation for Terraform providers is standardized and hosted by the registry. Nevertheless, some platforms such as LaunchDarkly choose to support Terraform integration only for users on pro or enterprise pricing tiers—presumably to offset anticipated support cost.

## Speakeasy Generates and Maintains Terraform Providers

With Speakeasy, you can generate a Terraform provider based on your OpenAPI spec. This means you don't need to be a Terraform expert or write any custom Go code. Speakeasy also makes sure your provider stays updated with your API by pushing a new branch to your provider's repository when your API spec changes.

To generate a Terraform provider, you map OpenAPI objects and operations to Terraform entities and actions by annotating your OpenAPI specification.

![Workflow diagram showing Speakeasy's Terraform generation](./assets/tf-workflow.png)

To get started, you can follow our [documentation on annotating your spec for the Terraform provider](/docs/create-terraform/extensions) generator.

After generating a provider, updating the provider becomes as straightforward as merging a PR from the update branch Speakeasy creates.

## Case Study: Airbyte Terraform Provider

On 22 June, [Airbyte launched their Terraform provider](https://airbyte.com/blog/terraform-provider-launched-for-airbyte-cloud) for Airbyte cloud users. The Airbyte [Terraform provider](https://registry.terraform.io/providers/airbytehq/airbyte/latest/docs) was generated by Speakeasy, based entirely on Airbyte's OpenAPI specification.

This release came after months of collaboration between Airbyte and Speakeasy, and we are delighted to have played a role in Airbyte's continued success.

> We looked for the best options in API tooling, so we didn’t have to build everything ourselves. We focus on what we do best: ensuring data is accessible everywhere it has value. For our API needs; we have Speakeasy.
>
> -- <cite>Riley Brook, Product @ Airbyte</cite>

Under the hood, the Airbyte Terraform provider uses a Go SDK generated by Speakeasy. Since the [generated provider is open source](https://github.com/airbytehq/terraform-provider-airbyte), we can take a look at what's in the repository.

We ran [Sloc Cloc and Code (scc)](https://github.com/boyter/scc/blob/master/README.md) on the repository and this is what we found:

```bash
$ scc terraform-provider-airbyte
```

| Language  | Files | Lines  | Blank | Comment | Code   | Complexity | Bytes    |
|-----------|------:|-------:|------:|--------:|-------:|-----------:|---------:|
| Go        | 3024  | 267623 | 35706 | 10727   | 221190 | 37484      | 9886221  |
| Markdown  | 240   | 17985  | 6760  | 0       | 11225  | 0          | 802305   |
| YAML      | 5     | 65577  | 8     | 24      | 65545  | 0          | 2170810  |
| JSON      | 1     | 6      | 0     | 0       | 6      | 0          | 83       |
| Makefile  | 1     | 9      | 3     | 0       | 6      | 0          | 138      |
| Terraform | 1     | 85     | 10    | 0       | 75     | 2          | 2106     |
| gitignore | 1     | 4      | 0     | 0       | 4      | 0          | 44       |
| Total     | 3273  | 351289 | 42487 | 10751   | 298051 | 37486      | 12861707 |

* Estimated Cost to Develop (organic) $10,705,339
* Estimated Schedule Effort (organic) 33.86 months
* Estimated People Required (organic) 28.09

Airbyte connects with more than 250 data sources and destinations, all with unique configuration parameters, which adds to this enormous Terraform provider.

Even if the scc estimation is off by a few orders of magnitude, it is clear that the Speakeasy Terraform provider generator saved Airbyte valuable development time and will continue to save time on maintenance in the future.

You can read more about [how Airbyte launched their SDKs and Terraform provider](/post/case-study-airbyte) on our blog.

## Summary

We believe that Terraform is poised to simplify SaaS configuration at scale and expect to see the continued growth of the Terraform registry.

However, navigating the Terraform ecosystem without deep expertise is daunting, and successfully publishing and maintaining a Terraform provider is no small undertaking.

Speakeasy is ready to help SaaS platforms expand their reach in this exciting ecosystem.

To get started with your Terraform provider, [follow our documentation](/docs/create-terraform).

[Join our Slack community](https://join.slack.com/t/speakeasy-dev/shared_invite/zt-1cwb3flxz-lS5SyZxAsF_3NOq5xc8Cjw) for expert advice on Terraform providers or get in touch to let us know how we can best help your organization.


 This is the content for the doc blog/building-php-sdks/index.mdx 

 ---
title: "How to Build an SDK in PHP"
description: "A detailed guide on how to build an SDK in PHP, including considerations for developer experience, designing resources, working with parameters, building HTTP requests, pagination, and more."
image: "/media/how-to-build-php-sdks.png"
date: 2024-05-01
authors:
  - name: Steve McDougall
  - image_url: '/media/author-headshots/steve.jpeg'
tags:
  - API Advice
featured_image: "/media/how-to-build-php-sdks.png"
---

import YouTube from 'react-youtube';

<div className="mt-10 flex justify-center items-center" >
  <YouTube
    videoId="O4xyEVSyS_s"
  />
</div>

The ability to streamline and simplify the integration process between systems is getting more and more invaluable. Everything, and I mean everything, is starting to come with its own API. If we want to implement new features, the chances are we will need to work with and external API of some description. Sometimes they offer SDKs, sometimes they don’t. The chances of them supporting your language, or framework, in the way that you need it …. Need I say more?

So learning how to build an SDK in PHP is a skillset you should definitely consider picking up. If you are building your own API and want people to use your service, you will want to provide an SDK for them to use.

In this tutorial, we are going to walk through the decisions you will take when designing an SDK in PHP:

- [What are we building](./building-php-sdks#what-are-we-building)
- [Thinking about Developer Experience](./building-php-sdks#thinking-about-developer-experience)
- [Designing our Resources](./building-php-sdks#designing-our-resources)
- [Working with Parameters](./building-php-sdks#working-with-query-parameters)
- [Building our HTTP Request](./building-php-sdks#building-our-http-request)
- [PSR-18 and sending HTTP Requests](./building-php-sdks#psr-18-and-sending-http-requests)
- [Working with Responses](./building-php-sdks#working-with-responses)
- [Pagination](./building-php-sdks#pagination)
- [Sending data through our SDK](./building-php-sdks#sending-data-through-our-sdk)
- [Summary](./building-php-sdks#summary)

There are many ways to skin a cat, I mean build an SDK. One of the first questions you need to answer is how much opinionation you want to bake into your SDK at the expense of flexibility. My approach will be unopinionated about dependencies, but more opinionated when it comes to the architecture and implementation. That’s because dependencies can be a sticking point for a lot developers, who may feel strongly about Guzzle vs. Symfony or have strict procedures in place for external dependencies. We want to ensure maximum compatibility with the PHP ecosystem. So we need to learn how to build SDKs that work no matter what. Now, let’s walk through how we might go about building an SDK.

## What are we building?

We are going to be building an SDK for a fictional e-commerce start up. The primary focus for their API is to allow their customers to sell products. Quite a common use case I am sure we can all agree.

When it comes to building an SDK, the first thing you want to think about is access. What do you want to enable access to, what resources are going to be available, and how should this work. Do we want full access? Do we want partial access, maybe read only access? This is typically tied directly to the abilities of your API.

For the SDK we are going to build, we want to be able to do the following:

- List all products, allowing the filtering and sorting of results.
- List a customers order history, and understanding the status of each order.
- Allowing customers to start creating an order, and progressing it to payment.
- Generate invoices for orders.

We won’t be handling any payment intents or actual payments in our fictional API, as there are enough payment providers out there already.

At this point we want to start thinking about the configurable options that we might have in our SDK. We can pull out the resources from the list above with relative ease. We will then need an authentication token to be passed in so that our SDK can be authorized to perform actions for us. We will also want some level of store identifier, which will indicate a specific customer’s account. How the API is set up, will depend on how the store identification works. We could use a subdomain identifier for our store, a query parameter, or a header value. It depends on how the API has been implemented. For this let’s assume we are using the subdomain approach, as it is the most common method I have seen.

## Thinking about Developer Experience

The DX is something that is important, frustrations with an SDK is the quickest way to lose the adoption you are trying to grow. Bad developer experience signals to developers that your focus isn’t on making their lives easier.

Some common things you should focus on that I find works well for developer experience are:

- Ensuring compatibility with as many implementations as possible
- Limiting third-party dependencies that could change behaviour, or break with updates
- Handling serialization effectively, nobody wants a JSON string to work with - they want objects
- Supporting pagination for paging through long result sets
- Providing programatic control over filtering query parameters,

This can tell us a lot about how to start our SDK, as we now know the parameters we need to pass to the constructor. The main thing we want to think about when it comes to our SDK, other than the core functionality, is developer experience.

So let’s start with some code, and I can walk you through the next steps:

```php
declare(strict_types=1);

namespace Acme;

final readonly class SDK
{
  public function __construct(
    private string $url,
    private string $token,
  ) {}
}
```

At this point we have an SDK class that we can use to start integrating with. Typically what I like to do is test the integration as I am building, to make sure that I am not going to be creating any pain points that I can solve early on.

```php
$sdk = new Acme\SDK(
  url: 'https://acme.some-commerce.com',
  token: 'super-secret-api-token',
);
```

This would typically be loaded in through environment variables and dependency injection, so we wouldn’t construct the SDK directly very often. However, we cannot rely on the assumptions here. In Laravel this would be declared in the following way:

```php
final class IntegrationServiceProvider extends ServiceProvider
{
  public function register(): void
  {
    $this->app->singleton(
      abstract: Acme\SDK::class,
      concrete: fn () => new Acme\SDK(
        url: config('services.commerce.url'),
        token: config('services.commerce.token'),
      ),
    );
  }
}

```

We should always test this too, I know I know, why test a constructor? Honestly, it is more of a habit right now than anything. Getting into the practice of testing your code is never a bad thing!

```php
it('can create a new sdk', function (): void {
  expect(
    new Acme\SDK(
      url: 'https://acme.some-commerce.com',
      token: 'super-secret-api-token',
    ),
  )->toBeInstanceOf(Acme\SDK::class);
});
```

As you can see here, I am using Pest PHP for testing. It’s less verbose and I think it’s actually fun to write! I find if you enjoy how you write tests, you are more likely to actually write the tests themselves.

## A Note on Authentication

In the example above you’ll notice that I am assuming that you will provide API Tokens for your users to use for their integrations. However, when it comes to APIs there are multiple options available. What is best depends on your usage patterns. You could use OAuth, HTTP Basic, API Token, or Personal Access Tokens. Each option has its benefits, depending on what you need to achieve and what you are providing.

A great example use case of something like OAuth would be if your API or service is designed to be tightly controlled. The implementation is something that you do not want to share credentials with directly, instead you want to proxy the control of this to the service you are authenticating with, which then provides an Access Token that the SDK/implementation can use on the users behalf.

Using HTTP Basic auth is something you see less and less of these days. It used to be extremely popular with government services, where you use you credentials directly to have access remotely. The core principle here is that the application doesn’t care if it is a first or third party, they should all have the same level of control and access.

That leaves API Tokens or Personal Access Tokens. This is my preferred method of authentication. You, as a user, create an API token that you want to use to gain access to the API. You can scope this to specific abilities and permissions, which then allows you to do exactly what you need nothing more. Each token is typically tied directly to a user, or entity. Using this token then also ties any actions you are trying to take directly to the entity the token belongs to. You can quickly and easily revoke these tokens, and you can cascade the deletion of the entity out to the tokens themselves. This is very similar to OAuth, but without as many hoops which makes it a great choice - at least until you actually need OAuth of course.

## Designing our Resources

From our testing above, we know the instantiation works. What’s next? Up to this point we have thought about the developer experience, and figured out how we want users to authenticate the SDK. Next we want to start defining the interface for our resources, starting with the Product resources. How I imagine this working is the following:

```php
$sdk->products()->list(); // this should return a collection of products
$sdk->products()->list('parameters'); // We should be able to filter based on parameters
```

To start building the Product resource out properly, we want to understand the potential options that we will be able to filter based on but also sorting. Personally I like enums for some of this, as it makes the most sense. Using an Enum allows you to tightly control what would be floating constants in your source code, it also gives you control over potential typos from the end user.

```php
enum Sort: string
{
  case Price = 'price';
  case Age = 'created_at';
  // other options you may want to sort on...
}
```

This would be used like the following:

```php
$sdk->products()->list(
  sort: Sort::price,
  direction: 'desc|asc',
);
```

This allows us to easily sort programmatically, giving as much control to the person implementing your SDK as possible.

## Working with Query Parameters

So, filtering. Filtering is an interesting one. There are a few different approaches that we could take here, with no clear winner. The option I personally like is passing in a list of filters to iterate over:

```php
$sdk->products()->list(
  filters: [
    Filter::make(
      key: 'brand',
      value: 'github',
    ),
  ],
);
```

This allows us to programmatically build up our request exactly as we want it. In theory this is perfect, how about in practice though? Is this going to cause frustrations?

```php
final readonly class IndexController
{
  public function __construct(
    private SDK $sdk,
    private Factory $factory,
  ) {}

  public function __invoke(Request $request): View
  {
    $products = $this->sdk->products();

    $sort = [];
    if ($request->has('sort')) {
      $sort['on'] = Sort::from(
        value: $request->string('sort')->toString(),
      );

      $sort['direction'] = $request->has('direction')
        ? $request->string('direction')->toString()
        : 'desc';
    }

    $filters = [];

    if ($request->has('filters')) {
      foreach ($request->get('filters') as $filter) {
        $filters[] = Filter::make(
          key: $filter['key'],
          value: $filter['value'],
        );
      }
    }

    try {
      $response = $products->list(
        filters: $filters,
        sort: $sort['sort'] ?? null,
        direction: $sort['direction'] ?? null,
      );
    } catch (Throwable $exception) {
      throw new ProductListException(
        message: 'Something went wrong fetching your products.',
        previous: $exception,
      );
    }

    return $this->factory->make(
      view: 'pages.products.index',
      data: [
        'products' => $response,
      ],
    );
  }
}
```

So, this isn’t perfect. We start by getting the products resource from the SDK, then process our request to programmatically change how we want to send the request to the API. Now, this is ok, but it is very long winded, which opens it up for issues and user error. We want to control things a little tighter, while still providing that flexibility. It does give me the approach I want and need to get exactly the data I want, but in a way that I personally wouldn’t want to have to use. In reality this would have been wrapped in a Service class to minimize breaking changes.

If we go with this approach, we can now start implementing the resource itself.

```php
final readonly class ProductResource
{
  public function __construct(
    private SDK $sdk,
  ) {}

  public function list(array $filters = [], null|Sort $sort = null, null|string $direction = null): Collection
  {
    // build initial request
    // build up request with filters and sorting
    // send request
    // capture response
    // throw error if response failed
    // return transformed response as a collection
  }
}
```

For now I am just commenting the steps here, because we’ll be stepping through each of these parts one by one.

## Building our HTTP Request

Building up the initial request. We want to make sure that we aren’t making any decisions for the user when it comes to their HTTP client. Luckily there is a PSR for that ([PSR-17](https://www.php-fig.org/psr/psr-17/)), which also allows us to leverage auto-discovery.

All of our resources are going to be required to create requests to send. We could either create an abstract resource, or a trait. I personally prefer composition over inheritance, so I would typically lean towards a trait here. The main benefit of composition is that we know that each resource is going to implement similar functionality - however, if we need tighter control over just one thing we can partially pull in a trait or simply not use it. Also, when it comes to testing, testing traits is a lot easier than testing abstract classes.

```php
trait CanCreateRequests
{
  public function request(Method $method, string $uri): RequestInterface
  {
    return Psr17FactoryDiscovery::findRequestFactory()->createRequest(
      method: $method->value,
      uri: "{$this->sdk->url()}/{$uri}",
    );
  }
}
```

This trait allows us to access the discovered Request Factory that implements PSR-17, to then create a request using a passed in method and url. The method here is a simple Enum that allows programatic choice of method, instead of using static variables like `GET` or `POST`.

As you can see we need to extend our base SDK class right now, to provide accessors to the private properties of `url` and later on `token`.

```php
final readonly class SDK
{
  public function __construct(
    private string $url,
    private string $token,
  ) {}

  public function url(): string
  {
    return $this->url;
  }

  public function token(): string
  {
    return $this->token;
  }
}
```

The first step is done, we can now create the request we need to so that we can build the request as required. The next step is to add the trait to the resource class, so we can implement the required logic.

```php
final readonly class ProductResource
{
  use CanCreateRequests;

  public function __construct(
    private SDK $sdk,
  ) {}

  public function list(array $filters = [], null|Sort $sort = null, null|string $direction = null): Collection
  {
    $request = $this->request(
      method: Method::GET,
      uri: '/products',
    );

    // build up request with filters and sorting
    // send request
    // capture response
    // throw error if response failed
    // return transformed response as a collection
  }
}
```

As you can see from the above, to build the request all we need to do is interact with the trait we have created. This will use the PSR-17 factory discovery to find the installed Request Factory, and create the request based on the parameters we sent through. The chances are that we will want to build up our requests in a lot of our resources, so we will need to extend our trait.

```php
trait CanCreateRequests
{
  public function request(Method $method, string $uri): RequestInterface
  {
    return Psr17FactoryDiscovery::findRequestFactory()->createRequest(
      method: $method->value,
      uri: "{$this->sdk->url()}/{$uri}",
    );
  }

  public function applyFilters(RequestInterface $request, array $filters): RequestInterface
  {
    foreach ($filters as $filter) {
      // now we need to work with the filter itself
    }
  }
}
```

But, before we work with the filters on the request we need to understand the options for the filters. They are using query parameters to build the query parameters, which is supported in PSR-7. Let’s look at the filter class, and add a method for working with the filters.

```php
final readonly class Filter
{
  public function __construct(
    private string $key,
    private mixed $value,
  ) {}

  public function toQueryParameter(): array
  {
    return [
      $this->key => $this->value,
    ];
  }

  public static function make(string $key, mixed $value): Filter
  {
    return new Filter(
      key: $key,
      value: $value,
    );
  }
}
```

We just need a way to take the content passed into the filter class, and turn it into an array that we can work with.

```php
trait CanCreateRequests
{
  public function request(Method $method, string $uri): RequestInterface
  {
    return Psr17FactoryDiscovery::findRequestFactory()->createRequest(
      method: $method->value,
      uri: "{$this->sdk->url()}/{$uri}",
    );
  }

  public function applyFilters(RequestInterface $request, array $filters): RequestInterface
  {
    $parameters = $request->getQueryParameters();

    foreach ($filters as $filter) {
      $parameters = array_merge($parameters, $filter->toQueryParameter());
    }

    return $request->withQueryParameters($parameters);
  }
}
```

In the snippet above, we are extracting the query parameters that may already be in place on our request, then merging them with the passed through filter query parameters, before returning back our modified request. A thing to note here is that the PSR-7 request is typically immutable by default, so you need to make sure that your logic is applied in the way that you expect.

```php
final readonly class ProductResource
{
  use CanCreateRequests;

  public function __construct(
    private SDK $sdk,
  ) {}

  public function list(array $filters = [], null|Sort $sort = null, null|string $direction = null): Collection
  {
    $request = $this->request(
      method: Method::GET,
      uri: '/products',
    );

    $request = $this->applyFilters(
      request: $request,
      filters: $filters,
    );

    // send request
    // capture response
    // throw error if response failed
    // return transformed response as a collection
  }
}
```

We can now work on sending the request, and how we might want to achieve that using PSRs too.

## PSR-18 and sending HTTP Requests

We’ve already seen PSR-17, but how about [PSR-18](https://www.php-fig.org/psr/psr-18/). It allows a level of interoperability between HTTP clients, so that you aren’t stuck using Guzzle v7.0 or Symfony HTTP Client. Instead, like all good software, you build your implementation to an interface and rely on dependency injection or similar to tell the application exactly what should be used when resolving the interface. This is clean, very testable, and great for building PHP code that isn’t going to break from a random `composer update`.

How can we implement it though? It can be pretty confusing to try and implement PSRs on their own, the documentation is aimed at library authors who are typically used to reading specification documents. Let’s look at a quote from the specification so you can understand what I mean.

> Note that as a result, since [PSR-7 objects are immutable](https://github.com/php-fig/fig-standards/blob/master/accepted/PSR-7-http-message-meta.md#why-value-objects), the Calling Library MUST NOT assume that the object passed to `ClientInterface::sendRequest()` will be the same PHP object that is actually sent. For example, the Request object that is returned by an exception MAY be a different object than the one passed to `sendRequest()`, so comparison by reference (===) is not possible.
>

Now if you read it, it makes sense! But if you are trying to build against it, along with other PSRs - things can get complicated quickly as the rules pile up in-front of you. This is why we use a library such as [PHP HTTP](https://docs.php-http.org/en/latest/), which allows us to auto-discover everything that we need.

Using this library, we are able to discover the HTTP client installed and use it directly. However, I prefer (and recommend) a different approach. The [PHP-HTTP library](https://docs.php-http.org/en/latest/) offers a Plugin Client that we can use. This offers more of a composable approach to building up our HTTP client. Let’s look at how we can use this in isolation before how we might implement this into our SDK.

```php
use Http\Discovery\HttpClientDiscovery;
use Http\Client\Common\PluginClient;

$client = new PluginClient(
  client: HttpClientDiscovery::find(),
  plugins: [],
);
```

So, our plugin client will use the discovered client, but also accept an array of plugins the can be applied on each request. You can see all of the requirements for this [here](https://docs.php-http.org/en/latest/plugins/introduction.html) but I will walk you through a standard approach that I like to use:

```php
use Http\Discovery\HttpClientDiscovery;
use Http\Client\Common\PluginClient;
use Http\Client\Common\Plugin\AuthenticationPlugin;
use Http\Client\Common\Plugin\ErrorPlugin;
use Http\Client\Common\Plugin\RetryPlugin;
use Http\Message\Authentication\Bearer;

$client = new PluginClient(
  client: HttpClientDiscovery::find(),
  plugins: [
    new RetryPlugin(),
    new ErrorPlugin(),
    new AuthenticationPlugin(
      authentication: new Bearer(
        token: 'YOUR_API_TOKEN',
      ),
    ),
  ],
);
```

You can add as many plugins as you need here, there are cache plugins, history plugins, decoding plugins. The list goes on, and is well documented in case you want to build your own plugins. But retry, errors, and authentication is a good list to start with.

Now we know how to build it, we can look at how we might want to implement this. All of our resources are going to want to send requests. But, we don’t want to overload them with traits. To me, the perfect place for this is on the client itself.

```php
final class SDK
{
  public function __construct(
    private readonly string $url,
    private readonly string $token,
    private array $plugins = [],
  ) {}

  public function withPlugins(array $plugins): SDK
  {
    $this->plugins = $plugins;

    return $this;
  }

  public function url(): string
  {
    return $this->url;
  }

  public function token(): string
  {
    return $this->token;
  }
}
```

First we need to start by removing the `readonly` from the class, and add it to the `url` and `token` properties. The reason for this is because our plugins property that we need to add, we want to be able to override, or at least have the option to should we need to. As this will be your SDK, we can customize this a little past this point.

```php
final class SDK
{
  public function __construct(
    private readonly string $url,
    private readonly string $token,
    private array $plugins = [],
  ) {}

  public function withPlugins(array $plugins): SDK
  {
    $this->plugins = array_merge(
      $this->defaultPlugins(),
      $plugins,
    );

    return $this;
  }

  public function defaultPlugins(): array
  {
    return [
      new RetryPlugin(),
      new ErrorPlugin(),
      new AuthenticationPlugin(
        new Bearer(
          token: $this->token(),
        ),
      ),
    ];
  }

  public function url(): string
  {
    return $this->url;
  }

  public function token(): string
  {
    return $this->token;
  }
}
```

Our final step is to have a way to get and override the client that will be used to send all of the HTTP requests. At this point our client is getting pretty big, and people using our SDK may want to implement their own approach. It is important that we avoid making too many decisions for our users. The best way to achieve this, as always, is to code to an interface. Let’s design that now:

```php
interface SDKContract
{
  public function withPlugins(array $plugins): SDKContract;

  public function defaultPlugins(): array;

  public function client(): ClientInterface;

  public function setClient(ClientInterface $client): SDKContract;

  public function url(): string;

  public function token(): string;
}
```

Let’s focus in on our two new methods:

```php

final class SDK implements SDKContract
{
  public function __construct(
    private readonly string $url,
    private readonly string $token,
    private ClientInterface $client,
    private array $plugins = [],
  ) {}

  public function client(): ClientInterface
  {
    return new PluginClient(
      client: HttpClientDiscovery::find(),
      plugins: $this->defaultPlugins(),
    );
  }

  public function setClient(ClientInterface $client): SDKContract
  {
    $this->client = $client;

    return $this;
  }
}
```

Our `client` method will return a new Plugin Client, using HTTP discovery to find the client we have installed, also attaching the plugins that we want by default. But, how about if our users want to add additional plugins? How would this look in Laravel?

```php
final class AppServiceProvider extends ServiceProvider
{
  public function register(): void
  {
    $this->app->singleton(
      abstract: SDKContract::class,
      concrete: fn () => new SDK(
        url: config('services.commerce.url'),
        token: config('services.commerce.token'),
        client: new PluginClient(
          client: HttpClientDiscovery::find(),
        ),
        plugins: [
          new CustomPlugin(),
        ],
      ),
    );
  }
}
```

## Working with Responses

At this point we are able to send the requests we need - at least for GET requests so far. Next, we want to look at how we receive and process the response data itself. There are two different approaches you could take when it comes to handling responses coming back from your API.

- Return the PSR-7 Response directly
- Transform the response into a Data Transfer Object.

There are benefits to each approach, however it mostly depends on the purpose of the SDK. If you want a completely hands free approach, then working with Data Transfer Objects is my recommended approach. Providing strongly typed, contextual objects that your customers can use to work with the data as required. The other option is of course to allow the clients to transform the response, as they see fit.

At this point we need to think back to what this SDK is for. This is an SDK that allows people to integrate with their online stores, so you want to be able to give as much freedom on implementation as possible. However for the purpose of education, let’s show how we might transform this response data anyway.

The way we do this in PHP is by designing our class, and hydrating this as we get the response. A fantastic resource for this is a package called [Serde](https://github.com/Crell/Serde) by a member of PHP-FIG, [Crell](https://github.com/Crell). Another option is to use [Object Mapper](https://github.com/thephpleague/object-mapper) which is by The PHP League. Both libraries offer a very similar functionality, the choice is more down to your personal preference. Our first step is to design the class we want to hydrate, this will typically match your API response.

```php
final readonly class Product
{
  public function __construct(
    public string $sku,
    public string $name,
    public string $description,
    public int $price,
  ) {}
}
```

This assumes that any routing is using the `sku` to lookup the product. The way I like to use these objects is to add a static method that will hydrate the class. The reason for this is because it keeps all logic about creating the object is contained within the class it is creating. There is no looking around for what class does what, it is all in one place.

```php
final readonly class Product
{
  public function __construct(
    public string $sku,
    public string $name,
    public string $description,
    public int $price,
  ) {}

  public static function make(array $data): Product
  {
    $mapper = new ObjectMapperUsingReflection();

    return $mapper->->hydrateObject(
      className: self::class,
      payload: $data,
    );
  }
}
```

As you can see, this is a neat bundle that will allow you to just send data to the class and receive the object back in a uniform way. How does this look in our SDK?

```php
final readonly class ProductResource
{
  use CanCreateRequests;

  public function __construct(
    private SDK $sdk,
  ) {}

  public function list(array $filters = [], null|Sort $sort = null, null|string $direction = null): Collection
  {
    $request = $this->request(
      method: Method::GET,
      uri: '/products',
    );

    $request = $this->applyFilters(
      request: $request,
      filters: $filters,
    );

    try {
      $response = $this->sdk->client()->sendRequest(
        request: $request,
      );
    } catch (Throwable $exception) {
      throw new FailedToFetchProducts(
        message: 'Failed to fetch product list from API.',
        previous: $exception,
      );
    }

    return new Collection(
      collectionType: Product::class,
      data: array_map(
        callback: static fn (array $data): Product => Product::make(
          data: $data,
        ),
        array: (array) json_decode(
          json: $response->getBody()->getContents(),
          associative: true,
          flags: JSON_THROW_ON_ERROR,
        ),
      ),
    );
  }
}
```

This attempts to send the request, and catches any potential exceptions. We then throw a contextual exception so that if anything does go wrong, we capture it and understand exactly what and where things broke. We then return a collection of Products, by mapping over the json response as an array. We are using the [Collection](https://github.com/ramsey/collection) library that is built by [Ben Ramsey](https://github.com/ramsey) here, not the Laravel one. We *could* just return an array, but I find it useful if you are going to go to the effort of returning objects, wrapping them in something with additional developer experience is a huge plus.

## Pagination

At some point you will need to make a decision about how you want to handle pagination - if at all. Let’s walk through the options, and figure out the what why and hows for paginating your API requests in your SDK.

The first option that most developers reach for is the `do while` approach. Which you add a do while loop within your code to just crawl the API endpoint until you get to the end of the paginated data - and then return the response. Personally I do not like this approach as it makes a few too many decisions for you. What if you don’t want to fetch all of the data, and just want to first page?

Next up, the paginator class. This will do almost the same as the do while approach, but instead you wrap the SDK call inside a pagination class which will handle the looping for you. This is a little better, as you aren’t mixing the HTTP calls with client intended logic. However to achieve this, you need to add a way to work with pages within your methods.

Finally, the programmatic approach. Much like the paginator class, your method will just accept a nullable page parameter which will request the specific page you actually want. Personally, I like this approach the most. If the client wants to paginate over the data, they have the ability to - without me forcing them into my way of doing it. Let’s have a look at a quick example.

```php
final readonly class ProductResource
{
  use CanCreateRequests;

  public function __construct(
    private SDK $sdk,
  ) {}

  public function list(
    array $filters = [],
    null|Sort $sort = null,
    null|string $direction = null,
    null|int $page = null,
  ): Collection {
    $request = $this->request(
      method: Method::GET,
      uri: '/products',
    );

    $request = $this->applyFilters(
      request: $request,
      filters: $filters,
    );

    if (null !== $page) {
      $request = $request->withQueryParameters([
        'page' => $page
      ]);
    }

    // send request
    // capture response
    // throw error if response failed
    // return transformed response as a collection
  }
}
```

If we pass through a page, we want to make sure we include it in the query parameters being sent over to the API. Your pagination may be different, for example you may use cursor pagination which will require you to pass over a specific hash. Yes the method parameters are getting long, but they all serve a purpose for control. Whoever said methods shouldn’t have more than 3 arguments has never built an SDK before.

On the client side, this is now simple to work with:

```php
$products = $sdk->products()->list(
  page: 1,
);
```

You could even wrap this in your own pagination class or provide a dedicated one with your SDK should you need it. I will show a quick high level interface so you know how this would be structured.

```php
interface Paginator
{
  public function fetch(SDK $sdk, string $method, array $parameters = []): Generator;

  public function hasNext(): bool;
}
```

Now, let’s look at an implementation:

```php
final class Pagination implements Paginator
{
  public function __construct(
    private readonly int $perPage,
    private array $pagination = [],
  ) {}

  public function fetch(SDK $sdk, string $method, array $parameters = []): Generator
  {
    foreach ($this->fetch($sdk, $method, $parameters) as $value) {
      yield $value;
    }

    while ($this->hasNext()) {
      foreach ($this->fetchNext() as $value) {
        yield $value;
      }
    }
  }

  public function hasNext(): bool
  {
    return $this->pagination['next'] !== null;
  }

  private function get(string $key): array
  {
    $pagination = $this->pagination[$key] ?? null;

    if ($pagination === null) {
      return [];
    }

    // Send the request and get the response.

    $content = ResponseMediator::getContent($response);

    if (! \is_array($content)) {
      throw new RuntimeException('Pagination of this endpoint is not supported.');
    }

    $this->postFetch();

    return $content;
  }

  private function postFetch(): void
  {
    // Get the last request from the SDK Client.
    $this->pagination = $response === null
      ? []
      : ResponseMediator::getPagination($response);
  }
}
```

You do of course so something a little simpler if you need to, but in general this should work for you. The Response Mediator class is a utility class that I would sometimes use to simplify the working with API data. Let’s move onto how we might actually send some requests now though.

## Sending Data through our SDK

One of the final stepping stones to building a good SDK, is figuring out how we want to create and update potential resources. In our example of an e-commerce API, the likelihood of creating a product object via API is extremely low. Typically you would use a provided admin dashboard. So, for this next example we are going to focus on the Customer resource. When a user registers through your platform, you want to create a customer resource on the e-commerce API, so that if the authenticated user orders anything - they will be able to link to the correct customer quickly and easily. We will look at creating a new customer next.

There are a few options, as always, when creating resources through an SDK. You can either:

- Send a validated array through to the SDK
- Send another Data Transfer Object specific to the request through to the SDK

My personal preference here is to use DTOs and then let the SDK handle sending this in the correct format. It allows a more strongly typed approach, and puts all of the control in the hands of the SDK - which minimizes potential risk.

```php
final readonly class CreateCustomer
{
  public function __construct(
    public string $name,
    public string $email,
    public string $referrer,
  ) {}

  public static function make(array $data): CreateCustomer
  {
    $mapper = new ObjectMapperUsingReflection();

    return $mapper->->hydrateObject(
      className: self::class,
      payload: $data,
    );
  }
}
```

Just like the Product DTO, we add a static make method using the object mapper to create the object itself. Let’s now design the resource.

```php
final readonly class CustomerResource
{
  use CanCreateRequests;

  public function __construct(
    private SDK $sdk,
  ) {}

  public function create(CreateCustomer $customer)
  {
    $request = $this->request(
      method: Method::POST,
      uri: '/customers',
    );

    // attach the customer as a stream.
  }
}
```

We now need to work with our trait again, so that we can work with sending and using data.

```php
trait CanCreateRequests
{
  // Other method...

  public function attachPayload(RequestInterface $request, string $payload): RequestInterface
  {
    return $request->withBody(
      Psr17FactoryDiscovery::findStreamFactory()->createStream(
        content: $payload,
      );
    );
  }
}
```

What we are doing here is passing through the request we are building, and the stringified version of the payload. Again, we can use auto-discovery to detect what HTTP Stream Factory is installed, then create a stream from the payload and attach it to the request as its body.

We need a way to quickly and easily serialize the data from our DTOs to send through to create a stream. Let’s look at the DTO for creating a customer again.

```php
final readonly class CreateCustomer
{
  public function __construct(
    public string $name,
    public string $email,
    public string $referrer,
  ) {}

  public function toString(): string
  {
    return (string) json_encode(
      value: [
        'name' => $this->name,
        'email' => $this->email,
        'referrer' => $this->referrer,
      ],
      flags: JSON_THROW_ON_ERROR,
    );
  }

  public static function make(array $data): CreateCustomer
  {
    $mapper = new ObjectMapperUsingReflection();

    return $mapper->->hydrateObject(
      className: self::class,
      payload: $data,
    );
  }
}
```

Now let’s go back to the implementation.

```php
final readonly class CustomerResource
{
  use CanCreateRequests;

  public function __construct(
    private SDK $sdk,
  ) {}

  public function create(CreateCustomer $customer)
  {
    $request = $this->request(
      method: Method::POST,
      uri: '/customers',
    );

    $request = $this->attachPayload(
      request: $request,
      payload: $customer->toString(),
    );

    try {
      $response = $this->sdk->client()->sendRequest(
        request: $request,
      );
    } catch (Throwable $exception) {
        throw new FailedToCreateCustomer(
          message: 'Failed to create customer record on the API.',
          previous: $exception,
        );
    }

    // Return something that makes sense to your use case here.
  }
}
```

So, we can quickly and easily create and send data. A typical usage of this in a Laravel application, would be to leverage the events system - listening for something like the `Registered` event to be fired:

```php
final readonly class CreateNewCustomer
{
  public function __construct(
    private SDK $sdk,
  ) {}

  public function handle(Registered $event): void
  {
    try {
      $this->sdk->customers()->create(
        customer: CreateCustomer::make(
          data: [
            'name' => $event->name,
            'email' => $event->email,
            'referrer' => $event->referrer,
          ],
        ),
      );
    } catch (Throwable $exception) {
      Log::error('Failed to create customer record on API', ['event' => $event]);
      
      throw $exception;
    }
  }
}
```

Quite clean and easy to use I am sure you would agree. The only improvement I would potentially suggest here is to use a dispatchable job or event-sourcing style system here, something that would allow you to replay the attempt - giving you the opportunity to fix and retry.

## Summary

As you can see from this tutorial, building an SDK for your API isn’t overly tricky - but there are a lot of things to think about. With developer experience being a key factor in the success of your SDK, you need to make sure you think about that alongside the technical requirements that your SDK has.

At Speakeasy we have carefully designed how SDKs should work in each language we support, allowing you to follow a similar approach to the above without having to write a single line of code. Instead it will use your OpenAPI specification to generate a robust, well tested, and developer friendly SDK for your API. Even better, it will take less time than waiting for a pizza delivery. Now, I have always been against auto-generated SDKs, especially when you see some of the examples out there. However, what Speakeasy does is a completely different approach that guarantees better success and developer experience. Instead you can focus on building the best API and OpenAPI specification you can - and let us focus on providing you with a great SDK in multiple languages.


 This is the content for the doc blog/categories/[category].mdx 

 ---
title: "Blog"
description: "The Speakeasy Blog offers actionable advice for creating SDKs and Terraform providers from an OpenAPI / Swagger spec and tips on how to improve the developer experience of your API."
breadcrumb: false
---

import { Category, getStaticPaths as getCategoryStaticPaths, getStaticProps as getCategoryStaticProps } from '~/features/blog/category';

<Category />

export const getStaticPaths = getCategoryStaticPaths;
export const getStaticProps = getCategoryStaticProps;


 This is the content for the doc blog/choosing-your-framework-python/index.mdx 

 ---
title: "Choosing your Python REST API framework"
description: "We compare the most popular Python frameworks for building REST APIs."
image: "/media/choosing-your-framework-python.png"
date: 2024-12-09
authors:
  - name: Nolan Di Mare Sullivan
  - image_url: "/media/author-headshots/nolan.jpeg"
tags:
  - API Advice
featured_image: "/media/choosing-your-framework-python.png"
---

import { IconGrid } from "~/features/shared/recipes";
import { pickingAPythonFrameworkData } from "~/data/post/picking-a-python-framework";

We're fortunate to live in a time when a wide selection of Python API frameworks is available to us. But an abundance of choice can also be overwhelming. Do you go for the latest, trending option or stick with the tried-and-tested framework that offers security and control? 

Whether you're a startup founder who needs to deliver an MVP in a few weeks while taking scale and performance into consideration, or part of a large organization running hundreds of microservices needing reliable and robust technologies, choosing the right API framework is a critical decision. The key is recognizing that every framework choice involves trade-offs, which shift based on your project's unique needs. Failing to account for this can lead to frustration down the road.

In this post, we discuss the factors to consider when choosing a REST API framework and explores popular options, highlighting each framework's strengths and weaknesses. At the end of the article, we'll suggest a pragmatic approach you can take to make an informed decision.

<IconGrid {...pickingAPythonFrameworkData} />

## Factors to consider when choosing a Python API framework

### Iteration speed

For startups or fast-moving teams, the pressure to ship an MVP or new features quickly can outweigh concerns about the project's long-term architecture. But this short-term focus can lead to technical debt, making it harder to scale or adapt the API later. 

To strike the right balance between speed and maintainability, it helps to understand when speed is essential and when it's worth investing time in a more robust foundation. The solution lies in using tools that offer the flexibility to write code quickly while setting aside some initial scalability or performance concerns, with the option to refactor and evolve your architecture as your project grows.

Start with a simple, script-like setup for exposing endpoints without committing to a solid architecture upfront. Once the business is stable, you can take advantage of the framework's features to transition to a more complex and robust architecture.

### Enterprise needs: Scale and security

Your MVP has succeeded, and your project now serves a significant user base. Or maybe you're operating in an enterprise environment, building a service that must handle thousands or even millions of daily requests. While flexibility is still appealing at this stage, relying on tools that prioritize flexibility over structure is no longer wise. Instead, focus on well-structured frameworks designed to help with scalability, simplify complex processes, and abstract away the challenges introduced by your growing needs.

When choosing a framework for mature or large-scale projects, you need to consider:

- **Request volume:** The number of requests your application needs to handle.
- **Authorization:** How to manage user permissions securely and efficiently.
- **Database optimization:** Ensuring database queries are performant and scalable.
- **Logging:** Implementing proper logging for monitoring and debugging.
- **Performance:** Maintaining responsiveness under heavy traffic and load.

While lightweight frameworks can handle these challenges with careful implementation, your top priorities should shift to performance, robustness, and security.

When evaluating frameworks for these needs, consider these three critical factors:

- **Framework maturity and adoption:** A framework with wide industry adoption can be a sign of reliability. A strong community and long-standing development history often reflect a framework's stability and available support.
- **Security:** A framework with many built-in features may introduce security vulnerabilities. Assess the framework's history of handling security issues, its track record with security updates, and the quality of its documentation.
- **Robustness:** Evaluate the framework's architecture for its ability to abstract complex tasks effectively, ensuring scalability and maintainability over time.

### Async support

Asynchronous programming is known for its performance benefits, especially in non-blocking operations. For example, imagine an API that handles file uploads: The user doesn't need the upload to finish immediately or receive a download link right away. They just want confirmation that the process has started and that they'll be notified of its success or failure later. This is where async frameworks shine, allowing the API to respond without waiting for the file upload to complete.

Synchronous frameworks like Flask or Django can still handle asynchronous-like tasks using background job libraries like Celery paired with tools like Redis or RabbitMQ. While these frameworks have introduced partial async support in their architectures, they are not fully asynchronous yet. Background job solutions like Celery, Redis, and RabbitMQ are robust for task delegation, but they come with additional setup complexity and don't achieve proper non-blocking behavior within the API. 

Frameworks built with async programming in mind, like Tornado and FastAPI, provide a more intuitive coding experience for async tasks.

## Popular Python API frameworks

### Flask-RESTX: Familiar, lightweight, and flexible

Flask alone is sufficient to build a REST API. However, to add important REST API features like automatic Swagger documentation, serialization, and error handling, [Flask-RESTX](https://flask-restx.readthedocs.io/) offers tools that simplify additional parts of your workflow.

Here's an example that creates an application to list payments: 

```python app.py
from flask import Flask
from flask_restx import Api, Resource, fields

app = Flask(__name__)
api = Api(app, doc="/docs")  # Swagger UI documentation available at /docs

ns = api.namespace('payments', description="Payment operations")

payment_model = api.model('Payment', {
    'id': fields.Integer(description="The unique ID of the payment", required=True),
    'amount': fields.Float(description="The amount of the payment", required=True),
    'currency': fields.String(description="The currency of the payment", required=True),
    'status': fields.String(description="The status of the payment", required=True),
})

# Sample data
payments = [
    {'id': 1, 'amount': 100.0, 'currency': 'USD', 'status': 'Completed'},
    {'id': 2, 'amount': 50.5, 'currency': 'EUR', 'status': 'Pending'},
    {'id': 3, 'amount': 200.75, 'currency': 'GBP', 'status': 'Failed'},
]

@ns.route('/')
class PaymentList(Resource):
    @ns.marshal_list_with(payment_model)
    def get(self):
        return payments

api.add_namespace(ns)

if __name__ == "__main__":
    app.run(debug=True)
```

This code snippet creates an application that runs on port **5000** and provides two endpoints:

- `/payments`, for listing payments.
- `/docs`, for automatically documenting the payments endpoint.

The Flask-RESTX marshaling feature is noteworthy for how it automatically maps the results – whether from a database, file, or API request – to a defined schema and sends a structured response to the client. This functionality ensures consistency and reduces boilerplate code for formatting responses. 

The Flask ecosystem gives you the flexibility to create your application in the way that suits your needs. When the time comes to scale, Flask combined with [Flask-RESTX](https://flask-restx.readthedocs.io/) provides you with the features you need to handle larger, more complex projects effectively.

### Sanic: For lightweight and production-ready real-time APIs

Sanic (not to be confused with Sonic the Hedgehog, though it's just as speedy) is a lightweight, asynchronous Python web framework designed for high-performance and real-time applications. While these characteristics might suggest complexity, writing an application that serves both an HTTP endpoint and a WebSocket server is surprisingly straightforward.

```python app.py
from sanic import Sanic
from sanic.response import json

app = Sanic("ConfigAPI")

configs = {
    "app_name": "My App",
    "version": "1.0.0",
    "debug": True,
    "max_connections": 100,
    "allowed_hosts": ["localhost", "127.0.0.1"],
}


@app.get("/configs")
async def get_configs(request):
    return json(configs)


if __name__ == "__main__":
    app.run(host="127.0.0.1", port=8000, debug=True)
```

Sanic intuitively handles static files, making it a user-friendly alternative to popular frameworks like [Django, which can require more complex configurations for similar tasks](https://www.quora.com/Why-is-Django-making-handling-static-files-so-difficult).   

```python app.py
app = Sanic("ConfigAPI")

app.static('/static', './static')
```

Another point in Sanic's favor is its interesting approach to handling TLS, a process that can be complicated to understand and set up. With Sanic, you can start your server using your certificate files, or even better, let it automatically set up local TLS certificates, enabling secure access with little configuration. 

```bash
sanic path.to.server:app \--dev \--auto-tls
```

### FastAPI: Build modern and highly typed REST APIs

FastAPI's excellent developer experience has made it one of the most popular Python frameworks. By combining async programming, type hints, and automatic OpenAPI document generation, FastAPI enables you to create highly documented APIs with minimal effort.

FastAPI's design is also async-first, making it an excellent choice for real-time APIs, high-concurrency workloads, and systems needing rapid prototyping with built-in tools. FastAPI offers modern convenience and a healthy ecosystem of complementary tooling without compromising on performance. 

The following code example demonstrates creating a REST API for listing and creating invoices.

```python app.py
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import List

app = FastAPI()

class Invoice(BaseModel):
    id: int
    customer_uid: str
    amount: float
    status: str

# In-memory storage for invoices
invoices = [
    Invoice(id=1, customer_uid="4r3dd", amount=250.50, status="Paid"),
    Invoice(id=2, customer_uid="f3f3f3f", amount=150.00, status="Pending"),
]

@app.get("/invoices", response_model=List[Invoice])
async def list_invoices():
    return invoices
```

### Django REST framework

If what you care about is security, reliability, and maturity, [Django REST framework (DRF)](https://www.django-rest-framework.org/) is what you want. Django is the most mature Python framework and rose to prominence thanks to its abstractions of the tedious but essential parts of backend development: authentication, authorization, logging, multiple database connections, caching, testing, and much more. 

However, this abstraction comes with trade-offs. Django is not especially flexible or lightweight, and its enforced Model-View-Template (MVT) structure can feel verbose and rigid compared to more modern frameworks. However, if you embrace its design principles, Django can be one of the most stable and effective frameworks you've ever used.

When it comes to async support, DRF does not currently support async functionality. This limitation means you cannot create async API views or viewsets using DRF, as its core features – like serializers, authentication, permissions, and other utilities – are not designed to work asynchronously. 

Third-party package [ADRF (Async DRF)](https://github.com/em1208/adrf) adds async support, but it's not officially supported and may not be stable for production. That undermines the core value of Django REST framework: stability.

To create an API with DRF, you need to define a model first.   

```python models.py
from django.db import models

class Item(models.Model):
    name = models.CharField(max_length=255)
    description = models.TextField()
    price = models.DecimalField(max_digits=10, decimal_places=2)
    created_at = models.DateTimeField(auto_now_add=True)

    def __str__(self):
        return self.name
```

Then, you need to define a serializer that will convert the Python object retrieved from the Django ORM to a JSON object and vice versa.   

```python serializers.py
from rest_framework import serializers
from .models import Item

class ItemSerializer(serializers.ModelSerializer):
    class Meta:
        model = Item
        fields = ['id', 'name', 'description', 'price', 'created_at']
``` 
 
Next, you need to write a view (or in standard terms, controller) to handle the API logic, in this case, listing.

```python views.py
from rest_framework.generics import ListCreateAPIView
from .models import Item
from .serializers import ItemSerializer

class ItemListCreateView(ListCreateAPIView):
    queryset = Item.objects.all()
    serializer_class = ItemSerializer
```   

Finally, you need to register the view in a `urls.py` file.  

```python
from django.urls import path
from .views import ItemListCreateView

urlpatterns = [
    path('items/', ItemListCreateView.as_view(), name='item-list-create'),
]
```

This example illustrates how verbose Django can be. But by following its well-documented architecture, you ensure your application is robust and scalable while following proven design principles. 

### Tornado: Pure async logic

Tornado is a lightweight framework built entirely around asynchronous programming, making it ideal for building APIs where non-blocking I/O is critical, like WebSocket-based applications or systems with high-concurrency needs. If you don't have the immediate pressure of needing an extensive feature set or an existing ecosystem, Tornado can be an excellent choice for applications requiring pure async workflows.  

```python app.py
from tornado.ioloop import IOLoop
from tornado.web import Application, RequestHandler
import json

# In-memory storage
orders = []

# Handler to list all orders
class OrderListHandler(RequestHandler):
    async def get(self):
        self.set_header("Content-Type", "application/json")
        self.write(json.dumps(orders))

# Initialize the Tornado app
def make_app():
    return Application([
        (r"/orders", OrderListHandler),    # Endpoint to list all orders
    ])

if __name__ == "__main__":
    app = make_app()
    app.listen(8888)
    print("Server is running on http://127.0.0.1:8888")
    IOLoop.current().start()
```

However, Tornado lacks some of the built-in tools and abstractions found in more modern frameworks like FastAPI, meaning you might spend more time building features available out of the box elsewhere.

## Making pragmatic choices

The Python API frameworks we've discussed each have distinct strengths and trade-offs, but choosing the right framework for your project might still be a daunting task.

To help you select a framework, we've created a flowchart that simplifies the decision-making process and a table that maps use cases to recommended frameworks. To use these resources, start with the flowchart to narrow your options based on your project's stage, requirements, and priorities. Then, consult the table to match your use case and requirements to recommended frameworks. 

![A flowchart for choosing a Python framework](./assets/framework-decision-diagram.png)


| **Use case**                | **Requirements**                             | **Recommended frameworks**          |
|-----------------------------|---------------------------------------------|--------------------------------------|
| **MVP with limited resources** | Quick setup, simplicity, flexibility         | Flask-RESTX, FastAPI                      |
| **Complex project**          | Scalability, structure, robust tools         | Django + DRF                        |
| **Secure enterprise application** | Strong security, maintainability, scalability | Django + DRF                        |
| **Fully async workload**     | High concurrency, non-blocking performance   | FastAPI, Tornado                    |
| **Real-time application**    | WebSocket support, low latency               | Tornado, Sanic                      |
| **Existing project**         | Gradual migration to async or scaling needs  | Django (with ASGI), FastAPI         |

Consider:

1. What does your project need most — stability or speed?
2. Are you starting fresh or scaling an existing application?
3. Does the framework support your required features without adding unnecessary risk?  
4. How well does the framework align with your team's expertise?

If your team has extensive experience with one framework, that might be your go-to for creating a REST API. If stability, reliability, and enterprise-grade features are your priorities, then [Django REST framework (DRF)](https://www.django-rest-framework.org/) probably makes sense. If your priorities are a modern developer experience, performance, or emerging async capabilities, then a cutting-edge framework like **FastAPI** is a great choice.


 This is the content for the doc blog/contract-testing-with-openapi/index.mdx 

 ---
title: "Contract testing with OpenAPI"
description: "Learn how to implement contract testing with OpenAPI to ensure consistency across distributed systems and catch breaking changes early in development."
image: "/media/contract-testing-with-openapi.png"
date: 2024-09-30
authors:
  - name: Brian Flad
  - image_url: "/media/author-headshots/brian.jpg"
tags:
  - API Advice
featured_image: "/media/contract-testing-with-openapi.png"
---

import { ScrollyCoding } from "~/components/codehike/Scrollycoding";
import { Callout } from "~/components";

We've all heard that infernal phrase, "It works on my machine." Scaling any solution to work across many machines can be a challenge. The world of APIs with disparate consumers is no different. What if there was a well-defined contract between them?

But APIs and consumers change over time, which begs the question: How do we ensure our systems stick to their agreements? The answer is contract testing.

In this article, we'll explore contract testing, how it fits into the testing pyramid, and why it's important. We'll also walk through how to implement contract testing using OpenAPI, a popular API specification format.

Finally, we'll discuss how you can generate contract tests automatically using OpenAPI and Speakeasy.

## What is contract testing?

Contract testing verifies that two parties who interact via an API stick to the contract they agreed upon. We'll call these parties a consumer and a provider, based on the direction of the API calls between them. The consumer is the system that makes API calls, and the provider is the system that receives and responds to the API call.

In most cases, the contract between our parties is defined by an API specification, such as OpenAPI.

Even if there is no API specification, there is always, at the very least, an implicit agreement between the consumer and the provider. The consumer expects the provider to respond in a certain way, and the provider expects the consumer to send requests in a certain way.

This explicit or implicit agreement is the contract.

Contract testing, from the consumer's perspective, is about verifying that the provider sticks to the contract. From the provider's perspective, it's about verifying that the consumer sticks to the contract.

## How contract testing differs from unit testing, integration testing, and end-to-end testing

Testing strategy is often represented as a pyramid, with unit testing at the base, followed by other testing methodologies in ascending order of complexity and scope. The idea is that the majority of tests should be at the base of the pyramid, with fewer tests at each subsequent level.

The testing pyramid is a useful model for thinking about how different types of tests fit together in a testing strategy. It helps to ensure that the right types of tests are used in the appropriate proportions, balancing the need for comprehensive testing with the need for fast feedback.

<div className="mx-auto max-w-md">
  ![Testing pyramid showing unit testing at the base, followed by contract
  testing, integration testing, and end-to-end
  testing](./assets/testing-pyramid.svg)
</div>

Let's discuss each level of the pyramid in more detail, starting from the base.

### Unit testing: Does this function work as expected?

Unit testing forms the base of the testing pyramid. These tests focus on individual components or functions in isolation, typically mocking any dependencies. They are fast to run and easy to maintain, but don't test how components work together.

In the consumer's context, a unit test might verify whether the function that deserializes a JSON object into a Python object works correctly, without making any external API calls.

Unit tests are essential for catching bugs early in the development process and providing fast feedback to developers. They are also useful for ensuring that code behaves as expected when refactoring or adding new features. However, they don't provide much confidence that the system as a whole works correctly.

### Contract testing: Do we honor the API specification?

Moving up the pyramid, we have contract tests. Contract testing sits between unit testing and integration testing. It focuses specifically on the interactions between the provider and consumer for a given call, ensuring that the API contracts are honored. Contract tests are more complex than unit tests but less complex than integration tests.

A contract test verifies that a consumer can create requests with specific data and correctly handle the provider's expected responses or errors. This might be accomplished with mocked request or response data based on the contract. For example, an API contract test for an order creation endpoint might verify that request data correctly maps integer item IDs to quantities and that the response decodes to an expected success with an integer order ID.

Contract tests are useful for catching issues that arise when the consumer or provider strays from the agreed-upon contract. They provide a level of confidence that the system works as expected when the consumer and provider interact. They are also useful for catching breaking changes early in the development process.

### Integration testing: Do systems work together?

Further up, we find integration tests. These verify that different components of a system work together correctly. They are more complex than unit tests and contract tests, and may involve multiple components or services.

An integration test might verify that the consumer can successfully make an API call to the provider and receive a valid response. This test would involve both the consumer and provider, and would typically run in a test environment that mirrors the production environment.

Because integration tests involve multiple systems, they are useful for catching issues that arise when components interact, such as network issues between two services.

### End-to-end testing: Does the user flow work as expected?

At the top of the pyramid are end-to-end tests. These test the entire user flow and supporting systems from start to finish. They provide the highest level of confidence but are also the slowest to run and most difficult to maintain.

In our API context, an end-to-end test might involve making a series of API calls that represent a complete user journey, verifying that the system behaves correctly at each step. This could include creating a resource, updating it, retrieving it, and finally deleting it, all through the API.

When end-to-end tests fail, it can be challenging to identify the root cause of the failure, as the problem could be in any part of the system. Due to their complexity and cost, they are often used as a final check before deploying to production, rather than as part of the regular development process.

### Testing pyramid summary

Here's a summary of the different types of tests and how they compare:

| Aspect           | Unit testing     | Contract testing | Integration testing     | End-to-end testing |
| ---------------- | ---------------- | ---------------- | ----------------------- | ------------------ |
| Scope            | Functional logic | Interface logic  | Provider implementation | User journeys      |
| Speed            | Very fast        | Fast             | Moderate                | Slow               |
| Complexity       | Low              | Medium           | Medium to high          | High               |
| Isolation        | High             | Medium           | Low                     | Very low           |
| Typical quantity | Many             | Several          | Some                    | Few                |

## Why contract testing is important

Over time, APIs change in response to changing requirements, sometimes in subtle and imperceptible ways. For example, a provider may change the format of a field in a certain response from a string to an integer. This change may seem innocuous to the provider but could have catastrophic effects for the consumer.

Contract testing mitigates this risk by ensuring that any changes to the API contract are detected early in the development process. When the provider updates the API, corresponding contract tests will fail if the update is not backward compatible. This failure acts as an immediate signal that the change needs to be reviewed, preventing breaking changes from reaching production.

Consider this example: A subscription management platform (the provider) has an endpoint `/plan/{id}` that returns a subscription plan based on the plan ID. The consumer expects the response to include an `amount` field, which is an integer representing the cost of the plan. If the provider changes the `amount` field from an integer to a string, the consumer's contract test will fail, alerting the consumer to the breaking change.

In this example, a contract test would catch the breaking change early in the development process, before it reaches production. The consumer and provider can then work together to resolve the issue, ensuring that the API contract is honored.

## How to implement contract testing with OpenAPI

Let's walk through the process of implementing contract testing using [OpenAPI](/openapi/), focusing on both the consumer and provider perspectives.

### Step 1: Create a new project

We'll start by creating a new project for our consumer and provider code. We'll use a simple subscription management API as an example.

In the terminal, run:

```bash
mkdir contract-example
cd contract-example
```

Let's create a new TypeScript project for our SDK and tests:

In the terminal, run:

```bash
npm install --save-dev typescript
npx tsc --init
```

Select the default options when prompted.

### Step 2: Define the OpenAPI specification

We'll start by writing an OpenAPI specification for our API. In most cases, the provider will define the OpenAPI specification, as they are responsible for the implementation of the API.

<ScrollyCoding className="ch-scrollycoding-full-height ch-scrollycoding-force-focus-scroll" fullHeight>

## !!steps

Here's a basic example of an OpenAPI specification. Save it as `subscriptions.yaml` in the root of your project.

```yaml ! subscriptions.yaml
openapi: 3.1.0
info:
  title: Subscription Management API
  version: 1.0.0
servers:
  - url: http://127.0.0.1:4010
    description: Local server
tags:
  - name: subscription
    description: Subscription management
security:
  - api_key: []
paths:
  /plan/{id}:
    get:
      operationId: getPlanById
      tags:
        - subscription
      summary: Get a subscription plan by ID
      parameters:
        - name: id
          in: path
          required: true
          schema:
            type: integer
          examples:
            basic:
              value: 1
            premium:
              value: 2
      responses:
        "200":
          description: Successful response
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/Subscription"
              examples:
                basic:
                  value:
                    id: 1
                    name: "Basic"
                    amount: 100
                    currency: "USD"
                premium:
                  value:
                    id: 2
                    name: "Premium"
                    amount: 200
                    currency: "USD"
components:
  schemas:
    Subscription:
      type: object
      properties:
        id:
          type: integer
        name:
          type: string
        amount:
          type: integer
        currency:
          type: string
      example:
        id: 1
        name: "Basic"
        amount: 100
        currency: "USD"
  securitySchemes:
    api_key:
      type: apiKey
      name: X-API-Key
      in: header
```

---

## !!steps

This OpenAPI specification defines a single endpoint `/plan/{id}`.

```yaml ! subscriptions.yaml
# !focus(13:37)
# !mark(14)
```

---

## !!steps

The `/plan/{id}` endpoint has a single `GET` operation that retrieves a subscription plan by ID. It expects an integer `id` parameter in the path.

```yaml ! subscriptions.yaml
# !focus(13:37)
# !mark(15:25)
```

---

## !!steps

We'll only focus on the `200` response for now. The response should be a JSON object with the subscription plan details, as defined in the `Subscription` schema.

```yaml ! subscriptions.yaml
# !focus(31:37)
# !mark(37)
```

---

## !!steps

The `Subscription` schema defines the structure of the response object. It includes fields for `id`, `name`, `amount`, and `currency`.

```yaml ! subscriptions.yaml
# !focus(53:68)
```

</ScrollyCoding>

This example OpenAPI specification only defines the happy path for the `/plan/{id}` endpoint. In a real-world scenario, you would define additional paths, operations, and error responses to cover all possible scenarios.

### Step 3: Create an SDK with Speakeasy

We'll use Speakeasy to create a TypeScript SDK from the OpenAPI specification. If you don't have Speakeasy installed, you can install it from the [Introduction to Speakeasy](/docs/introduction/introduction#getting-started) guide.

With Speakeasy installed, run:

```bash
speakeasy quickstart
```

When prompted, select the `subscriptions.yaml` file and choose TypeScript as the target language. We decided on `Billing` as the SDK name, and `billing` as the package name.

### Step 4: Add tests

Now that we have an SDK, we can write tests to verify that the SDK handles the API responses correctly.

Let's install the necessary dependencies:

```bash
npm i --save-dev vitest
```

Create a new `tests` directory in the root of your project. Then, create a new file, `tests/subscription.test.ts`:

```typescript tests/subscription.test.ts
import { expect, test } from "vitest";
import { Billing } from "../billing-typescript/src/index.ts"

test("Subscription Get Plan By Id Basic", async () => {
  const billing = new Billing({
    apiKey: process.env["BILLING_API_KEY"] ?? "",
  });
  const result = await billing.subscription.getPlanById({
    id: 1,
  });
  expect(result).toBeDefined();
  expect(result).toEqual({
    id: 1,
    name: "Basic",
    amount: 100,
    currency: "USD",
  });
});
```

Add the following script to your `package.json`:

```json package.json
// !focus(2:4)
{
  "scripts": {
    "test": "vitest run"
  }
}
```

Now you can run the tests:

```bash
npm run test
```

This should run the test and verify that the SDK correctly handles the API responses, but since we haven't started a server yet, the test will fail.

### Step 5: Start a mock server

We'll use Prism to start a mock server that serves responses based on the OpenAPI specification.

Add Prism as a dev dependency:

```bash
npm install --save-dev @stoplight/prism-cli
```

Then, add a new script to your `package.json`:

```json package.json
// !focus(4)
{
  "scripts": {
    "test": "vitest run",
    "mock": "prism mock subscriptions.yaml"
  }
}
```

In a new terminal window, run:

```bash
npm run mock
```

This will start a mock server at `http://127.0.0.1:4010`.

### Step 6: Run the tests

Now that the mock server is running, you can run the tests again:

```bash
npm run test
```

This time, Prism returns a `401` status code because we haven't provided an API key. Let's run the test with the `BILLING_API_KEY` set to `test`:

```bash
export BILLING_API_KEY=test
npm run test
```

```txt
$ vitest run
 
 RUN  v2.1.1 /Users/speakeasy/contract-example
 
 ✓ tests/subscription.test.ts (1)
   ✓ Subscription Get Plan By Id Basic
 
 Test Files  1 passed (1)
      Tests  1 passed (1)
   Start at  07:28:38
   Duration  630ms (transform 191ms, setup 0ms, collect 199ms, tests 150ms, environment 0ms, prepare 86ms)
```

The test should now pass, verifying that the SDK correctly handles the API response.

### Step 7: Test for correctness

We've validated that the SDK can correctly handle an API response by interacting with a mock server, but we haven't confirmed whether the response conforms to the contract. To make this a true contract test, let’s verify that both the consumer and provider behaviors align with the agreed-upon OpenAPI specification.

We'll add a contract-validation step to the test, then use Ajv, a JSON Schema validator, to validate the response against the OpenAPI schema.

```bash
npm install --save-dev ajv ajv-errors ajv-formats yaml
```

Create a new file, `validateSchema.ts`:

```typescript validateSchema.ts
import Ajv from "ajv";
import addFormats from "ajv-formats";
import addErrors from "ajv-errors";
import { readFileSync } from "fs";
import yaml from "yaml";

// Load and parse the OpenAPI specification
const openApiSpec = yaml.parse(readFileSync("./subscriptions.yaml", "utf8")) as any;

// Initialize Ajv with formats and error messages
const ajv = new Ajv({ allErrors: true, strict: false });
addFormats(ajv);
addErrors(ajv);

// Compile the schema for the Subscription response
const subscriptionSchema = {
  ...openApiSpec.components.schemas.Subscription
};

const validate = ajv.compile(subscriptionSchema);

export const validateSubscription = (data: any) => {
  const isValid = validate(data);
  if (!isValid) {
    console.error(validate.errors);
    throw new Error("Validation failed");
  }
};
```

Update the test to include the contract-validation step:

```typescript tests/subscription.test.ts mark=3,19
import { expect, test, expectTypeOf } from "vitest";
import { Billing } from "../billing-typescript/src/index.ts";
import { validateSubscription } from "../validateSchema.ts";

test("Subscription Get Plan By Id Basic", async () => {
  const billing = new Billing({
    apiKey: process.env["BILLING_API_KEY"] ?? "",
  });
  const result = await billing.subscription.getPlanById({
    id: 1,
  });
  expect(result).toBeDefined();
  expect(result).toEqual({
    id: 1,
    name: "Basic",
    amount: 100,
    currency: "USD",
  });
  validateSubscription(result); // Contract validation
});
```

Now when you run the tests, the contract validation will ensure that the response from the mock server matches the OpenAPI specification.

```bash
npm run test
```

## Generating contract tests automatically with OpenAPI

Manually writing contract tests can be a time-consuming and error-prone process. If you're starting with an OpenAPI document as your contract, you may be able to automatically generate tests that conform to your contract.

By generating contract tests, you reduce the risk of human error, save significant development time, and ensure that tests are always kept up to date.

The biggest advantage of automated test generation is the assurance that your tests are based on the API specification. This means that all aspects of the API contract, from endpoint paths and methods to data types and constraints, are accurately represented in the generated tests.

A drawback of basing tests on OpenAPI documents is that the OpenAPI Specification does not currently have built-in support for test generation. Although examples of requests and responses allow test case generation, there are still challenges in linking request and response pairs to each other. These are problems we're working hard to overcome at Speakeasy.

## Speakeasy test generation

<Callout title="EARLY ACCESS" variant="info">
  Speakeasy API test generation is in beta. Join the [early
  access](/product/api-testing) program to give it a try.
</Callout>

At Speakeasy, we enable developers to automatically test their APIs and SDKs by creating comprehensive test suites. Shipping automated tests as part of your SDKs will enable your team to make sure that the interfaces your users prefer, your SDKs, are always compatible with your API. We ensure your APIs and SDKs stick to the contract so that you can focus on shipping features and evolving your API with confidence.

The process of adding tests with Speakeasy is straightforward: Add detailed examples to your OpenAPI document, or describe tests in a simple and well-documented YAML specification that lives in your SDK project. Speakeasy will regenerate your tests when they need to change, and you can run the tests as part of development or CI/CD workflows.

Speakeasy's new [automated API testing](/product/api-testing) platform is in early access and currently supports Python, Go, TypeScript, and Java.

## Speakeasy test generation roadmap

Looking ahead, Speakeasy's testing roadmap includes broader language support, advanced server mocking, ability to run contract tests on past versions of the API and SDK, and using the Arazzo specification to string together multiple contract tests. With these features, you'll be able to monitor the health of all your SDKs and APIs in one place.

We're also working on support for behavior-driven development (BDD) and end-to-end (E2E) testing by embracing OpenAPI and the recently published Arazzo specification for complex testing workflows.

To join the Speakeasy automated API testing early access program, follow the signup link on the [testing page](/product/api-testing).


 This is the content for the doc blog/create-a-terraform-provider-a-guide-for-beginners.mdx 

 ---
title: "How To Create a Terraform Provider — a Guide for Absolute Beginners"
description: "Learn the basics of creating a Terraform provider from scratch"
keywords: [go, golang, HashiCorp, Terraform, tutorial, provider]
image: "/media/api-advice-how-to-create-a-TF-provider.png"
date: 2024-03-13
authors:
  - name: Tristan Cartledge
  - image_url: "https://uploads-ssl.webflow.com/62ccd7b208cab0723d026273/635ff12733f46637e91ced22_1516859875198.jpg"
tags:
  - API Advice
featured_image: "/media/api-advice-how-to-create-a-TF-provider.png"
---

This tutorial shows you how to create a simple Terraform provider for your web service. 

Terraform is a large, complicated piece of software, and the Terraform tutorials on creating a Terraform provider are lengthy and intimidating. But creating a provider doesn't have to be complicated. 

In this guide, we strip away many of the unnecessary functions that Terraform demonstrates and create a provider that does nothing but create, read, update, and delete a resource via an API. You don't need any experience using Terraform to follow along — we'll explain everything as we go.

## Prerequisites

You need [Docker](https://docs.docker.com/get-docker) to run the code provided here. You can install Terraform and Go locally if you prefer, but you'll need to adjust the commands we provide to suit your operating system.

## Set Up Your System

Create a folder on your computer to work in. Open a terminal in the folder and run the commands below to create a basic project structure.

```sh
touch Dockerfile
mkdir 1_webservice
mkdir 2_customer
mkdir -p 3_provider/internal/provider
```

The `1_webservice` folder represents the service that your company sells online. In this example, we'll have an API that can add and remove users. This service can be in any programming language.

The `2_customer` folder represents how your users will call Terraform to talk to your service. This folder will hold a Terraform resource configuration file.

The `3_provider` folder is the custom Terraform provider that will let Terraform talk to your web service. This provider will have three files in Go (Terraform uses only Go for plugins).


Add the text below to the `Dockerfile`.

```bash
FROM --platform=linux/amd64 alpine:3.19

WORKDIR /workspace

RUN apk add go curl unzip bash sudo nodejs npm vim

ENV GOPATH=/root/go
ENV PATH=$PATH:$GOPATH/bin

# install terraform:
RUN curl -O https://releases.hashicorp.com/terraform/1.7.0/terraform_1.7.0_linux_amd64.zip && \
    unzip terraform_1.7.0_linux_amd64.zip && \
    mv terraform /usr/local/bin/ && \
    rm terraform_1.7.0_linux_amd64.zip
```

Now build the Docker image and start working in it using the commands below. Your current folder will be shared with the Docker container as `/workspace`, so you can edit the files on your computer while running Go in the container.

```sh
docker build -t timage .
docker run -it --volume .:/workspace --name tbox timage
# if you stop the container and want to restart it later, run: docker start -ai tbox
```

## Create the Web Service

Since we'll write the Terraform provider in Go, let's create a basic web service in Go, too. 

Terraform uses CRUD (create, read, update, and delete) operations to manage any resource in any system, from AWS and Azure to your company's finance, software, or healthcare product.

In the `1_webservice` folder, create a single-file service that allows a customer to create users with an ID and name, and update and delete users. Run the commands below in the Docker container terminal:

```sh
cd /workspace/1_webservice
go mod init main
go get github.com/go-chi/chi/v5
touch main.go
```

These commands create a `go.mod` file in the folder and add the `chi` web framework dependency.

In a text editor, copy the code below into `main.go`.

```go
package main

import (
	"fmt"
	"io"
	"net/http"
	"sync"

	"github.com/go-chi/chi/v5"
)

var users = make(map[string]string) // Map to store users with id as key and name as value
var mutex = &sync.RWMutex{}         // Mutex to protect access to the map as server is multithreaded

func main() {
	router := chi.NewRouter()

	router.Post("/{id}", func(response http.ResponseWriter, request *http.Request) {
		id := chi.URLParam(request, "id")
		name, err := io.ReadAll(request.Body)
		if err != nil {
			http.Error(response, "Failed to read request body", http.StatusBadRequest)
			return
		}
		mutex.Lock()
		defer mutex.Unlock()
		users[id] = string(name)
		fmt.Fprintf(response, "%s", string(name))
		fmt.Println("POST: ", id, " ", string(name))
	})
```

This code imports parts of the Go standard library related to HTTP and the `chi` web framework.

The code then makes a variable called `users` to hold the IDs and names of users. As we aren't using a database here, this will work only as long as the service is running, and all users will be lost when the service stops.

We then create a mutex to handle safe writing to the users lists. Go is multithreaded, so we need a mutex to allow each HTTP handler to check that no other thread is trying to update the users list at the same time.

Finally, we have an HTTP `POST` handler to set a user in the list. To keep this guide short, we do no fancy checks for existing users or errors. The service overwrites items in the list with `users[id] = string(name)`. The function returns plain text (not JSON) to the caller with `fmt.Fprintf(response, "%s", string(name))`. The last line prints to the console to show that it's working.

So far, we have only a `Create` handler with the `Post` method. Let's add read, update, and delete. Append the code below to `main.go`.

```go
  router.Get("/{id}", func(response http.ResponseWriter, request *http.Request) {
		id := chi.URLParam(request, "id")
		mutex.RLock()
		defer mutex.RUnlock()
		name, ok := users[id]
		if !ok {
			http.NotFound(response, request)
			return
		}
		fmt.Fprintf(response, "%s", name)
		fmt.Println("GET: ", id, " ", name)
	})

	router.Put("/{id}", func(response http.ResponseWriter, request *http.Request) {
		id := chi.URLParam(request, "id")
		name, err := io.ReadAll(request.Body)
		if err != nil {
			http.Error(response, "Failed to read request body", http.StatusBadRequest)
			return
		}
		mutex.Lock()
		defer mutex.Unlock()
		if _, ok := users[id]; !ok {
			http.NotFound(response, request)
			return
		}
		users[id] = string(name)
		fmt.Fprintf(response, "%s", string(name))
		fmt.Println("PUT: ", id, " ", users[id])
	})

	router.Delete("/{id}", func(response http.ResponseWriter, request *http.Request) {
		id := chi.URLParam(request, "id")
		mutex.Lock()
		defer mutex.Unlock()
		name, ok := users[id]
		if !ok {
			http.NotFound(response, request)
			return
		}
		delete(users, id)
		fmt.Fprintf(response, "%s", name)
		fmt.Println("PUT: ", id, " ", users[id])
	})

	http.ListenAndServe(":6251", router)
}
```

Test the service by running the commands below.

```sh
go run main.go &
curl -X POST -d "Jane" http://localhost:6251/2
curl http://localhost:6251/2
```

This series of commands starts the service in the background, creates a user `[2,Jane]`, and retrieves the user from the service.

To stop and restart the background service, run the command below:

```
killall main; go run main.go &
```

## Create a Terraform Configuration File

So you have a web service, and in reality, you might even have an SDK in Python, Go, Java, and other languages that your customers could use to call your service. Why do you need Terraform, too?

We answer this question in detail in [our blog post about using Terraform as a SaaS API interface](/post/build-terraform-providers). In summary, Terraform allows your customers to manage multiple environments with a single service (Terraform) through declarative configuration files that can be stored in Git. This means that if one of your customers wants to add a new user or a whole new franchise, they can copy a Terraform resource configuration file from an existing franchise, update it, check it into GitHub, and get it approved. Then Terraform can run it automatically using continuous integration. This has benefits for your customers in terms of speed, safety, repeatability, auditing, and correctness.

Let's create a Terraform configuration file to demonstrate this now. Run the commands below:

```sh
cd /workspace/2_customer
touch main.tf
```

Paste the code below into `main.tf`:

```hcl
# load the provider
terraform {
  required_providers {
    myuserprovider = {
      source  = "example.com/me/myuserprovider"
      # version = "~> 1.0"
    }
  }
}

# configure the provider
provider "myuserprovider" {
  endpoint = "http://localhost:6251/"
}

# configure the resource
resource "myuserprovider_user" "john_doe" {
  id   = "1"
  name = "John Doe"
}
```

In the first section, we tell Terraform that it will need to use a custom provider to interact with our service, `example.com/me/myuserprovider`. We name the service `myuserprovider`.

In the second section, we configure this provider with the URL of the web service.

The final section is what your customers will use most. Here we create a resource (a user) with an ID and a name. You could create hundreds of users here. Once the users are created, you can also change their names or delete them, and Terraform will automatically make the appropriate calls to your service to ensure that the API matches the state it recorded locally.

This `main.tf` file is all your customers need to work with once you've created a provider. Let's create the provider now.

## Create a Custom Terraform Provider

Run the commands below:

```sh
cd /workspace/3_provider
touch go.mod
```

Here we create `go.mod` manually because a Terraform provider needs a lot of dependencies. (The dependencies come from the [Terraform provider scaffolding project](https://github.com/hashicorp/terraform-provider-scaffolding-framework).)

Add the text below to `go.mod`.

```go
module example.com/me/myuserprovider

go 1.21

require (
	github.com/hashicorp/go-version v1.6.0
	github.com/hashicorp/terraform-plugin-docs v0.18.0
	github.com/hashicorp/terraform-plugin-framework v1.6.1
	github.com/hashicorp/terraform-plugin-go v0.22.0
	github.com/hashicorp/terraform-plugin-log v0.9.0
	github.com/hashicorp/terraform-plugin-testing v1.7.0
)

require (
	github.com/Kunde21/markdownfmt/v3 v3.1.0 // indirect
	github.com/Masterminds/goutils v1.1.1 // indirect
	github.com/Masterminds/semver/v3 v3.2.0 // indirect
	github.com/Masterminds/sprig/v3 v3.2.3 // indirect
	github.com/ProtonMail/go-crypto v1.1.0-alpha.0 // indirect
	github.com/agext/levenshtein v1.2.2 // indirect
	github.com/apparentlymart/go-textseg/v15 v15.0.0 // indirect
	github.com/armon/go-radix v1.0.0 // indirect
	github.com/bgentry/speakeasy v0.1.0 // indirect
	github.com/cloudflare/circl v1.3.7 // indirect
	github.com/fatih/color v1.16.0 // indirect
	github.com/golang/protobuf v1.5.3 // indirect
	github.com/google/go-cmp v0.6.0 // indirect
	github.com/google/uuid v1.4.0 // indirect
	github.com/hashicorp/cli v1.1.6 // indirect
	github.com/hashicorp/errwrap v1.1.0 // indirect
	github.com/hashicorp/go-checkpoint v0.5.0 // indirect
	github.com/hashicorp/go-cleanhttp v0.5.2 // indirect
	github.com/hashicorp/go-cty v1.4.1-0.20200414143053-d3edf31b6320 // indirect
	github.com/hashicorp/go-hclog v1.6.2 // indirect
	github.com/hashicorp/go-multierror v1.1.1 // indirect
	github.com/hashicorp/go-plugin v1.6.0 // indirect
	github.com/hashicorp/go-uuid v1.0.3 // indirect
	github.com/hashicorp/hc-install v0.6.3 // indirect
	github.com/hashicorp/hcl/v2 v2.20.0 // indirect
	github.com/hashicorp/logutils v1.0.0 // indirect
	github.com/hashicorp/terraform-exec v0.20.0 // indirect
	github.com/hashicorp/terraform-json v0.21.0 // indirect
	github.com/hashicorp/terraform-plugin-sdk/v2 v2.33.0 // indirect
	github.com/hashicorp/terraform-registry-address v0.2.3 // indirect
	github.com/hashicorp/terraform-svchost v0.1.1 // indirect
	github.com/hashicorp/yamux v0.1.1 // indirect
	github.com/huandu/xstrings v1.3.3 // indirect
	github.com/imdario/mergo v0.3.15 // indirect
	github.com/mattn/go-colorable v0.1.13 // indirect
	github.com/mattn/go-isatty v0.0.20 // indirect
	github.com/mattn/go-runewidth v0.0.9 // indirect
	github.com/mitchellh/copystructure v1.2.0 // indirect
	github.com/mitchellh/go-testing-interface v1.14.1 // indirect
	github.com/mitchellh/go-wordwrap v1.0.0 // indirect
	github.com/mitchellh/mapstructure v1.5.0 // indirect
	github.com/mitchellh/reflectwalk v1.0.2 // indirect
	github.com/oklog/run v1.0.0 // indirect
	github.com/posener/complete v1.2.3 // indirect
	github.com/russross/blackfriday v1.6.0 // indirect
	github.com/shopspring/decimal v1.3.1 // indirect
	github.com/spf13/cast v1.5.0 // indirect
	github.com/vmihailenco/msgpack v4.0.4+incompatible // indirect
	github.com/vmihailenco/msgpack/v5 v5.4.1 // indirect
	github.com/vmihailenco/tagparser/v2 v2.0.0 // indirect
	github.com/yuin/goldmark v1.6.0 // indirect
	github.com/yuin/goldmark-meta v1.1.0 // indirect
	github.com/zclconf/go-cty v1.14.3 // indirect
	golang.org/x/crypto v0.21.0 // indirect
	golang.org/x/exp v0.0.0-20230809150735-7b3493d9a819 // indirect
	golang.org/x/mod v0.15.0 // indirect
	golang.org/x/net v0.21.0 // indirect
	golang.org/x/sys v0.18.0 // indirect
	golang.org/x/text v0.14.0 // indirect
	golang.org/x/tools v0.13.0 // indirect
	google.golang.org/appengine v1.6.8 // indirect
	google.golang.org/genproto/googleapis/rpc v0.0.0-20231106174013-bbf56f31fb17 // indirect
	google.golang.org/grpc v1.61.1 // indirect
	google.golang.org/protobuf v1.32.0 // indirect
	gopkg.in/yaml.v2 v2.3.0 // indirect
)
```

Note the module name at the top of the file, `module example.com/me/myuserprovider`. This name consists of an example URL to make the module globally unique, and the name used for the provider in the `main.tf` file — `myuserprovider`.

There are only three code files that are essential to create a provider. They are each presented in a subsection below.

### The `main.go` File

The first file you need is `main.go`. Create it in `/workspace/3_provider/main.go` and add the code below to it:

```go
package main

import (
	"context"
	"log"

	"example.com/me/myuserprovider/internal/provider"
	"github.com/hashicorp/terraform-plugin-framework/providerserver"
)

func main() {
	opts := providerserver.ServeOpts{
		Address: "example.com/me/myuserprovider",
	}
	err := providerserver.Serve(context.Background(), provider.New(), opts)
	if err != nil {
		log.Fatal(err.Error())
	}
}
```

This file creates a `providerserver`, a server that hosts the provider plugin that Terraform can connect to and use. When Terraform looks for your plugin to load it, this `main` function is what Terraform calls to get access to the provider, created with `provider.New()`.

Providers are structured like a Go web service. Functions receive a `context`, which holds state, a request, and a response. Functions can add data to the `context` that Terraform will use when the function exits. We'll see an example of this when we create the resource file.

### The `provider.go` File

Create a `3_provider/internal/provider/provider.go` file and add the code below to it:

```go
package provider

import (
	"context"
	"net/http"

	tfdatasource "github.com/hashicorp/terraform-plugin-framework/datasource"
	tffunction "github.com/hashicorp/terraform-plugin-framework/function"
	tfprovider "github.com/hashicorp/terraform-plugin-framework/provider"
	tfschema "github.com/hashicorp/terraform-plugin-framework/provider/schema"
	tfresource "github.com/hashicorp/terraform-plugin-framework/resource"
	tftypes "github.com/hashicorp/terraform-plugin-framework/types"
)

type UserProviderModel struct {
	Endpoint tftypes.String `tfsdk:"endpoint"`
}

type UserProvider struct {
	endpoint string
	client   *http.Client
}

var _ tfprovider.Provider = &UserProvider{}
var _ tfprovider.ProviderWithFunctions = &UserProvider{}

func New() func() tfprovider.Provider {
	return func() tfprovider.Provider {
		return &UserProvider{}
	}
}
```

This code does the following:
- Imports the Terraform Go framework.
- Defines a `UserProviderModel` struct with an `endpoint`. This endpoint will come from the `main.tf` configuration file (the URL of your web service).
- Defines a `UserProvider` struct that holds any data the provider needs throughout its life. In our case, we need only the web service URL and an HTTP client that we can pass to the resource manager (created in the next section).
- Checks that `UserProvider` correctly implements all the functions Terraform needs in `var _ tfprovider.Provider = &UserProvider{}`. It creates a discarded `_` variable and assigns it the type `tfprovider.Provider` so that the Go compiler can verify it.
- Defines a `New()` function to return an instance of our provider. This function was called in the previous file in the provider server.

Next, add the functions below to the `provider.go` file:

```go
func (p *UserProvider) Metadata(ctx context.Context, req tfprovider.MetadataRequest, resp *tfprovider.MetadataResponse) {
	resp.TypeName = "myuserprovider" // matches in your .tf file `resource "myuserprovider_user" "john_doe" {`
}

func (p *UserProvider) Schema(ctx context.Context, req tfprovider.SchemaRequest, resp *tfprovider.SchemaResponse) {
	resp.Schema = tfschema.Schema{
		Attributes: map[string]tfschema.Attribute{
			"endpoint": tfschema.StringAttribute{
				MarkdownDescription: "Endpoint of the API, e.g. - http://localhost:6251/",
				Required:            true,
			},
		},
	}
}

func (p *UserProvider) Configure(ctx context.Context, req tfprovider.ConfigureRequest, resp *tfprovider.ConfigureResponse) {
	var data UserProviderModel
	resp.Diagnostics.Append(req.Config.Get(ctx, &data)...)
	if resp.Diagnostics.HasError() {
		return
	}
	p.endpoint = data.Endpoint.ValueString()
	p.client = http.DefaultClient
	resp.DataSourceData = p // will be usable by DataSources
	resp.ResourceData = p   // will be usable by Resources
}

func (p *UserProvider) Resources(ctx context.Context) []func() tfresource.Resource {
	return []func() tfresource.Resource{
		NewUserResource,
	}
}

func (p *UserProvider) DataSources(ctx context.Context) []func() tfdatasource.DataSource {
	return []func() tfdatasource.DataSource{}
}

func (p *UserProvider) Functions(ctx context.Context) []func() tffunction.Function {
	return []func() tffunction.Function{}
}
```

- `Metadata()` contains the name of the provider.
- `Schema()` must match the `main.tf` file so that Terraform can get the configuration settings for the provider.
- `Configure()` gets the settings from the configuration file, creates an HTTP client, saves the settings to the `UserProvider` struct, and adds them to the method's response type. We set `ResourceData` so that the resource manager has access to all the fields of the `UserProvider` struct.
- `Resources()` creates a single `NewUserResource` instance. The `NewUserResource` function returns a `UserResource` type, which is what interacts with the users in the web service, and we create it in the next subsection. Since our provider doesn't manage any `DataSources`, we don't create any.

### The `userResource.go` File

Create a `3_provider/internal/provider/userResource.go` file and add the code below to it:

```go
package provider

import (
	"bytes"
	"context"
	"fmt"
	"io"
	"net/http"

	tfpath "github.com/hashicorp/terraform-plugin-framework/path"
	tfresource "github.com/hashicorp/terraform-plugin-framework/resource"
	tfschema "github.com/hashicorp/terraform-plugin-framework/resource/schema"
	tftypes "github.com/hashicorp/terraform-plugin-framework/types"
)

var _ tfresource.Resource = &UserResource{}
var _ tfresource.ResourceWithImportState = &UserResource{}

type UserResource struct {
	client   *http.Client
	endpoint string
}

type UserModel struct {
	Id   tftypes.String `tfsdk:"id"`
	Name tftypes.String `tfsdk:"name"`
}

func NewUserResource() tfresource.Resource {
	return &UserResource{}
}
```

This code is similar to the code in the previous file we created. It loads dependencies, checks the interfaces compile, and defines the struct the resource will use.

Note the `UserModel`. This struct is what will communicate between the web service and Terraform core. Terraform will save the values here for `Id` and `Name` into a local state file that mimics what Terraform thinks the web service state is. Terraform uses its own types to do this, `terraform-plugin-framework/types`, not plain Go types.

Next, add the code below to allow the resource to configure itself:

```go

func (r *UserResource) Metadata(ctx context.Context, req tfresource.MetadataRequest, resp *tfresource.MetadataResponse) {
	resp.TypeName = req.ProviderTypeName + "_user" // matches in main.tf: resource "myuserprovider_user" "john_doe" {
}

func (r *UserResource) Schema(ctx context.Context, req tfresource.SchemaRequest, resp *tfresource.SchemaResponse) {
	resp.Schema = tfschema.Schema{
		MarkdownDescription: "User resource interacts with user web service",
		Attributes: map[string]tfschema.Attribute{
			"id": tfschema.StringAttribute{
				MarkdownDescription: "The user ID",
				Required:            true,
			},
			"name": tfschema.StringAttribute{
				MarkdownDescription: "The name of the user",
				Required:            true,
			},
		},
	}
}

func (r *UserResource) Configure(ctx context.Context, req tfresource.ConfigureRequest, resp *tfresource.ConfigureResponse) {
	if req.ProviderData == nil { // this means the provider.go Configure method hasn't been called yet, so wait longer
		return
	}
	provider, ok := req.ProviderData.(*UserProvider)
	if !ok {
		resp.Diagnostics.AddError(
			"Could not create HTTP client",
			fmt.Sprintf("Expected *http.Client, got: %T", req.ProviderData),
		)
		return
	}
	r.client = provider.client
	r.endpoint = provider.endpoint
}
```

Again, this code looks similar to the code in the previous file.
- Note how the `Metadata()` function combines the provider and resource names with `_` in `myuserprovider_user`. This matches the name in `main.tf` and is a Terraform naming standard.
- `Schema()` defines what Terraform will remember about the remote resource in local state.
- `Configure()` gets the information from the provider we configured in the `provider.go` file in the `Configure()` method, `resp.ResourceData = p`. It receives an HTTP client and URL from the provider to use in the resource manager.

The `if req.ProviderData == nil` line is essential. Terraform can load the resource manager before the provider, so when the `Configure()` function is called, there may not yet be a provider to get configuration data from. In this case, the function will exit, and Terraform will call it again later when the provider has been loaded. It seems strange that Terraform would call the resource manager before the provider since it seems that the provider **owns** the resource manager, but that's just how it is.

The last code you need to add to `userProvider.go` is the heart of the provider: Calling the web service with CRUD functions and returning the response to Terraform to update its state. This code is also the easiest to understand. We'll explain the `Create` function after you've added the code below. The other functions are similar.

```go
func (r *UserResource) Create(ctx context.Context, req tfresource.CreateRequest, resp *tfresource.CreateResponse) {
	var state UserModel
	resp.Diagnostics.Append(req.Plan.Get(ctx, &state)...)
	if resp.Diagnostics.HasError() {
		return
	}
	response, err := r.client.Post(r.endpoint+state.Id.ValueString(), "application/text", bytes.NewBuffer([]byte(state.Name.ValueString())))
	if err != nil {
		resp.Diagnostics.AddError("Client Error", fmt.Sprintf("Error sending request: %s", err))
		return
	}
	defer response.Body.Close()
	if response.StatusCode != http.StatusOK {
		resp.Diagnostics.AddError("HTTP Error", fmt.Sprintf("Received non-OK HTTP status: %s", response.Status))
		return
	}
	body, err := io.ReadAll(response.Body)
	if err != nil {
		resp.Diagnostics.AddError("Failed to Read Response Body", fmt.Sprintf("Could not read response body: %s", err))
		return
	}
	state.Name = tftypes.StringValue(string(body))
	resp.Diagnostics.Append(resp.State.Set(ctx, &state)...)
}

func (r *UserResource) Read(ctx context.Context, req tfresource.ReadRequest, resp *tfresource.ReadResponse) {
	var state UserModel
	resp.Diagnostics.Append(req.State.Get(ctx, &state)...)
	if resp.Diagnostics.HasError() {
		return
	}
	response, err := r.client.Get(r.endpoint + state.Id.ValueString())
	if err != nil {
		resp.Diagnostics.AddError("Client Error", fmt.Sprintf("Unable to read user, got error: %s", err))
		return
	}
	defer response.Body.Close()
	if response.StatusCode == http.StatusNotFound {
		resp.State.RemoveResource(ctx)
		return
	}
	if response.StatusCode == http.StatusOK {
		bodyBytes, err := io.ReadAll(response.Body)
		if err != nil {
			resp.Diagnostics.AddError("Error reading response body", err.Error())
			return
		}
		state.Name = tftypes.StringValue(string(bodyBytes))
		resp.Diagnostics.Append(resp.State.Set(ctx, &state)...)
		return
	}
	resp.Diagnostics.AddError("HTTP Error", fmt.Sprintf("Received bad HTTP status: %s", response.Status))
}

func (r *UserResource) Delete(ctx context.Context, req tfresource.DeleteRequest, resp *tfresource.DeleteResponse) {
	var data UserModel
	resp.Diagnostics.Append(req.State.Get(ctx, &data)...)
	if resp.Diagnostics.HasError() {
		return
	}
	request, err := http.NewRequest(http.MethodDelete, r.endpoint+data.Id.ValueString(), nil)
	if err != nil {
		resp.Diagnostics.AddError("Request Creation Failed", fmt.Sprintf("Could not create HTTP request: %s", err))
		return
	}
	response, err := r.client.Do(request)
	if err != nil {
		resp.Diagnostics.AddError("Client Error", fmt.Sprintf("Unable to delete user, got error: %s", err))
		return
	}
	defer response.Body.Close()
	if response.StatusCode != http.StatusOK {
		resp.Diagnostics.AddError("HTTP Error", fmt.Sprintf("Received non-OK HTTP status: %s", response.Status))
		return
	}
	data.Id = tftypes.StringValue("")
	data.Name = tftypes.StringValue("")
	resp.Diagnostics.Append(resp.State.Set(ctx, &data)...)
}

func (r *UserResource) Update(ctx context.Context, req tfresource.UpdateRequest, resp *tfresource.UpdateResponse) {
	var state UserModel
	resp.Diagnostics.Append(req.Plan.Get(ctx, &state)...)
	if resp.Diagnostics.HasError() {
		return
	}
	webserviceCall, err := http.NewRequest("PUT", r.endpoint+state.Id.ValueString(), bytes.NewBuffer([]byte(state.Name.ValueString())))
	if err != nil {
		resp.Diagnostics.AddError("Go Error", fmt.Sprintf("Error sending request: %s", err))
	}
	response, err := r.client.Do(webserviceCall)
	if err != nil {
		resp.Diagnostics.AddError("Client Error", fmt.Sprintf("Error sending request: %s", err))
		return
	}
	defer response.Body.Close()
	if response.StatusCode != http.StatusOK {
		resp.Diagnostics.AddError("HTTP Error", fmt.Sprintf("Received non-OK HTTP status: %s", response.Status))
		return
	}
	body, err := io.ReadAll(response.Body)
	if err != nil {
		resp.Diagnostics.AddError("Failed to Read Response Body", fmt.Sprintf("Could not read response body: %s", err))
		return
	}
	state.Name = tftypes.StringValue(string(body))
	resp.Diagnostics.Append(resp.State.Set(ctx, &state)...)
}

func (r *UserResource) ImportState(ctx context.Context, req tfresource.ImportStateRequest, resp *tfresource.ImportStateResponse) {
	tfresource.ImportStatePassthroughID(ctx, tfpath.Root("id"), req, resp)
}
```

The `Create` function looks like a web handler, with a context, request, and response. As mentioned earlier, Terraform uses the web metaphor to structure its plugins. Like the other three functions, `Create()` does three things:
- Loads the Terraform state for the resource with `req.Plan.Get(ctx, &state)`. This represents what Terraform thinks the remote resource is, or what it wants it to be.
- Calls the web service and gets the response with `r.client.Post(r.endpoint+state.Id.ValueString()`.
- Saves the response to the local Terraform state with `resp.State.Set(ctx, &state)`.

Note that you don't have to write any logic to reason about changing the remote state, for example, adding or updating the user if the response from the web service is not what you anticipated. That's what Terraform Core is for. Terraform will call the correct sequence of CRUD functions to work out how to change the remote users based on your desired users in the configuration file.

Be careful to use only `ValueString()` when working with Terraform string types. There are similar functions, like `String()` and `Value()`, that can add extra `"` marks to your fields. You'll encounter confusing errors with infinite update loops calling Terraform if you don't notice that you're adding extra string quotes to every web service call when you use the wrong method.

## Run the Provider

Let's recapitulate. You've:
- Created a one-file web service to manage users that represents your company's product that you sell to customers.
- Created a `main.tf` Terraform configuration file to say that you want to use the `myuserprovider` provider to create a user called "John Doe" using the web service.
- Created a Terraform provider with three files: a provider server, a provider, and a user resource manager.

Now it's time to run Terraform pretending that you're one of your customers calling your web service and check that your provider works with the configuration file.

Because your provider isn't hosted on the online Terraform registry, you need to tell Terraform to use the local project.

Create a file called `.terraformrc` in the `workspace` folder:

```sh
cd /workspace
touch .terraformrc
```

Insert the text below:

```hcl
provider_installation {
    dev_overrides {
        "example.com/me/myuserprovider" = "/workspace/3_provider/bin"
    }
    direct {} # For all other providers, install directly from their origin provider.
}
```

In the Docker terminal, run the command below to copy this Terraform settings file to the container home folder (where you're user `root`), so that Terraform knows where to look for your provider.

```sh
cp /workspace/.terraformrc /root/
```

Now let's run the provider and test it. Run the commands below.

```sh
cd /workspace/3_provider
go mod tidy # download dependencies
go build -o ./bin/terraform-provider-myuserprovider

cd /workspace/2_customer
terraform plan
terraform apply -auto-approve
```

Terraform should return:

```sh
Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

  # myuserprovider_user.john_doe will be created
  + resource "myuserprovider_user" "john_doe" {
      + id   = "1"
      + name = "John Doe"
    }

Plan: 1 to add, 0 to change, 0 to destroy.
myuserprovider_user.john_doe: Creating...
POST:  1   John Doe
myuserprovider_user.john_doe: Creation complete after 0s [id=1]

Apply complete! Resources: 1 added, 0 changed, 0 destroyed.
```

(If you've used Terraform before and are used to running `terraform init`, that won't work with the `dev_overrides` setting. The `Init` command isn't necessary because there's no need to download any plugins.)

If you need to do any debugging while working on the provider, set the environment variable for logging in the terminal with `export TF_LOG=WARN`, and ask Terraform to write information to the terminal in your `userResource.go` with:
```go
import "github.com/hashicorp/terraform-plugin-log/tflog" // at the top
tflog.Info(ctx, "We are inside CREATE\n") // in a function
```

Notice that Terraform created `/workspace/2_customer/terraform.tfstate`. This state file holds what Terraform thinks the remote state is. Never alter this file manually. If you need to update Terraform state because you added users directly through the web service, you'll need to implement the Terraform `import` command.

Experiment to see how Terraform calls the CRUD functions depending on how you change your state. Add more users to the `main.tf` file, change their names, call `curl -X POST -d "Jane" http://localhost:6251/1` to try to confuse Terraform, and see how it handles the changes.

## Limitations and Further Reading

You're done with writing code for this guide and now have a working minimal example of a Terraform provider that you can enhance. But this provider isn't ready for production use yet. There are features you'll probably want to add, for example:

- Markup responses (JSON or XML). This simplistic web service currently returns either a 404 or a string containing a user name directly in the response body. In reality, you'll use a markup language. You may even want to have your `userResource` call a Go SDK for your service instead of making web calls directly.
- Versioning and continuous integration. Your web service will change over time. The provider will need to change to match it. Your customers will need to use the correct versions of each. You will also want to automatically build and release your provider from GitHub, using GitHub actions.
- Testing. A real web service is complex, and you will need to write a lot of integration tests to ensure that every provider version you release does exactly what it's supposed to when calling the service.
- Documentation. Your customers want to know exactly how to set up and configure your provider to manage whatever resources your service offers.
- Publishing the provider to the Terraform registry. Until you add metadata to your provider and release it in the Terraform ecosystem, no one can use it.
- You also might want to add additional functionality, like handling data sources (which are different from resources) and external imports of resources.

If you want to learn how to enhance your provider, the best place to start is the official [Terraform provider creation tutorial](https://developer.hashicorp.com/terraform/tutorials/providers-plugin-framework/providers-plugin-framework-provider). You can also clone the [provider scaffolding repository](https://github.com/hashicorp/terraform-provider-scaffolding-framework) and read through it to see how Terraform structures a provider and uses `.github` to offer continuous integration.

Once you have worked through the tutorial, we recommend reading the theory on [Terraform plugins in the documentation](https://developer.hashicorp.com/terraform/plugin). Especially promising is the 2024 HashiCorp release of an [automated provider generator](https://developer.hashicorp.com/terraform/plugin/code-generation) from an OpenAPI schema or their custom specification language. Unfortunately, the HashiCorp provider generator is not ready for production use yet — you still need to write a lot of code yourself — but it's something to watch. We have an article discussing its features [here](/post/how-to-build-terraform-providers).

## A Simpler Way

You might feel that creating and maintaining your own Terraform provider is far too much work when you're busy trying to run a business and provide your core service. Luckily, there is a much easier way. We at Speakeasy are passionate about and dedicated to making web APIs easy for customers to use. Our service can automatically generate a complete Terraform provider with documentation that's ready to offer to your customers on the Terraform registry. All you need is an OpenAPI schema for your service and a few custom attributes.

Read about how you can create a Terraform provider with us in a few clicks in this [article](/post/how-to-build-terraform-providers) and see how we can massively reduce your workload.


 This is the content for the doc blog/definitive-guide-to-devex-portals.mdx 

 ---
title: "Definitive Guide to API DevEx Portals"
description: "A definitive guide to building an API DevEx Portal for your API users."
keywords: [api, api portal, developer portal, developer experience, devex, dx, api documentation, api key management, sdk]
image: "/media/definitive-guide-to-devex-portals.png"
date: 2022-11-18
authors:
  - name: Sagar Batchu
  - image_url: 'https://uploads-ssl.webflow.com/62ccd7b208cab0723d026273/62cdf303b28bf9598d7a6b63_sagar_headshot-p-500.jpeg'
tags:
  
  - API Advice
featured_image: "/media/definitive-guide-to-devex-portals.png"
---
import { ReactPlayer } from "~/recipes/Player/ReactPlayer";

## Why You Need A Portal If You Want to Serve Developers

When you’re teaching a kid to drive, you don’t hand them a car key, the operation manual for the car and then leave them to figure it out. Of course you could, but not everyone would get the car moving, and there might be some easily avoided accidents along the way.

But this is exactly how many companies teach people to use their APIs: they hand over a stack of documentation, an API key and call it a day. Of course, those tools are important; without them, your users are stuck at ‘Go’. But these tools alone don’t really deliver any sort of experience to users. It’s basic. It’s lackluster. It’s _an_ experience, but probably not **_THE_** developer experience you want to give your users. It’s certainly not a delightful experience or memorable enough to tell others about. And that lackluster experience has a material impact on the adoption and usage of your API.

If developer experience has been underinvested in, a common set of issues begin to pop up:

- The average time gap between user signup and first successful request is longer than one day.
- Your team spends hours every week troubleshooting client integrations.
- The average number of API calls & endpoints made by users isn’t expanding over time.

Resulting in:

- Decreased API adoption and usage
- A higher cost to support for each user.
- A reduced LTV for each user.

To address these issues you need to vastly improve your API’s DevEx. **The key to a great user experience is providing your users with an API DevEx Portal** which makes your API:

- **Accessible**: there is zero friction to begin sending API requests.
- **Understandable**: users are able to get immediate feedback on their API usage – and to self-service troubleshoot issues when they do occur.
- **Usable**: It is trivially easy for users to discover and test out new use cases for your API that naturally expand their usage.

But what tooling gets you to this point? Let’s walk through each of the above criteria and discuss the specific tools that can help you give your API users the DevEx they deserve.

## What Tooling Does Your API Portal Need

### Accessible

Making the API accessible means making it as easy as possible for users to make that first API call. 99% of companies are still stuck somewhere in this first stage.

**Key Capabilities**:

- **API Documentation** - There has been a pervasive view that documentation equals  great DevEx. We think that documentation is only the first step: it’s critical, but on its own it will still leave your API users wanting. Documentation should be comprehensive, easy to navigate / search, and have code snippets / examples embedded. Ideally, docs should enable users to try the API without any additional tooling or configuration. API docs should also differentiate between API reference (a full list of all endpoints, parameters, response codes, etc.) and usage guides (tutorials that take users step-by-step through how they can use the API to accomplish key tasks).

- **Auth Login** - If you want to offer developers a more personalized experience, auth is the prerequisite. You need to know who someone is before you can issue them an API key, and start giving them tools to help them understand and track their usage. Login should of course be managed by a single shared identity service e.g. auth0 or other system of record – you don’t want to build a separate user management system for your application and your API for example.

- **API Key Management** - Nobody wants to have to fill in a typeform and wait for customer support to review before they can get started with an API. If there’s no way for a developer to create keys on their own, most will never convert into users of your product. By the time someone has reviewed their access request, they will have moved on to a new priority, or found an alternative solution. If the API interfaces with sensitive data, and a review process is a legal requirement for production credentials, then enable users to provision sandbox keys without review (more on Sandboxes below).
  
<div align="center">
<ReactPlayer controls={false} loop={true} playing={true} url='https://storage.googleapis.com/speakeasy-design-assets/videos/key-management.mp4' volume={0} />
<i>Key management in Speakeasy’s API Portal</i>
<br /><br />
</div>

### Understandable

Even companies where APIs are the primary surface area often struggle to make the investment required to advance their developer portal to being understandable.

**Key Capabilities:**

- **API Request Viewer** - When debugging, there’s no substitute for being able to step through things one at a time. A request viewer makes it possible for your users to view the full list of requests they’ve sent to your API – without creating additional work for your team to pull logs, send screenshots via email or Slack, or jump on a Zoom call. Without a self-service request viewer, broken integrations create poor API experience and leads to churned clients. A request viewer should provide users the ability to filter by time, response code, endpoint and more, and ideally allow users to edit and replay the request for quick debugging.

<div align="center">
<ReactPlayer controls={false} loop={true} playing={true} url='https://storage.googleapis.com/speakeasy-design-assets/videos/Rrequest-viewer.mp4' volume={0} />
<i>Request Viewer in Speakeasy’s API Portal</i>
<br /><br />
</div>

- ‍**API Usage Metrics** - A request viewer is only useful to developers if they know there’s an issue to investigate. That is why it’s important to surface key usage metrics in real time – so that users know the overall health of their integration. Usage metrics should place an emphasis on error reporting and significant changes in usage so that your users can take corrective action to any errors or unintended changes.

<div align="center">
<ReactPlayer controls={false} loop={true} playing={true} url='https://storage.googleapis.com/speakeasy-design-assets/videos/usage-dashboard.mp4' volume={0} />
<i>Usage Dashboard in Speakeasy’s API Portal</i>
<br /><br />
</div>

- **API Status Page** - Developers need a place to check if APIs are experiencing downtime. Nothing is more frustrating than having to email a company, “is your API working?” An API status page brings transparency, and transparency is important for building trust with your users.

### Usable

Usability tooling is focused on making it easy to test out new API use cases and also making those new use cases easy to find. Usability tooling shines as APIs become larger. Early on an API will serve a single use case, and documentation will focus on supporting that use case. As the API’s surface area grows, documentation becomes denser, and isolating relevant instructions becomes challenging. Usability tooling will help insulate users against this by providing structure for the documentation, and making it easier to test out new use cases.

**Key Capabilities:**

- **Client SDKs** - You need to meet your developers where they already are. Providing client SDKs makes it easier for developers to get started with your API by grounding them in the familiarity of their favorite language, and significantly reducing the amount of boilerplate they need to write. This is especially true if your SDKs can handle auth, pagination, and retries and others. They are therefore great at helping maximize your audience while minimizing support costs. But it’s not enough to have SDKs, it’s critical that the SDKs are developer-friendly, meaning that they are language idiomatic and human readable. Unfortunately, creating client SDKs is prohibitively expensive for most API teams, since they need to be created and updated by hand. While open source generators exist, the SDKs they output are often buggy and not ergonomic.
- **API Runbooks** - We think of runbooks as live usage guides. They take users step-by-step through the process of using your API to accomplish specific tasks, but also show relevant, live API requests in real-time. This helps to focus developers on the key use cases required to complete API integrations. Your customers can use them to grow their usage of your API. As an API builder, runbooks also help you understand the maturity of your customer base: you can begin to understand your API usage as a customer funnel, and start to measure where and why users drop out of the funnel.  
- **API Sandbox** - Probably nothing helps more with adoption than giving developers an easy way to play with your API. A sandbox can give prospective users a way to use your APIs without needing to sign up for an account. Developers are more likely to trust an API if they’ve seen it working before needing to hand over their information. And a sandbox can give existing users a way to learn by doing, and without any risk of corrupting production workflows. This enables users to easily expand their use cases for your API.

## How to get to Best-In-Class: Build or Buy?

The list above is presented as a rough roadmap. To improve your DevEx, just build each of the tools listed above in order, and you can progress from having no tooling, to having a great Developer Portal.

But as any PM or engineer will tell you, knowing what to build is only the beginning. Finding the resources required to build is the real battle. Great DevEx is extremely important for a successful API, but building all of the above is a huge commitment of resources, requires significant ongoing maintenance, and likely isn’t a core competency for your organization. As a result, investing in Developer Experience continues to be the project that is slated for next quarter.

For almost every company therefore, investing in a best-of-breed solution makes more sense. With an API DevEx Portal from a company like Speakeasy, your customers get a world-class API Developer Experience in days instead of quarters, your product roadmap has negligible impact, and your eng teams don’t need to reinvent the wheel.

Furthermore, our product is designed with maximum flexibility in mind, giving you the best of both worlds. Every tool in our API DevEx Portal is a React component, and can be customized, branded and extended as you need. Similarly, our platform can be self-hosted or run in our Speakeasy Cloud depending on your requirements.

## Final Thoughts

For a long time, companies have been able to get by with substandard developer experiences, but that is beginning to change. Developer Experience is now getting the attention it deserves, and we are rapidly reaching an inflection point. What has been previously considered great DevEx is becoming table stakes for developer products.

We know that DevEx isn’t ignored because companies don’t see the value. Rather, it’s the result of painful prioritization decisions. That’s why Speakeasy exists. We don’t want anyone to have to ever make that tradeoff. With Speakeasy you can get a best-in-class, composable developer portal up and running in a matter of minutes. If you want to learn more, [come chat with us in our Slack](https://join.slack.com/t/speakeasy-dev/shared_invite/zt-1cwb3flxz-lS5SyZxAsF_3NOq5xc8Cjw)!


 This is the content for the doc blog/design-responses.md 

 ---
title: "Designing REST APIs: Responses Your Users Expect"
description: "Practical strategies for designing efficient, informative, and user-friendly API responses."
image: "/media/design-responses.png"
date: 2024-08-06
authors:
 - name: Nolan Sullivan
 - image_url: "/media/author-headshots/nolan.jpeg"
tags:
  - API Advice
featured_image: "/media/design-responses.png"
---

This article shows you how to use your OpenAPI specification to design API responses that are efficient, informative, and user-friendly.

## User-First Design

API requests are only as useful as their responses. So, to design a useful API, you must consider how to structure responses that make sense for your users. A good user experience requires an API that either responds with appropriate data or tells users how to recover from errors.

One way to enhance user experience is to take the _design-first approach_: Write your OpenAPI specification before you code. Starting from a specification puts the user experience at the first step of the development process. The specification has well-defined properties for schemas and responses, which helps you consider how to structure your design. Designing first also helps contain development scope, since developers can code to a precise specification.

This article is a guide to using the OpenAPI specification to design responses. Regardless of whether your API returns a successful ‘200’ status code or an error with a ‘500’ status code, OpenAPI provides you with the tools and methodologies to meticulously design your API responses for optimal performance and seamless user experiences. In the following sections, we will delve into the key principles and best practices to ensure your API responses meet the highest standards of usability, efficiency, and effectiveness.

## Principles of Good API Style

Before you start writing responses, consider the following guiding principles of API design.
From data structure to error messages, these principles should inform every aspect of how you approach responses.

### Be as Explicit as Possible

Describe the data the API returns as explicitly as possible. The more explicit and precise you are, the easier it is for users and their systems to interpret returned values.

The OpenAPI Specification has many properties to describe a data field. Every field requires a defined data type. Beyond this, when possible, also provide additional information about the data format and range, for example, a string may have `minLength` and `maxLength` values. Precise and predictable information helps users handle responses.

Also be explicit in how you name your data properties. Overly general names (like `type`) describe many things. More specific names (like `userType`) immediately provide context about their data.

Explicitness also helps users interpret response descriptions. For example, `List of users` is not as helpful as `List of users with active subscriptions`.

### Be Consistent

Most schemas in OpenAPI can be referenced and reused. Reuse adds consistency and makes writing easier.

Consistent naming conventions make it easier for computers and humans to process information. Consistent response descriptions with parallel grammar and coherent phrasing make response bodies easier to read and interpret.

### Prefer Flat... Until You Need to Nest

As the [Google JSON Style Guide](https://google.github.io/styleguide/jsoncstyleguide.xml) recommends, "data should not be arbitrarily grouped." Group data in objects only when the grouping makes semantic sense and is more convenient.

Each nested object in the specification requires another level of indentation. Be mindful of this indentation – too much might indicate that it's time to refactor.

Of course, information hierarchies often do help categorize and sort information. Use your judgment to determine whether a grouping is worth the added complexity.
 

In the following sections, we'll provide illustrative descriptions of common status codes for better understanding. For the full list, review the [HTTP response status codes](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status) reference. Now, let's continue with the response descriptions that will help us craft precise and informative responses in the OpenAPI specification.

1. In the response object, provide a description.

   Some descriptions are reusable for all status codes.
   Other descriptions may depend on the specific operation.

   ```yaml
   responses:
     "200":
      description: A new user was created.
   ```

   Be as specific as is reasonable.
   Often, `200` statuses use only `OK` for the description, and that might be sufficient.

1. Define content type and schema.

   In the `content` object, describe the content type and the returned schema.
   Often the schema needs only to reference a structure described in the `components` object of your specification.

   REST APIs often return JSON content, `application/json`.
   But other formats, like `text/plain` or `img/png`, are common, too.

All together, a full `responses` object looks something like this:

```yaml
paths:
  /v1/user:
    post:
      operationId: createUserv1
      summary: Create user
      ###
      responses:
        "200":
          content:
            application/json:
              schema:
                ## Reuses the User object
                $ref: "#/components/schemas/User"
          description: OK
        "400":
          description: Bad request. User name must be a string.
        default:
          ## A default response for cases that are undescribed
          $ref: "#/components/responses/default"
```

> **Note:** Each response may also include response headers providing additional context about things like rate limits.

Status, description, and content: that's all you need to describe a response.
However, the best way to structure this content is highly contextually dependent.

The rest of this article recommends how you should describe this content for successful and unsuccessful requests.

## Make Success Feel Successful

Broadly, users make requests for two reasons:

- To get resources
- To create or modify the status of a resource

So, your success responses must tell the user what succeeded and provide the resources they requested.

### Give GETs Their Resources

Users typically expect GET requests to return some data.
The structure and content of the data depend entirely on the resources the application offers.
For specifics about how to describe this data, read our
[guide to data type formats](https://speakeasyapi.dev/post/openapi-tips-data-type-formats/).

However, no matter the specifics, the response to a GET is likely either:

- An object for a specifically requested item
- An array of these items

Many, if not most, of the items returned by a GET are composed of data structures that the API reuses in other requests and responses.
To keep your interface consistent and avoid tedious repetition, describe all reusable items in `components/schemas`.
Then reference the object in your response.

For example, a GET request to a `/users/{user_id}` probably returns a single user object:

```YAML
"200":
  content:
    application/json:
      schema:
        $ref: "#/components/schemas/User"
```

A GET request to just `/users` likely returns an array of these objects.
To describe this array, your schema might reference a `Users` schema that contains an array of `user` objects.
And for list operations like this, remember to paginate.
Large response bodies can become performance bottlenecks. Even if the listed objects are few at first, the number will grow with your user base.

In this schema, pagination is described by the `offset` property.

```yaml
users:
  description: A list of users to return.
  items:
    $ref: "#/components/schemas/User"
  type: array
offset:
  type: integer
  description: The page to return
  default: 1
```

### Define Payloads for Other Methods by Use Case

For other methods, like PUT and POST, the payloads are more variable.

For example, if a POST creates an object, users may find it convenient for the API to return the created object.
However, returning the full object may not always be useful or practical, especially when there are performance constraints to consider.
In these cases, it may be sufficient to return only the newly created ID with a link, or a link to its resource (refer to the `201` status described in the subsequent section).

Similar advice applies to PUT and PATCH requests.
If returning the object isn't necessary, your response might require only a description that informs the user of the new status.

```yaml
put:
  "200":
    description: User was updated.
```

> Besides, POST requests often do more than create, since the flexible syntax lends itself to custom operations.

### Going Beyond 200

`200` is the most common success status, but not the only one.
If appropriate, consider including the following codes as responses for some operations.

- `201`: Lets users know the resource is created. Returns a link instead of an object.
- `204`: Indicates an empty response body (and informs that an empty body is expected). Some APIs use the `204` status to indicate success for operations that don't require additional information or resources. For example, a successful DELETE request operates on resources that, by definition, no longer exist when its response is sent. A `204 No Content` can indicate that the resource was successfully deleted and that the empty body is part of the defined behavior.

## Return Errors That Inform and Help Recover

By definition, errors mean the API did not return a requested resource.
If a call returns an error, tell users what happened and how they can recover.

Your specification should describe all known responses to codify errors and suggest appropriate recovery.
For some errors, a status code and terse description provide enough information.
Other errors may require different bodies for different operations.

### Reuse Descriptions for Standard Errors

Some error statuses always have the same causes and the same response bodies.
For example, `429` errors always indicate that a rate limit was reached, and `418` errors always indicate that the user should [make a cup of tea](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/418).

To minimize writing and to maintain message consistency for users,
define these responses in your `components/responses` object and reuse them across definitions.

Here's an example of a `responses` object whose properties all refer to reusable error bodies:

```yaml
responses:
  "401":
    $ref: "#/components/responses/401"
  "403":
    $ref: "#/components/responses/403"
  "404":
    $ref: "#/components/responses/404"
  "429":
    $ref: "#/components/responses/429"
```

The content for these errors is described in the `components` part of the specification:

```YAML
components:
  responses:
    "401":
      description: Unauthorized. The request did not have a valid API key.
    "403":
      description: Forbidden. This API key doesn't have necessary permissions.
    "404":
      description: Not Found. Server cannot find the requested resource.
    "429":
      description: Too Many Requests. The rate limit has been reached for this API key.
```

### Provide Details To Help Fix Bad Requests

Other status codes may need more than a generic message.
For example, requests that receive a `400 Bad request` status often have invalid fields.
For these cases, consider giving each relevant operation a unique `400` description that describes its necessary fields.

```YAML
/v1/user:
   post:
    summary: Create user
    responses:
      "400":
          description: Bad request. Operation requires valid `username` and `email` fields.
          content:
            schema:
                $ref: "#/components/schemas/FailedUserCreation"
```

A caveat for this recommendation is that the number of response bodies can be very large, especially if responses are dynamically generated based on field-validation errors.

It may be impractical to describe all error cases.
As a workaround, some specification authors write only a specific `description` (as in the preceding snippet), then refer to a generic `400` schema with placeholder values.

## Multi-Purpose Response Descriptions

When referencing a reusable component is insufficient, the OpenAPI Specification has a few features to make descriptions more flexible.
These features provide ways to join sets of schemas, define responses across a range of statuses, or provide default responses.

### Join Schemas With `allOf`

You might want to compose a response from separate schemas.
For example, a request for a resource about an administrative user might include the basic `user` object along with additional properties particular to administrators.
In this case, describe your schemas with the `allOf` operator, putting each schema as an item in an array.

```yaml
Admin:
  description: A user with admin privileges
  allOf:
  - $ref: '#/components/schemas/User'
  - type: object
    properties:
      super_admin:
        type: boolean
        description: Whether the user has super admin privileges
```

For another use of `allOf`, the API may have basic and extended error models, as given in the [example from the specification](https://spec.openapis.org/oas/latest.html#schemaObject).

### Select Schemas With `anyOf` and `oneOf`

These operators describe responses that might contain some combination of schemas.
Similar to `allOf`, these operators are defined in an array.

For example, a request to an endpoint called `/one-binary-number` might return one of two possible schemas:

```yaml
myBinarySymbol:
  oneOf:
  - $ref: '#/components/schemas/zero'
  - $ref: '#/components/schemas/one'
```

Alternatively, `anyOf` could return one or both of the preceding references.

### Status Ranges

Sometimes, a single response is enough for an entire numeric range of statuses.
For these times, use the `nXX` convention (where `n` is the number the status code starts with).

For example, you may want all 500 errors to return the same body:

```yaml
'5XX':
  description: This was our fault. Please wait a minute and try again.
```

> This `xx` description _does not_ override other defined responses for the same error class.
> So you could describe, for example, the `501` error explicitly, then use `5xx` as a catch-all for all other server-side errors.

### The Default Property

As this article has emphasized, specificity is generally preferred.
But a well-defined default can also be important.

For these times, the `responses` object also accepts a `default` property:

```yaml
paths:
  /health:
    get:
      responses:
        "200":
          description: OK
        default:
          ## reusable default
          $ref: "#/components/responses/default"

## default definition

components:
  responses:
    default:
      content:
        application/json:
          schema:
            $ref: "#/components/schemas/Error"
      description: Default error response
```

## Conclusion

If you choose the design-first approach, the OpenAPI Specification provides a great authoring medium, with well-defined properties to structure well-defined data. It also has a robust ecosystem of tooling, which comes with its own benefits, as you can use the specification to create SDKs, contract test, mock servers, and so on.

But no matter how you write your API, the principles of design don't change. An API is as good as the value it returns. So, when you create an API, design its responses from the user's perspective.

## Further Reading

The following links are for canonical sources of information relevant to OpenAPI and HTTP responses.

- [MDN: HTTP status codes](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status)
- [RFC 9110: HTTP semantics](https://www.rfc-editor.org/rfc/rfc9110.html)  
- [The OpenAPI specification](https://spec.openapis.org/oas/latest.html)


 This is the content for the doc blog/e2e-testing-arazzo/index.mdx 

 ---
title: "End-to-end API testing with Arazzo, TypeScript, and Deno"
description: "Learn how to create resilient E2E API tests using Arazzo, TypeScript, and Deno, catching issues before customers do."
image: "/media/contract-testing-with-openapi.png"
date: 2024-10-30
authors:
  - name: Brian Flad
  - image_url: "/media/author-headshots/nolan.jpeg"
tags:

featured_image: "/media/contract-testing-with-openapi.png"
---

import { ScrollyCoding } from "~/components/codehike/Scrollycoding";
import { Callout } from "~/components";

We've previously written about [the importance of building contract & integration tests](/post/contract-testing-with-openapi) to comprehensively cover your API's endpoints, but there's still a missing piece to the puzzle. Real users don't consume your API one endpoint at a time - they implement complex workflows that chain multiple API calls together.

That's why reliable **end-to-end API tests** are an important component of the testing puzzle. For your APIs most common workflows, you need to ensure that the entire process works as expected, not just the individual parts.

In this tutorial, we'll build a test generator that turns Arazzo specifications into executable end-to-end tests. You'll learn how to:

- Generate tests that mirror real user interactions with your API
- Keep tests maintainable, even as your API evolves
- Validate complex workflows across multiple API calls
- Catch integration issues before they reach production

We'll use a simple "Build-a-bot" API as our example, but the principles and code you'll learn apply to any REST API.

## Arazzo? What & Why

Arazzo is a specification that describes how API calls should be sequenced to achieve specific outcomes. Think of it as OpenAPI for workflows - while OpenAPI describes what your API can do, Arazzo describes how to use it effectively.

Arazzo was designed to bridge the gap between API reference documentation and real-world usage patterns. Fortunately for us, it also makes a perfect fit for generating end-to-end test suites that validate complete user workflows rather than isolated endpoints.

By combining these specifications, we can generate tests that validate not just the correctness of individual endpoints, but the entire user journey.

<Callout title="Arazzo?" variant="info">
  Arazzo roughly translates to "tapestry" in Italian. Get it? A tapestry of API
  calls "woven" together to create a complete user experience. We're still
  undecided about how to pronounce it, though. The leading candidates are
  "ah-RAT-so" (like fatso) and "ah-RAHT-zoh" (almost like pizza, but with a
  rat). There is a minor faction pushing for "ah-razzo" as in razzle-dazzle.
  We'll let you decide.
</Callout>

Let's look at a simplified (and mostly invalid) illustrative example. Imagine a typical e-commerce API workflow:

```yaml arazzo.yaml
arazzo: 1.0.0
workflowId: purchaseProduct
sourceDescriptions:
  - url: ./openapi.yaml
steps:
  - stepId: authenticate
    operationId: loginUser
    # post login details
    # response contains auth token
    # if successful, go to checkInventory
  - stepId: checkInventory
    operationId: getProductsStock
    # with auth token from previous step:
    # get stock levels of multiple products
    # response contains product IDs and stock levels
    # if stock levels are sufficient, go to createOrder
  - stepId: createOrder
    operationId: submitOrder
    # with auth token from first step
    # and product IDs and quantities from previous step
    # post an order that is valid based on stock levels
    # response contains order ID
    # if successful, go to getOrder
# ...
```

Arazzo allows us to define these workflows, and specify how each step should handle success and failure conditions, as well as how to pass data between steps and even between workflows.

## From specification to implementation

The example above illustrates the concept, but let's dive into a working implementation. We'll use a simplified but functional example that you can download and run yourself. Our demo implements a subset of the Arazzo specification, focusing on the most immediately valuable features for E2E testing.

We'll use the example of an API called Build-a-bot, which allows users to create and manage their own robots. You can substitute this with your own OpenAPI document, or use the Build-a-bot API to follow along.

## Arazzo deep dive

Let's examine the key components of an Arazzo specification using our Build-a-bot API example. The specification describes a workflow for creating, assembling, and activating a robot - a perfect example of a complex, multi-step process that would be difficult to test with traditional approaches.

<ScrollyCoding fullHeight>

## !!steps

The header identifies this as an Arazzo 1.0.0 specification and references the OpenAPI document. This connection between Arazzo and OpenAPI is crucial - it allows us to validate that the workflow steps match the API's capabilities.

```yaml ! arazzo.yaml focus=1:10
!from ./assets/arazzo.yaml.txt
```

---

## !!steps

Each workflow has a unique ID and can specify required inputs. In this case, we need an API key for authentication.

```yaml ! arazzo.yaml focus=12:20
!from ./assets/arazzo.yaml.txt
```

---

## !!steps

Let's look at the first step in our workflow. This step demonstrates several key Arazzo features.

```yaml ! arazzo.yaml focus=21:49
!from ./assets/arazzo.yaml.txt
```

---

## !!steps

Each step has a unique `stepId`, and a `description`. The `stepId` is particularly important, as it allows us to reference this step's outputs in subsequent steps.

```yaml ! arazzo.yaml focus=21:49 mark=22:23
!from ./assets/arazzo.yaml.txt
```

---

## !!steps

Each step also specifies an `operationId`, which corresponds to an operation in the OpenAPI document. This connection ensures that the workflow steps are always in sync with the API's capabilities.

```yaml ! arazzo.yaml
# !focus(21:49)
# !mark(24[9:32])
```

---

## !!steps

A step can define a list of `parameters` that should be passed to the operation. These parameters can be static values, references to outputs from previous steps, runtime expressions that reference many other variables, or reusable objects.

```yaml ! arazzo.yaml focus=21:49 mark=25:28
!from ./assets/arazzo.yaml.txt
```

---

## !!steps

In this example, the `x-api-key` header is required for authentication. The value for the header is gathered at runtime from the workflow's inputs, using a runtime expression: `$inputs.BUILD_A_BOT_API_KEY`. We'll explore other available expressions later.

```yaml ! arazzo.yaml
# !focus(25:28)
# !mark(28[20:46])
```

---

## !!steps

Next up, the step defines a `requestBody` object. This object specifies the request body for the operation, which is required for creating a new robot design session.

Because the request body doesn't specify a `contentType`, Arazzo will look up the `content-type` in the OpenAPI document for the operation.

```yaml ! arazzo.yaml focus=29:32
!from ./assets/arazzo.yaml.txt
```

---

## !!steps

This brings us to the meat of the step, the `successCriteria` list. This list defines the conditions that must be met for the step to be considered successful.

Each success criterion in the step serves a specific purpose.

```yaml ! arazzo.yaml focus=33:43
!from ./assets/arazzo.yaml.txt
```

---

## !!steps

First, we validate the HTTP status code. This is a basic but essential check - the robot-creation endpoint should return `201 Created`.

```yaml ! arazzo.yaml focus=34
!from ./assets/arazzo.yaml.txt
```

---

## !!steps

Next, we validate the `robotId` using a regex pattern. This ensures the ID follows the expected UUID v4 format. Notice how we use the `context` field to specify which part of the response to validate, and the `type` field to indicate we're using a regex pattern.

```yaml ! arazzo.yaml focus=35:37
!from ./assets/arazzo.yaml.txt
```

---

## !!steps

The next three criteria validate specific fields in the response body using direct comparisons. These ensure the robot is created with the correct model, name, and initial status.

```yaml ! arazzo.yaml focus=38:40
!from ./assets/arazzo.yaml.txt
```

---

## !!steps

Finally, we use JSONPath to validate the structure of the `links` array. The condition `$.length == 5` checks that exactly five links are returned.

```yaml ! arazzo.yaml focus=41:43
!from ./assets/arazzo.yaml.txt
```

---

## !!steps

After successful validation, the step defines its outputs and next action.

```yaml ! arazzo.yaml focus=44:49
!from ./assets/arazzo.yaml.txt
```

---

## !!steps

The `outputs` section extracts the `robotId` from the response body using a JSON pointer. This ID will be available to subsequent steps through the runtime expression `$steps.createRobot.outputs.robotId`.

```yaml ! arazzo.yaml
# !focus(44:49)
# !mark(49[20:42])
```

---

## !!steps

The `onSuccess` action specifies that after successful validation, the workflow should proceed to the `addParts` step. This explicit flow control helps maintain clear step sequencing.

```yaml ! arazzo.yaml focus=44:47
!from ./assets/arazzo.yaml.txt
```

</ScrollyCoding>

This combination of validation patterns, data extraction, and flow control creates the foundation for testing complex API workflows.

Each success criterion serves a specific purpose in ensuring the API behaves as expected, while the outputs and success actions enable smooth workflow progression.

We'll explore the concepts we covered in more detail in the next sections, but first, let's set up a development environment so we can see Arazzo in action.

## Setting up the development environment

First, clone the demo repository:

```bash
git clone https://github.com/speakeasy-api/e2e-testing-arazzo.git
cd e2e-testing-arazzo
```

You'll need [Deno v2](https://docs.deno.com/runtime/) installed. On macOS and Linux, you can install Deno using the following command:

```bash
curl -fsSL https://deno.land/install.sh | sh
```

The repository contains:

- A simple API server built with [@oak/acorn](https://oakserver.org/acorn) that serves as the Build-a-bot API (in `packages/server/server.ts`)
- An Arazzo specification file (`arazzo.yaml`)
- An OpenAPI specification file (`openapi.yaml`)
- The test generator implementation (`packages/arazzo-test-gen/generator.ts`)
- Generated E2E tests (`tests/generated.test.ts`)
- An SDK created by Speakeasy to interact with the Build-a-bot API (`packages/sdk`)

### Running the Demo

To run the demo, start the API server:

```bash
deno task server
```

Deno will install the server's dependencies, then start the server on `http://localhost:8080`. You can test the server by visiting `http://localhost:8080/v1/robots`, which should return a `401 Unauthorized` error:

```json
{
  "status": 401,
  "error": "Unauthorized",
  "message": "Header x-api-key is required"
}
```

Next, in a new terminal window, generate the E2E tests:

```bash
deno task dev
```

After installing dependencies, this command will generate the E2E tests in `tests/generated.test.ts` and watch for changes to the Arazzo specification file.

You can run the tests in a new terminal window:

```bash
deno task test
```

This command will run the generated tests against the API server:

```txt
> deno task test
Task test deno test --allow-read --allow-net --allow-env --unstable tests/
running 1 test from ./tests/generated.test.ts
Create, assemble, and activate a new robot ...
  Create a new robot design session ... ok (134ms)
  Add parts to the robot ... ok (2ms)
  Assemble the robot ... ok (1ms)
  Configure robot features ... ok (2ms)
  Activate the robot ... ok (3ms)
  Get the robot details ... ok (1ms)
Create, assemble, and activate a new robot ... ok (143ms)
 
ok | 1 passed (6 steps) | 0 failed (147ms)
```

Beautiful, everything works! Let's see how we got here.

## Building an Arazzo test generator

Let's start with the overall structure of the test generator.

### Project structure

The test generator is a Deno project that consists of several modules, each with a specific responsibility:

- `generator.ts`: The main entry point that orchestrates the test generation process. It reads the Arazzo and OpenAPI specifications, validates their compatibility, and generates test cases.

- `readArazzoYaml.ts` and `readOpenApiYaml.ts`: Handle parsing and validation of the Arazzo and OpenAPI specifications respectively. They ensure the specifications are well-formed and contain all required fields.

- `expressionParser.ts`: A parser for runtime expressions like `$inputs.BUILD_A_BOT_API_KEY` and `$steps.createRobot.outputs.robotId`. These expressions are crucial for passing data between steps and accessing workflow inputs.

- `successCriteria.ts`: Processes the success criteria for each step, including status code validation, regex patterns, direct comparisons, and JSONPath expressions.

- `generateTestCase.ts`: Takes the parsed workflow and generates the actual test code, including setup, execution, and validation for each step.

- `security.ts`: Handles security-related aspects like API key authentication and other security schemes defined in the OpenAPI specification.

- `utils.ts`: Contains utility functions for common operations like JSON pointer resolution and type checking.

The project also includes a `runtime-expression` directory containing the grammar definition for runtime expressions:

- `runtimeExpression.peggy`: A Peggy grammar file that defines the syntax for runtime expressions
- `runtimeExpression.js`: The generated parser from the grammar
- `runtimeExpression.d.ts`: TypeScript type definitions for the parser

Let's dive deeper into each of these components to understand how they work together to generate effective E2E tests.

### Parsing until you parse out

While our project says "test generator" on the tin, the bulk of our work will go into parsing different formats. To generate tests from an Arazzo document, we need to parse:

1. The Arazzo document
2. The OpenAPI document
3. Conditions in the Arazzo success criteria
4. Runtime expressions in the success criteria, outputs, and parameters
5. Regular expressions in the success criteria
6. JSONPath expressions in the success criteria
7. JSON pointers in the runtime expressions

We won't cover all of these in detail, but we'll touch on each to get a sense of the complexity involved and the tools we use to manage it.

### Parsing the Arazzo specification

The first step in our test generator is parsing the Arazzo specification in `readArazzoYaml.ts`. This module reads the Arazzo YAML file and should ideally validate its structure against the Arazzo specification.

For our demo, we didn't implement full validation, instead parsing the YAML file into a JavaScript object. We then use TypeScript interfaces to define the expected structure of the Arazzo document:

```typescript
export interface ArazzoDocument {
  arazzo: string;
  info: ArazzoInfo;
  sourceDescriptions: Array<ArazzoSourceDescription>;
  workflows: Array<ArazzoWorkflow>;
  components: Record<string, unknown>;
}

export interface ArazzoWorkflow {
  workflowId: string;
  description: string;
  inputs: {
    type: string;
    properties: Record<string, { type: string; description: string }>;
  };
  steps: Array<ArazzoStep>;
}

export interface ArazzoStep {
  stepId: string;
  description: string;
  operationId: string;
  parameters?: Array<ArazzoParameter>;
  requestBody?: ArazzoRequestBody;
  successCriteria: Array<ArazzoSuccessCriterion>;
  outputs?: Record<string, string>;
}
```

These TypeScript interfaces help with autocompletion, type checking, and documentation, making it easier to work with the parsed Arazzo document in the rest of our code.

The real complexity comes in validating that the parsed document follows all the rules in the Arazzo specification. For example:

- Each `workflowId` must be unique within the document
- Each `stepId` must be unique within its workflow
- An `operationId` must reference a valid operation in the OpenAPI document
- Runtime expressions must follow the correct syntax
- Success criteria must use valid JSONPath or regex patterns

We don't validate all these rules in our demo, but in production, we'd use [Zod](https://zod.dev/) or [Valibot](https://valibot.dev/) to enforce these constraints at runtime and provide helpful error messages when the document is invalid.

The OpenAPI team hasn't finalized the Arazzo specification's JSON Schema yet, but once they do, we can use it to validate the Arazzo document against the schema with tools like [Ajv](https://ajv.js.org/).

Speakeasy also provides a [command-line interface](/docs/speakeasy-cli/getting-started) for linting Arazzo documents:

```bash
# Expects arazzo.yaml in the current directory
speakeasy lint arazzo
```

### Parsing the OpenAPI specification

The OpenAPI specification's path is gathered from the Arazzo document. In our test, we simply use the first `sourceDescription` to find the OpenAPI document path. But in a production generator, we'd need to handle multiple `sourceDescriptions` and ensure the OpenAPI document is accessible.

We parse the OpenAPI document in `readOpenApiYaml.ts` and use TypeScript interfaces from the [`npm:openapi-types`](https://www.npmjs.com/package/openapi-types) package to define the expected structure of the OpenAPI document.

We won't cover the OpenAPI parsing in detail, but it's similar to the Arazzo parsing: Read the YAML file, parse it into a JavaScript object, and type check it against TypeScript interfaces.

For OpenAPI, writing a custom validator is more complex due to the specification's size and complexity. We recommend validating against the [official OpenAPI 3.1.0 JSON Schema](https://spec.openapis.org/oas/v3.1.0/schema/) using [Ajv](https://ajv.js.org/), or Speakeasy's own OpenAPI linter:

```bash
speakeasy lint openapi --schema openapi.yaml
```

### Parsing success criteria

This is where things get interesting. Success criteria in Arazzo are a list of conditions that must be met for a step to be considered successful. Each criterion can be one of the following types:

- `simple`: Selects a value with a runtime expression and compares it to an expected value
- `jsonpath`: Selects a value using a JSONPath expression and compares it to an expected value
- `regex`: Validates a value against a regular expression pattern
- `xpath`: Selects a value using an XPath expression and compares it to an expected value, used for XML documents

In our demo, we don't implement the `xpath` type, but we do cover the other three. Here's an example of a success criterion in the Arazzo document:

```yaml
successCriteria:
  - condition: $statusCode == 201
  - condition: /^[0-9A-F]{8}-[0-9A-F]{4}-[4][0-9A-F]{3}-[89AB][0-9A-F]{3}-[0-9A-F]{12}$/i
    context: $response.body#/robotId
    type: regex
  - condition: $response.body#/model == "humanoid"
  - condition: $response.body#/name == "MyFirstRobot"
  - condition: $response.body#/status == "designing"
  - context: $response.body#/links
    condition: $.length == 5
    type: jsonpath
```

The `condition` field is required, and contains the expression to evaluate, while the `context` field specifies the part of the response to evaluate. The `type` field indicates the type of validation to perform.

If no `type` is specified, the success criterion is treated as a `simple` comparison, where the `condition` is evaluated directly.

### Evaluating simple criteria

Here's an example of how we parse a `simple` success criterion:

```yaml
condition: $statusCode == 201
```

We split this simple condition into:

- Left-hand side: `$statusCode` - Runtime expression to evaluate
- Operator: `==` - Comparison operator or assertion
- Right-hand side: `201` - Expected value

We'll evaluate the runtime expression `$statusCode` and compare it to the expected value `201`. If the comparison is true, the criterion passes; otherwise, it fails.

Runtime expressions can also reference other variables, like `$inputs.BUILD_A_BOT_API_KEY` or `$steps.createRobot.outputs.robotId`, or fields in the response body, like `$response.body#/model`.

We'll cover runtime expressions in more detail later.

### Evaluating JSONPath criteria

For JSONPath criteria, we use the `jsonpath` type and a JSONPath expression to select a value from the response:

```yaml
context: $response.body#/links
condition: $.length == 5
type: jsonpath
```

Let's break down the JSONPath criterion:

- `context`: `$response.body#/links` - Runtime expression to select the `links` array from the response body
- `condition`: `$.length == 5` - JSONPath expression compared to an expected value
- `type`: `jsonpath` - Indicates the criterion type

We further need to break down the condition into:

- Left-hand side: `$.length` - JSONPath expression to evaluate
- Operator: `==` - Comparison operator
- Right-hand side: `5` - Expected value

We evaluate the JSONPath expression `$.length` and compare it to the expected value `5`. If the comparison is true, the criterion passes.

### Evaluating regex criteria

For regex criteria, we use the `regex` type and a regular expression pattern to validate a value:

```yaml
context: $response.body#/robotId
condition: /^[0-9A-F]{8}-[0-9A-F]{4}-[4][0-9A-F]{3}-[89AB][0-9A-F]{3}-[0-9A-F]{12}$/i
type: regex
```

Let's break down the regex criterion:

- `context`: `$response.body#/robotId` - Runtime expression to select the `robotId` field from the response body
- `condition`: `/^[0-9A-F]{8}-[0-9A-F]{4}-[4][0-9A-F]{3}-[89AB][0-9A-F]{3}-[0-9A-F]{12}$/i` - Regular expression pattern to validate the value as a UUID v4
- `type`: `regex` - Indicates the criterion type

We evaluate the runtime expression `$response.body#/robotId` against the regular expression pattern. If the value matches the pattern, the criterion passes.

In our implementation, we use TypeScript's `factory.createRegularExpressionLiteral` to create a regular expression literal from the pattern string. This ensures that the pattern is properly escaped and formatted as a valid JavaScript regular expression.

The generated test code looks something like this:

```typescript
assertMatch(
  response.body.robotId,
  new RegExp(/^[0-9A-F]{8}-[0-9A-F]{4}-[4][0-9A-F]{3}-[89AB][0-9A-F]{3}-[0-9A-F]{12}$/i),
  'robotId should be a valid UUID v4'
);
```

This code uses Deno's built-in `assertMatch` function to validate that the `robotId` matches the UUID v4 pattern. If the value doesn't match, the test fails with a helpful error message.

### Parsing runtime expressions

Runtime expressions are used throughout the Arazzo specification to reference variables, fields in the response body, or outputs from previous steps. They follow a specific syntax defined in the Arazzo specification as an ABNF (augmented Backus–Naur form) grammar.

To parse runtime expressions, we use a parser generated from the ABNF grammar. In our demo, this is a two-step process. First, we use the [abnf](https://www.npmjs.com/package/abnf) npm package to generate a Peggy grammar file from the ABNF grammar:

```bash
cd packages/arazzo-test-gen
abnf_gen runtime-expression/runtimeExpression.abnf
```

This generates a `runtime-expression/runtimeExpression.peggy` file that defines the syntax for runtime expressions. We then use the [peggy](https://www.npmjs.com/package/peggy) npm package to generate a parser from the Peggy grammar:

```bash
cd packages/arazzo-test-gen
peggy --dts --output runtime-expression/runtimeExpression.js --format es runtime-expression/runtimeExpression.peggy
```

This generates a `runtime-expression/runtimeExpression.js` file that contains the parser for runtime expressions. We also generate TypeScript type definitions in `runtime-expression/runtimeExpression.d.ts`.

The parser reads a runtime expression like `$response.body#/robotId` and breaks it down into tokens. We then evaluate the tokens to resolve the expression at runtime.

### Evaluating runtime expressions

Once we've parsed a runtime expression, we need to evaluate it to get the value it references. For example, given the expression `$response.body#/robotId`, we need to extract the `robotId` field from the response body.

The `evaluateRuntimeExpression` function in `utils.ts` handles this evaluation. Here's an example of how it works:

```typescript
switch (root) {
  case "$statusCode": {
    // Handle $statusCode expressions
    result = factory.createPropertyAccessExpression(
      factory.createIdentifier("response"),
      factory.createIdentifier("status"),
    );
    break;
  }
  case "$response.": {
    // Handle $request and $response expressions
    const data = factory.createIdentifier("data");
    // use parseRef to handle everything after $response.body
    const pointer = parsePointer(expression.slice(15));
    result = pointer.length > 0
      ? factory.createPropertyAccessExpression(data, pointer.join("."))
      : data;
    break;
  }
  // Handle other cases ...
}
```

Here, we handle two types of runtime expressions: `$statusCode` and `$response.body`. We extract the `status` field from the `response` object for `$statusCode`, and the `body` object from the `response` object for `$response.body`.

We use the TypeScript compiler API to generate an abstract syntax tree (AST) that represents the expression. This AST is then printed to a string and saved as a source file that Deno can execute.

### Supported runtime expressions

In our demo, we support a limited set of runtime expressions:

- `$statusCode`: The HTTP status code of the response
- `$steps.stepId.outputs.field`: The output of a previous step
- `$response.body#/path/to/field`: A field in the response body selected by a JSON pointer

Arazzo supports many more runtime expressions, for example:

| Expression                         | Description                                                         |
| ---------------------------------- | ------------------------------------------------------------------- |
| `$url`                             | The full URL of the request                                         |
| `$method`                          | The HTTP method of the request                                      |
| `$statusCode`                      | The HTTP status code of the response                                |
| `$request.header.{name}`           | The value of the specified request header                           |
| `$request.query.{name}`            | The value of the specified query parameter from the request URL     |
| `$request.path.{name}`             | The value of the specified path parameter from the request URL      |
| `$request.body`                    | The entire request body                                             |
| `$request.body#/path/to/property`  | The value of the specified JSON pointer path from the request body  |
| `$response.header.{name}`          | The value of the specified response header                          |
| `$response.body`                   | The entire response body                                            |
| `$response.body#/path/to/property` | The value of the specified JSON pointer path from the response body |
| `$inputs.{name}`                   | The value of the specified workflow input                           |
| `$outputs.{name}`                  | The value of the specified workflow output                          |
| `$steps.{stepId}.{outputName}`     | The value of the specified output from the step with ID `{stepId}`  |
| `$workflows.{id}.{inputName}`      | The value of the specified input from the workflow with ID `{id}`   |
| `$workflows.{id}.{outputName}`     | The value of the specified output from the workflow with ID `{id}`  |

### Parsing regular expressions

Regular expressions in Arazzo are used to validate string values against patterns. They're particularly useful for validating IDs, dates, and other structured strings.

In our implementation, we handle regex patterns in the `parseRegexCondition` function:

```typescript
function parseRegexCondition(
  condition: string,
  usedAssertions: Set<string>,
  context: string,
): Expression {
  usedAssertions.add("assertMatch");
  return factory.createCallExpression(
    factory.createIdentifier("assertMatch"),
    undefined,
    [
      evaluateRuntimeExpression(context),
      factory.createNewExpression(
        factory.createIdentifier("RegExp"),
        undefined,
        [factory.createRegularExpressionLiteral(condition)],
      ),
      factory.createStringLiteral(condition),
    ],
  );
}
```

This function takes three parameters:

- `condition`: The regex pattern to match against
- `usedAssertions`: A set to track which assertion functions we've used
- `context`: The runtime expression that selects the value to validate

The function generates code that:

1. Evaluates the context expression to get the value to validate
2. Creates a new RegExp object from the pattern
3. Uses Deno's `assertMatch` function to validate the value against the pattern

The generated code looks like this:

```typescript
assertMatch(
  response.body.robotId,
  new RegExp(/^[0-9A-F]{8}-[0-9A-F]{4}-[4][0-9A-F]{3}-[89AB][0-9A-F]{3}-[0-9A-F]{12}$/i),
  'robotId should be a valid UUID v4'
);
```

This approach has several advantages:

- It preserves the original pattern's flags (like `i` for case-insensitive matching).
- It provides clear error messages when validation fails.
- It integrates well with Deno's testing framework.

In a production implementation, we'd want to add:

- Validation of the regex pattern syntax
- Support for named capture groups
- Error handling for malformed patterns
- Performance optimizations like pattern caching

But for our demo, this simple implementation is sufficient to show how regex validation works in Arazzo.

### Parsing JSONPath expressions

JSONPath expressions are a powerful way to query JSON data. In Arazzo, we use them in success criteria to select objects or values from complex response structures. While JSON Pointer (which we'll cover next) is great for accessing specific values, JSONPath shines when you need to:

- Validate arrays (for example, checking array length)
- Filter elements (for example, finding items matching a condition)
- Access deeply nested data with wildcards
- Aggregate values (for example, counting matches)

Here's how our test generator handles JSONPath expressions:

```typescript
function parseJsonPathExpression(path: string, context: string): Expression {
  return factory.createCallExpression(
    factory.createIdentifier("JSONPath"),
    undefined,
    [
      factory.createObjectLiteralExpression(
        [
          factory.createPropertyAssignment(
            factory.createIdentifier("wrap"),
            factory.createFalse(),
          ),
          factory.createPropertyAssignment(
            factory.createIdentifier("path"),
            factory.createStringLiteral(path),
          ),
          factory.createPropertyAssignment(
            factory.createIdentifier("json"),
            evaluateRuntimeExpression(context),
          ),
        ],
        true,
      ),
    ],
  );
}
```

This function generates code that evaluates a JSONPath expression against a context object (usually the response body). For example, given this success criterion:

```yaml
successCriteria:
  - context: $response.body#/links
    condition: $.length == 5
    type: jsonpath
```

Our generator creates a test that:

1. Extracts the `links` array from the response body using a JSON pointer
2. Evaluates the JSONPath expression `$.length` against this array
3. Compares the result to the expected value `5`

The generated test code looks something like this:

```typescript
assertEquals(
  JSONPath({
    wrap: false,
    path: "$.length",
    json: response.body.links
  }),
  5,
  "links array should contain exactly 5 elements"
);
```

JSONPath is particularly useful for validating:

- Array operations: `$.length`, `$[0]`, `$[(@.length-1)]`
- Deep traversal: `$..name` (all name properties at any depth)
- Filtering: `$[?(@.status=="active")]` (elements where status is `active`)
- Wildcards: `$.*.name` (name property of all immediate children)

A few things to keep in mind when using JSONPath:

1. JSONPath isn't well standardized, so different implementations vary widely. Arazzo makes provisions for this by allowing us to specify the JSONPath version in the test specification.
2. Even though we can specify a version, we still need to be cautious when using advanced features. Some features might not be supported by the chosen JSONPath library.
3. Check the [JSONPath comparison](https://cburgmer.github.io/json-path-comparison/) page to see how different libraries handle various features, and decide which features are safe to use.

### Parsing JSON Pointers

While JSONPath is great for complex queries, [JSON Pointer (RFC 6901)](https://datatracker.ietf.org/doc/html/rfc6901) is perfect for directly accessing specific values in a JSON document. In Arazzo, we use JSON Pointers in runtime expressions to extract values from responses and pass them to subsequent steps.

Here's how our test generator handles JSON Pointers:

```typescript
function evaluateRuntimeExpression(expression: string): Expression {
  // ...
  case "$response.": {
    const data = factory.createIdentifier("data");
    // Parse everything after $response.body
    const pointer = parsePointer(expression.slice(15));
    result = pointer.length > 0
      ? factory.createPropertyAccessExpression(data, pointer.join("."))
      : data;
    break;
  }
  // ...
}
```

This function parses runtime expressions that use JSON Pointers. For example, given this output definition:

```yaml
outputs:
  robotId: $response.body#/robotId
```

Our generator creates code that:

1. Takes the part after `#` as the JSON Pointer (`/robotId`)
2. Converts the pointer segments into property access expressions
3. Generates code to extract the value

The generated test code looks something like this:

```typescript
// During test setup
const context = {};
// ...
// In the first test
const data = response.json();
// Generated because of outputs: { robotId: $response.body#/robotId } in the Arazzo document
// highlight-next-line
context["createRobot.outputs.robotId"] = data.robotId;
// ...
// In a subsequent test
const robotId = context["createRobot.outputs.robotId"];
const response = await fetch(`${serverUrl}/v1/robots/${robotId}/assemble`, {
  // ...
});
```

## Generating end-to-end tests

Now that we understand how to parse Arazzo documents, let's look at how we generate executable tests from them. Our generator creates type-safe test code using TypeScript's factory methods rather than string templates, providing better error detection and maintainability.

### Test structure

The generator creates a test suite for each workflow in the Arazzo document. Each step in the workflow becomes a test case that executes sequentially.

Let's explore the structure of a generated test case.

<ScrollyCoding fullHeight>

## !!steps

We start by setting up a test suite for the workflow, using the Arazzo workflow `description` as the suite name.

```typescript ! generated.test.ts focus=9
!from ./assets/generated.test.ts.txt
```

---

## !!steps

Next we define the `serverUrl`, `apiKey`, and `context` variables. The `serverUrl` points to the API server. We use the `servers` list in the OpenAPI document to determine the server URL.

We also set up the `apiKey` for authentication. In our demo, we use a hardcoded API key, but in a real-world scenario, we'd likely get this after authenticating with the API.

We'll use the `context` object to store values extracted from the response body for use in subsequent steps.

```typescript ! generated.test.ts focus=10:12
!from ./assets/generated.test.ts.txt
```

---

## !!steps

For each step in the workflow, we generate a test case that executes the step and validates the success criteria.

Our first step is to create a new robot design session.

```typescript ! generated.test.ts focus=13
!from ./assets/generated.test.ts.txt
```

---

## !!steps

The HTTP method and path are extracted from the OpenAPI document using the `operationId` from the Arazzo step.

```typescript ! generated.test.ts focus=14:15
!from ./assets/generated.test.ts.txt
```

---

## !!steps

We set up the request headers, including the `x-api-key` header for authentication.

```typescript ! generated.test.ts focus=16:19
!from ./assets/generated.test.ts.txt
```

---

## !!steps

The request body is set up using the `requestBody` object from the Arazzo step.

```typescript ! generated.test.ts focus=20
!from ./assets/generated.test.ts.txt
```

---

## !!steps

We extract the response body as JSON.

```typescript ! generated.test.ts focus=22
!from ./assets/generated.test.ts.txt
```

---

## !!steps

We assert the success criteria for the step.

```typescript ! generated.test.ts focus=23:50
!from ./assets/generated.test.ts.txt
```

---

## !!steps

Finally, we extract the outputs from the step and store them in the `context` object for use in subsequent steps.

```typescript ! generated.test.ts focus=51
!from ./assets/generated.test.ts.txt
```

</ScrollyCoding>

This structure repeats for each step in the workflow, creating a series of test cases that execute the workflow sequentially. The generated tests validate the API's behavior at each step, ensuring that the workflow progresses correctly.

## Future development and improvements

Our generated tests are a good start, but they might not be truly end-to-end if we don't consider the interfaces our users interact with to access the API.

### Testing with SDKs

In our demo, we use the `fetch` API to interact with the Build-a-bot API. While this is a common approach, it's not always the most user-friendly. Developers often prefer SDKs that provide a more idiomatic interface to the API.

To make our tests more end-to-end, we could use the SDK Speakeasy created from the OpenAPI document to interact with the API.

Since the SDK is generated from the OpenAPI document, with names and methods derived from the API's tags and operation IDs, we could use Arazzo to validate the SDK's behavior against the API's capabilities.

For example, we could:

1. Get the `operationId` from the Arazzo step and derive the corresponding SDK method import.
2. Call the SDK method with the required parameters.
3. Validate the response against the success criteria.
4. Extract the outputs from the response and store them in the `context` object.
5. Repeat for each step in the workflow.

This approach would provide a more realistic end-to-end test, validating the SDK's behavior against the API's capabilities.

### Handling authentication

In our demo, we use a hard-coded API key for authentication. In a real-world scenario, we'd likely need to authenticate with the API to get a valid API key.

OpenAPI also supports more advanced authentication schemes like OAuth 2.0, JWT, and API key in headers, query parameters, or cookies. Our test generator should handle these schemes to ensure the tests are realistic and cover all authentication scenarios.

Arazzo can point to the security schemes in the OpenAPI document, allowing us to extract the required authentication parameters and set them up in the test suite.

### Hardening the parsers against vulnerabilities

Our parsers are simple and work well for the demo, but they lack robust error handling and edge case coverage.

For example, JSONPath-plus, the library we use for JSONPath, recently fixed a remote code execution vulnerability. We should ensure our parser is up to date and secure against similar vulnerabilities, or limit the JSONPath features we support to reduce the attack surface.

This applies to parsers in general, and the risk is even higher when parsing user input and generating code from it.

Deno provides some protection by limiting access to the filesystem and network by default, but the nature of API testing means we need to access the network and read files.

## Where to next?

The Arazzo specification, although released as v1.0.0, is in active development. The OpenAPI team is working on a JSON Schema for Arazzo, which will provide a formal definition of the specification's structure and constraints.

We found the specification slightly ambiguous in places, but the team is [active on GitHub](https://github.com/OAI/Arazzo-Specification/issues) and open to feedback and contributions. If you're interested in API testing, Arazzo is a great project to get involved with.

At Speakeasy, we're building tools to make API testing easier and more effective. Our TypeScript, Python, and Go SDK generators can already generate tests from OpenAPI documents, and we're working on integrating Arazzo support. Our CLI can already lint Arazzo documents, and we'll have more to share soon.

We're excited to see how Arazzo evolves and how it can help developers build robust, end-to-end tests for their APIs.


 This is the content for the doc blog/easytemplate-release.mdx 

 ---
title: "EasyTemplate OSS Release: Templating Superpowers for Go"
description: "A templating engine that allows you to use Go's text/template syntax, but with the ability to use JavaScript/Typescript snippets while templating."
keywords: [go, golang, templating, text templating, oss]
image: "/media/easy-template.png"
date: 2023-02-28
authors:
  - name: Tristan Cartledge
  - image_url: "https://uploads-ssl.webflow.com/62ccd7b208cab0723d026273/635ff12733f46637e91ced22_1516859875198.jpg"
tags:
  - Building Speakeasy
featured_image: "/media/easy-template.png"
---

At Speakeasy, we work in a variety of languages, but most of our backend is written in Go, specifically for its no nonsense outlook on code quality and long term maintainability. Without Go's vibrant OSS community, we wouldn't have been able to build the product we have today, which is why we're very excited to have the opportunity to contribute back to the community.

[**Check it out**](https://github.com/speakeasy-api/easytemplate)

## What is EasyTemplate?

[**easytemplate**](https://github.com/speakeasy-api/easytemplate) is Go's [text/template](https://pkg.go.dev/text/template) with super powers. It is a templating engine that allows you to use Go's [text/template](https://pkg.go.dev/text/template) syntax, but with the ability to use JavaScript or Typescript snippets to manipulate data, control templating and run more complex logic while templating.

[**easytemplate**](https://github.com/speakeasy-api/easytemplate) powers Speakeasy's [SDK Generation](/post/client-sdks-as-a-service/) product and is used by thousands of developers to generate SDKs for their APIs.

The module includes a number of features on top of the standard [text/template](https://pkg.go.dev/text/template) package, including:

- [Support for JavaScript snippets in templates](https://github.com/speakeasy-api/easytemplate#using-javascript).
  - ES5 Support provided by [goja](https://github.com/dop251/goja).
  - Built-in support for [underscore.js](http://underscorejs.org/)
  - Import JavaScripts scripts from other files and inline JavaScript snippets
  - Use JavaScript or Typescript
  - Modify the templating context from within JavaScript.
- [Controlling the flow of templating within the engine](https://github.com/speakeasy-api/easytemplate#controlling-the-flow-of-templating).
- [Inject Go functions into the JavaScript context](https://github.com/speakeasy-api/easytemplate#registering-js-functions-from-go), in addition to [Go functions into the templates](https://github.com/speakeasy-api/easytemplate#registering-templating-functions).
- [Inject JS functions into the template context.](https://github.com/speakeasy-api/easytemplate#registering-js-templating-functions)

## Why'd we build it?

Speakeasy needed a way of templating complex hierarchy's of templates that all relied on each other and the content they contained (like for when you generate SDKs from API Specs). By building a templating engine that allows more complex logic to be run at templating time via JS and allowing templates to template other templates, we unlock the ability to tailor templates to our needs based on the target output.

This allows us to decouple templating from our core binary, allowing new templates to be provided at runtime (think plugins) without the core go code/binary needing to know what templates there are, what data they need, enabling the templating to call itself on a dynamic set of files.

We chose JS/TS as the language for the embedded scripting because of its ubiquity, and ease of learning. It also has a thriving ecosystem of data and string manipulation modules which provide additional super powers to your templates.

## Basic Example

`main.go`

```go
package main

import (
    "fmt"
    "log"
    "os"

    "github.com/speakeasy-api/easytemplate"
)

func main() {
    // Create a new easytemplate engine.
    engine := easytemplate.New()

    // Start the engine from a javascript entrypoint.
    err := engine.RunScript("main.js", data)
    if err != nil {
        log.Fatal(err)
    }
}
```

`main.js`

```js
// From our main entrypoint, we can render a template file, the last argument is the data to pass to the template.
templateFile("tmpl.stmpl", "out.txt", { name: "John" });
```

`tmpl.stmpl`

In the below template we are using the `name` variable from the data we passed to the template from main.js.

We then also have an embedded JavaScript block that both renders output (the sjs block is replaced in the final output by any rendered text or just removed if nothing is rendered) and sets up additional data available to the template that it then uses to render another template inline.

```go
Hello {{ .Local.name }}!

```sjs
console.log("Hello from JavaScript!"); // Logs message to stdout useful for debugging.

render("This text is rendered from JavaScript!"); 

context.LocalComputed.SomeComputedText = "This text is computed from JavaScript!";
sjs```

{{ templateString "tmpl2.stmpl" .LocalComputed }}
```

`tmpl2.stmpl`

```go
And then we are showing some computed text from JavaScript:
{{ .SomeComputedText }}
```

The rendered file `out.txt`

```text
Hello John!

This text is rendered from JavaScript!

And then we are showing some computed text from JavaScript:
This text is computed from JavaScript!
```

## How should you use it?

`easytemplate` allows you to control templating directly from scripts or other templates which among other things, allows you to:

- Break templates into smaller, more manageable templates and reuse them, while also including them within one another without the need for your Go code to know about them or control the flow of templating them.
- Provide templates and scripts at runtime allowing pluggable templating for your application.
- Separate your templates and scripts from your Go code, allowing you to easily update them without having to recompile your application and keeping concerns separate.

We can't wait to see what the Go community uses EasyTemplate for!


 This is the content for the doc blog/enforcing-api-consistency/index.mdx 

 ---
title: "Enforcing API consistency"
description: "Learn how to enforce consistency in your APIs across teams and domains."
keywords:
  [
    api,
    api design,
    sdk,
    developer experience,
    devex,
    dx,
    openapi,
    rest,
    rest api,
    restful,
    restful api,
    swagger,
  ]
image: "/media/enforcing-api-consistency.png"
date: 2025-02-08
authors:
  - name: Sagar Batchu
  - image_url: "/media/author-headshots/sagar.jpeg"
tags:
  - API Advice

featured_image: "/media/enforcing-api-consistency.png"
---

import { Callout } from "~/components";

<Callout title="API Design Guide" variant="success">
  <p>If you're looking for a more comprehensive guide to API design, you can read our <a href="/api-design">REST API Design Guide</a>.</p>
</Callout>

API style guides often make developers' work more difficult, which leads to interface drift, which in turn affects real users. This is easy to resolve within a [two-pizza team](https://martinfowler.com/bliki/TwoPizzaTeam.html) using code review, pair programming, and the collective identity that results from time spent in the trenches together. Small teams have enough rapport and opportunities for interaction to resolve API design issues, update their style guides, and reach consensus without much friction.

Sure, it isn't always as rose-colored as that, but compared to reaching consensus *between* teams, it's a walk in the park. Friction between teams becomes a giant burden to organizations that have multiple teams working on a single API, and even more so when teams are working on multiple adjacent APIs.

The common response is to create an "API governance team" or "architecture review board" - a group of senior engineers tasked with maintaining consistency across teams.

It is painful just typing those phrases out. The idea is well-intentioned, but the execution is often disastrous:

* Teams wait weeks for reviews, slowing down development.
* Reviewers become bottlenecks, causing resentment.
* Standards become rigid and divorced from real-world needs.
* Teams find creative ways to bypass the process entirely.

This compounds until there is enough drift that consistency becomes an unattainable dream.

What's needed instead is a way to enforce consistency that works *with* teams rather than against them. This means moving from manual processes to automated checks; from subjective reviews to objective criteria. It means building tools that help developers stay consistent, and providing a clear path to resolution when they don't.

## What do we mean by consistency?

At its core, consistency means following the [principle of least astonishment](https://en.wikipedia.org/wiki/Principle_of_least_astonishment): APIs should behave in ways that minimize surprises for everyone who interacts with them.

Here's what this looks like in practice:

### Within your interfaces

The most fundamental form of consistency is within individual APIs. When developers interact with different parts of a single API, they should be able to apply what they've learned from one endpoint to other endpoints.

Here are some examples of internal consistency:

1. **Use the same naming patterns across all endpoints:** For example, if you use `snake_case` for field names in one place, you shouldn't switch to `camelCase` in another.
2. **Ensure request and response objects are uniform:** A reasonable assumption is that if an e-commerce API has a `city` field in the `orders` endpoint, it should have the same field in the `returns` endpoint. Replacing `city` with `town` in the `returns` endpoint would be inconsistent and confusing.
3. **Follow the same error-handling patterns throughout:** All endpoints should return errors in a consistent format, with appropriate status codes and messages. If a `GET` request to a resource that doesn't exist returns a `404 Not Found` status code, a `POST` request to the same resource should return the same status code.
4. **Keep authentication flows predictable:** If a user needs to provide a token in the `Authorization` header for one endpoint, they should reasonably expect to use the same header for all other endpoints that require authentication, rather than a query parameter or a cookie.

This internal consistency allows developers to build accurate mental models of how your API works.

### Across your organization

The next level of consistency extends across your organization. This means that every team building APIs should follow the same conventions. This includes:

1. **Shared authentication mechanisms across services:** If one team uses OAuth2 for authentication, all teams should use OAuth2. This ensures that developers don't need to learn new authentication mechanisms when switching between services.
2. **Common error handling across services:** When a service is down, every API should return a `503` status code with the same error structure, not a mix of different formats and codes for different services.
3. **Unified naming conventions:** If your user service uses `/v1/users/{id}` as a pattern, your order service shouldn't use `/api/2.0/orders/{orderId}`. This kind of inconsistency means developers have to remember different patterns for different services.
4. **Standard versioning approaches:** Allowing some teams to use URL versioning (`/v1/resource`) while others use accept headers (`Accept: application/vnd.company.resource.v1+json`) creates unnecessary complexity.
5. **Consistent rate-limiting implementations:** Rate limits should use the same headers and behavior across services. If one service uses `X-RateLimit-Remaining` while another uses `RateLimit-Remaining`, developers need to handle both cases.

This is where the most friction occurs. Teams have different priorities, different constraints, and different preferences. It's easy for standards to drift when there's no shared understanding of why they exist. We'll explore how to address this in more detail later.

### With your domain

Your API should make sense to developers who work in your industry:

1. **Use familiar field names:** A payment API using `amount` and `currency` will feel more natural than `monetary_value` and `money_type`.
2. **Follow standard workflows:** An e-commerce API should follow common patterns for checkout flows that developers will recognize from other platforms.
3. **Support expected features:** If every other API in your space supports bulk operations, your API probably should too.

This requires in-depth domain knowledge and an understanding of what developers expect from APIs in your industry. It's the hardest form of consistency to enforce, but it's also one of the most valuable.

### With HTTP standards

Most developers have expectations about how HTTP works. For example:

1. **GET requests should be safe and idempotent:** They shouldn't change data. A `GET` request to `/users/123` should never delete the user or have any other side effects.
2. **POST is for creation:** Only `POST` should be used to create new resources, not `PUT` or `GET`.
3. **Status codes should follow conventions:** Use `201` for successful creation, not `200` with a `"created"` string in the body.
4. **Cache headers should work:** If you say something can be cached for an hour, it should be safe to cache for an hour.

The goal isn't to perfect adherence to HTTP specifications but to meet developers' reasonable expectations about how HTTP works. We discuss this balance in more detail in our article, [Designing your API: Find the RESTful sweet spot](https://www.speakeasy.com/post/api-design).

## Focusing on what matters most

It is easy to get stuck in a tar pit while trying to deliberate and enforce every possible form of consistency. Bikeshedding and navel-gazing over insignificant details can lead to a loss of focus on what really matters. Here's how to prioritize:

### Non-negotiables

Some forms of consistency are so important that they should be enforced in all but the most exceptional cases. These are the things that will cause the most confusion and frustration if they're inconsistent:

1. **Authentication:** Security patterns need to be predictable and well-understood. Never roll your own authentication scheme, and always use the same mechanism across services.
2. **Error handling:** Consistent error responses are useful for developers to understand what went wrong. If every service returns a different error format, developers will waste time debugging.
3. **HTTP methods:** Stick to the standard HTTP methods and their meanings. This is one of the most fundamental forms of consistency in REST APIs and has been well-established for decades.
4. **HTTP status codes:** Status codes have well-defined meanings. If a resource isn't found, return a `404`. If a user is unauthorized, return a `401`. Don't reinvent the wheel here, and never return a `200` status code for an error.
5. **URL structure:** Predictable URLs make it easier for developers to navigate your API and discover endpoints.

### When to be flexible

Apart from these non-negotiables, most other forms of consistency can be more flexible for the right reasons. Here are some examples:

1. **Performance:** Bulk operations may return stripped-down resources to improve performance, while individual operations return full resources. This is a reasonable trade-off that can be explained in your documentation.
2. **Naming conventions:** If a team has a good reason for using a different naming convention, it's not worth enforcing consistency for its own sake. The goal is to make your API easier to use, not to make it uniform at all costs. For example, if the `users` resource is called a `debtor` in a financial API, that's fine as long as it's well-documented.
3. **Rate limiting:** Different services may have different rate limits based on their usage patterns. It's okay for these to vary as long as they're documented clearly.

In all three examples, documentation saves the day. If developers understand *why* things are inconsistent, they can work around it. If they don't understand your reasons, they may lose confidence in your API, or worse, think they made a mistake elsewhere and go bug-hunting. Explaining the reasons behind inconsistencies is often more important than enforcing consistency for its own sake.

## Consistency isn't the same for everyone

Our definition of consistency is based on the principle of least astonishment, but what's surprising in one context may be expected in another. Start by understanding your developers' expectations and work from there.

Different groups of developers bring different expectations. For example, developers in the financial industry may expect idempotency keys on all write operations, while developers in the gaming industry may not.

This is a balancing act. Some industries have become accustomed to certain patterns that may not be best practice. For example, the financial industry's reliance on SOAP APIs with complex XML payloads is a well-established pattern, but it's not the most developer-friendly approach. In this case, consistency with the industry may not be the best choice. This may be one of the reasons for Stripe's success - they take a developer-first approach to payments, rather than following the industry standard.

Once you understand the expectations of your developers, you can start prioritizing consistency based on what really matters in your context.

## How to enforce consistency

With a clear understanding of what consistency means for your API, you can start enforcing it.

### Use OpenAPI

An OpenAPI document should be the source of truth for your API. If your API framework doesn't generate OpenAPI documents, consider switching to one that does or adding a tool to generate them. Ideally, your OpenAPI document should either be generated automatically from your codebase or act as a contract that your codebase adheres to.

Specifying your API in OpenAPI allows your teams to discuss and agree on standards without implementing them. It also allows you to generate documentation, client libraries, and server stubs automatically.

In the context of consistency, OpenAPI enables you to automate checks for internal consistency.

### Automated enforcement

Start by automating everything that can be objectively verified:

#### Automate OpenAPI validation

Your API definitions should be valid according to the OpenAPI Specification. This is table stakes and should be enforced through CI/CD pipelines.

#### Automate linting

Use tools like [Spectral](https://github.com/stoplightio/spectral) to enforce style conventions. Create a ruleset that codifies your organization's standards. This can include naming conventions, error-handling patterns, and more.

Spectral has built-in rules for common patterns, but you can also write custom rules to enforce your organization's specific standards. For example, you could enforce `kebab-case` for all paths:

```yaml
rules:
  paths-kebab-case:
    description: Paths should be kebab-case.
    message: "{{property}} should be kebab-case (lower-case and separated with hyphens)"
    severity: warn
    given: $.paths[*]~
    then:
      function: pattern
      functionOptions:
        match: "^(\/|[a-z0-9-.]+|{[a-zA-Z0-9_]+})+$"
```

The [Speakeasy CLI](https://www.speakeasy.com/docs/speakeasy-reference/cli/getting-started) tool also provides [linting capabilities](https://www.speakeasy.com/docs/prep-openapi/linting). With the Speakeasy CLI installed, run the following command to lint your OpenAPI document:

```bash
speakeasy lint openapi -s openapi.yaml
```

This will output any issues found in your OpenAPI document:

![Screenshot of a terminal showing output from the Speakeasy CLI lint command](./assets/speakeasy-lint.png)

If you're using Speakeasy to generate SDKs, you can configure it to lint your OpenAPI document as part of the generation process. This ensures that your OpenAPI document is always up-to-date and consistent with your generated code.

Speakeasy supports custom rules in the Spectral format, so you can enforce your organization's standards in the same way as with Spectral.

Individual team members can run these checks locally, before pushing their changes. This reduces the burden on reviewers and ensures that issues are caught early, when they're easiest to fix. In fact, [Spectral](https://marketplace.visualstudio.com/items?itemName=stoplight.spectral) and [Speakeasy](https://marketplace.visualstudio.com/items?itemName=Speakeasy.speakeasy-vscode-extension) both provide VS Code extensions with linting features, so you can stay consistent without leaving your IDE. Shift left!

Linters can also be run as part of your CI/CD pipeline so that no changes are merged without passing these checks and inconsistencies are caught before they reach staging or production.

#### Contract testing

Verify that your API implementations match their specifications. Tools like [Pact](/post/pact-vs-openapi) can help you write tests that verify that your API behaves as expected. OpenAPI itself is not a contract testing tool in itself, but it can be used as a source of truth for contract tests.

Speakeasy supports [contract testing](https://www.speakeasy.com/docs/testing) for OpenAPI documents. You can generate contract tests from your OpenAPI document and run them as part of your CI/CD pipeline.

Speakeasy generates test workflows using [Arazzo](https://www.speakeasy.com/openapi/arazzo) (formerly known as OpenAPI Workflows), a simple, human-readable specification for API workflows. This allows you to extend the generated tests with custom logic, making it easy to test complex workflows across multiple services.

Automated contract tests ensure that your API implementations match their specifications, reducing the risk of inconsistencies.

#### Code generation

Generate server stubs and SDKs from your OpenAPI definitions. This ensures that your implementation matches your specification and provides consistent interfaces across languages.

[Speakeasy generates SDKs](https://www.speakeasy.com/docs/create-client-sdks) in multiple languages from your OpenAPI document.

#### Integration tests

Write automated tests that verify cross-service behavior, especially around authentication, error handling, and common workflows. Better yet, [generate these tests](https://www.speakeasy.com/docs/customize-testing/automated-test-generation) from your OpenAPI definitions.

### Human review where it matters

Some aspects of API design can't be automated and need human judgment:

1. **Domain alignment:** Are your API abstractions aligned with your business domain? This requires deep understanding of both your technical architecture and business context.
2. **Developer experience:** Is your API intuitive and easy to use? This often requires user research and feedback from actual developers.
3. **Breaking changes:** Will a proposed change break existing clients? Humans need to evaluate the impact of each proposed change and plan appropriate migration paths.
4. **Cross-team impacts:** How will changes affect other teams and services? This requires a thorough understanding of system dependencies and team dynamics.

### Establish clear processes

Create lightweight processes that combine automation with human judgment:

1. **API design reviews:** Start with automated checks, then focus human review on what matters. Run automated linting and validation first, then:
    - If the checks pass, reviewers focus on domain alignment and developer experience.
    - If the checks fail, fix the basic issues before involving more people.

2. **Regular API audits:** Periodically review your APIs as a whole:
   - Run consistency reports across all services.
   - Identify patterns of drift.
   - Update standards based on what's working.
   - Deprecate patterns that cause problems.

3. **Documentation and training:** Help teams understand and apply standards:
   - Maintain living documentation of your standards.
   - Provide clear examples of good and bad patterns.
   - Run workshops on API design.
   - Share case studies of successful and problematic APIs.

### When standards need to change

Standards shouldn't be static. As your organization grows and your APIs evolve, your standards will need to change too.

When updating standards:

1. **Start small:** Test changes with one team before rolling out widely.
2. **Provide migration paths:** Don't force immediate updates to existing APIs.
3. **Document clearly:** Explain what changed and why.
4. **Update tooling:** Ensure your automated checks align with new standards.

Tests that consistently fail should be updated as soon as possible. If a test is failing because it's outdated, it's not serving its purpose, and will degrade trust in your automated checks over time.

### Document the why

At Speakeasy, we're big fans of *starting with the why*. In internal discussions and pull requests, we often ask what problem we're trying to solve before presenting solutions. This helps us understand the context, make better decisions, and provide better feedback.

When documenting standards, it's important to explain why they exist. This helps developers understand the reasoning behind the rules and makes it easier to follow them. It also makes it easier to update standards when they're no longer relevant.

One way of keeping tabs on temporary inconsistencies is to document them as exceptions, each with a reference number to a ticket or a discussion. This way, you can track them and decide whether they should be resolved or documented as permanent exceptions.

### Reaching consensus across teams

When teams disagree on standards, try to understand the degree to which the inconsistency matters. If it's a non-negotiable, like authentication or error handling, it's worth spending the time required to reach consensus. If it's a naming convention or a performance optimization, it may not be worth the effort.

Use lightweight signals (like the [Internet Engineering Task Force (IETF) humming](https://en.wikipedia.org/wiki/Consensus_decision-making#IETF_rough_consensus_model)) to gauge general direction while concentrating on resolving voiced concerns.

Rough consensus is often enough to move forward. If a team has a strong reason for doing something differently, it's worth considering whether the standard should be updated.

Consensus is easier to reach if everyone understands the problem clearly. Once again, using a design-first approach with OpenAPI can help rule out any misunderstandings. If everyone is working from the same source of truth, it's easier to understand and compare one another's perspectives.

### Making it sustainable

Perfect consistency isn't the goal. The goal is making your APIs predictable and easy to use, while allowing for necessary variation. Focus on the patterns that matter most to your developers and be pragmatic about enforcing them.

## Building a culture of consistency

When done well, consistency reduces developers' cognitive load, speeds up integration, and makes your APIs more maintainable. When done poorly, it becomes a bureaucratic burden that slows teams down and encourages workarounds.

Before reaching for the "API governance team" hammer, consider the following:

1. Automate everything that can be automated, but don't try to automate judgment calls.
2. Focus human review on what matters most: domain alignment, developer experience, and cross-team impacts.
3. Keep processes lightweight and focused on enabling teams rather than controlling them.
4. Allow standards to evolve based on real-world feedback and changing needs.
5. If you need to be flexible, document why.

The goal is to create a culture where consistency is valued and maintained by everyone, rather than enforced by a select few, or worse, ignored by all.

This article is part of our series on [API design](/post/api-design), where we get technical about building APIs that developers love. If you're interested in learning more about API design, check out our other articles in the series.


 This is the content for the doc blog/fundraising-series-a/index.mdx 

 ---
title: "Speakeasy's $15M Series A"
description: "Speakeasy is today announcing that it has raised $15M in Series A funding from backers including Wesley Chan at FPV Ventures, GV and Quiet Capital."
image: "/media/announcement-series-a.png"
date: 2024-10-30
authors:
  - name: Sagar Batchu
  - image_url: '/media/author-headshots/sagar.jpeg'
tags:
  - Building Speakeasy
featured_image: "/media/announcement-series-a.png"
is_featured: true
---

import { Callout } from '~/components';

<Callout title="TL;DR" variant="success">
We've raised $15M to revolutionize REST API development. With this latest round of investment, we're expanding our product offerings, accelerating our roadmap, and growing our exceptional team 🚀
</Callout>

If software is eating the world, APIs are the knives and forks. They're not just connecting systems: they're fundamentally reshaping how we build, deploy, and scale software.

Slack aside, service-based architectures are how engineering teams are communicating with one another internally. Meanwhile, every B2B SaaS is working to transform into an API-based company and offer programmatic access to their products.

These trends have made APIs the #1 source of web traffic and they’re growing faster than any other type. With the rise of AI, we're on the cusp of an even more dramatic surge in traffic as machine-to-machine communication explodes.

But against this backdrop of rapid API growth, the tools and practices for building quality, reliable APIs haven't kept pace. This growing gap is creating a bottleneck that could choke the next wave of software innovation. Unless we invest in better API development solutions, we risk stifling the very progress that APIs have enabled.

## No more API embarrassment

In our conversations with countless engineering teams, we've discovered a common but rarely discussed emotion surrounding their APIs: embarrassment. It's consistent across companies of all sizes and industries.

Teams composed of brilliant engineers find themselves disappointed that their company's APIs don't represent the best of their team’s abilities. They’re embarrassed by:

- Documentation that's perpetually out of date
- Inadvertent breaking changes that slip into production
- Inconsistencies in naming conventions and functionality
- SDKs that lag behind API updates, if they exist at all
  
There’s a disconnect between the quality these teams aspire to and the reality of their APIs.

Why? Are developers inherently bad at designing and building APIs?

We don’t think so.

The root of the problem lies with the tools available. Even the most gifted craftsman needs the appropriate tools to build something they’re proud of. And unfortunately the API tooling ecosystem is stuck in 2005.

## Why we’re building Speakeasy

We want to make it trivially easy for every developer to build great APIs. Said another way, no more API embarrassment. To make that dream a reality, we’re building the API tools we’ve always wanted: a platform to handle the heavy lifting of API development to unburden developers to focus on refining the business logic.

Here’s the future we want to create:

1. Build: You use your favorite API framework to build your API. Speakeasy helps you make sure that your API matches industry & internal best practices.
2. Test: You develop new API features. Speakeasy automates API testing to make sure no unintentional breaking changes get shipped.
3. Distribute: You release your API. Speakeasy automatically generates the SDKs that make your API a joy to integrate.

import video_url from "./assets/customer_quotes_landscape.mp4";

<div align="center" className="mt-10" >
  <video controls={false} loop={true} autoPlay={true} width="70%">
    <source src={video_url} type="video/mp4" />
  </video>
</div>

## Why we raised money

We partnered with FPV Ventures to lead our $15M Series A funding round, with continued support from GV (formerly Google Ventures) and Quiet Capital. Our investors, alongside angels like Søren Bramer Schmidt (CEO at Prisma), Clint Sharp (Co-founder at Cribl), and Arpit Patel (CCO at Traceable), have provided us with the fuel we need to revolutionize API development for engineers everywhere.

We asked Wesley Chan, Managing Partner at FPV Ventures, why he invested:

> "The Speakeasy team’s past experience building enterprise APIs has given them profound insight into, and empathy for, the struggles engineering teams are facing. They are building a platform that will not only address existing inefficiencies in API development but anticipates future challenges in the ecosystem. But what ultimately convinced us to lead their round was the overwhelming feedback from their user base. Teams aren't just using the platform; they're enthusiastically championing it, which speaks volumes about Speakeasy's ability to deliver real value and an exceptional experience."
>

Of course, what ultimately matters isn’t what investors think, it’s what developers choose. This year, we've seen nearly 3,000 users generate 7,250 SDKs. That’s a 575% increase in companies investing in their API’s tooling. From fast-growing innovators like Vercel and Mistral AI to established giants like Verizon, to hobby projects by solo devs, engineers are using Speakeasy to accelerate their API development and adoption.

import Image from 'next/image'
import teamImage from './assets/speakeasy-team.png'

<div className="mt-10 flex justify-center">
  <Image 
    src={teamImage} 
    alt="Speakeasy Team" 
    width={400}  
    height={300} 
    style={{ width: '70%', height: 'auto', align: 'center' }}
  />
</div>

We’re proud of the progress we’ve made so far, but we can also say with certainty that we are  only getting started. With this new funding, we're expanding our product offerings, accelerating our roadmap, and growing our exceptional team across San Francisco and London. We have ambitious plans to revolutionize contract testing, API creation, and webhook management.

Ready to supercharge your API lifecycle? Let's talk.

**Sagar & Simon, Co-founders, Speakeasy**


 This is the content for the doc blog/hathora-gaming-devex/index.mdx 

 ---
title: "Game Dev & The Rise of Developer Experience"
description: "A look at Speakeasy customer, Hathora, and why DevEx is picking up steam in the gaming industry."
image: "/media/hathora-gaming-devex.png"
date: 2024-03-07
authors:
  - name: Tristan Cartledge
  - image_url: "/media/author-headshots/tristan.jpeg"
tags:
  - API Advice
featured_image: "/media/hathora-gaming-devex.png"
---

If you’re wondering why on earth Speakeasy has Unity plugins as a generation target, you can thank me and one of our early customers, [Hathora](http://hathora.dev). Before joining Speakeasy, I had a long career in the games industry, working on backends for multiplayer games.

One of our goals at Speakeasy is to make a great developer experience possible, no matter what vertical a developer works in. I’ve pushed hard for Gaming to be one of the verticals we focus on because of the industry’s proud history of innovation in the dev tooling space and because we’re in a period of profound change within gaming. The development of tools like Hathora and Speakeasy is helping to establish a higher benchmark for developer experience and democratizing access to tooling that makes it possible.

In this post, I will walk through some of my war stories, look at how the industry has changed over the last 15 years, and how tools like Hathora and Speakeasy catalyze another wave of change.

## Building Gaming Infrastructure the Old Way

In the 2000s, connecting millions of gamers across the globe was a monumental engineering undertaking reserved for only the most successful studios with the biggest budgets. Behind every multiplayer game was an army of gaming infrastructure professionals wielding massive budgets to build a platform capable of supporting their players all across the globe.

I was one such engineer working on projects as varied as the wave of multiplayer mobile games, MMORPGs, and AAA games like Halo and Gears of War. My teams were generally tasked with the creation of all the core components of the multiplayer platform:

1. Account Management - Creation and synchronization of accounts across all platforms and devices.  
2. Game Synchronization - Netcode to ensure that all players would see the same game state at the same time, which meant managing differences in individual network speeds and latencies.
3. Matchmaking - Creating a system that matched players together based on variables such as skill level, geographical location, and latency.
4. Games Server Orchestration - The biggest piece of the puzzle, managing the servers that hosted the games themselves. For mass multiplayer games this included elements such as:
   - Load balancing - Distributing player traffic across multiple servers to ensure that no single server becomes overloaded, accounting for regional latency.
   - Game lifecycle management - Ensuring that games were started and stopped as needed, and that players were matched to the right game.
   - Fleet management - Ensuring that there were enough servers to handle the load of players. Scaling up and down as needed.
  
Here's a simplified diagram of the multiplayer infrastructure we would've been building in the 2000s that would have been typical for a game like Halo or Gears of War:

![Image of Multiplayer Infratructure](./assets/hathora-infra-1.png)

At every studio, resources were sunk into building similar systems and trying to figure out cost-effective hosting options. Cloud technology was just entering the picture, so for a lot of games, servers were tucked away in the back corner of the studio office until you could find dedicated locations for them. Some studios could afford hosting partners to cover the US and Europe. But that still meant players from other continents were out of luck (growing up in Cairns, Australia, my >200ms latency was painful).

Needless to say, but building this infrastructure was a huge drain on resources and time that could have been spent on the actual game.

## The Standard Game Dev Technology Stack

Fortunately, in the last ten years, things have started to change: account management, cloud saving, cross-region networking are all now available as services you can buy off the shelf. The catalyst has been the consolidation around a common technology stack for games:

- Cloud Compute: The rise of the cloud was certainly a significant boost for developers and gamers - ping times dropped, and studios could better manage server costs as games rose and faded in popularity. You still needed to rebuild the core components of the multiplayer platform for each game, but removing the burden of server management was a huge win.

- Gaming Engines: Even more important than the cloud has been the emergence of gaming engines as platforms to build on, Unity for mobile games & Unreal for PC/consoles. This consolidation has made the whole industry more efficient. Instead of reinventing the wheel, studios can focus on differentiating their gameplay experience.

But even more exciting than the productivity boost realized by these developments is what it sets the table for… An explosion in tooling for game developers that is about to reshape the industry.

## The New Age of Building Multiplayer Games

With consolidation around common primitives, it’s now more feasible to build game development platforms (server hosting, matchmaking, live ops) that are instantly usable by the industry as a whole. This previously wasn’t realistic because every studio’s environment was so unique and filled with custom code that integration was impossible.

Hathora, one of Speakeasy’s earliest customers, is one such platform. They offer an API that makes deploying and scaling multiplayer servers worldwide a realistic weekend project. Reading through their site was equal parts exciting and frustrating. If Hathora had been an option when I was in gaming, they could have replaced entire pieces of infrastructure that were being maintained by my team. Those efforts could have instead been reinvested into the actual gameplay. Having a service provider completely changes the cost calculation of building a multiplayer game.

The same goes for the other pieces of the multiplayer stack:

| Feature Category              |        Description                    | Platforms                          |
|-------------------------------|---------------------------------------|------------------------------------|
| Account Management            | Creation and synchronization of accounts across all platforms and devices                         | [LootLocker](https://lootlocker.com/), [Pragma](https://pragma.gg/), [Beamable](https://beamable.com/), [PlayFab](https://playfab.com/)    |
| Game Synchronization          | Ensure that all players would see the same game state at the same time, managing network speeds and latencies | [Photon](https://doc.photonengine.com/pun/current/gameplay/synchronization-and-state#), [Heroic Labs](https://heroiclabs.com/), [Mirror](https://mirror-networking.com/)          |
| Matchmaking                   | Creating a system that matched players based on skill level, geographical location, and latency  | [Beamable](https://beamable.com/), [Pragma](https://pragma.gg/), [Playfab](https://playfab.com/), [IDEM](https://www.idem.gg/), [Heroic Labs](https://heroiclabs.com/)                   |
| Games Server Orchestration    | Load balancing, game lifecycle management, and fleet management                                   | [Hathora](https://hathora.dev/), [Multiplay](https://unity.com/products/game-server-hosting)               |

Here’s what my multiplayer architecture would look like in 2024. Much simpler:

![Image of Multiplayer Infratructure with Hathora](./assets/hathora-infra-2.png)

The availability of off-the-shelf services is going to trigger an explosion in creativity as smaller and smaller studios can execute increasingly grand visions. However, there’s still work to be done to make platforms like Hathora as impactful as possible. That’s where my work at Speakeasy comes in.

## The Role of API Integration Experience in Game Dev

You can build the most incredible tool in the world, but if it’s not easy to integrate with, it’s not useful. And that’s what Speakeasy is working to solve. We want it to be trivially easy to integrate with every game development platform's API. To make that happen, we're building our code gen platform to support library creation for every popular language in the game development space. We've started with C# & Unity and are planning support for Unreal and C++.

We make library creation easy by using an OpenAPI spec as the only required input. Maintain a spec, and you'll get a published library ready to put in the hands of your users without additional work. Providing libraries will remove the need for your users to write the tedious boilerplate code required to connect with your API platform: auth, retries, pagination, type checking, everything is taken care of by the library. API integrations that use a library are on average 60% faster and require less maintenance over time.

That allows the gaming platforms to stay focused on developing their core functionality without having to worry about the last mile of integration into their user’s code base.

Here's what integration with Hathora looks like with Speakeasy in the mix. The amount of code required to complete the integration is dramatically reduced:

![Image of Multiplayer Infratructure with Speakeasy](./assets/hathora-infra-3.png)

## The Future of Gaming APIs

We’re really excited to be doing our part to help the growth of APIs in gaming development.  And gaming platforms are just the start. Increasingly, Public APIs are an important part of the games themselves. An API platform enables communities to expand and build upon their favorite games. Community building opens up a new world of viral opportunities: social interactions, continuous updates, and customized experiences. This will only help increase engagement and attract more players. The future for APIs in gaming is full of possibilities!


 This is the content for the doc blog/hiring-a-founding-team.mdx 

 ---
title: "A New Approach to Hiring A Founding Team"
description: "Hire founding engineers goes beyond technical skills. Learn what are the vital traits required for founding engineers. Learn more with our guide."
image: "/media/hiring-a-founding-team.png"
date: 2022-08-18
authors:
  - name: Anuraag Nalluri
  - image_url: 'https://uploads-ssl.webflow.com/62ccd7b208cab0723d026273/62cdfd40eb73d17e05b712ca_3-anuraag_headshot-p-500.jpeg'
tags:
  - Building Speakeasy
featured_image: "/media/hiring-a-founding-team.png"
---

One of the most crucial yet challenging activities for an early software startup is hiring the founding engineering team. If you follow the standard hiring process for engineers, you’ll gauge technical competency but [fail to assess the vital attributes of a founding engineer:](https://blog.southparkcommons.com/startup-engineering-hiring-anti-patterns/) comfort with ambiguity, strong product instincts, and a sense of ownership/agency. After some early struggles with building the Speakeasy team, we stumbled onto a solution that had been hidden in plain sight. It was the process by which I myself had come to join Speakeasy as the first engineer – **a week-long trial period as a full member of the team.**

## The Need For a New Method

Initially, it was easy to default to our collective experience of being on both sides of the interview process at larger engineering organizations. This resulted in assessing devs for “competency” by sampling their abilities through coding/system design exercises. The problem we identified with this approach was that it often failed to produce strong signals. Surprisingly, this was true in many instances _regardless_ of interview performance.

As an early company, the whole team would have a round table discussion for each applicant we interviewed. But even upon the debrief of a compelling candidate who had performed well on our assessments, we were often left with the feeling of, “now what?” Even if we felt certain in the candidate’s technical ability, we lacked the comprehensive signal required to determine whether or not the candidate was someone who would meaningfully move the company forward. The questions we asked were too focused on what people “can do” and relegated us to assessing “how” they did it. What we needed to know was what they “will do” as an integral part of our team. Each founding engineer uniquely shapes the product and has an outsized impact on the success of the company, but we weren’t able to glean that from our interviews.

After reflecting on how strongly we’d felt about one another when I’d joined the company, we realized it was on us to create a similar environment for the candidates that better allowed them to showcase their strengths and make a more informed opinion about what it would be like to work with us. In turn, we would be able to develop conviction, champion candidates, and cultivate a more purposeful culture around hiring.

## My Journey to Speakeasy

When I first met Sagar and Simon, I was [exploring EdTech entrepreneurship as a South Park Commons member](https://www.southparkcommons.com/community).  During my exploration, I came across a classic research paper in education by Benjamin Bloom – [The 2 Sigma Problem](https://web.mit.edu/5.95/www/readings/bloom-two-sigma.pdf). Bloom found that the efficacy of 1:1 tutoring is remarkable. The _average_ tutored student performed above 98% of the students (2 standard deviations) in a control class of 30 students and 1 teacher. There’s no shortage of takeaways that can be drawn from this study, but I took this as evidence for the power of focused attention in driving exceptional outcomes and the impact of [doing things that don’t scale](http://paulgraham.com/ds.html) wherever possible.

I decided to apply this learning to my personal career journey. The standard engineering job search typically involves lining up interviews with as many companies as possible and using competing offers as leverage to settle on the best outcome. I figured I’d be better served focusing on a single prospect at a time, diving into the subject area, and getting a more dynamic signal about the team. I wanted to build conviction deliberately. When I connected with Sagar (Speakeasy CEO), I found someone with the same philosophy; we agreed to spend a week closely collaborating together before any longer-term decisions were made.  
  
Over the span of a week, I was involved in design sessions, user discovery calls, and even interviews with other candidates. I was given an unfiltered view of the product direction with full access to all existing Notion docs, code, and proposed GTM planning. Equipped with this knowledge, I was encouraged to define and drive my own project that would be useful to the company. I came to understand the founders as not only congenial people who were easy to share a meal with, but insightful pragmatists who led with a sense of focus and approachability. I was able to identify where I could immediately contribute and where there existed proximal zones of development for my own growth. My understanding of what working at Speakeasy entailed was two standard deviations above what it typically had been prior to making previous career decisions. And I was paid for all of it.

## How it Worked in Practice

We were initially unsure whether it was realistic to ask candidates to do trial periods with us, but we found them to be very open to the process. When we explained why we thought it was important, let them know we would compensate them for their time, and committed to accommodating their normal work schedules, people were eager to give working with us a shot.

During their trial periods, candidates operate as a full member of the team. They are given a real project to work on, welcome to join all standups and design sessions, and are given full access to our team documents. This gives candidates the same opportunity I had to explore and build conviction in Speakeasy’s mission and plan of execution.  

So far we’ve extended this process to every full time dev on the team and the results have been nothing short of stellar. The developers we’ve been fortunate to hire have used their collaboration periods to demonstrate ownership, thoughtfulness about the user experience, and a sincerity that is present in the quality of their work. By the time they officially joined, they had already become part of the team and made meaningful contributions.

We’ve also observed the positive impact on team culture the collaboration period has brought. While there’s value in a company having a unifying culture, people are diverse in their strengths and we believe this should be leveraged. With trial periods, we ended up taking responsibility for cultivating fit, rather than seeking it as a natural occurrence gleaned in the cumulative 4 hrs of a typical interview process.

## Thoughts on Scaling

The conclusion of Bloom’s “2 Sigma Problem” isn’t that everyone should be tutored 1:1 (that’s ideal, but totally unrealistic), rather it is an invitation to explore how we can “find methods of group instruction as effective as one-to-one tutoring”.  In the same vein, we know it’s not realistic to offer an extended ‘trial period’ to every compelling candidate indefinitely. There will soon come a point where we need to graduate from this process, extract the core values, and develop new processes that embody these values as the company scales.

It’s something we’re already thinking about. We believe the trial period incorporates a few values that have served us well such as radical transparency and openness. We’re in the process of formally defining these values, so we can continue to be intentional in our hiring process and build a strong foundation as a team.

In “The 2 Sigma Problem” there is another experiment where students within an _entire class_ performed a standard deviation better than others. The result came from shifting the responsibility to the educator to employ more tailored instructional and feedback-driven strategies. For Speakeasy, this means not throwing a bog-standard ‘Cracking the Coding Interview’ question at an applicant and calling it a day. Even at scale, we’ll always have a responsibility to engage with each candidate in a way that puts them at the center of the process. In an industry where many developers feel like proficiency with a leetcode question bank is often the be-all and end-all to employability, we’re committed to being thoughtful about the overall candidate experience and giving them the opportunity to make genuine contributions during the hiring process.

Whether this involves dynamically responding to a developer’s skills as we add more structure to our process or using OSS work for collaboration that can also help build up their portfolio, we’re excited to continue making the experience a positive one for all who are involved.


 This is the content for the doc blog/how-to-build-sdks/index.mdx 

 ---
title: "How to Build SDKs for Your API: Handwritten, OpenAPI Generator, or Speakeasy?"
description: "Compare three ways to build robust SDKs and solve the challenges of developer experience, maintenance, and scaling API integrations."
image: "/media/how-to-build-sdks.png"
date: 2025-02-10
authors:
  - name: Emre Tezisci
  - image_url: "/media/author-headshots/emre.jpeg"
tags:
  - API Advice
featured_image: "/media/how-to-build-sdks.png"
---
import { Callout } from "~/components";

## Why SDKs Matter for Developer Adoption

An SDK can be a game-changer for accelerating developer adoption and streamlining integration. Without one, developers are left to decipher API documentation that might lack essential information or be disorganized, and then build each API call by hand. This means handling everything from authentication and request construction to response parsing, error handling, retries, pagination, and beyond—a process that significantly complicates and delays integration.

In contrast, a well-designed SDK lets developers get started in minutes by importing a single library. Features like in-IDE auto-completion and type safety prevent integration bugs before they happen. Advanced tasks like rate limiting or pagination become seamless. The result is a smooth, even delightful developer experience that fosters trust in your API.

Established API-first companies—Stripe, Plaid, Twilio—prove the point. Their client SDKs provide an A+ developer experience, helping them dominate in their respective markets.

## Developer Experience Without vs. With an SDK

The value of an SDK becomes crystal clear when you compare the integration process with and without one. Let's contrast the developer experience:

```typescript Manual API Integration
// Without SDK - Complex manual implementation
async function getUser(userId: string): Promise<User> {
    try {
        const response = await fetch(
            `https://api.example.com/v1/users/${userId}`,
            {
                headers: {
                    'Authorization': `Bearer ${apiKey}`,
                    'Content-Type': 'application/json'
                }
            }
        );

        if (!response.ok) {
            if (response.status === 429) {
                // Implement rate limiting logic
                await sleep(calculateBackoff(response.headers));
                return getUser(userId);
            }
            throw new Error(`API error: ${response.status}`);
        }

        const data = await response.json();
        // Manual type validation
        if (!isValidUser(data)) { // Check for required fields, data types, etc.
            throw new Error('Invalid user data received');
        }
        return data;
    } catch (error) {
        // Complex error handling
        if (shouldRetry(error)) { // e.g., check for network errors
            await delay(calculateBackoff()); // Exponential backoff strategy
            return getUser(userId);
        }
        throw error;
    }
}

// Implementing pagination
async function listUsers(): Promise<User[]> {
    const allUsers = [];
    let page = 1;

    while (true) {
        const response = await fetch(
            `https://api.example.com/v1/users?page=${page}`,
            { headers: { Authorization: `Bearer ${apiKey}` } }
        );

        const data = await response.json();
        allUsers.push(...data.users);

        if (!data.hasNextPage) break;
        page++;
    }

    return allUsers;
}
```

With a well-designed SDK, however, developers can get started in minutes by simply importing the library:

```typescript SDK Integration
// With SDK - Clean, type-safe interface
const client = new APIClient({
    apiKey: process.env.API_KEY
});

// Simple request with built-in error handling
const user = await client.users.get(userId);

// Automatic pagination handling
for await (const user of client.users.list()) {
    console.log(user.name);
}
```

The difference is dramatic. An SDK transforms complex, error-prone implementation details into simple, intuitive method calls. It handles the heavy lifting of authentication, error handling, rate limiting, and pagination behind the scenes, allowing developers to focus on building their applications rather than wrestling with API integration details.

To dive deeper into why SDKs are crucial for API adoption and developer experience, [check out our comprehensive guide on APIs vs SDKs.](/post/apis-vs-sdks-difference)

## Comparing SDK Development Options

When it comes to building SDKs for your API, you have three main routes. Each comes with specific costs, maintenance burdens, and control levels:

| Handwritten                                                                                                                                                | Open Source                                                                                                                                                                                                                                                         | Speakeasy                                                                                                                                                                                                                                 |
| :--------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| ✅ Full DevEx control<br/>✅ Unlimited custom code<br/>✅ Aligned with internal coding style<br/>❌ High cost (~\$90K per SDK)<br/>❌ Upfront cost per language<br/>❌ Requires diverse in-house language expertise<br/>❌ Slow API feature updates<br/>❌ No automated documentation<br/> | ✅ No upfront cost<br/>❌ Feature gaps for common API features (OAuth 2.0, pagination, retries)<br/>❌ Non‐idiomatic code hurts DevEx<br/>❌ No CI/CD integration<br/>❌ High operational costs<br/>❌ Requires OpenAPI spec<br/>❌ Slow maintenance (4,000+ open GitHub issues)<br/>❌ Major customization limitations | ✅ Up‐to‐date, idiomatic code aligned with best practices<br/>✅ Strong DevEx control<br/>✅ Custom code support<br/>✅ Automated publishing<br/>✅ Docs integration<br/>✅ Full ownership of code<br/>❌ Paid solution<br/>❌ Requires OpenAPI spec<br/>❌ Small customization limitations<br/> |

### Hand-Written SDKs

Building SDKs by hand offers maximum control over the developer experience and allows for perfect alignment with internal coding styles. However, this approach comes with significant trade-offs. The initial development cost is high (around $90,000 per SDK), and ongoing maintenance requires a dedicated team with expertise in multiple programming languages. Beyond the direct costs, several common pitfalls can undermine the success of hand-written SDKs:

1.  **Neglected Maintenance:** APIs evolve. If your SDK doesn’t evolve alongside it, you’ll introduce breaking changes, outdated docs, and dissatisfied users.
2.  **Inconsistent Language Support:** If you release multiple SDKs but treat one as a “primary” language, users in other languages may feel neglected.
3.  **Improper Error Handling:** Failing to handle retries, rate limits, or authentication seamlessly can turn a developer’s first impression sour.
4.  **Over-Engineering or Under-Engineering:** Trying to build a “perfect” SDK can lead to months of development. Conversely, a bare-bones approach can frustrate users with missing features.
5.  **Incomplete Documentation:** Even the best SDK is useless if developers can’t find clear examples and usage instructions.

---

### Using OpenAPI Generator

OpenAPI Generator is a robust, open-source tool that automates the creation of SDKs from your OpenAPI specifications. Distributed under the Apache 2.0 license, it offers the flexibility to modify and integrate the generated code into commercial projects across multiple languages. Its straightforward setup and integration with CI/CD pipelines make it an attractive option for teams focused on rapid prototyping or projects with narrowly defined requirements.

That said, while the tool boasts a low upfront cost, it comes with a set of challenges that can become significant in production environments. For instance, as of January 2024, the repository was burdened with over 4,500 open GitHub issues—a stark indicator of the ongoing community maintenance challenges and the absence of formal support or SLAs. This reliance on community-driven fixes can result in unpredictable resolution times for critical bugs or regressions, making it a less-than-ideal choice for enterprise applications.

Moreover, the quality and idiomatic correctness of the generated code can vary widely between target languages. Developers may find themselves investing considerable time customizing templates, patching bugs, and integrating advanced features like OAuth flows, rate limiting, or webhooks to meet internal standards and production-grade requirements. This hidden engineering overhead can quickly erode the initial cost savings offered by the tool.

While OpenAPI Generator remains a viable solution for projects with very specific needs or constraints—particularly where time-to-market is paramount—its challenges in maintenance, support, and consistency often prompt larger organizations to consider more comprehensive, enterprise-grade alternatives.

For a deeper dive into these challenges and a detailed comparison with Speakeasy’s managed approach, [read our analysis.](/post/speakeasy-vs-openapi-generator)

---

### Speakeasy

Speakeasy generates enterprise-grade SDKs directly from your OpenAPI spec, eliminating the need for a proprietary DSL or additional config files.

**Key Benefits**:

*   **Fully Managed & Always Up-to-Date:** Automated validation, code generation, publishing, and regeneration upon API spec changes.
*   **OpenAPI-Native & No Lock-In:** Uses your existing OpenAPI spec as the single source of truth.
*   **Idiomatic & Enterprise-Ready:** Generates code that feels native to each language, with built-in authentication, retries, pagination, and error handling.
*   **Automated Testing & Documentation:** Ensures SDK compatibility and provides comprehensive API references.
*   **Dedicated Support:** A professional team to handle fixes, new features, and improvements.

<Callout type="quote">
  "Finding Speakeasy has been transformational in terms of our team's velocity. We've been able to progress our roadmap faster than we thought possible. We were able to get SDKs for 3 languages in production in a couple of weeks!"

  — Codat Engineering Team
</Callout>

---

## Making the Right Choice

Your decision hinges on **resources, timeline,** and **feature demands**:

*   **Hand-Written SDKs:** Maximum control, but at the highest cost and longest development time.
*   **OpenAPI Generator:** A seemingly free option, but often requires significant hidden engineering effort for maintenance and customization.
*   **Speakeasy:** The fastest and most cost-effective way to get enterprise-grade, fully-managed SDKs, directly from your OpenAPI spec.

Building SDKs is a significant investment in your API's success, but the right approach can dramatically impact both your costs and adoption rates. Speakeasy offers a compelling alternative to traditional methods, providing enterprise-grade SDKs without the usual time and cost burden.

Because Speakeasy is OpenAPI-native, you maintain complete control of your API definition. Generate your first SDK in minutes using your existing OpenAPI spec, or work with our team to optimize it for the best possible results. 

[Click here](https://app.speakeasy.com/) to generate your first SDKs — for free.


 This is the content for the doc blog/how-to-build-terraform-providers/index.mdx 

 ---
title: "How to Generate Terraform Providers"
description: "How to create a Terraform provider automatically from an OpenAPI/Swagger Document with Speakeasy, and how it compares to using the new HashiCorp codegen framework."
keywords: [go, golang, HashiCorp, Terraform, OAS, OpenAPI, schema, provider]
image: "/media/how-to-build-terraform-providers.png"
date: 2024-02-21
authors:
  - name: Thomas Rooney
  - image_url: "/media/author-headshots/thomas.jpeg"
tags:
  - Terraform
featured_image: "/media/how-to-build-terraform-providers.png"
---

HashiCorp (creators of Terraform) recently released a tool for automatically creating Terraform provider data types from your OpenAPI documents. In this post we'll do a full walkthrough of how to use both of these tools, but before getting into the details, here's a high level summary of the differences between the two:

- Requires a separate, custom generation configuration. Speakeasy uses the built-in OpenAPI Specification extensions mechanism to define Terraform Provider resources and data modeling. (Both must be handwritten today, but we could make a product decision to enable better UX.)
- Only creates Terraform schema and data handling types. There is no code generation for the underlying code to handle API requests/responses, implement API security, nor Terraform Provider resource logic. Speakeasy does everything (works out of the box).
- Does not support the full OpenAPI Specification data handling system. Speakeasy supports OAS schemas including advanced features, such as `oneOf` and `allOf`.
- Has only received dependency maintenance updates since January 2024. Speakeasy is actively maintained and enhanced.
- Because the Speakeasy workflow is end to end, it is easy to fully automate the generation. Speakeasy has a Github Action that can easily be added to your CI/CD. Hashicorp would require a custom script to pull together a couple of tools in order to fully automate the generation.
- In contrast to Speakeasy's "OpenAPI-first" philosophy, HashiCorp uses an intermediate format between the OpenAPI schema and the provider. This format is theoretically useful if you want to create a provider with something other than OpenAPI, such as directly from your API codebase. But in that case, you probably would need to write a custom script, as there is no tool for this yet.

For those who need it, let's start with a brief overview of Terraform providers and how they work. Otherwise, you can skip ahead to [Generating a Terraform Provider](#generating-a-terraform-provider)

## What Is a Terraform Provider?

Terraform is a free tool to manage infrastructure with configuration files. For instance, you can call Terraform to create identical AWS servers ready to run an application in development, test, and production environments by giving it the same configuration file for each environment. A Terraform provider is a plugin to the Terraform core software that allows Terraform to access resources that live in a 3rd party system (for example, the AWS provider allows access to AWS, the system that manages cloud infrastructure resources). 

## Why Build a Terraform Provider for an API?

If your API calls a stateless service (to get a share price, for instance, or charge a credit card), there is nothing for configuration files to manage. However, if your API manages any resource that persists (like user permissions or an accounting system), you could offer your users a custom Terraform provider as an interface to your API, allowing them to call your service through a standard set of configuration files.

For a more thorough conversation of Terraform providers and examples, see our article on the [benefits of Terraform providers](/post/build-terraform-providers).

## About Terraform Providers

Terraform providers are modules written in Go as plugins for Terraform.

When you install a Terraform provider with `go install`, it is saved to the `go` path, for example, `root/go/bin`.

The Terraform provider filename will match the first line in the module's `go.mod` file. For example, the following:

```go
module github.com/speakeasy/terraform-provider-terraform
```

Will match the file `root/go/bin/terraform-provider-terraform`.

However, the name you use for the provider in the `source` field of the Terraform resource configuration file comes from your module's `main.go` file. In this excerpt:

```hcl
terraform {
  required_providers {
    terraform = {
      source  = "speakeasy/terraform"
      version = "0.0.3"
    }
  }
}
```

The name used in the `source` field comes from the module's `main.go` file:

```go
	opts := providerserver.ServeOpts{
		Address: "registry.terraform.io/speakeasy/terraform",
```

When building and testing Speakeasy and HashiCorp providers locally, you need to match your Terraform repository overrides to the `main.go` field in `.terraformrc`:

```hcl
provider_installation {
  dev_overrides {
    "speakeasy/terraform" = "/root/go/bin"
    "terraform-provider-petstore" = "/root/go/bin"
  }
  direct {}
}
```

## Generating a Terraform Provider


### Prerequisites

If you would like to create a Terraform provider by following this tutorial, you'll need [Docker](https://docs.docker.com/get-docker) installed. Alternatively, you can install Go, Node.js, Speakeasy, Terraform, and the Terraform provider creation modules on your local machine.

Below is a Dockerfile that creates an image prepared with Go, Terraform, Speakeasy, and the new HashiCorp codegen framework that you can use to run all the code in this article. Replace the Speakeasy key with your own on line nine and save the file as `Dockerfile`.

```bash
FROM --platform=linux/amd64 alpine:3.19

WORKDIR /workspace

RUN apk add go curl unzip bash sudo nodejs npm vim

ENV GOPATH=/root/go
ENV PATH=$PATH:$GOPATH/bin
ENV SPEAKEASY_API_KEY=SET_YOUR_API_KEY_HERE

# install terraform:
RUN curl -O https://releases.hashicorp.com/terraform/1.7.0/terraform_1.7.0_linux_amd64.zip && \
    unzip terraform_1.7.0_linux_amd64.zip && \
    mv terraform /usr/local/bin/ && \
    rm terraform_1.7.0_linux_amd64.zip

# install openapi terraform provider framework:
RUN go install github.com/hashicorp/terraform-plugin-codegen-framework/cmd/tfplugingen-framework@latest
RUN go install github.com/hashicorp/terraform-plugin-codegen-openapi/cmd/tfplugingen-openapi@latest

# install speakeasy
RUN curl -fsSL https://go.speakeasy.com/cli-install.sh | sh
```

Run the following commands in a terminal to start using the Dockerfile:

```sh
mkdir code
docker build -t seimage .  # build the image
docker run -it --volume ./code:/workspace --name sebox seimage   # run the container using the code folder to work in

# Run this command if you need to start the container again later:
# docker start -ai sebox
```

In another terminal on your host machine (not inside Docker), run the code below to create folders to work in for the Speakeasy and HashiCorp examples:

```sh
cd code
mkdir hashi # hashicorp
mkdir se # speakeasy
cd se
touch openapi.yaml
```

You need to give your host user write permissions to files created in the container to edit them. On Unix-like systems, use the following command on your host machine, replacing `myusername` with your user name:

```
sudo chown -R myusername:myusername code
```

Now insert the Swagger Petstore example schema (available [here](https://github.com/speakeasy-api/examples-repo/blob/main/how-to-build-terraform-providers/original-openapi.yaml)) into the `openapi.yaml` file. The Swagger Petstore example schema is the API description of a service that manages pets and orders for pets at a store.


## Create a Terraform Provider With the HashiCorp Provider Spec Generator

The [HashiCorp automated Terraform provider creator](https://developer.hashicorp.com/terraform/plugin/code-generation/design) works differently from Speakeasy. HashiCorp provides an API SDK to convert your OpenAPI schema into an intermediate format, called the provider code specification (JSON). This document is then transformed into a provider by Terraform SDK. These transforming SDKs are both CLI tools.

```mermaid
flowchart TD
  subgraph 0[" "]
    1(📜 OpenAPI schema)
    1b(📜 Generator configuration)
  end
  0 --⚙️ API SDK--> 2(📃 Provider code specification)
  2 --⚙️ Terraform SDK --> 3(🗝️ Go provider)
```

An OpenAPI schema does not describe which Terraform resource each operation maps to. So, like Speakeasy extension attributes, you need to include mapping information in a generator configuration file along with your schema.

You can create a provider by starting at any one of the three steps:
- [Start with an OpenAPI schema](https://developer.hashicorp.com/terraform/plugin/code-generation/openapi-generator), as with Speakeasy.
- [Write a provider code specification manually](https://developer.hashicorp.com/terraform/plugin/code-generation/framework-generator), or with some tool the Terraform community may develop in the future, without using OpenAPI at all. Writing a provider code specification is closely coupled to the Terraform system and allows you to precisely create a compatible provider. You can even include custom Go functions to map objects between your API and Terraform. The full list of features with examples is [here](https://developer.hashicorp.com/terraform/plugin/code-generation/specification).
- Create a provider manually by coding it in Go (the traditional way).

As noted in the [HashiCorp code generation design principles](https://developer.hashicorp.com/terraform/plugin/code-generation/design#apis-support-more-than-just-terraform-providers), there is a mismatch between an OpenAPI schema and a Terraform provider. Providers expect resources, transfers, and errors to relate in a way that an API doesn't. For this reason, it's unlikely that there will ever be a general solution to creating a provider from a schema that does not require annotations like Speakeasy extension attributes or a HashiCorp generator configuration.

### The HashiCorp Workflow Example

HashiCorp provides a [full walkthrough for creating a Terraform provider from a schema](https://developer.hashicorp.com/terraform/plugin/code-generation/workflow-example). The Docker container you have been working in has everything you need to follow the Hashicorp walkthrough if you'd like to. Change to the `hashi` folder and continue working.

We don't repeat HashiCorp's tutorial here, but let's take a look at the steps and how the process differs from Speakeasy.

- HashiCorp doesn't create a full Go project for you. You need to create one with `go mod init terraform-provider-petstore`.
- You need to use the framework code generator `scaffold` command to create a template for the Go provider code, and write your own `main.go` file.
- Instead of adding attributes to your schema, you create a `generator_config.yml` file to hold the mapping between the schema and the provider. It looks like this:
  ```yaml
  provider:
  name: petstore
  resources:
    pet:
      create:
        path: /pet
        method: POST
      read:
        path: /pet/{petId}
        method: GET
      schema:
        attributes:
          aliases:
            petId: id
  ```
- The `tfplugingen-openapi generate` command creates a provider code specification in JSON from your schema, and then `tfplugingen-framework generate` creates the provider from the provider code specification, like so:
  ```sh
  tfplugingen-openapi generate \
    --config ./generator_config.yaml \
    --output ./specification.json \
    ./openapi.yaml &&

  tfplugingen-framework generate all \
      --input specification.json \
      --output internal/provider
  ```
- This creates the Go files `internal/provider/provider_petstore/petstore_provider_gen.go` and `internal/provider/resource_pet/pet_resource_gen.go`. The `_gen` in the filename is a hint that a tool created the file, and it should not be edited manually.
- The HashiCorp Terraform provider generator does not create all the code you need. It creates only the Go data types for the pet resource, not the code that manages the data. In the middle of the HashiCorp Terraform provider generation walkthrough, you can see that a long page of code needs to be copied and pasted into `/internal/provider/pet_resource.go`.

## Create a Terraform Provider With Speakeasy

In the Docker container terminal, navigate to the `se` directory using the command `cd /workspace/se` and run the following command to check that your OpenAPI schema is acceptable to Speakeasy:

```sh
speakeasy validate openapi -s openapi.yaml;
```

The Petstore schema has three object types: pet, order, and user. To test Terraform providers, we'll implement the `addPet` and `getPetById` operations. Terraform will use these two operations to create a single pet, and then check if the pet exists when verifying the Terraform state against the API. These operations correspond to Create and Read in CRUD.

### Add Speakeasy Terraform Annotations

We use Speakeasy extension attributes in a schema to have Speakeasy create a Terraform provider. The Speakeasy extensions tell Terraform which OpenAPI schema operations map to which CRUD operations for each resource, and which field is the ID.

Read our [overview of how the Terraform provider creation process works](/docs/create-terraform) or view the [full list of Speakeasy Terraform extensions](/docs/terraform/extensions) for more information about creating Terraform providers with Speakeasy.

Insert the following commented lines into `openapi.yaml`:

```yaml
...
    post:
      tags:
        - pet
      summary: Add a new pet to the store
      description: Add a new pet to the store
      x-speakeasy-entity-operation: Pet#create  # <-----
      operationId: addPet
...
  /pet/{petId}:
    get:
      tags:
        - pet
      summary: Find pet by ID
      description: Returns a single pet
      operationId: getPetById
      x-speakeasy-entity-operation: Pet#read  # <-----
      parameters:
        - name: petId
          x-speakeasy-match: id  # <-----
...
components:
  schemas:
    ...
    Pet:
      x-speakeasy-entity: Pet  # <-----
      required:
        - name
        - photoUrls
      type: object
...
```

Validate the schema and create the provider in the Docker container:

```sh
speakeasy validate openapi -s openapi.yaml &&
speakeasy generate sdk --schema openapi.yaml --out sdk --lang terraform
```

Speakeasy creates a Terraform provider (Go module) in the `sdk` folder.

#### Speakeasy Security Support

In most cases, Speakeasy should support [security in providers](/docs/create-terraform):
> Every authentication mechanism that relies on static authorization is supported with its values automatically available to be configured in the provider configuration.

But you may encounter instances where this will not be true in practice. If you create a provider for the Petstore schema without removing the security elements, when you run `go run main.go --debug`, you'll get the error:

```sh
internal/provider/pet_data_source.go:135:43: not enough arguments in call to r.client.Pet.GetPetByID
 	have (context.Context, operations.GetPetByIDRequest)
 	want (context.Context, operations.GetPetByIDRequest, operations.GetPetByIDSecurity)
```

In this instance, Speakeasy will not create a provider, as the API method is defined to have differing *resource* security configuration to the global *provider* security configuration in the OpenAPI specification. 

Similarly, for oAuth2 authenticated APIs, the authentication mechanism between a Client and a Token endpoint is ambiguous, even in the (latest) OpenAPI 3.1 Specification. Speakeasy currently natively supports the `client_secret_post` oAuth2 authentication schema as described in Section 9 of [OpenID Connect Core 1.0](https://openid.net/specs/openid-connect-discovery-1_0.html#OpenID.Core), under the client credentials flow, but does require that some code is written to help authenticate your provider with your service for your flavour of authentication.

### Install the Terraform Provider

Run the commands below in the Docker terminal to install the Terraform provider as `root/go/bin/terraform-provider-terraform`:

```sh
cd sdk
go install
```

You need to edit the Terraform settings file to redirect provider requests from the online Terraform repository to the custom local provider we created, or Terraform will try to find a provider online for your service and fail. The file is not in the shared `code` folder, so you need to edit it in the Docker terminal. Below we use Vim.

```sh
vim /root/.terraformrc

# inside vim:
# i to enter into edit mode
# ctrl-shift-v to paste the text below:

provider_installation {
  dev_overrides {
    "speakeasy/terraform" = "/root/go/bin",
    "terraform-provider-petstore" = "/root/go/bin"
  }
  direct {}
}

# escape to exit edit mode
# :wq to write and quit vim
```

Here we add `terraform-provider-petstore` in addition to the Speakeasy line so that your container is ready to run the HashiCorp tutorial later.

### Call the Provider From Terraform

Now that the provider is installed and ready, we need a Terraform resource configuration file as input.

Insert the code from `sdk/examples/provider/provider.tf` (which defines the provider to use) into `sdk/examples/resources/terraform_pet/resource.tf` (which defines the resource to change). The final `sdk/examples/resources/terraform_pet/resource.tf` file should look like this:

```hcl
terraform {
  required_providers {
    terraform = {
      source  = "speakeasy/terraform"
      version = "0.0.1"
    }
  }
}

provider "terraform" {
  # Configuration options
}

resource "terraform_pet" "my_pet" {
  id   = 10
  name = "doggie"
  photo_urls = [
    "...",
  ]
  status = "available"
}
```

Now we can call the Petstore service through the API using Terraform and the resource configuration file. In Docker:

```sh
cd /workspace/se/sdk/examples/resources/terraform_pet
terraform plan
terraform apply
```

The result is an expected Terraform execution:

```sh
/workspace/se/sdk/examples/resources/terraform_pet # terraform apply
╷
│ Warning: Provider development overrides are in effect
│
│ The following provider development overrides are set in the CLI configuration:
│  - speakeasy/terraform in /root/go/bin
│  - speakeasy/hashicups in /root/go/bin
│
│ The behavior may therefore not match any released version of the provider and applying changes may cause the state to become incompatible with published releases.
╵

Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

  # terraform_pet.my_pet will be created
  + resource "terraform_pet" "my_pet" {
      + category   = (known after apply)
      + id         = 10
      + name       = "doggie"
      + photo_urls = [
          + "...",
        ]
      + status     = "available"
      + tags       = (known after apply)
    }

Plan: 1 to add, 0 to change, 0 to destroy.

Do you want to perform these actions?
  Terraform will perform the actions described above.
  Only 'yes' will be accepted to approve.

  Enter a value: yes

terraform_pet.my_pet: Creating...
terraform_pet.my_pet: Creation complete after 2s [name=doggie]

Apply complete! Resources: 1 added, 0 changed, 0 destroyed.
```

You'll notice we do not have a local implementation of the API service running somewhere for the provider to call. The Petstore example is a real service provided online by Swagger. You can see the URL in the `server` field of the schema. For example, you can browse to an operation at https://petstore3.swagger.io/.

If you are building your own API, you'll need to make a service the provider can call.

### Summary of the Speakeasy Terraform Provider Creation Process

Let's review what we did:

- Annotate an OpenAPI schema file with Speakeasy extension attributes to indicate which operations are for which Terraform CRUD functions.
- Remove security elements and non-JSON request and response elements.
- Create the Terraform provider Go code with Speakeasy.
- Compile and install the provider.
- Redirect Terraform settings to use the local provider.
- Make a Terraform resource configuration file.
- Run Terraform against the file.

As your API changes over time and you release new Terraform provider versions to clients, you will need to add extension attributes. Apart from that, the Terraform provider creation process should be an automated set of terminal commands.


## Comparison and Conclusion

In conclusion, Speakeasy provides a complete solution for creating a Terraform provider from a schema with only one manual step. The HashiCorp automated Terraform provider generator is not ready for production use yet, but is something to keep an eye on during 2024 to see how it catches up. The HashiCorp provider code specification intermediate language will also benefit from the massive Terraform community building plugins.

Read [our case study on how leading data integration platform Airbyte uses Speakeasy](/customers/airbyte) to create and maintain Terraform providers alongside SDKs and minimize engineer burden.

## Further Reading

- [Benefits of providers for an API](/post/build-terraform-providers)
- [Original Petstore example](https://github.com/speakeasy-api/examples-repo/blob/main/how-to-build-terraform-providers/original-openapi.yaml)
- [Annotated Petstore example](https://github.com/speakeasy-api/examples-repo/blob/main/how-to-build-terraform-providers/annotated-openapi.yaml)
- [HashiCorp provider example](https://github.com/hashicorp/terraform-provider-hashicups)
- [Speakeasy provider example](https://github.com/speakeasy-sdks/terraform-provider-hashicups)
- [OpenTofu — the open-source Terraform substitute](https://opentofu.org)

### HashiCorp Automated Terraform Provider Creation
- [Documentation overview](https://developer.hashicorp.com/terraform/plugin/code-generation/design)
- [Provider code specification documentation](https://developer.hashicorp.com/terraform/plugin/code-generation/specification)
- [OpenAPI schema SDK](https://github.com/hashicorp/terraform-plugin-codegen-openapi)
- [Terraform SDK](https://github.com/hashicorp/terraform-plugin-codegen-framework)

### Speakeasy Automated Terraform Provider Creation
- [Documentation overview](/docs/create-terraform)
- [Annotation documentation](/docs/terraform/extensions)


 This is the content for the doc blog/how-to-create-a-custom-python-sdk.mdx 

 ---
title: "How To Build A Best In Class Python SDK"
description: "This tutorial demonstrates one way to code and package a Python SDK."
keywords: [python, SDK, api, developer experience, devex, dx, openapi]
image: "/media/how-to-build-python-sdks.png"
date: 2024-04-29
authors:
  - name: Tristan Cartledge
  - image_url: "/media/author-headshots/tristan.jpeg"
tags:
  - API Advice
featured_image: "/media/how-to-build-python-sdks.png"
---

import { Callout } from "nextra/components";

This tutorial demonstrates one way to code and package a Python SDK.

## Why Are We Building an SDK?

Since the 2000s, HTTP APIs have enabled businesses to be more connected than ever and, as a result, produce higher utility and profit — no wonder APIs have exploded in popularity.

So, your business has created an API? Great! At first, developers might use `curl` or create a Postman collection to experiment with your API. However, the true power of an API is only unleashed when developers can interact with it in an automated and programmatic way. To get some real work done, you'll want to wrap the HTTP API in your language of choice, so that it can be testable and have the most important aspects abstracted for your convenience and productivity.

## What Are We Building?

We'll build a Python SDK that wraps an HTTP API.

Fictional e-commerce startup ECOM enables the selling of products through the creation of online stores and associated products on its website. The ECOM HTTP API enables developers to create stores and manage products in an automated way. We want to give Python programmers easy access to the ECOM API with a robust, secure, and user-friendly SDK that handles the underlying HTTP API service in a type-safe, programmatic way.

## Example SDK Repository

You can follow along without downloading our complete example repository, but if you get stuck or want to see the final result, you can find the code on GitHub at [speakeasy-api/ecom-sdk](https://github.com/speakeasy-api/ecom-sdk).

## Initialize the Project

Before we begin coding the SDK, let's set up our project.

### Install pyenv

While not strictly necessary in all cases, we prefer to manage Python versions with pyenv. If you're building the SDK with us, [install `pyenv`](https://github.com/pyenv/pyenv?tab=readme-ov-file#installation) for your operating system.

On macOS, you can install `pyenv` with Homebrew:

```bash
brew install pyenv
```

### Decide on a Python Version

<Callout title="Python Versions" variant="warning">
  Deciding on a [Python version](https://devguide.python.org/versions/) that
  your SDK will support is important. At the time of writing, Python 3.8 is the
  minimum version supported by many popular libraries and frameworks. Python
  3.12 is the latest stable version. Even though Python 2 is no longer
  supported, some older projects still use it, so you may need to support Python
  2.7 if your SDK is to be used in internal legacy systems that have not yet
  been updated.
</Callout>

For this tutorial, we'll use Python 3.8, because it is the oldest version that still receives security updates.

### Install Python 3.8

Install Python 3.8 with `pyenv`:

```bash
pyenv install 3.8.19
```

### Set Up a Python Virtual Environment

We'll set up a Python virtual environment to isolate our project dependencies from the system Python installation.

Create a new Python 3.8 virtual environment:

```bash
pyenv virtualenv 3.8.19 ecom-sdk
```

Activate the virtual environment:

```bash
pyenv activate ecom-sdk
```

After activating the virtual environment, depending on the shell you're using, your shell prompt might change to indicate that you are now using the virtual environment. Any Python packages you install will be installed in the virtual environment and won't affect the system Python installation.

### Upgrade pip

When you create a new virtual environment, it's good practice to upgrade `pip` to the latest version:

```bash
python3.8 -m pip install --upgrade pip
```

### Decide on a Build Backend

<Callout title="Python Packaging" variant="warning">
  The [complexities of Python
  packaging](https://packaging.python.org/en/latest/) can make navigating your
  options challenging. We will outline the options briefly before selecting an
  option for this particular example.
</Callout>

In the past, Python used a `setup.py` or `setup.cfg` configuration file to prepare Python packages for distribution, but new standards (like PEPs 517, 518, 621, and 660) and build tools are modernizing the Python packaging landscape. We want to configure a modern build backend for our SDK and we have many options to choose from:

- [Hatchling](https://hatch.pypa.io/latest/history/hatchling/)
- [Poetry](https://python-poetry.org/)
- [PDM](https://pdm-project.org/)
- [Setuptools](https://pypi.org/project/setuptools/)
- [Flit](https://flit.pypa.io/en/stable/)
- [Maturin](https://github.com/PyO3/maturin)

Some factors to consider when selecting a build backend include:

- **Python version support:** Some build backends only support a subset of Python versions, so ensure your chosen build backend supports the correct versions.
- **Features:** Determine the features you need and choose a backend that meets your requirements. For example, do you need features like project management tools, or package uploading and installation capabilities?
- **Extension support:** Do you need support for extension modules in other languages?

We'll use [Hatchling](https://hatch.pypa.io/latest/history/hatchling/) in this tutorial for its convenient defaults and ease of configurability.

### Set Up a Project With Hatchling

First, install Hatch:

```bash
pip install hatch
```

Now, create a new project with Hatch:

```bash
hatch new -i
```

The `-i` flag tells Hatch to ask for project information interactively. Enter the following information when prompted:

```bash
Project name: ECOM SDK
Description: Python SDK for the ECOM HTTP API
```

Hatch will create a new project directory with the name `ecom-sdk` and initialize it with a basic `pyproject.toml` file.

Change into the project directory:

```bash
cd ecom-sdk
```

### See the Project Structure

Run `tree` to see the project structure:

```bash
tree .
```

The project directory should now contain the following files:

```bash
.
├── LICENSE.txt
├── README.md
├── pyproject.toml
├── src
│   └── ecom_sdk
│       ├── __about__.py
│       └── __init__.py
└── tests
    └── __init__.py

4 directories, 6 files
```

The `LICENSE.txt` file contains the MIT license, the `README.md` file has a short installation hint, and the `pyproject.toml` file contains the project metadata.

### Update the README File

If you continue to support and expand this SDK, you'll want to keep the `README.md` file up to date with the latest documentation, providing installation and usage instructions, and any other information relevant to your users. Without a good README, developers won't know where to start and won't use the SDK.

For now, let's add a short description of what the SDK does:

```markdown
# ECOM SDK

Python SDK for the ECOM HTTP API
```

### Create a Basic SDK

Add a `./src/ecom_sdk/sdk.py` file containing Python code, for example:

```python
def sdkFunction():
    return 1
```

We'll use the `./src/ecom_sdk/sdk.py` file to ensure our testing setup works.

### Create a Test

As we add functionality to the SDK, we will populate the `./tests` directory with tests.

For now, create a `./src/ecom_sdk/test_sdk.py` file containing test code:

```python
import src.ecom_sdk.sdk

def test_sdk():
    assert src.ecom_sdk.sdk.sdkFunction() == 1
```

Later in this guide, we'll run the test with scripts provided by Hatch.

### Inspect the Build Backend Configuration

The `pyproject.toml` file contains the project metadata and build backend configuration.

Be sure to take a peek at the `pyproject.toml` [guide](https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#writing-pyproject-toml) and [specification](https://packaging.python.org/en/latest/specifications/pyproject-toml/#pyproject-toml-specification) for details on all the possible metadata fields available for the `[project]` table. For example, you may want to enhance the discoverability of your SDK on PyPI by specifying keyword metadata or additional classifiers.

### Test Hatch

Here's the Hatch test script that we'll use to run tests:

```bash
hatch run test
```

The first time you run the test script, Hatch will install the necessary dependencies and run the tests. Subsequent runs will be faster because the dependencies are already installed.

After running the test script, you should see output similar to the following:

```bash
========================= test session starts ==========================
platform darwin -- Python 3.12.3, pytest-8.1.1, pluggy-1.5.0
rootdir: /speakeasy/ecom-sdk
configfile: pyproject.toml
collected 1 item

tests/test_sdk.py .                                              [100%]

========================== 1 passed in 0.00s ===========================
```

## Code the SDK

Now that we have the project set up, let's start coding the SDK.

### Add an SDK Method To Fetch a List of Stores

In the `./src/ecom_sdk/sdk.py` file, define a class, constructor, and `list_stores()` method for fetching a list of stores from our API:

```python
import requests

HTTP_TIMEOUT_SECONDS = 10


class EComSDK:
    def __init__(self, api_url, api_key):
        self.api_url = api_url
        self.api_key = api_key

    def list_stores(self):
        r = requests.get(
            self.api_url + "/store",
            headers={"X-API-KEY": self.api_key},
            timeout=HTTP_TIMEOUT_SECONDS,
        )
        if r.status_code == 200:
            return r.json()
        else:
            raise Exception("Invalid response status code: " +
                            str(r.status_code))
```

Now we can begin writing tests in the `./tests/test_sdk.py` file to test that the newly added `list_stores()` method works as intended.

In `requests.get()`, we use `HTTP_TIMEOUT_SECONDS` to set a maximum bound for waiting for the request to finish. If we don't set a timeout, the `requests` library will wait for a response forever.

Add the following to `./tests/test_sdk.py`:

```python
from src.ecom_sdk.sdk import EComSDK
import responses
from responses import matchers

api_url = "https://example.com"
api_key = "hunter2"


def test_sdk_class():
    sdk = EComSDK(api_url, api_key)
    assert sdk.api_url == api_url
    assert sdk.api_key == api_key


@responses.activate
def test_sdk_list_stores():
    responses.add(
        responses.GET,
        api_url + "/store",
        json=[
            {"id": 1, "name": "Lidl", "products": 10},
            {"id": 2, "name": "Walmart", "products": 15},
        ],
        status=200,
        match=[matchers.header_matcher({"X-API-KEY": api_key})],
    )

    sdk = EComSDK(api_url, api_key)
    stores = sdk.list_stores()

    assert len(stores) == 2
    assert stores[0]["id"] == 1
    assert stores[0]["name"] == "Lidl"
    assert stores[1]["id"] == 2
    assert stores[1]["name"] == "Walmart"
```

Here we use the `responses` library to mock API responses since we don't have a test or staging version of the ECOM HTTP API. However, even with the ECOM API, we might choose to have some part of the testing strategy mock the API responses as this approach can be faster and tightly tests code without external dependencies.

The `test_sdk_class()` test function checks that we can instantiate the class and the correct values are set internally.

The `test_sdk_list_stores()` test function makes a call to `sdk.list_stores()` to test that it receives the expected response, which is a JSON array of stores associated with the user's account.

### Add Dependencies

We need to add the `requests` and `responses` libraries to the project dependencies. Add the following to the `pyproject.toml` file:

```toml
dependencies = [
  "requests",
  "responses",
  "pydantic",
]
```

### Run the Tests

Let's run the Hatch `test` script we configured earlier to check that everything is working correctly:

```bash
hatch run test
```

Once Hatch has installed our new dependencies, you should see output similar to the following:

```bash
=============================== test session starts ================================
platform darwin -- Python 3.12.3, pytest-8.1.1, pluggy-1.5.0
rootdir: /speakeasy/ecom-sdk
configfile: pyproject.toml
collected 2 items

tests/test_sdk.py ..                                                         [100%]

================================ 2 passed in 0.09s =================================
```

## Exception Handling

To create a pleasant surface for our SDK users, we'll hide details of HTTP implementation behind exception handling and provide helpful error messages should things go wrong.

Let's modify the `list_stores()` function to catch some more common errors and print helpful information for the user:

```python src/ecom_sdk/sdk.py
import requests

HTTP_TIMEOUT_SECONDS = 10


class EComSDK:
    def __init__(self, api_url, api_key):
        self.api_url = api_url
        self.api_key = api_key

    def list_stores(self):
        try:
            r = requests.get(
                self.api_url + "/store",
                headers={"X-API-KEY": self.api_key},
                timeout=HTTP_TIMEOUT_SECONDS,
            )
            r.raise_for_status()
        except requests.exceptions.ConnectionError as err:
            raise ValueError("Connection error, check `EComSDK.api_url` is set correctly") from err
        except requests.exceptions.HTTPError as err:
            if err.response.status_code == 403:
                raise ValueError("Authentication error, check `EComSDK.api_key` is set correctly") from err
            else:
                raise

        return r.json()
```

When an exception is raised from the call to `requests.get()`, we catch the exception, add useful information, and then re-raise the exception for the SDK user to handle in their code.

The call to `r.raise_for_status()` modifies the `requests` library behavior to raise an `HTTPError` if the HTTP response status code is unsuccessful. Read more about `raise_for_status()` in the [Requests library documentation](https://requests.readthedocs.io/en/latest/api/#requests.Response.raise_for_status).

Now we'll add tests for a 403 response and a connection error to the `test_sdk.py` file. We'll also import the `requests` library into the `test_sdk.py` file:

```python tests/test_sdk.py
import requests

# ...

@responses.activate
def test_sdk_list_stores_connection_error():
    responses.add(
        responses.GET,
        api_url + "/store",
        body=requests.exceptions.ConnectionError(),
    )

    sdk = EComSDK(api_url, api_key)
    try:
        sdk.list_stores()
    except ValueError as err:
        assert "Connection error" in str(err)
    else:
        assert False, "Expected ValueError"


@responses.activate
def test_sdk_list_stores_403():
    responses.add(
        responses.GET,
        api_url + "/store",
        status=403,
    )

    sdk = EComSDK(api_url, api_key)
    try:
        sdk.list_stores()
    except ValueError as err:
        assert "Authentication error" in str(err)
    else:
        assert False, "Expected ValueError"
```

This test ensures that the helpful error message from our SDK is displayed when a connection error or 403 response occurs.

Check that the new code passes the test:

```bash
hatch run test
```

## Type Safety With Enums

To make development easier and less error-prone for our SDK users, we'll define Enums to use with the `list_products` endpoint.

Add the following Enums to the `EComSDK` class:

```python src/ecom_sdk/sdk.py
import requests
from enum import Enum

HTTP_TIMEOUT_SECONDS = 10

class EComSDK:
    # ...

    class ProductSort(str, Enum):
        PRICE = "price"
        QUANTITY = "quantity"

    class ProductSortOrder(str, Enum):
        DESC = "desc"
        ASC = "asc"

    # ...
```

The `ProductSort` and `ProductSortOrder` Enums inherit from the `str` class and can be used with the `list_products()` method we'll define next – `ProductSort` specifies the sort category, and `ProductSortOrder` determines the sort order of the product list.

Now define the `list_products()` function at the bottom of the `EComSDK` class:

```python src/ecom_sdk/sdk.py
# ...
class EComSDK:
    # ...
    def list_products(self, store_id, sort_by=ProductSort.PRICE, sort_order=ProductSortOrder.ASC):
        try:
            r = requests.get(
                self.api_url + f"/store/{store_id}/product",
                headers={"X-API-KEY": self.api_key},
                params={"sort_by": sort_by, "sort_order": sort_order},
                timeout=HTTP_TIMEOUT_SECONDS,
            )
            r.raise_for_status()
        except requests.exceptions.ConnectionError as err:
            raise ValueError("Connection error, check `EComSDK.api_url` is set correctly") from err
        except requests.exceptions.HTTPError as err:
            if err.response.status_code == 403:
                raise ValueError("Authentication error, check `EComSDK.api_key` is set correctly") from err
            else:
                raise

        return r.json()
```

The `list_products()` function accepts named parameters `sort_by` and `sort_order`. If the `list_products()` function is called with named parameters, the parameters are added to the `params` dictionary to be included in the request's HTTP query parameters.

An SDK user can call the `list_products()` function with the string `list_products(sort_by="quantity")` or with the safer equivalent using Enums: `list_products(sort_by=sdk.ProductSort.QUANTITY)`. By encouraging the user to use Enums in this way, we prevent HTTP error requests that don't clearly identify what went wrong should a user mistype a string, for example, "prise" instead of "price".

Now add another test at the bottom of the `test_sdk.py` file:

```python tests/test_sdk.py
# ...

@responses.activate
def test_sdk_list_products_sort_by_price_desc():
    store_id = 1
    responses.add(
        responses.GET,
        api_url + f"/store/{store_id}/product",
        json=[
            {"id": 1, "name": "Banana", "price": 0.5},
            {"id": 2, "name": "Apple", "price": 0.3},
        ],
        status=200,
        match=[matchers.header_matcher({"X-API-KEY": api_key})],
    )

    sdk = EComSDK(api_url, api_key)
    products = sdk.list_products(store_id, sort_by=EComSDK.ProductSort.PRICE, sort_order=EComSDK.ProductSortOrder.DESC)

    assert len(products) == 2
    assert products[0]["id"] == 1
    assert products[0]["name"] == "Banana"
    assert products[1]["id"] == 2
    assert products[1]["name"] == "Apple"
```

Check that the new test passes:

```bash
hatch run test
```

## Output Type Safety With Pydantic

To make the SDK even more user-friendly, we can use Pydantic to create data models for the responses from the ECOM API.

First, add Pydantic to the project dependencies in the `pyproject.toml` file:

```toml
dependencies = [
  "requests",
  "responses",
  "pydantic",
]
```

Now, create a `Product` model in the `./src/ecom_sdk/models.py` file:

```python src/ecom_sdk/models.py
from pydantic import BaseModel

class Product(BaseModel):
    id: int
    name: str
    price: float
```

Next, import the `Product` model into the `./src/ecom_sdk/sdk.py` file:

```python src/ecom_sdk/sdk.py
from .models import Product
```

Modify the `list_products()` function to return a list of `Product` models:

```python src/ecom_sdk/sdk.py
# ...
class EComSDK:
    # ...
    def list_products(self, store_id, sort_by=ProductSort.PRICE, sort_order=ProductSortOrder.ASC):
        try:
            r = requests.get(
                self.api_url + f"/store/{store_id}/product",
                headers={"X-API-KEY": self.api_key},
                params={"sort_by": sort_by, "sort_order": sort_order},
                timeout=HTTP_TIMEOUT_SECONDS,
            )
            r.raise_for_status()
        except requests.exceptions.ConnectionError as err:
            raise ValueError("Connection error, check `EComSDK.api_url` is set correctly") from err
        except requests.exceptions.HTTPError as err:
            if err.response.status_code == 403:
                raise ValueError("Authentication error, check `EComSDK.api_key` is set correctly") from err
            else:
                raise

        return [Product(**product) for product in r.json()]
```

The `list_products()` function now returns a list of `Product` models created from the JSON response.

Now update the `test_sdk.py` file to test the new `Product` model:

```python tests/test_sdk.py
# ...
from src.ecom_sdk.models import Product

# ...

@responses.activate
def test_sdk_list_products_sort_by_price_desc():
    store_id = 1
    responses.add(
        responses.GET,
        api_url + f"/store/{store_id}/product",
        json=[
            {"id": 1, "name": "Banana", "price": 0.5},
            {"id": 2, "name": "Apple", "price": 0.3},
        ],
        status=200,
        match=[matchers.header_matcher({"X-API-KEY": api_key})],
    )

    sdk = EComSDK(api_url, api_key)
    products = sdk.list_products(store_id, sort_by=EComSDK.ProductSort.PRICE, sort_order=EComSDK.ProductSortOrder.DESC)

    assert len(products) == 2
    assert products[0].id == 1
    assert products[0].name == "Banana"
    assert products[1].id == 2
    assert products[1].name == "Apple"
    assert isinstance(products[0], Product)
    assert isinstance(products[1], Product)
```

We'll also need to update the `test_sdk_list_products()` test to check that the `Product` models are returned from the `list_products()` function.

```python tests/test_sdk.py
# ...

    assert len(products) == 2
    assert products[0].id == 1
    assert products[0].name == "Banana"
    assert products[0].price == 0.5
    assert products[1].id == 2
    assert isinstance(products[0], Product)
    assert isinstance(products[1], Product)
```

Check that the new tests pass:

```bash
hatch run test
```

We've now added type safety to the SDK using Pydantic, ensuring that the SDK user receives a list of `Product` models when calling the `list_products()` function. The same principle can be applied to other parts of the SDK to ensure that the user receives the correct data types.

## Add Type Safety to the SDK Constructor

To ensure that the SDK user provides the correct data types when instantiating the `EComSDK` class, we can use Pydantic to create a `Config` model for the SDK constructor.

First, create a `Config` model in the `./src/ecom_sdk/models.py` file:

```python src/ecom_sdk/models.py
from pydantic import BaseModel

class Config(BaseModel):
    api_url: str
    api_key: str
```

Next, import the `Config` model into the `./src/ecom_sdk/sdk.py` file:

```python src/ecom_sdk/sdk.py
from .models import Config
```

Now, modify the `EComSDK` class to accept a `Config` model in the constructor:

```python src/ecom_sdk/sdk.py
# ...
class EComSDK:
    def __init__(self, config: Config):
        self.api_url = config.api_url
        self.api_key = config.api_key

    # ...
```

The `EComSDK` class now accepts a `Config` model in the constructor, ensuring that the SDK user provides the correct data types when instantiating the class.

Let's update the `test_sdk.py` file to test the new `Config` model:

```python tests/test_sdk.py
# ...

from src.ecom_sdk.models import Config

# ...

def test_sdk_class():
    config = Config(api_url="https://example.com", api_key="hunter2")
    sdk = EComSDK(config)
    assert sdk.api_url == config.api_url
    assert sdk.api_key == config.api_key
```

Follow the same pattern to update the other tests in the `test_sdk.py` file to use the new `Config` model. Replace `sdk = EComSDK(api_url, api_key)` with:

```python tests/test_sdk.py
# ...
    config = Config(api_url=api_url, api_key=api_key)
    sdk = EComSDK(config)
# ...
```

Check that the new tests pass:

```bash
hatch run test
```

## Things to Consider

We've described some basic steps for creating a custom Python SDK, but there are many facets to an SDK project besides code that contribute to its success or failure. For any publicly available Python library, you should consider such aspects as documentation, linting, and licensing.

### Documentation

To focus on the nuts and bolts of a custom Python SDK, this guide does not cover developing an SDK's documentation. But documentation is critical to ensure your users can easily pick up your library and use it productively. Without good documentation, developers may opt not to use your SDK at all.

All SDK functions, parameters, and behaviors should be documented, and creating beautiful, functional documentation is an essential part of making your SDK usable. You can roll your own documentation and add Markdown to the project `README.md` file or use a popular library like [Sphinx](https://www.sphi_doc.org/en/master/) that includes such features as automatic highlighting, themes, and HTML or PDF outputs.

### Linting

Consistently formatted code improves readability and encourages contributions that are not jarring in the context of the existing codebase. While this guide doesn't cover linting, linting your SDK code should form part of creating an SDK.

For best results, linting should be as far-reaching and opinionated as possible, with little to zero default configuration required. Some popular options for linting include [Flake8](https://pypi.org/project/flake8/), [Ruff](https://github.com/astral-sh/ruff), and [Black](https://pypi.org/project/black/).

### Licensing

A project's license can significantly influence the type and number of potential open-source contributors. Choosing the right license for your SDK is key. Do you want your SDK's license to be community-orientated? Simple and permissive? To preserve a particular philosophy on enforcing the sharing of code modifications? In this example, we selected the MIT license for simplicity and ease of use. If you're unsure which license would best suit your needs, consider using a tool like [Choose a license](https://choosealicense.com/).

### Other Endpoints

This tutorial covered a basic SDK for two endpoints. Consider that real-world SDKs can have many more endpoints and features. You can use the same principles to add more endpoints to your SDK.

### Authentication Methods

If APIs use OAuth 2.0 or other authentication methods, you'll need to add authentication methods to your SDK. You can use libraries like [Authlib](https://docs.authlib.org/en/latest/) to handle OAuth 2.0 authentication.

### Pagination

If the API returns paginated results, you'll need to handle pagination in your SDK.

### Retries and Backoff

If the API is rate-limited or has intermittent failures, you'll need to add retry and backoff logic to your SDK.

## Build the Package

Now that we have a working SDK, we can build the package for distribution.

```bash
hatch build
```

Hatch will build the package and output the distribution files:

```bash
────────────────────────────────────── sdist ───────────────────────────────────────
dist/ecom_sdk-0.0.1.tar.gz
────────────────────────────────────── wheel ───────────────────────────────────────
dist/ecom_sdk-0.0.1-py3-none-any.whl
```

You should now have a `./dist` directory containing your source (`.tar.gz`) and built (`.whl`) distributions:

```bash
.
├── dist
│   ├── ecom_sdk-0.0.1-py3-none-any.whl
│   └── ecom_sdk-0.0.1.tar.gz
```

## Upload the SDK to the Distribution Archives

We now have just enough to upload the SDK to the PyPI test repo at test.pypi.org.

To upload the build to TestPyPI, you need:

1. A test PyPI account. Go to [https://test.pypi.org/account/register/](https://test.pypi.org/account/register/) to register.

2. A PyPI API token. Create one at [https://test.pypi.org/manage/account/#api-tokens](https://test.pypi.org/manage/account/#api-tokens), setting the "Scope" to "Entire account".

<Callout title="PyPI API Tokens" variant="warning">
  Don't close the token page until you have copied and saved the token. For
  security reasons, the token will only appear once.
</Callout>

If you plan to automate SDK publishing in your CI/CD pipeline, you should create per-project tokens. For automated releasing using CI/CD, it is recommended that you create per-project API tokens.

Finally, publish the package distribution files by executing:

```bash
hatch publish -r test
```

The `-r test` switch specifies that we are using the TestPyPI repository.

Hatch will ask for a username and credentials. Use `__token__` as the username (to indicate that we are using a token value rather than a username) and paste your PyPI API token in the credentials field.

```bash
hatch publish -r test                                                                                                                                            ⇐ [15:13]═
Enter your username [__token__]: __token__
Enter your credentials: (paste your token here)
dist/ecom_sdk-0.0.1-py3-none-any.whl ... success
dist/ecom_sdk-0.0.1.tar.gz ... success

[ecom-sdk]
https://test.pypi.org/project/ecom-sdk/0.0.1/
```

Your shiny new package is now available to all your new Python customers!

The `ecom-sdk` python package can now be installed using:

```bash
pip install --index-url https://test.pypi.org/simple/ --no-deps ecom-sdk
```

We use the `--index-url` switch to specify the TestPyPI repo instead of the default live repo. We use the `--no-deps` switch because the test PyPI repo doesn't have all dependencies (because it's a test repo) and the `pip install` command would fail otherwise.

## Automatically Create Language-Idiomatic SDKs From Your API Specification

We've taken the first few steps in creating a Python SDK but as you can see, we've barely scratched the surface. It takes a good deal of work and dedication to iterate on an SDK project and get it built right. Then comes the maintenance phase, dealing with pull requests, and triaging issues from contributors.

You might want to consider automating the creation of SDKs with a managed service like Speakeasy. You can quickly get up and running with SDKs in nine languages with best practices baked in and maintain them automatically with the latest language and security updates.


 This is the content for the doc blog/how-to-generate-a-mock-server/index.mdx 

 ---
title: "How to generate a mock server to test SDKs"
description: "Learn how to generate a mock server using Speakeasy and test your SDK against it."
image: "/media/generate-mock-server.png"
date: 2024-12-02
authors:
  - name: Brian Flad
  - image_url: "/media/author-headshots/brian.jpg"
tags:
  - Product Updates
featured_image: "/media/generate-mock-server.png"
is_featured: true
---

import { CodeWithTabs } from "~/components/codehike/CodeTabs";
import { ScrollyCoding } from "~/components/codehike/Scrollycoding";


Testing your SDK against your API can be challenging. During development, you often need to spin up a local server as well as a database and other dependencies, which can slow down the process. You're also prone to network issues, rate limits, and other external factors that can disrupt development and testing.

Mock servers provide a way to simulate your API's behavior without needing the actual API to be running. They're especially useful when you need to test how your SDK handles specific behaviors – like rate limiting or malformed responses – without relying on unpredictable or hard-to-reproduce real-world conditions.

In this guide, we'll walk through how to generate a mock server using Speakeasy and how to test your SDK against it. We'll also discuss the advantages of using a mock server during SDK development and compare Speakeasy with other mock server solutions.

## What is a mock server?

A mock server is a virtual API endpoint that simulates the behavior of a real API server. It intercepts test HTTP requests and returns predefined responses according to your OpenAPI document. This means you can test your SDK without connecting to a live API.

Think of a mock server as a stand-in actor during a rehearsal. It follows a script (your OpenAPI document) and responds exactly as needed, every time. This consistency is invaluable for ensuring thorough testing across various scenarios, from successful responses to error conditions. It also significantly speeds up the development process by removing the need to wait for real API responses.


```mermaid
graph TD
    A[Unit Test] -->|1 Setup expectations| C[Mock Server]
    A -->|2 Tests| B[SDK]
    B -->|3 Sends expected request| C
    C -->|4 Returns simulated response| B
    C -->|5 Verify requests using assertion| A
```

## Why use mock servers?

In development, you need to verify how your SDK:

- Manages rate limits
- Handles network timeouts
- Processes malformed responses

While Speakeasy-generated SDKs handle these scenarios gracefully, you still need to test them to ensure your SDK behaves as expected.

A mock server allows you to simulate these scenarios reliably, without waiting for them to occur in a real environment, ensuring your SDK is thoroughly tested before it reaches production.

Additionally, mock servers allow you to **test your SDK in complete isolation**. Instead of depending on external services, you can execute local tests that provide consistent, predictable responses every time. 

This stability has significant advantages if your backend experiences intermittent downtime or if you want to minimize the impact of outside variables like network latency or downtime windows. When using Speakeasy, the mock server aligns closely with your OpenAPI document, which means that simulated responses closely mirror the behavior of your existing API.

While generating your SDK, Speakeasy automatically creates a mock server based on your OpenAPI document, eliminating time-consuming manual coding. It even generates a suite of tests that interact with the server, giving you a strong baseline of coverage for your endpoints right out of the box.

As your API evolves, you can regenerate and update both the mock server and the test suite whenever you regenerate your SDK, meaning your simulated mock environment and tests stay in sync with the latest version of your OpenAPI document.


```mermaid
sequenceDiagram
    Tests ->> SDK: Makes calls
    SDK ->> MockServer: Sends request
    MockServer ->> SDK: Match request & return mocked response
    SDK ->> Tests: Verifies results
```

## Generating a mock server with Speakeasy

To generate a mock server using Speakeasy, we'll use our [example FastAPI server](https://github.com/speakeasy-api/examples/tree/main/frameworks-example-fastapi-travel-server), which includes an OpenAPI document. 

### 1. Clone the examples repository

Begin by cloning the the Speakeasy examples repository. This will serve as our base project.

   ```bash
   clone git@github.com:speakeasy-api/examples.git
   ```

Go to the FastAPI example:

   ```bash
   cd examples/frameworks-example-fastapi-travel-server
   ```

### 2. Set up Speakeasy 

If you haven't installed the Speakeasy CLI yet, follow these steps to get started:

- **macOS (Homebrew):**
     ```bash
     brew tap speakeasy-api/homebrew-tap
     brew install speakeasy
     ```
- **macOS/Linux (Shell Script):**
     ```bash
     curl -fsSL https://raw.githubusercontent.com/speakeasy-api/speakeasy/main/install.sh | bash
     ```
- **Windows (Scoop):**
     ```powershell
     scoop bucket add speakeasy-api https://github.com/speakeasy-api/speakeasy
     scoop install speakeasy
     ```

You can verify the installation by running the following command:

   ```bash
   speakeasy --version
   ```

Next, authenticate your CLI with the Speakeasy platform:

   ```bash
   speakeasy auth login
   ```

For more detailed installation instructions, refer to the [getting started guide](/docs/speakeasy-reference/cli/getting-started).

### 3. Generate the SDK

In the cloned repository, use the Speakeasy CLI to generate an SDK from the OpenAPI document.

   ```bash
   speakeasy quickstart -o ./sdk -s openapi.yaml -t python
   ```

Answer the prompts to configure the SDK generation process. The resulting SDK will be saved in the `/sdk` directory.

### 4. Modify the `gen.yaml` file

Navigate to the generated SDK directory and locate the `.speakeasy` folder. 

   ```bash
   cd sdk/.speakeasy
   ```

The `gen.yaml` file in the `.speakeasy` folder contains the configuration for the SDK generation process. We'll modify this file to enable mock server generation.

Open the `gen.yaml` file in your text editor:

   ```bash
   nvim gen.yaml  # or your preferred editor
   ```



<ScrollyCoding>

### !!steps

Add the `tests` configuration to the `gen.yaml` file and set `generateNewTests` to `true` to enable mock server generation and create test files.

```yaml ! .speakeasy/gen.yaml
# !focus(18:19)
configVersion: 2.0.0
generation:
  devContainers:
    enabled: true
    schemaPath: openapi.yaml
  sdkClassName: HolidayDestinations
  maintainOpenAPIOrder: true
  usageSnippets:
    optionalPropertyRendering: withExample
  useClassNamesForArrayFields: true
  fixes:
    nameResolutionDec2023: true
    parameterOrderingFeb2024: true
    requestResponseComponentNamesFeb2024: true
  auth:
    oAuth2ClientCredentialsEnabled: true
    oAuth2PasswordEnabled: true
  tests:
    generateNewTests: true
```

</ScrollyCoding>

### 5. Generate the mock server

Next, regenerate the SDK with the updated configuration. Run the following command from a terminal in your SDK directory:

   ```bash
   speakeasy run
   ```

A new `/tests` directory will be created in the `./sdk` folder, containing the mock server and test files.

```bash SDK directory structure
sdk
├── .devcontainer
├── .gitattributes
├── .gitignore
├── .speakeasy
├── CONTRIBUTING.md
├── README.md
├── USAGE.md
├── docs
├── poetry.toml
├── py.typed
├── pylintrc
├── pyproject.toml
├── scripts
├── src
└── tests
    ├── __init__.py
    ├── mockserver
    │   ├── Dockerfile
    │   ├── Makefile
    │   ├── README.md
    │   ├── go.mod
    │   ├── go.sum
    │   ├── internal
    │   ├── testdata
    │   └── main.go
    ├── test_client.py
    ├── test_destinations.py
    └── test_general.py
```

### 5. Run the mock server

Navigate to the mock server directory: 

   ```bash
   cd tests/mockserver
   ```

Start the mock server:

   ```bash
   go run .
   ```

You now have a fully operational mock server to simulate API responses and test your SDK without relying on the actual API.

For more information on running the mock server, read the generated `README.md` file in the `tests/mockserver` directory.

## Testing against the mock server

Let's look at how you can unit test your SDK against the mock server. 

The generated SDK includes test files that you can use to validate the behavior of your SDK.

<CodeWithTabs>

```shell !!tabs tests/
sdk
└── tests
    ├── __init__.py
    ├── mockserver
    ├── test_client.py
    ├── test_destinations.py
    └── test_general.py
```

```python !!tabs tests/test_destinations.py
import holiday_destinations
from holiday_destinations import HolidayDestinations
import os
from tests.test_client import create_test_http_client


def test_destinations_get_destinations_destinations_get():
    with HolidayDestinations(
        server_url=os.getenv("TEST_SERVER_URL", "http://localhost:18080"),
        client=create_test_http_client("get_destinations_destinations_get"),
    ) as holiday_destinations:
        assert holiday_destinations is not None

        res = holiday_destinations.destinations.get_destinations_destinations_get()
        assert res is not None
        assert res is not None
        assert res == [
            holiday_destinations.Destination(
                country="Indonesia",
                description="Beautiful beaches and vibrant culture.",
                name="Bali",
                rating=4.8,
            ),
            holiday_destinations.Destination(
                country="Indonesia",
                description="Beautiful beaches and vibrant culture.",
                name="Bali",
                rating=4.8,
            ),
        ]


def test_destinations_create_destination_destinations_post():
    with HolidayDestinations(
        server_url=os.getenv("TEST_SERVER_URL", "http://localhost:18080"),
        client=create_test_http_client("create_destination_destinations_post"),
    ) as holiday_destinations:
        assert holiday_destinations is not None

        res = holiday_destinations.destinations.create_destination_destinations_post(
            country="Indonesia",
            description="Beautiful beaches and vibrant culture.",
            name="Bali",
            rating=4.8,
        )
        assert res is not None
        assert res is not None
        assert res == holiday_destinations.Destination(
            country="Indonesia",
            description="Beautiful beaches and vibrant culture.",
            name="Bali",
            rating=4.8,
        )


def test_destinations_delete_destination_destinations_destination_id_delete():
    with HolidayDestinations(
        server_url=os.getenv("TEST_SERVER_URL", "http://localhost:18080"),
        client=create_test_http_client(
            "delete_destination_destinations__destination_id__delete"
        ),
    ) as holiday_destinations:
        assert holiday_destinations is not None

        holiday_destinations.destinations.delete_destination_destinations_destination_id_delete(
            destination_id=0
        )


def test_destinations_get_destination_by_id_destinations_destination_id_get():
    with HolidayDestinations(
        server_url=os.getenv("TEST_SERVER_URL", "http://localhost:18080"),
        client=create_test_http_client(
            "get_destination_by_id_destinations__destination_id__get"
        ),
    ) as holiday_destinations:
        assert holiday_destinations is not None

        res = holiday_destinations.destinations.get_destination_by_id_destinations_destination_id_get(
            destination_id=0
        )
        assert res is not None
        assert res is not None
        assert res == holiday_destinations.Destination(
            country="Indonesia",
            description="Beautiful beaches and vibrant culture.",
            name="Bali",
            rating=4.8,
        )


def test_destinations_update_destination_destinations_destination_id_put():
    with HolidayDestinations(
        server_url=os.getenv("TEST_SERVER_URL", "http://localhost:18080"),
        client=create_test_http_client(
            "update_destination_destinations__destination_id__put"
        ),
    ) as holiday_destinations:
        assert holiday_destinations is not None

        res = holiday_destinations.destinations.update_destination_destinations_destination_id_put(
            destination_id=1,
            country="Indonesia",
            description="Beautiful beaches and vibrant culture.",
            name="Bali",
            rating=4.8,
        )
        assert res is not None
        assert res is not None
        assert res == holiday_destinations.Destination(
            country="Indonesia",
            description="Beautiful beaches and vibrant culture.",
            name="Bali",
            rating=4.8,
        )
```

---

</CodeWithTabs>

To run the tests, you'll need to install `pytest` and a few other modules listed in the `pyproject.toml` of the generated SDK. 

Open a new terminal window and install the dependencies. It's best to install in a virtual environment.

```bash
pip install pytest httpx pydantic typing-inspect
```

Navigate to the `tests` directory in the SDK and run the tests:

```bash
pytest
```

The generated tests will be run against the mock server, validating that your SDK behaves as expected.

## Comparison with other mock server solutions

Several other mock server solutions are available, each with its own set of features and limitations.

- **[Prism](https://github.com/stoplightio/prism):** An open-source API mocking tool that uses OpenAPI documents to generate mock servers.
- **[MockServer](https://www.mock-server.com/):** A Java-based tool for mocking HTTP/HTTPS requests.
- **[Postman](https://www.postman.com/):** An API development platform that includes mocking capabilities.

The table below compares Speakeasy with these mock server solutions.

| Feature                 | **Speakeasy**                                                      | **Prism**                                             | **MockServer**                                  | **Postman**                                    |
|-------------------------|--------------------------------------------------------------------|-------------------------------------------------------|-------------------------------------------------|------------------------------------------------|
| **Primary use case**    | Automated SDK generation and management                            | API mocking and validation based on OpenAPI documents | HTTP/HTTPS request-response mocking and testing | API development, testing, and collaboration    |
| **SDK generation**      | ✅ Yes (automated SDK generation)                                   | ❌ No                                                  | ❌ No                                            | ❌ No                                           |
| **Test generation**     | ✅ Yes                                                              | ❌ No                                                  | ❌ No                                            | ✅ Yes (pre-saved tests)                        |
| **Supported languages** | 8+ languages, including Python, JavaScript, TypeScript, Java, and Go.                     | Language-agnostic                                     | Java only                                       | Language-agnostic                              |
| **Testing types**       | SDK testing, unit testing, contract testing                        | Contract testing, API prototyping                     | Integration, functional, and system testing     | Functional, integration, and regression testing            |
| **Mocking support**     | ✅ Yes, built-in for SDKs                                           | ✅ Yes (dynamic/static examples)                       | ✅ Yes (complex mocking with templates)          | ✅ Yes (mock servers with predefined responses) |
| **Request validation**  | ✅ Built-in for SDKs (validates requests against OpenAPI documents) | ✅ Yes                                                 | ✅ Yes                                           | ⚠️ Limited (manually set up via tests)          |
| **Response generation** | ✅ Handles SDK responses                                            | ✅ Static and dynamic responses                        | ✅ Templated responses                           | ⚠️ Static responses                            |
| **OpenAPI support**     | ✅ Yes, creates mock expectations based on your OpenAPI document    | ✅ Yes                                                 | ✅ Yes                                           | ⚠️ Partial (import/export specs)               |

## Why choose Speakeasy for test generation and mocking?

Speakeasy simplifies two key parts of your SDK development workflow: **test generation** and **mocking**. Here's how:

1. **Immediate test suite**  
   Speakeasy generates a suite of tests when you generate your SDK. Each test aligns with a specific API endpoint, so you can quickly validate both regular and edge-case scenarios without writing boilerplate code.

2. **Automatic mock server**  
   With one command, Speakeasy can start a mock server based on your OpenAPI document. You won't have to set up separate testing environments or craft mock responses by hand, making local testing easier.

3. **Isolated and repeatable testing**  
   Because tests run against a mock server, you aren't affected by network issues or external service downtime. The environment remains consistent, so test results are reliable and easy to reproduce.

4. **Comprehensive endpoint coverage**  
   When Speakeasy generates tests alongside a mock server, it covers every endpoint in your API document. This helps you catch issues early and maintain higher test coverage.

5. **Easy regeneration**  
   As your API changes, update your OpenAPI document. Speakeasy regenerates the mock server and tests, ensuring everything remains in sync with minimal effort on your part.

By handling **test generation** and **mocking**, Speakeasy frees you from having to constantly devise tests and maintain testing environments through your development cycle.

## Next steps

For a deeper dive into testing, take a look at our [guide to API contract test generation](/post/release-contract-testing), which covers automated testing and validating API contracts.


 This is the content for the doc blog/how-to-set-operationid.mdx 

 ---
title: "OpenAPI Tips - How to set operationId"
description: "Notes on how to correctly set OperationId in your OpenAPI spec."
keywords: [openapi, swagger, operationid, sdk generation, sdk]
image: "/media/openapi-tips-operationid.png"
date: 2022-10-04
authors:
  - name: Tristan Cartledge
  - image_url: "https://uploads-ssl.webflow.com/62ccd7b208cab0723d026273/635ff12733f46637e91ced22_1516859875198.jpg"
tags:
  - OpenAPI Tips
featured_image: "/media/openapi-tips-operationid.png"
---

import { Callout } from "~/components";

<Callout title="Announcing: OpenAPI Reference" variant="success">
Hi! These blog posts have been popular, so we've built an entire [OpenAPI Reference Guide](/openapi/) to answer any question you have.

It includes detailed information on [**operations**](/openapi/paths/operations).

Happy Spec Writing!

</Callout>

## Intro

The OpenAPI spec is best known for descriptions of RESTful APIs, but it’s designed to be capable of describing any HTTP API whether that be REST or something more akin to RPC based calls. That leads to the spec having a lot of flexibility baked-in; there's a lot of ways to achieve the exact same result that are equally valid in the eyes of the spec. Because of this, [the OpenAPI docs](https://spec.openapis.org/oas/v3.1.0#operation-object) are very ambiguous when it comes to telling you how you should define your API. That’s why we’d like to take the time to eliminate some of the most common ambiguities that you’ll confront when you build your OpenAPI spec. In this case we’ll be taking a look at **operationId.**

## Common OpenAPI Problem - OperationId

A common problem developers face is the handling of operationId (the name of a particular endpoint). The spec lists it as completely optional, but not including it will become a blocker when attempting to use your API Spec with tooling built to generate docs, SDKs, etc from your spec.

Now let’s take a look at the naming convention for operationId. The [official OpenAPI documentation](https://spec.openapis.org/oas/v3.1.0#operation-object) defines operationId as: “A unique string used to identify the operation. The id MUST be unique among all operations described in the API. The operationId value is case-sensitive. Tools and libraries MAY use the operationId to uniquely identify an operation, therefore, it is RECOMMENDED to follow common programming naming conventions.”

While the IDs are case-sensitive, there are a number of tools and programming languages that might be targeted that will require case-insensitivity, case-insensitivity can also help with the readability of your spec. So if you are planning on using your OpenAPI spec to generate downstream artifacts like docs, SDKs, Server stubs, etc, it might be worthwhile ensuring your IDs are named consistently, descriptively and uniquely enough.

## How to write OpenAPI Spec - OperationId

Our recommendation would be to **treat the operationId as a required field,** and **make each operationId unique** within the document **treating it as case insensitive**, while avoiding using anything other than alphanumerics and simple separators such as hyphens and underscores. Also be sure to avoid the potential of operationIds being non-unique when any separators are removed (which can happen with a number of tools as they convert your spec to code).

Treating operationIds this way gives you a number of advantages:

- Avoids name conflicts when generating things such as code for SDKs, server stubs etc
- Provides a simple way to refer to your various endpoints in your openapi spec, both for yourself and the consumers of your API.
- Provides additional consistency to your OpenAPI spec.

Here are some examples of good and bad operationIds:

```yaml
# GOOD
## The below examples are all unique within the document and are avoiding use of anything but simple separators:

operationId: "getPetByTag"
...
operationId: "add-pet"
...
operationId: "findpetsbystatus"
...
operationId: "update_pet_with_form"

# BAD
## The below examples are of operationIds that while different, are not unique within the document when treated case-insensitively and separators are removed (a common practice for code gen):

operationId: "getPetById"
...
operationId: "getpetbyid"
...
operationId: "get-pet-by-id"
## The below examples generally cause issues for a lot of tooling:

operationId: "getPet(ById)"
...
operationId: "$getPetById"
...
operationId: ""
...
operationId: "get pet by id"
...
operationId: "getPet byId"
```


 This is the content for the doc blog/how-we-built-cli/index.mdx 

 ---
title: "Why and How we invested in building a best in class CLI"
description: "CLI best practices, and how to use Charm to build a best in class CLI"
image: "/media/how-to-build-cli-charm.png"
date: 2024-02-14
authors:
  - name: Chase Crumbaugh
  - image_url: "/media/author-headshots/chase.jpeg"
tags:
  - Building Speakeasy
featured_image: "/media/how-to-build-cli-charm.png"
---

import quickstart_excerpt_url from "./assets/cli-quickstart-excerpt.mp4";
import quickstart_url from "./assets/cli-quickstart.mp4";
import validate_url from "./assets/cli-validate-table.mp4";

Like many startups, the original product we worked on isn’t the one that ended up getting product-market fit. One of the side effects of our pivot is that our users were navigating a UX that had been patched in order to support the new core use case (SDK Creation). Not ideal.

To address the situation, we spent the last month focused on building a **revamped CLI experience** to establish the foundation for a new standardized SDK creation and management workflow. This is the first step in creating a DX (Developer Experience) that will eventually unify the creation of API artifacts locally, in production, or via the web.

In this article we’ll walk through our motivation for doing a v2, what principles guided the development process, and how we used [Charm’s libraries](https://charm.sh/) to implement a best-in-class CLI. We hope that this can be both an inspiration and guide to other teams considering similar projects.

<div className="mt-10">
  <video controls={false} loop={true} autoPlay={true} width="100%">
    <source src={quickstart_url} type="video/mp4" />
  </video>
</div>

## Why did we rebuild our CLI?

The decision to focus the efforts of our onboarding rebuild on a new CLI was because of the nature of our product. Our product generates libraries, which are output as a set of files. We therefore wanted our DX to be as close to our user’s file management workflows as possible. The made focusing on CLI as the natural choice. Our focus on CLI isn’t a comment about the importance of traditional GUI-based UX. That too is an important part of DX, and one that we plan on tackling now that we’ve established a unified workflow.

Even if CLI isn’t quite as important as UI for your product, building your CLI first may still be a good idea. A CLI should be the core actions a user might take while using your product, with all the veneer stripped away. Building it is a forcing function to make sure you carefully consider and design the base set of commands, which you will later assemble into more complex workflows. It is a natural starting point.

As for the timing, the rebuild was triggered by two motivating forces:

1. **Need for new primitives**: As mentioned, we needed a fresh new workflow design that was both optimized for our core use case: artifact creation from an OpenAPI spec, and flexible enough to keep pace with the company’s aggressive vision for the future.
2. **New tooling enables new possibilities**: We became aware of [Charm.sh](https://charm.sh/) and their libraries to “make the command line glamorous.” in late 2023. The example apps on their website blew us away and had us playing with ideas we hadn’t thought previously possible. With such great tools available to us, there was no excuse for providing users with a mediocre CLI experience.

## What were our principles?

For anyone who is building a CLI, we strongly recommend that they first read through the [Command Line Interface Guidelines](https://clig.dev/). Don’t take it as gospel, but it’s an incredibly useful guide authored by some of the folks who built `docker compose`. The advice may seem at times obvious, but often the best advice is 🙂

- **Assume no prior context** - One of the consistently annoying things about CLIs is that they are often the functional equivalent of a set of magic incantations. Say it correctly, and you’re successful. Get it even a bit wrong, and no rabbit comes out of the hat. That means that before you can use a CLI functionally, you need to go and read through the instruction set and match it against your use case.

  Our goal is for anyone to be able to install our CLI, enter `speakeasy` and just by interacting with it, understand the full scope of what’s possible and how they should use it. No docs required.

- **Make it Conversational** - Maybe this will change, but at least for the time being, most CLI users are still human. And yet most CLIs don’t really cater to people. Most CLIs don’t provide any feedback when you’re using them and provide no information on common patterns you might want to follow. It’s a choose your own adventure.

  There’s no reason it has to be this way. Our goal is for the CLI to provide a guided experience, alongside the rawer primitives.

  - Include prompts as an alternative to flags for providing information.
  - Provide suggestions when an input is incorrect.
  - When an action is complete, we indicate the likely next action.

- **Keep it simple** - When presenting users with a CLI’s commands, there’s often a well-intentioned desire to exhaustively describe everything that’s possible. That typically backfires and what’s important gets lost.

  To combat bloat, we adhere to a few rules: - Avoid deep nesting of commands wherever possible. - Use sensible defaults rather than asking the user for information.

The sum total of these rules was the creation of a compact and easily grok-able CLI that someone could understand and use without having any previous understanding of Speakeasy.

Armed with our design philosophy we set out to build our CLI.

## Why and How Did we Use Charm?

It worth stating that we’re in no way being sponsored by [Charm](https://charm.sh/) to write this section of our blog post. But if anyone is looking to build a CLI, there is really no substitute for the tooling developed by the Charm team. We’re a Go shop, so there was no learning curve, but even if you’re not, it’s probably worth learning Go just so that you can build on top of their libraries.

The best analogy for explaining the value of Charm is that it’s like React for Terminal UI. It makes it possible to build beautiful user experiences at a fraction of the cost. To build our new CLI we made use of several of Charm’s libraries which we’ll walkthrough in more detail.

### Bubble Tea to build our foundation

In the React analogy, [Bubble Tea](https://github.com/charmbracelet/bubbletea) is the equivalent of the components framework. We used Bubble Tea as the framework for defining our Terminal application. Some of the more sophisticated aspect of the CLI were built as custom components. For example, our Validation table:

```go cliVisualizer.go
func (m cliVisualizer) Update(msg tea.Msg) (tea.Model, tea.Cmd) {
    switch msg := msg.(type) {
    case tea.KeyMsg:
        if msg.String() == "ctrl+c" || msg.String() == "esc" {
            m.status = StatusFailed
            return m, tea.Quit
        }
    case UpdateMsg:
        switch msg {
        case MsgUpdated:
            return m, listenForUpdates(m.updates) // wait for next event
        case MsgSucceeded:
            m.status = StatusSucceeded
            return m, tea.Quit
        case MsgFailed:
            m.status = StatusFailed
            return m, tea.Quit
        }
    }

    var cmd tea.Cmd
    m.spinner, cmd = m.spinner.Update(msg)
    return m, cmd
}
```

<div className="mt-10">
  <video controls={false} loop={true} autoPlay={true} width="100%">
    <source src={validate_url} type="video/mp4" />
  </video>
</div>

Bubble tea makes it possible to easily create delightful experiences that users don’t associate with the Terminal.

### Lip Gloss for custom styling

[Lip Gloss](https://github.com/charmbracelet/lipgloss) is the equivalent of custom CSS. The custom coloring, text formatting, and selection highlighting in our CLI is all being controlled by our Lip Gloss rules. In particular we make heavy use of Adaptive colors, which ensure that the CLI looks good no matter what our user’s terminal theme is.

Is it critical to the functioning of the CLI? No. But it’s those nice small touches that make the CLI into something that is recognizable as a Speakeasy experience:

```go styles.go
var (
    Margins = lipgloss.NewStyle().Margin(1, 2)

    HeavilyEmphasized = lipgloss.
                NewStyle().
                Foreground(Colors.Yellow).
                Bold(true)

    Emphasized = HeavilyEmphasized.Copy().Foreground(Colors.White)

    Info    = Emphasized.Copy().Foreground(Colors.Blue)
    Warning = Emphasized.Copy().Foreground(Colors.Yellow)
    Error   = Emphasized.Copy().Foreground(Colors.Red)

    Focused       = lipgloss.NewStyle().Foreground(Colors.Yellow)
    FocusedDimmed = Focused.Copy().Foreground(Colors.DimYellow)

    Dimmed       = lipgloss.NewStyle().Foreground(Colors.Grey)
    DimmedItalic = Dimmed.Copy().Italic(true)
    Help         = DimmedItalic.Copy()

    Success = Emphasized.Copy().Foreground(Colors.Green)

    Cursor = FocusedDimmed.Copy()
    None   = lipgloss.NewStyle()
```

### Using Huh to build Quickstart

[Huh](https://github.com/charmbracelet/huh) is Charm’s latest & greatest library (released December 2023). It is a form builder for terminals. Despite being so new, we jumped on the opportunity to use it. It was a perfect fit foundation for our `speakeasy quickstart` experience. If you agree that CLI experiences should resemble a conversation, then providing users with prompts to keep them moving through the workflow is critically important. We’ve built our quickstart command to wrap our other command primitives (`configure` & `run`) to give users a fully guided onboarding experience,

```go quickstart.go
// !focus(4[44:65],5,6)
func PromptForNewTarget(currentWorkflow *workflow.Workflow, targetName, targetType, outDir string) (string, *workflow.Target, error) {
	sourceName := getSourcesFromWorkflow(currentWorkflow)[0]
	prompts := getBaseTargetPrompts(currentWorkflow, &sourceName, &targetName, &targetType, &outDir, true)
	if _, err := tea.NewProgram(charm.NewForm(huh.NewForm(prompts),
		"Let's setup a new target for your workflow.",
		"A target is a set of workflow instructions and a gen.yaml config that defines what you would like to generate.")).
		Run(); err != nil {
		return "", nil, err
	}
	...
}
```

<div className="mt-10">
  <video controls={false} loop={true} autoPlay={true} width="100%">
    <source src={quickstart_excerpt_url} type="video/mp4" />
  </video>
</div>

### What’s Next

Rebooting our CLI was the first step of a complete overhaul to our onboarding workflow. We’re now working on two related projects to complete the end to end workflow. 1) Moving our [Github action](https://github.com/speakeasy-api/sdk-generation-action) to use the new CLI primitives, for a single source of truth. 2) Creating a sync with Github so that users can easily iterate on their production SDKs.

Have ideas on what we should build next? Have thoughts on the new CLI experience? We’d love to hear them, please feel free to [join our public slack](https://join.slack.com/t/speakeasy-dev/shared_invite/zt-1cwb3flxz-lS5SyZxAsF_3NOq5xc8Cjw) and let us know what you think.


 This is the content for the doc blog/how-we-built-universal-ts/index.mdx 

 ---
title: "How We Built It - Universal Typescript"
description: "The story about why we rebuilt our TypeScript generation, and the design choices we made along the way."
image: "/media/how-we-built-universal-ts.png"
date: 2024-01-20
authors:
  - name: Georges Haidar
  - image_url: '/media/author-headshots/georges.jpeg'
tags:
  - Building Speakeasy
featured_image: "/media/how-we-built-universal-ts.png"
is_featured: true
---

import { Callout } from '~/components';

<Callout title="Get Started" variant="success">
Try out our new TypeScript generation for yourself. Download our CLI to get started:

```bash
brew install speakeasy-api/homebrew-tap/speakeasy
```

</Callout>

In this blog post, we'll share the story behind why we decided to build v2 of our typescript generation. And talk through some of the critical design choices we made along the way. Whether you're a seasoned TypeScript developer or just starting out, we hope you'll find something valuable in this article.

## Learning from V1

Let's start by talking about the [open-source generators](https://openapi-generator.tech/docs/generators/); there are a lot of them (11 for TypeScript currently). It'd be fair to ask, why do we need another one, and why would someone pay for it.

None of the existing generators are good enough to build SDKs for an enterprise API offering (without a fair amount of custom work). We're very glad that the open-source generators exist. They're great for experimentation and hobby projects, but they fall short of serving enterprises (which, to be fair, was never the intent of the OSS project).

We rolled out the first version of our TypeScript generator exactly 1 year ago. Our goal was to build an SDK generator that could serve enterprise use cases. Our initial requirements were:

- Support for OpenAPI 3.0 & 3.1
- Idiomatic TypeScript code
- Runtime Type safety for both request and response payloads
- Support for Node LTS
- Support for retries & pagination
- CI/CD Automation for building & publishing

We satisfied all of these requirements, but weren't ourselves satisfied with the result. We hadn't built something that was really great. It was certainly better than the open-source offerings available, but we found ourselves frustrated with a few aspects of the generator:

1. Our approach to de/serialization had us in a straight jacket. We had decided to use classes with decorators. This approach had several limitations and made it difficult to maintain and extend our codebase. Specifically, it impeded our ability to build support for Union types. We needed a more flexible solution that would allow us to better support the evolving needs of our users without sacrificing runtime type safety.

```typescript title="OldPet.ts"
export class Pet extends SpeakeasyBase {
    @SpeakeasyMetadata({ data: "form, name=category;json=true" })
    @Expose({ name: "category" })
    @Type(() => Category)
    category?: Category;

    @SpeakeasyMetadata({ data: "form, name=id" })
    @Expose({ name: "id" })
    id?: number;

    @SpeakeasyMetadata({ data: "form, name=name" })
    @Expose({ name: "name" })
    name: string;

    @SpeakeasyMetadata({ data: "form, name=photoUrls" })
    @Expose({ name: "photoUrls" })
    photoUrls: string[];

    /**
     * pet status in the store
     */
    @SpeakeasyMetadata({ data: "form, name=status" })
    @Expose({ name: "status" })
    status?: PetStatus;

    @SpeakeasyMetadata({ data: "form, name=tags;json=true", elemType: Tag })
    @Expose({ name: "tags" })
    @Type(() => Tag)
    tags?: Tag[];
}
```

2. Our SDK generation was overly focused on server-side usage. Understandable, because this was the majority of our usage. But more and more JavaScript applications are being built where the line between server responsibility and client responsibility are blurred. In these applications, both rely on a common set of libraries. We wanted to cover this use case.

3. Finally, the rise of AI APIs in the last year had created new and growing demand for TypeScript SDKs that could better handle long running data streams.

So three months ago, we embarked on the journey of building a new TypeScript generator to overcome these deficiencies.

## How we designed our new generator

A theme that we're going to keep coming back to is, "Use the platform". We're building a TypeScript generator, so we use TypeScript primitives wherever possible. We're building a generator for OpenAPI, so we use OpenAPI primitives wherever possible.

Seems straightforward, but sometimes it's easy to get caught up in the excitement of building something new and forget to take advantage of the tools that are already available to us.

### Rebuilding Type Safety with Zod

Validation is really important when you talk about APIs. By making your API’s inputs explicit, developers can debug in their IDE as they write the application code, sparing them the frustration of having to compare constructed data object to API docs to see where mistakes occurred. This is even more important in the world of JavaScript, where users will pass you anything, and your types don't exist at runtime.

As we mentioned, our first attempt worked at plugging the hole of runtime type safety, but it had downsides. Adding support for more complex types was overly difficult.

In our second attempt, we turned to Zod: "A TypeScript-first schema validation library that allows you to define schemas from a simple `string` to a complex nested object."

Our TypeScript generator creates Zod schemas for all the request and response objects in a users OpenAPI spec:

```typescript title="product.ts"
export namespace ProductInput$ {
    export type Inbound = {
        name: string;
        price: number;
    };

    export const inboundSchema: z.ZodType<ProductInput, z.ZodTypeDef, Inbound> = z
        .object({
            name: z.string(),
            price: z.number().int(),
        })
        .transform((v) => {
            return {
                name: v.name,
                price: v.price,
            };
        });

    export type Outbound = {
        name: string;
        price: number;
    };

    export const outboundSchema: z.ZodType<Outbound, z.ZodTypeDef, ProductInput> = z
        .object({
            name: z.string(),
            price: z.number().int(),
        })
        .transform((v) => {
            return {
                name: v.name,
                price: v.price,
            };
        });
}
```

We then use these schemas to validate the request and response payloads at runtime:

```typescript title="zodExample.ts"
import { SDK } from "@speakeasy/super-sdk";

async function run() {
  const sdk = new SDK();

  const result = await sdk.products.create({
    name: "Fancy pants",
    price: "ummm"
  });
}

run();

// 🚨 Throws
//
// ZodError: [
//   {
//     "code": "invalid_type",
//     "expected": "number",
//     "received": "string",
//     "path": [
//       "price"
//     ],
//     "message": "Expected number, received string"
//   }
// ]

```

Our validation also goes beyond user input, by validating the server's responses. We will guarantee that what your API is providing to users is correct, as per your spec. And if it's not, we fail loudly. There's no hidden errors for users to parse through.

#### Validation Tradeoffs

It's worth acknowledging that there are tradeoffs to using Zod. The biggest one is having a 3rd party dependency in the library. We've tried hard to keep our generated libraries free of them because of the security risks they pose. However, validation is a critical feature, and Zod doesn't pull in any additional dependencies, so we felt it was well worth it.

Additionally, we've encountered a couple of truly enormous OpenAPI specs that have resulted in huge SDKs. These can suffer some performance regressions from having to type-check all the way through. It's an edge case, and one that we're working on some heuristics to mitigate, but it's worth noting.

### Going TypeScript Native for Client Support

Most SDKs you encounter will live in repos like `acme-sdk-node` or `acme-sdk-front-end`, but these qualifiers don't need to exist anymore. The primitives needed to run a feature-rich Typescript SDK across all the major runtimes are available. And that what we set out to build

The biggest changes that we needed to make were dropping our dependency on Axios and moving to the native `fetch` API. We now have a single codebase that can be used in any environment, including Node.js, browsers, and serverless functions.

Other changes we needed to make to better support client-side usage were:

- Enabling tree-shaking - we decoupled the SDKs' modules wherever possible. If SDKs are subdivided into namespaces, such as `sdk.comments.create(...)`, it's now possible to import the exact namespaces, or "sub-SDKs" as we call them, and tree-shake the rest of the SDK away at build time.

#### Universality Tradeoffs

If you set out to build an SDK per runtime, like an SDK for node, an SDK for bun, you will be able to leverage more native APIs that in some instances could perform better than the primitive APIs we use. For example, Node's [stream library](https://nodejs.org/api/stream.html) is a little bit more performant than the web streams one, but we think the trade off that we made is valuable in the long run and better at enterprise scale.

It's cognitively simpler to distribute and talk about one SDK. It allows you to manage one set of documentation, and maintain one education path for users. That's invaluable to an org operating at scale.

### Adding Support for Data Streams

The last major feature we wanted to add was support for data streams. When we talk about data streams, we're talking about support for two different things, both of which are important for AI APIs. The first is traditional file uploads and downloads. Previously, we had supported this where the entire file was loaded into memory before being sent to the server. This is fine for small files, but isn't workable for large ones.

We shifted our file support to use the `Blob()` and `File()` APIs, so that files could be sent to/from APIs via a data stream. We base that on whether your OpenAPI spec marks a certain field as binary data. If it does we'll automatically generate a type for that field such that your users can pass a blob-like object or an entire byte array to upload. On the response side, if we know that the response is binary data, then users will be given a readable stream to consume.

Finally, there's another type of streaming that we've built support for: server-sent events (SSEs). SSEs have gained popularity recently as a way to stream data from the server to the client. They're a great fit for AI APIs, where you might be streaming the results of a long running job. 

We've built a straightforward implementation that doesn't require any proprietary extensions in your OpenAPI spec. Just mark the response as a `text/event-stream` and we'll automatically generate a type for it. We'll also generate a `stream` option on the request object that will return an async iterable that you can use to consume the stream:

```typescript title="sse.ts"
import { SDK } from "@speakeasy/super-sdk";

async function run() {
  const sdk = new SDK();

  const result = await sdk.chat({
    stream: true,
    messages: [{
      role: "user",
      text: "Tell me three interesting facts about Norwegian Forest cats."
    }]
  });

  if (!result.chatStream) { throw new Error("expected completion stream"); }

  for await (const event of result.chatStream) {
    process.stdout.write(event.data.content);
  }
  // 👆 gradually prints the chat response to the terminal
}

run();
```

## Summary

So that's it. We're really proud of the new TypeScript generator that we've built. We think it's better than any other TypeScript generation that's out there, and is on par with even the best hand-written SDKs. We're interested in hearing people's feedback, so please give it a go yourself. Join [our public slack](https://join.slack.com/t/speakeasy-dev/shared_invite/zt-1cwb3flxz-lS5SyZxAsF_3NOq5xc8Cjw) and let us know what you think!


 This is the content for the doc blog/index.mdx 

 ---
title: "Blog"
description: "Speakeasy blog"
---

import { Blog } from '~/features/blog/home';

<Blog />


 This is the content for the doc blog/internal-sdks/index.mdx 

 ---
title: "Building SDKs for internal APIs: How to Boost developer velocity"
description: "How internal SDKs can improve developer velocity, boost overall business growth, and improve developer satisfaction."
keywords: [api, devex]
image: "/media/internal-sdks.png"
date: 2023-11-23
authors:
  - name: Nolan Sullivan
  - image_url: "/media/author-headshots/nolan.jpeg"
tags:
  - API Advice
featured_image: "/media/internal-sdks.png"
---

import { Testimonial } from "~/components";

People often think about SDKs in the context of libraries that make it easier for **external** users to integrate with an API. But SDKs are just as as valuable to internal developers working with internal APIs.

In fact, internal APIs are where SDKs can provide the most business value:

- **Most APIs are internal**:
  In its [2023 state of the API](https://www.postman.com/state-of-api/a-day-week-or-year-in-the-life/#a-day-week-or-year-in-the-life) report,
  Postman found that 61% of APIs are for private use only.
- **Internal APIs are heavily used**:
  An external API probably has a single point of integration whereas an internal API is likely reused across a suite of applications in their frontend, backend, and middleware.
  
Because of this, building SDKs for internal APIs can be transformational:

- **Increased velocity** - SDKs can reduce the time to integrate with an API by 50% or more. That means more time for innovation and less time on boilerplate.
- **Improved API Governance** - SDKs can be a powerful tool for API governance, helping teams work autonomously while maintaining a consistent interface across the organization.
- **Better staff retention** - Faster velocity, and less reptition leads to happier and more productive developers, which leads to better staff retention.

## Developer velocity drives business growth

For orgs with an API-first approach, ease of integration with internal APIs is critical for business success. SDKs enable this through:

- **Eliminates integration boilerplate** - Eliminates the tedious, repititve integration work that needs to be done before integrating with a service.
- **Reduces errors** - SDKs mean there's less opprotunity to shoot yourself in the foot. The SDK will handle areas where people will frequently make mistakes, like authentication, error handling, and serialization.
- **Speeds up debugging** - SDK wll shrink the surface area of the integration, so when issues do occur, there's less code to dig through.

![simple, non-scientific diagram showing how internal SDKs create an inflection point in dev-velocity and growth](./assets/diagram-business-velocity-after-speakeasy.png)

With SDKs handling so much of the integration work, developers can focus on innovating where it matters, the business logic of their application. And the more teams using your internal SDKs, the faster the gains in velocity compound.

## Greater independence with consistent interfaces

Organizations fail when they create lengthy review processes to enforce consistency across development teams. They inevitably kill innovation without solving the consistency challenge. The better strategy is to hand developers tools that speed up their work, and have the side effect of ensuring consistency.

Derived from a common API contract, SDKs can be a usual tool to make sure that API consumption practices are consistent acorss the organization. This is a major compenent of a successufl API governance program.  Kin Lane [defines API governance](https://apievangelist.com/2021/11/13/some-thoughts-on-api-governance) as:

<Testimonial
  avatar="/media/quote-headshots/kin-lane.jpeg"
  quoted="Kin Lane, The API Evangelist"
>
  “Ensuring that the complex systems powering the enterprise are as defined, discoverable, and observable as possible so that you can understand the state of the system, and then incrementally evolve the state of the system as a whole, in the right direction.”
</Testimonial>

oAs a codebase grows, governance becomes increasingly important.
Good SDKs make it easier for teams to make good design choices and harder to make bad ones.

## Happy Developers, Happy Business

[A study by McKinsey](https://www.mckinsey.com/industries/technology-media-and-telecommunications/our-insights/developer-velocity-how-software-excellence-fuels-business-performance) found that high developer velocity correlates strongly with many indicators of business health, including talent retention.

The study concluded that a major driver of velocity comes from the quality of internal tooling:

<Testimonial
  avatar="/media/quote-headshots/shivam-srivastava.jpeg"
  quoted="Shivam Srivastava, MicKinsey"
>
  “The ability to access relevant tools for each stage of the software life cycle contributes to developer satisfaction and retention rates that are 47 percent higher for top-quartile companies compared with bottom-quartile performers.”
</Testimonial>

The previous sections have explained how SDKs can bring a level of reusability and consistency to API usage.

To understand the impact of that reusability on developers' quality of life, consider a common pattern that manifests at organizations where it's missing:

1. Every team writes bespoke code. No one shares resources. When someone tries to share, they soon find that no one else uses or even recognizes their attempt.
2. The first time two teams discover they have independently done the same thing, it's amusing. Then, this becomes a running joke. But beneath the humor is mounting frustration.
3. Inevitably, people start to feel that their work is unimportant, meaningless. Data inconsistencies pile on top of fragile designs;
the codebase begins to feel brittle and perilous; workers feel less and less incentive to innovate; dreams of standardization becomes more and more remote as disarray spreads.
4. All productive engineers are looking for a new job.

An SDK cannot save an organization from chaos, but it can heavily contribute to consistency and well-being.

## SDKs are a win-win

- Effective organizations encourage teams to work autonomously and discover their own solutions.
- Effective organizations benefit from standardized codebases and design patterns.

A good SDK program can ease the tension between these apparently contradictory statements.
The standardized interface and pre-built libraries help teams work faster, work autonomously, and develop quickly without "going rogue".
This harmony promotes both bottom-up creativity and top-down governance.

## OK, but making an SDK is hard work

One fact may undermine my whole argument: good SDKs are hard to build and maintain.
This is true even with a stable API and a single development language.
For fast-moving, polyglottal teams, the maintenance complexity explodes.

What if there were a tool to generate quality SDKs automatically, in multiple languages, using taut, idiomatic code, and avoiding heaps of boilerplate?

Grab an OpenAPI spec and [try Speakeasy yourself](https://app.speakeasy.com/).


 This is the content for the doc blog/introducing-speakeasy/index.mdx 

 ---
title: "Speakeasy's $11M Raise"
description: "Speakeasy is today announcing that it has raised $11M in combined seed, pre-seed funding from backers including Crystal Huang at Google Ventures, Astasia Myers at Quiet Capital, Flex Capital, StoryHouse Ventures, Firestreak Ventures, and angels including Amit Agarwal (President at Datadog), Clint Sharp (Co-founder and CEO of Cribl) and Todd Berman (CTO of Attentive), and more."
image: "/media/introducing-speakeasy.png"
date: 2023-06-29
authors:
  - name: Sagar Batchu
  - image_url: 'https://uploads-ssl.webflow.com/62ccd7b208cab0723d026273/62cdf303b28bf9598d7a6b63_sagar_headshot-p-500.jpeg'
tags:
  - Building Speakeasy
featured_image: "/media/introducing-speakeasy.png"
is_featured: true
---

import { Callout } from '~/components'

# Speakeasy's $11M Raise

4000 SDKs, 100's of Github repos, 9 team members, and 8 languages later...

Today, we’re excited to [officially announce Speakeasy to the world](https://techcrunch.com/2023/06/29/speakeasy-is-using-ai-to-automate-api-creation-and-distribution/), with $11 million in combined pre-seed & seed funding from backers including: [Crystal Huang](https://twitter.com/CrystalHuang) at [Google Ventures](https://www.gv.com/), [Astasia Myers](https://twitter.com/AstasiaMyers) at [Quiet Capital](https://quiet.com/), [Flex Capital](https://www.flexcapital.com/), [StoryHouse Ventures](https://www.storyhousevc.com/), [Firestreak Ventures](https://www.firestreak.com/), and angels including Amit Agarwal (President of Datadog), Clint Sharp (co-founder and CEO of Cribl) and Todd Berman (CTO of Attentive).

To show off all the exciting features we’ve built this year, we’ll be hosting a Feature Week, July 10th-14th. Every day, we’ll be posting short deep-dives on what we’re busy building here at Speakeasy. [Sign up for our newsletter](/post#subscribe) and we’ll send you a reminder!

## Why are we building Speakeasy?

There is one thing we can all agree on: APIs are ubiquitous and critical to building modern software. In a single line of code, you are able to harness the collective efforts of a thousand developers. It's not much of an exaggeration to say that APIs give engineering teams superpowers.

Yet shifting access patterns and heightened user expectations mean it has never been harder to build a "great" API. Providing the tools necessary for users to easily integrate requires navigating a world of API marketplaces, plugin ecosystems, chat interfaces, a dozen language communities, and more. We’re a long way from the days of the humble `curl`. Of course, everyone wants their API to have a great developer experience and be natively accessible in any environment & runtime, but very few are able to commit the huge platform engineering investments required to solve this "final mile" problem. Those who do - such as Stripe, Plaid, Twilio, Github — reap fantastic rewards.

Most API teams however are left in the lurch. Between managing new versions, duct taping schemas, and keeping documentation from going stale, their hands are already full. That often places the “final mile” of integration on the shoulders of the user. Their only tools: an API reference page, their own determination, and a high threshold for frustration.

As a result, APIs — whether for internal or external users — end up under-used and under-resourced. Neither builder nor user is happy. And yet what's the alternative? Building all the tooling to offer that ideal API DevEx in-house would leave API teams with tons of tech debt that isn't related to their core product.

That's why Speakeasy has showed up, with a product, a pipeline, and a team of people to solve this problem once and for all.

<Callout title="What We're About" variant="info">
**📣 Speakeasy’s mission is to make it easy to create and consume any API.**
</Callout>

## What We Do

Speakeasy provides production-quality developer surfaces for your API that delight users and make integration easy. Today, that means <b>managed native-language SDKs and Terraform providers</b>.

Speakeasy SDKs enable your API users, whether external customers or internal teams, to integrate rapidly. We provide a far more intuitive and developer-friendly (even, dare we say, enjoyable?) experience than is possible with the status quo “API reference + sheer determination” approach today.

Speakeasy managed SDKs will equip your API users with compilable usage snippets for every function, context-aware in-IDE code completion, and type safety. Users are spared from writing error-prone boilerplate code, dramatically reducing frustration and the number of support tickets.

Ultimately, API builders save huge amounts of time and cost, while user adoption is maximized thanks to a world-class API developer experience.

Here’s what a couple of our customers have to say:

> “The engineering team is consistently focused on developing Codat’s core infrastructure, and we’re always figuring out the most efficient way to advance our developer experience. Finding Speakeasy has been transformational in terms of our team’s velocity. We’ve been able to progress our roadmap faster than we thought possible. We already have SDKs for 3 languages in production. If we’d been on our own, we’d probably be getting ready to publish the first one now.”
>

[David Coplowe, Codat DevEx Team](/post/case-study-codat)

> “Speakeasy's unique offering of high-quality SDKs including a Terraform provider, all generated from our existing API specs allowed us to take a huge leap in our own product go-to-market. We don't need to invest in hiring teams of specialist engineers — allowing us to focus on our core product.”
>

[Viljami Kuosmanen, Head of Engineering, epilot](/post/case-study-epilot)

## How does it work?

Today, given an API, we:

- Automatically maintain your API specs through AI-powered suggestions and telemetry-based drift detection
- Create idiomatic, type safe, production-quality SDKs in 8 languages and counting: Python, Java, Typescript, Go, Ruby, PHP, Swift, C# — and even new API ecosystems like Terraform Providers. We create and maintain these in polished Github repos.
- Customise and brand your SDKs with a batteries-included experience like retries, pagination and auth. You can steer our code generation engine with extensions and simple config.
- Generate docs for your SDK. Making it incredibly simple for API consumers to pick up and use in minutes. 1 copy paste to a working integration
- Publish SDKs to package managers (npm, PyPI, etc.). No more signign into your sonatype account.
- Watch for updates to your API spec, and re-run the entire workflow automatically so your SDKs are always up-to-date
- Manage the rollout of your SDKs, client authentication with gateways and self service telemetry in just a few clicks

![Speakeasy manages the entire workflow of SDK and Terraform provider creation: from spec validation/enrichment, through code creation, and package publishing](./assets/speakeasy-diagram.png)

Speakeasy manages the entire workflow of SDK and Terraform provider creation: from spec validation/enrichment, through code creation, and package publishing

## Why We’re Different

Prior to Speakeasy, the most prevalent options for creating SDKs were:

1. Creating SDKs manually
2. Using open-source generators (yes, the one with >3K issues)

Neither of these are great options for most companies. Manually creating SDKs requires costly eng teams to be hired and maintained, and dilutes focus from other core development priorities. Open-source generators are great for hobbyists — but lack the comprehensive commercial support, idiomatic code output, and broad OpenAPI compatibility needed for enterprises. If using the OSS generators, teams ultimately still need to invest a significant amount of eng time in order to support production use cases.

**Speakeasy offers a compelling alternative**

- SDKs that are fully-managed and supported by our responsive team, providing you with all the benefits of an [API platform](/post/why-an-api-platform-is-important/) team at a fraction of the cost.
- A comprehensive pipeline for generating SDKs, Terraform providers, and other developer surfaces: CLIs, Zapier plugins, natural language agents and more.
- Integrates seamlessly with your API development. We integrate directly with GitHub, GitLab, and other CI/CD platforms ensuring SDKs are updated on every release.
- Code generation built from the ground up, with a focus on creating customisable, idiomatic, fault tolerant and type safe SDKs. You can see the results for yourself:

  - [Speakeasy’s Python SDKs vs. OpenAPI Generator](/docs/languages/python/oss-comparison-python)
  - [Speakeasy’s Typescript SDKs vs. OpenAPI Generator](/docs/languages/typescript/oss-comparison-ts)
  - [Speakeasy’s Go SDKs vs. OpenAPI Generator](/docs/languages/golang/oss-comparison-go)`

## Who Do We Work With?

You, we hope!

Our product has been battle-tested across 4000 SDKs, and by great product and engineering teams like Shippo, [Airbyte](/post/case-study-airbyte), [Codat](/post/case-study-codat) and more.

## What’s next?

We’re excited to continue helping builders build, by making APIs incredibly easy to create and consume. What’s coming up next?

- Adding more code generation targets - languages, clients, runtimes, ecosystems, novel targets
- Providing plug and play infrastructure to provide deep insights into API changes and usage
- Going upstream and integrating into your favorite server side frameworks to remove the need for API specs and cumbersome documentation workflows

## Want to try Speakeasy?

Sign up today at [https://www.speakeasy.com/](https://www.speakeasyapi.dev)! Bring your API spec if you have one - we like those :)

## Talk to us!

- Follow us on [Twitter](https://twitter.com/speakeasydev) and [LinkedIn](https://www.linkedin.com/company/speakeasyapi/)
- Come chat with us on [Slack](https://join.slack.com/t/speakeasy-dev/shared_invite/zt-1cwb3flxz-lS5SyZxAsF_3NOq5xc8Cjw)
- [Check out our open roles](https://jobs.ashbyhq.com/Speakeasy), we’re hiring amazing engineers and a developer focused UX designer.

## Last but not least

We'll leave you with a carefully crafted poem. Well not so crafted... thanks ChatGPT! Prompt engineering credit goes to our newest team member, Sterling:

> In search of clear instructions,
We turn to the API's functions.
But to use them without confusion,
We need SDK documentation.

> Yet sometimes it's hard to follow,
The API's lingo can be hollow.
We need a way to make it clear,
To rewrite it in a language we hold dear.

> With OpenGPT-3.5 at our side,
We can translate and simplify with pride.
The developer's task is now made light,
With SDK documentation in their sight.

> So let us embrace this new tool,
And make our SDKs easy to use.
From API to SDK, it's a breeze,
With OpenGPT-3.5, we achieve with ease.


 This is the content for the doc blog/introducing-universal-ts/index.mdx 

 ---
title: "Introducing Universal TypeScript: A TS SDK your users will love"
description: "Our new TypeScript generation is the best SDK for the biggest language community."
image: "/media/introducing-universal-ts.png"
date: 2023-12-01
authors:
  - name: Georges Haidar
  - image_url: '/media/author-headshots/georges.jpeg'
tags:
  - Product Updates
featured_image: "/media/introducing-universal-ts.png"
---

import { Callout } from '~/components';

## The best SDKs for the biggest language community

Today, we're introducing our updated TypeScript code generation target that will power the next wave of TypeScript SDKs built on top of OpenAPI. Our new code generator takes full advantage of TypeScript's type system, native Fetch APIs and the amazing data validation and transformation library [Zod](https://zod.dev/) to deliver feature rich SDKs that run anywhere modern JavaScript can run.

There's a lot to unpack so, before going any further, here are the headline features that come with TypeScript SDKs generated using Speakeasy:

- Compatibility with the browser & server
- Support for popular JavaScript runtimes including Node.js, Bun, Deno, React Native
- User input and server response validation with Zod
- Support for polymorphic types, also known as unions or `oneOf` in OpenAPI.
- Support for multipart streaming upload

To get started, all you need is an OpenAPI spec. Simply install the speakeasy CLI, and start generating:

```bash
brew install speakeasy-api/homebrew-tap/speakeasy
```

```bash
speakeasy generate sdk -s openapi.yaml --output ./sdk -l typescript
```

<Callout title="Breaking changes" variant="info">
If you are currently using Speakeasy for TypeScript generation, we've listed the breaking changes in the later sections of this post as well as instructions on using the new generator.
</Callout>

## New features

### Works in the browser, Node.js and other modern JS runtimes

One key decision we took when designing for new TypeScript SDKs was to stick as close to modern and ubiquitous web standards as possible. This included switching from Axios to the Fetch API as our HTTP client. This API includes all the necessary building blocks to make HTTP requests: `fetch`, `Request`, `Response`, `Headers`, `FormData`, `File` and `Blob`. Previously, SDKs leaked some of the Axios API and it meant that users needed to be aware of it which was undesirable. Making this move also ensures that your SDKs will work seamlessly on both the server & browser. We also observed frameworks like `Next.js` which specifically augment the fetch API to enable caching of HTTP responses within React Server Components. That is now unlocked with new SDKs.

In addition to browser compatibility, the standard nature of this SDK means it will work in modern JavaScript runtimes. This includes: Node.js, Deno, Bun, React Native. We’ve already been able to run our extensive suite to confirm that new SDKs work in Node.js, Bun and browsers. We’re working to expand our automated testing to cover Deno and React Native.

Wherever and however your users are building, they will be able to use your SDK.

### Tree-shaking-ly good

Our new SDKs contain fewer internal couplings between modules. This means users that are bundling them into client-side apps can take advantage of better tree-shaking performance when working with "deep" SDKs. These are SDKs that are subdivided into namespaces such as `sdk.comments.create(...)` and `sdk.posts.get(...)`. Importing the top-level SDK will pull in the entire SDK into a client-side bundle even if a small subset of functionality was needed. It's now possible to import the exact namespaces, or "sub-SDKs" as we call them, and tree-shake the rest of the SDK away at build time.

```typescript
import { PaymentsSDK } from "@speakeasy/super-sdk/sdk/payments";
// 👆 Only code needed by this SDK is pulled in by bundlers

async function run() {
	const payments = new PaymentsSDK({ authKey: "" });

  const result = await payments.list();

  console.log(result);
}

run();
```

We also benchmarked whether there would be benefits in allowing users to import individual SDK operations but from our testing it seems that this only yielded marginal reduction in bundled code versus importing sub-SDKs. It's highly dependent on how operations are grouped and the depth and breadth of an SDK as defined in the OpenAPI spec. If you think your SDK users could greatly benefit from exporting individual operations then please reach out to us and we can re-evaluate this feature.

### Support for server-sent events

We're really excited to share that TypeScript SDKs now support streaming events from your API using [server-sent events][sse] (SSE). SSE is a feature of the web that has been around for quite some time and has seen renewed popularity in the AI space. It's the technology that's powering some of your favourite AI / LLM chat-based user interfaces.

Here's an example of working with a chat completion stream in Node.js:

```typescript
import { SDK } from "@speakeasy/super-sdk";

async function run() {
  const sdk = new SDK();

  const result = await sdk.chat({
    stream: true,
    messages: [{
      role: "user",
      text: "Tell me three interesting facts about Norwegian Forest cats."
    }]
  });

  if (!result.chatStream) { throw new Error("expected completion stream"); }

  for await (const event of result.chatStream) {
    process.stdout.write(event.data.content);
  }
  // 👆 gradually prints the chat response to the terminal
}

run();
```

We wanted to make sure the experience is ergonomic and found that exposing an [async iterable][mdn-for-await-of] which can be looped over was our favourite solution. This will work the same way in the browser and other JavaScript runtimes!

One of the challenges, we've had to tackle when working on this feature was figuring out how to model these APIs within OpenAPI and we're proud to share that we've developed a proposed specification that is free from propietary extensions. It's vanilla OpenAPI and you can start describing your SSE endpoints with it today then generate SDKs with Speakeasy. As more and more chat-based products emerge, we want to ensure that the APIs and SDKs powering them are free from unnecessary vendor lock-in and instead move towards a common approach to describing them.

[mdn-for-await-of]: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/for-await...of
[sse]: https://html.spec.whatwg.org/multipage/server-sent-events.html

### Runtime validation powered by [Zod](https://zod.dev/)

TypeScript provides static type safety to give you greater confidence in the code your shipping. However, TypeScript has limited support to protect from opaque data at the boundaries of your programs. User input and server data coming across the network can circumvent static typing if not correctly modelled. This usually means marking this data as `unknown` and exhaustively sanitizing it.

Our new TypeScript SDKs solve this issue neatly by modelling all the data at the boundaries using Zod schemas. That ensures that everything coming from users and servers will work as intended, or fail loudly with clear validation errors. This is even more impactful for the vanilla JavaScript developers using your SDK.

```typescript
import { SDK } from "@speakeasy/super-sdk";

async function run() {
  const sdk = new SDK();

  const result = await sdk.products.create({
    name: "Fancy pants",
    price: "ummm"
  });
}

run();

// 🚨 Throws
//
// ZodError: [
//   {
//     "code": "invalid_type",
//     "expected": "number",
//     "received": "string",
//     "path": [
//       "price"
//     ],
//     "message": "Expected number, received string"
//   }
// ]
```

While validating user input is considered table stakes for SDKs, it’s especially useful to validate server data given the information we have in your OpenAPI spec. This can help detect drift between schema and server and prevent certain runtime issues such as missing response fields or sending incorrect data types.

### Unions are here

Support for polymorphic types is critical to most production applications. In OpenAPI, these types are defined using the `oneOf` keyword. We represent these using TypeScript's union notation `Cat | Dog`. We want to give a big shout out to Zod for helping us deliver this feature!

```typescript
import { SDK } from "@speakeasy/super-sdk";

async function run() {
  const sdk = new SDK();
  const pet = await sdk.fetchMyPet();

  switch (pet.type) {
    case "cat":
      console.log(pet.litterType);
      break;
    case "dog":
      console.log(pet.favoriteToy);
      break;
    default:
      // Ensures exhaustive switch statements in TypeScript
      pet satisfies never;
      throw new Error(`Unidentified pet type: ${pet.type}`)
  }
}

run();
```

### Support for data streaming

Support for streaming is critical for applications that need to send or receive large amounts of data between client and server without first buffering the data into memory, potentially exhausting this system resource. Uploading a very large file is one use case where streaming can be useful.

As an example, in Node.js v20, streaming a large file to a server using an SDK is only a handful of lines:

```typescript
import { openAsBlob } from "node:fs";

import { SDK } from "@speakeasy/super-sdk";

async function run() {
  const sdk = new SDK();

  const fileHandle = await openAsBlob("./src/sample.txt");

  const result = await sdk.upload({ file: fileHandle });

  console.log(result);
}

run();
```

On the browser, users would typically select files using `<input type="file">` and the SDK call is identical to the sample code above.

Other JavaScript runtimes may have similar native APIs to obtain a web-standards [File](https://developer.mozilla.org/en-US/docs/Web/API/File) or [Blob](https://developer.mozilla.org/en-US/docs/Web/API/Blob) and pass it to SDKs.

For response streaming, SDKs expose a [ReadableStream](https://developer.mozilla.org/en-US/docs/Web/API/ReadableStream), a part of the [Streams API](https://developer.mozilla.org/en-US/docs/Web/API/Streams_API) web standard.

```typescript
import fs from "node:fs";
import { Writable } from "node:stream";
import { SDK } from "@speakeasy/super-sdk";

async function run() {
  const sdk = new SDK();

  const result = await sdk.usageReports.download("UR123");
  
  const destination = Writable.toWeb(
    fs.createWriteStream("./report.csv")
  );
  
  await result.data.pipeTo(destination);
}

run();
```

### Support for arbitrary-precision decimals powered by [decimal.js](https://github.com/MikeMcl/decimal.js)

Using decimal types is crucial in certain applications such as code manipulating monetary amounts and in situations where overflow, underflow, or truncation caused by precision loss can lead to significant incidents.

To describe a decimal type in OpenAPI, you can use the `format: decimal` keyword. The SDK will take care of serializing and deserializing decimal values under the hood.

```typescript
import { SDK } from "@speakeasy/super-sdk";
import { Decimal } from "@speakeasy/super-sdk/types";

const sdk = new SDK();
const result = await sdk.payments.create({
  amount: new Decimal(0.1).add(new Decimal(0.2))
});
```

### Support for big integers using the native `BigInt` type

Similar to decimal types, there are numbers too large to be represented using JavaScript’s `Number` type. For this reason, we’ve introduced support for `BigInt` values.

In an OpenAPI schema, fields that are big integers can be modelled as strings with `format: bigint`.

```typescript
import { SDK } from "@speakeasy/super-sdk";

const sdk = new SDK();
const result = await sdk.doTheThing({
  value: 67_818_454n,
  value: BigInt("340656901")
});
```

## Breaking changes

### ES2020 and Node.js v18+

In order to deliver our leanest TypeScript SDKs yet, we set out to avoid unnecessary third-party libraries, polyfills and transpilation which could inflate JavaScript bundles. Based on browser and backend usage statistics, we decided to create a support policy which targets JavaScript features that have been available for at least 3 years. Additionally, when it comes to Node.js in particular, we'll be supporting the current LTS releases. At the time of writing, this is version 18 ([source](https://nodejs.org/en/about/previous-releases)).

### Moving from Axios to fetch

Our previous TypeScript SDK generator used [Axios](https://axios-http.com/) as the underlying HTTP client. SDKs were also exposing Axios APIs to users establishing an unwanted expectation that they are familiar with this library and understand how to configure custom clients and requests. Fortunately, the [Fetch API](https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API) is a standard web platform API and has become ubiquitous across all runtimes, from browsers to React Native to Bun/Deno/Node.js. Switching to `fetch` means SDKs no longer pull in an unnecessary third-party dependency and leverage standard platform features.

### Changes in SDK file structure

In previous versions of our SDKs, various functionality such as model classes and types were nest in the package's directory structure under a `dist/` folder. While modern editors with language server support take the burden out of typing out imports, it was still unpleasant to see the build folder present in import paths. Many of our existing users commented as much and we fully agree so we've updated how we package SDKs into NPM modules and eliminated this folder from appearing in import paths. This is a breaking change but one that we think SDK owners and users will appreciate.

We've also reorganised various supporting files in the SDK and moved away from the `internal/` package to `lib/`. We do not believe this is going to affect end-users of SDKs but, since it's a breaking change, we're listing it here for completeness.

## Next steps

If you are using Speakeasy to generate your TypeScript SDK for the first time, then you'll automatically be using our new generator.

For existing Speakeasy customers with TypeScript SDKs, we've introduced a new field that you can add in your `gen.yaml` file, called `templateVersion`, to opt-in to the new generator:

```diff
configVersion: 1.0.0
# Rest of gen.yaml omitted for brevity
typescript:
+  templateVersion: v2
```

If you are using our GitHub Action then, after committing that change, the next run will generate a refreshed SDK. `speakeasy` CLI users can rerun the `generate` command which will pick up the flag and regenerate the new SDK.

## Building on good foundations

We're really excited to provide users with an awesome experience using machine-generated SDKs. There's often a trade-off that product engineers and API owners consider when relying on code generators versus hand-building SDKs and the quality of the code and public interface they produce. We believe that our refreshed TypeScript SDK generator has baked in a lot of good ideas that ultimately result in a great developer experience, one that increasingly feels like working with a carefully curated TypeScript SDK. We now have the foundation to build even more exciting features like support for Server-sent Events and we're looking forward to taking more of the pain away from shipping awesome DX for your products.

If you do try out Speakeasy and our TypeScript SDKs then we'd love to get your feedback about your experience, new ideas or feature requests.

Happy hacking!


 This is the content for the doc blog/langchain-vs-haystack-api-tools/index.mdx 

 ---
title: "Building an AI agent with OpenAPI: LangChain vs. Haystack"
description: "Compare LangChain and Haystack in terms of features, workflows, and documentation to choose the best framework for your needs."
image: "/media/langchain-vs-haystack.png"
date: 2024-12-05
authors:
  - name: Nolan Di Mare Sullivan
  - image_url: "/media/author-headshots/nolan.jpeg"
tags:
  - OpenAPI
featured_image: "/media/langchain-vs-haystack.png"
---

import { Callout } from "~/components";

If you're developing an AI application, you're probably considering using APIs to extend its capabilities and integrate it with various services (internal or external).

Fortunately, popular AI agent frameworks like [LangChain](https://python.langchain.com/docs/introduction/) and [Haystack](https://haystack.deepset.ai/), make this easy. You can use them to build an AI agent that can process user queries, interact with APIs, and generate responses based on the data retrieved. All you need to start connecting the agent with outside systems is an [OpenAPI document](/openapi). 

OpenAPI is a standardized way to describe a RESTful API (in JSON/YAML). The AI agents can use this document to understand and interact with the API.

In this guide, we'll build an agent with each of these frameworks. The agents will connect with a mock **F1 API** to answer queries about Formula One (F1) race winners, using the API's OpenAPI document to automatically understand which API endpoints to call, what data to send, and how to interpret the responses.

When we're done, we'll compare LangChain and Haystack in terms of their features, workflows, and documentation to help you decide which is better suited to your needs.

## What is an agent?

An AI agent is an intelligent system that can autonomously perform tasks like decision-making, data retrieval, and interacting with external systems. Think of it as a digital assistant that helps automate complex workflows without needing constant human supervision.

## How do agents and APIs interact, and where does OpenAPI fit in?

The [OpenAPI Specification](/openapi) provides a standardized format for describing RESTful APIs that agents can use to understand what endpoints are available, how to authenticate, what data is needed, and what responses to expect.

By [generating an OpenAPI document from code](/openapi/frameworks), you can guarantee a correct interface between agents and APIs. This means agents can autonomously work with APIs, reducing the manual work involved in crafting queries and parsing responses.

## Agents vs. LLMs?

Just as web frameworks like Flask or FastAPI simplify full-stack development by handling much of the boilerplate for routing, input validation, and middleware, AI agent frameworks do the heavy lifting when working with large language models. Instead of manually writing HTTP requests and parsing JSON responses line by line, you can use an AI framework to quickly get started using structured components.

For example, when building the F1 agent in this guide, using a framework like LangChain or Haystack spares you from writing custom code to fetch the winner from an endpoint like `/winners/2024/monaco`. Instead, you can plug in your OpenAPI document, and the framework's existing tools handle the low-level details. This means less time spent wrestling with request formatting and more time focusing on your agent's logic.

For a quick, one-off prompt, directly calling OpenAI or Claude might be simpler. But if you're aiming for a production-level system that is reliable and can handle edge cases like LLM refusal (for example, "I can't answer that"), using a framework saves on development time and headaches, much like web frameworks simplify traditional app development.

## What we're building

We'll build an F1 race agent that answers users' questions about F1 races to demonstrate how AI can integrate with an API to retrieve real-time or historical data. When prompted with a question, the agent will autonomously call the relevant endpoints, parse results, and deliver meaningful answers.

For example, if a user asks, _"Who won the Monaco Grand Prix in 2024?"_, the agent will:

1. Recognize the query and identify the relevant API endpoint, like `/winners/{year}/{race}`, based on the OpenAPI spec.
2. Call the endpoint with the necessary parameters.
3. Return a clear, user-friendly reply based on the API response, for example, _"Charles Leclerc won the Monaco Grand Prix in 2024."_

Here's a diagram of our agent's workflow:

```mermaid
flowchart TB
    A["User"] -- (1) sends query to --> B["Agent"]
    B -- (2) reads schema from --> C["openapi.yaml"]
    B -- (3) formulates API request and calls --> D["API Server"]
    D -- (4) returns response to --> B
    B -- (5) sends query context to --> E["LLM"]
    E -- "(6) generates user-friendly reply for" --> B
    B -- (7) sends answer to --> A
    D -- (8) generates --> C
     A:::user
     A:::user
     B:::agent
     B:::agent
     B:::agent
     C:::schema
     C:::schema
     D:::api
     D:::api
     E:::llm
    classDef user stroke:#EAB308,stroke-width:2px
    classDef agent stroke:#3B82F6,stroke-width:2px
    classDef schema stroke:#6366F1,stroke-width:2px
    classDef api stroke:#F87171,stroke-width:2px
    classDef llm stroke:#84CC16,stroke-width:2px
```

## AI frameworks: LangChain and Haystack

**LangChain** and **Haystack** are two popular frameworks for API integration, each offering a different design philosophy and user experience.

### LangChain

One of the most widely-used frameworks for building AI applications, [LangChain](https://python.langchain.com/docs/introduction/) is known for its ability to integrate with OpenAPI documents, enabling agents to understand and interact with APIs naturally. In theory, this makes LangChain a solid candidate for building our F1 agent, where the goal is to fetch race winners from a FastAPI backend based on user queries.

Our expectation was that LangChain would deliver a smooth transition from a static spec file to a working prototype in no time: Feed in an OpenAPI document, and the agent should automatically figure out which endpoint (such as `/winners/{year}/{race}`) to call for queries like "Who won the Monaco Grand Prix in 2024?"

In reality, we spent a lot of time struggling with LangChain's documentation. Much of the OpenAPI integration guidance was outdated, referencing methods and classes that had been deprecated or moved elsewhere. Trying to use the code within the Langchain OpenAPI guide often resulted in deprecation errors like this one:

```text
LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``
```

This forced us into a trial-and-error approach, where we had to rely on `langchain-community` modules rather than the official `langchain` package.

#### Hallucination and debugging the agent

Once we had a working prototype, our LangChain-based agent occasionally hallucinated non-existent endpoints (like `/winners/latest`), and required extra prompt tuning and spec details to keep it on track.

The silver lining was that the `AgentExecutor` tool allowed us to see the agent's internal reasoning steps so we could trace the logic that led to a faulty endpoint choice. This transparency helped us debug the agent's behavior.

#### Strengths

- Highly flexible and extensible ecosystem.
- Large community offering workarounds and additional tools.
- Useful view of the agent's "chain of thought" for debugging and prompt engineering.

#### Challenges

- Outdated and incomplete official documentation.
- Reliance on community-driven modules.

### Haystack

[Haystack](https://haystack.deepset.ai/) was initially designed for search, retrieval-augmented generation (RAG), and question-answering (QA), but it's evolved into a general-purpose AI agent framework that also integrates with OpenAPI documents. While this means that Haystack can enable an agent to understand and call specific API endpoints much like LangChain does, it handles such tasks with a more standardized pipeline structure.

Haystack's modular pipeline structure uses standardized components to handle different parts of an agent's workflow, making it easier to understand how tasks are processed step by step. Compared to LangChain's "black box" approach, this modularity made the experience of implementing our F1 agent with Haystack more straightforward.

Without having to hunt down unofficial modules or rummage through outdated examples, we got the agent calling the correct `/winners/{year}/{race}` endpoint and retrieving data with comparatively little friction. Queries like "Who won the Monaco Grand Prix in 2024?" worked reliably within a much shorter setup time.

A standout feature of Haystack is its accurate and up-to-date documentation. Instead of encountering deprecated functions or incomplete references, we found guides that matched the latest version of the framework and provided clear, step-by-step instructions.

Unlike LangChain, where we found that most new features required some community-driven workaround, Haystack's official docs led us directly to solutions that work out of the box.

#### Hallucination and debugging the agent

As with our LangChain-based agent, our Haystack-based agent occasionally tried to call non-existent endpoints. We addressed this by providing more detailed descriptions in the OpenAPI document, as we did previously. 

Unlike LangChain, Haystack didn't readily expose the agent's reasoning steps. Although this made certain debugging tasks less transparent, the overall reliability of the agent and reduced need for guesswork in its implementation meant we didn't feel as dependent on seeing those internal processes. Haystack's consistent documentation and structured design approach helped us avoid many of the pitfalls that required extensive investigation in LangChain.

For example, we asked the question "Who is the latest winner of the Monaco Grand Prix?" The Haystack agent hallucinated an endpoint:

```text
HTTP error occurred: 500 Server Error: Internal Server Error for url: http://127.0.0.1:8000//winners/2023/monaco_gp while sending request to http://127.0.0.1:8000//winners/latest/monaco_gp

Error invoking OpenAPI endpoint. Error: HTTP error occurred: 500 Server Error: Internal Server Error for url: http://127.0.0.1:8000//winners/2023/monaco_gp

LLM Response: It seems that there was a server error when trying to retrieve the information for the latest Monaco Grand Prix. Unfortunately, I cannot access the data at the moment. If you're looking for information about the winners or another specific query regarding F1, please let me know, and I'll do my best to assist you!
```

#### Strengths

- Clear, up-to-date documentation.
- More stable and consistent components, resulting in fewer breaking changes.
- No reliance on community modules.

#### Challenges

- Smaller ecosystem means fewer experimental or cutting-edge integrations.
- No visibility into the agent's internal reasoning steps.

## Building an OpenAPI agent

Now we'll walk you through creating two AI agents that interact with an F1 API using OpenAPI documents: One built with LangChain and the other with Haystack. We'll cover setting up the F1 API server, loading the OpenAPI document, and implementing each agent.

### Example API Server

The agents use an F1 API built with FastAPI, featuring endpoints for race standings, to demonstrate how agents interact with real-world data.

The F1 API includes the endpoints `/winners/{year}/{race}`, which returns the winner of a specific race in a given year, and `/winners/{year}`, which returns all race winners for that year.

<Callout title="Example Repository" variant="info">
Take a look at the [F1 API repository](https://github.com/speakeasy-api/openapi-agent-examples/tree/main/f1-fastapi-server) for more details on the API implementation.
</Callout>


#### Running the F1 API server

To run the F1 API server, follow these steps:

1. Clone the [repository](https://github.com/speakeasy-api/openapi-agent-examples/tree/main/f1-fastapi-server) and navigate to the `f1-fastapi-server` directory.

```bash
git clone https://github.com/speakeasy-api/openapi-agent-examples.git

cd openapi-agent-examples/f1-fastapi-server
```

2. Install the required dependencies using `pip install -r requirements.txt`.

3. Run the FastAPI server using `uvicorn main:app --reload`.

The API server will start on `http://127.0.0.1:8000/` by default.

### Generating the OpenAPI document

We'll use FastAPI's built-in support for OpenAPI to generate the OpenAPI document that describes the F1 API's endpoints, request parameters, and response formats. This spec serves as a blueprint for the AI agent to understand the API's capabilities and interact with it effectively.

Find the generated OpenAPI document by spinning up the FastAPI server and navigating to `http://127.0.0.1:8000/openapi.json`.

Convert the OpenAPI document to YAML format using an online tool like [JSON to YAML](https://www.json2yaml.com/).

### Building an agent with LangChain

You can follow along with the code in our [example repository](https://github.com/speakeasy-api/openapi-agent-examples).

#### Prerequisites

You'll need the following to build the agent with LangChain:

- An Anthropic API key to use with the ChatAnthropic model. Sign up for an account and get an API key from the [Anthropic website](https://www.anthropic.com/).
- The OpenAPI document (`openapi.json`) that describes the F1 API's endpoints and data structure. Read the [running the F1 API server](#running-the-f1-api-server) section to generate the OpenAPI document.

#### 1. Importing libraries

First install and import the necessary libraries for building the agent:

```txt requirements.txt
langchain_anthropic
langchain_community
```

```bash
pip install -r requirements.txt
```

Now import the required modules in the agent script:

```python langchain_agent.py
import os
import json
import argparse

from langchain_community.utilities.requests import RequestsWrapper
from langchain_community.agent_toolkits.openapi import planner
from langchain_community.agent_toolkits.openapi.spec import reduce_openapi_spec
from langchain_anthropic import ChatAnthropic
```

#### 2. Checking the API key

Let's add a check to ensure the API key is set before proceeding:

```python langchain_agent.py
if "ANTHROPIC_API_KEY" not in os.environ:
    raise ValueError("ANTHROPIC_API_KEY environment variable not set")
```

#### 3. Parsing command-line arguments

We'll use argparse to parse command-line arguments for using the agent:

```python langchain_agent.py
argparser = argparse.ArgumentParser()
argparser.add_argument("query", type=str, help="User query. E.g: 'Who won in Monaco in 2024?'")
argparser.add_argument("--model", type=str, default="claude-3-sonnet-20240229", help="Model name")
argparser.add_argument("--timeout", type=int, default=10, help="Timeout in seconds")
argparser.add_argument("--stop", type=str, default="</s>", help="Stop token")
args = argparser.parse_args()
```

This code snippet provides a CLI interface to input user queries and set optional parameters like model name, timeout, and stop token.

#### 4. Initializing the Anthropic model

Next, we'll initialize the Anthropic model for generating responses:

```python langchain_agent.py
model = ChatAnthropic(
    model_name=args.model,
    timeout=args.timeout,
    stop=[args.stop],
)
```

#### 5. Loading the OpenAPI document

Now load the OpenAPI document (`openapi.json`):

```python langchain_agent.py
with open("openapi.json") as f:
    openapi = json.load(f)
```

#### 6. Reducing the OpenAPI document

We'll reduce the OpenAPI document to optimize it for the agent:

```python langchain_agent.py
f1_spec = reduce_openapi_spec(openapi)
```

#### 7. Initializing the requests wrapper

Now initialize `RequestsWrapper` to handle HTTP requests:

```python langchain_agent.py
requests_wrapper = RequestsWrapper()
```

#### 8. Creating the OpenAPI agent

Create the OpenAPI agent by combining the optimized OpenAPI document, request handling, and Anthropic model:

```python langchain_agent.py
f1_agent = planner.create_openapi_agent(
    f1_spec, requests_wrapper, model, allow_dangerous_requests=True
)
```

Here we set `allow_dangerous_requests` to `True` to enable the agent to make potentially unsafe requests to the F1 API.

#### 9. Invoking the agent

Finally, invoke the agent with the user query:

```python langchain_agent.py
f1_agent.invoke(args.query)
```

#### Running the script

Before running the script, make sure the [F1 API server is running](#running-the-f1-api-server).

1. Place the OpenAPI document (`openapi.json`) in the working directory.

2. Set your Anthropic API key in the environment variables:

   ```bash
   export ANTHROPIC_API_KEY="your_anthropic_api_key"
   ```

3. Run with a query:

   ```bash
   python langchain_agent.py "Who won the Monaco Grand Prix in 2024?"
   ```

You should receive a response similar to the following:

   ```text
   Based on the data from the F1 API, Charles Leclerc won the 2024 Monaco Grand Prix.
   ```

### Building an agent with Haystack

You can follow along with the code in our [example repository](https://github.com/speakeasy-api/openapi-agent-examples).

#### Prerequisites

You'll need the following to build an agent with Haystack:

- An OpenAI API key. You can sign up for an account and get an API key from the [OpenAI website](https://platform.openai.com/).
- The OpenAPI document (`openapi.yaml`) that describes the F1 API's endpoints and data structure. Read the [running the F1 API server](#running-the-f1-api-server) section to generate the OpenAPI document.

#### 1. Importing libraries

First, install and import the necessary libraries for building the pipeline:

```txt requirements.txt
haystack-ai
openapi3
jsonref
haystack-experimental==0.3.0
```

Run the following command to install the required libraries:

```bash
pip install -r requirements.txt
```

Now import the required modules in the agent script:

```python haystack_agent.py
import os
import argparse
from haystack import Pipeline
from haystack.dataclasses import ChatMessage
from haystack.components.builders import ChatPromptBuilder
from haystack.components.generators.chat import OpenAIChatGenerator
from haystack_experimental.components.tools.openapi import OpenAPITool, LLMProvider
```

#### 2. Checking the API key

Let's add a check to make sure that the API key is set:

```python haystack_agent.py
if "OPENAI_API_KEY" not in os.environ:
    raise ValueError("OPENAI_API_KEY environment variable not set")
```

#### 3. Initializing the OpenAPI tool

Next, initialize the OpenAPI tool with the F1 API schema:

```python haystack_agent.py
f1_tool = OpenAPITool(
    generator_api=LLMProvider.OPENAI,
    spec="openapi.yaml",
)
```

#### 4. Building the prompt template

Let's define a conversation template to guide the LLM in generating responses:

```python haystack_agent.py
messages = [
    ChatMessage.from_system(
        "Answer the F1 query using the API. Race names with two words should be separated by an underscore and be in lowercase. The API stores data from 2021 to 2024."
    ),
    ChatMessage.from_user("User asked: {{user_message}}"),
    ChatMessage.from_system("API responded: {{service_response}}"),
]

builder = ChatPromptBuilder(template=messages)
```

#### 5. Initializing the LLM

Set up the LLM to generate API-based replies:

```python haystack_agent.py
llm = OpenAIChatGenerator(generation_kwargs={"max_tokens": 1024})
```

#### 6. Building the pipeline

Now we'll create a pipeline that connects the OpenAPI tool, prompt builder, and LLM. Haystack's modular design allows us to chain components together easily:

```python haystack_agent.py
pipe = Pipeline()
pipe.add_component("f1_tool", f1_tool)
pipe.add_component("builder", builder)
pipe.add_component("llm", llm)

pipe.connect("f1_tool.service_response", "builder.service_response")
pipe.connect("builder.prompt", "llm.messages")
```

#### 7. Querying the pipeline

Define a function to process user queries through the pipeline and return the LLM's response:

```python haystack_agent.py
def query_f1_pipeline(user_query: str):
    """
    Run the F1 bot pipeline with the user's query.
    :param user_query: The user's query as a string.
    :return: The response generated by the LLM.
    """
    result = pipe.run(data={
        "f1_tool": {
            "messages": [ChatMessage.from_user(user_query)]
        },
        "builder": {
            "user_message": ChatMessage.from_user("Answer the F1 query in a user-friendly way")
        }
    })
    return result["llm"]["replies"][0].content
```



#### 8. Creating a CLI tool

Finally, let's set up the main function to allow the script to accept user input via command-line arguments:

```python haystack_agent.py
def main():
    parser = argparse.ArgumentParser(description="Query the F1 pipeline CLI tool.")
    parser.add_argument("query", type=str, help="User query. E.g., 'Who won in Monaco in 2024?'")
    parser.add_argument("--model", type=str, default="gpt-4", help="Model name")
    parser.add_argument("--timeout", type=int, default=10, help="Timeout in seconds")
    parser.add_argument("--max_tokens", type=int, default=1024, help="Maximum tokens for response")

    args = parser.parse_args()

    llm.generation_kwargs["max_tokens"] = args.max_tokens

    response = query_f1_pipeline(args.query)
    print("LLM Response:", response)

if __name__ == "__main__":
    main()
```

#### Running the script

Before running the script, make sure the [F1 API server is running](#running-the-f1-api-server).

1. Place the F1 API document (`openapi.yaml`) in the working directory.

2. Set your OpenAI API key as an environment variable:

   ```bash
   export OPENAI_API_KEY="your_openai_api_key"
   ```

3. Run the script with a query:

   ```bash
   python haystack_agent.py "Who won in Monaco in 2024?"
   ```

You should receive a response similar to the following:

   ```text
   LLM Response: Based on the data from the F1 API, Charles Leclerc won the 2024 Monaco Grand Prix.
   ```

## The production gap

Turning a proof-of-concept into a production-ready system involves more than just getting basic queries right. Even if your agent works perfectly in testing, production brings new challenges, like how to handle errors, manage resources, and keep the agent secure. 

### Error handling

In production, your agent must gracefully handle unexpected inputs, outdated OpenAPI documents, and API timeouts. If a user asks about a non-existent race, your agent should respond with a helpful message rather than crash.

Input validation, API timeout handling, and clear error messages ensure the system stays stable. Logging errors makes it easier to troubleshoot issues later.

### Resource management

As usage grows, so do costs and performance demands. Without limits, frequent LLM and API calls can lead to significant bills.

Caching popular results reduces unnecessary calls. Monitoring request rates and scaling resources as needed helps maintain responsiveness without overspending.

### Security

With increased traffic comes higher security risks. Always sanitize user inputs to prevent malicious payloads.

Secure API keys, add authentication if needed, and ensure only authorized users can access sensitive endpoints.

### Making your agent production-ready

Implement rate limiting to handle traffic spikes, and add retries for flaky network calls. A good monitoring system should warn you if something goes wrong, while a thorough testing suite (including integration tests) ensures that updates don't break critical features.



## Final thoughts

LangChain is more of a collection of tools than a fully integrated framework. The LangChain toolset offers good flexibility, allowing you to pick and choose components, integrate various LLMs, and adapt the setup to unusual requirements. However, LangChain's official documentation is lacking, and you'll rely on community modules to piece together solutions. Developing a good agent involves experimenting with `langchain-community` modules to replace outdated instructions.

Haystack, on the other hand, focuses on reliability and production-readiness. The Haystack documentation is clear and up-to-date, and the structured pipeline design makes it easier to understand how components interact. Haystack also offers a lower risk of breaking changes and deprecated functions, and eliminates the need to rely on community modules to fill gaps.

Keep in mind that even with the right framework, AI agents can hallucinate endpoints and produce unexpected errors.

Overall, Haystack is the better choice for production-level systems and quick POCs, while LangChain is more suited for projects that require greater flexibility and allow for time to experiment.


 This is the content for the doc blog/loom-for-remote-collaboration.mdx 

 ---
title: "Using Loom for Remote Collaboration"
description: "We've found a good remote work practice has been posting short Loom videos for dev updates in our slack. In this one we get the team familiar with Pulumi for managing infra."
image: "/media/loom-for-remote-collaboration.jpeg"
date: 2022-07-06
authors:
  - name: Anuraag Nalluri
  - image_url: 'https://uploads-ssl.webflow.com/62ccd7b208cab0723d026273/62cdfd40eb73d17e05b712ca_3-anuraag_headshot-p-500.jpeg'
tags:
  - Building Speakeasy
featured_image: "/media/loom-for-remote-collaboration.jpeg"
---

Working on a remote-first dev team can be challenging. Most of us devs have spent years building up processes optimized for in person collaboration. We've found a really quick win has been posting short [Loom](https://www.linkedin.com/company/useloom/) videos for dev updates in our slack! This builds shared context for our team without more meetings. Our hope is to build up dozens of these so new hires can have a library of resources to watch and reference when they join the team. In this short clip, I demonstrate how we use [Pulumi](https://www.linkedin.com/company/pulumi/) for managing infra.

<video src="https://cdn.loom.com/sessions/thumbnails/5f07a3da015442a4b125a1ae3a28d5e5-00001.mp4" playsinline="" loop="" autoplay="" class="css-1dd3ex7"></video>


 This is the content for the doc blog/more-apis-less-complexity/index.mdx 

 ---
title: "More APIs, Less Complexity"
description: "To speed up new product and business creation, we need to simplify API development, maintenance, and usage for developers."
image: "/media/more-apis-less-complexity.jpeg"
date: 2022-05-13
authors:
  - name: Sagar Batchu
  - image_url: 'https://uploads-ssl.webflow.com/62ccd7b208cab0723d026273/62cdf303b28bf9598d7a6b63_sagar_headshot-p-500.jpeg'
tags:
  - API Advice
  
featured_image: "/media/more-apis-less-complexity.jpeg"
---

_This post is the first from the Speakeasy blog!  Follow us as we explore why APIs are important to the future of software, the challenges developers at non-FAANG companies face, and what the future of dev infra for APIs holds._

It has always been the case that there are far more ideas in the world which deserve to be built, than there are people to build them. The tricky thing about ideas is that it’s really hard to know whether they’re good or not until you get knee deep in them.  You could of course try and get really good at identifying the ideas that have legs, but the far safer method is to just throw as many ideas at the wall as possible and see what sticks.

The question then becomes, as a community, how do we make sure that we are pursuing as many ideas as possible?  The answer is that we do what humans have always done, we build tools.  The best tools empower each individual to accomplish what previously took 10 people to do. With the right tools the same number of people can collectively tackle 10x the number of projects and thus push the boundaries of what’s possible.

Nowhere has this pattern of tools providing 10X productivity boosts been more powerful than in software.  Free of nearly all physical constraints, the creation and proliferation of software is only ever constrained by the time of the world’s developers. Unfortunately, that’s still a big constraint. There aren’t nearly enough new developers being trained to keep pace with the cambrian explosion of new software products being created. The only way to keep the industry accelerating is to keep building tools which deliver a step change boost in productivity.  We believe the next step change in productivity will be achieved when developers’ are able to easily operationalise a common, but underutilized technology, APIs.

> _If we want to massively accelerate the creation of new products and businesses, we need to make it easier for developers to build, maintain, and ultimately,_ **_use_** _APIs._

APIs are the next solution to the consistent problem of limited developer bandwidth. A well built API is like giving a developer [superpowers](https://www.notboring.co/p/apis-all-the-way-down?s=r). They enable a dev, with a single line of code, to harness functionality that would’ve taken a team of 10 devs years to build. That dev is now able to focus more time on true innovation rather than reinventing the wheel. A perfect example of this is the explosion of D2C e-commerce, none of which would have been possible without the layers of abstraction in payments processing provided by API companies like [Shopify](https://shopify.dev/docs/api) and [Stripe](https://stripe.com/docs/api):

![A group of astronauts standing next to each other.](./assets/more-apis-less-complexity-image-01.png)

e-commerce = Abstraction all the way down

APIs have the potential to bring an explosion in innovation to every industry they touch.

## Too often, APIs go unbuilt and unused

There’s no doubt that APIs are the answer to the problem of developer bandwidth. And yet, within the answer lies another set of problems. Too often, APIs go unbuilt because productionizing them is too tedious to be valuable.  And even more often, APIs that are built go unused because their value is hidden by a layer of usability issues.  Before the full promise of APIs can be realized, these issues need to be fixed.

Nearly every development team outside of FAANG (now christened _MAMAA?_) finds itself trapped in what could be described as API development purgatory, they know they need APIs to power innovation across their business, but they can’t justify the upfront investment which would be required to build the tooling devs need to easily build said APIs.  So, API development limps forward, too important to give up, too tangential to business objectives to be a priority.  

## The Problem: Building reliable and usable APIs takes a lot of effort.

Without tooling to make development easy, it’s each developer’s personal conviction that determines whether an API is built, and if so, to what standard. Often developers simply can’t justify the time investment which would be required to make the API high quality.  This is because writing code is merely one task on the long laundry list of necessary activities which comprise the full API development lifecycle. Some of the most particularly painful problems associated with the API lifecycle are:

- **Devs deserve a great user experience too!**: It is extremely easy for static artifacts to get out of sync with code. Every developer has experienced the pain & confusion caused by sparse, stale documentation.

- **The dreaded back compat:** It is expensive to maintain multiple versions of an API, but without versioning, making major changes becomes an epic migration with all the associated spreadsheets and client calls.

- **Yet another integration**: the API ecosystem is fragmented for Authentication, Gateways, Billing and much more. It’s challenging for a developer to keep these all in sync without causing customer downtime and rarely get accounted upfront in development planning.

- **K8s Apps, services, ingresses, proxies, gateways…. :(** :  The cloud is powerful, but complicated with many moving parts needed for a simple API.  Making sure that infrastructure is optimally configured for your use case can take as long as building the product in the first place.

The above is really just the tip of the iceberg. For any given API you may also need to consider key management, rate limiting, discovery, dev portals, usage tracking, billing, observability…. When you consider all this, it’s a wonder that any APIs get built at all.

![Live Footage of a dev deploying their API to prod](./assets/more-apis-less-complexity-image-02.png)

## How do we end API purgatory?

Unfortunately, it’s not going to happen in a day, but there is hope that the ease of API development can be massively improved for developers.  In future posts, we plan to break down each of the individual issues we mentioned and propose what a developer-first solution to the problem might look like.

We know we don’t have all the answers, so we look forward to hearing from everyone! Please don’t hesitate to chime in with your perspective on the challenges facing devs working on APIs, and what you think constitutes a good solution. If you ever want to speak with us, [don’t hesitate to reach out!](https://calendly.com/d/5dm-wvm-2mx/chat-with-speakeasy-team)

 This is the content for the doc blog/nivo-vs-recharts/index.mdx 

 ---
title: "Nivo vs Recharts - Which should you use?"
description: "Which React Charting Library should you use: Nivo or Recharts?"
image: "/media/nivo-vs-recharts.png"
date: 2022-10-11
authors:
  - name: Chase Crumbaugh
  - image_url: 'https://uploads-ssl.webflow.com/62ccd7b208cab0723d026273/63455d36b67d1990f1bba1f0_chase-headshot.jpeg'
tags:
  - Building Speakeasy
featured_image: "/media/nivo-vs-recharts.png"
---

If you work in B2B it’s inevitable that you’ll be asked to build a dashboard. Building dashboards means buildings charts, and creating nice-looking charts for the web is undeniably difficult. Sure you _could_ build your own solution directly using D3, but do you really _need_ (or want) to? Probably not. Building off of D3 might allow you to build some elaborate custom visualizations, but as any frequenter of [/r/dataisbeautiful](http://reddit.com/r/dataisbeautiful) knows, simplicity and usability go hand in hand when visualizing data. Good news!--there are plenty of great React libraries for making simple charts.

At Speakeasy, we were recently building out an API usage dashboard and in doing so explored Nivo and Recharts (an admittedly non-exhaustive dive into the sea of React charting libraries out there). We want to share, and save you from needing to do the same investigation, at least into those two.

## TLDR

If you’re picking between Nivo and Recharts, we strongly recommend choosing Recharts. If you’re deciding between Recharts and something else, maybe use Recharts (we like it well enough) but also know that it’s not without issues.

## Nivo - What We Liked

[Nivo](https://nivo.rocks/) is beautiful. Their charts are beautiful, their website is beautiful, their online sandbox is a fantastic feature. All of these are wonderful selling points and will hopefully make for a top-of-the-line chart library one day. We were drawn in by the siren’s song and pulled the trigger on it without doing any due diligence investigating other options. Unfortunately there are plenty of problems we encountered (fortunately very quickly).

## Nivo - What We Disliked

### Poor responsiveness

Static charts are ugly. Responsiveness is important. Here’s what happens when you try to make your Nivo charts responsive:

import portal_url_1 from './assets/nivo-vs-recharts-image-01.mp4'

  <video controls={false} loop={true} autoPlay={true} muted={true} width="100%" alt="Responsive Nivo charts poor responsiveness">
    <source src={portal_url_1} type="video/mp4" />
  </video>

This is a known issue ([here’s](https://github.com/plouc/nivo/issues/109) one of several Github issues calling it out). Workarounds exist for certain situations, but for others, no such luck. We were not able to get simple width responsiveness working; this was a big strike against Nivo.

### Poor interface

![A screenshot of a code editor containing a Nivo component.](./assets/nivo-vs-recharts-image-02.png)

We found Nivo to be very verbose. Those ultra-minimal charts with no axes, gridlines, or tooltips in the gif above? The code for the corresponding Nivo component, with all of its input props, is 30 lines long. 

To the left is (some of) the code for the default example on [their website](https://nivo.rocks/line/) (the rest of it didn’t fit on one screen for a screenshot). You can see that everything is crammed into the component props. Not the end of the world, but as you’ll see in the Recharts section, there’s a much better way.

### Subpar Technical Documentation

The poor interface mostly becomes an issue when paired with subpar documentation. If you want to do something simple (or something that happens to have a corresponding example in their [storybook](https://nivo.rocks/storybook/)), it’s (relatively) smooth sailing. If you want to do something that has no example, you’ll have to fumble in the dark a bit. Many of the property objects are not documented anywhere, leaving you to guess at what properties are available and what they do. I found myself messing around in their sandbox, looking at the corresponding code, and copying over the relevant properties in a tedious trial & error process. If your use case is simple you’ll be okay, but the second you run into an issue, the limited documentation makes troubleshooting very difficult.

### Mindshare is low

While very polished-looking, Nivo is one of the least used of the popular React charting libraries. This naturally means mindshare (read: stack overflow answers) will be limited and troubleshooting will involve praying that (a) there’s a corresponding issue on Github and (b) someone has responded to that issue with a fix or workaround. And again, because usage is low, that’s not super likely.

## Recharts - What We Liked

After struggling with the aforementioned issues with Nivo, we decided to cut our losses and swap in a different chart library. After spiking out an implementation using Recharts, we decided it met our needs and was a substantial improvement, so we trialed it everywhere.

### It’s easy to make pretty charts

The charts are nice-looking (though simple) out of the box. They come with things like a nice animation when the page is loaded

import portal_url_3 from './assets/nivo-vs-recharts-image-03.mp4'

  <video controls={false} loop={true} autoPlay={true} muted={true} width="100%" alt="Out of the box charts">
    <source src={portal_url_3} type="video/mp4" />
  </video>

It’s also trivial to add things like synchronized tooltips. This was a one-line change that yielded pretty cool results.  

import portal_url_4 from './assets/nivo-vs-recharts-image-04.mp4'

  <video controls={false} loop={true} autoPlay={true} muted={true} width="100%" alt="Synchronized tooltips in charts">
    <source src={portal_url_4} type="video/mp4" />
  </video>

### It has a nice interface

![Recharts interface](./assets/nivo-vs-recharts-image-05.png)

The interface for Recharts is very well designed, especially when compared to Nivo. Below is our implementation of the ultra-minimal charts shown above.

![Recharts ultra-minimal charts implementation](./assets/nivo-vs-recharts-image-06.png)

Declaring the different elements of a chart (axes, gridlines, the line itself) as individual components is very intuitive and nice to use. For the charts above we wanted _just_ the line, so to achieve that we simply added _just_ the \`Line\` component. Beautiful.

## Recharts - What We Dislike

### It has many open issues

Here’s one annoying one we encountered.

import portal_url_2 from './assets/nivo-vs-recharts-image-07.mp4'

  <video controls={false} loop={true} autoPlay={true} muted={true} width="100%" alt="Recharts annoying issue">
    <source src={portal_url_2} type="video/mp4" />
  </video>

Here you can see in that same synchronized tooltip example the page jumps around because the bottom tooltip starts off the screen. This is actually an issue for every tooltip, but most of the time if you hover over a chart it’s already on your screen. It was just particularly noticeable for these synchronized charts since the bottom one is often _not_ already on your screen. We tried to no avail to fix it, and ended up having to disable the synchronized tooltips altogether.

There are many such issues ([430](https://github.com/recharts/recharts/issues) of them, to be exact) so you’ll likely encounter one or two, which can be frustrating given that the documentation is not stellar.

### The documentation has room for improvement

While somewhat better than Nivo on the technical side of the docs, Recharts’ docs still lack real depth and meat. There are a fair few [examples](https://recharts.org/en-US/examples) which, like Nivo, are helpful if you are trying to do something simple with minimal customization. There’s also a [technical reference](https://recharts.org/en-US/api) which is at least a step up over Nivo in that it exists, but also contains so little detail that it’s not very useful. It can help remind you what properties exist, but it won’t help you figure out anything deeper than that.

## Conclusion

In the grand scheme of things, our charting needs are relatively simple and Nivo was not able to meet those simple needs, while Recharts was. So Recharts is definitely worthy of consideration, but we know that isn’t the full story. It’s definitely worth considering other libraries before you commit. We would love to hear what other libraries people have tried and how they compare to Recharts.


 This is the content for the doc blog/open-enums/index.mdx 

 ---
title: Evolving enums for evolving APIs
description: 
image: "/media/open-enums.png"
date: 2024-05-15
authors:
  - name: Georges Haidar
  - image_url: '/media/author-headshots/georges.jpeg'
tags:
  - Product Updates
featured_image: "/media/open-enums.png"
---

Today we're announcing support for "open" enums in our Go, Python and TypeScript
code generators. This feature will help you ship SDKs that continue to work as
you evolve your API and without causing your users unnecessary dependency
management churn.

## What even is that?

An enum is considered "closed" when it specifies a strict set of members like
this TypeScript enum:

```typescript
enum Color {
    Red = "red",
    Green = "green",
    Blue = "blue",
}

const value: Color = Color.Red;
//    ^ This can only be one of the three declared colors
```

Other languages, like Python and Java, treat enums similarly by default for
example.

An "open" enum, on the other hand, is one where unrecognized values can be
expressed alongside the known members. Some languages may not have a way to make
enums open but we can find a way such as with [branded types][branded-types]
in TypeScript:

[branded-types]: https://egghead.io/blog/using-branded-types-in-typescript

```typescript

declare const brand: unique symbol;
type Unrecognized = string & { [brand]: "unrecognized" };

function unrecognized(value: string): Unrecognized {
  return value as Unrecognized;
}

enum Color {
    Red = "red",
    Green = "green",
    Blue = "blue",
}
type OpenColor = Color | Unrecognized;

const stillWorks: OpenColor = Color.Blue;
const value: OpenColor = unrecognized("pink");

const badValue: Color = value;
//    ~~~~~~~~
//    Type 'Unrecognized' is not assignable to type 'Color'. (2322)
```

> We'll continue using TypeScript as the target language for the rest of this
> post.

## The problem

Enums in OpenAPI and JSONSchema have presented developers with a unique
challenge when it comes to making updates to their API. Let's consider an
example where we have an API to fetch a blog post from a CMS:

```yaml
openapi: 3.1.0
info:
  title: Blog CMS API
  summary: The API for the content management system of our blog.
  version: 0.1.0
servers:
  - url: https://headless-cms.example.com/api
paths:
  /posts/{slug}:
    get:
      tags: [posts]
      operationId: get
      parameters:
        - name: slug
          in: path
          required: true
          schema:
            type: string
      responses:
        "200":
          description: A blog post
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/BlogPost"
components:
  schemas:
    BlogPost:
      type: object
      required: [id, slug, title, readingTime, markdown, category]
      properties:
        id:
          type: string
        slug:
          type: string
        title:
          type: string
        readingTime:
          type: integer
        markdown:
          type: string
        category:
          type: string
          enum:
            - photography
            - lifestyle
            - sports
```

If we're building a TypeScript SDK with [Zod][zod] for runtime validation from
this API description, the code for the `BlogPost` schema might look like this:

[zod]: https://zod.dev/

```typescript
import { z } from "zod";

export enum Category {
    Photography = "photography",
    Lifestyle = "lifestyle",
    Sports = "sports",
}

export const BlogPost = z.object({
    id: z.string(),
    slug: z.string(),
    title: z.string(),
    readingTime: z.number().int(),
    markdown: z.string(),
    category: z.nativeEnum(Category),
});
export type BlogPost = z.output<typeof BlogPost>;
//          ^? type BlogPost = { id: string; slug: string; title: string; readingTime: number; markdown: string; category: Category; }
```

We're showing an example here with TypeScript enums but the problem we're
solving is also present when using literal string unions like if we were to 
define `Category` as:

```typescript
export const Category = z.enum(["photography", "lifestyle", "sports"]);
export type Category = z.infer<typeof Category>;
//          ^? type Category = "photography" | "lifestyle" | "sports"
```

> The Speakeasy TypeScript SDK generator lets you choose if you want to generate
> TypeScript-native enums or literal unions.

We ship version 1 of our SDK and users can interact with the API like so:

```typescript
import { CMS } from "@acme/cms";

const cms = new CMS();

const post = await cms.posts.get({ slug: "my-first-post" });
console.log(post.category);  // -> photography
```

Some time passes and we've decide to add a new "tech" category to our API. We
update our API description as follows:

```diff
components:
  schemas:
    BlogPost:
      type: object
      required: [id, slug, title, readingTime, markdown, category]
      properties:
        id:
          type: string
        slug:
          type: string
        title:
          type: string
        readingTime:
          type: integer
        markdown:
          type: string
        category:
          type: string
          enum:
            - photography
            - lifestyle
            - sports
+           - tech
```

Once we deploy this change to our servers, users on v1 start getting validation
errors because the category `tech` is not recognised by the SDK.

```
Uncaught:
[
  {
    "received": "tech",
    "code": "invalid_enum_value",
    "options": [
      "photography",
      "lifestyle",
      "sports"
    ],
    "path": [],
    "message": "Invalid enum value. Expected 'photography' | 'lifestyle' | 'sports', received 'tech'"
  }
]
```

This is not a novel problem and depending on the language and API description
format you're using, enums are sometimes treated as "closed" by default which
gives rise to this challenge with evolving APIs.

There is a longstanding [GitHub issue][oapi-enums] in the OpenAPI community to
address this problem. In a different world, [protobuf enums][proto-enum] have
varied representations where certain languages translate them to open enums and
others to closed.

[oapi-enums]: https://github.com/OAI/OpenAPI-Specification/issues/1552
[proto-enum]: https://protobuf.dev/programming-guides/enum/

## How we're solving it

Previously, the Speakeasy generator treated enums as closed and emitted code
appropriately in target languages. Starting from today, we're exposing an
OpenAPI extension, `x-speakeasy-unknown-values`, to allow you to selectively
mark certain enums in your API description as open.

To get started, add the extension to your enums:

```diff
components:
  schemas:
    BlogPost:
      type: object
      required: [id, slug, title, readingTime, markdown, category]
      properties:
        # ... other fields omitted for brevity ...
        category:
          type: string
+         x-speakeasy-unknown-values: allow
          enum:
            - photography
            - lifestyle
            - sports
```

SDKs generated after this change will now have a `Category` enum type that is
open. For TypeScript, the code we generate is equivalent to the following
snippet:

```typescript
import * as z from "zod";
import { catchUnrecognizedEnum } from "../../types";
//        ^ A utility to capture and brand unrecognized values

export enum Category {
    Photography = "photography",
    Lifestyle = "lifestyle",
    Sports = "sports",
}

export const BlogPost = z.object({
    id: z.string(),
    slug: z.string(),
    title: z.string(),
    readingTime: z.number().int(),
    markdown: z.string(),
    category: z.nativeEnum(Category).or(z.string().transform(catchUnrecognizedEnum)),
});

export type BlogPost = z.output<typeof BlogPost>;
//          ^? type BlogPost = { id: string; slug: string; title: string; readingTime: number; markdown: string; category: Category; }

type OpenCategory = z.output<typeof BlogPost>["category"];
//   ^? type OpenCategory = Category | Unrecognized<string>
```

In case you're interested, here's how `catchUnrecognizedEnum` works to create a
branded type:

```typescript
declare const __brand: unique symbol;
export type Unrecognized<T> = T & { [__brand]: "unrecognized" };

export function catchUnrecognizedEnum<T>(value: T): Unrecognized<T> {
  return value as Unrecognized<T>;
}
```

> Speakeasy TypeScript SDKs explicitly emit TypeScript types that are tied to
> Zod schemas instead of being inferred from them.

Continuing with our example above, when the new "tech" category is introduced,
the following code continues to compile and work:

```typescript
import { CMS } from "@acme/cms";

const cms = new CMS();

const post = await cms.posts.get({ slug: "my-first-post" });
//                           ^ Previously, this would throw a validation error

console.log(post.category);  // -> tech
```

Users of the SDK also get the editor support they're used to when working with
enums. For instance, switch-blocks work great for branch logic over enums:

```typescript
import { CMS } from "@acme/cms";
import { Unrecognized } from "@acme/cms/types";

// ...

let icon: "📸" | "🎨" | "🏈" | "❓";
switch (post.category) {
  case "lifestyle":
    icon = "🎨";
    break;
  case "photography":
    icon = "📸";
    break;
  case "sports":
    icon = "🏈";
    break;
  default:
    post.category satisfies Unrecognized<string>;
    //            ^ Helps assert that our switch cases above are exhaustive
    icon = "❓";
    break;
}
```

Great! It seems we've done a lot of work to get back to client code that
continues work. The net outcome, however, is that we've made more room for our
APIs to evolve without causing issues for users on older versions of our SDK.
This is _in addition_ to retaining good type safety, backed by strict runtime
validation, and great developer experience (editor auto-complete continues to
work for open enums).

## Wrapping up

The "open" enums feature, using the `x-speakeasy-unknown-values` extension, is
available for Go, Python and TypeScript SDKs with support for additional
language targets being added in the future. Check out our docs on [customizing
enums][customizing-enums] to learn about this and other customization options.

[customizing-enums]: /docs/customize-sdks/enums


 This is the content for the doc blog/open-source-pledge-2024/index.md 

 ---
title: "$40,000 for OSS maintainers"
description: "We're formalizing our commitment to Open Source by joining the OSS Pledge."
image: "/media/oss-pledge-2024.png"
date: 2024-10-04
authors:
  - name: Nolan Sullivan
  - image_url: '/media/author-headshots/nolan.jpeg'
tags:
  - Building Speakeasy
featured_image: "/media/oss-pledge-2024.png"
---

For as long as Speakeasy has had money in a bank account, we've been contributing to open-source projects we depend on. It therefore feels like a natural evolution to announce that we've joined [Open Source Pledge](https://opensourcepledge.com/) to formalize our support of the maintainers and projects that make our work possible.

## What is the Open Source Pledge?

For too long Open Source software has been taken for granted by the software industry. The Open Source Software Pledge, initiated by Sentry, is attempting to change that by encouraging companies to commit to financially support open-source maintainers. The minimum participation is $2,000 per full-time employed developer per year. You can read more about it [here](https://opensourcepledge.com/about/).

## Speakeasy's open source contributions

We donate a total of $3,523 per month ($42,276 per year) to OSS projects which annualizes to $4,228/engineer.

Here's a breakdown of our monthly sponsorships:

| Project | Maintainer | Monthly Contribution |
|---------|------------|----------------------|
| [libopenapi](https://github.com/pb33f/libopenapi) | [quobix](https://github.com/daveshanley) | $500 |
| [nextra](https://github.com/shuding/nextra) | [dimaMachina](https://github.com/dimaMachina) | $100 |
| [pydantic](https://github.com/pydantic/pydantic) | [pydantic](https://github.com/pydantic) | $500 |
| [codehike](https://github.com/code-hike/codehike) | [pomber](https://github.com/pomber) | $299 |
| [zod](https://github.com/colinhacks/zod) | [colinhacks](https://github.com/colinhacks) | $499 |
| [openapi-codegen](https://github.com/oapi-codegen/oapi-codegen) | [jamietanna](https://github.com/jamietanna) | $150 |
| [openapi-typescript](https://github.com/openapi-ts/openapi-typescript) | [drwpow](https://github.com/drwpow) | $250 |
| [FastAPI](https://github.com/fastapi/fastapi) | [tiangolo](https://github.com/tiangolo) | $250 |
| [Goa](https://github.com/goadesign/goa) | [raphael](https://github.com/raphael) | $125 |
| [HTTPX](https://github.com/encode/httpx) | [Encode](https://github.com/encode) | $400 |
| [OpenAPI](https://github.com/OAI/OpenAPI-Specification) | [handrews](https://github.com/handrews) | $50 |

## Why we support open source

Like any software company in 2024, our success stands on the shoulders of open-source giants. Many of the projects we sponsor have been crucial in developing our product, while others play a vital role in maintaining a healthy API development ecosystem.

## Thank you, OSS community

To all the maintainers, contributors, and issue raisers behind these open-source projects: thank you. Your dedication and hard work have not only made our work possible but have also paved the way for countless other developers and companies to innovate and succeed.

We hope others will join us in supporting open-source software to create a sustainable future for the tools and technologies that power innovation.


 This is the content for the doc blog/openapi-has-flaws/index.md 

 ---
title: "OpenAPI has flaws, so what?"
description: "Why we decided to use OpenAPI instead of a DSL, despite its flaws."
image: "/media/openapi-has-flaws.png"
date: 2025-02-11
authors:
  - name: Sagar Batchu
  - image_url: '/media/author-headshots/sagar.jpeg'
tags:
  - Building Speakeasy
featured_image: "/media/openapi-has-flaws.png"
---

When we started Speakeasy, we considered creating a DSL (domain-specific language). Our goal was to autogenerate SDKs from our user’s API configuration files. Creating a DSL would’ve allowed us to design the exact SDK configurations available to our users.

However, we decided against it. Instead, we opted for the preexisting [OpenAPI standard](https://swagger.io/specification/), which is indisputably the most popular standard for defining REST APIs. A typical OpenAPI spec details the API routes, inputs, and expected outputs. They are either handwritten or (increasingly) autogenerated by popular API frameworks such as [FastAPI](https://fastapi.tiangolo.com).

Years later, we are confident that we made the right choice. Using OpenAPI admittedly created some complexity for us — and we are stuck with the verbosity of the spec — but we also believe that our product wouldn’t be where it is today had we built a DSL.

Today, I want to share our learnings in hopes that it will encourage developers to use existing standards as a default choice instead of creating their own (provided that workarounds exist to avoid future limitations).

## Why we considered a DSL

The benefit of creating a DSL is that we could start with a clean slate. We could strictly focus on what matters to our generated SDKs; we wouldn’t have to navigate all the cruft and endless permutations of a preexisting spec. 

Another advantage is that DSLs (when done well) are a design-first strategy *that actually gets used*. While OpenAPI can also theoretically be used as a design-first language, its verbosity means it’s more often autogenerated by an API framework. Accordingly, developers aren’t forced to sit down and think through their SDK’s design as a DSL user would have to. 

Ultimately, we believe these benefits of opting for a DSL are overwhelmingly mitigated by the advantages of using a widely adopted spec. Let me explain why. 

## The flagship advantage of a preexisting standard

The flagship argument of using a widely accepted standard is that it creates the best long-term developer experience. Developers are either already familiar with the spec or can benefit from tools that autogenerate it. In the case of OpenAPI, it’s primarily the latter. 

The ubiquity of OpenAPI creates other benefits. OpenAPI has a huge community, meaning errors and quirks are well-documented and easy to learn. Additionally, the spec doesn’t exist in a vacuum — it’s part of a larger ecosystem. For example, OpenAPI users can tap into [Arazzo](https://www.openapis.org/arazzo), OpenAPI’s workflow and a tooling ecosystem that can provide docs, testing, and more. 

A DSL doesn’t technically eliminate the OpenAPI spec; it just exists in parallel to it. However, it still chips at the benefits of a universal spec because it distracts developer focus from one unified source of truth.

## The beauty of vendor extensions

The main limitation of OpenAPI is that it doesn’t support every desired feature, especially features pertinent to building scale-friendly SDKs. Thankfully, OpenAPI was designed with a built-in strategy for handling these deficits: vendor extensions.

[Vendor extensions](https://swagger.io/docs/specification/v3_0/openapi-extensions/) are an OpenAPI feature that enables companies building on the spec (such as Speakeasy) to expand it. A vendor extension involves adding additional fields to the OpenAPI spec, enabling end users to expand their OpenAPI spec’s coverage.

Speakeasy’s vendor extensions are what makes Speakeasy possible. Without them, we’d have to defer to a DSL (despite the issues) to accommodate missing OpenAPI features such as pagination, streaming, and retry automation. With vendor extensions, we get the best of both worlds; it negates the myth that DSLs produce better code. In fact, vendor extensions can enable the *best* code generation. We put our energy into building a great OpenAPI linter that can encourage the best practices — bandwidth that would otherwise be spent on creating a new spec from the ground up.

## The curious case of vendor lock-in

Another common argument for universal standards is that they don’t subject users to vendor lock-in. However, I hesitate to grandstand on this. Yes, OpenAPI minimizes technical debt should a customer want to switch providers. But it also doesn’t exactly eliminate lock-in.

One of the main reasons that customers opt for solutions like Speakeasy over [OpenAPI’s built-in SDK generator](https://github.com/OpenAPITools/openapi-generator) is due to improved code quality and coverage—made possible by Speakeasy’s vendor extension. Accordingly, we still subject our users to *some* vendor lock-in. We also enforce some opinionated (and popular) conventions, such as mandating [Zod](https://zod.dev) for schema validation and `oneOf` structs over `anyOf` structs. These design standards aren’t specific to Speakeasy but do encourage users to stay, as they’re compatible with our *flavor* of SDK generation.

However, in our defense, the goal of vendor extensions is strictly to patch coverage. Our value proposition is providing top-tier SDK generation; a comprehensive vendor extension is just a byproduct of that mission. Our dream outcome would be for OpenAPI to integrate concepts from our vendor extension into their spec, with our users gradually migrating to the unified standard. And this isn’t a pipe dream — we’ve been able to make real suggestions to the OpenAPI technical steering committee by referencing how we address gaps in the spec with our opinionated choices (such as [this example re. server-side events](https://github.com/OAI/OpenAPI-Specification/discussions/4171#discussioncomment-11348781)).

## A closing thought

I want to close on my general worldview of existing standards/specs: If the standard gets you 70% there, it’s better to fill in the gaps and nudge the community’s developers in the right direction. Otherwise, creating a brand-new “all-encompassing” spec runs into the problem in this xkcd strip: 

![XKCD standards comic](./assets/standards.png)

Developer experience of the tooling you sell matters, but your tool doesn’t exist in a vacuum. We don’t want to hurt the long-form developer experience because of a prideful notion that we could create a better experience than OpenAPI. End of day, OpenAPI is and will remain the most popular standard because it’s supported across tools. It’s better for us to leverage OpenAPI’s foundation, play nice with the existing ecosystem, and unlock new features through OpenAPI’s extensibility features that exist for a reason!

 This is the content for the doc blog/openapi-reference-guide/index.mdx 

 ---
title: Everything You Need to Know About OpenAPI
description:
image: "/media/openapi-ref-post1.png"
date: 2024-05-17
authors:
  - name: Nolan Di Mare Sullivan
  - image_url: "/media/author-headshots/nolan.jpeg"
tags:
  - OpenAPI Tips
featured_image: "/media/openapi-ref-post1.png"
---

[Speakeasy has released a comprehensive, Open Source reference to writing OpenAPI specifications.](/openapi/)

The reference has AI-search built in to help you quickly answer any questions that you may have.

If you are interested in contributing, the GitHub repo can be found [here](https://github.com/speakeasy-api/openapi-reference-documentation).

## Why is OpenAPI Important?

Consistent API design is essential. Building an API that developers enjoy interacting with, turns a SaaS business into a platform. However great design is only useful if it's well-documented and consistently represented across every API surface area (docs, SDKs, etc.).

That is where OpenAPI comes in. Trying to create and maintain all your surfaces manually will inevitably lead to frustration and inconsistencies. With OpenAPI, you get much greater visibility into your API, and you can unify all aspects of your errors, responses, and parameters, ensuring consistency.

If you are building a RESTful API, OpenAPI should be the source of truth that automates the creation of all your public surfaces (docs, SDKs, etc.)

![OpenAPI Spec](https://media.dev.to/cdn-cgi/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fxpq5c4ylckm40252u96r.png)

This documentation will help you understand the OpenAPI Specification.

## What is OpenAPI?

When we refer to OpenAPI, we mean the OpenAPI Specification - a standardized document structure for describing HTTP APIs in a way that humans and computers can understand.

OpenAPI files are written as JSON or YAML, describing your API using a standard vocabulary defined by the Specification - we'll call this JSON or YAML file an OpenAPI document.

A valid OpenAPI document describes your RESTful API and serves as the instruction set for tooling that generates API documentation, SDKs, and more. We will refer to an app or tool that reads an OpenAPI document to perform an action as an OpenAPI tool. Speakeasy is one such tool, a full list can be found here.

## OpenAPI Document Basics

Your OpenAPI document is composed of keywords (some required, some optional). Together, the document covers the key elements of your API:

- What security is required to access it?
- Which endpoints expose which resources?
- How are those resources constructed?

```yaml
openapi: 3.1.0
info:
  title: The Speakeasy Bar
  version: 1.0.0
servers:
  - url: https://speakeasy.bar
    description: The production server
security:
  - apiKey: []
tags:
  - name: drinks
    description: Operations related to drinks
paths:
  /drinks:
    get:
      tags:
        - drinks
      operationId: listDrinks
      summary: Get a list of drinks
      responses:
        "200":
          description: A list of drinks
          content:
            application/json:
              schema:
                type: array
                items:
                  $ref: "#/components/schemas/Drink"
components:
  schemas:
    Drink:
      type: object
      title: Drink
      properties:
        name:
          type: string
        price:
          type: number
  securitySchemes:
    apiKey:
      type: apiKey
      name: Authorization
      in: header
```

To break that down piece by piece:

`openapi`: The version of the OpenAPI Specification that the document conforms to, should be one of the supported versions.

```yaml
openapi: 3.1.0
```

Note: Speakeasy tooling currently only supports OpenAPI Specification versions 3.0.x and 3.1.x.

`info`: Contains information about the document including fields like `title`, `version`, and `description` that help to identify the purpose and owner of the document.

```yaml
info:
  title: The Speakeasy Bar
  version: 1.0.0
```

`servers`: Contains an optional list of servers the API is available on. If not provided, the default URL is assumed to be /, a path relative to where the OpenAPI document is hosted.

```yaml
servers:
  - url: https://speakeasy.bar
    description: The production server
```

`security`: Contains an optional list of security requirements that apply to all operations in the API. If not provided, the default security requirements are assumed to be [], an empty array.

```yaml
security:
  - apiKey: []
```

`tags`: Contains an optional list of tags that are generally used to group or categorize a set of Operations.

```yaml
tags:
  - name: drinks
    description: Operations related to drinks
paths:
  /drinks:
    get:
      tags:
        - drinks
      operationId: listDrinks
      summary: Get a list of drinks
```

`paths`: Contains the paths and operations available within the API.

```yaml
paths:
  /drinks:
    get:
      tags:
        - drinks
      operationId: listDrinks
      summary: Get a list of drinks
      responses:
        "200":
          description: A list of drinks
          content:
            application/json:
              schema:
                type: array
                items:
                  $ref: "#/components/schemas/Drink"
```

`components`: Contains an optional list of reusable schemas that can be referenced from other parts of the document. This improves the readability and maintainability of the document by allowing common schemas to be defined once and reused in multiple places.

```yaml
components:
  schemas:
    Drink:
      type: object
      title: Drink
      properties:
        name:
          type: string
        price:
          type: number
  securitySchemes:
    apiKey:
      type: apiKey
      name: Authorization
      in: header
```

## Format and File Structure

An OpenAPI document is a JSON or YAML file that contains either an entire API definition or a partial definition of an API and/or its components. All field names in the specification are case-sensitive unless otherwise specified.

A document can be split into multiple files, and the files can be in different formats. For example, you can have a JSON file that contains the API definition and a YAML file that contains the components, or a collection of files that contain partial definitions of the API and its components.

Generally, the main API definition file is called `openapi.json` or `openapi.yaml`, and the component files are called `components.json` or `components.yaml`, though this is not a requirement.

Some common organizational patterns for OpenAPI documents are:

- A single file that contains the entire API definition.
- A main file that contains the API definition and a components file that contains the components.
  - This is normally achieved by using the $ref keyword to reference the components file from the main file. Click here for more information on references.
- A collection of files that contain partial definitions of the API and its components.
  - Some tools support this pattern by allowing multiple files to be provided. Others, such as the Speakeasy Generator, require the individual files to be merged into a single file before being passed to the tool, which can be achieved using the Speakeasy CLI tool. Click here for more information on the Speakeasy CLI merge tool.

## How is this different from the official OpenAPI documentation?

The goal of this documentation is to provide a practitioner's guide for developers interested in understanding the impact of OpenAPI design on their downstream API surfaces. This guide prioritizes approachability and practicality over technical completeness.

We've structured the documentation according to the needs of OpenAPI users of any skill level.

## Which versions of the OpenAPI Specification does this documentation cover?

There are several versions of the OpenAPI specification in circulation: 2.0 (also known as Swagger), 3.0, and 3.1. We recommend developers use OpenAPI version 3.1 for all projects. The advantage of using OpenAPI version 3.1 is that it is fully compatible with JSON Schema, which gives you access to a much larger ecosystem of tools and libraries.

Speakeasy's documentation covers versions `3.0.x` and `3.1.x` of the OpenAPI specification. Where there is an important difference between the two versions, we call it out specifically, otherwise, the documentation will apply to both versions.


 This is the content for the doc blog/openapi-servers/index.mdx 

 ---
title: "Defining OpenAPI Servers - The Where To Your API's How"
description: "Tips and best practices for defining servers in your OpenAPI document"
keywords: [openapi, api]
image: "/media/openapi-tips-servers.png"
date: 2023-11-24
authors:
  - name: Nolan Sullivan
  - image_url: "https://uploads-ssl.webflow.com/62ccd7b208cab0723d026273/62cdf9e45dcbb4d20be59f5f_head.jpeg"
tags:
  - OpenAPI Tips
featured_image: "/media/openapi-tips-servers.png"
---

import { ScrollyCoding } from "~/components/codehike/Scrollycoding";
import { Callout } from "~/components";

<Callout title="Announcing: OpenAPI Reference" variant="success">
Hi! These blog posts have been popular, so we've built an entire [OpenAPI Reference Guide](/openapi/) to answer any question you have.

It includes detailed information on [**servers**](/openapi/servers).

Happy Spec Writing!

</Callout>

In this post, we'll take a detailed look at how the OpenAPI Specification (OAS) allows us to define servers in our OpenAPI documents (OADs), then at a few tips to help you provide the best developer experience for your users.

This aspect of API design is often overlooked, but specifying servers in a flexible and robust way can ensure your users know exactly where to send API calls, allows users the flexibility to pick a specific server based on their preference or data-privacy requirements, and allows your developers to switch between development and production environments while testing without editing code.

## A Brief History of Base URLs in Swagger (OAS 2.0)

If you have some experience with Swagger 2.0, the predecessor to OpenAPI 3.0, you may recall that specifying servers for your API was somewhat rigid. We're including this to show you how to convert your Swagger 2.0 base URL definition to OpenAPI 3.x later on. If you don't have a Swagger 2.0 document, you can safely skip this section.

In Swagger 2.0, we could define three fields to tell API users where to send requests: `host`, `basePath`, and `schemes`. The `host` specified the domain name or IP, the `basePath` defined the base path for the API, and `schemes` determined the protocols (HTTP or HTTPS) as an array.

Here's an example of the relevant Swagger 2.0 fields:

```yaml swagger-2.0.yaml
swagger: "2.0"
host: api.example.com
basePath: /v1
schemes:
  - https
  - http
# ...
```

To construct the base URL for requests, the API user should select a scheme, then concatenate the strings to form the URL: `schemes[n] + host + basepath`.

![Screenshot of Swagger 2.0 editor showing the scheme selector as the only URL-related option](./assets/scheme.png)

The screenshot above illustrates the scheme selector in the Swagger 2.0 editor. The scheme selector is the only option for building a base URL in Swagger 2.0.

## Servers in OAS 3.x - Controlled Flexibility

In response to the need for more flexibility, OAS 3.0 introduces the optional `servers` schema. The `servers` schema allows API users to select a base URL from an array of servers, some of which can include variables - allowing for the construction of more complex base URLs.

Each server in the `servers` array consists of an object with at least one field, `url`. Each server object can also contain an optional `description` field, as well as an optional array of `variables`.

<ScrollyCoding fullHeight>

## !!steps

Let's look at an OpenAPI 3.1.0 document with three different server objects to illustrate the available options, and how they influence the Swagger UI server selector.

```yaml ! openapi.yaml focus=2:18
!from ./assets/openapi-3.yaml
```

---

## !!steps

The first server object is the simplest. It contains only a `url` field, which is a string containing the base URL for the API: `https://speakeasy.bar`.

```yaml ! openapi.yaml focus=2:3
!from ./assets/openapi-3.yaml
```

---

## !!steps

The second server object contains a `url` field and a `description` field. The `description` field is a string that can be used to describe the server. This is useful for providing additional information about the server, such as its location or purpose.

```yaml ! openapi.yaml focus=4:5
!from ./assets/openapi-3.yaml
```

---

## !!steps

In our example, the `description` field is used to describe the server as the staging server.

```yaml ! openapi.yaml focus=4:5 mark=4[16:34]
!from ./assets/openapi-3.yaml
```

---

## !!steps

The third server object contains a `url` field, a `description` field, and a `variables` field. The `variables` field is an array of objects that define variables that can be used to construct the base URL.

```yaml ! openapi.yaml focus=6:18
!from ./assets/openapi-3.yaml
```

---

## !!steps

In this example, the URL is a template string that contains two variables: `organization` and `environment`.

```yaml ! openapi.yaml focus=7 mark=7[17:28],7[32:42]
!from ./assets/openapi-3.yaml
```

---

## !!steps

Each variable's name is defined by the object's key.

```yaml ! openapi.yaml focus=6:18 mark=9,16
!from ./assets/openapi-3.yaml
```

---

## !!steps

The `default` field is a string that defines the default value for the variable.

```yaml ! openapi.yaml focus=6:18 mark=10,17
!from ./assets/openapi-3.yaml
```

---

## !!steps

The `enum` field is an array of strings that define the possible values for the variable.

```yaml ! openapi.yaml focus=6:18 mark=12:15
!from ./assets/openapi-3.yaml
```

---

## !!steps

The `description` field is a string that can be used to describe the variable. This is useful for providing additional information about the variable, such as its purpose.

This field is not used by the OpenAPI documentation generator, but it can be used by other tools to provide additional information to API users.

```yaml ! openapi.yaml focus=6:18 mark=11,18
!from ./assets/openapi-3.yaml
```

</ScrollyCoding>

## Steps to Adapt Swagger 2.0 URL Definitions to OpenAPI 3.x

1. Identify Swagger 2.0 URL Components: Extract the `host`, `basePath`, and `schemes` values from your Swagger 2.0 document.

2. Create the servers array: Initiate a `servers` array in your OpenAPI 3.x document.

3. Translate URL Components: For each scheme in your Swagger 2.0 document, create a `server` object in the OpenAPI 3.x `servers` array. Combine the `scheme`, `host`, and `basePath` to form the `url` field of each server object.

For example, if your Swagger 2.0 document contains the following URL components:

```yaml swagger-2.0.yaml
swagger: "2.0"
host: api.example.com
basePath: /v1
schemes:
  - https
  - http
```

You would create the following `servers` array in your OpenAPI 3.x document:

```yaml openapi.yaml
openapi: 3.1.0
servers:
  - url: https://api.example.com/v1
  - url: http://api.example.com/v1
```

## Best Practices for Defining Servers in OpenAPI

When defining servers in an OpenAPI document, it's crucial to strike a balance between flexibility and clarity. The goal is to provide enough information for users to understand and use the API effectively while allowing for various deployment scenarios.

Here are some best practices to keep in mind:

1. **Provide clear and concise descriptions:** When using the `description` field, ensure it clearly indicates the purpose or specific use case of each server. This is particularly helpful in multiserver setups where different servers serve different roles, such as development, staging, and production.

2. **Use variables judiciously:** Variables offer great flexibility but can also introduce complexity. Use them sparingly and only when necessary, such as when users have unique base URLs or need to select a specific environment.

3. **Document server variables thoroughly:** If you use variables in your server URLs, provide clear documentation on what each variable represents and the valid values (`enum`) it can take. This documentation is crucial for users who need to understand how to construct the URLs correctly.

4. **Consider including common environment URLs:** While variables offer flexibility, sometimes it's easier for users if you explicitly list common environments (like `production`, `staging`, `development`) as separate server entries. This approach reduces the need for users to understand and manipulate variables.

5. **Validate server URLs regularly:** Use automated tools to validate that the URLs in the `servers` section are up to date and operational. This check is particularly important for APIs that undergo frequent changes or have multiple deployment environments.

6. **Stay consistent across documents:** If you manage multiple OpenAPI documents, maintain consistency in how servers are defined across them. This consistency helps users who work with multiple APIs in your suite, making it easier to understand and switch between them.

By following these best practices, you can ensure that your OpenAPI server definitions are both functional and user-friendly, enhancing the overall usability and accessibility of your API.

## Advanced Server Definitions: Using Variables

Server variables offer significant flexibility and adaptability when defining servers. This approach is especially useful in scenarios where the base URL of an API might change based on different environments (like production, staging, or development) or other factors (like user-specific or regional settings). Here's how to leverage variables effectively in your OpenAPI server definitions.

### Understanding Variables in Server URLs

1. **Defining variables:** Variables in OpenAPI are defined within the `servers` array. Each server object can have a `variables` field, which is an object itself. This object contains keys representing variable names, each with its set of properties.

2. **Properties of variables:** The properties of a variable can include:

   - `default`: A mandatory field that specifies the default value of the variable.
   - `enum`: An optional array of possible values the variable can take.
   - `description`: An optional field to describe the variable's purpose or usage.

3. **Using variables in URLs:** Variables are used within the `url` field of a server object, enclosed in curly braces `{}`. For example, `https://{environment}.api.example.com`.

### Best Practices for Using Variables

1. **Name variables clearly:** Choose clear and descriptive names for your variables. Names like `environment`, `region`, or `version` can be more intuitive for users to understand and use.

2. **Use sensible defaults:** Always provide sensible default values that point to the most common or recommended server configuration. This approach ensures that the API can be used out of the box without requiring users to modify the server URL.

3. **Restrict values with enums:** When appropriate, use `enum` to restrict the values that a variable can take. This is particularly useful for environment variables where only specific values like `production`, `staging`, and `development` are valid.

4. **Descriptive documentation:** Each variable should be accompanied by a description that explains its purpose and how it should be used. This is crucial for users who are unfamiliar with your API or its configuration options.

5. **Test variable-driven URLs:** Ensure that all combinations of variables and their values lead to valid and accessible API endpoints. This testing is critical to avoid configuration errors that could make the API unusable.

### Example of a Variable-Driven Server Definition

```yaml openapi.yaml
openapi: 3.1.0
servers:
  - url: https://{environment}.api.example.com/v1
    description: API server - selectable environment
    variables:
      environment:
        default: production
        enum:
          - production
          - staging
          - development
        description: Deployment environment of the API
```

In this example, the `environment` variable allows users to switch between different deployment environments without the need for separate server entries for each one.

Use variables in server definitions to enhance the flexibility and scalability of your API configurations, catering to a wide range of deployment scenarios and user needs.

## Servers at the Path or Operation Level

While it's common to define servers at the global level in OpenAPI documents, there are cases where specifying servers at the path or operation level is essential. This approach allows for more granular control, enabling different parts of the API to interact with different servers. It's particularly useful in microservices architectures, where different services may reside on different servers, or when specific operations require a unique endpoint.

### Overriding Servers at Path or Operation Level

1. **Path-level servers:** You can specify servers for individual paths. This is useful when different paths in your API are hosted on different servers. For instance, if your API handles file uploads and general data requests separately, you might have different servers handling each.

2. **Operation-level servers:** Similarly, servers can be specified for individual operations (GET, POST, PUT, DELETE, etc.). This granularity is beneficial when a specific operation, like a data submission (POST request), needs to be directed to a distinct server, like a secure data processing server.

### Best Practices

- **Clear documentation:** Clearly document why certain paths or operations use different servers. This clarity helps developers understand the API's architecture and its interaction with various servers.
- **Consistency in structure:** If you have different servers for different paths or operations, maintain a consistent structure in how these are defined to avoid confusion.

- **Fallback to global servers:** Ensure that there is always a fallback server defined at the global level. This fallback acts as a default in cases where a path or operation doesn't explicitly specify a server.

### Example of a Server Definition at the Path Level

Consider an API where file uploads are handled by a dedicated server. Here's how you might define this at the path level:

```yaml
paths:
  /upload:
    servers:
      - url: https://upload.api.example.com
        description: Dedicated server for file uploads
    post:
      summary: Upload a file
      # ... other operation details ...
```

In this example, any POST requests to the `/upload` path would be directed to the specified upload server, differentiating it from other operations in the API that use the default global server.

By strategically using servers at the path or operation levels, you can effectively manage different aspects of your API's functionality, ensuring that each part interacts with the most appropriate server.

## Case Studies: Effective Server Definitions in OpenAPI

We'll now look at a few examples of how different companies have used OpenAPI server definitions to enhance their APIs' usability and functionality.

### Stripe: Path-Level Servers for File Uploads

Stripe's OpenAPI documentation offers an excellent example of using path-level servers. In the Stripe API, the endpoint for file uploads is directed to the `https://files.stripe.com/` server, optimized for handling large data transfers. This separation ensures that the file upload process does not interfere with the regular API traffic and provides a more efficient way to handle resource-intensive operations.

The following excerpt from [Stripe's OpenAPI document](https://raw.githubusercontent.com/stripe/openapi/master/openapi/spec3.yaml) illustrates this setup:

```yaml stripe.yaml focus=6:7
openapi: 3.0.0
paths:
  /v1/files:
    post:
      operationId: PostFiles
      servers:
        - url: "https://files.stripe.com"
      # ... other operation details ...
servers:
  - url: "https://api.stripe.com"
```

This setup demonstrates a clear understanding of operational requirements and a commitment to providing a seamless user experience.

Stripe's OpenAPI document could be further enhanced by providing a fallback global server in case the file server is unavailable and documenting the reason for using a separate server for file uploads.

### Datadog: Dynamic Server Selection with Variables

Datadog's API, known for its scalability and flexibility, leverages variables in server definitions to allow users to select their preferred region. This feature is particularly useful for global services where latency and data residency are critical considerations.

<ScrollyCoding>

## !!steps

This excerpt from [Datadog's OpenAPI document](https://github.com/DataDog/datadog-api-client-python/blob/master/.generator/schemas/v2/openapi.yaml) illustrates this setup.

```yaml ! datadog.yaml
openapi: 3.0.0
servers:
  - url: https://{subdomain}.{site}
    variables:
      site:
        default: datadoghq.com
        description: The regional site for Datadog customers.
        enum:
          - datadoghq.com
          - us3.datadoghq.com
          - us5.datadoghq.com
          - ap1.datadoghq.com
          - datadoghq.eu
          - ddog-gov.com
      subdomain:
        default: api
        description: The subdomain where the API is deployed.
  - url: "{protocol}://{name}"
    variables:
      name:
        default: api.datadoghq.com
        description: Full site DNS name.
      protocol:
        default: https
        description: The protocol for accessing the API.
  - url: https://{subdomain}.{site}
    variables:
      site:
        default: datadoghq.com
        description: Any Datadog deployment.
      subdomain:
        default: api
        description: The subdomain where the API is deployed.
paths:
  /api/v2/logs:
    post:
      operationId: SubmitLog
      servers:
        - url: https://{subdomain}.{site}
          variables:
            site:
              default: datadoghq.com
              description: The regional site for customers.
              enum:
                - datadoghq.com
                - us3.datadoghq.com
                - us5.datadoghq.com
                - ap1.datadoghq.com
                - datadoghq.eu
                - ddog-gov.com
            subdomain:
              default: http-intake.logs
              description: The subdomain where the API is deployed.
        - url: "{protocol}://{name}"
          variables:
            name:
              default: http-intake.logs.datadoghq.com
              description: Full site DNS name.
            protocol:
              default: https
              description: The protocol for accessing the API.
        - url: https://{subdomain}.{site}
          variables:
            site:
              default: datadoghq.com
              description: Any Datadog deployment.
            subdomain:
              default: http-intake.logs
              description: The subdomain where the API is deployed.
```

---

## !!steps

In this example, users can dynamically choose the region closest to them, enhancing the performance and reliability of the API.

```yaml ! datadog.yaml focus=3:17

```

---

## !!steps

The `site` variable allows users to select the regional site for Datadog customers.

```yaml ! datadog.yaml focus=3:17 mark=4:14

```

---

## !!steps

The `enum` field restricts the possible values to the available regional sites.

```yaml ! datadog.yaml focus=3:17 mark=8:14

```

---

## !!steps

Datadog also uses operation-level servers to direct log uploads to the appropriate server.

```yaml ! datadog.yaml focus=38:53 mark=51:53

```

</ScrollyCoding>

## Conclusion: The Impact of Well-Defined Servers in API Usability

The way servers are defined in OpenAPI documents can significantly impact the usability and effectiveness of an API. Well-defined servers provide clear, accessible endpoints for different operational needs, improve the developer experience, and foster trust in the API's reliability and efficiency. Key benefits include:

- **Enhanced clarity:** Clear server definitions help developers understand where and how to interact with the API.
- **Operational flexibility:** Using variables and specifying servers at different levels (global, path, and operation) allows for greater operational flexibility and efficiency.
- **Improved performance:** Strategic server allocation, such as dedicated endpoints for resource-intensive tasks, optimizes API performance.
- **Global scalability:** Variables that allow for regional server selection make the API more adaptable to global users, addressing concerns like latency and data residency.

## Additional Resources and Tools for OpenAPI Server Definition

If you're interested in deepening your understanding of OpenAPI server definitions, we recommend the following resources and tools:

1. **OpenAPI Specification:** The official [OpenAPI Specification](https://spec.openapis.org/oas/v3.1.0#server-object) documentation provides comprehensive guidance on server definitions and other aspects of OpenAPI.
2. **Swagger Editor:** An online tool that helps visualize and [edit OpenAPI documents](https://editor-next.swagger.io/), making it easier to define and review server configurations.
3. **The OpenAPI Specification Explained: API Servers:** A detailed [guide to the OpenAPI Servers](https://learn.openapis.org/specification/servers.html) that explains the different aspects of server definitions and how to use them effectively.
4. **Speakeasy documentation:** Our documentation on how to [configure your servers](/docs/customize-sdks/servers) in OpenAPI while creating SDKs with Speakeasy.


 This is the content for the doc blog/openapi-tips-auth.mdx 

 ---
title: "OpenAPI Tips - How to Handle Auth"
description: "Tips & Best practices for how to correctly configure auth in your OpenAPI spec."
keywords:
  [
    openapi,
    swagger,
    authenticaiton,
    auth,
    api key,
    oauth2,
    openidconnect,
    bearer tokens,
    tokens,
    sdk generation,
    sdk,
  ]
image: "/media/openapi-tips-auth.png"
date: 2022-11-03
authors:
  - name: Tristan Cartledge
  - image_url: "https://uploads-ssl.webflow.com/62ccd7b208cab0723d026273/635ff12733f46637e91ced22_1516859875198.jpg"
tags:
  - OpenAPI Tips
featured_image: "/media/openapi-tips-auth.png"
---

import { Callout } from "~/components";

<Callout title="Announcing: OpenAPI Reference" variant="success">
Hi! These blog posts have been popular, so we've built an entire [OpenAPI Reference Guide](/openapi/) to answer any question you have.

It includes detailed information on [**API authentication**](/openapi/security).

Happy Spec Writing!

</Callout>

## The Problem

The OpenAPI spec is best known for descriptions of RESTful APIs, but it’s designed to be capable of describing any HTTP API whether that be REST or something more akin to RPC based calls. That leads to the spec having a lot of flexibility baked-in; there's a lot of ways to achieve the exact same result that are equally valid in the eyes of the spec. Because of this, [the OpenAPI](https://spec.openapis.org/oas/v3.1.0#operation-object) documentation is very ambiguous when it comes to how you should define your API. That’s why we’d like to take the time to eliminate some of the most common ambiguities that you’ll encounter when you build your OpenAPI spec. In this case we’ll be taking a look at **how to correctly configure auth in your OpenAPI spec.**

## What Authentication mechanisms are available?

OpenAPI supports a number of different options for API authentication, which can be daunting when first starting out. Before we give our thoughts on the different methods, it’s worth highlighting that regardless of the method of authentication you choose, you should pair it with TLS. TLS encrypts the messages to and from your API, to protect you and your users from attack. [Learn more about setting up TLS here](https://letsencrypt.org/getting-started/). Some of the common types of authentication are listed below:

- **apiKey**: This is the most common form of authentication for machine-to-machine (M2M) APIs and supports passing a pre-shared secret in a number of different ways i.e. either via the _Authorization_ header (or another custom header), as a query parameter, or via a cookie. While this is probably the most commonly used mechanism, it is generally one of the least secure. This is especially true if the key is passed outside of headers or cookies (i.e. via query params as various logging mechanisms normally store query param information). The biggest security flaw is that most pre-shared secrets are long lived and if intercepted can be used until they are either revoked or expire (generally in a number of months or years). This risk is normally tolerated for M2M applications as the chance of interception (especially when using private VPCs/TLS and other mechanisms) is relatively low when compared to a key from a user’s device traveling on a public network.
- **basic**: This is a simple authentication mechanism baked into the HTTP protocol. It supports sending an _Authorization_ header containing an encoded username and password. While this can be a relatively simple mechanism to get started with, if used incorrectly can risk leaking easy to decode passwords. It also shares a lot of the downsides of apiKeys below.
- **bearer**: This scheme allows the passing of a token (most commonly a JWT) in the _Authorization_ header. This is generally used for short lived tokens that are granted to the users of your API through an additional login mechanism. Using a JWT allows for the storage of additional metadata within the token which can be helpful for some use cases, such as storing scopes for permissions models.
- **oauth2**: A popular open authentication mechanism that supports an authentication flow that allows servers to authenticate on behalf of a user or organization. While more generally used for authenticating clients and end-users it is quite often used in machine-to-machine applications as well, but is less popular due to the added complexity of the authentication flows. OAuth2 is considered more secure than other mechanisms due to its granted privileges through short lived tokens, that limit damage from intercepting the tokens.
- **openIdConnect**: Is an authentication mechanism built on top of OAuth2 that allows obtaining identity information about the authenticating user via JWTs.

## Global Authentication vs Endpoint Authentication

The OpenAPI specification allows you to describe all the above authentication mechanisms and more from the [HTTP Authentication Scheme Registry](https://www.iana.org/assignments/http-authschemes/http-authschemes.xhtml).

Describing security in your OpenAPI document is then done through 1 of 2 different options:

- **Global security**: the security you describe is available for all operations in your document.
- **Per operation security:** when described it overrides any global level security described.

Here is an example of describing security in the ways mentioned above:

```yaml
openapi: 3.0.3
info:
  title: Example Security Definitions
  version: 1.0.0
servers:
  - url: http://api.prod.speakeasyapi.dev
# Here we are describing the Global security schemes used by the operations in this document
# This is a list of security schemes names defined in the components section
security:
  - APIKey: []
components:
  # The definition of the used security schemes
  securitySchemes:
    APIKey:
      type: apiKey
      in: header
      name: X-API-Key
    Bearer:
      type: http
      scheme: bearer
      bearerFormat: JWT
paths:
  /test:
    get:
      # The security schemes defined here will override the global security schemes for this operation
      security:
        - Bearer: []
      responses:
        200:
          description: OK
    # This operation used the global security schemes defined as it doesn't provide its own
    delete:
      responses:
        200:
          description: OK
```

The important parts of the above example are the [security](https://spec.openapis.org/oas/v3.1.0#security-requirement-object) and [securitySchemes](https://spec.openapis.org/oas/v3.1.0#security-scheme-object/security-schemes) sections. We will go into some details about how they are defined and the options available.

## How To Describe Security

The [security](https://spec.openapis.org/oas/v3.1.0#security-requirement-object) section is a list (actually a list of key-value pairs, but we will talk a bit more about that later) of security schemes that can be used to authenticate all operations or a particular operation (depending on the scope of the [security](https://spec.openapis.org/oas/v3.1.0#security-requirement-object) list).

Below is an example of a number of different ways you can use the [security](https://spec.openapis.org/oas/v3.1.0#security-requirement-object) section of your document:

```yaml
# The below example shows a single mandatory scheme needed for the API
security:
  - APIKey: []
# The below example shows that one of the below schemes is required for the API
security:
  - APIKey: []
  - Bearer: []
# The below example shows there is no security required for the API
# this is equivalent to not having a security section at all at the Global scope
# or disabling security at the per operation level
security: []
# The below example shows that security is optional for the API
# this may be used if an API provides additional functionality when authenticated
security:
  - APIKey: []
  - {}
# The below example shows that certain scopes are required by the OAuth token used
# to authenticate the API
security:
  - OAuth:
    - read
    - write
```

The items in the list are key-value pairs with a name or key of a security scheme defined in the components section. We recommend giving them a boring name that explains what they are.

The values are an array of scopes used only by the [oauth2](https://spec.openapis.org/oas/v3.1.0#oauth2-security-requirement) and [openIdConnect](https://tools.ietf.org/html/draft-ietf-oauth-discovery-06) type schemes, and define what scopes are needed for the API.

When used as shown above it provides a list of available schemes that can be used, with the end-user of the API being able to choose one of the available schemes to use to authenticate.

If more than one scheme is required to authenticate an API, then that is where additional pairs in the key-value pairs come in. See the example below:

```yaml
# The below example shows 2 options for an end user to choose, as long as they use one or the other
# they will be able to access the API
security:
  - APIKey: []
  - Bearer: []
# The example below differs as it is a single option with multiple schemes
# Both the APIKey and SigningKey need to be used together to access the API
security:
  - APIKey: []
    SigningKey: []
# The example below shows multiple options for an end user to chose
# with one of them requiring the use of multiple schemes
security:
  - APIKey: []
    SigningKey: []
  - Bearer: []
```

Combining schemes like above give you the option to define AND/OR type functionality when it comes to the requirements of your API.

## How To Describe Security Schemes

[securitySchemes](https://spec.openapis.org/oas/v3.1.0#security-scheme-object/security-schemes) are the actual details of the options provided in the [security](https://spec.openapis.org/oas/v3.1.0#security-requirement-object) sections of your document. The security schemes are components that are defined with the [components](https://spec.openapis.org/oas/v3.1.0#components-object) section of your document. Below is an example of the 5 types of security schemes described above and how they are defined:

```yaml
---
components:
  schemas: ...
  responses: ...
  # The definition of the used security schemes
  securitySchemes:
    BasicAuth: # An arbitrary scheme name, we recommend something descriptive
      type: http
      scheme: basic
    Bearer:
      type: http
      scheme: bearer
      bearerFormat: JWT # Optional token format
    APIKey:
      type: apiKey
      in: header # or query/cookie
      name: X-API-Key
    OAuth:
      type: oauth2
      flows: # Many different flows are available - https://spec.openapis.org/oas/v3.1.0#oauth-flows-object
        implicit:
          authorizationUrl: https://test.com/oauth/authorize
          scopes:
            read: Grants read access
            write: Grants write access
    OpenIdConnect:
      type: openIdConnect
      openIdConnectUrl: https://test.com/.well-known/openid-configuration
```

## Best Practices

I generally recommend considering developer experience and weighing this up against the security requirements of your API. Consider its use cases such as will it be called from another server? A client? Or a combination of both. Based on your needs then try to describe your security requirements in your OpenAPI document as simply as possible, if you can avoid multiple options or too many per operation differences then it will generally require less friction for your end-user to get up and running and start using your API. This is the main reason we still see pre-shared secrets (described by the [apiKey](https://spec.openapis.org/oas/v3.1.0#api-key-sample) type above) being the most ubiquitous option amongst APIs today, but if not managed correctly it can be one of the least secure options available.


 This is the content for the doc blog/openapi-tips-data-type-formats.mdx 

 ---
title: "OpenAPI tips - Data types and formats"
description: "Tips and best practices for working with data types and formats in your OpenAPI spec."
keywords:
  [
    openapi,
    swagger,
    data type,
    data format,
    object,
    fully typed object,
    free form,
    object,
    sdk generation,
    sdk,
  ]
image: "/media/openapi-tips-data-types-formats.png"
date: 2022-12-06
authors:
  - name: Tristan Cartledge
  - image_url: "https://uploads-ssl.webflow.com/62ccd7b208cab0723d026273/635ff12733f46637e91ced22_1516859875198.jpg"
tags:
  - OpenAPI Tips
featured_image: "/media/openapi-tips-data-types-formats.png"
---

import { Callout } from "~/components";

<Callout title="Announcing: OpenAPI Reference" variant="success">
Hi! These blog posts have been popular, so we've built an entire [OpenAPI Reference Guide](/openapi/) to answer any questions you have.

It includes detailed information on [**data types**](/openapi/schemas).

Happy Spec Writing!

</Callout>

## The problem

The OpenAPI spec is best known for descriptions of RESTful APIs, but it's designed to be capable of describing any HTTP API whether that be REST or something more akin to RPC based calls.

That leads to the spec having a lot of flexibility baked-in: there's a lot of ways to achieve the exact same result that are equally valid in the eyes of the spec. Because of this, [the OpenAPI](https://spec.openapis.org/oas/v3.1.0#operation-object) documentation is very ambiguous when it comes to how you should define your API.

That's why we're taking the time to eliminate some of the most common ambiguities that you'll encounter when you build your OpenAPI spec. In this case we'll be taking a look at **how to effectively use data types in your OpenAPI 3.0.X spec.**

Note: We will cover the differences introduced by 3.1 in a future post.

## Recommended practices

The OpenAPI Spec gives you plenty of options for describing your types, but also a lot of options to describe them loosely. Loose is fine if your goal is to have a spec that is valid, but if you are using your OpenAPI document to generate: code, documentation or other artifacts, loose will get you into trouble.

**Describe your types as accurately as possible**; you will not only improve the documentation of your API reducing ambiguity for end-users), but **will give as much information as possible to any tools you might be using to generate code, documentation or other artifacts from your OpenAPI document.** Concretely, we recommend that you:

- Describe your types as explicitly as possible by using the OpenAPI defined formats.
- Use additional validation attributes as much as possible: mark properties as required, set readOnly/writeOnly, and indicate when fields that are nullable.

Below, we will step through the different types available in OpenAPI and explain how to use formats, patterns and additional attributes to give you a spec that is descriptive and explicit.

## The data types

In addition to an **object** type, for custom type definitions, the [OpenAPI Specification](https://spec.openapis.org/oas/latest.html#data-types) supports most of the “primitive” types and objects you would expect to describe what your API is capable of sending and receiving:

- [**string**](/openapi/schemas/strings)
- [**number**](/openapi/schemas/numbers)
- [**integer**](/openapi/schemas/numbers)
- [**boolean**](/openapi/schemas/booleans)
- [**array**](/openapi/schemas/arrays)

For each of these primitive types, there is a set of commonly-used **formats** (i.e. date format for string) which you can designate to enforce additional constraints on the values of a schema or field. There is also the option of associating a **nullable** attribute. These options lead to a number of different possibilities for describing your data.

The OpenAPI Spec also includes the ability to describe more complex relationships between types using the **oneOf/anyOf/allOf** attributes and providing the ability to describe **enums** but we will leave the discussion of them to a future blog post.

For now, let's explore the various types and options available for describing your types.

### string

Of the primitive types (ignoring the **object** type) , the **string** type is the most flexible type available. In addition to being able to be used to represent other types (such as `“true”`, `“100”`, `“{\\“some\\”: \\”object\\”}”`), it supports a number of formats that overlay constraints to the type of data represented. This is useful for mapping to types in various languages if you are using the OpenAPI spec for code generation.

#### Formats

The string type via the OpenAPI Specification officially supports the below formats:

| Type   | Format    | Explanation                                                                                 | Example                                                |
| ------ | --------- | ------------------------------------------------------------------------------------------- | ------------------------------------------------------ |
| string | date      | An [RFC3339](https://www.rfc-editor.org/rfc/rfc3339#section-5.6) formatted date string      | “2022-01-30”                                           |
| string | date-time | An [RFC3339](https://www.rfc-editor.org/rfc/rfc3339#section-5.6) formatted date-time string | “2019-10-12T07:20:50.52Z”                              |
| string | password  | Provides a hint that the string may contain sensitive information.                          | “mySecretWord1234”                                     |
| string | byte      | Base-64 encoded data.                                                                         | “U3BlYWtlYXN5IG1ha2VzIHdvcmtpbmcgd2l0aCBBUElzIGZ1biE=” |
| string | binary    | Binary data, used to represent the contents of a file.                                      | “01010101110001”                                       |

The **format** attribute can also be used to describe a number of other formats the string might represent but outside the official list above, those formats might not be supported by tooling that works with the OpenAPI Spec, meaning that they would be provided more as hints to end-users of the API:

- email
- uuid
- uri
- hostname
- ipv4 & ipv6
- and others

Below are some examples of describing various string types:

```yaml
# A basic string
schema:
    type: string

# A string that represents a RFC3339 formatted date-time string
schema:
    type: string
    format: date-time

# A string that represents a enum with the specified values
schema:
    type: string
    enum:
      - "one"
      - "two"
      - "three"

# A string that represents a file
schema:
    type: string
    format: binary
```

#### Patterns

The **string** type also has an associated **pattern** attribute that can be provided to define a regular expression that should be matched by any string represented by that type. **The format of the regular expression is based on** [**Javascript**](https://262.ecma-international.org/5.1/#sec-15.10.1) and therefore could describe regular expressions that might not be supported by various tools or target languages, so **make sure to check the compatibility with your intended targets**.

Example of a string defined with a regex pattern:

```yaml
# A string that must match the specified pattern
schema:
  type: string
  pattern: ^[a-zA-Z0-9_]*$
```

### number/integer

The **number/integer** types allow the description of various number formats through a combination of the **type** and **format** attributes, along with a number of attributes for validating the data, the spec should cover most use cases.

Available formats are:

| Type    | Format | Explanation                                | Example                                      |
| ------- | ------ | ------------------------------------------ | -------------------------------------------- |
| number  |        | Any number integer/float at any precision. | **10** or **1.9** or **9223372036854775807** |
| number  | float  | 32-bit floating point number.              | **1.9**                                      |
| number  | double | 64-bit floating point number.              | **1.7976931348623157**                       |
| integer |        | Any integer number.                        | **2147483647** or **9223372036854775807**    |
| integer | int32  | 32-bit integer.                            | **2147483647**                               |
| integer | int64  | 64-bit integer.                            | 9223372036854775807                          |

Below are some examples of defining **number/integer** types:

```yaml
# Any number
schema:
    type: number

# A 32-bit floating point number
schema:
    type: number
    format: float

# A 64-bit floating point number
schema:
    type: number
    format: double

# Any integer
schema:
    type: integer

# A 32-bit integer
schema:
    type: integer
    format: int32

# A 64-bit integer
schema:
    type: integer
    format: int64
```

Various tools may treat a **number/integer** without a format attribute as a type capable of holding the closest representation of that number in the target language. For example, a **number** might be represented by a **double,** and an **integer** by an **int64.** Therefore, it's recommended that you **be explicit with the format of your number type and always populate the format attribute**.

The **number** type also has some optional attributes for additional validation:

- **minimum**: The **minimum** inclusive number the value should contain.
- **maximum**: The **maximum** inclusive number the value should contain.
- **exclusiveMinimum**: Make the **minimum** number exclusive.
- **exclusiveMaximum**: Make the **maximum** number exclusive.
- **multipleOf**: Specify the **number/integer** is a multiple of the provided value.

Some examples are below:

```yaml
# An integer with a minimum inclusive value of 0
schema:
    type: integer
    format: int32
    minimum: 10

# An integer with a minimum exclusive value of 0
schema:
    type: integer
    format: int32
    minimum: 0
    exclusiveMinimum: true

# A float with a range between 0 and 1
schema:
    type: number
    format: float
    minimum: 0
    maximum: 1

# A double with an exclusive maximum of 100
schema:
    type: number
    format: double
    maximum: 100
    exclusiveMaximum: true

# An 64 but integer that must be a multiple of 5
schema:
    type: integer
    format: int64
    multipleOf: 5
```

### boolean

The boolean type is simple; it represents either **true** or **false**. Be aware that it doesn't support other truthy/falsy values like: **1** or **0**, an empty string “” or **null**. It has no additional attributes to control its format or validation.

```yaml
# A boolean type
schema:
  type: boolean
```

### array

The **array** type provides a way of defining a list of other types through providing an **items** attribute that represents the schema of the type contained in the array.

```yaml
# An array of string
schema:
    type: array
    items:
        type: string

# An array of objects
schema:
    type: array
    items:
        type: object
        properties:
            name:
                type: string
            age:
                type: integer

# An array of arbitrary things
schema:
    type: array
    items: {}
```

The **array** type will support any schema that describes any other type in its items attribute including types using **oneOf/anyOf/allOf** attributes. The **array** type also has some optional attributes for additional validation:

- **minItems**: The minimum number of items the array must contain.
- **maxItems**: The maximum number of items the array must contain.
- **uniqueItems**: The array must contain only unique items.

```yaml
# An array of floats that must contain at least 1 element.
schema:
    type: array
    items:
        type: number
        format: float
    minItems: 1

# An array of strings that must contain at most 10 elements.
schema:
    type: array
    items:
        type: string
    maxItems: 10

# An array of booleans that must contain exactly 3 elements.
schema:
    type: array
    items:
        type: boolean
    minItems: 3
    maxItems: 3

# An array of strings that must contain only unique elements.
schema:
    type: array
    items:
        type: string
    uniqueItems: true
```

### object

The **object** type allows simple and complex objects, dictionaries, and free-form objects, along with a number of attributes to control validation.

#### Fully typed object

Fully typed objects can be described by providing a properties attribute that lists each property of the object and its associated type.

```yaml
# A fully typed object
schema:
    type: object
    properties:
        name:
            type: string
        age:
            type: integer
            format: int32
        active:
            type: boolean

# A fully typed object with a nested object
schema:
    type: object
    properties:
        name:
            type: string
        age:
            type: integer
            format: int32
        active:
            type: boolean
        address:
            type: object
            properties:
                street:
                    type: string
                city:
                    type: string
                state:
                    type: string
                zip:
                    type: string
```

Objects with properties have access to some additional attributes that allow the objects to be validated in various ways:

- **required**: A list of properties that are required. Specified at the object level.
- **readOnly**: A property that is only available in a response.
- **writeOnly**: A property that is only available in a request.

```yaml
# A fully typed object with all fields required
schema:
    type: object
    properties:
        name:
            type: string
        age:
            type: integer
            format: int32
        active:
            type: boolean
    required:
        - name
        - age
        - active

# A fully typed object with only one field required
schema:
    type: object
    properties:
        name:
            type: string
        age:
            type: integer
            format: int32
        active:
            type: boolean
    required:
        - name

# A fully typed object with some field as read-only
schema:
    type: object
    properties:
        name:
            type: string
        age:
            type: integer
            format: int32
        active:
            type: boolean
            readOnly: true # This field is only returned in a response
    required:
        - name
        - age
        - active # This field will only be required in a response

# A fully typed object with some field as write-only
schema:
    type: object
    properties:
        name:
            type: string
        age:
            type: integer
            format: int32
        active:
            type: boolean
        isHuman:
            type: boolean
            writeOnly: true # This field is only required in a request
    required:
        - name
        - age
        - active
        - isHuman # This field will only be required in a request
```

#### Using object for dictionaries

The **object** type can also be used to describe dictionaries/maps/etc that use strings for keys and support any value type that can be described by the OpenAPI Spec.

```yaml
# A dictionary of string values
schema:
    type: object
    additionalProperties:
        type: string

# A dictionary of objects
schema:
    type: object
    additionalProperties:
        type: object
        properties:
            name:
                type: string
            age:
                type: integer
                format: int32
```

You can also describe dictionaries that will contain certain keys

```yaml
# A dictionary that must contain at least the specified keys
schema:
  type: object
  properties:
    name:
      type: string # Must match type of additionalProperties
  required:
    - name
  additionalProperties:
    type: string
```

When using the **additionalProperties** attribute you can also specify additional attributes to validate the number of properties in the object:

- **minProperties**: The minimum number of properties allowed in the object.
- **maxProperties**: The maximum number of properties allowed in the object.

For example:

```yaml
# A dictionary of string values that has at least one key.
schema:
    type: object
    additionalProperties:
        type: string
    minProperties: 1

# A dictionary of string values that has at most 10 keys.
schema:
    type: object
    additionalProperties:
        type: string
    maxProperties: 10

# A dictionary of string values that has 1 key.
schema:
    type: object
    additionalProperties:
        type: string
    minProperties: 1
    maxProperties: 1
```

#### Free-form objects

The **object** type can also be used to describe any arbitrary key/value pair (where the keys are still required to be strings).

```yaml
# An arbitrary object/dictionary that can contain any value.
schema:
    type: object
    additionalProperties: true

# An alternate way to specify an arbitrary object/dictionary that can contain any value.
schema:
    type: object
    additionalProperties: {}
```

### null

OpenAPI 3.0.X doesn't support a null type but instead allows you to mark a schema as being nullable. This allows that type to either contain a valid value or null.

```yaml
# A nullable string
schema:
    type: string
    nullable: true

# A nullable integer
schema:
    type: integer
    format: int32
    nullable: true

# A nullable boolean
schema:
    type: boolean
    nullable: true

# A nullable array
schema:
    type: array
    items:
        type: string
    nullable: true

# A nullable object
schema:
    type: object
    properties:
        foo:
            type: string
    nullable: true
```


 This is the content for the doc blog/openapi-tips-oneof-allof-anyof.mdx 

 ---
title: "OneOf, AllOf, AnyOf Oh my! How to define union types in OpenAPI"
description: "How to effectively use oneOf, allOf and anyOf in your OpenAPI 3.X OADs."
keywords: [openapi, api]
image: "/media/openapi-tips-anyof-allof.png"
date: 2023-10-19
authors:
  - name: Nolan Sullivan
  - image_url: "/media/author-headshots/nolan.jpeg"
tags:
  - OpenAPI Tips
featured_image: "/media/openapi-tips-anyof-allof.png"
---

import { Callout } from '~/components'

<Callout title="Announcing: OpenAPI Reference" variant="success">
Hi! These blog posts have been popular, so we've built an entire [OpenAPI Reference Guide](/openapi/) to answer any question you have. 

It includes detailed information on [**polymorphic types**](/openapi/schemas/objects/polymorphism).

Happy Spec Writing!
</Callout>

The OpenAPI Specification (OAS) is designed to be capable of describing any HTTP API, whether that be REST or something more akin to RPC-based calls.  That leads to the OAS having a lot of flexibility baked-in: there are a lot of ways to achieve the exact same result that are equally valid in the eyes of the OAS.

That’s why we’re taking the time to eliminate some of the most common ambiguities that you’ll encounter when you build your OpenAPI documents (OADs). In this case, we’ll be taking a look at **how to effectively use anyOf, allOf, and oneOf in your OpenAPI 3.X OADs.**

The `anyOf`, `allOf`, and `oneOf` keywords are defined by JSON Schema and used in OpenAPI to define the structure and validation rules for data. They can be used together to define complex and flexible schemas.

- **`oneOf`:** The value must match exactly one of the subschemas. The `oneOf` keyword is useful for describing scenarios where a property can be defined with multiple possible data structures, but only one of them is used at a time. For example, if your API accepts a `string` or an `int` for a certain field depending on the use case, `oneOf` would be used. In code generation, it will be generally interpreted as a union type.
- **`allOf`:** The value must match all of the subschemas. The `allOf` keyword is useful for describing model composition: the creation of complex schemas via the composition of simpler schemas.
- **`anyOf`:** The value must match one or more of the subschemas. The `anyOf` keyword is useful for describing type validation (similar to `oneOf`), but it can get you into a lot of trouble in code generation. There is no straightforward way for a code generator to interpret what `anyOf` means, which can lead to undefined or unintended behavior or simply any schema being allowed. We’ll dig into this more later.

## **Recommended Practices**

When you’re writing your OAD, you need to consider your end goals. The distinctions between allOf, oneOf, anyOf are subtle, but the implications on types in a generated SDK can be huge. To avoid downstream problems, we recommend following these rules:

- Use `oneOf` to represent union type object fields.
- Use `allOf` to represent intersection type / composite objects and fields.
- Don’t use `anyOf` unless you absolutely need to.

Below, we will step through each of the different keywords and explain how to use formats, patterns, and additional attributes to give you a spec that is descriptive and explicit.

## **What is `oneOf`?**

The `oneOf` keyword in JSON Schema and OpenAPI specifies that a value must match **exactly one** from a given set of schemas. 

`oneOf` is the closest OpenAPI analog to the concept of a union type. A union type is a way to declare a variable or parameter that can hold values of multiple different types. They allow you to make your code more flexible while still providing type safety to users.

Let’s look at an example of how a `oneOf` is translated into a typescript object:

```yaml
components:
	schemas:
		Drink:
		  type: object
		  oneOf:
		    - $ref: "#/components/schemas/Cocktail"
		    - $ref: "#/components/schemas/Mocktail"
```

That would produce a type structure like:

```tsx
type Drink = Cocktail | Mocktail;
```

## **What is `allOf`?**

The `allOf` keyword in JSON Schema and OpenAPI combines multiple schemas to create a single object that must be valid against **all of** the given subschemas. 

`allOf` is the closest OpenAPI analog to an intersection type or a composite data type. You can use allOf to create a new type by combining multiple existing types. The new type has all the features of the existing types.

```json
components:
	schemas:
		MealDeal:
		  type: object
		  allOf:
		    - $ref: "#/components/schemas/Cocktail"
		    - $ref: "#/components/schemas/Snack"
```

That would produce a type structure like:

```tsx
type MealDeal = Cocktail & Snack;
```

### Pitfall: Construction of Illogical Schemas

`allOf` has valid use cases, but you can also shoot yourself in the foot fairly easily.  The most common problem that occurs when using `allOf` is the construction of an illogical schema. Consider the following example:

```yaml
type: object
properties:
  orderId:
    description: ID of the order.
    type: integer
    allOf:
      - $ref: '#/components/schemas/MealDealId'
...
components:
	schemas:
		MealDealId:
			type: string
      description: The id of a meal deal.
```

The OAS itself doesn’t mandate type validation, so this is *technically* valid. However, if you try to turn this into functional code, you will quickly realize that you’re trying to make something both an integer and a string at the same time, something that is clearly not possible.


>Speakeasy’s implementation of `allOf` is a work in progress. To avoid the construction of illogical types, we currently construct an object using the superset of fields from the listed schemas. In cases where the base schemas have a collision, we will default to using the object deepest in the list.


## **What is `anyOf`?**

The `anyOf` keyword in JSON Schema and OpenAPI is the poor misunderstood sibling of `oneOf` and `allOf`. There is no established convention about how `anyOf` should be interpreted, which often leads to some very nasty unintended behavior. The issue arises when `anyOf` is interpreted to mean that a value must match **at least one** of the given listed schemas. 


>There could be a valid use of `anyOf` to describe an extended match of **one** element of a list. But that is not currently implemented by any OpenAPI tooling known to us. 


### Pitfall: Combinatorial Explosion of Type

`anyOf` leads to a lot of problems in code generation because, taken literally, it describes a combinatorial number of data types. Imagine the following object definition:

```tsx
components:
  schemas:
    Drink:
      type: object
      anyOf:
        - $ref: "#/components/schemas/Soda"
        - $ref: "#/components/schemas/Water"
        - $ref: "#/components/schemas/Wine"
        - $ref: "#/components/schemas/Spirit"
        - $ref: "#/components/schemas/Beer"
```


>To avoid the explosion of types described below, Speakeasy’s SDK creation interprets `anyOf` as `oneOf`.


If you’re doing code generation, you need to explicitly build types to cover all the possible combinations of these 5 liquids (even though most would be disgusting). That would lead you to build over 200 types to cover all the different combinations. That would lead to tremendous bloat in your library. That’s why our recommendation is **don’t use anyOf.**

## Describing Nullable Objects

People sometimes incorrectly use `oneOf` when they want to indicate that it is possible for an object to be null.  It differs based on the the version of OpenAPI you are using, but there are better ways to describe something as nullable.

If you are using OpenAPI 3.0 use the nullable property:

```yaml
components:
	schemas:
		Drink:
		  type: object
			nullable: true
```

If you are using OpenAPI 3.1, use `type: [’object’, ‘null’]` to specify that an object is nullable:

```yaml
components:
	schemas:
		Drink:
			type: [object, 'null']
```

## **Conclusion**

AnyOf, AllOf, and OneOf are powerful keywords that can be used to define the structure and validation rules for data in OpenAPI.

You’ll notice that this article doesn’t cover the JSON Schema `not`keyword. Although this keyword is valid in OAS, its use with code-generation tools leads to immediate problems. How can a code generator generate code for every possible schema **except** one or a set? This problem has taxed many big-brains, and remains unsolved today.

Here is a link to a blog post that provides more information about defining data types in OpenAPI:

https://speakeasyapi.dev/post/openapi-tips-data-type-formats/


 This is the content for the doc blog/openapi-tips-query-parameters-serialization.mdx 

 ---
title: "OpenAPI Tips - Query Parameters & Serialization"
description: "Tips & Best practices for working with query parameters & serialization in your OpenAPI spec."
keywords:
  [
    openapi,
    swagger,
    query parameters,
    paramater serialization,
    sdk generation,
    sdk,
  ]
image: "/media/openapi-tips-serialization.png"
date: 2022-12-20
authors:
  - name: Anuraag Nalluri
  - image_url: /media/author-headshots/anuraag.jpeg
tags:
  - OpenAPI Tips
featured_image: "/media/openapi-tips-serialization.png"
---

import { Callout } from "~/components";

<Callout title="Announcing: OpenAPI Reference" variant="success">
Hi! These blog posts have been popular, so we've built an entire [OpenAPI Reference Guide](/openapi/) to answer any question you have.

It includes detailed information on [**query parameters**](/openapi/paths/parameters/query-parameters).

Happy Spec Writing!

</Callout>

## The Problem

The OpenAPI spec is best known for descriptions of RESTful APIs, but it'is designed to be capable of describing any HTTP API whether that be REST or something more akin to RPC based calls.

That leads to the spec having a lot of flexibility baked-in: there's a lot of ways to achieve the exact same result that are equally valid in the eyes of the spec. Because of this, [the OpenAPI documentation](https://spec.openapis.org/oas/v3.1.0#operation-object) is very ambiguous when it comes to how you should define your API.

That's why we're taking the time to eliminate some of the most common ambiguities that you'll encounter when you build your OpenAPI schema. In this case we'll be taking a look at **how to serialize query parameters in your OpenAPI 3.0.X schema.**

## Recommended Practices

The OpenAPI spec grants quite a bit of flexibility in defining query parameters for any operation. There are many serialization options and defaults, therefore it's advisable you **define query parameters as strictly as possible** in your schema. This will **improve your API documentation** thereby reducing ambiguity for end-users. In addition, explicit definitions will **aid any OpenAPI tooling you may be using to produce artifacts**, such as client SDKs.

As an API developer, strict definitions will also give you a more intuitive understanding of each operatio's intended behavior as you iterate on your OpenAPI schema. Concretely, we recommend that you:

- Describe your query parameters as explicitly as possible by using OpenAPI defined formats.
- Use additional validation attributes as much as possible: mark properties as required, allowReserved, allowEmptyValue, and indicate when fields are nullable.

It's also important to note that OpenAPI considers a unique operation as a combination of a path and HTTP method, so it is not possible to have multiple operations that only differ by query parameters. In this case, it's advisable to use unique paths as shown below:

```yaml
GET /users/findByName?name=anuraag
GET /users/findByRole?role=developer
```

## Query Parameters

Query parameters are criteria which appear at the end of a request URL demarcated by a question mark (?), with different key=value pairs usually separated by ampersands (&). They may be required or optional, and can be specified in an OpenAPI schema by specifying **in: query**. Consider the following operation for an event catalog:

```yaml
GET /events?offset=100&limit=50
```

Query parameters could be defined in the schema as follows:

```yaml
parameters:
  - in: query
    name: offset
    schema:
      type: integer
    description: The number of items to skip before starting to collect the result set
  - in: query
      name: limit
      schema:
        type: integer
      description: The numbers of items to return
```

When you're working with query parameters, it's important to understand serialization. Let's explore what serialization is, and the variety of ways the OpenAPI specification supports serialization of query parameters.

## Serialization

Serialization is responsible for transforming data into a format that can be used in transit and reconstructed later. For query parameters specifically, this format is the query string for requests of that operation. The serialization method allows us to define this through the use of the following keywords:

- **style** – defines how multiple values are delimited. Possible styles depend on the parameter location – [path](https://swagger.io/docs/specification/serialization/#path), [query](https://swagger.io/docs/specification/serialization/#query), [header](https://swagger.io/docs/specification/serialization/#header) or [cookie](https://swagger.io/docs/specification/serialization/#cookie).
- **explode** – (true/false) specifies whether arrays and objects should generate separate parameters for each array item or object property.

OpenAPI supports serialization of arrays and objects in all operation parameters (path, query, header, cookie). The serialization rules are based on a subset of URI template patterns defined by [RFC 6570](https://tools.ietf.org/html/rfc6570).

From the OpenAPI Swagger documentation, query parameters support the following style values:

- **form** (default): ampersand-separated values, also known as form-style query expansion. Corresponds to the `{?param_name}` URI template.
- **spaceDelimited**: space-separated array values. Has effect only for non-exploded arrays (`explode: false`), that is, the space separates the array values if the array is a single parameter, as in arr=a b c.
- **pipeDelimited**: pipeline-separated array values. Has effect only for non-exploded arrays (`explode: false`), that is, the pipe separates the array values if the array is a single parameter, as in arr=a|b|c.
- **deepObject**: simple non-nested objects are serialized as `paramName[prop1]=value1&paramName[prop2]=value2&....` The behavior for nested objects and arrays is undefined.

The **default serialization method** is **style: form and explode: true**. As shown in the GET /events call above, the `“?offset=100&limit=50”` query string is created with this default serialization when the schema has no references to style or explode. However, we recommend explicitly setting these values, even in the default case, to reap the benefits discussed in “Recommended Practices” above.

Style and explode cover the most common serialization methods, but not all. For more complex scenarios (ex. a JSON-formatted object in the query string), you can use the **content** keyword and specify the media type that defines the serialization format. The example schema below does exactly that:

```yaml
parameters:
  - in: query
    name: filter
    # Wrap 'schema' into 'content.'
    content:
      application/json: #media type indicates how to serialize/deserialize parameter content
        schema:
          type: object
          properties:
            type:
              type: string
            location:
              type: string
```

## Additional Attributes

Query parameters can be specified with quite a few additional attributes to further determine their **serialization, optionality, and nullability**.

### AllowReserved

This is the only additional attribute which is specific to query parameters. From the OpenAPI Swagger documentation: The **allowReserved** keyword specifies whether the reserved characters, defined as :**/?#[]@!$&'()\*+,;=** by [RFC 3986](https://www.rfc-editor.org/rfc/rfc3986), are allowed to be sent as they are as query parameter values or should be percent-encoded. By default, allowReserved is false, and reserved characters are percent-encoded. For example, / is encoded as %2F (or %2f), so that the parameter value, events/event_info.txt, will be sent as events%2Fevent_info.txt. To preserve the / as is, **allowReserved** would have to be set to true as shown below:

```yaml
parameters:
  - in: query
    name: path
    required: true
    schema:
      type: string
    allowReserved: true
```

### Required

By default, OpenAPI treats all request parameters as optional. You can add **required: true** to mark a parameter as required.

### Default

Use the **default** keyword in the parameter schema to specify the default value for an optional parameter. The default value is the one that the server uses if the client does not supply the parameter value in the request. The value type must be the same as the parameter's data type.

Consider a simple example, where default used with paging parameters allows these 2 calls from the client to be equivalent:

```yaml
GET /events
GET /events?offset=0&limit=100
```

This would be specified in the schema like so:

```yaml
- in: query
  name: offset
  schema:
    type: integer
    default: 0
  description: The number of items to skip before starting to collect the result set
- in: query
  name: limit
  schema:
    type: integer
    default: 100
  description: The numbers of items to return
```

The **default keyword should not be used with required values**. If a parameter is required, the client must always send it and therefore override the default.

### Enum and Constant Parameters

You can restrict a parameter to a fixed set of values by adding the enum to the parameter's schema. The **enum** values must be the same type as the parameter data type.

A constant parameter can then be defined as a required parameter with only one possible value as shown below:

```yaml
parameters:
  - in: query
    name: eventName
    required: true
    schema:
      type: string
      enum:
        - coachella
```

The enum property specifies possible values, and in this example, only one value can be used.

It's important to note a **constant parameter is not the same as the default parameter value**. A constant parameter is always sent by the client, whereas the default value is something that the server uses if the parameter is not sent by the client.

### Empty-Valued and Nullable

Query string parameters may only have a name and no value, like so:

```yaml
GET /events?metadata
```

Use allowEmptyValue to describe such parameters:

```yaml
parameters:
  - in: query
    name: metadata
    required: true
    schema:
      type: boolean
    allowEmptyValue: true
```

The OpenAPI spec also supports **nullable** in schemas, allowing operation parameters to have the null value when **nullable: true**. This simply means the parameter value can be null, and is **not the same as an empty-valued or optional parameter**.

### Deprecated

Use **deprecated: true** to mark a parameter as deprecated.

### Common Parameters Across Methods in Same Path

Parameters may be defined once to be used in multiple methods/paths in an OpenAPI schema. Parameters shared by all operations of a path can be defined on the path level instead of the operation level. These path-level parameters are inherited by all operations (GET/PUT/PATCH/DELETE) of that path. An example is shown below(manipulating the same resource in different ways is a good use case here):

```yaml
paths:
  /events:
    parameters:
      - in: query
        name: filter
        content:
          application/json:
            schema:
              type: object
                properties:
                  type:
                    type: string
                  location:
                    type: string
  get:
    summary: Gets an event by type and location
    ...
  patch:
    summary: Updates the newest existing event with the specified type and location
    ...
  delete:
```

Any extra parameters defined at the operation level are used **in addition** to path-level parameters. Specific path-level parameters **may also be overridden on the operation level, but cannot be removed**.

### Common Parameters Across Multiple Paths

Parameters can also be shared across multiple paths. Pagination is a good candidate for this:

```yaml
components:
  parameters:
    offsetParam:
      - in: query
        name: offset
        required: false
        schema:
          type: integer
        minimum: 0
        default: 0
        description: The number of items to skip before collecting the result set.
    limitParam:
      - in: query
        name: limit
        required: false
        schema:
          type: integer
        minimum: 1
        default: 10
        description: The number of items to return.
paths:
  /events:
    get:
      summary: Gets a list of events
      parameters:
        - $ref: '#/components/parameters/offsetParam'
        - $ref: '#/components/parameters/limitParam'
      responses:
        '200':
          description: OK
  /locations:
    get:
      summary: Gets a list of locations
      parameters:
        - $ref: '#/components/parameters/offsetParam'
        - $ref: '#/components/parameters/limitParam'
      responses:
        '200':
          description: OK
    ...
```

Note the above parameters defined in components are simply global definitions that can be handily referenced. They are not necessarily applied to all methods of an operation.


 This is the content for the doc blog/openapi-tips-webhooks-callbacks/index.mdx 

 ---
title: "Webhooks & Callbacks in OpenAPI/Swagger"
description: "How to correctly use webhooks & callbacks in your OpenAPI/Swagger specification."
keywords: [openapi, swagger, webhook, callback, sdk generation, sdk]
image: "/media/openapi-tips-webhooks-callbacks.png"
date: 2023-12-05
authors:
  - name: Nolan Di Mare Sullivan
  - image_url: "/media/author-headshots/nolan.jpeg"
tags:
  - OpenAPI Tips
featured_image: "/media/openapi-tips-webhooks-callbacks.png"
---

import { ScrollyCoding } from "~/components/codehike/Scrollycoding";
import { Callout } from "~/components";

<Callout title="Announcing: OpenAPI Reference" variant="success">
Hi! These blog posts have been popular, so we've built an entire [OpenAPI Reference Guide](/openapi/) to answer any question you have.

It includes detailed information on [**webhooks**](/openapi/webhooks) **&** [**callbacks**](/openapi/paths/operations/callbacks).

Happy Spec Writing!

</Callout>

## What Are Webhooks and Callbacks and When Are They Used in OpenAPI?

A traditional REST API functions by allowing users to trigger a request that the API immediately sends a response to; this is known as a pull mechanism. Webhooks and callbacks expand the possible ways of working with the API beyond this traditional call/response interface.

- `webhooks` are a mechanism that allows an API to send real-time data to a user as soon as an event occurs (without requiring the user to take any action). The user simply needs to subscribe to the event stream and provide a URL to start receiving data.
- `callbacks` are a mechanism that allows a user to specify a URL to which an API request should send a certain response.

### Which Should You Use?

Both webhooks and callbacks are a way of defining asynchronous communication with an API. You can use webhooks and callbacks somewhat interchangeably, but we recommend sticking to the following convention:

- If users will be receiving a stream of data over time with a consistent format, you should use webhooks.
- If the initial API request triggers a long-running job and the user wants to receive the response asynchronously, use callbacks.

## A Short History of Webhooks and Callbacks in OpenAPI

Callbacks were added to the OpenAPI Specification in [version 3](https://spec.openapis.org/oas/v3.0.0#callback-object) in 2017; webhooks in [version 3.1](https://spec.openapis.org/oas/v3.1.0#oasWebhooks) in 2021.

| OpenAPI Version                               | Date    | Notes           |
| --------------------------------------------- | ------- | --------------- |
| [3.0.0](https://spec.openapis.org/oas/v3.0.0) | 2017-07 | Callbacks added |
| [3.0.1](https://spec.openapis.org/oas/v3.0.1) | 2017-12 |                 |
| [3.0.2](https://spec.openapis.org/oas/v3.0.2) | 2018-10 |                 |
| [3.0.3](https://spec.openapis.org/oas/v3.0.3) | 2020-02 |                 |
| [3.1.0](https://spec.openapis.org/oas/v3.1.0) | 2021-02 | Webhooks added  |

In OpenAPI, webhooks and callbacks are defined as follows:

- `webhooks` are a top-level entry represented by a map of Path Item Objects or OpenAPI Reference Objects that are keyed by the unique name of the webhook. Webhooks specify what is pushed to a given URL but provide no way of setting the target URL. The subscription itself might be configured by a sales representative, entered during the sign-up process when a user creates an account on your system, or even set by a separate API endpoint (duplicating how callbacks work).
- A `callback` is a map of runtime expressions (that represent a URL the callback request is sent to) to a Path Item Object or Reference that defines a request to be initiated by the API provider and a potential response to be returned. The expression, when evaluated at runtime, will resolve to a URL represented in the parameters, request body, or response body of the parent operation.

A valid API schema can comprise only webhooks. For your schema to be valid, it needs only an `info` element and at least one of `paths`, `webhooks`, or `components`.

## Creating a Webhook in OpenAPI

Below is the same notification service described as a webhook.

<ScrollyCoding fullHeight className="ch-scrollycoding-full-height">

### !!steps Add a Webhook Description

Add a webhook named `concertAlert` that describes what information will be pushed to a subscriber. This is the only requirement for a valid schema with a webhook.

Notice that there is no way for a user to register for this alert using the API, nor is the URL on which the user will be notified specified.

```yaml !
# !focus(5:19)
openapi: 3.1.0
info:
  title: SpeakeasyClub
  version: 1.0.0
webhooks:
  concertAlert:
    post:
      summary: Concert alert
      description: Notify the registered URL with details of an upcoming concert
      requestBody:
        required: true
        content:
          text/plain:
            schema:
              type: string
            example: "The Swing Machine will be playing at 19h30 tomorrow. $10 cover charge."
      responses:
        "200":
          description: Notification received by the external service.
```

---

### !!steps Add a Subscription Path

To allow users to register for alerts without using a callback, you can optionally mimic callback functionality by proving a subscription endpoint in a `/path`.

OpenAPI has no way to explicitly link the webhook with the registration. You will have to make this clear to users in your `description` elements or by grouping the operations with tags.

```yaml !
# !focus(20:40)
openapi: 3.1.0
info:
  title: SpeakeasyClub
  version: 1.0.0
webhooks:
  concertAlert:
    post:
      summary: Concert alert
      description: Notify the registered URL with details of an upcoming concert
      requestBody:
        required: true
        content:
          text/plain:
            schema:
              type: string
            example: "The Swing Machine will be playing at 19h30 tomorrow. $10 cover charge."
      responses:
        "200":
          description: Notification received by the external service.
paths:
  /registerForAlert:
    post:
      summary: Register for concert alerts
      description: Register a URL to be called when new concerts are scheduled.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              properties:
                url:
                  type: string
                  format: uri
                  description: The URL to be notified about approaching concerts.
            example:
              url: "http://example.com/notify"
      responses:
        "200":
          description: Registration successful.
```

---

</ScrollyCoding>

## Creating a Callback in OpenAPI

Let's create a simple callback example. We use YAML rather than JSON for readability.

<ScrollyCoding fullHeight>

### !!steps Add a Subscription Path

Now add a single `/registerForAlert` endpoint that a user can pass a URL to for concert notifications. We disregard error responses for brevity.

```yaml !
# !focus(5:25)
openapi: 3.1.0
info:
  title: SpeakeasyClub
  version: 1.0.0
paths:
  /registerForAlert:
    post:
      summary: Register for concert alerts
      description: Register a URL to be called when new concerts are scheduled.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              properties:
                url:
                  type: string
                  format: uri
                  description: The URL to be notified about approaching concerts.
            example:
              url: "http://example.com/notify"
      responses:
        "200":
          description: Registration successful.
      callbacks:
        concertAlert:
          "{$request.body#/url}":
            post:
              summary: Concert alert
              description: Notify the registered URL with details of an upcoming concert.
              requestBody:
                required: true
                content:
                  text/plain:
                    schema:
                      type: string
                    example: "The Swing Machine will be playing at 19h30 tomorrow. $10 cover charge."
              responses:
                "200":
                  description: Notification received by the external service.
```

---

### !!steps Add a Callback to the Path

Finally, add a callback to the endpoint. The callback gets the URL using `{$request.body#/url}` from the POST to send a string describing the next concert.

Selecting parameters in a POST request in this way is called a [runtime expression](https://spec.openapis.org/oas/v3.1.0#runtime-expressions). Read more about the syntax in the specification.

```yaml !
# !focus(26:47)
openapi: 3.1.0
info:
  title: SpeakeasyClub
  version: 1.0.0
paths:
  /registerForAlert:
    post:
      summary: Register for concert alerts
      description: Register a URL to be called when new concerts are scheduled.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              properties:
                url:
                  type: string
                  format: uri
                  description: The URL to be notified about approaching concerts.
            example:
              url: "http://example.com/notify"
      responses:
        "200":
          description: Registration successful.
      callbacks:
        concertAlert:
          "{$request.body#/url}":
            post:
              summary: Concert alert
              description: Notify the registered URL with details of an upcoming concert.
              requestBody:
                required: true
                content:
                  text/plain:
                    schema:
                      type: string
                    example: "The Swing Machine will be playing at 19h30 tomorrow. $10 cover charge."
              responses:
                "200":
                  description: Notification received by the external service.
```

---

</ScrollyCoding>

## Syntax Rules

The `webhooks` element has identical syntax to the `paths` element. Both are lists of [Path Item Objects](https://spec.openapis.org/oas/v3.1.0#pathItemObject). (This makes sense if you consider that a webhook is like a reverse path: Just as paths describe endpoints on the server's API, webhooks describe endpoints on the user's API.)

A `callback` is also a Path Item Object.

This means a webhook or callback has all the following path properties available to it: `$ref`, `summary`, `description`, `get`, `put`, `post`, `delete`, `options`, `head`, `patch`, `trace`, `servers`, and `parameters`.

## Callbacks and Webhooks in Speakeasy

Speakeasy will [automatically include your webhook types](/docs/customize-sdks/webhooks) in generated code and documentation. You don't need to do anything extra or include Speakeasy extensions (`x-speakeasy`) to use these features.

## Tips

Here are a few more considerations when designing your API's use of webhooks and callbacks:

- If using callbacks, you can manage multiple subscriptions in the same endpoint using multiple parameters — one for each URL. This might be neater than creating one registration path per callback.
- If using webhooks, be sure to explain in the summary or description exactly how users can subscribe and unsubscribe, as well as any associated fees for the service.
- Any `description` elements may use [CommonMark syntax](https://spec.openapis.org/oas/v3.1.0#rich-text-formatting).
- Callbacks and webhooks must have unique names in the schema. The names are case-sensitive.
- Make your webhooks idempotent. Sending or receiving the same event multiple times should not cause side effects.
- Protect your API from DDoS attacks by making sure webhooks are protected from spam registrations with authentication and that limits are in place for the rate and size of your messages.

## What About AsyncAPI Standard?

OpenAPI is a general-purpose API specification that can be used for asynchronous APIs, but it is not necessarily optimized for them. If you find that OpenAPI is insufficient for your use case, you should check out [AsyncAPI](https://www.asyncapi.com/). Just be aware that AsyncAPI is still in the early stages of development and is not yet widely supported by the tooling ecosystem.


 This is the content for the doc blog/pact-vs-openapi/index.mdx 

 ---
title: "Pact vs OpenAPI: Choosing the right foundation for your API testing strategy"
description: "How does Pact compare to the combination of OpenAPI and type-safe SDKs for API testing?"
keywords: [openapi, swagger, pact, testing, sdk generation, sdk]
image: "/media/pact-vs-openapi.png"
date: 2024-12-05
authors:
  - name: Nolan Di Mare Sullivan
  - image_url: "/media/author-headshots/nolan.jpeg"
tags:
  - Testing
  - OpenAPI
featured_image: "/media/pact-vs-openapi.png"
---

The promise of reliable, well-tested APIs shouldn't at the expense of developer productivity. Yet, that's precisely what many teams face when Pact, a consumer-driven approach to enterprise contract testing.

Pact's approach was born out of a worthy goal. Rigorous and comprehensive API contract testing is necessary, but Pact fell into a classic trap. The creators tried to create a new standard to solve 100% of the testing problem, instead of building on existing standards that already solved 80% of the issue: OpenAPI. The result was an extra 20% of value for at least 2x the cost (but typically much more).

In this article, we'll weigh up the costs and benefits of using Pact vs. OpenAPI for API contract testing.

TL;DR:

1. While Pact offers comprehensive contract testing, its implementation complexity and maintenance overhead often outweigh the benefits for most teams.

2. OpenAPI-based testing provides comparable reliability with significantly less overhead, especially when combined with Arazzo for workflow testing.

3. Teams serving external API consumers can benefit most from OpenAPI-based approaches, while Pact might still make sense for mission-critical dependencies within internal microservices architectures.

## The API testing challenge

Well-tested APIs are essential when building reliable systems. API integrations, sitting at the edges between systems, represent the ideal place to catch and prevent issues before they cascade into production problems. Getting testing right at these boundaries provides outsized returns on investment.

### Why API integration failures are so expensive

Bugs that originate with API requests typically propagate through multiple systems, making them extremely difficult to pinpoint and resolve.

This leads to rolled-back releases, large-scale outages, and years of wasted developer time. The most expensive loss may very well be developers' trust in your system.

To minimize the cost of API failures, teams employ various testing methodologies for their APIs. The most comprehensive test methodologies are usually the most complex. We need to ask whether adding more complexity to an already brittle integration may be pricier than simply supporting the bugs that arise.

### What teams want from tests

To be truly useful, API testing strategies should provide three key benefits:

1. Confidence that API changes will not break existing integrations.
2. Early detection of potential issues.
3. **Minimal maintenance overhead.**

Consumer-driven contract testing, as implemented with Pact, deliver on the first two points, but fails spectacularly at the third.

## Understanding Pact

Pact implements consumer-driven contract testing, where API consumers define their expectations in advance. These expectations form a contract that API providers must fulfill. While this approach sounds logical, its implementation can become surprisingly complex.

```mermaid
sequenceDiagram
    title Testing workflow with Pact
    participant Consumer Team
    participant Pact Broker
    participant Provider Team
    
    Note over Consumer Team: Write consumer test
    Consumer Team->>Consumer Team: Generate contract
    Consumer Team->>Pact Broker: Publish contract
    Note over Pact Broker: Store contract
    Provider Team->>Pact Broker: Fetch contracts
    Pact Broker->>Provider Team: 
    Provider Team->>Provider Team: Verify API against contracts
    Provider Team->>Pact Broker: Publish results
    
    alt If contract verification fails
        Provider Team->>Consumer Team: Negotiate changes
        Consumer Team->>Consumer Team: Update tests
        Consumer Team->>Pact Broker: Republish contract
    end
```

Let's break down what's happening:

### 1. Consumer teams write tests describing their API expectations

The consumer's teams must write specialized Pact tests in one of Pact's supported languages. These tests define expected request and response pairs.

Here's an example from [pact-js](https://github.com/pact-foundation/pact-js):

```javascript
import { PactV3, MatchersV3 } from '@pact-foundation/pact';

// Create a 'pact' between the two applications in the integration we are testing
const provider = new PactV3({
  dir: path.resolve(process.cwd(), 'pacts'),
  consumer: 'MyConsumer',
  provider: 'MyProvider',
});

// API Client that will fetch dogs from the Dog API 
// This is the target of our Pact test
public getMeDogs = (from: string): AxiosPromise => {
  return axios.request({
    baseURL: this.url,
    params: { from },
    headers: { Accept: 'application/json' },
    method: 'GET',
    url: '/dogs',
  });
};

const dogExample = { dog: 1 };
const EXPECTED_BODY = MatchersV3.eachLike(dogExample);

describe('GET /dogs', () => {
  it('returns an HTTP 200 and a list of dogs', () => {
    // Arrange: Setup our expected interactions
    //
    // We use Pact to mock out the backend API
    provider
      .given('I have a list of dogs')
      .uponReceiving('a request for all dogs with the builder pattern')
      .withRequest({
        method: 'GET',
        path: '/dogs',
        query: { from: 'today' },
        headers: { Accept: 'application/json' },
      })
      .willRespondWith({
        status: 200,
        headers: { 'Content-Type': 'application/json' },
        body: EXPECTED_BODY,
      });

    return provider.executeTest((mockserver) => {
      // Act: test our API client behaves correctly
      //
      // Note we configure the DogService API client dynamically to 
      // point to the mock service Pact created for us, instead of 
      // the real one
      dogService = new DogService(mockserver.url);
      const response = await dogService.getMeDogs('today')

      // Assert: check the result
      expect(response.data[0]).to.deep.eq(dogExample);
    });
  });
});
```

### 2. These tests generate a contract file

When the developer runs their tests locally or in a staging environment, Pact generates a contract file.

Contract files are JSON documents that describe the consumer's expected requests and responses. Each consumer generates their own contract. If your API has 100 consumers, you can expect 100 contract files to be generated by their teams.

### 3. The contract is published to a Pact Broker

As the provider, you need to maintain a service called a Pact Broker. This service versions, tags, and stores contracts. It sits between the consumer and the provider.

### 4. Provider teams verify their API against all consumer contracts

As part of the provider's CI/CD workflow, their API needs to verify against all consumer contracts in the Pact Broker.

Here's an example from [pact-js](https://github.com/pact-foundation/pact-js):

```javascript
const { Verifier } = require('@pact-foundation/pact');

// (1) Start provider locally. Be sure to stub out any external dependencies
server.listen(8081, () => {
  importData();
  console.log('Animal Profile Service listening on http://localhost:8081');
});

// (2) Verify that the provider meets all consumer expectations
describe('Pact Verification', () => {
  it('validates the expectations of Matching Service', () => {
    let token = 'INVALID TOKEN';

    return new Verifier({
      providerBaseUrl: 'http://localhost:8081', // <- location of your running provider
      pactUrls: [ path.resolve(process.cwd(), "./pacts/SomeConsumer-SomeProvider.json") ],
    })
      .verifyProvider()
      .then(() => {
        console.log('Pact Verification Complete!');
      });
  });
});
```

Each time the API is verified, the results are published back to the Pact Broker.

### 5. Failed verifications block provider deployments

This is where this process changes from complex to a developer time vortex. The provider and consumer teams now have to negotiate contract changes. Either the provider must fix their API, or consumers need to update their tests and publish new contracts. This process takes place for all failed verifications across all consumer contracts. Finally, the provider re-verifies the API and the cycle starts anew.

### Pact's direct costs

The Pact workflow above demonstrates why implementing Pact is often so complex:

- **Setup complexity**: The initial implementation of Pact is a significant undertaking for any team size. It requires standing up new tools, and the orchestration of CI/CD pipelines.
- **Coordination overhead**: The burden of testing lies with API consumers, but the maintenance and synchronization of contracts depends on the provider. This coordination requires meetings, training, and ongoing maintenance.
- **Learning curve**: Pact requires specialized knowledge on both the consumer and provider's side.
- **Misaligned incentives**: Pact separates the responsibility for the contract, from the responsibility of maintaining the service. It's hard to motivate the consumer teams to keep on top of maintaining Pact definitions when the services they are consuming are at the periphery of their day-to-day work. Out of sight, out of mind.
- **Duplication**: Each consumer team has to maintain their own Pact tests with overlap between teams likely.

In almost every case, OpenAPI offers comparable benefits without these costs.

But before we dive into OpenAPI, let's take a look at where Pact **does** shine.

### Where Pact shines

Large organizations with a multitude of internal microservices and strong inter-team communication channels may be able to make Pact work, regardless of the complexity and cost. Pact's high degree of assurance can also provide the confidence required to release updates to truly mission-critical services, where failures would be catastrophic. In that case, the cost of failure far outweighs the maintenance cost of Pact tests and workflows.

The decision to use Pact should be based on potential costs of API failures versus the ever-increasing complexity of maintaining Pact tests.

Now, let's take a look at OpenAPI as an alternative.

## The OpenAPI ecosystem approach

While Pact focuses on consumer-driven contracts, OpenAPI is effectively the reverse: a provider-driven API spec that guarantees a contract to the consumer. This approach aligns the responsibility for the contract with the responsibility of maintaining the service.

```mermaid
sequenceDiagram
    title Testing workflow with OpenAPI
    participant API Team
    participant Test Runner
    participant OpenAPI Spec
    participant Consumer Teams
    
    API Team->>Test Runner: Propose spec update
    Test Runner->>OpenAPI Spec: Test passed: publish
    OpenAPI Spec->>Consumer Teams: Consume API (directly or SDK)
    Note over Consumer Teams: Compile-time validation
    
    alt Breaking Change
        Test Runner->>API Team: Test failed: block release
        alt Manual release
          Test Runner->>OpenAPI Spec: Override Test: publish
        end
    end
```

### Benefits of using OpenAPI for contract testing

The OpenAPI approach offers several benefits over Pact:

1. **Reduced setup complexity**: OpenAPI specifications are easier to write and maintain than Pact tests. They can also be generated automatically from some API frameworks. Most orgs already have an OpenAPI specification for their API, so their is no setup cost.
2. **Little to no coordination needed between teams**: Since the API team owns the OpenAPI specification, consumers use the API as documented. There's no need for separate contracts or negotiation between teams.
3. **No duplication**: There is a single OpenAPI specification for every consumer. There's no need for per-team contracts.
4. **Early detection**: You can test changes to your API before writing code. You simply propose a change to the OpenAPI specification, and run your tests.


### Limitations of using OpenAPI for contract testing

OpenAPI is not specifically designed for contract testing. It's a specification for describing your API, and as such, it's not as comprehensive as Pact.

1. **Coverage scope**: OpenAPI-based testing is best suited for testing the API's contract and functionality. Natively, it may not catch all integration issues, especially those that involve multiple APIs or complex business logic. (More on this in the next section.)

2. **Specification maintenance**: OpenAPI specifications must be kept up-to-date with the API's actual behavior. If the specification falls out of sync with the API, consumers may encounter unexpected behavior. However, this is a common problem with any API testing strategy.

3. **Theoretical vs. actual**: In some ways, an OpenAPI spec is a theoretical contract. It describes all the ways the API can be used, but doesn't describe how the API is actually used in practice. This can lead to false positives in your tests. There may be a breaking change in the API, but in actual practice, no consumer is not using the API in that way.

## Future considerations

[Arazzo](/openapi/arazzo) is a recently published workflow specification that enables developers to describe complex workflows that involve multiple APIs. By combining OpenAPI-based testing with Arazzo, teams can [test end-to-end scenarios that span multiple APIs](/post/e2e-testing-arazzo), ensuring that their integrations work as expected.

### How Arazzo workflows enhance API testing

1. **End-to-end testing**: Arazzo workflows describe complex interactions between multiple APIs, enabling teams to test entire user journeys from start to finish.

2. **Scenario-based testing**: Workflows can describe different scenarios that users might encounter, such as error conditions, edge cases, or performance bottlenecks.

3. **Automated testing**: Workflows can be executed automatically as part of your CI/CD pipeline, ensuring that your integrations work as expected before they reach production.

4. **Improved developer experience**: By describing workflows in a human-readable format, Arazzo makes it easy for developers to understand and contribute to your testing efforts.

We foresee a future where teams combine OpenAPI-based testing with Arazzo workflows to create comprehensive, reliable, and maintainable API tests that catch integration issues early and often.

## Making the decision

When deciding between Pact and OpenAPI-based testing, consider the following factors:

1. **Team structure**
   - Teams with mission-critical internal dependencies might prefer Pact.
   - Smaller or more distributed teams could benefit more from OpenAPI's reduced complexity.

2. **Consumer profile**
   - If your APIs have many external consumers, OpenAPI is the better choice as it provides a single contract for every consumer.
   - APIs with few but tightly coupled internal consumers might justify Pact's effort for higher assurance.

3. **Resource availability**
   - Teams with limited resources may find OpenAPI more manageable due to lower overhead and maintenance.
   - Pact may require dedicated resources for broker management and contract maintenance.

4. **API complexity**
   - Straightforward APIs with straightforward interactions may not need the advanced features of Pact; OpenAPI suffices.
   - Complex APIs with functionality that lives outside the spec may still benefit from Pact's guarantees.

The choice between Pact and OpenAPI should align with your team's structure, goals, and resources. By understanding the trade-offs, you can make an informed decision that best suits your API strategies.

## Key differences between Pact and OpenAPI

- **Pact**: Offers thorough contract testing with a heavy emphasis on consumer-driven contracts but involves significant setup and maintenance complexity.
- **OpenAPI**: Provides a single contract for every consumer, and a single source of truth for your API. It is lightweight to implement, and requires no additional setup at the cost of some comprehensiveness.

## How to try OpenAPI-based testing

Speakeasy offers a simple way to get started with OpenAPI-based testing:

1. Start by creating an OpenAPI specification for your API, or add examples to your existing specification.
2. Sign up for [Speakeasy's testing beta](/product/api-testing) to generate test suites from your OpenAPI specification.

That's all there is to it. With Speakeasy, you can start testing your API with generated SDKs and tests in minutes.

If you made it this far, you're clearly interested in improving your API testing strategy. We're on a mission to solve this problem, and we'd love to hear from you. [Join our Slack community](https://join.slack.com/t/speakeasy-dev/shared_invite/zt-1cwb3flxz-lS5SyZxAsF_3NOq5xc8Cjw) to share your thoughts, or to learn more about Speakeasy.


 This is the content for the doc blog/picking-a-javascript-api-framework/index.mdx 

 ---
title: "Choosing the right JavaScript API framework"
description: "We compare the most popular and relevant JavaScript API frameworks to help you choose the right REST API framework for your project."
image: "/media/choosing-your-framework-js.png"
date: 2024-12-09
authors:
  - name: Nolan Di Mare Sullivan
  - image_url: "/media/author-headshots/nolan.jpeg"
tags:
  - API Advice
featured_image: "/media/choosing-your-framework-js.png"
---

The fast-paced and ever-evolving JavaScript ecosystem, with its plethora of server-side frameworks for building REST APIs in JavaScript and TypeScript, can feel overwhelming when choosing the right tool for your project.

This article explores the key factors for selecting a JavaScript API framework, covering community support, documentation, scalability, request-processing speed, concurrency, and OpenAPI compatibility, and provides a decision-making framework to help you choose between options like Express, NestJS, Fastify, Hono, and ElysiaJS.

## Factors to consider when choosing a JavaScript API framework
---

### Iteration speed

Speed is critical for startups and projects with tight deadlines. Selecting a JavaScript framework with a strong ecosystem ensures you can quickly build features and abstract logic without unnecessary complexity. Frameworks that support rapid development and scalability are ideal for MVPs.

For quick iteration and simplicity, consider frameworks like Express or Hono, which enable rapid endpoint creation while leaving room for future enhancements.

### Robustness and security

If your MVP has succeeded, or you need to build a secure API for an existing service, robustness and security take priority. To ensure a framework meets these needs, consider the following:

- Architecture: Look for clear patterns, like dependency injection or layered architectures, to ensure modularity, scalability, and maintainability.  
- Community support: Opt for frameworks with active communities, comprehensive documentation, and a strong ecosystem of plugins.  
- Maintenance: Consider frameworks with stable or LTS versions, regular updates, and consistent security patches.  
- TypeScript support: Strong typing and improved refactoring capabilities make TypeScript invaluable for reducing runtime errors in large-scale projects. 
- Security features: Built-in authentication, access control, and data validation tools simplify secure API implementation and reduce vulnerability risks.


### Maturity vs innovation

Bun has reshaped the JavaScript ecosystem by addressing the performance limitations often associated with Node.js. Known for its speed and optimization, Bun reduces the bottlenecks caused by slow Node.js core improvements.

Bun offers faster and safer development with native optimizations and built-in tools, including a JavaScript runtime, bundler, and task runner. However, compared to Node.js, which boasts over 15 years of stability, long-term support policies, and a vast ecosystem, Bun lacks maturity and comprehensive compatibility. Despite this, Bun is steadily improving its compatibility with Node.js libraries, enabling developers to explore its potential.

While frameworks like Express are compatible with Bun, Hono and ElysiaJS are specifically designed to leverage Bun's capabilities, offering streamlined integration and optimized performance.

**So, how do you choose between a newer framework and a more established one?**

If stability is essential and you want to avoid tools with an underdeveloped ecosystem or undocumented edge cases, opt for mature frameworks like Fastify, NestJS, or Express.

However, ElysiaJS is worth testing if you already have experience with Bun's ecosystem. While robust, it's best suited for developers who are comfortable taking risks and delving into source code to address issues, as error handling and documentation might be limited.

## Popular JavaScript API frameworks
---

### Express: Lightweight, simple, and battle-tested

[Express](https://expressjs.com/) is one of the oldest and most widely used JavaScript frameworks for building REST APIs. Valued for its simplicity and minimalism, Express provides a lightweight structure that allows developers to make their own architectural decisions. Its flexible design makes it ideal for projects with evolving or undefined requirements.

Here's an example of creating an endpoint to fetch a list of products from a database:

```javascript index.js
import express from "express";
import { Pool } from "pg";

// Create an Express app
const app = express();

// PostgreSQL database connection pool
const pool = new Pool({
  connectionString: 'postgres://user:password@localhost:5432/mydatabase',
});

// One-liner route to get all products
app.get('/products', async (req, res) => {
  try {
    res.json((await pool.query('SELECT * FROM products')).rows);
  } catch (error) {
    console.error('Error fetching products:', error.message);
    res.status(500).json({ error: 'Internal Server Error' });
  }
});

// Start the server
const PORT = 3000;
app.listen(PORT, () => {
  console.log(`🚀 Server is running at http://localhost:${PORT}`);
});
```

You can start the server with the `node index.js` command. This example demonstrates a basic Express application, but you can organize your code or leverage ecosystem tools to streamline development. Express relies on the middleware design pattern, where middleware processes requests, handles tasks like logging, authentication, or error handling, and passes control to the next middleware or route handler.

![Express middleware architecture example](./assets/express-middleware.png)

Find a list of middleware modules the Express team maintains [in the documentation](https://expressjs.com/en/resources/middleware.html).

### Hono: For serverless APIs with essential features

[Hono](/openapi/frameworks/hono) is a modern JavaScript framework tailored for serverless architectures that simplifies development by directly bundling features like authentication, middleware, and validation into the framework.

**Why choose serverless for your API?**

Serverless architecture reduces developer overhead by abstracting server management. Here are three technical benefits:

1. Cost efficiency: Pay only for your API's compute power, making it ideal for MVPs or traffic with unpredictable demand.  
2. Dynamic scaling: Platforms like AWS Amplify and Cloudflare Workers scale automatically during traffic spikes without manual intervention.  
3. Reduced complexity: Serverless manages infrastructure, patching, and scaling, letting developers focus on code.

Hono enhances these serverless advantages by offering built-in authentication, validation, and routing tools, minimizing external dependencies, and streamlining development.

Here is how you can write an API that returns a list of Pokémon, for example:

```javascript index.js
import { Hono } from 'hono';
import { logger } from 'hono/logger';
import { cors } from 'hono/cors';
import { swaggerUI } from '@hono/swagger-ui'

const app = new Hono();

// Pokémon data
const pokemons = [
  { id: 1, name: 'Bulbasaur', type: 'Grass/Poison' },
  { id: 2, name: 'Charmander', type: 'Fire' },
  { id: 3, name: 'Squirtle', type: 'Water' },
];

// Middleware: Logger
app.use('*', logger());

// Middleware: CORS
app.use('*', cors());

// Middleware: Swagger UI
app.get('/ui', swaggerUI({ url: '/doc' }))

// Route to return a list of Pokémon
app.get('/pokemons', (c) => {
  return c.json(pokemons);
});

export default app;
```

### NestJS: For Robust and Secure Enterprise Applications

As your project scales or if you need a robust and scalable solution from the start, frameworks with strong architectural foundations are the better choice, offering proven design patterns and built-in tools to effectively address security, reliability, and scalability. 
    
The framework that excels in building robust, scalable, maintainable applications is [NestJS](/openapi/frameworks/nestjs). Its opinionated architecture enforces best practices, making NestJS ideal for complex systems focused on security and reliability. Built on top of Express or, optionally, Fastify, NestJS provides a structured layer tailored to enterprise needs.

NestJS supports multiple programming paradigms:

- Object-oriented programming (OOP): Ensures modularity and encapsulation.  
- Functional programming (FP): Promotes clean, declarative logic.  
- Domain-driven design (DDD): Suitable for large, complex applications with intricate domain modeling.

NestJS's flexibility allows developers to handle simple CRUD operations and advanced business logic without compromising maintainability. 

Key built-in NestJS features that simplify development are:

- Authentication and authorization: Use [@nestjs/jwt](https://github.com/nestjs/jwt) for authentication and implement role-based access control (RBAC) with guards for enhanced security.  
- OpenAPI documentation: [@nestjs/swagger](https://docs.nestjs.com/openapi/introduction) automatically generates OpenAPI-compliant documentation, easing API consumption and integration.
- Deep TypeScript support: NestJS employs TypeScript's type system to provide robust type checking and ensure type safety throughout the application.
    
However, these benefits come with a significant inconvenience: verbosity. Let's see how we can create a simple API to manage books for a library.

First, you need to define the model. NestJS integrates well with Mongoose.

```typescript book.schema.ts
import { Prop, Schema, SchemaFactory } from '@nestjs/mongoose';
import { Document } from 'mongoose';

@Schema()
export class Book extends Document {
  @Prop({ required: true })
  title: string;

  @Prop({ required: true })
  author: string;

  @Prop()
  publishedYear: number;
}

export const BookSchema = SchemaFactory.createForClass(Book);
```

Then, you need to define the data transfer object (DTO), which helps validate incoming data.

```javascript create-book.dto.ts
export class CreateBookDto {
  readonly title: string;
  readonly author: string;
  readonly publishedYear?: number;
}
```

Next, you implement the service as the middleman between your application and the database. Queries to create and retrieve items can be defined here.

```javascript books.service.ts
import { Injectable } from '@nestjs/common';
import { InjectModel } from '@nestjs/mongoose';
import { Model } from 'mongoose';
import { Book } from './book.schema';
import { CreateBookDto } from './create-book.dto';

@Injectable()
export class BooksService {
  constructor(@InjectModel(Book.name) private readonly bookModel: Model<Book>) {}

  async getAllBooks(): Promise<Book[]> {
    return this.bookModel.find().exec();
  }

  async createBook(createBookDto: CreateBookDto): Promise<Book> {
    const newBook = new this.bookModel(createBookDto);
    return newBook.save();
  }
}
```

With the services defined, you can write the controller that will handle the requests to the REST API.

```javascript books.controller.ts
import { Controller, Get, Post, Body } from '@nestjs/common';
import { BooksService } from './books.service';
import { CreateBookDto } from './create-book.dto';
import { Book } from './book.schema';

@Controller('books')
export class BooksController {
  constructor(private readonly booksService: BooksService) {}

  @Get()
  async getAllBooks(): Promise<Book[]> {
    return this.booksService.getAllBooks();
  }

  @Post()
  async createBook(@Body() createBookDto: CreateBookDto): Promise<Book> {
    return this.booksService.createBook(createBookDto);
  }
}
```

The `BooksController` will expose these endpoints:

- `GET /books`: Retrieve all books.
    
- `POST /books`: Add a new book.
    

The defined components are part of the books module, which registers the providers (services), controllers, and schema, ensuring modularity and organization within the application.

```javascript books.module.ts
import { Module } from '@nestjs/common';
import { MongooseModule } from '@nestjs/mongoose';
import { BooksController } from './books.controller';
import { BooksService } from './books.service';
import { Book, BookSchema } from './book.schema';

@Module({
  imports: [MongooseModule.forFeature([{ name: Book.name, schema: BookSchema }])],
  controllers: [BooksController],
  providers: [BooksService],
})
export class BooksModule {}
```

Finally, you can add the `BooksModule` to the main module.

```javascript app.module.ts
import { Module } from '@nestjs/common';
import { MongooseModule } from '@nestjs/mongoose';
import { BooksModule } from './books/books.module';

@Module({
  imports: [
    MongooseModule.forRoot('mongodb://localhost/nest-books'),
    BooksModule,
  ],
})
export class AppModule {}
```

NestJS's structured approach, though initially tedious, is justified by its ability to simplify the management of complex applications, even in large teams. Its modular design ensures that every component – models, DTOs, controllers, and modules – has a clear and defined role, reducing ambiguity and enforcing best practices.

This focus on robust architecture and built-in features makes NestJS a trusted choice for critical applications, as evidenced by its use in organizations like [Adidas](https://adidas.github.io/) and Société Générale. When robustness and security are essential, NestJS provides the reliability needed. 


### Fastify: A replacement for Express

JavaScript's asynchronous core makes it inherently fast, but not all frameworks maximize its potential. A notable limitation of Express is its lack of optimization for asynchronous workflows. Although Express now supports `async/await`, its core, originally designed for callbacks, doesn't handle errors in async route handlers automatically.

For example, if an `async` route handler throws an error or rejects a promise, you must explicitly use a `try/catch` block or pass errors to `next()` to invoke the built-in error-handling mechanism. Without this, unhandled errors may crash the application, highlighting Express's limitations in modern asynchronous processing.

```javascript
app.get('/products', async (req, res, next) => {
  try {
    const data = await someAsyncFunction();
    res.json(data);
  } catch (err) {
    next(err); // Pass the error to the Express error handler
  }
});
```

Without `try/catch` or `next(err)`, the application might crash or fail to handle the error appropriately. In addition, older third-party middleware in Express may not always support `async/await` out of the box, which can lead to performance bottlenecks, as the architecture doesn't optimize for high-throughput asynchronous tasks.

This is where [Fastify](/openapi/frameworks/fastify) is a framework worth considering, offering syntax and ease of use that closely resemble Express. To illustrate, here is how the example we wrote for the product REST API built with Express can be implemented with Fastify:

```javascript index.js
import Fastify from 'fastify';
import { createPool } from './db.js';

// Create a Fastify instance
const fastify = Fastify({ logger: true });

// Import PostgreSQL connection pool
const pool = createPool();

// Route to get all products
fastify.get('/products', async (request, reply) => {
  try {
    const { rows } = await pool.query('SELECT * FROM products');
    reply.send(rows);
  } catch (error) {
    fastify.log.error(error);
    reply.status(500).send({ error: 'Internal Server Error' });
  }
});

// Start the server
const startServer = async () => {
  try {
    await fastify.listen({ port: 3000 });
    console.log('🚀 Server is running at http://localhost:3000');
  } catch (err) {
    fastify.log.error(err);
    process.exit(1);
  }
};

startServer();
```

The `GET /products` route can also be written using `fastify.route`. This method helps with schema definition for both the response and request and integrates with Fastify's built-in support for OpenAPI documentation generation if needed.

```javascript
// Define the schema for the route
const getProductsSchema = {
  response: {
    200: {
      type: 'array',
      items: {
        type: 'object',
        properties: {
          id: { type: 'integer' },
          name: { type: 'string' },
          price: { type: 'number' },
          description: { type: 'string' },
        },
        required: ['id', 'name', 'price'],
      },
    },
  },
};

// Define the route
fastify.route({
  method: 'GET',
  url: '/products',
  schema: getProductsSchema,
  handler: async (request, reply) => {
    try {
      const { rows } = await pool.query('SELECT * FROM products');
      reply.send(rows);
    } catch (error) {
      fastify.log.error(error);
      reply.status(500).send({ error: 'Internal Server Error' });
    }
  },
});
```

Fastify excels in high-performance server setups by using a refined asynchronous model. Fastify, built on `async/await` and Promises, ensures non-blocking request handling with exceptional efficiency. Fastify's key features include:

* Schema validation: Streamlines request and payload validation, reducing runtime overhead.
    
* Logging performance: Integrated with [Pino](https://github.com/pinojs/pino) at its core, Fastify provides fast, low-cost logging even under heavy loads.
    
* Throughput: Fastify can handle up to 30,000 requests per second, making it one of the fastest frameworks for traditional or containerized setups. That's [2x to 3x time faster than ExpressJS](https://thenewstack.io/a-showdown-between-express-js-and-fastify-web-app-frameworks/).
    

Fastify's speed also comes from using the `fast-json-stringify` library for efficient JSON handling and a lightweight, plugin-based architecture that optimizes components and connections.

Thanks to its high performance and plugin-based architecture, Fastify is an excellent choice for building fast, lightweight MVPs as it simplifies initial development. Fastify can serve as the HTTP adapter for a more robust framework, like NestJS, making it a strategic choice: Start with Fastify for speed and agility, then migrate to NestJS when requirements for modularity, maintainability, and advanced features like dependency injection and guards become priorities.

### ElysiaJS: For speed and developer experience

With the emergence of Bun, the latest and fastest JavaScript runtime, new frameworks and paradigms are redefining the ecosystem. This raises the question: Should you choose a mature or cutting-edge framework?

[ElysiaJS](https://elysiajs.com/) is a notable framework optimized for Bun and Node.js environments. Designed for high performance and developer experience, ElysiaJS includes features like route schema definitions that efficiently generate API documentation using tools such as Swagger UI or Scalar, providing a modern, responsive interface for managing APIs. 

Here's an example of an API written in ElysiaJS with OpenAPI schema definitions:

```javascript index.js
import process from 'node:process'
import { Elysia } from 'elysia'
import { logger } from '@bogeychan/elysia-logger'
import { swagger } from '@elysiajs/swagger'
import { cors } from '@elysiajs/cors'
import { prisma } from './db'
import { getAllProducts } from './orm'

const app = new Elysia()
  .use(logger())
  .use(
    swagger({
      documentation: {
        info: {
          title: 'Products API',
          version: '1.0.0',
          description: 'API documentation for retrieving all products.',
        },
        servers: [
          {
            url: 'http://localhost:3000',
          },
        ],
        tags: [
          { name: 'Products', description: 'Product endpoints' },
        ],
        components: {
          schemas: {
            Product: {
              type: 'object',
              properties: {
                id: {
                  type: 'integer',
                },
                name: {
                  type: 'string',
                },
                shopId: {
                  type: 'integer',
                },
              },
            },
          },
        },
      },
    }),
  )
  .use(cors())
  .get(
    '/api/products',
    async () => {
      const products = await getAllProducts()
      return products
    },
    {
      detail: {
        tags: ['Products'],
        summary: 'Get all products',
      },
    },
  )

await prisma.$connect()

app.listen(process.env.PORT as string, () =>
  console.info(`🦊 Server started at ${app.server?.url.origin}`))
```

The code above exposes a `GET /api/products` API route but also does something interesting: It generates documentation built on [Scalar UI](https://scalar.com/). Visiting `https://localhost:3000/swagger` will return a page similar to this:

![ElysiaJS Scalar UI](./assets/elysiajs-scalar.png)

## Making pragmatic choices

The JavaScript API frameworks discussed here each have distinct strengths and trade-offs, making it challenging to select the right one for your project. We've included a flowchart outlining key factors like performance, scalability, and stability and a decision table that maps everyday use cases to recommended frameworks to assist in this decision.

Use the flowchart to narrow your choices based on your project's needs and priorities. Then, consult the decision table to find the framework that best matches your requirements.

![Flowchart to choose a JavaScript API framework](./assets/framework-js-selection.png)

| Scenario                       | Recommended framework | Why?                                                                                               |
|--------------------------------|-----------------------|----------------------------------------------------------------------------------------------------|
| MVP with limited resources     | Hono, Fastify         | Lightweight, fast, and easy to set up. It is ideal for rapid iteration and serverless deployments. |
| Enterprise-grade applications  | NestJS                | Provides a structured architecture, robust security, and maintainability for large-scale systems.  |
| Heavily async workloads        | Fastify               | Optimized for high-throughput and non-blocking operations, outperforming Express in concurrency.   |
| Familiarity with Node.js tools | Express               | A stable and well-documented ecosystem with extensive middleware options.                          |
| Experimenting with Bun         | ElysiaJS              | High performance with unique developer tools, leveraging Bun's runtime for cutting-edge projects.  |

To be concise, consider:

- Stability or speed? Express and NestJS for stability; Fastify and ElysiaJS for speed.  
- New or scaling? Hono and Fastify for new projects; NestJS for scaling.  
- Features vs risk? NestJS provides robust features; Hono and ElysiaJS are lightweight and modern.  
- Team expertise? Express suits familiar teams; ElysiaJS is ideal for Bun experts.

For stability, choose Express or NestJS; explore Fastify, Hono, or ElysiaJS for speed and innovation.


 This is the content for the doc blog/pulumi-terraform-provider.mdx 

 ---
title: "How To Wrap Your Terraform Provider for Pulumi"
description: "An actionable guide on making your Terraform provider available on Pulumi."
keywords:
  [
    terraform,
    terraform provider,
    api,
    openapi,
    swagger,
    sdk generation,
    go,
    golang,
    go sdk,
    golang sdk,
    developer experience,
    devex,
    dx,
  ]
image: "/media/wrap-terraform-pulumi.png"
date: 2023-09-15
authors:
  - name: Thomas Rooney
  - image_url: "/media/author-headshots/thomas.jpeg"
tags:
  - Terraform
featured_image: "/media/wrap-terraform-pulumi.png"
---

In this post, we'll show you how to make a Terraform provider available on Pulumi. The article assumes some prior knowledge of Terraform and Pulumi, as well as fluency in Go. If you are new to Terraform providers, please check out [our Terraform documentation](/docs/create-terraform/).

While we provide instructions for building a Pulumi provider here, the resultant provider is not intended for production use. If you want to maintain a Pulumi provider as part of your product offering, we recommend you get in touch with us. Without a partner, providers can become a significant ongoing cost.

## Why Users Are Switching From Terraform to Pulumi

Following the recent [HashiCorp license change](https://www.hashicorp.com/blog/hashicorp-adopts-business-source-license), many users are exploring Pulumi as an alternative to Terraform.

The license change came as a surprise. In response, many companies are considering alternatives to manage their infrastructure-as-code setup. Given the scale of the Terraform ecosystem, it's unlikely that the license change will lead to Terraform disappearing. However, we can expect to see some fragmentation in the market.

If you're used to Terraform, you might notice that Pulumi has fewer providers available. Currently, Pulumi offers 125 providers in their registry, while Terraform boasts an incredible 3,511.

We know the comparison isn't completely fair, though – some users take the "everything-as-code" approach to the extreme, with providers for [ordering pizza](https://registry.terraform.io/providers/MNThomson/dominos/latest/docs), [building Factorio factories](https://github.com/efokschaner/terraform-provider-factorio), and [placing blocks in Minecraft](https://registry.terraform.io/providers/HashiCraft/minecraft/latest). But even accounting for hobbyist providers, it's clear that Terraform has significantly more third-party support.

So, let's look at how we can shrink that provider gap...

## How Pulumi Differs From Terraform

Pulumi and Terraform are both infrastructure-as-code tools, but they [differ in many ways](https://www.pulumi.com/docs/concepts/vs/terraform/), most importantly in the languages they support.

Terraform programs are defined in the declarative HashiCorp Configuration Language (HCL), while Pulumi allows users to create imperative programs using familiar programming languages like Python, Go, JavaScript, TypeScript, C#, and Java.

This difference has some benefits and drawbacks. With Pulumi's imperative approach, users have more control over how their infrastructure is defined and can write complex logic that isn't easily expressed in Terraform's declarative language. However, this also means that Pulumi code can be less readable than Terraform code.

## Bridging Terraform and Pulumi

Pulumi provides two tools to help maintainers build bridge providers. The first is [Pulumi Terraform Bridge](https://github.com/pulumi/pulumi-terraform-bridge), which creates Pulumi SDKs based on a Terraform provider schema. The second repository, [Terraform Bridge Provider Boilerplate](https://github.com/pulumi/pulumi-tf-provider-boilerplate), is a template for building a new Pulumi provider based on a Terraform provider.

While creating a new provider, we'll use the Terraform Bridge Provider Boilerplate, but we'll often call functions from the Pulumi Terraform Bridge.

Pulumi Terraform Bridge is actively maintained, so bear in mind that the requirements and steps below may change with time.

## How the Pulumi Terraform Bridge Works

Pulumi Terraform Bridge plays an important role during two distinct phases: design time and runtime.

During design time, Pulumi Terraform Bridge inspects a Terraform provider schema, then generates Pulumi SDKs in multiple languages.

At runtime, the bridge connects Pulumi to the underlying resource via the Terraform provider schema. This way, the Terraform provider schema continues to perform validation and calculates differences between the state in Pulumi and the resource state.

Pulumi Terraform Bridge does not use the Terraform provider binaries. Instead, it creates a Pulumi provider based only on a Terraform provider's Go modules and provider schema.

## Step by Step: Creating a Terraform Bridge Provider in Pulumi

The process of creating a Pulumi provider differs slightly depending on how the Terraform provider was created. In the past, most Terraform providers were based on [Terraform Plugin SDK](https://github.com/hashicorp/terraform-plugin-sdk). More recent providers are usually based on [Terraform Plugin Framework](https://github.com/hashicorp/terraform-plugin-framework).

The steps you'll follow depend on your Terraform provider. Inspect the `go.mod` file in your provider to see whether it depends on `github.com/hashicorp/terraform-plugin-sdk` or `github.com/hashicorp/terraform-plugin-framework`.

### Prerequisites

We manually installed the required tools before noticing that the Terraform Bridge Provider Boilerplate contains a Dockerfile to set up a development image. The manual process wasn't too painful, and either method should work.

The following must be available in your `$PATH`:

- [`pulumictl`](https://github.com/pulumi/pulumictl#installation)
- [Pulumi](https://www.pulumi.com/docs/install/)
- [Go 1.17](https://golang.org/dl/) or 1.latest
- [NodeJS](https://nodejs.org/en/) 14.x – we recommend using [nvm](https://github.com/nvm-sh/nvm) to manage Node.js installations
- [Yarn](https://yarnpkg.com/)
- [TypeScript](https://www.typescriptlang.org/)
- [Python](https://www.python.org/downloads/) (called as `python3`) – for recent versions of macOS, the system-installed version is fine
- [.NET](https://dotnet.microsoft.com/download)

### Terraform Plugin SDK to Pulumi

As an example of a Terraform provider based on Terraform Plugin SDK, we'll use this [Spotify Terraform provider](https://github.com/conradludgate/terraform-provider-spotify), a small provider for managing Spotify playlists with Terraform.

To create a new Pulumi provider, we'll start with the [Terraform Bridge Provider Boilerplate](https://github.com/pulumi/pulumi-tf-provider-boilerplate).

#### Clone the Terraform Bridge Provider Boilerplate

Go to the [Terraform Bridge Provider Boilerplate](https://github.com/pulumi/pulumi-tf-provider-boilerplate) repository in GitHub and click on the green **Use this template** button. Select **Create a new repository** from the dropdown.

Select your organization as the owner of the new repository (we'll use `speakeasy-api`) and create a name for your Pulumi provider. In Pulumi, it is conventional to use `pulumi-` followed by the resource name in lowercase as the provider name. We'll use `pulumi-spotify`.

Click **Create repository**.

Use your Git client of choice to clone your new Pulumi provider repository on your local machine. Our examples below will use the command line on macOS.

In the terminal, replace `speakeasy-api` with your GitHub organization name in the code below and run it:

```bash mark=1[26:38]
git clone git@github.com:speakeasy-api/pulumi-spotify.git
cd pulumi-spotify
```

#### Rename Pulumi-Specific Strings in the Boilerplate

The Pulumi Terraform Bridge Provider Boilerplate in its current state is primarily an internal tool used by the Pulumi team to bring Terraform providers into Pulumi. We need to replace a few instances where the boilerplate assumes Pulumi will publish the provider in their GitHub organization.

The `Makefile` has a `prepare` command that handles some of the string replacement. In the terminal, replace `speakeasy-api` with your GitHub organization name in the command below and run it:

```bash mark=1[49:61]
make prepare NAME=spotify REPOSITORY=github.com/speakeasy-api/pulumi-spotify
```

The `make` command will print the `sed` commands it ran to replace the boilerplate strings in two files in the repo.

Next, we'll use `sed` to replace strings in the rest of the repo:

In the terminal, replace `speakeasy-api` with your GitHub organization name, then run:

```bash mark=5[55:67]
find . -not \( -name '.git' -prune \) /
	-not -name 'Makefile' /
	-type f /
	-exec sed /
	-i '' 's|github.com/pulumi/pulumi-spotify|github.com/speakeasy-api/pulumi-spotify|g' {} \;
```

In the `Makefile`, replace the `ORG` variable with the name of your GitHub organization.

Finally, in the `provider/resources.go` file, manually replace the values in the `tfbridge.ProviderInfo` struct. Many of these values define names and other fields in the resulting Pulumi SDK packages. Set the `GitHubOrg` to `conradludgate`.

#### Import Your Terraform Provider

Back in the `provider/resources.go` file, replace the `github.com/terraform-providers/terraform-provider-spotify/spotify` import with `github.com/conradludgate/terraform-provider-spotify/spotify`.

In a terminal run the following to change into the provider directory and install requirements.

```bash
cd provider
go mod tidy
```

#### Fix a Dependency Version

This temporary step is a workaround related to the version of `terraform-plugin-sdk` imported in the boilerplate.

During our testing, we encountered a bug in `terraform-plugin-sdk` that was fixed in `v2.0.0-20230710100801-03a71d0fca3d`.

In `provider/go.mod`, replace `replace github.com/hashicorp/terraform-plugin-sdk/v2 => github.com/pulumi/terraform-plugin-sdk/v2 v2.0.0-20220824175045-450992f2f5b9` with `replace github.com/hashicorp/terraform-plugin-sdk/v2 => github.com/pulumi/terraform-plugin-sdk/v2 v2.0.0-20230710100801-03a71d0fca3d`. Note the difference in the version strings.

#### Remove Outdated `make` Step

This temporary step removes a single line from the `Makefile` that copies a nonexistent `scripts` directory while building the Node.js SDK. In earlier versions of Pulumi, the Node.js SDK included a `scripts` folder containing `install-pulumi-plugin.js`, but [Pulumi no longer generates these files](https://github.com/pulumi/pulumi/issues/13195#issuecomment-1703318022).

In the `Makefile`, remove the `cp -R scripts/ bin && \` line from `build_nodejs`:

```makefile Makefile
# !focus(7)
build_nodejs:: VERSION := $(shell pulumictl get version --language javascript)
build_nodejs:: install_plugins tfgen # build the node sdk
	$(WORKING_DIR)/bin/$(TFGEN) nodejs --overlays provider/overlays/nodejs --out sdk/nodejs/
	cd sdk/nodejs/ && \
        yarn install && \
        yarn run tsc && \
		cp -R scripts/ bin && \ # remove this line
        cp ../../README.md ../../LICENSE package.json yarn.lock ./bin/ && \
		sed -i.bak -e "s/\$${VERSION}/$(VERSION)/g" ./bin/package.json
```

#### Remove the Nonexistent `prov.MustApplyAutoAliasing()` Function

In `provider/resources.go`, remove the line `prov.MustApplyAutoAliasing()` from the `Provider()` function.

#### Build the Generator

In the terminal, run:

```bash
make tfgen
```

Go will build the `pulumi-tfgen-spotify` binary. You can safely ignore any warnings about missing documentation. This can be resolved by mapping documentation from Terraform to Pulumi, but we won't cover that in this guide because the Pulumi boilerplate code does not include this step yet.

#### Build the Provider

In the terminal, run:

```bash
make provider
```

Go now builds the `pulumi-resource-spotify` binary and outputs the same warnings as before.

#### Build the SDKs

In the final step, Pulumi generates SDK packages for .NET, Go, Node.js, and Python.

In the terminal, run:

```bash
make build_sdks
```

You can find the generated SDKs in the new `sdk` directory in your repository.

### Terraform Plugin Framework to Pulumi

As we mentioned earlier, more recent Terraform plugins are based on Terraform Plugin Framework instead of Terraform Plugin SDK. The way Terraform Plugin Framework structures Go code adds a few extra steps when bridging a plugin to Pulumi.

The difference is significant enough that Pulumi Terraform Bridge includes a dedicated tool called [Pulumi Bridge for Terraform Plugin Framework](https://github.com/pulumi/pulumi-terraform-bridge/blob/master/pf/README.md) in its main repository.

As with providers created using Terraform Plugin SDK, Pulumi Bridge for Terraform Plugin Framework needs to create a new Go binary that calls the Terraform plugin's new provider function. Plugins created with Terraform Plugin Framework define their new provider functions in an _internal_ package, which means we can't import the package directly.

To work around this, we'll create a shim that imports the internal package and exposes a function to our bridge.

But we're getting ahead of ourselves. Let's look at a step-by-step example.

#### Airbyte Terraform Provider

For this example, we'll bridge the [Airbyte Terraform provider](https://registry.terraform.io/providers/airbytehq/airbyte/latest/docs) to Pulumi. While not the focus of this guide, it is worth mentioning that this provider was [entirely generated by Speakeasy](/customers/airbyte).

#### Clone the Terraform Bridge Provider Boilerplate

Go to the [Terraform Bridge Provider Boilerplate](https://github.com/pulumi/pulumi-tf-provider-boilerplate) repository in GitHub and click on the green **Use this template** button. Select **Create a new repository** from the dropdown.

Select your organization as the owner of the new repository (we'll use `speakeasy-api` again) and create a name for your Pulumi provider. Let's use `pulumi-airbyte`.

Click **Create repository**.

Use your Git client of choice to clone your new Pulumi provider repository on your local machine. Our examples below will use the command line on macOS.

In the terminal, replace `speakeasy-api` with your GitHub organization name in the code below and run it:

```bash mark=1[26:38]
git clone git@github.com:speakeasy-api/pulumi-airbyte.git
cd pulumi-airbyte
```

#### Rename Pulumi-Specific Strings in the Boilerplate

You'll remember that the Pulumi Terraform Bridge Provider Boilerplate in its current state is primarily an internal tool used by the Pulumi team to bring Terraform providers into Pulumi, so we need to replace a few instances where the boilerplate assumes Pulumi will publish the provider in their GitHub organization.

The `Makefile` has a `prepare` command that handles some of the string replacement. In the terminal, replace `speakeasy-api` with your GitHub organization name in the command below and run it:

```bash mark=1[49:61]
make prepare NAME=airbyte REPOSITORY=github.com/speakeasy-api/pulumi-airbyte
```

The `make` command will print the `sed` commands it ran to replace the boilerplate strings in two files in the repo.

Next, we'll use `sed` to replace strings in the rest of the repo.

In the terminal, replace `speakeasy-api` with your GitHub organization name, then run:

```bash mark=5[55:67]
find . -not \( -name '.git' -prune \) /
	-not -name 'Makefile' /
	-type f /
	-exec sed /
	-i '' 's|github.com/pulumi/pulumi-airbyte|github.com/speakeasy-api/pulumi-airbyte|g' {} \;
```

In the `Makefile`, replace the `ORG` variable with the name of your GitHub organization.

In the `provider/resources.go` file, manually replace the values in the `tfbridge.ProviderInfo` struct. Many of these values define names and other fields in the resulting Pulumi SDK packages. Set the `GitHubOrg` to your `airbytehq`.

Most importantly, in `provider/resources.go`, replace `fmt.Sprintf("github.com/pulumi/pulumi-%[1]s/sdk/", mainPkg),` with `fmt.Sprintf("github.com/speakeasy-api/pulumi-%[1]s/sdk/", mainPkg),`:

```diff provider/resources.go mark=3[29:41]
  ImportBasePath: filepath.Join(
-   fmt.Sprintf("github.com/pulumi/pulumi-%[1]s/sdk/", mainPkg),
+   fmt.Sprintf("github.com/speakeasy-api/pulumi-%[1]s/sdk/", mainPkg),
    tfbridge.GetModuleMajorVersion(version.Version),
```

Remember to replace `speakeasy-api` with your organization name.

#### Remove Outdated `make` Step

This temporary step removes a single line from the `Makefile` that copies a nonexistent `scripts` directory while building the Node.js SDK. In earlier versions of Pulumi, the Node.js SDK included a `scripts` folder containing `install-pulumi-plugin.js`, but [Pulumi no longer generates these files](https://github.com/pulumi/pulumi/issues/13195#issuecomment-1703318022).

In the `Makefile`, remove the `cp -R scripts/ bin && \` line from `build_nodejs`:

```makefile Makefile
# !focus(7)
build_nodejs:: VERSION := $(shell pulumictl get version --language javascript)
build_nodejs:: install_plugins tfgen # build the node sdk
	$(WORKING_DIR)/bin/$(TFGEN) nodejs --overlays provider/overlays/nodejs --out sdk/nodejs/
	cd sdk/nodejs/ && \
        yarn install && \
        yarn run tsc && \
		cp -R scripts/ bin && \ # remove this line
        cp ../../README.md ../../LICENSE package.json yarn.lock ./bin/ && \
		sed -i.bak -e "s/\$${VERSION}/$(VERSION)/g" ./bin/package.json
```

#### Remove the Nonexistent ‘prov.MustApplyAutoAliasing()’ Function

In `provider/resources.go`, remove the line `prov.MustApplyAutoAliasing()` from the `Provider()` function.

#### Create a Shim To Import the Internal New Provider Function

Start with a new directory called `provider/shim` in your `pulumi-airbyte` project:

```bash
mkdir provider/shim
```

Add a `go.mod` file to this directory with the following contents:

```go provider/shim/go.mod
module github.com/airbytehq/terraform-provider-airbyte/shim

go 1.18

require (
  github.com/airbytehq/terraform-provider-airbyte latest
  github.com/hashicorp/terraform-plugin-framework v1.3.5
)
```

Now we'll add `shim.go` to this directory:

```go provider/shim/shim.go
package shim

import (
	tfpf "github.com/hashicorp/terraform-plugin-framework/provider"
	"github.com/airbytehq/terraform-provider-airbyte/internal/provider"
)

func NewProvider() tfpf.Provider {
	return provider.New("dev")()
}
```

#### Add Shim Requirements

To have Go gather the requirements for our shim module, run the following from the root of the project:

```bash
cd provider/shim
go mod tidy
cd ../..
```

#### Import the New Shim Provider and the Terraform Package Framework Bridge

In `provider/resources.go`, edit your imports to look like this (replace `speakeasy-api` with your organization name):

```go provider/resources.go mark=11[14:26]
import (
	"fmt"
	"path/filepath"

	"github.com/pulumi/pulumi-terraform-bridge/v3/pkg/tfbridge"
	"github.com/pulumi/pulumi-terraform-bridge/v3/pkg/tfbridge/tokens"
	shim "github.com/pulumi/pulumi-terraform-bridge/v3/pkg/tfshim"
	// Import the Pulumi Terraform Framework Bridge:
	pf "github.com/pulumi/pulumi-terraform-bridge/pf/tfbridge"
	"github.com/pulumi/pulumi/sdk/v3/go/common/resource"
	"github.com/speakeasy-api/pulumi-airbyte/provider/pkg/version"
	// Import our shim:
	airbyteshim "github.com/airbytehq/terraform-provider-airbyte/shim"
)
```

#### Instantiate the Shimmed Provider

In `provider/resources.go`, replace `shimv2.NewProvider(airbyte.Provider())` with `pf.ShimProvider(airbyteshim.NewProvider())`:

```diff provider/resources.go
func Provider() tfbridge.ProviderInfo {
    // Instantiate the Terraform provider
-   p := shimv2.NewProvider(airbyte.Provider())
+   p := pf.ShimProvider(airbyteshim.NewProvider())
```

#### Add the Shim Module as a Requirement

Edit `provider/go.mod`, and add `github.com/airbytehq/terraform-provider-airbyte/shim v0.0.0` to the requirements.

```go provider/go.mod
require (
	github.com/airbytehq/terraform-provider-airbyte/shim v0.0.0
	// ...
)
```

Also in `provider/go.mod`, replace `github.com/airbytehq/terraform-provider-airbyte/shim` with `./shim` as shown below, to let the Go compiler look for the shim in our local repository:

```go provider/go.mod
replace (
	github.com/airbytehq/terraform-provider-airbyte/shim => ./shim
)
```

#### Install Go Requirements

From the root of the project, run:

```bash
cd provider
go mod tidy
cd ..
```

#### Build the Generator

In the terminal, run:

```bash
make tfgen
```

Go will build the `pulumi-tfgen-airbyte` binary. You can safely ignore any warnings about missing documentation. The missing documentation warnings can be resolved by mapping documentation from Terraform to Pulumi, but we won't cover that in this guide as the Pulumi boilerplate code does not include this step yet.

#### Build the Provider

In the terminal, run:

```bash
make provider
```

Go now builds the `pulumi-resource-airbyte` binary and outputs the same warnings as before.

#### Build the SDKs

In the final step, Pulumi generates SDK packages for .NET, Go, Node.js, and Python.

In the terminal, run:

```bash
make build_sdks
```

You can find the generated SDKs in the new `sdk` directory in your repository.

## Summary

We hope this comparison of Terraform and Pulumi and our step-by-step guide to bridging a Terraform provider into Pulumi has been useful to you. You should now be able to create a Pulumi provider based on your Terraform provider.

Speakeasy can help you generate a Terraform provider based on your OpenAPI specifications. Follow [our documentation](/docs/create-terraform) to enter this exciting ecosystem.

Speakeasy is considering adding Pulumi support. [Join our Slack community](https://join.slack.com/t/speakeasy-dev/shared_invite/zt-1cwb3flxz-lS5SyZxAsF_3NOq5xc8Cjw) to discuss this or for expert advice on Terraform providers.


 This is the content for the doc blog/pydantic-vs-dataclasses.mdx 

 ---
title: "Type Safety in Python: Pydantic vs. Data Classes vs. Annotations vs. TypedDicts"
description: "Runtime errors can break your Python code. Learn how to enforce type safety with Pydantic, data classes, annotations and TypedDicts."
image: "/media/python-type-safety.png"
date: 2024-08-29
authors:
  - name: Tristan Cartledge
  - image_url: "/media/author-headshots/tristan.jpeg"
tags:
  - API Advice
featured_image: "/media/python-type-safety.png"
---

import { Callout } from "~/components";

<Callout title="Tip" variant="success">
  A massive thank you to [Sydney Runkle](https://x.com/sydneyrunkle) from the
  [Pydantic](https://pydantic.dev/) team for her invaluable feedback and
  suggestions on this post!!
</Callout>

Python's dynamic typing is one of its greatest strengths. It is the language developers use to get things done without getting bogged down by type definitions and boilerplate code. When prototyping, you don't have time to think about unions, generics, or polymorphism - close your eyes, trust the interpreter to guess your variable's type, and then start working on the next feature.

That is, until your prototype takes off and your logs are littered with `TypeError: 'NoneType' object is not iterable` or `TypeError: unsupported operand type(s) for /: 'str' and 'int'`. You might blame the users for adding units in the amount field, or the frontend devs for posting `null` instead of `[]`. So you fix the bug with another `if` statement, a `try` block, or the tenth validation function you've written this week. No time for reflection, just keep shipping, right? The ball of twine must grow.

We all know there is a better way. Python has had type annotations for years, and data classes and typed dictionaries allow us to document the shapes of the objects we expect.

Pydantic is the most comprehensive solution available to enforce type safety and data validation in Python, which is why we chose it for our SDKs at Speakeasy.

In this post we'll run through how we got to this conclusion. We'll detail the history of type safety in Python and explain the differences between: type annotations, data classes, TypedDicts, and finally, Pydantic.

## If It Walks Like a Duck and It Quacks Like a Duck, Then It Must Be a Duck

Python is a [duck-typed language](https://docs.python.org/3/glossary.html#term-duck-typing). In a duck-typed language, an object's type is determined by its behavior at runtime, based on the parts of the object that are actually used. Duck-typing makes it easier to write generic code that works with different types of objects.

If your code expects a `Duck` object to make it quack, Python doesn't care if the object is a `Mallard` or a `RubberDuck`. From Python's perspective, anything with a `quack` method is a `Duck`:

```python
class Duck:
    def quack(self):
        print("Quack!")

class Mallard:
    def quack(self):
        print("Quack!")

def make_duck_quack(duck):
    duck.quack()

make_duck_quack(Duck()) # prints "Quack!"
make_duck_quack(Mallard()) # prints "Quack!"
```

This code runs without errors, even though `make_duck_quack` expects a `Duck` object in our mental model, and we pass it a `Mallard` object. The `Mallard` object has a `quack` method, so it behaves like a `Duck` object.

One of the reasons for Python's popularity is its flexibility. You can write generic and reusable code without worrying about the specific object types.

But this flexibility comes at a cost. If you pass the wrong type of object to a function you'll only find out at runtime, leading to bugs that are difficult to track down.

This was the motivation behind developing type annotations.

## Type Annotations

Type annotations were introduced in Python 3.5 to add optional type hints to your code ([PEP 484](https://www.python.org/dev/peps/pep-0484/)). Type hints can help you catch bugs while you are still writing your code by telling you when you pass the wrong type of object to a function.

<Callout title="TIP" variant="info">
To make the most of these type hints, many developers use type checkers. Type checkers are tools that analyze your Python code without running it, looking for potential type-related errors. One popular type checker is [Pylance](https://marketplace.visualstudio.com/items?itemName=ms-python.vscode-pylance), a Visual Studio Code Extension that checks your Python code for type mismatches and shows you hints in your IDE.

If you're not using VS Code, [Pyright](https://github.com/microsoft/pyright/tree/main) has similar functionality and can be run from the [command line](https://microsoft.github.io/pyright/#/command-line) or as an [extension](https://microsoft.github.io/pyright/#/installation) to many text editors.

</Callout>

Here's how you can add type hints to the `make_duck_quack` function:

```python
# !mark(15:16)
class Duck:
    def quack(self):
        print("Quack!")


class RubberDuck:
    def quack(self):
        print("Quack!")


def make_duck_quack(duck: Duck):
    duck.quack()

make_duck_quack(Duck()) # prints "Quack!"
make_duck_quack(RubberDuck())
# Pylance will show the hint: Argument 1 to "make_duck_quack" has incompatible type "RubberDuck"; expected "Duck".
```

Now, when you pass a `RubberDuck` object to the `make_duck_quack` function, your IDE hints that there's a type mismatch. Using annotations won't prevent you from running the code if there is a type mismatch, but it can help you catch bugs during development.

This covers type annotations for functions, but what about classes? We can use data classes to define a class with specific types for its fields.

## Data Classes

Data classes were introduced in Python 3.7 ([PEP 557](https://www.python.org/dev/peps/pep-0557/)) as a convenient way to create classes that are primarily used to store data. Data classes automatically generate special methods like `__init__()`, `__repr__()`, and `__eq__()`, reducing boilerplate code. This feature aligns perfectly with our goal of making type-safe code easier to write.

By using data classes, we can define a class with specific types for its fields while writing less code than we would with a traditional class definition. Here's an example:

```python
# !mark(17[23:25])
from dataclasses import dataclass


@dataclass
class Duck:
    name: str
    age: int

    def quack(self):
        print(f"{self.name} says: Quack!")


donald = Duck("Donald", 5)
print(donald)  # Duck(name='Donald', age=5)
donald.quack()  # Donald says: Quack!

daffy = Duck("Daffy", "3")
# Pylance will show the hint: Argument of type "Literal['3']" cannot be assigned to parameter "age" of type "int" in function "__init__".
```

We define a `Duck` data class with two fields: `name` and `age`. When we create a new `Duck` object and pass in values, the data class automatically generates an `__init__()` method that initializes the object with these values.

In the data class definition, the type hints specify that the `name` field should be a string and that `age` should be an integer. If we create a `Duck` object with the wrong data types, the IDE hints that there's a type mismatch in the `__init__` method.

We get a level of type safety that wasn't there before, but at runtime, the data class still accepts any value for the fields, even if they don't match the type hints. Data classes make it convenient to define classes that store data, but they don't enforce type safety.

What if we're building an SDK and want to help users pass the right types of objects to functions? Using `TypedDict` types can help with that.

## TypedDict Types

Introduced in Python 3.8 ([PEP 589](https://www.python.org/dev/peps/pep-0589/)), `TypedDict` lets you define specific key and value types for dictionaries, making it particularly useful when working with JSON-like data structures:

```python
# !mark(29[20:22])
from typing import TypedDict


class DuckStats(TypedDict):
    name: str
    age: int
    feather_count: int


def describe_duck(stats: DuckStats) -> str:
    return f"{stats['name']} is {stats['age']} years old and has {stats['feather_count']} feathers."


print(
    describe_duck(
        {
            "name": "Donald",
            "age": 5,
            "feather_count": 3000,
        }
    )
)
# Output: Donald is 5 years old and has 3000 feathers.

print(
    describe_duck(
        {
            "name": "Daffy",
            "age": "3",  # Pylance will show the hint: Argument of type "Literal['3']" cannot be assigned to parameter "age" of type "int" in function "describe_duck"
            "feather_count": 5000,
        }
    )
)
```

In this example, we define a `DuckStats` `TypedDict` with three keys: `name`, `age`, and `feather_count`. The type hints in the `TypedDict` definition specify that the `name` key should have a string value, while the `age` and `feather_count` keys should have integer values.

When we pass a dictionary to the `describe_duck` function, the IDE will show us a hint if there is a type mismatch in the dictionary values. This can help us catch bugs early and ensure that the data we are working with has the correct types.

While we now have type hints for dictionaries, data passed to our functions from the outside world are still unvalidated. Users can pass in the wrong types of values and we won't find out until runtime. This brings us to Pydantic.

## Pydantic

Pydantic is a data validation library for Python that enforces type hints at runtime. It helps developers with the following:

1. Data Validation: Pydantic ensures that data conforms to the defined types and constraints.
2. Data Parsing: Pydantic can convert input data into the appropriate Python types.
3. Serialization: Pydantic makes it easy to convert Python objects into JSON-compatible formats.
4. Deserialization: It can transform JSON-like data into Python objects.

These Pydantic functionalities are particularly useful when working with APIs that send and receive JSON data, or when processing user inputs.

Here's how you can use Pydantic to define a data model for a duck:

```python
from pydantic import BaseModel, Field, ValidationError

class Duck(BaseModel):
    name: str
    age: int = Field(gt=0)
    feather_count: int | None = Field(default=None, ge=0)

# Correct initialization
try:
    duck = Duck(name="Donald", age=5, feather_count=3000)
    print(duck)  # Duck(name='Donald', age=5, feather_count=3000)
except ValidationError as e:
    print(f"Validation Error:\n{e}")

# Faulty initialization
try:
    invalid_duck = Duck(name="Daffy", age=0, feather_count=-1)
    print(invalid_duck)
except ValidationError as e:
    print(f"Validation Error:\n{e}")
```

In this example, we define a `Duck` data model with three fields: `name`, `age`, and `feather_count`. The `name` field is required and should have a string value, while the `age` and `feather_count` fields are optional and should have integer values.

We use the `Field` class from Pydantic to define additional constraints for the fields. For example, we specify that the `age` field should be greater than or equal to zero, and the `feather_count` field should be greater than or equal to zero, or `None`.

In Python 3.10 and later, we can use the `|` operator for union types ([PEP 604](https://www.python.org/dev/peps/pep-0604/)), allowing us to write `int | None` instead of `Union[int, None]`.

When we try to create an invalid `Duck` instance, Pydantic raises a `ValidationError`. The error message is detailed and helpful:

```bash
Validation Error:
2 validation errors for Duck
age
  Input should be greater than 0 [type=greater_than, input_value=0, input_type=int]
    # link[35:80] https://errors.pydantic.dev/2.8/v/greater_than
    For further information visit https://errors.pydantic.dev/2.8/v/greater_than
feather_count
  Input should be greater than or equal to 0 [type=greater_than_equal, input_value=-1, input_type=int]
    # link[35:86] https://errors.pydantic.dev/2.8/v/greater_than_equal
    For further information visit https://errors.pydantic.dev/2.8/v/greater_than_equal
```

This error message clearly indicates which fields failed validation and why. It specifies that:

1. The 'age' should be greater than 0, but we provided `0`.
2. The 'feather_count' should be greater than or equal to 0, but we provided `-1`.

Detailed error messages make it much easier to identify and fix data validation issues, especially when working with complex data structures or processing user inputs.

## Simplifying Function Validation with Pydantic

While we've seen how Pydantic can validate data in models, it can also be used to validate function arguments directly. This can simplify our code while making it safer to run. Let's revisit our `describe_duck` function using Pydantic's `validate_call` decorator:

```python
from pydantic import BaseModel, Field, validate_call

class DuckDescription(BaseModel):
    name: str
    age: int = Field(gt=0)
    feather_count: int = Field(gt=0)

@validate_call
def describe_duck(duck: DuckDescription) -> str:
    return f"{duck.name} is {duck.age} years old and has {duck.feather_count} feathers."

# Valid input
print(describe_duck(DuckDescription(name="Donald", age=5, feather_count=3000)))
# Output: Donald is 5 years old and has 3000 feathers.

# Invalid input
try:
    print(describe_duck(DuckDescription(name="Daffy", age=0, feather_count=-1)))
except ValueError as e:
    print(f"Validation Error: {e}")
# Validation Error: 2 validation errors for DuckDescription
# age
#   Input should be greater than 0 [type=greater_than, input_value=0, input_type=int]
#     For further information visit https://errors.pydantic.dev/2.8/v/greater_than
# feather_count
#   Input should be greater than 0 [type=greater_than, input_value=-1, input_type=int]
#     For further information visit https://errors.pydantic.dev/2.8/v/greater_than
```

In this example, we made the following changes:

1. We defined a `DuckDescription` Pydantic model to represent the expected structure and types of our duck data.
2. We used the `@validate_call` decorator on our `describe_duck` function. This decorator automatically validates the function's arguments based on the type annotations.
3. The function now expects a `DuckDescription` object instead of separate parameters. This ensures that all the data is validated as a unit before the function is called.
4. We simplified the function body since we can now be confident that the data is valid and of the correct type.

By using Pydantic's `@validate_call` decorator, we made our function safer and easier to read.

## Comparing Python Typing Methods

The table below summarizes the key differences between the Python typing methods we discussed. Keep in mind that some points may have exceptions or nuances depending on your specific use case. The table is meant to provide a general overview only.

| Feature                   | Type Annotations | Data Classes | `TypedDict` | Pydantic |
| ------------------------- | :--------------: | :----------: | :---------: | :------: |
| Static type checking      |        ✅        |      ✅      |     ✅      |    ✅    |
| Runtime type checking     |        ❌        |      ❌      |     ❌      |    ✅    |
| Automatic data validation |        ❌        |      ❌      |     ❌      |    ✅    |
| JSON serialization        |        ❌        |      ❌      |     ❌      |    ✅    |
| Nested object support     |        ✅        |      ✅      |     ✅      |    ✅    |
| Custom validation rules   |        ❌        |      ❌      |     ❌      |    ✅    |
| IDE autocomplete support  |        ✅        |      ✅      |     ✅      |    ✅    |
| Performance overhead      |       None       |   Minimal    |    None     | Minimal  |
| Compatibility with dicts  |        ❌        |      ❌      |     ✅      |    ✅    |
| Standard Library          |        ✅        |      ✅      |     ✅      |    ❌    |

## Why Speakeasy Chose Pydantic

At Speakeasy, we chose Pydantic as the primary tool for data validation and serialization in the Python SDKs we create.

After our initial Python release, support for Pydantic was one of the most requested features from our users. Pydantic provides a great balance between flexibility and type safety. And because Pydantic uses Rust under the hood, it has a negligible performance overhead compared to other third-party data validation libraries.

SDKs are an ideal use case for Pydantic, providing automatic data validation and serialization for the data structures that API users interact with.

By working with the Pydantic team, we've contributed to the development of features that make Pydantic even better suited for SDK development.

## The Value of Runtime Type Safety

To illustrate the value of runtime type safety, consider a scenario where we are building an API that receives JSON data from a client to represent an order from a shop. Let's use a `TypedDict` to define the shape of the order data:

```python
from typing import TypedDict


class Order(TypedDict):
    customer_name: str
    quantity: int
    unit_price: float


def calculate_order_total(order: Order) -> float:
    return order["quantity"] * order["unit_price"]


print(
    calculate_order_total(
        {
            "customer_name": "Alex",
            "quantity": 10,
            "unit_price": 5,
        }
    )
)  # Output: 50
```

In this example, we define an `Order` `TypedDict` with three keys: `customer_name`, `quantity`, and `unit_price`. We then create an `order_data` dictionary with values for these keys and pass it to the `calculate_order_total` function.

The `calculate_order_total` function multiplies the `quantity` and `unit_price` values from the `order` dictionary to calculate the total order amount. It works fine when the `order_data` dictionary has the correct types of values, but what if the client sends us invalid data?

```python
print(
    calculate_order_total(
        {
            "customer_name": "Sam",
            "quantity": 10,
            "unit_price": "5",
        }
    )
)  # Output: 5555555555
```

In this case, the client sends us a string value for the `unit_price` key instead of a float. Since Python is a duck-typed language, the code will still run without errors, but the result will be incorrect. This is a common source of bugs in Python code, especially when working with JSON data from external sources.

Now, let's see how we can use Pydantic to define a data model for the order data and enforce type safety at runtime:

```python
from pydantic import BaseModel, computed_field


class Order(BaseModel):
    customer_name: str
    quantity: int
    unit_price: float

    @computed_field
    def calculate_total(self) -> float:
        return self.quantity * self.unit_price


order = Order(
    customer_name="Sam",
    quantity=10,
    unit_price="5",
)
print(order.calculate_total)  # Output: 50.0
```

In this case, Pydantic converts the string `"5"` to a float value of `5.0` for the `unit_price` field. The automatic type coercion prevents errors and ensures the data is in the correct format.

Pydantic enforces type safety at runtime, but don't we lose the simplicity of passing dictionaries around?

But we don't have to give up on dictionaries.

## Using Typed Dictionaries With Pydantic Models

In some cases, you may want to accept both `TypedDict` and Pydantic models as input to your functions. You can achieve this by using a union type in your function signature:

```python
from typing import TypedDict

from pydantic import BaseModel


class OrderTypedDict(TypedDict):
    customer_name: str
    quantity: int
    unit_price: float


class Order(BaseModel):
    customer_name: str
    quantity: int
    unit_price: float


def calculate_order_total(order: Order | OrderTypedDict) -> float:
    if not isinstance(order, BaseModel):
        order = Order(**order)
    return order.quantity * order.unit_price


print(
    calculate_order_total(
        {
            "customer_name": "Sam",
            "quantity": 10,
            "unit_price": "5",
        }
    )
)  # Output: 50.0
```

In this example, we define an `OrderTypedDict` `TypedDict` and an `Order` Pydantic model for the order data. We then define a `calculate_order_total` function to accept a union type of `Order` and `OrderTypedDict`.

If the input is a `TypedDict`, it'll be converted to a Pydantic model before performing the calculation. Now our function can accept both `TypedDict` and Pydantic models as input, providing us flexibility while still enforcing type safety at runtime.

Speakeasy SDKs employ this pattern so users can pass in either dictionaries or Pydantic models to the SDK functions, reducing the friction of using the SDK while maintaining type safety.

## Conclusion

To learn more about how we use Pydantic in our SDKs, see our post about [Python Generation with Async & Pydantic Support](/post/release-python-v2-alpha).


 This is the content for the doc blog/python-http-clients-requests-vs-httpx-vs-aiohttp.mdx 

 ---
title: "Python HTTP Clients: Requests vs. HTTPX vs. AIOHTTP"
description: "Learn about the differences between Requests, HTTPX, and AIOHTTP, and when to use each library for your Python projects."
image: "/media/python-http-clients.png"
date: 2024-08-24
authors:
  - name: Georges Haidar
  - image_url: '/media/author-headshots/georges.jpeg'
tags:
  - API Advice
featured_image: "/media/python-http-clients.png"
---

Anyone who's been using Python for more than a minute has come across the `Requests` library. It is so ubiquitous, some may have thought it was part of the standard library. Requests is so intuitive that writing `r = requests.get` has become muscle memory. In contrast, any script using Python's built-in [`urllib`](https://docs.python.org/3/library/urllib.html) starts with a trip to the Python docs.

But Python has evolved, and simply defaulting to Requests is no longer an option. While `Requests` remains a solid choice for short synchronous scripts, newer libraries like `HTTPX` and `AIOHTTP` are better suited for modern Python, especially when it comes to asynchronous programming.

Let's compare these three popular HTTP clients for Python: [`Requests`](https://github.com/psf/requests), [`HTTPX`](https://github.com/projectdiscovery/httpx), and [`AIOHTTP`](https://docs.aiohttp.org/en/stable/). We'll explore their strengths, weaknesses, and ideal use cases to help you choose the right tool for your next project.

## In The Beginning, Guido Created Urllib

Before we dive into our comparison of modern HTTP libraries, it's worth taking a brief look at where it all began: Python's built-in `urllib` module.

`urllib` has been part of Python's standard library since the early days. It was designed to be a comprehensive toolkit for URL handling and network operations. However, its API is notoriously complex and unintuitive, often requiring multiple steps to perform even simple HTTP requests.

Here's a basic example of making a GET request with `urllib`:

```python urllib_basic.py
from urllib.request import urlopen

with urlopen('https://api.github.com') as response:
    body = response.read()
    print(body)
```

While this might seem straightforward for a simple GET request, things quickly become more complicated when dealing with headers, POST requests, or authentication. For instance, here's how you might make a request with authentication:

```python urllib_example.py
import urllib.request
import json

url = 'http://httpbin.org/basic-auth/user/passwd'
username = 'user'
password = 'passwd'

# Create an opener with authentication handler
password_mgr = urllib.request.HTTPPasswordMgrWithDefaultRealm()
password_mgr.add_password(None, url, username, password)
auth_handler = urllib.request.HTTPBasicAuthHandler(password_mgr)
opener = urllib.request.build_opener(auth_handler)

# Make the request
with opener.open(url) as response:
    raw_data = response.read()
    encoding = response.info().get_content_charset('utf-8')
    data = json.loads(raw_data.decode(encoding))

print(data)
```

In this example, we create an authentication handler and an opener to make the request. We then read the response, decode it, and parse the JSON data.

The verbosity and complexity of `urllib` led to the creation of third-party libraries that aimed to simplify HTTP requests in Python.

## Requests: HTTP For Humans™️

In 2011 (on Valentine's day, no less), Kenneth Reitz released the [Requests](https://github.com/psf/requests) library, designed to make HTTP requests as human-friendly as possible. After only two years, [by July 2013, Requests had been downloaded more than 3,300,000 times](https://web.archive.org/web/20130905090055/http://kennethreitz.org/growing-open-source-seeds), and as of [August 2024](https://web.archive.org/web/20240818081841/https://pypistats.org/top), it gets downloaded around 12 million times a day. 

It turns out [devex is important after all](/docs/introduction/api-devex)!

To install Requests, use pip:

```bash
pip install requests
```

Let's compare the previous `urllib` examples with their Requests equivalents:

```python requests_example.py
import requests

# GET request
response = requests.get('https://api.github.com')
print(response.text)

# request with auth
url = 'http://httpbin.org/basic-auth/user/passwd'
username = 'user'
password = 'passwd'

response = requests.get(url, auth=(username, password))
data = response.json()

print(data)
```

The simplicity and readability of `Requests` code compared to `urllib` is immediately apparent. `Requests` abstracts away much of the complexity, handling things like authentication headers and JSON responses with ease.

Some key features that made `Requests` the de facto standard include:

1. **Automatic content decoding**: `Requests` automatically decodes the response content based on the Content-Type header.
2. **Session persistence**: The `Session` object allows you to persist certain parameters across requests.
3. **Elegant error handling**: `Requests` raises intuitive exceptions for network problems and HTTP errors.
4. **Automatic decompression**: `Requests` automatically decompresses gzip-encoded responses.

However, as Python evolved and the use cases for Python expanded, new needs arose that `Requests` wasn't designed to address. In particular, Asynchronous rose as a need which led to the introduction of `asyncio` in Python 3.4. 

## `AIOHTTP`: Built for Asyncio

[`AIOHTTP`](https://github.com/aio-libs/aiohttp), first released in October 2014, was one of the first libraries to fully embrace Python's asyncio framework. Designed from the ground up for asynchronous operations, it's an excellent choice for high-performance, concurrent applications. Today, `AIOHTTP` is widely used, with around [six million downloads per day](https://pypistats.org/packages/aiohttp) as of August 2024.

`AIOHTTP` has several key features that set it apart from Requests:

1. **Purely asynchronous**: All operations in `AIOHTTP` are async, allowing for efficient handling of many concurrent connections.
2. **Both client and server**: `AIOHTTP` can be used to create both HTTP clients and servers.
3. **WebSocket support**: It offers full support for WebSocket connections.

Install `AIOHTTP` using pip:

```bash
pip install aiohttp
```

Here's a basic example of using `AIOHTTP`:

```python aiohttp_basic.py
import aiohttp
import asyncio

async def fetch(session, url):
    async with session.get(url) as response:
        return await response.text()

async def main():
    async with aiohttp.ClientSession() as session:
        html = await fetch(session, 'https://api.github.com')
        print(html)

asyncio.run(main())
```

To really test `AIOHTTP`'s capabilities, you need to run multiple requests concurrently. Here's an example that fetches multiple URLs concurrently:

```python aiohttp_multiple.py
import asyncio
import aiohttp
import time

urls = [
    "https://httpbin.org/delay/1",
    "https://httpbin.org/delay/2",
    "https://httpbin.org/delay/3",
    "https://httpbin.org/delay/1",
    "https://httpbin.org/delay/2",
]

async def fetch(session, url, i):
    try:
        start_time = time.perf_counter()
        async with session.get(url) as response:
            await response.text()
            elapsed = time.perf_counter() - start_time
            print(f"Request {i} completed in {elapsed:.2f}s")
    except asyncio.TimeoutError:
        print(f"Request {i} timed out")

async def async_requests():
    start_time = time.perf_counter()
    async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=10)) as session:
        tasks = [fetch(session, url, i) for i, url in enumerate(urls, 1)]
        await asyncio.gather(*tasks)
    
    total_time = time.perf_counter() - start_time
    print(f"\nTotal time: {total_time:.2f}s")

if __name__ == "__main__":
    asyncio.run(async_requests())
```

In this example, we're fetching five URLs concurrently, each with a different server-side delay. The script will output the time taken for each request to complete, as well as the total time taken:

```bash output
Request 1 completed in 2.22s
Request 4 completed in 2.22s
Request 5 completed in 3.20s
Request 2 completed in 3.20s
Request 3 completed in 4.30s

Total time: 4.31s
```

For comparison, here's how you might achieve the same thing using Requests:

```python requests_multiple.py
import requests
import time

urls = [
    "https://httpbin.org/delay/1",
    "https://httpbin.org/delay/2",
    "https://httpbin.org/delay/3",
    "https://httpbin.org/delay/1",
    "https://httpbin.org/delay/2",
]

def sync_requests():
    start_time = time.time()
    with requests.Session() as session:
        session.timeout = 10.0
        for i, url in enumerate(urls, 1):
            try:
                response = session.get(url)
                print(f"Request {i} completed in {response.elapsed.total_seconds():.2f}s")
            except requests.Timeout:
                print(f"Request {i} timed out")
    
    total_time = time.time() - start_time
    print(f"\nTotal time: {total_time:.2f}s")

if __name__ == "__main__":
    sync_requests()
```

The output will be similar to the `AIOHTTP` example, but the total time taken will be significantly longer due to the synchronous nature of Requests.

```bash output
Request 1 completed in 3.04s
Request 2 completed in 2.57s
Request 3 completed in 3.26s
Request 4 completed in 1.23s
Request 5 completed in 2.49s

Total time: 12.61s
```

As you can see, `AIOHTTP`'s asynchronous nature allows it to complete all requests in roughly the time it takes to complete the slowest request, while Requests waits for each request to complete sequentially.

While `AIOHTTP` is a powerful library for asynchronous operations, it doesn't provide a synchronous API like Requests. This is where HTTPX comes in.

## `HTTPX`: The Best of Both Worlds

[HTTPX](https://github.com/encode/httpx), released by Tom Christie (the author of Django REST framework) in August 2019, aims to combine the best features of Requests and `AIOHTTP`. It provides a synchronous API similar to Requests but also supports asynchronous operations.

Key features of `HTTPX` include:

1. **Familiar Requests-like API**: `HTTPX` maintains a similar API to Requests, making it easy for developers to transition.
2. **Both sync and async support**: Unlike Requests or `AIOHTTP`, `HTTPX` supports both synchronous and asynchronous operations.
3. **HTTP/2 support**: `HTTPX` natively supports HTTP/2, allowing for more efficient communication with modern web servers.
4. **Type annotations**: `HTTPX` is fully type-annotated, which improves IDE support and helps catch errors early.

To install `HTTPX`, use pip:

```bash
pip install httpx
```

Here's a basic example of using `HTTPX` synchronously:

```python httpx_sync.py
import httpx

response = httpx.get('https://api.github.com')
print(response.status_code)
print(response.json())
```

The code is almost identical to the Requests example, making it easy to switch between the two libraries. However, HTTPX also supports asynchronous operations:

```python httpx_async.py
import asyncio
import httpx
import time

urls = [
    "https://httpbin.org/delay/1",
    "https://httpbin.org/delay/2",
    "https://httpbin.org/delay/3",
    "https://httpbin.org/delay/1",
    "https://httpbin.org/delay/2",
]

async def fetch(client, url, i):
    response = await client.get(url)
    print(f"Request {i} completed in {response.elapsed.total_seconds():.2f}s")

async def async_requests():
    start_time = time.time()
    async with httpx.AsyncClient(timeout=10.0) as client:
        tasks = [fetch(client, url, i) for i, url in enumerate(urls, 1)]
        await asyncio.gather(*tasks)
    
    total_time = time.time() - start_time
    print(f"\nTotal time: {total_time:.2f}s")

if __name__ == "__main__":
    asyncio.run(async_requests())
```

The output will be similar to the AIOHTTP example:

```bash output
Request 1 completed in 1.96s
Request 4 completed in 1.96s
Request 5 completed in 3.00s
Request 2 completed in 3.30s
Request 3 completed in 4.42s

Total time: 4.44s
```

HTTPX's ability to switch seamlessly between synchronous and asynchronous operations makes it a versatile choice for a wide range of applications. It's especially useful when you need to interact with both synchronous and asynchronous code within the same project.

This brings us to the question: which library should you choose for your next Python project? That depends on your specific requirements.

## Choosing the Right HTTP Client for Your Project

Here's a quick comparison of the key features of Requests, AIOHTTP, and HTTPX:

| Feature / Characteristic | Requests  | AIOHTTP   | HTTPX     |
| ------------------------ | --------- | --------- | --------- |
| Synchronous operations   | ✅        | ❌        | ✅        |
| Asynchronous operations  | ❌        | ✅        | ✅        |
| Built-in HTTP/2 support  | ❌        | ❌        | ✅        |
| WebSocket support        | ❌        | ✅        | Via addon |
| Type hints               | Partial   | ✅        | ✅        |
| Retries with backoff     | Via addon | ✅        | ✅        |
| SOCKS proxies            | Via addon | Via addon | ✅        |
| Event hooks              | ✅        | ❌        | ✅        |
| Brotli support           | Via addon | ✅        | ✅        |
| Asynchronous DNS lookup  | ❌        | ✅        | ✅        |

## Recommendations

1. If you're working on a simple script or a project that doesn't require asynchronous operations, stick with **`Requests`**. Its simplicity and wide adoption make it an excellent choice for straightforward HTTP tasks.

2. For high-performance asyncio applications, especially those dealing with many concurrent connections or requiring WebSocket support, **`AIOHTTP`** is your best bet. It's particularly well-suited for building scalable web services.

3. If you need the flexibility to use both synchronous and asynchronous code, or if you're looking to future-proof your application with `HTTP/2` support, go with **`HTTPX`**. It's also a great choice if you're familiar with `Requests` but want to start incorporating async operations into your project.

## How Speakeasy Uses `HTTPX`

When creating Python SDKs, Speakeasy includes HTTPX as the default HTTP client. This choice allows developers to use our SDKs for synchronous and asynchronous operations.

For example, here's how you might use the [Mistral Python SDK](https://github.com/mistralai/client-python) created by Speakeasy to make requests.

First, install the SDK:

```bash
pip install mistralai
```

Set your [Mistral API key](https://console.mistral.ai/api-keys/) as an environment variable:

```bash
export MISTRAL_API_KEY="your-api-key"
```

Here's how you might use the SDK to make a synchronous request:

```python mistral_sync.py
from mistralai import Mistral
import os

s = Mistral(
    api_key=os.getenv("MISTRAL_API_KEY", ""),
)

res = s.chat.complete(model="mistral-small-latest", messages=[
    {
        "content": "Who is the best French painter? Answer in one short sentence.",
        "role": "user",
    },
])

if res is not None and res.choices:
    print(res.choices[0].message.content)
```

And here's the same SDK and request using the asynchronous API:

```python mistral_async.py
import asyncio
from mistralai import Mistral
import os

async def main():
    s = Mistral(
        api_key=os.getenv("MISTRAL_API_KEY", ""),
    )
    res = await s.chat.complete_async(model="mistral-small-latest", messages=[
        {
            "content": "Who is the best French painter? Answer in one short sentence.",
            "role": "user",
        },
    ])
    if res is not None:
        print(res.choices[0].message.content)

asyncio.run(main())
```

Note how the asynchronous version uses the `_async` suffix for the method name, but otherwise the code is almost identical. This consistency makes it easy to switch between synchronous and asynchronous operations as needed.

You'll also notice that there is no need to instantiate a different client object for the asynchronous version. SDKs created by Speakeasy allow developers to use the same client object for both synchronous and asynchronous operations. By abstracting away the differences between the modes of operation in HTTPX, Speakeasy reduces boilerplate code and makes your SDKs more user-friendly.

To illustrate the value of mixing synchronous and asynchronous operations, consider a scenario where you need to make a synchronous request to fetch some data, then use that data to make multiple asynchronous requests. HTTPX's unified API makes this kind of mixed-mode operation straightforward.

```python mistral_mixed.py
import asyncio
from mistralai import Mistral
import os

# Initialize Mistral client
s = Mistral(
    api_key=os.getenv("MISTRAL_API_KEY", ""),
)

def sync_request():
    res = s.chat.complete(model="mistral-small-latest", messages=[
        {
            "content": "Who is the best French painter? Answer with only the name of the painter.",
            "role": "user",
        },
    ])
    if res is not None and res.choices:
        print("Sync request result:", res.choices[0].message.content)
        return res.choices[0].message.content

async def async_request(question):
    res = await s.chat.complete_async(model="mistral-small-latest", messages=[
        {
            "content": question,
            "role": "user",
        },
    ])
    if res is not None and res.choices:
        return res.choices[0].message.content
    return None

async def main():
    # Make a sync request
    painter = sync_request()
    
    # Make two async requests
    tasks = [
        async_request(f"Name the most iconic painting by {painter}. Answer in one short sentence."),
        async_request(f"Name one of {painter}'s influences. Answer in one short sentence."),
    ]
    results = await asyncio.gather(*tasks)
    
    # Print the results of async requests
    print("Async request 1 result:", results[0])
    print("Async request 2 result:", results[1])

if __name__ == "__main__":
    asyncio.run(main())
```

In this example, we first make a synchronous request to get the name of a painter. We then use that information to make two asynchronous requests to get more details about the painter. The SDK is only instantiated once, and the same client object is used for both synchronous and asynchronous operations.

## Using a Different HTTP Client in Speakeasy SDKs

While HTTPX is the default HTTP client in SDKs created by Speakeasy, you can [easily switch to Requests for synchronous operations](/docs/customize-sdks/custom-http-client) if needed. For example, to use Requests in the Mistral SDK, you can set the `client` parameter when initializing the client:

```python mistral_requests.py
import os
import requests
from mistralai import Mistral, HttpClient

# Define a custom HTTP client using Requests
class RequestsHttpClient(HttpClient):
    def __init__(self):
        self.session = requests.Session()

    def send(self, request, **kwargs):
        return self.session.send(request.prepare())

    def build_request(
        self,
        method,
        url,
        *,
        content = None,
        headers = None,
        **kwargs,
    ):
        return requests.Request(
            method=method,
            url=url,
            data=content,
            headers=headers,
        )

# Initialize the custom client
client = RequestsHttpClient()

# Initialize Mistral with the custom client
s = Mistral(
    api_key=os.getenv("MISTRAL_API_KEY", ""),
    client=client,
)

# Use the Mistral client
res = s.chat.complete(model="mistral-small-latest", messages=[
    {
        "content": "Who is the best French painter? Answer in one short sentence.",
        "role": "user",
    },
])

if res is not None and res.choices:
    print(res.choices[0].message.content)
```

In this example, we define a custom `RequestsHttpClient` class that extends `HttpClient` from the Mistral SDK. This class uses the Requests library to send HTTP requests. We then initialize the Mistral client with this custom client, allowing us to use Requests for synchronous operations.

# Conclusion

To learn more about how we use HTTPX in our SDKs, see our post about [Python Generation with Async & Pydantic Support](/post/release-python-v2-alpha).

You can also read more about our Python SDK design principles in our [Python SDK Design Overview](/docs/sdk-design/python/methodology-python).


 This is the content for the doc blog/release-contract-testing/index.mdx 

 ---
title: "Introducing: API contract test generation"
description: "Generate comprehensive test suites for your API complete with realistic test data"
image: "/media/release-testing.png"
date: 2024-12-02
authors:
  - name: Brian Flad
  - image_url: "/media/author-headshots/brian.jpg"
tags:
  - Product Updates
featured_image: "/media/release-testing.png"
is_featured: true
---

import { CodeWithTabs } from "~/components/codehike/CodeTabs";

Today we're excited to announce the beta launch of API contract test generation, a powerful new addition to our API development platform that uses your OpenAPI spec to automatically create comprehensive test suites for your API. This release continues our mission of automating the tedious parts of API development, enabling your team to stay focused on building great products.

## The Hidden Cost of API Testing

API contract testing is crucial for maintaining reliability and preventing breaking changes, but creating and maintaining test suites is a significant burden on engineering teams. Today, developers face two major challenges:

First, they must manually write test code using HTTP frameworks, carefully crafting requests and validation logic for each endpoint. This involves tedious work like handling authentication, managing data structures, and writing assertions.

Second, they need to create and maintain realistic test data. While simple endpoints might only need basic examples, real-world APIs often have complex data structures with numerous fields and edge cases. Missing even a single field in your test coverage can lead to broken integrations down the line.

The result? Teams either invest significant engineering resources in testing or, more commonly, settle for incomplete test coverage that leaves them vulnerable to breaking changes.

## Generating test suites

Speakeasy Contract Testing approaches this problem from both sides. We don't just generate the test code – we also create the test data needed to validate your API's behavior.

**Native Test Generation**: Tests are generated in your favorite language's native testing framework ([pytest](https://docs.pytest.org/en/stable/) for Python, [vitest](https://vitest.dev/) for TypeScript, etc.), ensuring they integrate seamlessly with your existing development workflow. We know that debugging impenetrable auto-generated tests is a nightmare, so we've put a lot of work into making the tests we generated look and feel like they were written by your team.

<CodeWithTabs>

```ts !!tabs users.test.ts
test("Users Create User", async () => {
  const petstore = new Petstore({
    serverURL: process.env["TEST_SERVER_URL"] ?? "http://localhost:18080",
    httpClient: createTestHTTPClient("createUser"),
    apiKey: process.env["PETSTORE_API_KEY"] ?? "",
  });
  const result = await petstore.users.create({
    id: 10,
    username: "theUser",
    firstName: "John",
    lastName: "James",
    email: "john@email.com",
    password: "12345",
    phone: "12345",
    userStatus: 1,
  });
  expect(result).toBeDefined();
  expect(result).toEqual({
    id: 10,
    username: "theUser",
    firstName: "John",
    lastName: "James",
    email: "john@email.com",
    password: "12345",
    phone: "12345",
    userStatus: 1,
  });
});
```

```python !!tabs test_user_sdk.py
def test_user_sdk_create_user():
    with Petstore(
        server_url=os.getenv("TEST_SERVER_URL", "http://localhost:18080"),
        client=create_test_http_client("createUser"),
        api_key="<YOUR_API_KEY_HERE>",
    ) as s:
        assert s is not None

        res = s.user.create_user(
            request={
                "id": 10,
                "username": "theUser",
                "first_name": "John",
                "last_name": "James",
                "email": "john@email.com",
                "password": "12345",
                "phone": "12345",
                "user_status": 1,
            }
        )
        assert res is not None
        assert res == petstore.User(
            id=10,
            username="theUser",
            first_name="John",
            last_name="James",
            email="john@email.com",
            password="12345",
            phone="12345",
            user_status=1,
        )
```

```go !!tabs user_test.go
func TestUser_CreateUser(t *testing.T) {
	s := petstoresdk.New(
		petstoresdk.WithServerURL(utils.GetEnv("TEST_SERVER_URL", "http://localhost:18080")),
		petstoresdk.WithClient(createTestHTTPClient("createUser")),
		petstoresdk.WithSecurity("<YOUR_API_KEY_HERE>"),
	)

	ctx := context.Background()
	res, err := s.User.CreateUser(ctx, &components.User{
		ID:         petstoresdk.Int64(10),
		Username:   petstoresdk.String("theUser"),
		FirstName:  petstoresdk.String("John"),
		LastName:   petstoresdk.String("James"),
		Email:      petstoresdk.String("john@email.com"),
		Password:   petstoresdk.String("12345"),
		Phone:      petstoresdk.String("12345"),
		UserStatus: petstoresdk.Int(1),
	})
	require.NoError(t, err)
	assert.Equal(t, 200, res.HTTPMeta.Response.StatusCode)
	assert.NotNil(t, res.User)
	assert.Equal(t, &components.User{
		ID:         petstoresdk.Int64(10),
		Username:   petstoresdk.String("theUser"),
		FirstName:  petstoresdk.String("John"),
		LastName:   petstoresdk.String("James"),
		Email:      petstoresdk.String("john@email.com"),
		Password:   petstoresdk.String("12345"),
		Phone:      petstoresdk.String("12345"),
		UserStatus: petstoresdk.Int(1),
	}, res.User)
}
```

---

</CodeWithTabs>

## Solving the testing workflow

Generating testing code is only part of the solution. Testing is a workflow, and we know every team's testing needs are different, so we've built flexibility and out of the box completeness into the core of our testing platform:

**Comprehensive Data Coverage**: Beyond just testing happy paths, our platform generates test data that covers edge cases and optional fields. If you have examples in your OpenAPI spec, we'll use those. If not, we'll generate realistic mock data that validates your API's full schema.

**Flexible testing environment**: Have your own sandbox environment? We've got you covered. You can run your tests against any server URL you'd like. Don't have a sandbox? We've got you covered there too. Our platform will create a mock server for you to run your tests against.

**Flexible Configuration**: We are ready to support your preferred workflow. For teams managing their OpenAPI spec, simply add the `x-speakeasy-test` annotation to your OpenAPI spec to enable testing for specific endpoints or your entire API. Alternatively, you can use our external configuration support to define tests without modifying the underlying OpenAPI document.

**CI/CD Integration**: Tests can be run locally during development or automated in your CI/CD pipeline. We provide GitHub Actions workflows out of the box, making it easy to validate API changes on every pull request.

## Testing end-to-end

In addition to contract testing, we're also rolling out the beginnings of end-to-end testing support. This will allow you to validate your API's behavior across multiple endpoints, ensuring that your API behaves as expected in complex workflows. For example, you might want to test a workflow where a user logs in, creates an order, and then verifies the order appears in their order history. This kind of multi-step testing is crucial because it validates not just individual endpoints, but the connections between them.

To enable end-to-end testing, we're leveraging the [Arazzo specification](/openapi/arazzo), which allows you to arrange API calls into multi-step workflows. The Arazzo specification is fully compatible with the OpenAPI specification, so you can use your existing OpenAPI documents to generate end-to-end tests with a fully open source framework.

We'll be rolling out more support for bootstrapping Arazzo workflows in the coming months, so stay tuned for more updates!

## Getting Started

Contract Testing is available for early access. You can generate tests in TypeScript, Python, and Go today, with more languages (Java, C#, etc.) coming soon. Existing customers can reach out to their account manager to get access. If you're new to Speakeasy, you can request access to the testing module by filling out this [form](/book-demo).

We're excited to see how this helps teams build more reliable APIs with less effort. This is just the beginning – we have lots more planned for testing, including deeper workflow validation, end-to-end testing support, and enhanced mock data generation.

Ready to automate your API testing? [Sign up now](https://app.speakeasy.com/) or check out our [documentation](https://speakeasy.com/docs) to learn more.


 This is the content for the doc blog/release-custom-code-regions/index.mdx 

 ---
title: "Custom code regions: SDK customization without limits"
description: "Take SDK customization to the next level with Custom Code Regions, the most flexible way to tailor your SDKs without modifying the OpenAPI spec."
keywords:
  [api, openapi, sdk generation, customization, custom code regions]
image: "/media/release-custom-code-regions.png"
date: 2025-01-15
authors:
  - name: Emre Tezisci
  - image_url: "/media/author-headshots/emre.jpeg"
featured_image: "/media/release-custom-code-regions.png"
tags:
  - Product Updates
---

import { Callout } from "~/components";

We’re excited to announce **Custom Code Regions**, a powerful new feature that puts you in complete control of your SDKs. Whether you need to add custom methods, integrate third-party libraries, or build bespoke functionality, Custom Code Regions let you do it all—directly in the generated SDK. And the best part? Your customizations persist across updates, with no need to edit your OpenAPI spec or deal with workarounds.  

---

### What are Custom Code Regions?  

Custom Code Regions give developers the ability to embed their own code into specific parts of the generated SDK. Using foldable region syntax, you can define areas in the codebase for your custom logic. These regions are preserved during regenerations, meaning you can enhance the SDK while maintaining its stability.  

Whether you're adding helper methods, extending SDK functionality, or introducing custom integrations, Custom Code Regions make it easy to personalize your SDK without impacting the underlying OpenAPI spec.  

#### **How It Works**

Custom Code Regions leverage foldable region syntax, inspired by Visual Studio Code, to define and preserve custom code sections. Here’s an example:

  ```typescript
  import { ClientSDK } from "./lib/sdks.js";
  // #region imports
  import chalk from 'chalk';
  // #endregion imports

  class Acme extends ClientSDK {
    // ... generated code ...

    // #region sdk-class-body
    greet(name: string): string {
      return chalk.green(`Hello, ${name}!`);
    }
    // #endregion sdk-class-body
  }
  ```
  
During SDK generation, the generator identifies these regions and ensures your custom code is seamlessly integrated into the updated SDK. This process ensures consistent formatting while preserving customizations.

### Why Custom Code Regions?  

For developers, flexibility is key. Before Custom Code Regions, SDK customization options were limited to overlays and hooks, which are powerful tools but sometimes require modifying the OpenAPI spec or working programmatically within the generation process. Custom Code Regions provide a simpler, more direct approach:  

1. **Direct Control**: Write custom logic right in the SDK, bypassing spec modifications or hook configurations.  
2. **Persistent Changes**: Customizations are preserved during SDK regenerations, so you don’t have to worry about losing your code when the spec changes.  
3. **Unlimited Flexibility**: From helper methods to advanced integrations, you can do anything with Custom Code Regions.  

---

### How Custom Code Regions Fit with Overlays and Hooks  

Custom Code Regions complement overlays and hooks, giving developers three levels of control over their SDKs:  

| **Customization Tool**    | **Purpose**                                                                 | **Key Use Case**                                         |
|----------------------------|-----------------------------------------------------------------------------|---------------------------------------------------------|
| **Overlays**               | Modify the OpenAPI spec for structural or schema-related changes.           | Adding paths, tweaking parameters, or updating models.  |
| **Hooks**                  | Intercept and modify SDK generation programmatically during the build.      | Dynamic updates, injecting logic at specific stages.    |
| **Custom Code Regions**    | Insert custom logic directly into the generated SDK code at runtime.        | Adding helper methods, third-party integrations, or SDK-specific tweaks. |

By combining these tools, you can build SDKs that are perfectly tailored to your needs.  

---

### Ready to Try Custom Code Regions?  

Custom Code Regions are now available for enterprise customers in TypeScript and Python SDKs generated with the latest Speakeasy CLI. Support for additional languages is on the way, so stay tuned.

> 📚 Dive into the documentation:  
> 🔗 [Custom Code Regions Documentation](/docs/customize/code/code-regions/overview)


 This is the content for the doc blog/release-java-ga/index.md 

 ---
title: "Generally Available: Java"
description: "Our Java generation is now generally available. That means all SDK features are available with an enhanced developer experience."
image: "/media/release-java-ga.png"
date: 2024-03-19
authors:
  - name: Nolan Sullivan
  - image_url: '/media/author-headshots/nolan.jpeg'
tags:
  - Product Updates
featured_image: "/media/release-java-ga.png"
is_featured: true
---

Today, our Java generation is generally available! Every SDK feature we offer is now available to users generating Java libraries. In addition to the slew of new features, we've invested significantly in  enhancing the usability, readability, and overall developer experience of the library code.

Before going any further, here are the headline features that come with the new Java SDKs generated using Speakeasy:

- Enhanced `null` safety and `Optional` support
- Builder patterns for better readability, discoverability, and convenient overloads
- Lists instead of arrays for collections
- No direct field access (getter methods are used now)
- A simplified Gradle project structure
- Support for non-discriminated `oneOf`s
- Auto-Pagination
- Retry support
- Oauth2 support

To get started, all you need is an OpenAPI spec. Simply install the speakeasy CLI, and start generating:

```bash
brew install speakeasy-api/homebrew-tap/speakeasy
```

```bash
speakeasy quickstart
```

## Enhanced Null Safety and Optional Support

We've improved compile-time type safety by adding native support for null fields (using `JSONNullable`) and optional fields (using `java.util.Optional`). More explicit handling of fields allows your users to write robust and error-resistant code.

## Builder Patterns for Better Readability

A major focus of the general availability work was enhancing the readability of the code. That includes everything from whitespacing to formatting, to the directory structure. But one of the most noticeable changes is the introduction of builder patterns which allow for more fluent and intuitive object creation and request preparation. That makes your users' code easier to write, read, and maintain.

```java
Person person = new Person.Builder()
    .name("John Doe")
    .age(30)
    .build();
```

## Lists over Arrays for Collections

Recognizing the limitations of arrays in dynamic contexts, our Java generation now makes use of `java.util.List`, which offers a more intuitive interface for users working with collections.

## OneOf Support

Our Java generation now handles more complex APIs by offering support for `oneOf`. This allows for the generation of polymorphic types in the SDK.

```java
Pet pet = ...; // might be returned from an SDK call
if (pet.value() instanceof Cat cat) {
   // do something with the cat
} else if (pet.value() instanceof Dog dog) {
   // do something with the dog
} else {
   throw new RuntimeException("unexpected value");
}
```

## Auto-Pagination

To further ease the processing of large responses, the new Java generation incorporates auto-pagination by creating a `callAsStream()` method which returns a `java.util.Stream`.

```java
SDK sdk = SDK.builder() ... ;

sdk.searchDocuments()    // builder for the request
   .contains("simple")   // parameter
   .minSize(200)         // parameter
   .maxSize(400)         // parameter
   .callAsStream()       // returns Stream<DocumentsPageResponse>
   .flatMap(x -> x.res() // returns Optional<DocumentsPage>
                  .stream()
                  .flatMap(y -> y.documents().stream()))
   // we are now dealing with a Stream<Document>
   .filter(document -> "fiction".equals(document.category()))
   .limit(200) // no more than 200 documents
   .map(document -> document.name())
   .forEach(System.out::println);
```

## OAuth2 Support

We now offer native support for an OAuth2 Client Credentials flow where the credentials  are passed in the request body of the `tokenUrl` request. We will generate an SDK with a security instantiation as follows:

```java
SDK s = SDK.builder().security(
  Security.builder()
      .clientId("..CLIENT_ID..")
      .clientSecret("..CLIENT_SECRET..")
      .build())
  .build();
```

## Retry Support

Retries can be easily enabled to handle transient errors using an easily customizable backoff strategy.

```yaml
x-speakeasy-retries:
  strategy: backoff
  backoff:
    initialInterval: 500        # 500 milliseconds
    maxInterval: 60000          # 60 seconds
    maxElapsedTime: 3600000     # 5 minutes
    exponent: 1.5
  statusCodes:
    - 5XX
  retryConnectionErrors: true
```

## Refined Gradle Experience

Improvements to the Gradle build configuration and project structure aim to simplify dependency management and streamline the build process, enhancing the development workflow.

## Building on good foundations

We're really excited to provide users with an awesome experience using generated SDKs. There's often a trade-off that product engineers and API owners consider when relying on code generators versus hand-building SDKs and the quality of the code and public interface they produce. We believe that our refreshed Java generator has baked in a lot of good ideas that ultimately result in a great developer experience, one that feels like working with a carefully curated Java SDK. We now have the foundation to build even more exciting features like support for Server-sent Events and we're looking forward to taking more of the pain away from shipping awesome DX for your products.

If you do try out Speakeasy and our Java SDKs, we'd love to get your feedback about your experience, as well as hear any new ideas or feature requests you have.

Happy hacking!


 This is the content for the doc blog/release-oss-arazzo-parser/index.mdx 

 ---
title: "OSS Release: Arazzo Parser"
description: "We're excited to announce the release of our Arazzo Parser, a new tool that allows you to parse and manipulate the Arazzo specification."
image: "/media/oss-release-arazzo-parser.png"
date: 2025-01-06
authors:
  - name: Tristan Cartledge
  - image_url: '/media/author-headshots/tristan.jpeg'
tags:
  - Building Speakeasy
featured_image: "/media/oss-release-arazzo-parser.png"
is_featured: true
---
import { CodeWithTabs } from "~/components/codehike/CodeTabs";

We've been hard at work on building an automated end-to-end testing framework for REST APIs. That's meant building a lot of internal tooling to work with the [Arazzo specification](https://github.com/OAI/Arazzo-Specification).

Today, we're excited to announce the release of our Arazzo parser, a powerful tool for working with the Arazzo specification. We hope that this will be help the community build more tooling that leverages the Arazzo specification.

[Check it out on GitHub →](https://github.com/speakeasy-api/openapi/tree/main/arazzo)

## What is Arazzo?

The Arazzo specification is a language-agnostic way to describe chains of API calls. While OpenAPI documents define the individual API endpoints and methods available, Arazzo allows you to define sequences of calls that relate to those OpenAPI documents. This means you can create complex workflows like "authenticate → create user → get user → delete user" and ensure the output of one call feeds correctly into the inputs of another.

What makes Arazzo particularly powerful is its ability to reference multiple OpenAPI documents from different providers, enabling you to build and test intricate integrations across various services.

## Why'd we build a parser?

Developers testing API workflows often resort to writing custom testing applications or using end-to-end testing frameworks that don't integrate well with their API tooling. This leads to duplicate schema definitions and a disconnect between testing and the rest of the API development lifecycle.

We see Arazzo bridging this gap by providing a native way to define workflows that leverage your existing OpenAPI specifications. This means you're not just testing individual API endpoints – you're validating entire workflows while ensuring your SDKs and integrations work as expected.

## Basic Example

Here's a simple example of an Arazzo workflow for a hypothetical bar API:

```yaml
workflows:
  createDrink:
    workflowId: create-drink
    summary: Creates a new drink in the system
    inputs:
      drinkName: string
      drinkType: string
      price: number
    steps:
      - operationId: authenticate
        inputs:
          username: ${inputs.username}
          password: ${inputs.password}
      - operationId: createDrink
        inputs:
          name: ${inputs.drinkName}
          type: ${inputs.drinkType}
          price: ${inputs.price}
```

## What's in the parser

The parser includes comprehensive features for:

- **Reading** Arazzo documents
- **Validating** documents
- **Walking** through a document
- **Creating** new documents
- **Mutating** existing documents

Here's how you can get started:

<CodeWithTabs>

```go !!tabs read.go
package main

import (
 "bytes"
 "context"
 "fmt"
 "os"

 "github.com/speakeasy-api/openapi/arazzo"
)

func main() {
    ctx := context.Background()

    r, err := os.Open("testdata/speakeasybar.arazzo.yaml")
    if err != nil {
        panic(err)
    }
    defer r.Close()

    // Unmarshal the Arazzo document which will also validate it against the Arazzo Specification
    a, validationErrs, err := arazzo.Unmarshal(ctx, r)
    if err != nil {
        panic(err)
    }

    // Validation errors are returned separately from any errors that block the document from being unmarshalled
    // allowing an invalid document to be mutated and fixed before being marshalled again
    for _, err := range validationErrs {
        fmt.Println(err.Error())
    }

    // Mutate the document by just modifying the returned Arazzo object
    a.Info.Title = "Speakeasy Bar Workflows"

    buf := bytes.NewBuffer([]byte{})

    // Marshal the document to a writer
    if err := arazzo.Marshal(ctx, a, buf); err != nil {
        panic(err)
    }

    fmt.Println(buf.String())
}
```

```go !!tabs validate.go
package main

import (
 "context"
 "fmt"
 "os"

 "github.com/speakeasy-api/openapi/arazzo"
)

func main() {
    ctx := context.Background()

    f, err := os.Open("arazzo.yaml")
    if err != nil {
        panic(err)
    }

    _, validationErrs, err := arazzo.Unmarshal(ctx, f)
    if err != nil {
        panic(err)
    }

    for _, err := range validationErrs {
        fmt.Printf("%s\n", err.Error())
    }
}
```

```go !!tabs walk.go
package main

import (
 "context"
 "fmt"
 "os"

 "github.com/speakeasy-api/openapi/arazzo"
)

func main() {
    ctx := context.Background()

    f, err := os.Open("arazzo.yaml")
    if err != nil {
        panic(err)
    }

    a, _, err := arazzo.Unmarshal(ctx, f)
    if err != nil {
        panic(err)
    }

    err = arazzo.Walk(ctx, a, func(ctx context.Context, node, parent arazzo.MatchFunc, a *arazzo.Arazzo) error {
        return node(arazzo.Matcher{
            Workflow: func(workflow *arazzo.Workflow) error {
                fmt.Printf("Workflow: %s\n", workflow.WorkflowID)
                return nil
            },
        })
    })
    if err != nil {
        panic(err)
    }
}
```

```go !!tabs create.go
package main

import (
 "context"
 "fmt"

 "github.com/speakeasy-api/openapi/arazzo"
 "github.com/speakeasy-api/openapi/pointer"
)

func main() {
    ctx := context.Background()

    arazzo := &arazzo.Arazzo{
        Arazzo: arazzo.Version,
        Info: arazzo.Info{
            Title:   "My Workflow",
            Summary: pointer.From("A summary"),
            Version: "1.0.0",
        },
        // ...
    }

    buf := bytes.NewBuffer([]byte{})

    err := arazzo.Marshal(ctx, buf)
    if err != nil {
        panic(err)
    }

    fmt.Printf("%s", buf.String())
}
```

```go !!tabs mutate.go
package main

import (
 "context"
 "fmt"

 "github.com/speakeasy-api/openapi/arazzo"
)

func main() {
    ctx := context.Background()

    f, err := os.Open("arazzo.yaml")
    if err != nil {
        panic(err)
    }

    arazzo, _, err := arazzo.Unmarshal(ctx, f)
    if err != nil {
        panic(err)
    }

    arazzo.Info.Title = "My updated workflow title"

    buf := bytes.NewBuffer([]byte{})

    if err := arazzo.Marshal(ctx, buf); err != nil {
        panic(err)
    }

    fmt.Printf("%s", buf.String())
}
```

</CodeWithTabs>
## What's Next?

While the Arazzo specification is broad and deep, we're starting with focused support for testing workflows against single APIs. Our roadmap includes:

- Visual workflow builders to make creating Arazzo documents more intuitive
- Enhanced testing capabilities across multiple APIs
- Integration with our existing SDK generation tools
- Expanded tooling in our CLI for Arazzo validation and workflow management

## Try It Out

The Arazzo parser is available now on GitHub. Get started by checking out our [documentation](https://www.speakeasy.com/openapi/arazzo) and let us know what you build with it!

We're excited to see how the community uses Arazzo to improve their API testing and integration workflows. This is just the beginning of our journey to make API development more streamlined and reliable.


 This is the content for the doc blog/release-php/index.mdx 

 ---
title: "Type-Safe PHP Generation"
description: "Our type-safe PHP generation is now in beta."
image: "/media/release-php.png"
date: 2024-12-05
authors:
  - name: Ian Bentley
  - image_url: '/media/author-headshots/ian.jpg'
tags:
  - Product Updates
featured_image: "/media/release-php.png"
is_featured: true
---
import { Callout } from '~/components';

## PHP is so back

Off the back of [Laravel's $57 million Series A](https://laravel-news.com/laravel-raises-57-million-series-a), we won't be the first to observe that ***PHP is so back***. Which makes it the perfect time to announce the beta release of our new PHP SDK Generator! We're bringing modern type safety and a streamlined developer experience to the PHP SDKs generated on our platform.

## Headline features

Our PHP SDK Generator balances a simple developer experience with feature depth.

Simple developer experience:

- **Robust type safety** with carefully typed properties for all models
- **Readability** for easy debugging with a streamlined, object-oriented approach 
- **Minimal external dependencies** for a lightweight footprint

Depth:

- **Union type support**, embracing PHP 8's modern type system
- **Laravel service provider** for seamless integration
- **SDK hooks** for customizing request workflows
- **Pagination support** for handling large datasets efficiently
- **Retry logic** for handling transient errors

## Type safety in PHP

### Humble beginnings

Born as a loosely typed language, PHP spent years as the wild child of web development, allowing developers to play fast and loose with their data types. But as applications have grown more complex, the need for stricter type checking has become apparent.

Enter PHP 7, which introduced scalar type declarations and return type declarations, marking the beginning of PHP's type matruity. Next, PHP 8 landed, bringing union types, null-safe operators, and other type-related improvements that firmly put PHP on the path to true type-safety.

### Building type safety into our SDK generation

Our PHP SDK Generator takes fullest advantage of PHP's nascent type system. We've implemented a robust type-hinting system that leverages the latest PHP features to provide a truly type-safe developer experience. Here's how we've done it:

1. **Native Types**: Wherever possible, we use PHP's native types like `enum`, `string`, `int`, `float`, and `bool`.
2. **Class-Based Objects**: We generate standard PHP classes with public properties, using attributes and reflection to guide serialization.
3. **DateTime Handling**: We use the native `\DateTime` class for timestamp handling, ensuring consistent date and time operations.
4. **Custom Types**: For special cases like `Date`, we leverage the `Brick\DateTime\LocalDate` class from our minimal set of dependencies.

Let's take a look at how this translates into real code:

```php
class Drink 
{
    public string $name;
    public float $price;
    public ?DrinkType $type;
    public ?int $stock;
    public ?string $productCode;

    public function __construct(string $name, float $price, ?DrinkType $type, ?int $stock, ?string $productCode)
    {
        // Constructor implementation
    }
}
```

This approach ensures that your IDE can provide accurate auto-complete suggestions, that type-related errors are caught early in the development process and that developers cannot accidentally build objects with incomplete data.

## Unions: Embracing PHP 8's Type System

One of the most exciting features of PHP 8 was the introduction of union types, and our SDK Generator leverages this to provide even more precise type definitions. Union types allow properties or parameters to accept multiple types, providing flexibility while maintaining type safety.

Here's how we've implemented union types in our generated SDKs:

```php
class BeverageContainer
{
    /**
     *
     * @var Shared\Mocktail|Shared\Cocktail $beverage
     */
    public Shared\Mocktail|Shared\Cocktail $beverage;

  
    public function __construct(Shared\Mocktail|Shared\Cocktail $beverage)
    {
        $this->beverage = $beverage;
    }
}
```

## A Lightweight Footprint

We understand the importance of keeping your project's dependency tree manageable. That's why our PHP SDK generator has been designed to rely on as few external libraries as possible. We've carefully selected a minimal set of dependencies:

- `guzzlehttp/guzzle`: For a robust HTTP client
- `jms/serializer`: To handle data serialization and deserialization
- `Brick\DateTime`: For comprehensive date and time support

This lean approach ensures that integrating our generated SDK into your project won't bloat your composer.json or introduce potential conflicts with your existing dependencies.

## Laravel-compatible packages for every API

PHP generation comes with optional Laravel integration support that can be enabled in the SDK's `gen.yaml` configuration. This will generate a Laravel [Service Provider](https://laravel.com/docs/master/providers). The following snippet demonstrates an example of how to use
the Laravel DI container with [Dub's PHP SDK](https://github.com/dubinc/dub-php).

```php
use Dub\Dub;
use Illuminate\Contracts\View\View;
use Illuminate\Http\Request;

final readonly class LinksController
{
    public function __construct(
        private Dub $dub,
    ) {}
    
    public function index(Request $request): View
    {
        return view('links.index', [
            'links' => $this->dub->links->list(),
        ]);
    }
}
```

## Inject custom logic with hooks

One of our most powerful new features is SDK hooks, which allow you to intercept and modify requests at various stages in their lifecycle. This gives you precise control over how your users' SDK interacts with your APIs, enabling customizations like:

- Adding custom headers or query parameters
- Modifying request bodies
- Implementing complex authentication flows
- Adding custom logging or monitoring

Here's an example of how you might use hooks to make sure all requests are sent over `HTTPS`:

```php
namespace Some\SDK\Hooks;

use GuzzleHttp\ClientInterface;

class HttpsCheckHook implements SDKInitHook
{
    public function sdkInit(string $baseUrl, ClientInterface $client): SDKRequestContext
    {
        $parts = parse_url($baseUrl)
        if (array_key_exists('scheme', $parts) && $parts['scheme'] !== 'https') {
            $parts['scheme'] = 'https';
        }
        $baseUrl = http_build_url($parts);

        return new SDKRequestContext($baseUrl, $client);
    }

}
```

## Enhanced Developer Experience

We've gone the extra mile to ensure that working with our generated PHP SDKs is a joy for developers:

- **Improved Import Patterns**: Say goodbye to namespace conflicts and hello to predictable behavior in your IDE's type hinting.
- **Intuitive Factory Pattern**: Our convenient factory pattern manages the SDK configuration, making it a breeze to get started and customize as needed.
- **Comprehensive Documentation**: Each generated SDK comes with detailed markdown documentation, ensuring you have all the information you need at your fingertips.

## Looking Forward

As we enter this beta phase, we're excited to see how the PHP community puts our SDK Generator to work. We're committed to refining and improving the generator based on your feedback, so don't be shy – put it through its paces and let us know what you think!


 This is the content for the doc blog/release-postman-generator/index.mdx 

 ---
title: "Alpha Release: Postman Generator"
description: "Our Postman generation is now in alpha. Learn more about how you can automatically create high quality Postman Collections"
image: "/media/release-postman.png"
date: 2024-05-08
authors:
  - name: Luke Hagar
  - image_url: "/media/author-headshots/luke.jpeg"
tags:
  - Product Updates
featured_image: "/media/release-postman.png"
---

import postman_generator from './assets/Postman Generation.mp4';
import { Callout } from "~/components";

Postman is a popular tool for API development and testing, but it is tedius and often challenging to keep Postman Collections up-to-date with the latest API changes.

To address this issue, we are excited to announce the release of our newest generation target: Postman Collections. This new generator means that you can now automatically generate high quality Postman Collections with the same OpenAPI documents, extensions, and workflows that you use today.


<div className='mt-10'>
  <video controls={false} loop={true} autoPlay={true} width="100%" >
    <source src={ postman_generator } type="video/mp4" />
  </video>
</div>


## Get Started

<Callout title="Learn more" variant="info">
  If you are new to Speakeasy, you can learn more about how to [get started here](/docs/introduction/introduction).
</Callout>

To get started just run:
```bash
speakeasy configure targets
```

Once you have configured the Postman target, use `speakeasy run` to run the workflow.

The Postman collection will be generated, ready for import into Postman

We are very excited to share this with our community. Please give it a try and let us know what you think.

We invite you to join our [Slack community](https://join.slack.com/t/speakeasy-dev/shared_invite/zt-1cwb3flxz-lS5SyZxAsF_3NOq5xc8Cjw), and we look forward to your feedback and suggestions for future improvements.

<Callout title="Read on" variant="info">
  If you're new to Postman, read on to learn more
  about what Postman Collections offer and why they are important.
</Callout>

## What is a Postman Collection?

A Postman Collection is a structured set of API endpoints and associated requests that can be imported into the Postman application for testing, development, and automation purposes. A collection encapsulates various operations like GET, POST, PUT, and DELETE requests, allowing developers to interact with APIs effectively and efficiently.

## Why are they useful to maintain?

Maintaining Postman Collections facilitates the easy adoption, development, and testing of APIs. Collections allow developers to quickly execute API requests without setting up complex environments, speeding up both development and testing. Collections can also serve as a form of documentation, showing how APIs should be used, which is especially beneficial for onboarding new developers or for external users who need to understand the API's capabilities quickly.

## What makes maintenance hard?

Despite their utility, maintaining Postman Collections is challenging. The difficulty comes from needing to keep collections up to date with the latest API changes. Manually updating collections in Postman is time-consuming and prone to errors, and the lack of versioning support in Postman Collections can lead to confusion and inconsistencies. These issues are all compounded when collections are forked by a large number of users.

## How does the generation work?

Postman Collections can be automatically generated from an OpenAPI specification, which contains all the details of the API endpoints. Simply configure a Postman workflow target, run `speakeasy configure github`, and GitHub actions will automate generation. This automatic generation ensures that the collection always reflects any changes in the API specification, reducing the manual effort required and minimizing the risk of errors.

## How does this improve upon existing solutions?

The automated generation of Postman Collections is a significant improvement over manual methods, and the Speakeasy OpenAPI feature set allows a much larger array of customization and functionality over existing automated solutions. This automation not only saves time but also enhances accuracy and consistency across different users and systems. By dynamically generating collections, developers can ensure that their APIs are always correctly represented and can immediately be tested for any updates or changes.


 This is the content for the doc blog/release-python/index.mdx 

 ---
title: "Python Generation with Async & Pydantic Support"
description: "Our new Python generation with Pydantic support & HTTPX."
image: "/media/release-python.png"
date: 2024-07-24
authors:
  - name: Tristan Cartledge
  - image_url: "/media/author-headshots/tristan.jpeg"
tags:
  - Product Updates
featured_image: "/media/release-python.png"
is_featured: true
---

import { CodeWithTabs } from "~/components/codehike/CodeTabs";
import { Callout } from "~/components";
import beezy_ide_video from "./assets/beezy-ide.mp4";

<Callout title="GA Status Update" variant="info">
  Python generation is GA (Generally Available)! Check out our [language maturity page](/docs/languages/maturity) for the latest information on language support.
</Callout>

Today, we're announcing the release of our new Python Generator! The new generator takes full advantage of the best tooling available in the Python ecosystem to introduce true end-to-end type safety, support for asynchronous operations, and a streamlined developer experience.

The full details are below, but here are the headline features that come included in the new Python SDKs:

- Full type safety with [Pydantic](https://github.com/pydantic/pydantic) models for all request and response objects.
- Support for both asynchronous and synchronous method calls using `HTTPX`.
- Support for typed dicts as method inputs for an ergonomic interface.
- `Poetry` for dependency management and packaging.
- Improved IDE compatibility for a better type checking experience.
- A DRYer and more maintainable internal library codebase.

And if you want to see new SDKs in the wild, check out the SDK from our design partner:

- [Dub.co](https://github.com/dubinc/dub-python)

## End-to-end Type Safety with Pydantic

<div className="mt-10">
  <video controls={false} loop={true} autoPlay={true} width="100%">
    <source src={beezy_ide_video} type="video/mp4" />
  </video>
</div>

Pydantic is a data modeling library beloved in the Python ecosystem. It enhances Python's type hinting annotations, allowing for more explicit API contracts and runtime validation.

And now, Speakeasy generates Pydantic models for all request **and response** objects defined in your API. The request models ensure that your user's data is correct at run time, while the response models validate the data returned by the server matches the contract.

The Pydantic-powered hints and error messages presented to users helps them ensure identify and correct errors before they cause issues downstream. This functionality is crucial for maintaining data integrity and reliability in applications that rely on your APIs.

## Enhanced Asynchronous and Synchronous Support

<div style={{ width: '100%', overflow: 'auto' }}>
    <div style={{ float: 'left', width: '50%', padding: '20px'}}>
        <CodeWithTabs>
          ```python !!tabs sync.py
            import beezy_ai
            from beezy_ai import BeezyAI
            import os

            s = BeezyAI(
                api_key_auth=os.getenv("API_KEY"),
            )

            res = s.chat.stream(request={
                "model": "beezy-small-latest",
                "messages": [
                    {
                        "role": beezy_ai.ChatCompletionRole.USER,
                        "content": "What's the difference between OpenAPI and Swagger??",
                    },
                ],
                "max_tokens": 512,
            })

            if res is not None:
                for event in res:
                    # handle event
                    print(event)
          ```
        </CodeWithTabs>
    </div>
    <div style={{ float: 'left', width: '50%', padding: '20px'}}>
        <CodeWithTabs>
          ```python !!tabs async.py
          # !focus(1,6,10[7:37],23)
            import asyncio
            import beezy_ai
            from beezy_ai import BeezyAI
            import os

            async def main():
                s = BeezyAI(
                    api_key_auth=os.getenv("API_KEY"),
                )
                res = await s.chat.stream_async(request={
                    "model": "beezy-small-latest",
                    "messages": [
                        {
                            "role": beezy_ai.ChatCompletionRole.USER,
                            "content": "What's the difference between OpenAPI and Swagger??",
                        },
                    ],
                    "max_tokens": 512,
                })
                if res is not None:
                    for event in res:
                        print(event)
            asyncio.run(main())
          ```
        </CodeWithTabs>
    </div>

</div>

As the Python ecosystem has expanded to support data intensive, real-time applications, asynchronous support has grown in importance. That's why we've built our Python SDKs on top of `HTTPX`. Python SDKs will now support both asynchronous and synchronous method calls.

And to make it as ergonomic as possible, there's no need for users to declare separate sync & async clients if they need both. Just instantiate one SDK instance and call methods sync or async as needed.

## Support for `TypedDict` Input

```python main.py
# !focus(5:7)
  from clerk_dev import Clerk

  s = Clerk()

  res = s.invitations.create(email_address="user@example.com",
                            ignore_existing=True, notify=True, public_metadata={},
                            redirect_url="https://example.com/welcome")

  if res is not None:
    # handle response
    pass
```

Continuing with our efforts to make the SDKs as ergonomic as possible. SDKs now support the use of `TypedDict`s for passing data into methods. This feature allows you to construct request objects by simply listing off `key: value` pairs.

The SDK will handle the construction of the request object behind the scenes. Just another way we're making it easier for your users to get integrated with your APIs.

## A Streamlined Developer Experience

It's what on the inside that matters, so we've made significant improvements to the internal library code as well:

- **Improved Import Patterns**: By refining how we handle imports internally, developers will see a more stable and predictable behavior in their IDE's type hinting. This change helps maintain a cleaner namespace and reduces the chance of conflicts or errors due to improper imports.
- **Enhanced Dependency Management**: Transitioning from `pip` to `poetry` has streamlined our SDK's setup and dependency management, making it easier to maintain and update. `poetry` provides a more declarative way of managing project dependencies, which includes automatic resolution of conflicts and simpler packaging and distribution processes.

- **Renamed Packages**: To further enhance usability, we've decoupled SDK class names from package names, allowing for more intuitive and flexible naming conventions. This adjustment allows better organization and integration within larger projects, where namespace management is crucial.

- **DRYer Codebase**: We've refactored our internal library code to reduce redundancy and improve code reuse. This makes it easier for users to step through the codebase and understand how the SDK functions.

These changes collectively reduce the complexity and increase the maintainability of projects using our SDK.

## Looking Forward

The new Python Generator is just the beginning. We plan to continue refining the SDK based on user feedback. Over the next few weeks we'll be moving to make this new generation the default for all new Python SDKs generated on the platform.

We are excited to see how the community puts these new features to work. Your feedback is invaluable to us, and we welcome everyone to join us in refining this tool to better suit the needs of the Python community.


 This is the content for the doc blog/release-react-hooks/index.mdx 

 ---
title: "React Hooks: TypeScript SDKs with TanStack React Query Support"
description: "Our code generation now supports the addition of custom logic to SDKs, allowing you to further customize your SDKs."
image: "/media/react-query-hooks.png"
date: 2024-12-06
authors:
  - name: Georges Haidar
  - image_url: '/media/author-headshots/georges.jpeg'
tags:
  - Product Updates
featured_image: "/media/react-query-hooks.png"
is_featured: true
---

import { CodeWithTabs } from "~/components/codehike/CodeTabs";
import { Callout } from '~/components';

<Callout title="Preview Availability" variant="success">
  Now in preview! Enable React hook generation for your TypeScript SDKs through the Speakeasy CLI. Check out our [getting started guide](/docs/customize/typescript/react-hooks) to try it today.
</Callout>

Today, we're excited to announce first-class support for React hooks in our TypeScript SDKs. This new generation feature builds on top of our [standalone functions](/post/standalone-functions) work and [TanStack Query](https://tanstack.com/query/latest) (formerly React Query) to provide seamless integration between your API and React applications.

We think this feature is going supercharge teams to build awesome React applications against their APIs in the fewest steps possible.

Used in roughly 1 in 6 React projects today, TanStack Query has become the de-facto standard for managing server state in React applications. Our new generator wraps your API operations, utilizing TanStack Query's powerful caching, synchronization, and data management features to create fully-typed hooks that are ready for use in your React app. Here are the key features you get out of the box:

- Full type safety from your API through React components
- Backed by runtime validation with [Zod](https://zod.dev) so you can trust your types
- Great tree-shaking performance so you only bundle the hooks and SDK code you use
- Automatic cache management with smart invalidation utilities
- Support for both standard and infinite pagination patterns
- Integration with server-side rendering, React Server Components and Suspense
- Optimistic updates and background refetching
- Smart request deduplication and request cancellation

<CodeWithTabs>
```typescript !!tabs profile-view.tsx
import { useActorProfile } from "@speakeasy-api/bluesky/react-query";

function Demo() {
  const { data, status, error, isPlaceholderData } = useActorProfile(
    {
      actor: props.username,
    },
    {
      // All the familiar options from TanStack Query.
      enabled: !!props.username && !!didResult.data,
      placeholderData: (previousData) => previousData,
    },
  );

  if (status === "loading") {
    return <div>Loading...</div>;
  }

  if (status === "error") {
    return <div>Error: {error.message}</div>;
  }

  const { followersCount = "-", followsCount = "-" } = data;

  return (
    <div className="inline-flex items-start gap-2 rounded border-zinc-800">
      <img
        className="w-16 aspect-square rounded-full"
        src={data.avatar}
        alt={data.displayName}
      />
      <div>
        <h1 className="text-2xl">{data.displayName}</h1>
        <p className="text-muted-foreground">{data.handle}</p>
        <p>
          <span className="font-semibold">{followersCount}</span>
          <span className="text-muted-foreground">followers</span>
        </p>
        <p>
          <span className="font-semibold">{followsCount}</span>
          <span className="text-muted-foreground">follows</span>
        </p>
      </div>
    </div>
  );
}
```
```typescript !!tabs actorProfile.ts
export function useActorProfile(
  request: operations.AppBskyActorGetProfileRequest,
  options?: QueryHookOptions<ActorProfileQueryData>,
): UseQueryResult<ActorProfileQueryData, Error> {
  const client = useBlueskyContext();
  return useQuery({
    ...buildActorProfileQuery(
      client,
      request,
      options,
    ),
    ...options,
  });
}
```
</CodeWithTabs>

## End-to-end Type Safety

Our React hooks provide complete type safety from your API definition all the way through to your React components. Request and response types are derived from your OpenAPI specification and validated at runtime, ensuring your application stays in sync with your API contract.

The type-safe interface helps developers catch errors early and enables rich IDE features like autocompletion and inline documentation.

## Intelligent Cache Management

Managing cached data is one of the most challenging aspects of building modern web applications. Building on TanStack query, our React hooks handle this complexity for you by generating intelligent cache keys. We then provide utility functions to invalidate specific resources or groups of resources, making it easy to keep your UI in sync with your server state. The cache management system is built to handle common patterns like:

- Optimistic updates for a snappy UI
- Background refetching of stale data
- Smart request deduplication
- Automatic revalidation after mutations

## Support for SSR, RSC, Suspense and more

Our React hooks are designed to work seamlessly with modern React patterns and features. We provide both standard and Suspense-enabled versions of each query hook, letting you choose the right approach for your application.

Additionally, we provide utilities for prefetching data during server-side rendering and in React Server Components that will be immediately available to client components using the hooks.

The hooks also support TanStack Query's latest features for handling loading states, preventing layout shift, and managing complex data dependencies.

Here's an example of everything you get for each operation in your SDK:

```typescript
import {
  // Query hooks for fetching data.
  useFollowers,
  useFollowersSuspense,

  // Query hooks suitable for building infinite scrolling or "load more" UIs.
  useFollowersInfinite,
  useFollowersInfiniteSuspense,

  // Utility for prefetching data during server-side rendering and in React
  // Server Components that will be immediately available to client components
  // using the hooks.
  prefetchFollowers,
  
  // Utilities to invalidate the query cache for this query in response to
  // mutations and other user actions.
  invalidateFollowers,
  invalidateAllFollowers,
} from "@speakeasy-api/bluesky/react-query/followers.js";
```

## Pagination Made Simple

We automatically detect pagination patterns in your API and generate appropriate hooks for both traditional pagination and infinite scroll interfaces. The infinite query hooks integrate perfectly with intersection observers for building smooth infinite scroll experiences.

Here's an example using the [infinite query][infinite-query] version of a React hook: 

[infinite-query]: https://tanstack.com/query/v5/docs/framework/react/guides/infinite-queries

```typescript
import { useInView } from "react-intersection-observer";

import { useActorAuthorFeedInfinite } from "@speakeasy-api/bluesky/react-query/actorAuthorFeed.js";

export function PostsView(props: { did: string }) {
  const { data, fetchNextPage, hasNextPage } = useActorAuthorFeedInfinite({
    actor: props.did,
  });

  const { ref } = useInView({
    rootMargin: "50px",
    onChange(inView) {
      if (inView) { fetchNextPage(); }
    },
  });

  return (
    <div>
      <ul className="space-y-4">
        {data?.pages.flatMap((page) => {
          return page.result.feed.map((entry) => (
            <li key={entry.post.cid}>
              <FeedEntry entry={entry.post} />
            </li>
          ));
        })}
      </ul>
      {hasNextPage ? <div ref={ref} /> : null}
    </div>
  );

```

## Looking Forward

We're excited to see how the community puts these new features to work. Your feedback is invaluable to us, and we welcome everyone to join us in refining these tools to better serve the React ecosystem.

Try out the new React hooks today by updating your Speakeasy CLI and enabling React hooks generation for your TypeScript SDKs. Check out our documentation to get started.


 This is the content for the doc blog/release-sdk-docs/index.mdx 

 ---
title: "Code as Docs Integration: SDKs embedded in your API reference"
description: "Our SDKs can now be easily integrated with your API reference to make your docs code-native."
image: "/media/release-sdk-docs.png"
date: 2024-04-12
authors:
  - name: Sagar Batchu
  - image_url: "/media/author-headshots/sagar.jpeg"
tags:
  - Product Updates
featured_image: "/media/release-sdk-docs.png"
is_featured: true
---

import { Testimonial } from "~/components";
import snippets_url from "./assets/snippet-docs.mp4";

Production integration with an API involves a lot more than just making an HTTP request. So your docs need to do more than provide users with a generic `fetch` call.

Today, we're partnering with [Mintlify](https://mintlify.com/) to release our new "code as docs" integration to help companies shift their API references to being code-native. You can now fully integrate your SDKs into your documentation provider so that building a production integration with your API is as easy as ⌘c, ⌘p.

<div className="mt-10">
  <video controls={false} loop={true} autoPlay={true} width="100%">
    <source src={snippets_url} type="video/mp4" />
  </video>
</div>

## Building with Mintlify

We spent the last two months in close collaboration developing the SDK Docs solution with the stellar team over at [Mintlify](https://mintlify.com/docs/integrations/sdks/speakeasy). Our shared commitment to Developer experience and building OpenAPI-based tooling made the team at Mintlify natural launch partners. We couldn't be more excited to work together towards our shared vision of making API integrations as easy as possible for developers.

<Testimonial
  variant="dark"
  avatar="/media/quote-headshots/han-wang.jpeg"
  quoted="Han Wang, Co-founder @ Mintlify"
>
  Your users always know best. Even before we officially met Speakeasy, we were
  familiar with the product because we had tons of shared users and they were
  describing Speakeasy with the same vocabularly which we use at Mintlify:
  "developer-centric", "attention to detail", "extensible". Working together has
  been like an extension of our team.
</Testimonial>

## How It Works

For every method in your OpenAPI spec, we will generate code snippets that demonstrate use of your SDK to make the corresponding API request. We then add these snippets back into your spec using the `x-codeSamples` extension.

To enable the new feature, you simply make a one line change to your Speakeasy workflow file:

```yaml .speakeasy/workflow.yaml
# !focus(5:6)
targets:
  my-target:
    target: typescript
    source: my-source
    codeSamples:
      output: codeSamples.yaml
```

With your new workflow configured, we will regenerate snippets and create an updated OpenAPI spec.

Point your docs provider at the new spec, and you're good to go!

## Supported documentation

This feature was developed in partnership with Mintlify, but was designed for extensibility. It should be compatible with any documentation vendor that supports the `x-codeSamples` extension. That includes:

- [Mintlify](https://mintlify.com/docs/integrations/sdks/speakeasy)
- [Redoc](https://redocly.com/)
- [Readme](https://readme.com/)
- [Stoplight](https://stoplight.io/)
- **Many more**

## The Future

As we look ahead, the integration of SDKs into documentation platforms like Mintlify is only the beginning. We are working to enhance code snippets to be, not just copiable, but fully executable within a live sandbox environment.

This transformative feature will empower developers to bootstrap production usage directly from the documentation pages.


 This is the content for the doc blog/release-sdk-hooks/index.md 

 ---
title: "SDK Hooks: Safely add custom logic to your SDKs"
description: "Our code generation now supports the addition of custom logic to SDKs, allowing you to further customize your SDKs."
image: "/media/release-sdk-hooks.png"
date: 2024-04-04
authors:
  - name: Tristan Cartledge
  - image_url: '/media/author-headshots/tristan.jpeg'
tags:
  - Product Updates
featured_image: "/media/release-sdk-hooks.png"
is_featured: true
---

For those who live and breathe APIs, there’s a nuanced distinction between what is considered an SDK (Software Development Kit) and what is considered an HTTP Client. The difference lies in the level of abstraction that’s being provided on top of the API. HTTP clients offer a language-native, but unadorned way of sending requests over the internet. SDKs meanwhile are a superset of an HTTP Client, injecting additional functionality that lives outside of the API definition.  The line is fuzzy, but by the most pedantic definition, up to now Speakeasy has created (amazing) HTTP clients. 

However, with our newest feature – SDK Hooks, we’re stepping firmly into the territory of SDKs. Hooks provide SDK authors with a way to easily inject custom code that executes at specified events in the SDK’s runtime. This allows Speakeasy users to extend their SDKs to include business logic or additional transformations that lie outside of their API definition.

[Full documentation here](/docs/customize/code/sdk-hooks)

## How Does It Work?

In this intial release, we are exposing four event types (Hooks) where users are able to specify custom functionality:

- **SDK initialization** - at the time the end user instantiates their SDK.
- **Pre-request** - before a request is sent to the server.
- **Post-request success** - after a request has been successfully completed.
- **Post-request error** - after a request has resulted in an error.

![Diagram showing SDK hooks in the request stream](./assets/sdk-hooks.png)

To add custom code via a Hook you just need to add a new file to the `hooks` folder of your SDK that defines a hook class that implements a subset of the above four types:

```typescript
import {
  AfterSuccessContext,
  AfterSuccessHook,
  BeforeRequestContext,
  BeforeRequestHook,
} from "./types";

import { HTTPClient } from "../lib/http";

export class ExampleHook
  implements BeforeRequestHook, AfterSuccessHook
{
  beforeRequest(hookCtx: BeforeRequestContext, request: Request): Request {
    // modify the request object before it is sent, such as adding headers or query parameters or throw an error to stop the request from being sent
    return request;
  }

  afterSuccess(hookCtx: AfterSuccessContext, response: Response): Response {
    // modify the response object before deserialization or throw an error to stop the response from being deserialized
    return response;
  }
}
```

## What Can You Do With Hooks?

Anything you can think of! That’s what is so exciting about Hooks. Allowing for the addition of custom code in a safe, extensible manner means there’s no limit on what’s possible.

A few of the use cases that have us really excited right off the bat:

- **Custom authentication** - Inject code to handle a custom authentication mechanism that lives outside of what’s easily definable in OpenAPI.
- **Use a custom HTTP client** - Have your SDK make use of a custom HTTP client if you have non-standard networking requirements.
- **Add Logging** - Hook in your favorite telemetry provider to log data on what’s happening on the client side of your API integrations.
- **Handle Sensitive Data** - If you’re worried about sensitive information being erroneously sent, to your API, inject code to make sure certain fields are properly encrypted, or even write code to handle the encryption for your customers.
- **Add caching** Write code to build a local cache in which you can store commonly produced responses. Save users time, and spare your API the overhead.
- **Error handling** - Insert custom error handling into your SDK to help end users troubleshoot a broken integration. Maybe flagging that a particular endpoint has had recent breaking changes, and pointing them towards the docs.

The above are just a few of the examples of what’s possible. We can’t wait to see what other use cases people discover.

## **The Future**

We want to give our users the tools to make the richest SDKs possible. Looking ahead, we’re excited about the possibility of adding additional Hooks to make control as fine-grained as possible. If there are any additional hooks that you would like to see, please don’t hesitate to get in touch and let us know!

 This is the content for the doc blog/release-sdk-sandboxes/index.md 

 ---
title: "One-Click SDK Testing & Experimentation with SDK Sandboxes"
description: "Speakeasy released SDK Sandboxes to enable fast and easy SDK experimentation and testing in GitHub."
keywords: [api, sdk, sdk sandbox, developer containers]
date: 2023-10-11
image: "/media/release-sdk-sandbox.png"
authors:
  - name: Ryan Albert
  - image_url: "/media/author-headshots/ryan.png"
tags:
  - Product Updates
featured_image: "/media/release-sdk-sandbox.png"
is_featured: true
---

TL;DR: Speakeasy [SDK Sandboxes](/docs/advanced-setup/sdk-sandbox) enable you and your SDK end-users to easily test and experiment with your SDKs with a single click in GitHub - no more wrestling with new language setups or juggling endless dependencies. Get hands-on with the SDK in seconds.

As an API producer looking to offer a great developer experience for your end-users, you’ve recognized that SDKs are a key part of delivering on that promise. A critical step in building and [publishing your SDK](/post/apis-vs-sdks-difference) is testing that it works as advertised. Unless, of course, you're a maverick who deploys a new feature 2 minutes prior to a live demo to investors, in which case you’d probably skip all testing anyway! #yolo

Assuming that’s not you, before you can test the SDK, you first need to set up a development environment for each SDK language you want to test. For example, you may need to set up a Java environment, then a C# environment, then a PHP environment, then… If you’ve managed to navigate thus far, you still need to set up a test project, download or import the SDK, and manually make your SDK calls.

You may also want to give your SDK consumers a rapid way to explore and test the SDK — one that doesn’t require them to import the SDK, create toy projects, or worry about dependency clashes, configuration quirks, or setting up specific environments. Achieving this can help boost your time to 200 by giving consumers a no-risk, friction-free way to try your SDK.

## Enter Speakeasy SDK Sandboxes

Speakeasy SDK Sandboxes automatically set up language-specific environments for your SDKs with just a few lines of config. This creates a sandbox where you or your SDK consumers can jump straight into exploring the SDK, without the overhead of creating new dev setups or risking disruptions in their existing development environment. It's a ready-to-go test kit where all the pieces are pre-arranged, allowing users to focus solely on the SDK's capabilities.

Speakeasy’s SDK Sandboxes also provide an in-browser IDE that includes the Speakeasy CLI. With the CLI, you or your SDK users can immediately [generate SDK usage examples](/docs/code-samples/generate-code-samples) for any method without needing to hunt through docs — making for a powerful exploration experience.

Under the hood, our dev container product integrates effortlessly with a wide range of platforms, including GitHub's in-browser container solution, Codespaces.

## How It Works

To enable SDK Sandboxes in your Speakeasy SDK, just add a few lines of configuration to your project:

```yaml
configVersion: 1.0.0
generation:
  devContainers:
    enabled: true
    schemaPath: ./openapi.yaml
```

On the next generation run, Speakeasy will automatically generate support documentation and an SDK Sandboxes badge in your SDK README.

![A new SDK Sandboxes badge](./img/sdk-sandboxes-badge.png)

Once Speakeasy SDK Sandboxes are enabled, the SDK will show a new SDK Sandboxes badge.

Then, any user viewing the repo can just click the handy “Open in GitHub Codespace” badge to open the in-browser code editor and get started!

We also create custom SDK Sandboxes documentation that shows how to work with SDK usage snippets in your dev container environment, as well as how to generate additional usage snippets for any operation via the integrated Speakeasy CLI.

>✅ We currently offer SDK Sandbox support for `Go`, `Typescript`, and `Python`. [Please reach out for additional language requests](https://join.slack.com/t/speakeasy-dev/shared_invite).

## Skip Setup and Jump to Friction-Free DevEx

Speakeasy SDK Sandboxes offer both you and your SDK consumers a no-effort sandbox environment where you can validate the behavior of your SDK, and your customers can quickly explore its full capabilities. Instantly initialize a sandbox in [Github Codespaces](https://docs.github.com/en/codespaces/overview) with just a click, from any browser, whether you are in the office, on an airplane, or sitting on the beach!

Ready to try it for yourself? [Sign up](https://app.speakeasy.com/) for free today and head over to the [SDK Sandboxes docs](/docs/advanced-setup/sdk-sandbox) to add it to your SDK today.


 This is the content for the doc blog/release-speakeasy-docs/index.mdx 

 ---
title: "Speakeasy Docs: the documentation your API deserves"
description: "Get docs that are as sleek as your SDKs with Speakeasy Docs, powered by Scalar."
image: "/media/release-speakeasy-docs.png"
date: 2024-12-04
authors:
  - name: Sagar Batchu
  - image_url: '/media/author-headshots/sagar.jpeg'
tags:
  - Product Updates
featured_image: "/media/release-speakeasy-docs.png"
is_featured: true
---

Great documentation isn't just a nice-to-have — it's essential for developer adoption and success. We've heard from countless companies that while generating SDKs solved a crucial part of their API distribution challenge, they're still struggling to provide a documentation experience that matches their brand and meets their developers' needs.

We're excited to announce the launch of Speakeasy Docs, powered by [Scalar](https://scalar.com/). This new offering combines Speakeasy's expertise in SDK generation with Scalar's best-in-class documentation platform to provide a complete solution so companies can deliver exceptional developer experiences.

## Too often docs let developers down

Companies often face a difficult choice when building and maintaining API documentation: invest significant engineering resources into building the docs experience they want, or protect engineering resources by settling for a generic experience that doesn't meet their quality bar.

Existing documentation solutions have problems such as customization limitations, OpenAPI spec rendering challenges, and difficulties maintaining consistency between their SDKs and documentation. These limitations put a ceiling on the developer experience they can deliver, impacting adoption and satisfaction.

## The docs your API deserves

**Complete OpenAPI support**: Your API is more complicated than the pet store API. That's why Speakeasy Docs starts with industry-leading OpenAPI spec rendering. Your entire API, in all its messy glory, will be presented with accuracy and clarity in the generated documentation.

**Customized branding**: Companies work hard to establish a unique identity, and your docs should reflect that. Customization is at the heart of Speakeasy Docs. You have complete control over the look and feel of your documentation. Your docs won't just contain your logo — they'll embody your brand's identity, matching your color schemes, typography, and custom design elements seamlessly.

The result? Documentation that looks and feels custom-built for your brand.

**Always in-sync**: We've also solved one of the most persistent challenges in API documentation: maintaining consistency between your SDKs and your docs. By integrating directly with our SDK generation platform, Speakeasy Docs ensures that your documentation and code samples are always in sync. When your API evolves, both your SDKs and documentation update automatically, eliminating the drift that often occurs between documentation and implementation.

## Why we partnered with Scalar

Our partnership with Scalar is built on complementary strengths. While we've focused on building the best SDK generation platform, Scalar has established itself as a leader in API documentation, particularly when it comes to API reference rendering.

This partnership allows both companies to focus on their core strengths:

- Speakeasy: Advanced SDK generation and API tooling
- Scalar: Design excellence and documentation expertise

The result is a solution that's greater than the sum of its parts, offering our customers the best of both worlds without compromise.

### How the partnership works

When you use Speakeasy Docs, you get the full Scalar solution without any limitations. You'll work with one vendor (us), with one support channel for both your docs & SDKs. Down the road, you'll see even deeper integration with new features that make the experience more seamless.

## Getting Started

Getting started with Docs is straightforward and can be done entirely through our self-service dashboard. The platform works seamlessly with your existing OpenAPI specifications, and our team is here to help with any customization needs.

For existing Speakeasy customers, just head to the Docs tab in the Speakeasy dashboard and follow the steps to enable it. For new customers, you can now get started with both SDK generation and documentation in one integrated solution by [signing up](https://app.speakeasy.com/).

Join the growing number of companies that are choosing Speakeasy Docs to provide their API with the documentation experience it deserves!

 This is the content for the doc blog/release-speakeasy-suggest/index.mdx 

 ---
title: "Introducing Speakeasy Suggest - Automatic OpenAPI Spec Maintenance"
description: "How we built an OpenAPI LLM agent."
keywords: [api, openapi, llm, ai, llm agent, rag]
image: "/media/release-speakeasy-suggest.png"
date: 2023-09-25
authors:
  - name: Anuraag Nalluri
  - image_url: "/media/author-headshots/anuraag.jpeg"
tags:
  - Product Updates
featured_image: "/media/release-speakeasy-suggest.png"
---

[`Speakeasy Suggest`](/post/release-speakeasy-suggest), our AI-powered tool for automatically improving OpenAPI specs, is available now through the [Speakeasy CLI](/docs/speakeasy-cli/suggest/README) or as a [Github workflow](/docs/workflow-reference). Provide your own OpenAI API key, or simply use ours by default. We’d love to hear your feedback in our [Slack community](https://join.slack.com/t/speakeasy-dev/shared_invite/zt-1df0lalk5-HCAlpcQiqPw8vGukQWhexw)!

Stay tuned for more posts on `Suggest` output as Github PRs when configuring it as a workflow, interesting results on a variety of specs, and its downstream effects on Speakeasy-generated SDKs!

✨ We plan on open sourcing the core of our LLM-based agent for general-purpose use. Its primary function will be to serve as a JSON document transformer that receives a custom validation function, list of errors, and original document as inputs.

import video_url from "./assets/speakeasy-suggest-demo.mp4";

<video controls={false} loop={true} autoPlay={true} width="100%">
  <source src={video_url} type="video/mp4" />
</video>

## Background

At Speakeasy, we’ve been automating the creation of high-quality developer surfaces for API companies around the world. These include SDKs across multiple languages and even Terraform providers. Today, our generation logic is built on top of OpenAPI, requiring users to supply an OpenAPI schema to effectively use our tooling and generate these surfaces.

Unfortunately, OpenAPI is a complicated specification with lots of potential for misconfiguration and unnecessary repetition. For example, the following schema operations contain duplicate operationIDs (i.e., `listDrinks`), duplicate inline schema objects, and no examples.

```yaml

---
/drinks:
  get:
    operationId: listDrinks
    summary: Get a list of drinks.
    description: Get a list of drinks, if authenticated this will include stock levels and product codes otherwise it will only include public information.
    security:
      - {}
    tags:
      - drinks
    parameters:
      - name: drinkType
        in: query
        description: The type of drink to filter by. If not provided all drinks will be returned.
        required: false
        schema:
          $ref: "#/components/schemas/DrinkType"
    responses:
      "200":
        description: A list of drinks.
        content:
          application/json:
            schema:
              type: array
              items:
                type: object
                properties:
                  name:
                    description: The name of the drink.
                    type: string
                  type:
                    $ref: "#/components/schemas/DrinkType"
                  price:
                    description: The price of one unit of the drink in US cents.
                    type: number
                  stock:
                    description: The number of units of the drink in stock, only available when authenticated.
                    type: integer
                    readOnly: true
                  productCode:
                    description: The product code of the drink, only available when authenticated.
                    type: string
                required:
                  - name
                  - price
---
/drink/{name}:
  get:
    operationId: listDrinks
    summary: Get a drink.
    description: Get a drink by name, if authenticated this will include stock levels and product codes otherwise it will only include public information.
    tags:
      - drinks
    parameters:
      - name: name
        in: path
        required: true
        schema:
          type: string
    responses:
      "200":
        description: A drink.
        content:
          application/json:
            schema:
              type: object
              properties:
                name:
                  description: The name of the drink.
                  type: string
                type:
                  $ref: "#/components/schemas/DrinkType"
                price:
                  description: The price of one unit of the drink in US cents.
                  type: number
                stock:
                  description: The number of units of the drink in stock, only available when authenticated.
                  type: integer
                  readOnly: true
                productCode:
                  description: The product code of the drink, only available when authenticated.
                  type: string
              required:
                - name
                - price
```

As a result of this complexity, many companies create a spec to benefit from the vast ecosystem of OpenAPI tooling (e.g. docs providers), but they don’t have resources or processes in place to maintain it as a first-class resource.

At Speakeasy, we’ve worked with many users’ specs to ensure they are compliant, clean, and accurately depict the state of their API. By leveraging our OpenAPI expertise and custom spec extensions, we’ve been able to create specs that produce idiomatic and human-readable SDKs for dozens of companies. **But wouldn’t it be great if we could automate this? Enter Speakeasy Suggest.**

## Building Speakeasy Suggest

### What is it?

`Speakeasy Suggest` is our LLM-based agent that, given an OpenAPI document, automatically suggests fixes, applies them, and outputs the modified spec. Using AI, we’re able to offload the burden of spec management from API producers. `Suggest` can be invoked through both the Speakeasy CLI (outputs modified spec to the local filesystem) and our GitHub Action (creates PR) today.

Applying `Suggest` on the invalid spec above, we produce a valid document with unique operationIDs, re-use of common objects where applicable, and better examples.

```yaml
components:
  schemas:
    ...
    Drink:
      type: object
      properties:
        name:
          description: The name of the drink.
          type: string
        type:
          $ref: "#/components/schemas/DrinkType"
        price:
          description: The price of one unit of the drink in US cents.
          type: number
        stock:
          description: The number of units of the drink in stock, only available when authenticated.
          type: integer
          readOnly: true
        productCode:
          description: The product code of the drink, only available when authenticated.
          type: string
      required:
        - name
        - price
      example:
        name: Old Fashioned
        type: cocktail
        price: 1000
        stock: 50
        productCode: EX123
...
/drinks:
    get:
      operationId: listDrinks
      summary: Get a list of drinks.
      description: Get a list of drinks, if authenticated this will include stock levels and product codes otherwise it will only include public information.
      security:
        - {}
      tags:
        - drinks
      parameters:
        - name: drinkType
          in: query
          description: The type of drink to filter by. If not provided all drinks will be returned.
          required: false
          schema:
            $ref: "#/components/schemas/DrinkType"
      responses:
        "200":
          description: A list of drinks.
          content:
            application/json:
              schema:
                type: array
                items:
                  $ref: "#/components/schemas/Drink"
        ...
/drink/{name}:
  get:
    operationId: getDrink
    summary: Get a drink.
    description: Get a drink by name, if authenticated this will include stock levels and product codes otherwise it will only include public information.
    tags:
      - drinks
    parameters:
      - name: name
        in: path
        required: true
        schema:
          type: string
        example: CocaCola
    responses:
      "200":
        description: A drink.
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/Drink"
      ...
...
```

For the remainder of this post, we’d like to delve deeper into the decision-making and engineering challenges behind `Speakeasy Suggest`. To do that, we’ll start from the beginning.

### Good Input = Good Output

Just as a polished OpenAPI spec may be used to generate high-quality SDKs, an LLM requires input with sufficient specificity and detail to produce useful suggestions for a document. It became quickly obvious to us that dumping a spec and naively asking an LLM to “make it better” would not be fruitful.

We found that our in-house validator (i.e. `speakeasy validate` from our [CLI](https://github.com/speakeasy-api/speakeasy)) would be effective at adding a more specific, deterministic context to our LLM prompt. Our validator is built using [vacuum](https://github.com/daveshanley/vacuum), enabling us to specify **custom rules**. Since these rules are defined by us, they output fixed error messages and line numbers for an array of spec issues. Below is a table highlighting a few of the errors, the suggestions we’d hope to receive from the LLM when including them in the prompt, and explanations of the resulting effects on Speakeasy-generated SDKs when applying those suggestions to the OpenAPI spec.

| Validation Error                             | Suggestion                                                  | Explanation                                                       |
| -------------------------------------------- | ----------------------------------------------------------- | ----------------------------------------------------------------- |
| duplicate operationId fields within same tag | Change value of offending operationId's                     | Compiles without method names conflicting to get a functional SDK |
| duplicate inline object schemas              | Move to shared component                                    | Much shorter and more human-looking class names                   |
| missing examples                             | Add examples for parameter, request bodies, responses, etc. | Generated usage snippets are more human-looking                   |

Each of the validation errors above is present in our invalid spec. So let’s examine the generated Go SDK code before and after running `Speakeasy Suggest` on the document.

**Before**

```go
 // ListDrinks - Get a drink.
// Get a drink by name, if authenticated this will include stock levels and product codes otherwise it will only include public information.
func (s *drinks) ListDrinks(ctx context.Context, request operations.ListDrinksRequest) (*operations.ListDrinksResponse, error) {
  ...
  switch {
    case httpRes.StatusCode == 200:
      switch {
      case utils.MatchContentType(contentType, `application/json`):
        var out *operations.ListDrinks200ApplicationJSON
        if err := utils.UnmarshalJsonFromResponseBody(bytes.NewBuffer(rawBody), &out); err != nil {
          return nil, err
        }

        res.ListDrinks200ApplicationJSONObject = out
      ...
      }
    ...
  }
  return res, nil
}

// ListDrinks - Get a list of drinks.
// Get a list of drinks, if authenticated this will include stock levels and product codes otherwise it will only include public information.
func (s *drinks) ListDrinks(ctx context.Context, request operations.ListDrinksRequest) (*operations.ListDrinksResponse, error) {
  ...
  switch {
    case httpRes.StatusCode == 200:
      switch {
      case utils.MatchContentType(contentType, `application/json`):
        var out []operations.ListDrinks200ApplicationJSON
        if err := utils.UnmarshalJsonFromResponseBody(bytes.NewBuffer(rawBody), &out); err != nil {
          return nil, err
        }

        res.ListDrinks200ApplicationJSONObjects = out
      ...
      }
    ...
  }
  return res, nil
}
```

#### After

```go
// GetDrink - Get a drink.
// Get a drink by name, if authenticated this will include stock levels and product codes otherwise it will only include public information.
func (s *drinks) GetDrink(ctx context.Context, request operations.GetDrinkRequest) (*operations.GetDrinkResponse, error) {
  ...
  switch {
    case httpRes.StatusCode == 200:
      switch {
      case utils.MatchContentType(contentType, `application/json`):
        var out *shared.Drink
        if err := utils.UnmarshalJsonFromResponseBody(bytes.NewBuffer(rawBody), &out); err != nil {
          return nil, err
        }

        res.Drink = out
      ...
      }
    ...
  }
  return res, nil
}

// ListDrinks - Get a list of drinks.
// Get a list of drinks, if authenticated this will include stock levels and product codes otherwise it will only include public information.
func (s *drinks) ListDrinks(ctx context.Context, request operations.ListDrinksRequest) (*operations.ListDrinksResponse, error) {
  ...
  switch {
    case httpRes.StatusCode == 200:
      switch {
      case utils.MatchContentType(contentType, `application/json`):
        var out []shared.Drink
        if err := utils.UnmarshalJsonFromResponseBody(bytes.NewBuffer(rawBody), &out); err != nil {
          return nil, err
        }

        res.Drinks = out
      ...
      }
    ...
  }
  return res, nil
}
```

The code in “Before” would not even compile due to duplicate method names from the conflicting operationIDs. As such, we wouldn’t even generate the SDK without throwing a validation error but have done so here simply to show the differences in output. Also, notice the stark difference in the generated class names the successful responses are being deserialized to (i.e. `ListDrinks200ApplicationJSON` vs. `Drink`).

Let’s also examine the differences in the README’s usage snippets your users will reference in their implementation.

**Before**

```go
...
func main() {
  s := sdk.New(
      sdk.WithSecurity(shared.Security{
          APIKey: "",
      }),
  )

  ctx := context.Background()
  res, err := s.Drinks.ListDrink(ctx, operations.ListDrinkRequest{
      Name: "Willie Gulgowski DVM",
  })
  if err != nil {
      log.Fatal(err)
  }

  if res.ListDrink200ApplicationJSONObject != nil {
      // handle response
  }
}
...
```

**After**

```go
...
func main() {
  s := sdk.New(
      sdk.WithSecurity(shared.Security{
          APIKey: "",
      }),
  )

  ctx := context.Background()
  res, err := s.Drinks.GetDrink(ctx, operations.GetDrinkRequest{
      Name: "CocaCola",
  })
  if err != nil {
      log.Fatal(err)
  }

  if res.Drink != nil {
      // handle response
  }
}
...
```

In addition to better method names and more human-readable classnames, the example value for the drink name parameter is much more relevant. This makes the generated SDK easier for end-users to consume and integrate into their applications.

The validation errors we’ve applied suggestions for are just a small sample of the improvements we can make to an OpenAPI spec. By including them in the prompt, we’ve enabled a feedback loop where even non-critical errors that don’t block SDK generation are encouraged to be added if addressing them improves the quality of the SDK output.

Let’s delve into how we receive these suggestions from the LLM in a format that allows us to apply them to the spec.

## Structured Output Parser

In our initial implementation of `Suggest`, we were only focused on reporting suggestions instead of applying them. Unfortunately, this requires a human in the loop to copy-paste the suggestions themselves. To avoid potential errors and automate the spec management, we needed to be involved in the process of applying the suggestions to our input document as well. This would enable us to revalidate the document upon each applied fix and ensure that overall document correctness was being improved.

Modifying an OpenAPI schema requires us to receive structured output from the LLM that we can apply to the document. We decided to use JSON patch for the format of the suggestion itself. Using [langchain-js](https://github.com/langchain-ai/langchainjs), this involved defining a custom agent with an output parser specifying the [zod](https://github.com/colinhacks/zod) schema we pass in to ensure we get LLM output in the right format.

````tsx
// zod schema
export const SUGGESTION_SCHEMA = z.object({
  suggested_fix: z.string().describe(
    `a simple English description of the suggested JSON patch.
      For example, the JSON patch [{"op": "replace", "path": "/paths/~1pet/post/operationId", "value": "addPet"}] could be described as "Replace the operationId of the POST /pet endpoint with addPet`
  ),
  json_patch: z.string().describe(`suggested fix in the form of a JSON Patch`),
  reasoning: z
    .string()
    .describe(
      "a brief explanation of why you think the suggested fix will resolve the error"
    ),
});

...

// output parser which verifies LLM's final response is formatted according to the zod schema
class JsonOutputParser<T> extends AgentActionOutputParser {
  lc_namespace = ["langchain", "agents", "custom_llm_agent"];
  schema: z.ZodType<T>;

  constructor(schema: z.ZodType<T>) {
    super();

    this.schema = schema;
  }

  async parse(text: string): Promise<AgentAction | AgentFinish> {
    console.log("\n" + text);

    const answerMatch = /```json(.*)```/gms.exec(text);
    if (answerMatch) {
      try {
        const json = JSON.parse(answerMatch[1].trim());

        // This will throw an error if the json does not match the schema.
        this.schema.parse(json);

        return {
          log: "Got answer",
          returnValues: json,
        };
      } catch (e) {
        console.log(
          "Answer is invalid JSON or does not match schema. Trying again..."
        );
        return {
          tool: "logger",
          toolInput: `Error: ${e}`,
          log: `Final answer is invalid. It does not conform to the requested output schema. Output schema: ${JSON.stringify(
            zodToJsonSchema(this.schema)
          )}`,
        };
      }
    }
    ...
  }
  ...
}
````

This ensured responses were in a form that was easy for us to extract the JSON patch from. However, we soon found that our agent would hallucinate invalid JSON patches that referenced keys that didn’t exist in the OpenAPI document. This required augmenting our agent with another tool to verify the validity of these patches by checking if we could apply them.

```tsx
export class JsonPatchValidator extends DynamicTool {
  static description = `Use this to verify that a given JSON patch is valid.
Always use this tool to check the validity of your final suggestion.
If your suggestion is invalid, use the error message to try to fix it.
Do not return anything this tool says is invalid as your answer.
This tool will return "valid" if the patch is valid, or an error message if it is not.

Example input to this tool:
  [{{ "op": "replace", "path": "/baz", "value": "boo" }}]

Example output: "valid", "error: path /baz does not exist"`;

  constructor(spec: JSON) {
    super({
      name: "json_patch_valid",
      func: async (input) => {
        input = removeQuotes(input);

        try {
          apply_patch(spec, input);
          return "valid";
        } catch (e: any) {
          return `error: ${e}`;
        }
      },
      description: JsonPatchValidator.description,
    });
  }
}
```

💡For a yaml spec, `Speakeasy Suggest` takes extra caution by converting it to JSON before applying the patch and converting it back to yaml while preserving the original key ordering.

We’ll discuss several of the tools we equipped our agent within the next section, where we detail the decision-making process of moving forward with a custom agent.

## Benchmarking Different Approaches

There were two main approaches we tested — _Custom Agent vs. Retrieval Augmented Generation (RAG)_. In order to not exceed GPT-4’s token limits, we provide a small range of lines surrounding the error from the spec to the LLM prompt. As a result, both approaches need to be capable of enabling the LLM to gather information from the full spec in order to return valid JSON patches. The primary differentiator is how this is achieved:

- An agent utilizes tools to enable the LLM to execute custom logic to traverse the spec
- In RAG, we use external data to augment our prompts. In our case, this involves the standard method of using a vector store to persist embeddings of the spec, which the LLM can quickly index when trying to answer the prompt.

### **Agent with Custom Tools**

Directly from the langchain docs: “In agents, a language model is used as a reasoning engine to determine which actions to take and in which order.” Each action an agent can take corresponds to one of the tools defined by us that executes a custom function. Since we’re using GPT-4 as our LLM, this takes advantage of [OpenAI’s function calling](https://openai.com/blog/function-calling-and-other-api-updates). Our tools take the OpenAPI spec as input and are capable of performing a range of operations on it.

**Searching for line numbers that contain a particular string**

The LLM may need to locate regions of the spec that are not in close proximity to the validation error but contain a specific key.

```bash
WARN validation warn: [line 63] oas3-unused-component - `#/components/schemas/Pets` is potentially unused or has been orphaned

Using model gpt-4-0613
Running agent...

The error message indicates that the schema 'Pets' is potentially unused or has been orphaned. This means that it is not referenced anywhere in the document. To confirm this, I will use the document_text_searcher tool to search for any references to 'Pets' in the document. If there are no references, the schema 'Pets' can be removed from the document. If there are references, they need to be replaced with the correct schema.
Action: document_text_searcher
Action Input: 'Pets'
```

From the LLM logs, we can see that the `document_text_searcher` tool searches the document for `Pets` to see if any usage of this component exists across the schema. The wonderful thing about agents is that the result of this action can be fed as input to other tools before returning a final answer (see `get_line_range` below).

**Retrieving specific line ranges**

This is helpful since our validation errors - and the output of other tools - report the offending line number. The LLM uses this to retrieve the region of the spec it needs more information from or where most fixes are likely to be applied.

Following the output of `document_text_searcher` above, the LLM receives appropriate line numbers to conclude its search and validate the final answer.

```bash
The 'Pets' schema is referenced on lines 5 and 99. Line 99 is the definition of the 'Pets' schema itself, so it doesn't count as a usage. I need to check line 5 to see how 'Pets' is used. I will use the get_line_range tool to retrieve lines 1-20 for context.
Action: get_line_range
Action Input: '1-20'

The 'Pets' schema is not used in lines 1-20. It seems that the 'Pets' schema is indeed unused. I will suggest a JSON patch to remove the 'Pets' schema from the document. I will also validate the JSON patch using the json_patch_valid tool.
Action: json_patch_valid
Action Input: [{"op": "remove", "path": "/components/schemas/Pets"}]

The JSON patch is valid. I will now provide the final answer.
Final Answer:
{
  "suggested_fix": "Remove the unused 'Pets' schema from the components.",
  "json_patch": "[{\"op\": \"remove\", \"path\": \"/components/schemas/Pets\"}]",
  "reasoning": "The 'Pets' schema is not referenced anywhere in the document, making it unused and can be safely removed."
}
```

**Resolving $ref definitions**

Many OpenAPI specs contain `$ref` keys that point to definitions living in different parts of the document. The LLM should be able to locate the original definition from this when it needs to use it to suggest a fix. This is useful when we want to suggest an example for a component in the OpenAPI spec.

```bash
INFO	validation hint: [line 104] missing-examples - Missing example for component. Consider adding an example

Using model gpt-4-0613
Running agent...

The error message indicates that there is a missing example for a component. Looking at the surrounding context, it seems that the error is on line 162, which corresponds to the "Pets" schema. This schema is an array of "Pet" objects. To fix this error, we need to add an example for the "Pets" schema. The example should be an array of "Pet" objects. We can use the "Pet" schema to create a valid example.

Action: ref_resolver
Action Input: #/components/schemas/Pet

The "Pet" schema requires an "id" and a "name", both of which are strings. An example "Pet" could be {"id": 1, "name": "Fido", "tag": "dog"}. We can use this to create an example for the "Pets" schema, which is an array of "Pet" objects. The JSON patch to add this example would be [{"op": "add", "path": "/components/schemas/Pets/example", "value": [{"id": 1, "name": "Fido", "tag": "dog"}]}]. Let's validate this patch.

Action: json_patch_valid
Action Input: [{"op": "add", "path": "/components/schemas/Pets/example", "value": [{"id": 1, "name": "Fido", "tag": "dog"}]}]

The JSON patch is valid. Therefore, we can suggest this patch as a fix for the error. The patch adds an example to the "Pets" schema, which is an array of "Pet" objects. The example is a valid "Pet" object, as it includes the required "id" and "name" properties.

Final Answer:
{
  "suggested_fix": "Add an example to the 'Pets' schema. The example should be an array of 'Pet' objects. An example 'Pet' object could be {'id': 1, 'name': 'Fido', 'tag': 'dog'}.",
  "json_patch": "[{\"op\": \"add\", \"path\": \"/components/schemas/Pets/example\", \"value\": [{\"id\": 1, \"name\": \"Fido\", \"tag\": \"dog\"}]}]",
  "reasoning": "The error message indicates that there is a missing example for a component. The 'Pets' schema is an array of 'Pet' objects, so the example should also be an array of 'Pet' objects. The 'Pet' schema requires an 'id' and a 'name', so the example 'Pet' object includes these properties."
}
```

By equipping the agent with the necessary toolkit to explore the spec JSON, we are able to traverse the document without exceeding the TPM (tokens per minute) limit. However, since each initial query to the agent can chain through a sequence of actions before returning a final answer, we wanted to assess another approach that would limit the number of OpenAI calls.

**Retrieval Augmented Generation (OpenAPI Spec Embeddings in Chroma)**

We use embeddings to store the spec for quick similarity searches without requiring the full contents to be passed into the prompt, enabling us to respect the token limit. Specifically, we used [RetrievalQAChain](https://js.langchain.com/docs/modules/chains/popular/vector_db_qa) with the OpenAPI spec embedded in [Chroma](https://github.com/chroma-core/chroma).

**Results**

We compared the execution time, number of OpenAI calls, and the accuracy of both approaches above. Although RAG seemed to perform fine on **\***most**\*** simple errors, complex tasks such as moving duplicate inline schemas to shared components seemed impossible. At first, the returned JSON patch for such a task seems reasonable.

```bash
INFO {"error":"validation hint: [line 22] duplicate-schemas - Identical inline object schemas found: [line 22] - [line 31] conflicts with [line 107] - [line 116]. Consider moving to a shared component"}

Asking for a Suggestion!

[{"op": "add", "path": "/components/schemas/Error", "value": {"type": "object", "required": ["code", "message"], "properties": {"code": {"type": "integer", "format": "int32"}, "message": {"type": "string"}}}}, {"op": "replace", "path": "/paths/~1pets/get/parameters/0/schema", "value": {"$ref": "#/components/schemas/Error"}}, {"op": "replace", "path": "/components/schemas/Error", "value": {"$ref": "#/components/schemas/Error"}}]
```

But upon further review, we found it added the shared component and then swapped out its own schema definition with the `$ref`, thinking it was one of the duplicate schemas itself despite having a clear line number to check against. Since RAG can’t gather more context via function calls, it would use a similarity search to suggest fixes for same-name fields on the wrong lines. Due to this behavior, this approach wasn’t sufficient for returning JSON patches with the correct paths.

The agent fared much better on all validation errors ranging across a broad span of complexity. Despite the fact that it took 2-3x as long to execute, the agent’s ability to “reason” through a sequence of actions via the execution of custom functions proved to be critical for good suggestion quality. The ability to equip the agent with any new tool we could think of makes it more flexible and future-proof for our use-case than embedding the OpenAPI schema. This is the most important factor in ensuring `Suggest` is a useful product, as OpenAPI specs vary greatly in shape, purpose, and functionality, much like the tools and people who produce them.

### Conclusion

Even after settling on the agent approach, suggestion quality, rate limits, and execution time were all variables that still needed to be addressed. Our team has been tackling these roadblocks by implementing parallelization, passing in additional guidance to the prompt for specific validation errors, and benchmarking various LLMs post fine-tuning.

Want to try it for yourself? Head over to the [Speakeasy Suggest docs](/post/release-speakeasy-suggest), or just copy paste [this workflow file](https://github.com/speakeasy-sdks/template-sdk/blob/main/.github/workflows/speakeasy_spec_suggestions.yml) into your own github repo to get started!


 This is the content for the doc blog/release-terraform-v2/index.md 

 ---
title: "Release: Terraform v2"
description: "Updated Terraform generation that handles increasingly complex APIs."
image: "/media/release-terraform-generation-v2.png"
date: 2024-02-27
authors:
  - name: Thomas Rooney
  - image_url: '/media/author-headshots/thomas.jpeg'
tags:
  - Product Updates
featured_image: "/media/release-terraform-generation-v2.png"
---

Offering a Terraform provider for your API is one of the best ways to unlock new use cases and new revenue. Since we rolled out our provider generation, we’ve been making steady improvements behind the scenes, like migrating to the terraform-plugin-framework from terraform-plugin-sdk/v2.  That’s meant continuity for our users without any action needed from their teams. But now we’re excited to share some new capabilities that expand the product offering.

The next version of our OpenAPI-based Terraform Provider generation is now available to all users. Our new generation is able to handle increasingly complex API patterns and produce the corresponding Terraform resources as expected.

So what’s now possible?

- Collapse multiple API endpoints into a single Terraform Entity.
- Adding Custom Plan Validators to your Provider
- Runtime Validations
- Support for Default and Const Attributes
- Handling Batch Endpoints

To get started, all you need is an OpenAPI spec. Simply install the speakeasy CLI, annotate your spec and start generating:

```bash
brew install speakeasy-api/homebrew-tap/speakeasy
```

```bash
speakeasy quickstart
```

## New Features

### Multi-endpoint Resources

As APIs age and grow, they inevitably develop some rough edges. A common situation is one where a user needs to interface with multiple endpoints to configure a single business resource. Imagine a case where a user makes a call to create a transaction, then a second call to tag the transaction. It’s not a big problem, but the ideal devex would be a single API call that creates a transaction, including tagging data.

With our new support for multi-endpoint resources, it’s now possible to collapse two calls into a single entity definition in your Terraform Provider. This frees your users from needing to manage complex entities that span multiple API calls for their lifecycle operations.

All you need to do is add `x-speakeasy-entity-operation` annotations to the API endpoints you want to collapse:

```yaml
/drinks:
  post:
    x-speakeasy-entity-operation: Drink#create
    requestBody:
      required: true
      content:
        application/json:
        schema:
          x-speakeasy-entity: Drink
          type: object
          properties:
            name:
              description: The name of the drink.
              type: string
            type:
              description: The type of drink.
              type: string
              enum:
              - cocktail
              - non-alcoholic
              - beer
              - wine
            price:
              description: The price of one unit of the drink in US cents.
              type: number
      responses:
        "200":
          content:
          application/json:
            schema:
            type: object
            properties:
              data:
                type: object
                x-speakeasy-entity: Drink
                properties:
                    ...
  /drink/{id}/visibility:
    post:
      x-speakeasy-entity-operation: Drink#create#2
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              x-speakeasy-entity: Drink
              properties:
                visibility:
                  type: string
                  enum:
                    - above-bar
                    - below-bar
      responses:
```

The resulting Terraform entity will look like:

```go
func (r *DrinkResource) Schema(ctx context.Context, req resource.SchemaRequest, resp *resource.SchemaResponse) {
  resp.Schema = schema.Schema{
    MarkdownDescription: "Drink Resource",

    Attributes: map[string]schema.Attribute{
      "type": schema.StringAttribute{
        Optional:    true,
        Computed:    true
        Description: `The type of drink.`,
        stringvalidator.OneOf(
          "cocktail",
          "non-alcoholic",
          "beer",
          "wine",
        ),
      },
      "name": schema.StringAttribute{
        Required:    true,
        Description: `The name of the drink.`,
      },
      "price": schema.Int64Attribute{
        Required:    true,
        Description: `The price of one unit of the drink in US cents.`,
      },
      "type": schema.StringAttribute{
        Optional:    true,
        Computed:    true
        Description: `The visibility of drink.`,
        stringvalidator.OneOf(
          "above-bar",
          "below-bar",
        ),
      },
    },
  }
}
```

And we'd syncronously invoke the first API request followed by the second API request during the `Drink` resource `Create` step. Any attributes that the first API call returns will be available to the following API call, and all of the data returned by both API calls will be made available to terraform state.

There's no limit on the amount of chaining that you can do. For instance, an `x-speakeasy-entity-operation: MYEntity#Read#1..N` could invoke many API calls and merge all of the responses together into a gigantic data source to simplify user interactions with your resources.

### Custom Plan Validators

Plan validators are additional validation checks that are applied to your user’s Terraform execution plan before any changes are applied to the infrastructure. By default, we provide basic validation based on your OpenAPI spec, for example checking that `min` and `max` limits are being respected. But we now also provide the ability for you to define your own custom validators which will enforce specific pieces of business logic for your users.

Just annotate the schema in your OpenAPI spec with `x-speakeasy-plan-validators: MyValidator`, and we'll create a `internal/validators/stringvalidators/sell_by_validator.go` file that's bootstrapped to be compliant with what the `terraform-plugin-framework` expects, and ready for your logic to be written. You can re-use the validator by applying it to any other JSON Schema type with the same underlying `type`. See our [full implementation notes here](/docs/terraform/extensions#the-x-speakeasy-plan-validators-extension).

```yaml
components:
  schemas:
    Drink:
      type: object
      x-speakeasy-entity: Drink
      properties:
        name:
          type: string
        sell-by:
          type: string
          format: date-time
          x-speakeasy-plan-validators: SellByValidator
```

### Default Parameter/Request Body Support

There is now support for `default` across parameters and request body attributes. If your OpenAPI spec defines a default value for a parameter, we will now propagate that into the Terraform entity:

```yaml
- in: query
  name: deprecated
  schema:
    type: boolean
    default: false
  description: Indicates if the product is deprecated
```

```go
"deprecated": schema.BoolAttribute{
  Computed:    true,
  Optional:    true,
  Default:     booldefault.StaticBool(false),
  Description: `Indicates if the product is deprecated. Default: false`,
},
```

### Const Request Body Support

There is now support for `const` across request body attributes. If your OpenAPI spec defines a const value for any request attribute, we will now hide that value from the Terraform Entity and propagate it over the wire to your API. This can allow for an optimized terraform interface, especially for discriminators of `oneOf` types:

```yaml
oneOf:
  - type: object
    properties:
      sourceType:
        type: string
        const: "SourceType 1"
      ...
  - type: object
    properties:
      sourceType:
        type: string
        const: "SourceType 2"
      ...
```

### Array Batch Method Support

Terraform doesn’t support traditional parallelism: all interactions most be with a single resource. However if your API only has batch create & batch update endpoints, our generation target can support using these too!

Our provider will create API calls with single element arrays request/response values to interact with the single resource operations, but flatten these into a terraform schema that’s consistent with user expectations.


 This is the content for the doc blog/release-webhooks-support/index.mdx 

 ---
title: "Speakeasy SDK generation now supports webhooks"
description: "Generate typed webhook handlers and security verification with native OpenAPI support"
image: "/media/release-webhook-handlers.png"
date: 2024-12-03
authors:
  - name: David Adler
  - image_url: "/media/author-headshots/david.jpg"
tags:
  - Product Updates
featured_image: "/media/release-webhook-handlers.png"
is_featured: true
---

We're excited to announce that Speakeasy SDK generation now supports webhooks. This new feature makes it dramatically easier for both API producers and consumers to work with webhooks by providing type-safe handlers and built-in security verification, all powered by OpenAPI-native features.

## The webhook integration challenge

If you maintain an API platform, you almost certainly have webhooks. But implementing webhook support has always been more complex than it needs to be, with challenges on both sides of the integration:

For API consumers, integrating webhooks typically involves:

- Implementing complex security verification from scratch
- Manual type construction and validation
- Handling undefined or unexpected payloads
- Managing authentication secrets
- Building resilient processing infrastructure

For API producers:

- Writing extensive documentation for webhook security
- Maintaining separate authentication systems
- Ensuring correct payload construction
- Managing webhook delivery and retries
- Supporting customers through integration challenges

The result? Developers spend more time wrestling to integrate with the webhook system than building product on top of it.

## Better webhooks for producers & consumers

Our new webhook support simplifies this entire process by generating typed webhook handlers with built-in security verification. Here's what that looks like in practice.

### Consumer Support 

```typescript
const res = await sdk.validateWebhook({ request, secret });

if (res.error) {
  throw res.error; // Failed auth or unknown payload
}

const data = res.data;

if (data.type === 'company.created') {
  return myHandleCompanyCreated(data);
}

if (data.type === 'company.deleted') {
  return myHandleCompanyDeleted(data);
}

if (data.type === 'connection.created') {
  return myHandleConnection(data);
}

throw new Error(`Unhandled webhook payload: ${res.inferredType}`);
```

No more implementing HMAC SHA-256 verification from scratch. No more debugging undefined properties in production. Just install the SDK and start processing webhooks with confidence.

### Producer Support

Generate convenience methods for producers to correctly construct and sign webhook payloads.

```typescript sendPayment.ts
const finotech = new Finotech();

const result = await finotech.webhooks.sendCompanyCreated({
	recipient: {
	  url: "https://bank.com/finotech-webhooks",
	  secret: "secret-key"
	},
	{ id: "foo", name: "Foo Inc" }
});
```

### Key Features

**Type-Safe**: All webhook payloads are fully typed, letting you catch integration issues at compile time rather than production.

**Built-in Security**: Support for industry-standard webhook security including HMAC SHA-256 signing, with more verification methods coming soon.

**OpenAPI Native**: Webhooks are defined right in your OpenAPI spec, ensuring your SDK, docs, and webhook interfaces stay in sync as your API evolves.

## Getting Started

The magic happens through OpenAPI's native webhook support. Simply add add our custom extension to configure your webhook security and your SDK will generate the rest:

```yaml openapi.yaml
# !focus(4:25)
openapi: 3.1.1
paths:
  ...
x-speakeasy-webhooks:
  security:
    type: signature # a preset which signs the request body with HMAC
    name: x-signature # the name of the header
    encoding: base64 # encoding of the signature in the header
    algorithm: hmac-sha256
webhooks:
  user.created:
    post:
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              properties:
                id:
                  type: string
              required:
                - id
      responses:
        '200':
          description: Okay
```

The SDK will sign the request body. More complex signing schemes are also supported. Get in touch to find out how to support your signing scheme.

## Webhooks maturity

Webhook support is available today in TypeScript, with support for additional languages rolling out soon. We've also got some exciting features on our roadmap:

- Asymmetric signature verification
- Key rotation support
- Custom signing scheme support
- Infrastructure for reliable webhook delivery and processing

For existing Speakeasy Enterprise customers, define `webhooks` in your OpenAPI spec and we'll automatically include webhook generation in your next action run. For new customers, you can start generating webhook-enabled SDKs today by [signing up](https://app.speakeasy.com/).

Join the growing number of companies using Speakeasy to deliver exceptional API experiences, now with first-class webhook support!


 This is the content for the doc blog/rise-of-developer-infrastructure/index.mdx 

 ---
title: "The Rise of Developer Infrastructure"
description: "Good developer infrastructure is the secret weapon for sustained innovation in software development. Don't let your competition get ahead."
image: "/media/rise-of-developer-infrastructure.png"
date: 2022-05-18
authors:
  - name: Sagar Batchu
  - image_url: 'https://uploads-ssl.webflow.com/62ccd7b208cab0723d026273/62cdf303b28bf9598d7a6b63_sagar_headshot-p-500.jpeg'
tags:
  
featured_image: "/media/rise-of-developer-infrastructure.png"
---

We have a theory about what’s going on with developer infrastructure:

- The most successful engineering organizations in the industry have invested heavily in internal developer infrastructure, which has given them a differentiated advantage when it comes to constant innovation and speed of shipping products.
- The next 10 years will see the majority of developers shifting from using cloud infrastructure to using developer infrastructure
- Composable, Extensible and Usable: these will be the guiding principles for great developer experience.

## What is Dev Infrastructure

Dev infrastructure can be a bit of a fuzzy gray area, but we define it as the tooling which forms the connective tissue between your application code and your cloud primitives. Your cloud provider defines the limit of what’s computationally possible, your application code determines the particular what you’re focused on, and your developer infrastructure determines how quickly you're able to get your application code running in production and how well you can maintain it atop primitives from your cloud provider.

When it comes to sustained innovation in software development, **good** **developer infrastructure** is the secret weapon that gives the best companies a head start on their competition. It’s not often talked about because it’s often not the shiny apps your customers use, but it is critically important to velocity and quality. Developer infrastructure is a lot like public infrastructure: when it’s working well you forget it’s there, but when it’s not working, you’ve got yourself a major problem.

import portal_url_1 from './assets/rise-of-developer-infrastructure-image-01.mp4'

  <video controls={false} loop={true} autoPlay={true} muted={true} width="100%" alt="Train falling down in a river">
    <source src={portal_url_1} type="video/mp4" />
  </video>

when it’s not working, you’ve got yourself a major problem

Over the last 10 years, developers at smaller companies have struggled to balance developing innovative apps while also managing the complexity of the cloud. Meanwhile, companies like Uber, Airbnb, Stripe, Netflix et al. have been able to invest heavily to build up in-house platform teams, which supports the continued productivity of their application developers. Some of the developer infrastructure those teams created were shared publicly. Two well knowns that I’ve personally adopted in high scale settings are:

- [**Kubernetes**](https://kubernetes.io/) - The now ubiquitous container deployment and orchestration system was born from Google’s famous internal [**Borg**](https://kubernetes.io/blog/2015/04/borg-predecessor-to-kubernetes/) system which provided abstractions for resource allocation. For most (stateless) use cases devs were able to “submit” a container and let K8’s handle how it got running on VMs. Needless to say there is now a massive ecosystem in continuous evolution around K8s.  
- [**Spinnaker**](https://spinnaker.io/) - There were plenty of ways to build and deploy containers independently but they all required you to manage your own workflow. This meant brittle scripts, triggers, sometimes complete bespoke stacks maintained by internal teams. Spinnaker solved this with an orchestration first approach - a developer could string together many different steps which could live across team and system boundaries. Since then we’ve seen an [**explosion in this space**](https://landscape.cd.foundation/).

Each of these was enthusiastically adopted by the developer community. At the time of their release, they each represented massive improvements over the status quo.  

Yet, this wasn’t the end of the story. There were some issues. First off, it wasn’t sustainable for devs to continue to rely on larger companies sporadically open sourcing their tools. Increasingly ambitious business growth targets meant that devs needed consistent innovation of tooling to enable them to build more, faster. And more importantly, the tools had been developed by large organizations with huge dedicated platform functions; they weren’t optimized for application developers operating at a smaller scale without robust dev ops support. Simply stated, though the tools were powerful, they lacked a great dev experience. App devs were still having to go down the dev ops rabbit hole, spending far too much time trying to figure how to secure, deploy, and maintain their applications.

![BD about dev ops](./assets/rise-of-developer-infrastructure-image-02.png)

## Who Will Build the Future of Dev Infra

The way developers interact with the cloud is undergoing a profound shift, Erik Bernhardsson described it well in one of his recent blog posts, “[**Storm brewing in the stratosphere**](https://erikbern.com/2021/11/30/storm-in-the-stratosphere-how-the-cloud-will-be-reshuffled.html)”. The last 10 years were the initial phase of the cloud movement - shifting your compute and storage from your own server racks to those maintained by a commoditized public cloud. Now we are in the early days of the second phase - the abstraction of the cloud in order to undo the productivity loss caused by dev ops being splattered across the stack. We are pushing towards a future where every App and API dev will launch their product by focusing on the application primitives while maintaining the benefits of public cloud elasticity.

That’s why we’re beginning to see the paradigm start to shift. As the cloud has matured, we are now beginning to see the development of dev infra atop the underlying cloud primitives. Some of the biggest drivers for this shift are:

- **The desire for great UX**: Developers now expect their tools to not only be powerful, but also to be usable. A great UX means more personas in the org can insert themselves into the development loop, increasing leverage for the devs. A great dev tool is not only great UX but also great dev ex, as we explore below.
- **The focus on differentiation**: Developer time has never been in higher demand. Businesses need to focus the efforts of their developers on solving the problems that differentiate their business. Everything non-mission critical, wherever possible, should be handled by a 3rd party. Tools that take unnecessary tasks out of development and deployment are invaluable.
- **The dev infra gold rush**: The market is awash in solutions as startups armed with VC cash have rushed in to fill the need for cloud products with dev experience as the primary differentiator. For a dev looking to plug a gap in their development lifecycle or offload non-core work with 3rd party tooling, there have never been more options.
- **Multi-Cloud**: As organizations begin to consider the implications of cloud lock in, it becomes critical that their dev tooling remains consistent across platforms. Optimizing an application for multiple clouds is a vastly inefficient use of developer time. Dev infra developed by cloud vendors is typically limited to just their cloud and vertically integrated.

Cloud platforms rooted in developer productivity have seen rapid growth in the last few years. One of my favorite dev ex innovations recently is PlanetScale’s [**Revert**](https://planetscale.com/features/revert) feature. A mention of database migrations can invoke anxiety in the most battle-hardened devs. Commit a stateless SQL file to manage a production database? No thank you! Another noteworthy mention is [**Cloudflare open sourcing their Workers runtime**](https://blog.cloudflare.com/workers-open-source-announcement/) - Devs can now deploy fullstack apps serverless-ly on the edge with just a click and with full transparency, amazing ! As this trend continues, the leverage of each developer will soar. For the majority of teams, dev ops will be a distant memory. We’re approaching the inflection point.

## What Makes Great Dev Infrastructure

Companies like PlanetScale and Cloudflare are at the tip of the iceberg. The community of independent dev tool companies has really begun to blossom in the last few years. The cloud providers commoditized access to secure, reliable, scalable server capacity, This, in turn has provided the foundation required for dev infra companies 100% focused on building tools with a great dev experience to be viable.

As to what constitutes a great developer experience, it’s still early days so there aren’t many resources. However, when we’re building our tools, we grade our work against our developer experience pyramid:

![Developer experience pyramid](./assets/rise-of-developer-infrastructure-image-03.png)

The Dev Ex Pyramid

**Dev Infrastructure**:

- **Usable** - An individual dev or team should be able to find the tool, set it up, and start using it without barriers or issues in 30 minutes.
- **Composable** - The tool should be modular enough for developers to slot it into their (probably complex) environments. Support for multiple frameworks and integrations is key to adoption.  
- **Extensible** - Although most developers will only ever scratch the surface of a tool’s functionality, every tool will have its power users. Power users should be able to add functionality to the tool, for advanced use cases.

**Cloud Infrastructure (**These are table stakes!)

- **Scalable -** Able to elastically scale compute to the needs of the application.
- **Reliable -** This one is pretty easy. If a tool doesn’t have 99.99% reliability, then people won’t use it. If you are building infrastructure, you have to be dependable.
- **Secure -** You cannot jeopardize your client’s security. Your tools must be water tight. For us this means running within our client’s cloud environment and minimizing any external network communication.

We constructed this pyramid based on our experience working on enterprise software, and the things we valued in the tools we used. We would love to hear from other developers to see if this is in line with what they think is important. Are there things we’ve missed? We’d love to know.

The future of dev infra is bright, and we look forward to making our contribution. [**For any devs who want to pitch in and help us build great infra for the developer community, please check out the job board. We would love to hear from you!**](https://jobs.lever.co/speakeasyapi/)


 This is the content for the doc blog/rss.xml.mdx 

 import { getServerSideProps as getRssServerSideProps } from "~/features/blog/rss";


export const getServerSideProps = getRssServerSideProps;


 This is the content for the doc blog/sass-vs-css-modules-vs-css-in-js/index.mdx 

 ---
title: "SASS vs CSS Modules vs CSS-in-JS: How to Choose?"
description: "Struggling to decide between Sass & CSS-in-JS for your UI? Here's why we chose CSS-in-JS for effortless embedding & theming of UI components – critical."
keywords: [css, sass, css modules, css in js, js]
image: "/media/sass-vs-css-modules-vs-css-in-js.png"
date: 2022-07-14
authors:
  - name: Nolan Sullivan
  - image_url: 'https://uploads-ssl.webflow.com/62ccd7b208cab0723d026273/62cdf9e45dcbb4d20be59f5f_head.jpeg'
tags:
  - Building Speakeasy
featured_image: "/media/sass-vs-css-modules-vs-css-in-js.png"
---

We are in the midst of building the first version of our API Ops platform. One of the components which we are actively building is a developer console where devs can get an overview of their APIs and each endpoint’s performance. While building our UI, we are debating many of the fundamental front end architecture decisions that will shape our UI development. One of the biggest debates thus far was whether we would use SASS or CSS-In-JS for our styling.

We know developers are facing these same questions every day, so we want to publish our thoughts in case they are useful to anyone else. Ultimately, we chose to move forward with CSS-In-JS as our primary styling mechanism for reasons specific to our business; we considered it important for the UIs we build to be easily embeddable within external UIs. We felt that CSS-In-JS was the best option for embeds, because integrators wouldn’t need to worry about dealing with style injection, and could theme our components into their style.

We’d love to know your thoughts and how you reached decisions about styling your UI? Have you had any bad experiences with CSS-In-JS?

Below is our full internal conversation only minimillaly edited for brevity:

![Internal conversation about CSS-in-JS part 1](./assets/sass-vs-css-modules-vs-css-in-js-image-01.png)

![Internal conversation about CSS-in-JS part 2](./assets/sass-vs-css-modules-vs-css-in-js-image-02.png)

![Internal conversation about CSS-in-JS part 3](./assets/sass-vs-css-modules-vs-css-in-js-image-03.png)

![Internal conversation about CSS-in-JS part 4](./assets/sass-vs-css-modules-vs-css-in-js-image-04.png)

![Internal conversation about CSS-in-JS part 5](./assets/sass-vs-css-modules-vs-css-in-js-image-05.png)

If you’re interested in learning more about [what we're building](https://www.speakeasy.com/), please reach out!

—

Transcript of Convo for accessibility purposes :)

**Fullstack dev 1** \>

@UX Designer and I were just talking about the UI and I think it might be time to move away from some of the MaterialUI components to make it a little easier to get things looking as he's designed. I'd like to move most of the styling into sass. Anyone have thoughts on that?

**dev** \>

what is sass ? Is that another library ?

**Fullstack dev 1** \>

it's a "language" that transpiles to css:

[https://sass-lang.com/](https://sass-lang.com/)

**UX Designer** \>

yes, like a css framework that allows smart functionality over and above vanilla css

**Fullstack dev 1** \>

it makes it a little easier to have a consistent theme

**Tech Lead** \>

interesting - is this any different than using tailwind and related libraries ?

**Tech Lead** \>

another question i’ll ask is if we move away from MUI will we need to build our own modals, drawers etc ? I would be wary of introducing a lot of work around maintaining our own design system without being able to leverage tablestakes libraries under the hood (edited)

**UX Designer** \>

Could we use MUI partially, for the core components we don't need to redesign (like modals)

**Fullstack dev 1** \>

I think tailwind is sort of like bootstrap

**Fullstack dev 1** \>

[@](https://speakeasyapi.slack.com/team/U03MPFYRQ6M)UX Designer yeah, I was definitely going to start with the components that don't have a great MUI analog (or at least that don't style as well)

**UX Designer** \>

but then do some custom like for buttons and other more visual/branding components

**Fullstack dev 1** \>

right

**Tech Lead** \>

Having our consistent branding and style is important so our users feel they’re using a polished product but i would strongly reconsider spending any time on creating custom components for undifferentiated features (buttons, modals etc) and use that sparingly for differentiated features (request viewers, test automation components etc)

**Fullstack dev 2** \>

IMO Material UI / SASS are totally interoperable. Material UI is good in that it's a sensible set of defaults, but for anything designed it can be just ignored, or themed to match. Similarly if the styling is via SASS via \[styled-components, MUI/Emotion, tailwind classes\] it doesn't matter too much: it's just CSS at the end of the day.

I have biases against globally-running CSS rules, because it's slightly harder to maintain (as they start to overwrite each other): but that just depends on how SASS is compiled/injected into the components.

On a more general level, I personally have biases towards adjusting design to fit a standard component library rather than be more custom in each view. E.g. I'd rather we style MaterialUI, rather than do our own custom CSS, just because it's faster and easier to mutate in future.

**Fullstack dev 1** \>

ok

**Tech Lead** \>

i think the idea of using SASS is a good one but i think we should probably revisit the option every few weeks. Still feels premature to maintain our own components until we find a novel ux interaction that standard components don’t support

**UX Designer** \>

ok so the implications of this is that some of the styling in the UI may not reflect identically what we see in the live UI, but it will be minimal and inconsequential

**UX Designer** \>

As long as branding colors and fonts are custom (which they are in MUI), we should be largely ok

**Tech Lead** \>

Sounds good, thanks raising this Fullstack dev 1 and UX designer. Lets pushing MUI as long as possible here to reduce our maintenance burden.

**Tech Lead** \>

@**Fullstack dev 1,** @**Fullstack dev 2** I was thinking about this from another angle - it seems like if we have a Master CSS style sheet there is some value in using SASS right now (mostly from a developer  productivity point of view). If we use styled components i see that value going down.

The other thing to think about is we do have downstream in the product roadmap the need to inject parts of our developer dashboard (as iframe or embeds) into company’s own dashboards. It seems like going the way of styled components would keep the door open for that. Curious to hear you thoughts

**Fullstack dev 2** \>

IMO:

1. If we leave CSS-In-JS and go down the route of a Global CSS style sheet (e.g. via SASS), I’m not convinced we gain any short-term developer productivity benefit. The only time I’d personally recommend this nowadays is when we have CSS-only developers, who do not want to touch JS. My experience is that this gain still would often lose to other complexities better-handled in a CSS-In-JS approach in the medium-term \[0\] \[1\].

2. If we go down any of the CSS-In-JS routes (e.g. styled-components, mui/emotion), we will be easier to embed, as the developer embedding us will not need to think about style injection. Currently we use emotion (as MUI wraps it): [https://emotion.sh/docs/introduction](https://emotion.sh/docs/introduction) . Emotion is essentially a more modern version of styled-components: it provides a superset of features, and is a bit faster \[2\].

3. If we continue down a MUI-theme route, we become easier to re-style in one place. E.g. we could more easily be styled in customer colours. Similarly implementing dark mode is trivial, if we want that.

\[0\] I personally have a little Trauma from giant ball-of-mud global CSS stylesheets implementations. In a couple 2-year length projects we went down this route, but gradually spent more-and-more time hunting down bugs caused by CSS overriding each other all over the app. In each project, there were several “CSS refactor” mega-epics to try to trim the mud into something sensible. They always failed, and were very time-expensive. I don’t think this is the suggestion, but wanted to state my opinion and validate consensus that we should rule this out.

\[1\] An alternative that is closer to CSS is CSS Modules (which can be powered via SASS). I’ve also used this on one major project. I had no negative experience, but features which required dynamically adjusting theme (e.g. implementing dark mode) were expensive to implement, and so we never bothered. For a devtools project I think theme adjustment (either by adding dark mode, or by allowing a customer to theme us on an embed) is probably important. Hence would rather go with a pure CSS-In-JS solution.

\[2\] Of the CSS-In-JS libraries, I just picked emotion as it’s IMO the most modern of them, and it’s also the MUI default. The API to all of them is effectively the same. No strong opinions here. (edited)


 This is the content for the doc blog/sdk-best-practices/index.mdx 

 ---
title: "SDK Best Practices"
description: "Best practices to apply when designing SDKs for your API."
keywords: [api, developer experience, devex, dx, sdk, openapi]
image: "/media/sdk-best-practices.png"
date: 2024-03-21
authors:
  - name: Sagar Batchu
  - image_url: 'https://uploads-ssl.webflow.com/62ccd7b208cab0723d026273/62cdf303b28bf9598d7a6b63_sagar_headshot-p-500.jpeg'
tags:
  - API Advice
featured_image: "/media/sdk-best-practices.png"
---

import { Callout } from '~/components'

## From API-First to SDK-First

One of the most significant trends in tech over the past ten years has been the proliferation and success of API-as-a-product companies (e.g. Twilio, Algolia, etc).

But the term API-as-a-product, obscures one of the most critical ingredients in these companies’ success. The secret that the most successful API companies have been hiding in plain sight, is that their APIs are not the actual interface beloved by users. It is their SDKs which are at the heart of the best-in-class developer experience these companies offer.  If you want to delight developers, don’t try to just be API-first, focus on becoming SDK-first.

So why doesn’t every API company offer SDKs to their users? Up until now, it’s been really hard to sustainably build great SDKs. If you look at a list of [the most popular APIs](https://www.postman.com/explore/most-popular-apis-this-year), you’ll find that even some of the biggest API companies have failed to build out robust SDK programs. Many offer patchy or incomplete support.

Change is coming though. Speakeasy is committed to giving every company access to an API experience platform on par with what the best API companies provide. A major component of that platform is a workflow to easily and sustainably build SDKs for all your REST APIs.

In this piece, we’ll discuss why SDKs are important, what qualities make a great SDK, and how to overcome the common problems that typically plague SDK development and maintenance.

## Why Are SDKs Important?

SDKs provide numerous unique benefits to your end-users’ developer experience, and to your team too:

- **Reduce your team’s support burden**: By enabling type definitions in the IDE, SDKs reduce the likelihood of user error during user integration. That in turn means less support tickets for your team to manage.
- **Improve product discoverability**: SDKs put your product in the place where developers are most likely to look for solutions. Client libraries on Github and in popular package managers will help your product develop social proof as users encounter you in familiar environments.
- **Increase revenue with a larger addressable market**: Every SDK you offer makes it easier to appeal to a new community of developers. That means an increase in users, and ultimately, more revenue.

Of course, releasing a badly-written SDK could do more harm than good. Let’s dive into what it means to build a great SDK.
<br />

![Dank meme showing how SDKs improve your API](./assets/sdk-meme.png)
<br />

## Best Practices for a Great SDK

We’ve talked to hundreds of developers on this topic. While there is always a bit of personal preference, these are the things that every developer wants to see in an SDK:

### 1. Type Safe

Type safety might be the most important aspect of SDK creation. By making your API’s inputs and outputs explicit, the developers integrating the API into their application can better understand how the API is intended to be used — and massively reduce the amount of incorrect requests being made to your API. Type safety will help developers debug in their IDE as they write the application code, and spare them the frustration of having to comb through the constructed data object to see where/ mistakes occurred.

The more that you can include in your type definition, the more feedback developers will have when they are building with your SDK. The below example shows how Speakeasy uses Zod Schemas to define the input and output types for a product object in TypeScript. This allows developers to validate the input and output of the API at runtime, and provides a clear contract for how the API should be used:

```ts title="product.ts"
export namespace ProductInput$ {
    export type Inbound = {
        name: string;
        price: number;
    };

    export const inboundSchema: z.ZodType<ProductInput, z.ZodTypeDef, Inbound> = z
        .object({
            name: z.string(),
            price: z.number().int(),
        })
        .transform((v) => {
            return {
                name: v.name,
                price: v.price,
            };
        });

    export type Outbound = {
        name: string;
        price: number;
    };

    export const outboundSchema: z.ZodType<Outbound, z.ZodTypeDef, ProductInput> = z
        .object({
            name: z.string(),
            price: z.number().int(),
        })
        .transform((v) => {
            return {
                name: v.name,
                price: v.price,
            };
        });
}
```

### 2. Abstracted

SDKs spare your users from having to worry about the minutiae of how your API works. You can abstract away details like:

- **Networking code**: SDKs can handle the details of making network requests to an API. This allows developers to focus on the functionality they want to implement, rather than the details of how to communicate with the API.
- **Request and response formatting**: SDKs can handle the details of formatting requests and parsing responses in a format that is specific to the API
- **Error handling**: SDKs can interpret the details of errors that occur when using an API, allowing developers to focus on their application logic rather than error handling.

### 3. Human Readable

This one is pretty self-explanatory. AI hasn’t made developers obsolete yet, so there is going to be another person on the other side of your SDK code. When code is well-organized, well-commented and easy to read, developers are more likely to be able to understand how the SDK works and how to use it correctly.

### 4. Limited Dependencies

Codebases are jungles, and SDKs are another component of this complex ecosystem. When an SDK has a large number of dependencies, it can be more difficult to use the SDK with other libraries and frameworks. If a developer has to try and resolve incompatible dependencies before they can use your SDK, there is a high risk they will abandon the API integration altogether.

Limiting the number of external dependencies in your SDK is therefore critical to ensure compatibility.

### 5. Enterprise Features

We think that features like retries, pagination, and security helpers should come in every SDK. These aren’t things that are strictly required at the earliest stages of an integration, but as soon as users want to use your API for production use cases, this matters — and their absence can slow down integrations significantly. It’s just another case where a user doesn’t want to have to think about how to do this well — and may not have enough product context do to so optimally.

The API creator is in a much better position to set sensible defaults here. 

```tsx
x-speakeasy-retries:
  strategy: backoff
  backoff:
    initialInterval: 500        # 500 milliseconds
    maxInterval: 60000          # 60 seconds
    maxElapsedTime: 3600000     # 5 minutes
    exponent: 1.5
  statusCodes:
    - 5XX
```

### Language Idiomatic

This is a meaty topic, and it’s hard to discuss in generalities (it’s different for every language), so let’s walk through an example of the type of design choices that a developer might expect of a Go SDK:

- **Minimal dependencies** and relying on the Go standard library as much as possible.
- **Struct tags and reflection based (de)serializers** to define how the types we generate are correctly serialized based on the OpenAPI document.
- **Pointers for optional objects** including fields/parameters/response and request bodies to ensure that the user can differentiate between a field not being set and a field being set to a zero value.
- **A Utils package** that improves readability by bundling the methods for configuring the SDK and serializing/deserializing the types we generate into a shared package, avoiding the need to duplicate in each method.

```go
package shared

type PetStatusEnum string

const (
    PetStatusEnumAvailable PetStatusEnum = "available"
    PetStatusEnumPending   PetStatusEnum = "pending"
    PetStatusEnumSold      PetStatusEnum = "sold"
)

type Pet struct {
    Category  *Category      `json:"category,omitempty"`
    ID        *int64         `json:"id,omitempty"`
    Name      string         `json:"name"`
    PhotoUrls []string       `json:"photoUrls"`
    Status    *PetStatusEnum `json:"status,omitempty"`
    Tags      []Tag          `json:"tags,omitempty"`
}
```

If you make sure your SDK is type safe, idiomatic, and compatible with their existing environment you’re going to attract developers and inspire loyalty. At this point the last thing that needs to be solved is building a sustainable program for your SDK development.

## How to Sustainably Build SDKs

When you start building SDKs you will quickly run into two major issues:

1. There are a lot of languages that you’ll need to build support for
2. You need a way to update SDKs as your API changes.

Let’s walkthrough how you can overcome these two blockers.

### The Long-tail of languages and runtimes

In 2022, [the proliferation of programming languages accelerated](https://octoverse.github.com/2022/top-programming-languages) — and there’s no sign of that trend abating anytime soon.

That’s great for nerding out over language design, but it’s a pain if you’re on the hook for building your API’s SDKs. Whereas 15 years ago you could have covered most programmers with 3-4 libraries, it’s now probably closer to 8-10. Languages can also have multiple popular frameworks, each of which require idiosyncratic tweaks to get the developer experience correct.

This fragmentation of languages & runtimes makes it harder to provide the same level of service to your users and makes it hard to keep track of how users are interfacing with your product.

![Chart showing the diversfication of server-side languages](./assets/popular-languages.png)

It’s not reasonable to expect that every company will have the language expertise internally to be able to support every language & runtime. That’s why we’ve built the Speakeasy generator. We are committed to building out support for every popular language & runtime so that you don’t have to. And in cases where people need something very specific, we offer the ability to right a custom template for the generator to use.

### Preventing SDK Drift

Too many companies think of building SDKs as a one-time project. They assign developers or contractors to handroll SDKs in the languages they know best, and punt on a long-term support system. This works for a while, but inevitably an expanding API definition, and an increasing number of libraries saddles the engineering team with a constant stream of tedious refactoring work. This refactoring may or may not be prioritized leading to SDKs with divergent behavior.

The best API companies have built SDK generators and workflows that update the SDK automatically as part of their CI/CD pipeline. Whenever a new version of the API is published, a new version of their SDKs is released.

This is a huge lift for any company to undertake — which is where Speakeasy comes in. With Speakeasy, any development team can have the same API infrastructure as the world’s best API companies. Producing idiomatic SDKs as part of your CI/CD is now available with our generator and a simple Github action:

import workflow_url from './assets/github-workflow.mp4'

  <video controls={false} loop={true} autoPlay={true} width="100%" >
    <source src={workflow_url} type="video/mp4" />
  </video>

## Final Thoughts

What’s considered table stakes for developer experience has never been higher. And as the primary interface for APIs, your SDKs are perhaps the single most important component of your developer experience. At the same time, the proliferation in languages & runtimes being used in production applications, means it’s never been harder to support the developer community.

When you are building SDKs, make sure you build something that developers will actually want to use. That means making sure your SDKs are type-safe and idiomatic. Finally, make sure that your SDK development is sustainable. Make sure you have a plan to provide ongoing support to the SDKs you build, otherwise you risk developers losing trust in the product when SDKs are not at parity with the API.

If you want your to make your SDK creation and ongoing support easy to manage, consider trying out the Speakeasy pipeline.

 This is the content for the doc blog/speakeasy-branding-process/index.mdx 

 ---
title: "Speakeasy Branding Process: How We Decided on Look, Feel, Logo, & a Mascot"
description: "Branding can be an opaque process. Here's a window-in to the process to update Speakeasy's branding. It's the reference point we wished we had."
image: "/media/speakeasy-branding-process.png"
date: 2022-07-19
authors:
  - name: Nolan Sullivan
  - image_url: 'https://uploads-ssl.webflow.com/62ccd7b208cab0723d026273/62cdf9e45dcbb4d20be59f5f_head.jpeg'
tags:
  - Building Speakeasy
  
featured_image: "/media/speakeasy-branding-process.png"
---

_All the branding work for Speakeasy was done in partnership with our design partners,_ [_Catalog_](https://www.trycatalog.com/).

Last week we rolled out some new branding for the company, replacing the hand-rolled branding which had previously been cobbled together by a team in which two of the three members were colorblind; it represents a massive improvement.

How companies arrive at their branding is typically opaque to those outside the company (and often to some people within it!).  Prior to this exercise, nobody on our team had participated in a proper 0-1 branding exercise. Before we started, we weren’t able to identify many useful resources to help shape our expectations of what would be involved. That’s why we wanted to share our own process; hopefully it gives people a window-in and provides the reference point we wished we’d had.

## What we were looking for

Our design needs had three different aspects to it: Look & feel (color scheme, font, design elements, etc), logo, and mascot.  The need for look & feel, and a logo are pretty self explanatory, but the desire for a mascot does require a brief explanation.

We want Speakeasy to make API development a joyful activity. We believed that adding a mascot to serve as a companion for the journey through the product was something that could help bring delight to an otherwise utilitarian task. This is perhaps controversial, those old enough will still remember Clippy’s incessant and obtrusive bouncing.  But we think that, used sparingly and appropriately, a mascot can help bring personality to a user’s interactions with a new tool.

## Step 1: Defining our values for the design team

Before the designers started, we needed to articulate what values were most important to our company, so they could be central to the design process.  During a couple of 1-hr sessions we focused on what is most important to our users, and therefore most important to us.

We’re building the developer-first [API platform](/post/why-an-api-platform-is-important/); we make it easy for developers to ship quality APIs to their customers with confidence.  For developers, confidence in tooling comes from **transparency,** and **reliability**. No snake oil, black boxes, or downtime. Our platform is **honest** with our users, and **consistent** in its execution.

As previously mentioned, we also believe that dev-first means building tools that are joyful for developers to use.  Too often, developer tooling means a product with a densely-technical website, a cryptic set of instructions, and no UX to speak of. Whatever we build, we want it to be **approachable** for users, and give them a **direct** path to unlocking value.

These words: transparency, reliability, honest, consistent, approachable, direct were the ones we handed to our designers after our internal discussions. We then turned them loose to see what they could come up with.

## Iteration 1: Casting a wide net

![First variations of different web pages with different colors and designs for Speakeasy.](./assets/speakeasy-branding-process-image-01.png)

![Second variations of different web pages with different colors and designs for Speakeasy.](./assets/speakeasy-branding-process-image-02.png)

![Third variations of different web pages with different colors and designs for Speakeasy.](./assets/speakeasy-branding-process-image-03.png)

![Fourth variations of different web pages with different colors and designs for Speakeasy.](./assets/speakeasy-branding-process-image-04.png)

Our designers came back to us with four very different design styles for us to look through and give feedback on. The whole team individually recorded thoughts, before we collectively discussed to provide condensed feedback.  

The main takeaway that emerged from the first iteration was that it was tricky to balance approachability with reliability. How do you project openness and friendliness without appearing too flippant? Designs #1 and #4, we thought both did a good job of projecting approachability, but struggled to project reliability.  Meanwhile, Design #3 did the best job at projecting reliability, but wasn’t as friendly or approachable.  However, we felt sure that our future look & feel lay somewhere in the intersection of the three.

In terms of logos, there was a strong preference for the logo designs in #1 and #3.  We did not want to have our mascot also serve as our logo. We felt that doing so would make them a static favicon, thus robbing them of the opportunity to have a personality.

For iteration #2, we asked our designers to further refine the look & feel of the three options we had identified as having promise, with an eye towards cohesively integrating approachability and reliability. We also wanted to get more logo options, and begin to think about how our mascot could sit comfortably within the larger branding.

## Iteration 2: Committing to a Look & Feel

![Fifth variations of different web pages with different colors and designs for Speakeasy.](./assets/speakeasy-branding-process-image-05.png)

![Sixth variations of different web pages with different colors and designs for Speakeasy.](./assets/speakeasy-branding-process-image-06.png)

![Seventh variations of different web pages with different colors and designs for Speakeasy.](./assets/speakeasy-branding-process-image-07.png)

From the options we received, we were determined to select a single option to move forward with. We were therefore at a critical point in the branding cycle.  We decided to get opinions from the developer community.  We created a feedback survey which we sent out to all the developers who were signed up to trial our product to see what they thought.

This feedback exercise was a great example of why it’s important to get quantitative and qualitative feedback.  We asked people to score each of the designs, then rank the three, and finally provide written commentary about each design: how would they describe each design? What words came to mind?

Designs #1 (two cans of red bull) and #2 (Easy as A,P,I) scored significantly higher than design #3 (Smart and light at heart) with an edge going to design #2.  However, when we read through the responses, there was a much clearer alignment between design #1 and our team values.  Users responded with words like, “clean”, “reliable”, “to the point”, “approachable”.  

As for #2, people said it was professional, but they also said it, “popped”, was “bold” and “saturated”, reminded them of “Warby Parker”, or “modern 70s design”.  None of these are negative descriptions! Sentiment was overwhelmingly positive. They rated it very highly, but we felt that in some ways the design obscured the messaging we wanted to deliver.

We therefore decided to go with design #1 as the basis for our look and feel. With that decided, we turned our attention to the logo and mascot.

## Iteration 2: Logo & Mascot

![First variation of logo for Speakeasy.](./assets/speakeasy-branding-process-image-08.png)

![Second variation of logo for Speakeasy](./assets/speakeasy-branding-process-image-09.png)
‍
Our user survey had also gathered feedback on the mascot and logo choices.  The 16-bit pixelated mascot style had an overwhelmingly positive response, especially among the developers we interviewed (Stardew Valley has clearly left an impression on the community).  

However this was slightly at odds with the most popular logo; #8 was a clear favorite.   We felt strongly about consistency in design style. If we had a pixelated mascot, then we wanted a pixelated logo (i.e. logos 1,2,3).  However we didn’t feel strongly about any of the logos presented, so we pushed our designers for some more options, specifically one with a more distinct ‘S’ shape as opposed to the stacked blocks motif.  

We also internally had a discussion about what animal best represented the company (Mr. Diggsworth the Mole was sadly destined to be a placeholder). We discussed which animals we felt were hard workers (something we all aspire to), and very quickly focused on the natural world’s best engineers: beavers, ants, and bees.  

After some back and forth, we landed on Beezy the Speakeasy bee. One of nature’s most common and cutest builders.  That they live in (api)aries was an added plus!  

With our look and feel & mascot both decided, we headed into another iteration to put it all together…

## Iteration 3: Bringing it all together

![Eighth variations of different web pages with different colors and designs for Speakeasy.](./assets/speakeasy-branding-process-image-10.png)

We were overjoyed with the iteration, and felt like the branding was now in a place where we were ready to begin to see things come to life on a live webpage. And in fact the branding that we have live on our website today isn’t very different from this design iteration.

While building the site, a few minor alterations to the design were made after seeing what it looked like on a live screen. We swapped pink and yellow in the color hierarchy (yellow to primary accent, pink to secondary accent), and added some dark blue to the otherwise plain background.  With that, we had the final design:

![Ninth variations of different web pages with different colors and designs for Speakeasy.](./assets/speakeasy-branding-process-image-11.png)

And that was that! That is the full story of how we arrived at the branding we are using today. If you’ve made it this far down the article, I hope it was interesting, and that you find it useful if you ever find yourself in the midst of a design exercise. I’m sure that with time our product will expand and we will want to make updates to our design. When we do, I’ll be sure to follow up with more notes on our process.


 This is the content for the doc blog/speakeasy-vs-apimatic/index.mdx 

 ---
title: "In Depth: Speakeasy vs APIMatic"
description: "Want to know how Speakeasy and APIMatic compare? The summary is that Speakeasy supports more language targets for SDK generation, and has a deeper platform for managing API creation. Read on for the details."
image: "/media/speakeasy-vs-apimatic.png"
date: 2024-09-30
authors:
  - name: Nolan Sullivan
  - image_url: "/media/author-headshots/nolan.jpeg"
tags:

featured_image: "/media/speakeasy-vs-apimatic.png"
---

import { FileTree } from "nextra/components";
import { ScrollyCoding } from "~/components/codehike/Scrollycoding";
import { Callout } from "~/components";

At Speakeasy, we create [idiomatic SDKs](../docs/sdk-design/intro.md) in the most popular languages. Our generators follow principles that ensure we create SDKs that offer the best developer experience so that you can focus on building your API, and your developer-users can focus on delighting their users.

In this post, we'll compare TypeScript SDKs created by Speakeasy to those generated by APIMatic.

TL;DR? Here's what we found:

- **Ease of installation:** The Speakeasy CLI has a straightforward installation process, especially for macOS users, with a single dependency-free binary. APIMatic, while also straightforward, requires Node.js and is installed using npm, which might add complexity for some users.
- **Code generation:** In our test, the SDK generated by APIMatic via CLI had issues with the `src/clientInterface.ts` file. Although the APIMatic support team responded, the problem persisted in our Docker environment test. By contrast, Speakeasy generated a complete and error-free SDK on our first attempt.
- **Documentation and code structure:** The Speakeasy-created SDK includes comprehensive documentation, and relies on Zod for runtime data parsing, making it easier for developers to understand and use. The structure and organization of the SDK were clear and intuitive.
- **Developer experience and flexibility:** Speakeasy seems to place a significant emphasis on the developer experience, offering more customization options and a focus on the API-Developer Experience (DevEx). This could be particularly beneficial for teams looking for greater control over their SDKs.
- **Response to issues:** While the APIMatic support team was responsive, the resolution provided did not address the issue effectively in our case. Since we encountered no issues creating an SDK with Speakeasy, there was no need to similarly test the Speakeasy support team's responsiveness.
- **Bundle sizes and browser compatibility:** Even when including Zod for runtime type checking, bundles using Speakeasy's SDKs are smaller than those created with APIMatic SDKs. This could be beneficial for developers who need to keep their bundle sizes small. Speakeasy's SDKs are also compatible with modern browsers, which is essential for web developers.

<Callout title="NOTE" variant="info">
  Speakeasy and APIMatic each have their strengths, but Speakeasy's ease of
  installation, reliable code generation, and developer-focused features give it
  the edge.
</Callout>

Of course, individual experiences may vary based on specific needs and use cases, so you might want to follow our process below to test-drive both tools.

## Comparing Speakeasy and APIMatic

Before we get into the technical walkthrough, let's see whether each platform targets the languages your users require, offers features you want, and provides the support you can rely on.

### SDK Generation Targets

At Speakeasy, we believe it is crucial to meet your users where they are by supporting SDKs in languages your users depend on. Anyone who has had to maintain custom SDK code because a vendor doesn't support their tech stack knows how frustrating this can be.

This table shows the current, as of September 2024, languages and platforms targeted by Speakeasy and APIMatic. These lists will change over time, so check the official documentation for the latest language support.

| Language           |          Speakeasy           |  APIMatic  |
| ------------------ | :--------------------------: | :--------: |
| Python             |              ✅              |     ✅     |
| TypeScript         |              ✅              |     ✅     |
| Go                 |              ✅              | ✅ (Alpha) |
| C# (.NET)          |              ✅              |     ✅     |
| PHP                |              ✅              |     ✅     |
| Ruby               |              ✅              |     ✅     |
| Java               |              ✅              |     ✅     |
| Kotlin             | ⚠ Java is Kotlin-compatible |     ❌     |
| Terraform provider |              ✅              |     ❌     |
| Swift              |              ✅              |     ❌     |
| Unity              |              ✅              |     ❌     |
| Postman Collection |              ✅              |     ❌     |

We're always open to expanding our language support, but would only ever do this if we have the in-house experience to create idiomatic, best-in-class SDKs for a given language. [Let us know](/roadmap) if you would like to suggest a language or platform to support.

### SDK Features

The table below compares the current SDK features offered by Speakeasy and APIMatic as of September 2024. Both Speakeasy and APIMatic are under active development, so these features may change over time.

| Feature                     | Speakeasy |        APIMatic         |
| --------------------------- | :-------: | :---------------------: |
| Union types                 |    ✅     |           ✅            |
| Discriminated union types   |    ✅     | ⚠ non-OpenAPI standard |
| Server-sent events          |    ✅     |           ❌            |
| Retries                     |    ✅     |           ✅            |
| Pagination                  |    ✅     |           ❌            |
| Async support               |    ✅     |           ✅            |
| Streaming uploads           |    ✅     |           ❌            |
| OAuth 2.0                   |    ✅     |           ✅            |
| Custom SDK naming           |    ✅     |           ✅            |
| Customize SDK structure     |    ✅     |           ❌            |
| Custom dependency injection |    ✅     |           ❌            |

APIMatic lacks advanced SDK customization features, and we couldn't find any code or documentation related to pagination. These are features Speakeasy's users rely on.

### Platform Features

Speakeasy's primary interface is an open-source, full-featured, and portable CLI. Developers use our CLI to experiment and iterate locally and to customize their CI/CD workflows.

APIMatic's CLI depends on Node.js and several packages. This makes it much less portable. In testing, we also found that it does not generate SDKs as reliably as the APIMatic web interface.

| Feature                  | Speakeasy | APIMatic |
| ------------------------ | :-------: | :------: |
| GitHub CI/CD             |    ✅     |    ✅    |
| CLI                      |    ✅     |    ⚠    |
| Web interface            |    ✅     |    ✅    |
| Package publishing       |    ✅     |    ✅    |
| OpenAPI linting          |    ✅     |    ✅    |
| Documentation generation |    ✅     |    ✅    |
| Test generation          |    ✅     |    ✅    |
| OpenAPI overlays         |    ✅     |    ❌    |
| Change detection         |    ✅     |    ❌    |
| Developer portal         |    ❌     |    ✅    |

### Enterprise Support

Both Speakeasy and APIMatic offer support for Enterprise customers. This includes features like concierge onboarding, private Slack channels, and enterprise SLAs.

| Feature               | Speakeasy | APIMatic |
| --------------------- | :-------: | :------: |
| Concierge onboarding  |    ✅     |    ✅    |
| Private Slack channel |    ✅     |    ✅    |
| Enterprise SLAs       |    ✅     |    ✅    |
| User issues triage    |    ✅     |    ✅    |

### Pricing

Speakeasy offers a free plan, while APIMatic offers a limited free trial.

| Plan          | Speakeasy                               | APIMatic                                                    |
| ------------- | --------------------------------------- | ----------------------------------------------------------- |
| Free          | 1 free Published SDK, 50 endpoints      | Trial only                                                  |
| Startup       | 1 free + $250/mo/SDK, 50 endpoints each | N/A                                                         |
| Lite: Starter | N/A                                     | $15/mo. 1 API, 10 endpoints, no team members.               |
| Lite: Basic   | N/A                                     | Custom. 1 API, 20 endpoints, 2 team members.                |
| Business      | N/A                                     | Custom. Up to 50 APIs, 100 endpoints each, 15 team members. |
| Enterprise    | Custom                                  | Custom                                                      |

Speakeasy's free plan is more generous than both Lite plans offered by APIMatic.

## Speakeasy vs APIMatic Technical Walkthrough

Let's create SDKs with Speakeasy and APIMatic from a single API specification, to compare the output and customization features.

We've created an OpenAPI document that describes a fictional bookstore API. You can find the complete OpenAPI document in the [example repository](https://github.com/speakeasy-api/speakeasy-apimatic-comparison), but let's take a look at what's included.

<ScrollyCoding className="ch-scrollycoding-full-height">

## !!steps

Our bookstore OpenAPI document is compliant with OpenAPI 3.1, which is supported by both Speakeasy and APIMatic. We define a basic info section and add a single development server.

```yaml ! openapi.yaml focus=1:15
!from ./assets/openapi.yaml.txt
```

---

## !!steps

Here we define two tags to organize our operations with: `Books` and `Orders`.

```yaml ! openapi.yaml focus=16:20
!from ./assets/openapi.yaml.txt
```

---

## !!steps

We define one global authentication method, `apiKey`.

```yaml ! openapi.yaml focus=21:22
!from ./assets/openapi.yaml.txt
```

---

## !!steps

Let's examine the operations we'll need an SDK for, starting with `getAllBooks`.

This operation takes no input.

```yaml ! openapi.yaml focus=2:29
!from ./assets/openapi.yaml.txt 23:77
```

---

## !!steps

What makes this operation interesting is that it returns an array of objects of three types: `ProgrammingBook`, `FantasyBook`, and `SciFiBook`. Each object's type is determined by the book's category.

This example allows us to test how our SDK generators handle discriminated unions in OpenAPI.

```yaml ! openapi.yaml focus=2:29 mark=19:29
!from ./assets/openapi.yaml.txt 23:77
```

---

## !!steps

Next up, we have an operation that adds a book to the database, called `addBook`.

This operation takes one object of type `ProgrammingBook`, `FantasyBook`, or `SciFiBook` as input.

```yaml ! openapi.yaml mark=15:24
!from ./assets/openapi.yaml.txt 78:144
```

---

## !!steps

Our next book-related operation, `updateBookCoverById`, takes a book ID as a path variable, and an image as a binary payload.

We include this operation to test how our SDK generators handle binary payloads.

```yaml ! openapi.yaml mark=22:28
!from ./assets/openapi.yaml.txt 206:233
```

---

## !!steps

Our final book-related operation, `getBookById`, takes a book ID as a path variable, and returns one of our book objects.

```yaml ! openapi.yaml focus=1:32
!from ./assets/openapi.yaml.txt 145:205
```

---

## !!steps

Next up, we have an operation that returns a list of all orders in the database, called `getAllOrders`.

This operation returns an array of `Order` objects, so that we can test an array of nested objects.

```yaml ! openapi.yaml focus=1:19
!from ./assets/openapi.yaml.txt 237:278
```

---

## !!steps

Our next order-related operation, `createOrder`, takes an object of type `NewOrder` as input, and returns an object of type `Order`.

We include this one to test how our SDK generators help users avoid common mistakes, like passing the wrong type to an operation.

```yaml ! openapi.yaml mark=16,32
!from ./assets/openapi.yaml.txt 279:310
```

---

## !!steps

Finally, we have an operation that returns a stream of order events, called `getOrderStream`.

We include this operation to test how our SDK generators handle server-sent events.

```yaml ! openapi.yaml mark=14
!from ./assets/openapi.yaml.txt 358:373
```

---

## !!steps

The remainder of the OpenAPI document defines the components used in the operations above.

```yaml ! openapi.yaml
!from ./assets/openapi.yaml.txt 374:639
```

</ScrollyCoding>

We'll save this as `openapi.yaml` in the root of our test repository.

### Installing the APIMatic CLI

The APIMatic CLI depends on Node.js, and we'll install it using npm. In the terminal, run:

```bash
npm install -g @apimatic/cli
```

This will install the APIMatic CLI in your global `node_modules` folder and create the `apimatic` command.

On our test environment, this installed 250 npm packages, 17 of which were deprecated.

Check your APIMatic CLI version:

```bash
apimatic --version
# @apimatic/cli/1.1.0-alpha.5 darwin-arm64 node-v20.17.0
```

Authenticate with APIMatic by running:

```bash
apimatic auth:login
```

Then enter your APIMatic email address and password.

The APIMatic CLI is also [open source](https://github.com/apimatic/apimatic-cli), with the latest update in September 2023.

### Installing the Speakeasy CLI

To install the Speakeasy CLI, we'll follow the Speakeasy [Getting Started](/docs/introduction/introduction#getting-started) guide.

1. Create an account on [Speakeasy](https://app.speakeasy.com/).
2. Install the Speakeasy CLI using Homebrew or cURL:

   ```bash
   brew install speakeasy-api/tap/speakeasy
   ```

   or

   ```bash
   curl -fsSL https://go.speakeasy.com/cli-install.sh | sh
   ```

3. Authenticate the CLI with Speakeasy:

   ```bash
   speakeasy auth login
   ```

You can check the Speakeasy version:

```bash
speakeasy --version
# speakeasy version 1.390.5
# darwin_arm64
```

### Linting OpenAPI Documents

Both Speakeasy and APIMatic can validate OpenAPI documents.

Validate `openapi.yaml` using APIMatic:

```bash
apimatic api:validate --file=openapi.yaml
# Validating specification file... done
# Info: One or more elements in the API specification has a missing description.  (View Details)Source: API.
# ...
# Specification file provided is valid
```

Speakeasy goes beyond validation by linting an OpenAPI document, and then providing separate errors, warnings, and hints. This includes a link to a shareable lint report for easier collaboration.

```bash
speakeasy lint openapi -s openapi.yaml
```

Both platforms validated our OpenAPI document without errors, so let's move on to generating SDKs.

### Generating an SDK Using the APIMatic CLI Tutorial

We'll follow the [APIMatic tutorial](https://docs.apimatic.io/generate-sdks/create-sdks/create-sdks-through-cli/) to generate a TypeScript SDK.

In the terminal, run:

```bash
apimatic sdk:generate --platform=typescript --file="openapi.yaml"
```

This should print the following to the terminal:

```
Generating SDK... done
Downloading SDK... done
Success! Your SDK is located at ~/speakeasy-apimatic-comparison/openapi_sdk_typescript
```

## Inspecting the APIMatic-Generated SDK

To see what was generated, run the tree command from the new SDK directory:

```bash
tree openapi_sdk_typescript
```

<FileTree>
  <FileTree.File name="LICENSE" />
  <FileTree.File name="README.md" />
  <FileTree.Folder name="doc">
    <FileTree.File name="api-error.md" />
    <FileTree.File name="api-response.md" />
    <FileTree.Folder name="auth">
      <FileTree.File name="custom-header-signature.md" />
      <FileTree.File name="oauth-2-client-credentials-grant.md" />
    </FileTree.Folder>
    <FileTree.File name="client.md" />
    <FileTree.Folder name="controllers">
      <FileTree.File name="books.md" />
      <FileTree.File name="orders.md" />
    </FileTree.Folder>
    <FileTree.Folder name="models">
      <FileTree.File name="author-with-id.md" />
      <FileTree.File name="author-with-name.md" />
      <FileTree.File name="author.md" />
      <FileTree.File name="book.md" />
      <FileTree.File name="category-enum.md" />
      <FileTree.File name="fantasy-book.md" />
      <FileTree.File name="new-order.md" />
      <FileTree.File name="o-auth-provider-error-enum.md" />
      <FileTree.File name="o-auth-provider-error.md" />
      <FileTree.File name="o-auth-scope-client-credentials-enum.md" />
      <FileTree.File name="o-auth-token.md" />
      <FileTree.File name="order-stream-message.md" />
      <FileTree.File name="order.md" />
      <FileTree.File name="programming-book.md" />
      <FileTree.File name="sci-fi-book.md" />
      <FileTree.File name="status-enum.md" />
      <FileTree.File name="user.md" />
    </FileTree.Folder>
  </FileTree.Folder>
  <FileTree.File name="jest.config.js" />
  <FileTree.File name="package.json" />
  <FileTree.Folder name="src">
    <FileTree.File name="authProvider.ts" />
    <FileTree.File name="authentication.ts" />
    <FileTree.File name="client.ts" />
    <FileTree.File name="clientAdapter.ts" />
    <FileTree.File name="clientCredentialsManager.ts" />
    <FileTree.File name="clientInterface.ts" />
    <FileTree.File name="configuration.ts" />
    <FileTree.File name="core.ts" />
    <FileTree.File name="defaultConfiguration.ts" />
    <FileTree.File name="index.ts" />
    <FileTree.File name="schema.ts" />
  </FileTree.Folder>
  <FileTree.Folder name="test">
    <FileTree.File name="booksController.test.ts" />
    <FileTree.File name="ordersController.test.ts" />
    <FileTree.File name="testClient.ts" />
    <FileTree.File name="testHelper.ts" />
  </FileTree.Folder>
  <FileTree.File name="tsconfig.base.json" />
  <FileTree.File name="tsconfig.cjs.json" />
  <FileTree.File name="tsconfig.esm.json" />
  <FileTree.File name="tsconfig.json" />
</FileTree>

Poking around the source, we found that the generated SDK did not contain any model code or types related to our bookstore example.

### Corrupted SDK Generation

In a previous test from January 2024, we used the standard OpenAPI Petstore example API to generate an SDK using APIMatic. In that case, the SDK also did not contain any models, and we encountered a bizarre error - the `src/clientInterface.ts` file seems to have been generated incorrectly. Here's what we found:

```typescript src/clientInterface.ts
SdkRequestBuilderFactory = RequestBuilderFactory<
  Server,
  AuthParams
>;

export type SdkRequestBuilder = ReturnType<SdkRequestBuilderFactory>;

export type Server = 'default';

export type AuthParams = boolean;
/**
 * Swagger PetstoreLib
 *
 * This file was automatically generated by APIMATIC v3.0 ( https://www.apimatic.io ).
 */

import { RequestBuilderFactory } from './core';

export interface ClientInterface {
  getRequestBuilderFactory(): SdkRequestBuilderFactory;
}

export type
```

The file seems to start in the middle, then wraps around.

This error gave us an opportunity to engage with the APIMatic support team, so we'll take a brief detour and share our experience: After seven days of filing the bug report, we received a curt, "We've tested out the SDKs via the CLI method and they're being generated as expected." To be fair, the support agent did offer to provide further assistance if we still had a problem.

As any responsible tester would do, we decided to isolate the test environment from our system to be sure the issue didn't stem from an error on our side. We're using nvm on macOS after all, and issues can crop up when switching between Node versions.

We created a Dockerfile to install the requirements and generate an SDK:

```docker
FROM node:latest
ARG apimatic_auth_key=APIMATIC_KEY
RUN mkdir -p /usr/src/app
WORKDIR /usr/src/app
COPY petstore.yaml /usr/src/app
RUN npm install -g @apimatic/cli
RUN apimatic auth:login --auth-key=$apimatic_auth_key
RUN apimatic sdk:generate --platform=typescript --file="petstore.yaml"
RUN cat petstore_sdk_typescript/src/clientInterface.ts
```

Replace `$APIMATIC_KEY` with your APIMatic API key, then run:

```bash
docker build -t apimatic-petstore --build-arg apimatic_auth_key=$APIMATIC_KEY --progress plain .
```

On a second run with Docker, the bug appeared to fix itself, only to fail again later.

Sure enough, the result was the same - the `src/clientInterface.ts` file starts in the middle and wraps around. This might be caused by a race condition in the code that downloads and unzips the SDK from APIMatic. Tempting as it is to track this error down, we have SDKs to generate, so we'll move on.

If you're following along, remember to delete your Docker image, as it contains your API key. The key also appears in your Docker history.

In the terminal, run:

```bash
docker image rm apimatic-petstore
```

In both our Petstore and Bookstore examples, the APIMatic CLI failed to generate a usable SDK.

We need to find another way to generate an SDK using APIMatic - let's try the web app.

### Generating an SDK Using the APIMatic UI

Log in to the APIMatic web application and follow the prompts to import our `openapi.yaml` document as a new API.

Click on **Generate** and select TypeScript. This generates a TypeScript SDK, which downloads to your computer as a zip file. We'll save this in our working directory as `bookstore-sdk-apimatic`.

Here's what's inside:

<FileTree>
  <FileTree.File name="LICENSE" />
  <FileTree.File name="README.md" />
  <FileTree.Folder name="doc">
    <FileTree.File name="api-error.md" />
    <FileTree.File name="api-response.md" />
    <FileTree.Folder name="auth">
      <FileTree.File name="custom-header-signature.md" />
      <FileTree.File name="oauth-2-client-credentials-grant.md" />
    </FileTree.Folder>
    <FileTree.File name="client.md" />
    <FileTree.Folder name="controllers">
      <FileTree.File name="books.md" />
      <FileTree.File name="orders.md" />
    </FileTree.Folder>
    <FileTree.Folder name="models">
      <FileTree.File name="author-with-id.md" />
      <FileTree.File name="author-with-name.md" />
      <FileTree.File name="author.md" />
      <FileTree.File name="book.md" />
      <FileTree.File name="category-enum.md" />
      <FileTree.Folder name="containers">
        <FileTree.File name="add-book-body.md" />
        <FileTree.File name="add-book-response.md" />
        <FileTree.File name="author-2.md" />
        <FileTree.File name="get-all-books-response.md" />
        <FileTree.File name="get-book-by-id-response.md" />
        <FileTree.File name="order-products.md" />
      </FileTree.Folder>
      <FileTree.File name="fantasy-book.md" />
      <FileTree.File name="new-order.md" />
      <FileTree.File name="o-auth-provider-error-enum.md" />
      <FileTree.File name="o-auth-provider-error.md" />
      <FileTree.File name="o-auth-scope-client-credentials-enum.md" />
      <FileTree.File name="o-auth-token.md" />
      <FileTree.File name="order-stream-message.md" />
      <FileTree.File name="order.md" />
      <FileTree.File name="programming-book.md" />
      <FileTree.File name="sci-fi-book.md" />
      <FileTree.File name="status-enum.md" />
      <FileTree.File name="user.md" />
    </FileTree.Folder>
  </FileTree.Folder>
  <FileTree.File name="jest.config.js" />
  <FileTree.File name="package.json" />
  <FileTree.Folder name="src">
    <FileTree.File name="authProvider.ts" />
    <FileTree.File name="authentication.ts" />
    <FileTree.File name="client.ts" />
    <FileTree.File name="clientAdapter.ts" />
    <FileTree.File name="clientCredentialsManager.ts" />
    <FileTree.File name="clientInterface.ts" />
    <FileTree.File name="configuration.ts" />
    <FileTree.Folder name="controllers">
      <FileTree.File name="baseController.ts" />
      <FileTree.File name="booksController.ts" />
      <FileTree.File name="oAuthAuthorizationController.ts" />
      <FileTree.File name="ordersController.ts" />
    </FileTree.Folder>
    <FileTree.File name="core.ts" />
    <FileTree.File name="defaultConfiguration.ts" />
    <FileTree.Folder name="errors">
      <FileTree.File name="oAuthProviderError.ts" />
    </FileTree.Folder>
    <FileTree.File name="index.ts" />
    <FileTree.Folder name="models">
      <FileTree.File name="author.ts" />
      <FileTree.File name="authorWithID.ts" />
      <FileTree.File name="authorWithName.ts" />
      <FileTree.File name="book.ts" />
      <FileTree.File name="categoryEnum.ts" />
      <FileTree.Folder name="containers">
        <FileTree.File name="addBookBody.ts" />
        <FileTree.File name="addBookResponse.ts" />
        <FileTree.File name="author2.ts" />
        <FileTree.File name="getAllBooksResponse.ts" />
        <FileTree.File name="getBookByIdResponse.ts" />
        <FileTree.File name="orderProducts.ts" />
      </FileTree.Folder>
      <FileTree.File name="fantasyBook.ts" />
      <FileTree.File name="newOrder.ts" />
      <FileTree.File name="oAuthProviderErrorEnum.ts" />
      <FileTree.File name="oAuthScopeClientCredentialsEnum.ts" />
      <FileTree.File name="oAuthToken.ts" />
      <FileTree.File name="order.ts" />
      <FileTree.File name="orderStreamMessage.ts" />
      <FileTree.File name="programmingBook.ts" />
      <FileTree.File name="sciFiBook.ts" />
      <FileTree.File name="statusEnum.ts" />
      <FileTree.File name="user.ts" />
    </FileTree.Folder>
    <FileTree.File name="schema.ts" />
  </FileTree.Folder>
  <FileTree.Folder name="test">
    <FileTree.File name="booksController.test.ts" />
    <FileTree.File name="ordersController.test.ts" />
    <FileTree.File name="testClient.ts" />
    <FileTree.File name="testHelper.ts" />
  </FileTree.Folder>
  <FileTree.File name="tsconfig.base.json" />
  <FileTree.File name="tsconfig.cjs.json" />
  <FileTree.File name="tsconfig.esm.json" />
  <FileTree.File name="tsconfig.json" />
</FileTree>

This looks more complete, and none of the files are corrupted, so we'll move on to trying the Speakeasy generator.

### Create an SDK Using the Speakeasy CLI

To generate an SDK using Speakeasy, run the following in the terminal:

```bash Terminal
speakeasy generate sdk \
    --schema openapi.yaml \
    --lang typescript \
    --out ./bookstore-sdk-speakeasy
```

Speakeasy lints the OpenAPI document, then creates a new folder, `bookstore-sdk-speakeasy`, with the generated SDK.

### Setting Up a Mock Server

We used [Stoplight Prism](https://github.com/stoplightio/prism) to generate a mock server to test our SDKs:

```bash Terminal
npm install -g @stoplight/prism-cli
prism mock openapi.yaml
```

This command starts a mock server at `http://localhost:4010`.

### SDK Code Comparison

Now that we have two SDKs, let's compare the code generated by each platform.

#### Runtime Type Checking

Speakeasy creates SDKs that are type-safe from development to production. As our CEO recently wrote, [Type Safe is better than Type Faith](/post/type-safe-vs-type-faith).

Speakeasy uses [Zod](https://zod.dev/) to validate data at runtime. Data sent to the server and data received from the server are validated against Zod definitions in the client.

This provides safer runtime code execution and helps developers who use your SDK to provide early feedback about data entered by their end users. Furthermore, trusting data validation on the client side allows developers more confidence to build [optimistic UIs](https://medium.com/distant-horizons/using-optimistic-ui-to-delight-your-users-ac819a81d59a) that update as soon as an end user enters data, greatly improving end users' perception of your API's speed.

Let's see how Speakeasy's runtime type checking works in an example.

Consider the following `Book` component from our OpenAPI document:

```yaml mark=18:21
!from ./assets/openapi.yaml.txt 379:406
```

The highlighted `price` field above has the type `integer`.

```typescript speakeasy-example.ts mark=17
// techbooks-speakeasy SDK created by Speakeasy
import { TechBooks } from "techbooks-speakeasy";

const bookStore = new TechBooks({
  apiKey: "123",
});

async function run() {
  await bookStore.books.addBook({
    author: {
      name: "Robert C. Martin",
      photo: "https://example.com/photos/robert.jpg",
      biography: 'Robert Cecil Martin, colloquially known as "Uncle Bob", is an American software engineer...',
    },
    category: "Programming",
    description: "A Handbook of Agile Software Craftsmanship",
    price: 29.99,
    title: "Clean Code",
  });
}

run();
```

The `price` field in the `Book` object in our test code is set to `29.99`, which is a floating-point number. This will cause a validation error before the data is sent to the server, as the `price` field is expected to be an integer.

[Handling Zod validation errors](https://zod.dev/?id=error-handling) is straightforward, and allows developers to provide meaningful feedback to their end users early in the process.

The same book object in code using the SDK generated by APIMatic will only be validated on the server. This means that the error will only be caught from the client's perspective _after_ the data is sent to the server, and the server responds with an error message.

If the server is not set up to validate the `price` field, the error will _not be caught at all_, leading to unexpected behavior in your developer-users' applications.

As a result, developers using the SDK generated by APIMatic may need to write additional client-side validation code to catch these errors before they are sent to the server.

#### Dependency Injection: SDK Hooks

Speakeasy generates a clean mechanism for safely injecting custom code.

The abridged code below is from the SDK generated by Speakeasy:

```typescript speakeasy/hooks/types.ts
/*
 * Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT.
 */

// ...

export interface BeforeCreateRequestHook {
    /**
     * A hook that is called before the SDK creates a `Request` object. The hook
     * can modify how a request is constructed since certain modifications, like
     * changing the request URL, cannot be done on a request object directly.
     */
    beforeCreateRequest: (hookCtx: BeforeCreateRequestContext, input: RequestInput) => RequestInput;
}

export interface BeforeRequestHook {
    /**
     * A hook that is called before the SDK sends a request. The hook can
     * introduce instrumentation code such as logging, tracing and metrics or
     * replace the request before it is sent or throw an error to stop the
     * request from being sent.
     */
    beforeRequest: (hookCtx: BeforeRequestContext, request: Request) => Awaitable<Request>;
}

// ...
```

The types above are well documented, but you can read more about [Speakeasy SDK Hooks](/docs/customize/code/sdk-hooks) in Speakeasy's documentation.

In short, hooks are typed and contain relevant context depending on when in the lifecycle they are applied. To add hooks, register hooks in the `src/hooks/registration.ts` file in your TypeScript SDK.

Here's an example hook:

```typescript src/hooks/registration.ts
import { Hooks } from "./types";

/*
 * This file is only ever generated once on the first generation and then is free to be modified.
 * Any hooks you wish to add should be registered in the initHooks function. Feel free to define them
 * in this file or in separate files in the hooks folder.
 */

export function initHooks(hooks: Hooks) {
    // Add hooks by calling hooks.register{ClientInit/BeforeCreateRequest/BeforeRequest/AfterSuccess/AfterError}Hook
    // with an instance of a hook that implements that specific Hook interface
    // Hooks are registered per SDK instance, and are valid for the lifetime of the SDK instance

    hooks.registerBeforeCreateRequestHook(
        {
            beforeCreateRequest: (hookCtx, input) => {
                // Modify the request input here
                console.log("BeforeCreateRequestHook", input);
                console.log("HookContext", hookCtx);
                return input;
            },
        }
    );
}
```

Speakeasy also provides a clean abstraction to add dependencies to the SDK, by specifying dependencies in the SDK's gen.yaml file:

```yaml gen.yaml
typescript:
  additionalDependencies:
    dependencies:
      uuid: ^9.0.1
    devDependencies:
      "@types/uuid": "^9.0.8"
    peerDependencies: {}
```

Dependency injection and SDK customization are not well documented for APIMatic. Of course, developers can patch the generated SDKs as much as they want, but mixing generated and custom code is often a recipe for disaster.

#### OAuth Client Credentials Handling

Both SDKs handle OAuth 2.0 with client credentials.

Our bookstore API requires an OAuth 2.0 token with client credentials to access the API. Let's see how the SDKs handle this.

Consider the following OAuth 2.0 configuration from our OpenAPI document:

```yaml openapi.yaml
!from ./assets/openapi.yaml.txt 633:639
```

The SDK generated by Speakeasy takes a `clientID` and `clientSecret` when instantiating the SDK. The SDK also includes `ClientCredentialsHook` class that implements `BeforeRequestHook` to check whether the token is expired and refresh it if necessary. The hook also checks whether the client has the necessary scopes to access the endpoint, and handles authentication errors.

```typescript speakeasy-example.ts
// techbooks-speakeasy SDK created by Speakeasy
import { TechBooks } from "techbooks-speakeasy";

const bookStore = new TechBooks({
  security: {
    // OAuth 2.0 client credentials
    clientID: "<YOUR_CLIENT_ID_HERE>",
    clientSecret: "<YOUR_CLIENT_SECRET_HERE>",
  },
});

async function run() {
  // The SDK handles the token lifecycle, retries, and error handling for you
  await bookStore.books.addBook({
    // Book object
  });
}

run();
```

The SDK generated by APIMatic has similar functionality.

#### Server-Sent Events (SSE) and Streaming Responses

Our bookstore API includes an operation that streams orders to the client using Server-Sent Events (SSE).

```yaml mark=15
paths:
  /orderstream:
    get:
      summary: Get a stream of orders
      operationId: getOrderStream
      description: Returns a stream of orders
      tags:
        - Orders
      security:
        - apiKey: []
      responses:
        "200":
          description: A stream of orders
          content:
            text/event-stream:
              schema:
                $ref: "#/components/schemas/OrderStreamMessage"
```

Let's see how the SDKs handle this.

[Speakeasy generates types and methods for handling SSE](/docs/customize-sdks/streaming) without any customization. Here's an example of how to use the SDK to listen for new orders:

```typescript speakeasy-example.ts
import { TechBooks } from "techbooks-speakeasy";

const bookStore = new TechBooks({
  apiKey: 'KEY123',
});

async function run() {
  const result = await bookStore.orders.getOrderStream();

  if (result.orderStreamMessage == null) {
    throw new Error('Failed to create stream: received null value');
  }

  const stream = result.orderStreamMessage.stream;

  if (!stream || typeof stream.getReader !== 'function') {
    throw new Error('Invalid stream: expected a ReadableStream');
  }

  const reader = stream.getReader();

  try {
    while (true) {
      const { done, value } = await reader.read();
      if (done) break;
      console.log(new TextDecoder().decode(value));
    }
  } catch (error) {
    console.error('Error reading stream', error);
  } finally {
    reader.releaseLock();
  }
}

run();
```

(The example above does not run against a local Prism server, but you can test it against [Stoplight's hosted Prism](https://stoplight.io/) server.)

APIMatic does not generate SSE-handling code.

#### Discriminated Unions

Our OpenAPI document includes a `Book` component with a `category` field that can be one of three values: `Programming`, `Fantasy`, or `SciFi`.

This allows us to type the `Book` component in requests and responses as specific book types, such as `ProgrammingBook`, `FantasyBook`, and `SciFiBook`.

OpenAPI supports discriminated unions using the `discriminator` field in the schema. Here's an example of a response that returns an array of books of different types:

```yaml openapi.yaml
schema:
  type: array
  items:
    oneOf:
      - $ref: "#/components/schemas/ProgrammingBook"
      - $ref: "#/components/schemas/FantasyBook"
      - $ref: "#/components/schemas/SciFiBook"
    discriminator:
      propertyName: category
      mapping:
        Programming: "#/components/schemas/ProgrammingBook"
        Fantasy: "#/components/schemas/FantasyBook"
        Sci-fi: "#/components/schemas/SciFiBook"
```

Let's see how the SDKs handle this.

Speakeasy generates TypeScript types for each book type, and uses a discriminated union to handle the different book types. This enables developers to use the correct type when working with books of different categories. This pattern could just as easily apply to payment methods or delivery options.

The example below shows how Speakeasy defines the `ProgrammingBook` type. It also generates types for `FantasyBook` and `SciFiBook`.

In this example, you'll notice that the `category` field is optional in the `ProgrammingBook` type, but is enforced by Zod validation in the SDK.

```typescript speakeasy/books.ts mark=16,29,50,61
/*
 * Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT.
 */

import { Author, Author$ } from "./author";
import * as z from "zod";

export type ProgrammingBook = {
    id?: number | undefined;
    title: string;
    description: string;
    /**
     * Price in USD cents
     */
    price: number;
    category?: "Programming" | undefined;
    author: Author;
    coverImage?: string | undefined;
};

/** @internal */
export namespace ProgrammingBook$ {
    export const inboundSchema: z.ZodType<ProgrammingBook, z.ZodTypeDef, unknown> = z
        .object({
            id: z.number().int().optional(),
            title: z.string(),
            description: z.string(),
            price: z.number().int(),
            category: z.literal("Programming").optional(),
            author: Author$.inboundSchema,
            cover_image: z.string().optional(),
        })
        .transform((v) => {
            return {
                ...(v.id === undefined ? null : { id: v.id }),
                title: v.title,
                description: v.description,
                price: v.price,
                ...(v.category === undefined ? null : { category: v.category }),
                author: v.author,
                ...(v.cover_image === undefined ? null : { coverImage: v.cover_image }),
            };
        });

    export type Outbound = {
        id?: number | undefined;
        title: string;
        description: string;
        price: number;
        category: "Programming";
        author: Author$.Outbound;
        cover_image?: string | undefined;
    };

    export const outboundSchema: z.ZodType<Outbound, z.ZodTypeDef, ProgrammingBook> = z
        .object({
            id: z.number().int().optional(),
            title: z.string(),
            description: z.string(),
            price: z.number().int(),
            category: z.literal("Programming").default("Programming" as const),
            author: Author$.outboundSchema,
            coverImage: z.string().optional(),
        })
        .transform((v) => {
            return {
                ...(v.id === undefined ? null : { id: v.id }),
                title: v.title,
                description: v.description,
                price: v.price,
                category: v.category,
                author: v.author,
                ...(v.coverImage === undefined ? null : { cover_image: v.coverImage }),
            };
        });
}
```

We can see how Speakeasy generates SDK code to handle the different book types in the response for the `getgetAllBooks` operation:

```typescript speakeasy/getallbooks.ts
/*
 * Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT.
 */

import * as components from "../components";
import * as z from "zod";

export type ResponseBody =
    | (components.ProgrammingBook & { category: "Programming" })
    | (components.FantasyBook & { category: "Fantasy" })
    | (components.SciFiBook & { category: "Sci-fi" });

export type GetAllBooksResponse = {
    httpMeta: components.HTTPMetadata;
    /**
     * A list of books
     */
    responseBodies?:
        | Array<
              | (components.ProgrammingBook & { category: "Programming" })
              | (components.FantasyBook & { category: "Fantasy" })
              | (components.SciFiBook & { category: "Sci-fi" })
          >
        | undefined;
};

// ...
```

Note how the array elements in `responseBodies` are typed according to the book category.

This may seem like a trivial example, but it illustrates how Speakeasy generates types that are more specific and easier to work with than the types generated by APIMatic. This could, for instance, help developers correctly handle different book types in their applications.

APIMatic does not generate types for discriminated unions, and developers must manually handle the different book types in the response.

Here is the equivalent type definition generated by APIMatic:

```typescript apimatic/programmingBook.ts
/**
 * Bookstore APILib
 *
 * This file was automatically generated by APIMATIC v3.0 ( https://www.apimatic.io ).
 */

// ...

import { CategoryEnum, categoryEnumSchema } from './categoryEnum';

// ...

export interface ProgrammingBook {
  id?: number;
  title: string;
  description: string;
  /** Price in USD cents */
  price: number;
  category: CategoryEnum;
  author: Author2;
  coverImage?: string;
}

// ...
```

Following the `CategoryEnum` import:

```typescript apimatic/categoryEnum.ts
/**
 * Bookstore APILib
 *
 * This file was automatically generated by APIMATIC v3.0 ( https://www.apimatic.io ).
 */

// ...

/**
 * Enum for CategoryEnum
 */
export enum CategoryEnum {
  Scifi = 'Sci-fi',
  Fantasy = 'Fantasy',
  Programming = 'Programming',
}

// ...
```

Discriminating between different book types in the response is left to users.

### OpenAPI Overlays

If editing your OpenAPI document is not an option, Speakeasy also supports the [OpenAPI Overlays](/docs/prep-openapi/overlays/create-overlays) specification, which allows you to add or override parts of an OpenAPI document without modifying the original document.

This step can form part of your CI/CD pipeline, ensuring that your SDKs are always up-to-date with your API, even if your OpenAPI document is generated from code.

Speakeasy's CLI can also generate OpenAPI overlays for you, based on the differences between two OpenAPI documents.

### SDK and Bundle Size

Let's compare the bundle sizes of the SDKs generated by Speakeasy and APIMatic.

Start by adding a `sdk-tests/speakeasy.ts` file that imports the Speakeasy SDK:

```typescript sdk-tests/speakeasy.ts
import { SDKCore } from "openapi/core.js";
import { booksAddBook } from "openapi/funcs/booksAddBook.js";

// Use `SDKCore` for best tree-shaking performance.
// You can create one instance of it to use across an application.
const sdk = new SDKCore({
  apiKey: "<YOUR_API_KEY_HERE>",
});

async function run() {
  const res = await booksAddBook(sdk, {
    id: 1,
    title: "New Sci-Fi Book",
    description: "A new Sci-Fi book description",
    category: "Sci-fi",
    price: 1999,
    author: {
      id: 1,
      name: "New Author",
      photo: "https://example.com/photos/newauthor.jpg",
      biography: "New Author is an upcoming writer in the Sci-Fi genre...",
    },
    coverImage: "https://example.com/covers/newbook.jpg",
  });

  if (!res.ok) {
    throw res.error;
  }

  const { value: result } = res;

  // Handle the result
  console.log(result)
}

run();
```

Next, add a `sdk-tests/apimatic.ts` file that imports the APIMatic SDK:

```typescript sdk-tests/apimatic.ts
import {
  Client,
  BooksController,
  AddBookBody,
  AddBookResponse,
  CategoryEnum,
  ApiError,
} from "bookstore-apilib";

const client = new Client({
  apiKeyCredentials: {
    "X-API-Key": "YOUR_API_KEY",
  },
});

const booksController = new BooksController(client);

const body: AddBookBody = {
  title: "Clean Code",
  description: "A Handbook of Agile Software Craftsmanship",
  price: 2999,
  category: CategoryEnum.Programming,
  author: {
    name: "Robert C. Martin",
    photo: "https://example.com/photos/robert.jpg",
    biography:
      'Robert Cecil Martin, colloquially known as "Uncle Bob", is an American software engineer...',
  },
  id: 1,
  coverImage: "https://example.com/covers/cleancode.jpg",
};

async function addBook() {

  try {
    const { result, ...httpResponse } = await booksController.addBook(body);
    console.log(result);
    if (AddBookResponse.isProgrammingBook(result)) {
      // Use the result narrowed down to ProgrammingBook type.
    } else if (AddBookResponse.isFantasyBook(result)) {
      // Use the result narrowed down to FantasyBook type.
    } else if (AddBookResponse.isSciFiBook(result)) {
      // Use the result narrowed down to SciFiBook type.
    } else {
      // result is narrowed down to type 'never'.
    }
    // Get more response info...
    // const { statusCode, headers } = httpResponse;
  } catch (error) {
    console.error(error);
    if (error instanceof ApiError) {
      const errors = error.result;
    }
  }
}

addBook();
```

Running the code above generates a validation error, due to the lack of discriminated unions in the SDK generated by APIMatic. This won't affect the bundle size, though.

We'll use `esbuild` to bundle the SDKs. First, install `esbuild`:

```bash
npm install esbuild
```

Next, add a `sdk-tests/build.js` script that uses `esbuild` to bundle the SDKs:

```typescript sdk-tests/build.js
import * as esbuild from "esbuild";
import * as fs from "fs";

const speakeasyBuild = await esbuild.build({
  entryPoints: ["speakeasy.ts"],
  outfile: "dist/speakeasy.cjs",
  bundle: true,
  minify: true,
  treeShaking: true,
  metafile: true,
  target: "node18",
  platform: "node",
});

fs.writeFileSync(
  "dist/speakeasy.json",
  JSON.stringify(speakeasyBuild.metafile, null, 2)
);

const apimaticBuild = await esbuild.build({
  entryPoints: ["apimatic.ts"],
  outfile: "dist/apimatic.cjs",
  bundle: true,
  minify: true,
  treeShaking: true,
  metafile: true,
  target: "node18",
  platform: "node",
});

fs.writeFileSync(
  "dist/apimatic.json",
  JSON.stringify(apimaticBuild.metafile, null, 2)
);
```

Run the `build.js` script:

```bash
node build.ts
```

This generates two bundles, `dist/speakeasy.cjs` and `dist/apimatic.cjs`, along with their respective metafiles.

#### Bundle Size Comparison

Now that we have two bundles, let's compare their sizes.

First, let's look at the size of the `dist/speakeasy.cjs` bundle:

```bash
du -sh dist/speakeasy.cjs
# Output
# 128K    dist/speakeasy.cjs
```

Next, let's look at the size of the `dist/apimatic.cjs` bundle:

```bash
du -sh dist/apimatic.cjs
# Output
# 360K    dist/apimatic.cjs
```

Despite lacking runtime data validation, the bundle built with the SDK generated by APIMatic is significantly larger than that built with the SDK generated by Speakeasy.

We can use the metafiles generated by `esbuild` to analyze the bundle sizes in more detail.

#### Analyzing Bundle Sizes

The metafiles generated by `esbuild` contain detailed information about which source files contribute to each bundle's size, presented as a tree structure.

We used esbuild's online [bundle visualizer](https://esbuild.github.io/analyze/) to analyze the bundle sizes.

Here's a summary of the bundle sizes:

The `dist/speakeasy.cjs` bundle's largest contributor, at 43.4%, is the Zod library used for runtime data validation. The Zod library's tree-shaking capabilities are a work in progress, and future versions of SDKs are expected to have smaller bundle sizes.

![Speakeasy Bundle Size](./assets/speakeasy-bundle-size.png)

The `dist/apimatic.cjs` bundle's largest contributor, at 37.4%, is `mime-db`, a "large database of mime types and information about them" ([mime-db on npm](https://www.npmjs.com/package/mime-db)).

![APIMatic Bundle Size](./assets/apimatic-bundle-size.png)

### Bundling for the Browser

Speakeasy SDKs are designed to work in a range of environments, including the browser. To bundle an SDK for the browser, you can use a tool like `esbuild` or `webpack`.

Here's an example of how to bundle the Speakeasy SDK for the browser using `esbuild`:

```bash
npx esbuild speakeasy.ts --bundle --minify --target=es2020 --platform=browser --outfile=dist/speakeasy.js
```

Doing the same for the APIMatic SDK generates an error, as the SDK is not designed to work in the browser out of the box.

```bash
npx esbuild apimatic.ts --bundle --minify --target=es2020 --platform=browser --outfile=dist/apimatic.js
# ✘ [ERROR] Could not resolve "stream"
```

## Linting and Change Detection

Speakeasy keeps track of changes in your OpenAPI document, and versions the SDKs it creates based on changes.

## Speakeasy Compared to Open-Source Generators

If you are interested in seeing how Speakeasy stacks up against other SDK generation tools, check out our [post](/post/compare-speakeasy-open-source).


 This is the content for the doc blog/speakeasy-vs-fern/index.mdx 

 ---
title: "In depth: Speakeasy vs Fern"
description: "Want to know how Speakeasy and Fern compare? The summary is that Speakeasy supports more language targets for SDK generation, and has a deeper platform for managing API creation. Read on for the details."
image: "/media/speakeasy-vs-fern.png"
date: 2025-02-01
authors:
  - name: Nolan Sullivan
  - image_url: "/media/author-headshots/nolan.jpeg"
tags:

featured_image: "/media/speakeasy-vs-fern.png"
---

import { Callout } from "~/components";

<Callout title="NOTE" variant="info">
  This comparison of Speakeasy and Fern is based on a snapshot of two developing companies as of January 2025. If you think we need to update this post, please let us know!
</Callout>

[Speakeasy](https://www.speakeasy.com/) and [Fern](https://buildwithfern.com/) both offer free and paid services that API developers use to create SDKs (client libraries) and automate SDKs' publication to package managers, but how do they differ? Here's the short answer:

1. **Fern** is an SDK generation tool designed for the Fern domain-specific language (DSL). It creates SDKs in seven languages and API reference documentation.
2. **Speakeasy** is a complete platform for building and exposing enterprise APIs. It is OpenAPI-native and supports SDK generation in ten languages, as well as Terraform providers and documentation.

## How is Speakeasy different?

### Speakeasy is everything you need in one

We've built a platform that does more than merely generate SDKs. You could use Fern for SDKs, Stoplight for documentation, Spectral for linting, and handroll your Terraform provider, or you could use Speakeasy to do it all. One platform, one team, all your API needs handled.

### OpenAPI-native vs OpenAPI-compatible

Speakeasy is designed to be **OpenAPI-native**. We don't believe the world needs another standard for describing APIs. OpenAPI has its flaws, but it's the established standard, and we're committed to making it better. That means that Speakeasy is interoperable with the rest of the API tooling ecosystem. Mix and match us with your other favorite tools, and we'll play nice.

Fern is built on top of a [DSL (domain-specific language)](https://buildwithfern.com/learn/api-definition/fern/overview), with **optional** support for OpenAPI. This makes Fern **OpenAPI-compatible**, meaning your OpenAPI document is no longer the single source of truth for your API.

### Engineering velocity and maturity

Fern's initial GitHub commit was in [April 2022](https://github.com/fern-api/fern/commit/322908f557ee94882ed64f265993ed53ae002198), and the tool has expanded its language support to seven languages since then. By comparison, [Speakeasy's first commit was in September 2022](https://github.com/speakeasy-api/speakeasy/commit/cb126d57ba7ad2ed9c1445a396beb5b48714da80), and the platform has released support for ten languages in a shorter period. 


The Speakeasy platform is also broader, with support for additional generation features not supported by Fern, like [React Hooks](/post/release-react-hooks) and [Terraform providers](/post/release-terraform-v2).


### Speakeasy SDKs work where you need them

Speakeasy SDKs are designed to work in any environment. Speakeasy supports the latest versions of the languages it targets, and we're committed to staying up to date with new releases. Our TypeScript SDKs can be bundled for the browser and many other JavaScript environments, while Fern's are Node.js-only.

Speakeasy gets high-quality products in the hands of our users fast.

## Comparing Speakeasy and Fern

### SDK generation

Everyone has that one odd language that is critically important to their business and seemingly to nobody else's. That's why we're committed to supporting the long tail. We've made a dent, but we've got further to go. Is there a language you need that we don't support? [Let us know](https://github.com/orgs/speakeasy-api/projects/6/views/1)!

| Language           | Speakeasy | Fern |
| ------------------ | --------- | ---- |
| Go                 | ✅        | ✅   |
| Python             | ✅        | ✅   |
| TypeScript         | ✅        | ✅   |
| Java               | ✅        | ✅   |
| C#                 | ✅        | ✅   |
| PHP                | ✅        | ✅   |
| Ruby               | ✅        | ✅   |
| Terraform          | ✅        | ❌   |
| Swift              | ✅        | ❌   |
| Unity              | ✅        | ❌   |

### SDK features

Fern and Speakeasy SDKs differ in two key areas of feature support:

1. Fern lacks native support for some of the more advanced enterprise features supported by Speakeasy. Features like pagination and OAuth are left up to the customer to implement with custom code.
2. Fern offers customizations to the names used in the SDK but not to the fundamental structure of the SDK. In addition to names, Speakeasy allows you to customize details like the directory structure and how parameters are passed into functions.

| Feature                      | Speakeasy | Fern |
|------------------------------|-----------|------|
| Union types                  | ✅         | ✅    |
| Server-side events           | ✅         | ✅    |
| Retries                      | ✅         | ✅    |
| Webhooks                     | ✅         | ✅    |
| Async support                | ✅         | ✅    |
| Custom SDK naming            | ✅         | ✅    |
| Pagination                   | ✅         | ✅    |
| API documentation            | ✅         | ✅    |
| Streaming uploads            | ✅         | ❌    |
| OAuth 2.0                    | ✅         | ❌    |
| React Hooks support          | ✅         | ❌    |
| Caching and state management | ✅         | ❌    |
| Customized SDK structure     | ✅         | ❌    |

### Platform features

The primary differences between the platforms are:

1. Fern is solely focused on the generation of artifacts. Speakeasy has a deeper platform that supports the management of API creation through CLI validation.
2. Speakeasy offers a web interface for managing and monitoring the creation of your SDKs.

| Feature               | Speakeasy | Fern |
| --------------------- | --------- | ---- |
| GitHub CI/CD          | ✅        | ⚠️   |
| CLI                   | ✅        | ✅   |
| Web interface         | ✅        | ❌   |
| Package publishing    | ✅        | ✅   |
| Product documentation | ✅        | ✅   |
| Server stubs          | ❌        | ✅   |
| OpenAPI validation    | ✅        | ❌   |
| OpenAPI Overlays      | ✅        | ❌   |
| AI-powered spec edits | ✅        | ❌   |

⚠️ Fern claims CI/CD support for SDKs on its paid plan, but this feature is not mentioned in the documentation.

### Enterprise support

Speakeasy sets up tracking on all customer repositories and will proactively triage any issues that arise.

| Feature               | Speakeasy | Fern |
| --------------------- | --------- | ---- |
| Concierge onboarding  | ✅        | ✅   |
| Private Slack channel | ✅        | ✅   |
| Enterprise SLAs       | ✅        | ✅   |
| User-issues triage    | ✅        | ❌   |

### Pricing

The biggest difference between the two pricing models is the starter plan. Speakeasy offers one free SDK with unlimited endpoints, while Fern's starter plan is paid.

| Plan       | Speakeasy             | Fern                           |
|------------|-----------------------|--------------------------------|
| Starter    | 1 free published SDK  | $250/mo/SDK; max 50 endpoints  |
| Scaleup    | 1 free + $250/mo/SDK  | ❌                              |
| Business   | 1 free + $600/mo/SDK  | $600/mo/SDK; max 150 endpoints |
| Enterprise | Custom                | Custom                         |


## Fern and Speakeasy walkthrough

Let's walk through generating an SDK with both Fern and Speakeasy. This is well explained in the documentation, so we'll keep it brief.

Both services support Linux, macOS, and Windows, and run in Docker.

Some of the examples below are from the [Speakeasy Bar Starter SDK](https://github.com/speakeasy-sdks/template-speakeasy-bar/).

## Creating SDKs

### Fern quickstart

Follow the [Fern quickstart](https://buildwithfern.com/learn/sdks/getting-started/generate-your-first-sdk).

In the folder containing the `openapi.yaml` file, open a terminal and use Node.js with npm:

```bash
npm install -g fern-api
fern init --openapi ./openapi.yaml;
# will require GitHub login in browser
fern generate
```

- `init` creates a `fern` folder containing a copy of the OpenAPI document and some configuration files.
- `generate` creates SDKs in the folder `../generated`. You can change the output folder by editing `generators.yaml`. We used the following file to create all four languages:

```yaml
default-group: local
groups:
local:
 generators:
 - name: fernapi/fern-typescript-node-sdk
 version: 0.7.2
 output:
 location: local-file-system
 path: ./generated/typescript
 config:
 outputSourceFiles: true # output .ts instead of .js with definitions files
 - name: fernapi/fern-python-sdk
 version: 0.7.2
 output:
 location: local-file-system
 path: ./generated/python
 - name: fernapi/fern-java-sdk
 version: 0.5.15
 output:
 location: local-file-system
 path: ../generated/java
 - name: fernapi/fern-go-sdk
 version: 0.9.2
 output:
 location: local-file-system
 path: ../generated/go
 - name: fernapi/fern-postman
 version: 0.0.45
 output:
 location: local-file-system
 path: ./generated/postman
```

Fern can also generate documentation:

- `init --docs` creates a `docs.yml` configuration file.
- `generate --docs;` creates documentation at the URL specified in the configuration file.

### Speakeasy quickstart

Follow the [Speakeasy quickstart](https://speakeasyapi.dev/docs/speakeasy-cli/getting-started).

The Speakeasy CLI is a single executable file [built with Go](https://github.com/speakeasy-api/speakeasy).

```bash
brew install speakeasy-api/homebrew-tap/speakeasy

speakeasy quickstart
```

- Speakeasy handles authentication with a secret key in an environment variable. You can get the secret key on the Speakeasy website.
- Running the Speakeasy quickstart launches an interactive mode that will guide you through generating an SDK.

## Comparing TypeScript SDK generation with Fern and Speakeasy

Comparing the output of Fern and Speakeasy for all four SDK languages Fern supports would be too long for this article. We'll focus on TypeScript (JavaScript).

### SDK structure

Below is the Fern folder structure.

```bash
├── Client.d.ts
├── Client.js
├── api
│   ├── errors
│   │   ├── BadRequestError.d.ts
│   │   ├── BadRequestError.js
│   │   ├── UnauthorizedError.d.ts
│   │   ├── UnauthorizedError.js
│   │   ├── index.d.ts
│   │   └── index.js
│   ├── index.d.ts
│   ├── index.js
│   ├── resources
│   │   ├── authentication
│   │   │   ├── client
│   │   │   │   ├── Client.d.ts
│   │   │   │   ├── Client.js
│   │   │   │   ├── index.d.ts
│   │   │   │   ├── index.js
│   │   │   │   └── requests
│   │   │   │       ├── LoginRequest.d.ts
│   │   │   │       ├── LoginRequest.js
│   │   │   │       ├── index.d.ts
│   │   │   │       └── index.js
│   │   │   ├── index.d.ts
│   │   │   ├── index.js
│   │   │   └── types
│   │   │       ├── LoginRequestType.d.ts
│   │   │       ├── LoginRequestType.js
│   │   │       ├── LoginResponse.d.ts
│   │   │       ├── LoginResponse.js
│   │   │       ├── index.d.ts
│   │   │       └── index.js
│   │   ├── config
│   │   │   ├── client
│   │   │   │   ├── Client.d.ts
│   │   │   │   ├── Client.js
│   │   │   │   ├── index.d.ts
│   │   │   │   └── index.js
│   │   │   ├── index.d.ts
│   │   │   ├── index.js
│   │   │   └── types
│   │   │       ├── SubscribeToWebhooksRequestItem.d.ts
│   │   │       ├── SubscribeToWebhooksRequestItem.js
│   │   │       ├── index.d.ts
│   │   │       └── index.js
│   │   ├── drinks
│   │   │   ├── client
│   │   │   │   ├── Client.d.ts
│   │   │   │   ├── Client.js
│   │   │   │   ├── index.d.ts
│   │   │   │   ├── index.js
│   │   │   │   └── requests
│   │   │   │       ├── ListDrinksRequest.d.ts
│   │   │   │       ├── ListDrinksRequest.js
│   │   │   │       ├── index.d.ts
│   │   │   │       └── index.js
│   │   │   ├── index.d.ts
│   │   │   └── index.js
│   │   ├── index.d.ts
│   │   ├── index.js
│   │   ├── ingredients
│   │   │   ├── client
│   │   │   │   ├── Client.d.ts
│   │   │   │   ├── Client.js
│   │   │   │   ├── index.d.ts
│   │   │   │   ├── index.js
│   │   │   │   └── requests
│   │   │   │       ├── ListIngredientsRequest.d.ts
│   │   │   │       ├── ListIngredientsRequest.js
│   │   │   │       ├── index.d.ts
│   │   │   │       └── index.js
│   │   │   ├── index.d.ts
│   │   │   └── index.js
│   │   └── orders
│   │       ├── client
│   │       │   ├── Client.d.ts
│   │       │   ├── Client.js
│   │       │   ├── index.d.ts
│   │       │   ├── index.js
│   │       │   └── requests
│   │       │       ├── CreateOrderRequest.d.ts
│   │       │       ├── CreateOrderRequest.js
│   │       │       ├── index.d.ts
│   │       │       └── index.js
│   │       ├── index.d.ts
│   │       └── index.js
│   └── types
│       ├── ApiError.d.ts
│       ├── ApiError.js
│       ├── BadRequest.d.ts
│       ├── BadRequest.js
│       ├── Drink.d.ts
│       ├── Drink.js
│       ├── DrinkType.d.ts
│       ├── DrinkType.js
│       ├── Error_.d.ts
│       ├── Error_.js
│       ├── Ingredient.d.ts
│       ├── Ingredient.js
│       ├── IngredientType.d.ts
│       ├── IngredientType.js
│       ├── Order.d.ts
│       ├── Order.js
│       ├── OrderStatus.d.ts
│       ├── OrderStatus.js
│       ├── OrderType.d.ts
│       ├── OrderType.js
│       ├── index.d.ts
│       └── index.js
├── core
│   ├── fetcher
│   │   ├── APIResponse.d.ts
│   │   ├── APIResponse.js
│   │   ├── Fetcher.d.ts
│   │   ├── Fetcher.js
│   │   ├── Supplier.d.ts
│   │   ├── Supplier.js
│   │   ├── createRequestUrl.d.ts
│   │   ├── createRequestUrl.js
│   │   ├── getFetchFn.d.ts
│   │   ├── getFetchFn.js
│   │   ├── getHeader.d.ts
│   │   ├── getHeader.js
│   │   ├── getRequestBody.d.ts
│   │   ├── getRequestBody.js
│   │   ├── getResponseBody.d.ts
│   │   ├── getResponseBody.js
│   │   ├── index.d.ts
│   │   ├── index.js
│   │   ├── makeRequest.d.ts
│   │   ├── makeRequest.js
│   │   ├── requestWithRetries.d.ts
│   │   ├── requestWithRetries.js
│   │   ├── signals.d.ts
│   │   ├── signals.js
│   │   └── stream-wrappers
│   │       ├── Node18UniversalStreamWrapper.d.ts
│   │       ├── Node18UniversalStreamWrapper.js
│   │       ├── NodePre18StreamWrapper.d.ts
│   │       ├── NodePre18StreamWrapper.js
│   │       ├── UndiciStreamWrapper.d.ts
│   │       ├── UndiciStreamWrapper.js
│   │       ├── chooseStreamWrapper.d.ts
│   │       └── chooseStreamWrapper.js
│   ├── index.d.ts
│   ├── index.js
│   ├── runtime
│   │   ├── index.d.ts
│   │   ├── index.js
│   │   ├── runtime.d.ts
│   │   └── runtime.js
│   └── schemas
│       ├── Schema.d.ts
│       ├── Schema.js
│       ├── builders
│       │   ├── date
│       │   │   ├── date.d.ts
│       │   │   ├── date.js
│       │   │   ├── index.d.ts
│       │   │   └── index.js
│       │   ├── enum
│       │   │   ├── enum.d.ts
│       │   │   ├── enum.js
│       │   │   ├── index.d.ts
│       │   │   └── index.js
│       │   ├── index.d.ts
│       │   ├── index.js
│       │   ├── lazy
│       │   │   ├── index.d.ts
│       │   │   ├── index.js
│       │   │   ├── lazy.d.ts
│       │   │   ├── lazy.js
│       │   │   ├── lazyObject.d.ts
│       │   │   └── lazyObject.js
│       │   ├── list
│       │   │   ├── index.d.ts
│       │   │   ├── index.js
│       │   │   ├── list.d.ts
│       │   │   └── list.js
│       │   ├── literals
│       │   │   ├── booleanLiteral.d.ts
│       │   │   ├── booleanLiteral.js
│       │   │   ├── index.d.ts
│       │   │   ├── index.js
│       │   │   ├── stringLiteral.d.ts
│       │   │   └── stringLiteral.js
│       │   ├── object
│       │   │   ├── index.d.ts
│       │   │   ├── index.js
│       │   │   ├── object.d.ts
│       │   │   ├── object.js
│       │   │   ├── objectWithoutOptionalProperties.d.ts
│       │   │   ├── objectWithoutOptionalProperties.js
│       │   │   ├── property.d.ts
│       │   │   ├── property.js
│       │   │   ├── types.d.ts
│       │   │   └── types.js
│       │   ├── object-like
│       │   │   ├── getObjectLikeUtils.d.ts
│       │   │   ├── getObjectLikeUtils.js
│       │   │   ├── index.d.ts
│       │   │   ├── index.js
│       │   │   ├── types.d.ts
│       │   │   └── types.js
│       │   ├── primitives
│       │   │   ├── any.d.ts
│       │   │   ├── any.js
│       │   │   ├── boolean.d.ts
│       │   │   ├── boolean.js
│       │   │   ├── index.d.ts
│       │   │   ├── index.js
│       │   │   ├── number.d.ts
│       │   │   ├── number.js
│       │   │   ├── string.d.ts
│       │   │   ├── string.js
│       │   │   ├── unknown.d.ts
│       │   │   └── unknown.js
│       │   ├── record
│       │   │   ├── index.d.ts
│       │   │   ├── index.js
│       │   │   ├── record.d.ts
│       │   │   ├── record.js
│       │   │   ├── types.d.ts
│       │   │   └── types.js
│       │   ├── schema-utils
│       │   │   ├── JsonError.d.ts
│       │   │   ├── JsonError.js
│       │   │   ├── ParseError.d.ts
│       │   │   ├── ParseError.js
│       │   │   ├── getSchemaUtils.d.ts
│       │   │   ├── getSchemaUtils.js
│       │   │   ├── index.d.ts
│       │   │   ├── index.js
│       │   │   ├── stringifyValidationErrors.d.ts
│       │   │   └── stringifyValidationErrors.js
│       │   ├── set
│       │   │   ├── index.d.ts
│       │   │   ├── index.js
│       │   │   ├── set.d.ts
│       │   │   └── set.js
│       │   ├── undiscriminated-union
│       │   │   ├── index.d.ts
│       │   │   ├── index.js
│       │   │   ├── types.d.ts
│       │   │   ├── types.js
│       │   │   ├── undiscriminatedUnion.d.ts
│       │   │   └── undiscriminatedUnion.js
│       │   └── union
│       │       ├── discriminant.d.ts
│       │       ├── discriminant.js
│       │       ├── index.d.ts
│       │       ├── index.js
│       │       ├── types.d.ts
│       │       ├── types.js
│       │       ├── union.d.ts
│       │       └── union.js
│       ├── index.d.ts
│       ├── index.js
│       └── utils
│           ├── MaybePromise.d.ts
│           ├── MaybePromise.js
│           ├── addQuestionMarksToNullableProperties.d.ts
│           ├── addQuestionMarksToNullableProperties.js
│           ├── createIdentitySchemaCreator.d.ts
│           ├── createIdentitySchemaCreator.js
│           ├── entries.d.ts
│           ├── entries.js
│           ├── filterObject.d.ts
│           ├── filterObject.js
│           ├── getErrorMessageForIncorrectType.d.ts
│           ├── getErrorMessageForIncorrectType.js
│           ├── isPlainObject.d.ts
│           ├── isPlainObject.js
│           ├── keys.d.ts
│           ├── keys.js
│           ├── maybeSkipValidation.d.ts
│           ├── maybeSkipValidation.js
│           ├── partition.d.ts
│           └── partition.js
├── environments.d.ts
├── environments.js
├── errors
│   ├── NdimaresApiError.d.ts
│   ├── NdimaresApiError.js
│   ├── NdimaresApiTimeoutError.d.ts
│   ├── NdimaresApiTimeoutError.js
│   ├── index.d.ts
│   └── index.js
├── index.d.ts
├── index.js
└── serialization
    ├── index.d.ts
    ├── index.js
    ├── resources
    │   ├── authentication
    │   │   ├── client
    │   │   │   ├── index.d.ts
    │   │   │   ├── index.js
    │   │   │   └── requests
    │   │   │       ├── LoginRequest.d.ts
    │   │   │       ├── LoginRequest.js
    │   │   │       ├── index.d.ts
    │   │   │       └── index.js
    │   │   ├── index.d.ts
    │   │   ├── index.js
    │   │   └── types
    │   │       ├── LoginRequestType.d.ts
    │   │       ├── LoginRequestType.js
    │   │       ├── LoginResponse.d.ts
    │   │       ├── LoginResponse.js
    │   │       ├── index.d.ts
    │   │       └── index.js
    │   ├── config
    │   │   ├── client
    │   │   │   ├── index.d.ts
    │   │   │   ├── index.js
    │   │   │   ├── subscribeToWebhooks.d.ts
    │   │   │   └── subscribeToWebhooks.js
    │   │   ├── index.d.ts
    │   │   ├── index.js
    │   │   └── types
    │   │       ├── SubscribeToWebhooksRequestItem.d.ts
    │   │       ├── SubscribeToWebhooksRequestItem.js
    │   │       ├── index.d.ts
    │   │       └── index.js
    │   ├── drinks
    │   │   ├── client
    │   │   │   ├── index.d.ts
    │   │   │   ├── index.js
    │   │   │   ├── listDrinks.d.ts
    │   │   │   └── listDrinks.js
    │   │   ├── index.d.ts
    │   │   └── index.js
    │   ├── index.d.ts
    │   ├── index.js
    │   ├── ingredients
    │   │   ├── client
    │   │   │   ├── index.d.ts
    │   │   │   ├── index.js
    │   │   │   ├── listIngredients.d.ts
    │   │   │   └── listIngredients.js
    │   │   ├── index.d.ts
    │   │   └── index.js
    │   └── orders
    │       ├── client
    │       │   ├── createOrder.d.ts
    │       │   ├── createOrder.js
    │       │   ├── index.d.ts
    │       │   └── index.js
    │       ├── index.d.ts
    │       └── index.js
    └── types
        ├── ApiError.d.ts
        ├── ApiError.js
        ├── BadRequest.d.ts
        ├── BadRequest.js
        ├── Drink.d.ts
        ├── Drink.js
        ├── DrinkType.d.ts
        ├── DrinkType.js
        ├── Error_.d.ts
        ├── Error_.js
        ├── Ingredient.d.ts
        ├── Ingredient.js
        ├── IngredientType.d.ts
        ├── IngredientType.js
        ├── Order.d.ts
        ├── Order.js
        ├── OrderStatus.d.ts
        ├── OrderStatus.js
        ├── OrderType.d.ts
        ├── OrderType.js
        ├── index.d.ts
        └── index.js
```

Below is the Speakeasy folder structure.

```bash
├── CONTRIBUTING.md
├── FUNCTIONS.md
├── README.md
├── RUNTIMES.md
├── USAGE.md
├── docs
│   ├── lib
│   │   └── utils
│   │       └── retryconfig.md
│   ├── models
│   │   ├── callbacks
│   │   │   └── createorderorderupdaterequestbody.md
│   │   ├── components
│   │   │   ├── drink.md
│   │   │   ├── drinktype.md
│   │   │   ├── errort.md
│   │   │   ├── ingredient.md
│   │   │   ├── ingredienttype.md
│   │   │   ├── order.md
│   │   │   ├── ordertype.md
│   │   │   ├── security.md
│   │   │   └── status.md
│   │   ├── errors
│   │   │   ├── apierror.md
│   │   │   └── badrequest.md
│   │   ├── operations
│   │   │   ├── createorderrequest.md
│   │   │   ├── createorderresponse.md
│   │   │   ├── getdrinkrequest.md
│   │   │   ├── getdrinkresponse.md
│   │   │   ├── listdrinksrequest.md
│   │   │   ├── listdrinksresponse.md
│   │   │   ├── listdrinkssecurity.md
│   │   │   ├── listingredientsrequest.md
│   │   │   ├── listingredientsresponse.md
│   │   │   ├── loginrequestbody.md
│   │   │   ├── loginresponse.md
│   │   │   ├── loginresponsebody.md
│   │   │   ├── loginsecurity.md
│   │   │   ├── requestbody.md
│   │   │   ├── type.md
│   │   │   └── webhook.md
│   │   └── webhooks
│   │       └── stockupdaterequestbody.md
│   └── sdks
│       ├── authentication
│       │   └── README.md
│       ├── config
│       │   └── README.md
│       ├── drinks
│       │   └── README.md
│       ├── ingredients
│       │   └── README.md
│       ├── orders
│       │   └── README.md
│       └── sdk
│           └── README.md
├── jsr.json
├── package.json
├── src
│   ├── core.ts
│   ├── funcs
│   │   ├── authenticationLogin.ts
│   │   ├── configSubscribeToWebhooks.ts
│   │   ├── drinksGetDrink.ts
│   │   ├── drinksListDrinks.ts
│   │   ├── ingredientsListIngredients.ts
│   │   └── ordersCreateOrder.ts
│   ├── hooks
│   │   ├── hooks.ts
│   │   ├── index.ts
│   │   ├── registration.ts
│   │   └── types.ts
│   ├── index.ts
│   ├── lib
│   │   ├── base64.ts
│   │   ├── config.ts
│   │   ├── dlv.ts
│   │   ├── encodings.ts
│   │   ├── files.ts
│   │   ├── http.ts
│   │   ├── is-plain-object.ts
│   │   ├── logger.ts
│   │   ├── matchers.ts
│   │   ├── primitives.ts
│   │   ├── retries.ts
│   │   ├── schemas.ts
│   │   ├── sdks.ts
│   │   ├── security.ts
│   │   └── url.ts
│   ├── models
│   │   ├── callbacks
│   │   │   ├── createorder.ts
│   │   │   └── index.ts
│   │   ├── components
│   │   │   ├── drink.ts
│   │   │   ├── drinkinput.ts
│   │   │   ├── drinktype.ts
│   │   │   ├── error.ts
│   │   │   ├── index.ts
│   │   │   ├── ingredient.ts
│   │   │   ├── ingredientinput.ts
│   │   │   ├── ingredienttype.ts
│   │   │   ├── order.ts
│   │   │   ├── orderinput.ts
│   │   │   ├── ordertype.ts
│   │   │   └── security.ts
│   │   ├── errors
│   │   │   ├── apierror.ts
│   │   │   ├── badrequest.ts
│   │   │   ├── httpclienterrors.ts
│   │   │   ├── index.ts
│   │   │   ├── sdkerror.ts
│   │   │   └── sdkvalidationerror.ts
│   │   ├── operations
│   │   │   ├── createorder.ts
│   │   │   ├── getdrink.ts
│   │   │   ├── index.ts
│   │   │   ├── listdrinks.ts
│   │   │   ├── listingredients.ts
│   │   │   ├── login.ts
│   │   │   └── subscribetowebhooks.ts
│   │   └── webhooks
│   │       ├── index.ts
│   │       └── stockupdate.ts
│   ├── sdk
│   │   ├── authentication.ts
│   │   ├── config.ts
│   │   ├── drinks.ts
│   │   ├── index.ts
│   │   ├── ingredients.ts
│   │   ├── orders.ts
│   │   └── sdk.ts
│   └── types
│       ├── blobs.ts
│       ├── constdatetime.ts
│       ├── enums.ts
│       ├── fp.ts
│       ├── index.ts
│       ├── operations.ts
│       ├── rfcdate.ts
│       └── streams.ts
└── tsconfig.json
```

Speakeasy includes a documentation folder next to the SDK folder.

Speakeasy creates a complete npm package, with a `package.json` file, that is ready to be published to the npm registry. With Fern, you have to do extra work to prepare for publishing.

The structure of the SDK also has some bearing on the DevEx. To call order functions in the SDKs, you would use `api/resources/orders/Client.js` in Fern and `src/sdk/orders.ts` in Speakeasy.

### Example SDK method

Let's take a look at the code for a single call, `createOrder`, in Fern and Speakeasy.

<div className="md:flex gap-10">
  <div className="md:w-1/2">
```ts fern-example/createOrder.ts

/**
 * Create an order for a drink.
 */
createOrder(request, requestOptions) {
    var _a;
    return __awaiter(this, void 0, void 0, function* () {
        const { callbackUrl, body: _body } = request;
        const _queryParams = new url_search_params_1.default();
        if (callbackUrl != null) {
            _queryParams.append("callback_url", callbackUrl);
        }
        const _response = yield core.fetcher({
            url: (0, url_join_1.default)((_a = (yield core.Supplier.get(this._options.environment))) !== null && _a !== void 0 ? _a : environments.NdimaresApiEnvironment.Default, "order"),
            method: "POST",
            headers: {
                Authorization: yield this._getAuthorizationHeader(),
                "X-Fern-Language": "JavaScript",
            },
            contentType: "application/json",
            queryParameters: _queryParams,
            body: yield serializers.orders.createOrder.Request.jsonOrThrow(_body, { unrecognizedObjectKeys: "strip" }),
            timeoutMs: (requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.timeoutInSeconds) != null ? requestOptions.timeoutInSeconds * 1000 : 60000,
        });
        if (_response.ok) {
            return yield serializers.Order.parseOrThrow(_response.body, {
                unrecognizedObjectKeys: "passthrough",
                allowUnrecognizedUnionMembers: true,
                allowUnrecognizedEnumValues: true,
                breadcrumbsPrefix: ["response"],
            });
        }
        if (_response.error.reason === "status-code") {
            throw new errors.NdimaresApiError({
                statusCode: _response.error.statusCode,
                body: _response.error.body,
            });
        }
        switch (_response.error.reason) {
            case "non-json":
                throw new errors.NdimaresApiError({
                    statusCode: _response.error.statusCode,
                    body: _response.error.rawBody,
                });
            case "timeout":
                throw new errors.NdimaresApiTimeoutError();
            case "unknown":
                throw new errors.NdimaresApiError({
                    message: _response.error.errorMessage,
                });
        }
    });
}
```

    </div>


  <div className="md:w-1/2">
```ts speakeasy-example/createOrder.ts
/**
 * Create an order.
 *
 * @remarks
 * Create an order for a drink.
 */
export async function ordersCreateOrder(
    client$: SDKCore,
    request: operations.CreateOrderRequest,
    options?: RequestOptions
): Promise<
    Result<
        operations.CreateOrderResponse,
        | errors.APIError
        | SDKError
        | SDKValidationError
        | UnexpectedClientError
        | InvalidRequestError
        | RequestAbortedError
        | RequestTimeoutError
        | ConnectionError
    >
> {
    const input$ = request;

    const parsed$ = schemas$.safeParse(
        input$,
        (value$) => operations.CreateOrderRequest$outboundSchema.parse(value$),
        "Input validation failed"
    );
    if (!parsed$.ok) {
        return parsed$;
    }
    const payload$ = parsed$.value;
    const body$ = encodeJSON$("body", payload$.RequestBody, { explode: true });

    const path$ = pathToFunc("/order")();

    const query$ = encodeFormQuery$({
        callback_url: payload$.callback_url,
    });

    const headers$ = new Headers({
        "Content-Type": "application/json",
        Accept: "application/json",
    });

    const security$ = await extractSecurity(client$.options$.security);
    const context = {
        operationID: "createOrder",
        oAuth2Scopes: [],
        securitySource: client$.options$.security,
    };
    const securitySettings$ = resolveGlobalSecurity(security$);

    const requestRes = client$.createRequest$(
        context,
        {
            security: securitySettings$,
            method: "POST",
            path: path$,
            headers: headers$,
            query: query$,
            body: body$,
            timeoutMs: options?.timeoutMs || client$.options$.timeoutMs || -1,
        },
        options
    );
    if (!requestRes.ok) {
        return requestRes;
    }
    const request$ = requestRes.value;

    const doResult = await client$.do$(request$, {
        context,
        errorCodes: ["4XX", "5XX"],
        retryConfig: options?.retries || client$.options$.retryConfig,
        retryCodes: options?.retryCodes || ["429", "500", "502", "503", "504"],
    });
    if (!doResult.ok) {
        return doResult;
    }
    const response = doResult.value;

    const responseFields$ = {
        HttpMeta: { Response: response, Request: request$ },
    };

    const [result$] = await m$.match<
        operations.CreateOrderResponse,
        | errors.APIError
        | SDKError
        | SDKValidationError
        | UnexpectedClientError
        | InvalidRequestError
        | RequestAbortedError
        | RequestTimeoutError
        | ConnectionError
    >(
        m$.json(200, operations.CreateOrderResponse$inboundSchema),
        m$.fail("4XX"),
        m$.jsonErr("5XX", errors.APIError$inboundSchema),
        m$.json("default", operations.CreateOrderResponse$inboundSchema)
    )(response, { extraFields: responseFields$ });
    if (!result$.ok) {
        return result$;
    }

    return result$;
}
```

    </div>
</div>

### Type safety

Both Fern and Speakeasy ensure that, if the input is incorrect, the SDK will throw an error instead of silently giving you incorrect data.

Fern uses a custom data serialization validator to validate every object received by your SDK from the server. See an example of this in `api/resources/pet/client/Client.ts`, where the line `return await serializers.Pet.parseOrThrow(_response.body, {` calls into the `core/schemas/builders` code.

Speakeasy uses [Zod](https://github.com/colinhacks/zod), an open-source validator, eliminating the need for custom serialization code.

### File streaming

Streaming file transmission allows servers and clients to do gradual processing, which is useful for playing videos or transforming long text files.

Fern [supports file streaming](https://buildwithfern.com/learn/api-definition/openapi/streaming-and-sse) but with the use of a proprietary endpoint extension, `x-fern-streaming: true`.

Speakeasy supports the [Streams API](https://developer.mozilla.org/en-US/docs/Web/API/Streams_API) web standard automatically. You can use code like the following to upload and download large files:

```js
const fileHandle = await openAsBlob("./src/sample.txt");
const result = await sdk.upload({ file: fileHandle });
```


### React Hooks

React Hooks simplify state and data management in React apps, enabling developers to consume APIs more efficiently.

Fern does not support React Hooks natively. Developers must manually integrate SDK methods into state management tools like React Context, Redux, or TanStack Query.

Speakeasy generates built-in React Hooks using [TanStack Query](https://tanstack.com/query/latest). These hooks provide features like intelligent caching, type safety, pagination, and seamless integration with modern React patterns such as SSR and Suspense.

Here's an example:

```typescript example/loadPosts.tsx
import { useQuery } from "@tanstack/react-query";

function Posts() {
  const { data, status, error } = useQuery([
    "posts" // Cache key for the query
  ], async () => {
    const response = await fetch("https://jsonplaceholder.typicode.com/posts");
    return response.json();
  });

  if (status === "loading") return <p>Loading posts...</p>;
  if (status === "error") return <p>Error: {error?.message}</p>;

  return (
    <ul>
      {data.map((post) => (
        <li key={post.id}>{post.title}</li>
      ))}
    </ul>
  );
}
```

In this example, the `useQuery` hook fetches data from an API endpoint. The cache key ensures unique identification of the query. The `status` variable provides the current state of the query: `loading`, `error`, or `success`. Depending on the query status, the component renders `loading`, `error`, or the fetched data as a list.

#### Auto-pagination

Speakeasy's React Hooks also enable auto-pagination, which automatically fetches more data when the user scrolls to the bottom of the page. This feature is useful for infinite scrolling in social media feeds or search results.

```typescript example/PostsView.tsx
import { useInView } from "react-intersection-observer";

import { useActorAuthorFeedInfinite } from "@speakeasy-api/bluesky/react-query/actorAuthorFeed.js";

export function PostsView(props: { did: string }) {
  const { data, fetchNextPage, hasNextPage } = useActorAuthorFeedInfinite({
    actor: props.did,
  });

  const { ref } = useInView({
    rootMargin: "50px",
    onChange(inView) {
      if (inView) { fetchNextPage(); }
    },
  });

  return (
    <div>
      <ul className="space-y-4">
        {data?.pages.flatMap((page) => {
          return page.result.feed.map((entry) => (
            <li key={entry.post.cid}>
              <FeedEntry entry={entry.post} />
            </li>
          ));
        })}
      </ul>
      {hasNextPage ? <div ref={ref} /> : null}
    </div>
  );
```

Fern also supports pagination, but only offset- and cursor-based pagination, and these require additional configuration.

For an in-depth look at how Speakeasy uses React Hooks, see our [official release article](https://www.speakeasy.com/post/release-react-hooks).

### Webhooks support

Webhooks enable users to receive real-time updates from your API through HTTP callbacks in your SDK. Both Speakeasy and Fern generate SDKs that support webhooks and provide built-in support for webhook validation, payload parsing, and delivery.

However, the way the platforms handle webhooks differs slightly. Speakeasy provides a higher-level abstraction that includes validation and event type inference, whereas Fern requires manual event handling after signature verification.

We'll use an example bookstore API to demonstrate how both SDKs handle webhooks.

First we'll look at the OpenAPI definition for the webhook:

```yaml
openapi: 3.1.1
paths:
  ...
x-speakeasy-webhooks:
  security:
    type: signature # a preset which signs the request body with HMAC
    name: x-signature # the name of the header
    encoding: base64 # encoding of the signature in the header
    algorithm: hmac-sha256
webhooks:
  book.created:
    post:
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              properties:
                id:
                  type: string
                title:
                  type: string
              required:
                - id
                - title
    responses:
      '200':
        description: Book creation event received
  book.deleted:
    ...
```

Here's how you would handle the webhook using the SDKs:

<div className="md:flex gap-10">
  <div className="md:w-1/2">
    ```typescript speakeasy-example/webhook.ts
    // techbooks-speakeasy SDK created by Speakeasy
    import { TechBooks } from "techbooks-speakeasy";

    const bookStore = new TechBooks();

    async function handleWebhook(request: Request) {
      const secret = "my-webhook-secret";

      const res = await bookStore.webhooks.validateWebhook({ request, secret }); 

      if (res.error) {
        console.error("Webhook validation failed:", res.error);
        throw new Error("Invalid webhook signature");
      }

      // Speakeasy provides type inference and payload parsing
      const { data, inferredType } = res;

      switch (data.type) {
        case "book.created":
          console.log("New Book Created:", data.title);
          break;
        case "book.deleted":
          console.log("Book Deleted:", data.title);
          break;
        default:
          console.warn(`Unhandled event type: ${inferredType}`);
      }
    }
    ```
  </div>
  <div className="md:w-1/2">
    ```typescript fern-example/webhook.ts
    // techbooks-fern SDK created by Fern
    import FernClient from 'fern-sdk';

    const client = new FernClient();

    async function handleWebhook(req) {
      try {
        const payload = client.webhooks.constructEvent({
          body: req.body,
          signature: req.headers['x-imdb-signature'],
          secret: process.env.WEBHOOK_SECRET
        });

        if (payload.type === "book.created") {
          console.log("New Book Created:", payload.title);
        } else if (payload.type === "book.deleted") {
          console.log("Book Deleted:", payload.title);
        } else {
          console.warn(`Unhandled event type: ${payload.type}`);
        }
      } catch (error) {
        console.error("Webhook validation failed:", error);
        throw new Error("Invalid webhook signature");
      }
    }
    ```
  </div>
</div>


You can read more about how Speakeasy handles webhooks in our [webhooks release post](/post/release-webhooks-support).




### OAuth client credentials handling 

<Callout title="NOTE" variant="info">
  OAuth 2.0 client handling is only available on Fern's paid plans. Speakeasy supports OAuth 2.0 client credentials on all plans.
</Callout>

Both Speakeasy and Fern generate SDKs that handle OAuth 2.0 with client credentials, offering similar functionality in managing the token lifecycle and authentication processes.

Our bookstore API requires an OAuth 2.0 token with client credentials to access the API. Let's see how the SDKs handle this.

Consider the following OAuth 2.0 configuration from the OpenAPI document:

```yaml
components:
  securitySchemes:
    OAuth2:
      type: oauth2
      flows:
        clientCredentials:
          tokenUrl: https://api.bookstore.com/oauth/token
          scopes:
            write: Grants write access
            read: Grants read access
```

Let's look at how you can use the SDKs to create a new book in the bookstore API and how to handle OAuth 2.0 authentication.

<div className="md:flex gap-10">
  <div className="md:w-1/2">
    ```typescript example/techbooks-speakeasy.ts
    import { TechBooks } from "techbooks-speakeasy";

    const bookStore = new TechBooks({
      security: {
        // OAuth 2.0 client credentials
        clientID: "<YOUR_CLIENT_ID_HERE>",
        clientSecret: "<YOUR_CLIENT_SECRET_HERE>",
      },
    });
    
    async function run() {
      // The SDK handles the token lifecycle, retries, and error handling for you
      await bookStore.books.addBook({
        // Book object
      });
    }

    run();
    ```
  </div>

  <div className="md:w-1/2">
    ```typescript example/techbooks-fern.ts
    import FernClient from 'fern-sdk';

    const client = new FernClient({
      clientId: '<YOUR_CLIENT_ID_HERE>',
      clientSecret: '<YOUR_CLIENT_SECRET_HERE>',
    });

    async function run() {
      await client.books.addBook({
        // Book object
      });
    }

    run();
    ```
  </div>
</div>

Both Speakeasy and Fern SDKs handle OAuth 2.0 automatically – you provide credentials when creating the client, and the SDK manages token lifecycle, refreshes, and errors for you without additional manual handling.


## Fern-generated SDK case study: Cohere TypeScript

Let's take a closer look at a real-world SDK generated by Fern for a more complete view of Fern's SDK generation. We inspected the [Cohere TypeScript SDK](https://github.com/cohere-ai/cohere-typescript) and here's what we found.

### SDK structure

The Cohere SDK's repository is deeply nested, reminiscent of older Java codebases. This may reflect the generator's codebase, or it may be due to the generator's templates being designed by developers who aren't TypeScript specialists.

There is a separation between core SDK code and API-specific code such as models and request methods, but internal SDK tools that hide behind layers of abstraction are not marked clearly as internal. This can lead to breaking changes in users' applications in the future.

Speakeasy addresses these problems by clearly separating core internal code into separate files, or marking individual code blocks as clearly as possible for internal use. Repository structure and comments follow the best practices for each SDK's target platform, as designed by specialists in each platform.

### Data validation libraries

Both Speakeasy and Fern generate SDKs that feature runtime data validation. We've observed that Speakeasy uses Zod, a popular and thoroughly tested data validation and schema declaration library.

The Cohere TypeScript SDK, on the other hand, uses a custom Zod-like type-checking library, which ships as part of the SDK. Using a hand-rolled type library is a questionable practice for various reasons.

Firstly, it ships type inference code as part of the SDK, which adds significant complexity.

Here's an example of [date type inference](https://github.com/cohere-ai/cohere-typescript/blob/30ac11173e374e66310184834831cc5fca2256fc/src/core/schemas/builders/date/date.ts#L6-L8) using complex regular expression copied from Stack Overflow.

```typescript src/core/schemas/builders/date/date.ts
// !focus(6:8)
import { BaseSchema, Schema, SchemaType } from "../../Schema";
import { getErrorMessageForIncorrectType } from "../../utils/getErrorMessageForIncorrectType";
import { maybeSkipValidation } from "../../utils/maybeSkipValidation";
import { getSchemaUtils } from "../schema-utils";

// https://stackoverflow.com/questions/12756159/regex-and-iso8601-formatted-datetime
const ISO_8601_REGEX =
    /^([+-]?\d{4}(?!\d{2}\b))((-?)((0[1-9]|1[0-2])(\3([12]\d|0[1-9]|3[01]))?|W([0-4]\d|5[0-2])(-?[1-7])?|(00[1-9]|0[1-9]\d|[12]\d{2}|3([0-5]\d|6[1-6])))([T\s]((([01]\d|2[0-3])((:?)[0-5]\d)?|24:?00)([.,]\d+(?!:))?)?(\17[0-5]\d([.,]\d+)?)?([zZ]|([+-])([01]\d|2[0-3]):?([0-5]\d)?)?)?)?$/;
```

While Zod uses a similar regex-based approach to dates under the hood, we know that Zod's types and methods are widely used, tested by thousands of brilliant teams each day, and are supported by stellar [documentation](https://zod.dev/?id=dates).

Furthermore, using Zod in SDKs created by Speakeasy allows users to include Zod as an external library when bundling their applications. This is what Speakeasy encourages, by including Zod as a peer dependency to the SDK.

A hand-rolled type library will almost certainly lead to safety issues that are challenging to debug and impossible to find answers for from other developers, as there is no community support.

### Documentation

Apart from a short README, the Cohere TypeScript SDK does not include any documentation. This is in stark contrast to SDKs created by Speakeasy, which contain copy-paste usage examples for all methods and documentation for each model. Speakeasy SDKs are also supported by Zod's detailed and clear documentation regarding types and validation.

### Readability

SDK method bodies in the Cohere SDK are extremely long, unclear, and contain repeated verbose response-matching code. As a result, methods are difficult to read and understand at a glance.

Response matching in SDK methods involves long switch statements that are repeated in each method. The snippet below from the Cohere SDK is repeated multiple times.

```typescript src/Client.ts
        // ...
        if (_response.error.reason === "status-code") {
            switch (_response.error.statusCode) {
                case 400:
                    throw new Cohere.BadRequestError(_response.error.body);
                case 401:
                    throw new Cohere.UnauthorizedError(_response.error.body);
                case 403:
                    throw new Cohere.ForbiddenError(_response.error.body);
                case 404:
                    throw new Cohere.NotFoundError(_response.error.body);
                case 422:
                    throw new Cohere.UnprocessableEntityError(
                        await serializers.UnprocessableEntityErrorBody.parseOrThrow(_response.error.body, {
                            unrecognizedObjectKeys: "passthrough",
                            allowUnrecognizedUnionMembers: true,
                            allowUnrecognizedEnumValues: true,
                            skipValidation: true,
                            breadcrumbsPrefix: ["response"],
                        })
                    );
                case 429:
                    throw new Cohere.TooManyRequestsError(
                        await serializers.TooManyRequestsErrorBody.parseOrThrow(_response.error.body, {
                            unrecognizedObjectKeys: "passthrough",
                            allowUnrecognizedUnionMembers: true,
                            allowUnrecognizedEnumValues: true,
                            skipValidation: true,
                            breadcrumbsPrefix: ["response"],
                        })
                    );
                case 499:
                    throw new Cohere.ClientClosedRequestError(
                        await serializers.ClientClosedRequestErrorBody.parseOrThrow(_response.error.body, {
                            unrecognizedObjectKeys: "passthrough",
                            allowUnrecognizedUnionMembers: true,
                            allowUnrecognizedEnumValues: true,
                            skipValidation: true,
                            breadcrumbsPrefix: ["response"],
                        })
                    );
                case 500:
                    throw new Cohere.InternalServerError(_response.error.body);
                case 501:
                    throw new Cohere.NotImplementedError(
                        await serializers.NotImplementedErrorBody.parseOrThrow(_response.error.body, {
                            unrecognizedObjectKeys: "passthrough",
                            allowUnrecognizedUnionMembers: true,
                            allowUnrecognizedEnumValues: true,
                            skipValidation: true,
                            breadcrumbsPrefix: ["response"],
                        })
                    );
                case 503:
                    throw new Cohere.ServiceUnavailableError(_response.error.body);
                case 504:
                    throw new Cohere.GatewayTimeoutError(
                        await serializers.GatewayTimeoutErrorBody.parseOrThrow(_response.error.body, {
                            unrecognizedObjectKeys: "passthrough",
                            allowUnrecognizedUnionMembers: true,
                            allowUnrecognizedEnumValues: true,
                            skipValidation: true,
                            breadcrumbsPrefix: ["response"],
                        })
                    );
                default:
                    throw new errors.CohereError({
                        statusCode: _response.error.statusCode,
                        body: _response.error.body,
                    });
            }
        }

        switch (_response.error.reason) {
            case "non-json":
                throw new errors.CohereError({
                    statusCode: _response.error.statusCode,
                    body: _response.error.rawBody,
                });
            case "timeout":
                throw new errors.CohereTimeoutError();
            case "unknown":
                throw new errors.CohereError({
                    message: _response.error.errorMessage,
                });
        }
        // ...
```

By contrast, Speakeasy creates SDKs with improved readability by breaking SDK functionality into smaller, more focused methods, without hiding important steps behind multiple layers of abstraction.

### Open enums

Both Speakeasy and Fern generate SDKs that allow users to pass unknown values in fields that are defined as enums if the SDK is configured to do so. This is useful to keep legacy SDKs working when an API changes.

However, where Speakeasy SDKs clearly mark unknown enum values by wrapping them in an `Unrecognized` type, SDKs generated by Fern use a type assertion. By not marking unrecognized enum values as such, Fern undermines the type safety TypeScript users rely on.

Consider the following OpenAPI component:

```yaml openapi.yaml
components:
  schemas:
    BackgroundColor:
      type: string
      x-speakeasy-unknown-values: allow
      enum:
        - red
        - green
        - blue
```

Based on this definition, Speakeasy will allow users to set the value of the `BackgroundColor` string to `yellow`, but will mark it as unrecognized. Here's an example of what this looks like in TypeScript:

```typescript speakeasy/BackgroundColor.ts
type BackgroundColor = 'red' | 'green' | 'blue' | Unrecognized<string>;
```

In the Cohere SDK generated by Fern, we found this enum:

```typescript src/serialization/resources/finetuning/resources/finetuning/types/Status.ts
/**
 * This file was auto-generated by Fern from our API Definition.
 */

import * as serializers from "../../../../../index";
import * as Cohere from "../../../../../../api/index";
import * as core from "../../../../../../core";

export const Status: core.serialization.Schema<serializers.finetuning.Status.Raw, Cohere.finetuning.Status> =
    core.serialization.enum_([
        "STATUS_UNSPECIFIED",
        "STATUS_FINETUNING",
        "STATUS_DEPLOYING_API",
        "STATUS_READY",
        "STATUS_FAILED",
        "STATUS_DELETED",
        "STATUS_TEMPORARILY_OFFLINE",
        "STATUS_PAUSED",
        "STATUS_QUEUED",
    ]);

export declare namespace Status {
    type Raw =
        | "STATUS_UNSPECIFIED"
        | "STATUS_FINETUNING"
        | "STATUS_DEPLOYING_API"
        | "STATUS_READY"
        | "STATUS_FAILED"
        | "STATUS_DELETED"
        | "STATUS_TEMPORARILY_OFFLINE"
        | "STATUS_PAUSED"
        | "STATUS_QUEUED";
}
```

When we looked at the definition of `core.serialization.enum_`, we found that any string value can be passed as a status, and would be represented as type `Status`.

## SDK and bundle size

Both Speakeasy and Fern SDKs include runtime data validation, which can increase the bundle size. However, Speakeasy SDKs are designed to be tree-shakable, so you can remove any unused code from the SDK before bundling it.

Speakeasy also exposes a standalone function for each API call, which allows you to import only the functions you need, further reducing the bundle size.

### Creating bundles

Let's compare the bundle sizes of the SDKs generated by Speakeasy and Fern.

Start by adding a `speakeasy.ts` file that imports the Speakeasy SDK:

```typescript speakeasy.ts
import { SDKCore } from "./bar-sdk-speakeasy/src/core";
import { drinksListDrinks } from "./bar-sdk-speakeasy/src/funcs/drinksListDrinks";

// Use `SDKCore` for best tree-shaking performance.
// You can create one instance of it to use across an application.
const sdk = new SDKCore();

async function run() {
  const res = await drinksListDrinks(sdk, {});

  if (!res.ok) {
    throw res.error;
  }

  const { value: result } = res;

  // Handle the result
  console.log(result)
}

run();
```

Next, add a `fern.ts` file that imports the Fern SDK:

```typescript fern.ts
import { NdimaresApiClient } from "./generated/typescript";

// Create an instance of the Fern SDK client
const client = new NdimaresApiClient({
    apiKey: "YOUR_API_KEY",
});

async function run() {
  try {
    // Use the drinks.listDrinks() method to get the list of drinks
    const result = await client.drinks.listDrinks();

    // Handle the result
    console.log(result);
  } catch (error) {
    console.error("An error occurred:", error);
  }
}

run();
```

We'll use esbuild to bundle the SDKs. First, install esbuild:

```bash
npm install esbuild
```

Next, add a `build.js` script that uses esbuild to bundle the SDKs:

```typescript build.js
import * as esbuild from "esbuild";
import * as fs from "fs";

const speakeasyBuild = await esbuild.build({
  entryPoints: ["speakeasy.ts"],
  outfile: "dist/speakeasy.js",
  bundle: true,
  minify: true,
  treeShaking: true,
  metafile: true,
  target: "node18",
  platform: "node",
});

fs.writeFileSync(
  "dist/speakeasy.json",
  JSON.stringify(speakeasyBuild.metafile, null, 2)
);

const fernBuild = await esbuild.build({
  entryPoints: ["fern.ts"],
  outfile: "dist/fern.js",
  bundle: true,
  minify: true,
  treeShaking: true,
  metafile: true,
  target: "node18",
  platform: "node",
});

fs.writeFileSync("dist/fern.json", JSON.stringify(fernBuild.metafile, null, 2));
```

Run the `build.js` script:

```bash
node build.js
```

This generates two bundles, `dist/speakeasy.js` and `dist/fern.js`, along with their respective metafiles.

### Bundle size comparison

Now that we have two bundles, let's compare their sizes.

First, let's look at the size of the `dist/speakeasy.js` bundle:

```bash
du -sh dist/speakeasy.js
# Output
# 76K    dist/speakeasy.js
```

Next, let's look at the size of the `dist/fern.js` bundle:

```bash
du -sh dist/fern.js
# Output
# 232K    dist/fern.js
```

The SDK generated by Fern is significantly larger than that built with the SDK generated by Speakeasy.

We can use the metafiles generated by esbuild to analyze the bundle sizes in more detail.

### Analyzing bundle sizes

The metafiles generated by esbuild contain detailed information about which source files contribute to each bundle's size, presented as a tree structure.

We used esbuild's online [bundle visualizer](https://esbuild.github.io/analyze/) to analyze the bundle sizes.

Here's a summary of the bundle sizes:

The `dist/speakeasy.js` bundle's largest contributor, at 72.3%, is the Zod library used for runtime data validation. The Zod library's tree-shaking capabilities are a work in progress, and future versions of SDKs are expected to have smaller bundle sizes.

![Speakeasy bundle size](./assets/speakeasy-bundle-size.png)

The `dist/fern.js` bundle includes bundled versions of `node-fetch`, polyfills, and other dependencies, which contribute to the larger bundle size. Fern's SDKs also include custom serialization code and a validation library, which can increase the bundle size.

![Fern bundle size](./assets/fern-bundle-size.png)

### Bundling for the browser

Speakeasy SDKs are designed to work in a range of environments, including the browser. To bundle an SDK for the browser, you can use a tool like esbuild or webpack.

Here's an example of how to bundle the Speakeasy SDK for the browser using esbuild:

```bash
npx esbuild src/speakeasy.ts --bundle --minify --target=es2020 --platform=browser --outfile=dist/speakeasy-web.js
```

Doing the same for the Fern SDK generates an error, as the SDK is not designed to work in the browser out of the box.

## Summary

Speakeasy's additional language support and SDK documentation make it a better choice than Fern for most users.

If you are interested in seeing how Speakeasy stacks up against other SDK generation tools, check out our [post](https://www.speakeasy.com/post/compare-speakeasy-open-source).


 This is the content for the doc blog/speakeasy-vs-liblab/index.mdx 

 ---
title: "In depth: Speakeasy vs liblab"
description: "A detailed breakdown of the differences between Speakeasy and liblab for generating SDKs."
image: "/media/speakeasy-vs-liblab.png"
date: 2024-07-05
authors:
  - name: Nolan Sullivan
  - image_url: "/media/author-headshots/nolan.jpeg"
tags:

featured_image: "/media/speakeasy-vs-liblab.png"
---

import { FileTree } from "nextra/components";
import { ScrollyCoding } from "~/components/codehike/Scrollycoding";

This analysis compares Speakeasy and liblab in terms of SDK generation, OpenAPI integration, language support, features, platform support, enterprise support, and pricing. We'll also provide a technical walkthrough of generating SDKs using both services and compare the generated TypeScript SDKs.

## In short: How do Speakeasy and liblab differ?

1. **OpenAPI integration:** Speakeasy is [built for OpenAPI](/docs/openapi/openapi-support), supporting advanced features of OpenAPI 3.0 and 3.1, while testing and implementing upcoming OpenAPI features like OpenAPI [Overlays](/openapi/overlays) and [Workflows](/openapi/arazzo). liblab uses OpenAPI as a starting point, but has not yet implemented advanced OpenAPI features like Overlays or Workflows, instead depending on its own configuration system. This can lead to a divergence between the OpenAPI document and the generated SDK, and may require additional configuration after spec changes.

2. **Velocity and language support**: [liblab was founded in January 2022](https://www.sequoiacap.com/companies/liblab/) and gradually expanded its language support and features to support seven languages. In comparison, Speakeasy was founded in May 2022, found market traction in early 2023, and released support for ten languages within 12 months. Speakeasy meets the diverse needs of users, while supporting their existing stacks.

3. **SDK generator maturity:** Speakeasy creates SDKs that are [idiomatic to each target language](/docs/sdk-design/intro), type safe during development and production, human-readable, and fault-tolerant. Our comparison found some room for improvement in liblab's type safety, fault tolerance, and SDK project structure. Both products are under active development, and improvement should be expected.

## Comparing Speakeasy and liblab

We'll start by comparing the two services in terms of their SDK generation targets, features, platform support, enterprise support, and pricing.

### SDK generation targets

As your user base grows, the diversity of their technical requirements will expand beyond the proficiencies of your team. At Speakeasy, we understand the importance of enabling users to onboard with our clients without making major changes to their tech stacks. Our solution is to offer support for a wide range of SDK generation targets.

The table below highlights the current SDK language support offered by Speakeasy and liblab as of June 2024. Please note that these lists are subject to change, so always refer to the official documentation for the most up-to-date information.

| Language           |          Speakeasy           |            liblab            |
| ------------------ | :--------------------------: | :--------------------------: |
| Go                 |              ✅              |              ✅              |
| Python             |              ✅              |              ✅              |
| Typescript         |              ✅              |              ✅              |
| Java               |              ✅              |              ✅              |
| C#                 |              ✅              |              ✅              |
| PHP                |              ✅              |              ✅              |
| Swift              |              ✅              |              ✅              |
| Kotlin             | ⚠ Java is Kotlin-compatible | ⚠ Java is Kotlin-compatible |
| Terraform provider |              ✅              |              ✅              |
| Ruby               |              ✅              |              ❌              |
| Unity              |              ✅              |              ❌              |
| Postman Collection |              ✅              |              ❌              |

Everyone has that one odd language that is critical to their business. In our first year, we've made a dent, but we've got further to go. See a language that you require that we don't support? [Let us know](https://github.com/orgs/speakeasy-api/projects/6/views/1).

### SDK features

This table shows the current feature support for Speakeasy and liblab as of June 2024. Refer to the official documentation for the most recent updates.

| Feature                     | Speakeasy |         liblab         |
| --------------------------- | :-------: | :--------------------: |
| Union types                 |    ✅     |           ✅           |
| Discriminated union types   |    ✅     |           ✅           |
| Server-sent events          |    ✅     |           ❌           |
| Retries                     |    ✅     | ⚠ Global retries only |
| Pagination                  |    ✅     |           ❌           |
| Async support               |    ✅     |           ✅           |
| Streaming uploads           |    ✅     |           ❌           |
| OAuth 2.0                   |    ✅     |           ❌           |
| Custom SDK naming           |    ✅     |           ✅           |
| Customize SDK structure     |    ✅     |           ❌           |
| Custom dependency injection |    ✅     |           ✅           |

Speakeasy creates SDKs that handle advanced authentication. For example, Speakeasy can generate SDKs that handle OAuth 2.0 with client credentials - handling the token lifecycle, retries, and error handling for you.

liblab leaves some of these features to be implemented by the user. For example, liblab's configuration allows for global retries on all operations, but only recently released support for custom retries requiring custom implementation per SDK.

liblab also lacks support for pagination, server-sent events, and streaming uploads.

### Platform features

Speakeasy is designed to be used locally, with a dependency-free CLI that allows for local experimentation and iteration. This makes it easier to test and iterate on your SDKs and allows for custom CI/CD workflows.

For local use, liblab provides an NPM package with a dependency tree of 749 modules. Installing and updating the liblab CLI is slower than Speakeasy's single binary, the CLI is less feature-rich, and it depends on Node.js and NPM.

| Feature               | Speakeasy | liblab |
| --------------------- | :-------: | :----: |
| GitHub CI/CD          |    ✅     |   ✅   |
| CLI                   |    ✅     |   ✅   |
| Web interface         |    ✅     |   ✅   |
| OpenAPI Overlays      |    ✅     |   ❌   |
| Package publishing    |    ✅     |   ✅   |
| Product documentation |    ✅     |   ✅   |
| OpenAPI linting       |    ✅     |   ✅   |
| Change detection      |    ✅     |   ❌   |

### Enterprise support

Both Speakeasy and liblab offer support for Enterprise customers. This includes features like concierge onboarding, private Slack channels, and enterprise SLAs.

| Feature               | Speakeasy | liblab |
| --------------------- | :-------: | :----: |
| Concierge onboarding  |    ✅     |   ✅   |
| Private Slack channel |    ✅     |   ✅   |
| Enterprise SLAs       |    ✅     |   ✅   |
| User issues triage    |    ✅     |   ✅   |
| SOC 2 compliance      |    ❌     |   ✅   |

### Pricing

Speakeasy offers a free tier, with paid plans starting at $250 per month.

liblab's free tier is limited to open-source projects, with paid plans starting at $120 per month.

Both services offer custom enterprise plans.

| Plan                | Speakeasy                              | liblab                    |
| ------------------- | -------------------------------------- | ------------------------- |
| Free                | 1 free Published SDK                   | Open-source projects only |
| Startup/Starter     | 1 free + $250/mo/SDK; max 50 endpoints | $120/mo                   |
| Enterprise/Advanced | Custom                                 | Custom                    |

## Speakeasy vs liblab technical walkthrough

To start our technical comparison, let's create an SDK using Speakeasy and liblab. We'll create an OpenAPI document for a fictional bookstore API, that covers a broad range of OpenAPI functionality. You can find the complete OpenAPI document in the [example repository](https://github.com/speakeasy-api/speakeasy-liblab-comparison), but let's take a look at what's included.

<ScrollyCoding className="ch-scrollycoding-full-height" fullHeight>

## !!steps

Our bookstore OpenAPI document is compliant with OpenAPI 3.1, which is supported by both Speakeasy and liblab. We define a basic info section and add a single development server.

```yaml ! openapi.yaml focus=1:15
!from ./assets/openapi.yaml.txt
```

---

## !!steps

Here we define two tags to organize our operations with: `Books` and `Orders`.

```yaml ! openapi.yaml focus=16:20
!from ./assets/openapi.yaml.txt
```

---

## !!steps

We define one global authentication method, `apiKey`.

```yaml ! openapi.yaml focus=21:22
!from ./assets/openapi.yaml.txt
```

---

## !!steps

Let's take a look at the operations we'll need an SDK for, starting with `getAllBooks`.

This operation takes no input.

```yaml ! openapi.yaml focus=2:29
!from ./assets/openapi.yaml.txt 23:77
```

---

## !!steps

What makes this operation interesting is that it returns an array of objects of three types: `ProgrammingBook`, `FantasyBook`, and `SciFiBook`. Each object's type is determined by the book's category.

This example allows us to test how our SDK generators handle discriminated unions in OpenAPI.

```yaml ! openapi.yaml focus=2:29 mark=19:29
!from ./assets/openapi.yaml.txt 23:77
```

---

## !!steps

Next up, we have an operation that adds a book to the database, called `addBook`.

This operation takes one object of type `ProgrammingBook`, `FantasyBook`, or `SciFiBook` as input.

```yaml ! openapi.yaml mark=15:24
!from ./assets/openapi.yaml.txt 78:144
```

---

## !!steps

Our next book-related operation, `updateBookCoverById`, takes a book ID as a path variable, and an image as a binary payload.

We include this operation to test how our SDK generators handle binary payloads.

```yaml ! openapi.yaml mark=22:28
!from ./assets/openapi.yaml.txt 206:233
```

---

## !!steps

Our final book-related operation, `getBookById`, takes a book ID as a path variable, and returns one of our book objects.

```yaml ! openapi.yaml focus=1:32
!from ./assets/openapi.yaml.txt 145:205
```

---

## !!steps

Next up, we have an operation that returns a list of all orders in the database, called `getAllOrders`.

This operation returns an array of `Order` objects, so that we can test an array of nested objects.

```yaml ! openapi.yaml focus=1:19
!from ./assets/openapi.yaml.txt 237:278
```

---

## !!steps

Our next order-related operation, `createOrder`, takes an object of type `NewOrder` as input, and returns an object of type `Order`.

We include this one to test how our SDK generators help users avoid common mistakes, like passing the wrong type to an operation.

```yaml ! openapi.yaml mark=16,32
!from ./assets/openapi.yaml.txt 279:310
```

---

## !!steps

Finally, we have an operation that returns a stream of order events, called `getOrderStream`.

We include this operation to test how our SDK generators handle server-sent events.

```yaml ! openapi.yaml mark=14
!from ./assets/openapi.yaml.txt 358:373
```

---

## !!steps

The remainder of the OpenAPI document defines the components used in the operations above.

```yaml ! openapi.yaml
!from ./assets/openapi.yaml.txt 374:639
```

</ScrollyCoding>

### Installing Speakeasy CLI

Speakeasy CLI is distributed as a single binary, which you can [install directly from GitHub](https://github.com/speakeasy-api/speakeasy?tab=readme-ov-file#installation), or by using Homebrew on macOS:

```bash Terminal
brew install speakeasy
```

### Installing liblab CLI

liblab CLI is distributed as an NPM package, which you can install using the following command:

```bash Terminal
npm install -g liblab
```

### Linting OpenAPI documents

Before generating an SDK, it's a good idea to lint your OpenAPI document. This ensures that your document is valid and that your SDK will be generated correctly.

Speakeasy's CLI includes a linter that checks your OpenAPI document for errors and warnings, and provides helpful hints on how to improve your document.

To lint your OpenAPI document, run the following command in the terminal:

```bash Terminal
speakeasy lint openapi -s openapi.yaml
```

To validate your OpenAPI spec using liblab, run the following commands in the terminal:

```bash Terminal
liblab init --spec openapi.yaml
liblab validate
```

### Generating SDKs: Speakeasy vs liblab

Let's generate an SDK each using Speakeasy and liblab.

#### Creating an SDK using Speakeasy CLI

To generate an SDK, locate your `openapi.yaml` file and run the following in the terminal:

```bash Terminal
speakeasy generate sdk \
    --schema openapi.yaml \
    --lang typescript \
    --out ./bookstore-ts/
```

Speakeasy lints the OpenAPI document, then creates a new folder with the generated SDK.

This happens locally, and you have immediate access to start testing your SDK. We'll explore the SDK shortly.

#### Generating an SDK using liblab CLI

To generate an SDK using liblab, run the following command in the terminal:

```bash Terminal
liblab build --language=typescript
```

liblab creates a new folder `output/typescript` with the generated SDK.

### Setting up a mock server

We used [Stoplight Prism](https://github.com/stoplightio/prism) to generate a mock server to test our SDKs:

```bash Terminal
npm install -g @stoplight/prism-cli
prism mock openapi.yaml
```

This command starts a mock server at `http://localhost:4010`.

## TypeScript SDK comparison

Now that we have two TypeScript SDKs generated from a single OpenAPI document, let's see how they differ.

### SDK structure overview

Before we dive into the detail, let's get an overall view of the default project structure for each SDK.

Speakeasy automatically generates detailed documentation with examples for each operation and component, while liblab generates an `examples` folder with a single example.

liblab generates a `test` folder, while Speakeasy does not. We'll take a closer look at this shortly.

In the comparison below, comparing the folder structure might seem superficial at first, but keep in mind that SDK users get the same kind of high-level glance as their first impression of your SDK. Some of this may be a matter of opinion, but at Speakeasy we aim to generate SDKs that are as organized as SDKs coded by hand.

<div className="md:flex gap-10">
  <div className="md:w-1/2">

#### Speakeasy SDK structure

Speakeasy generates separate folders for models and operations, both in the documentation and in the source folder. This indicates a clear separation of concerns.

We also see separate files for each component and operation, indicating modularity and separation of concerns.

    <div className="[&>div>div]:block">
      <FileTree>
        <FileTree.File name="README.md" />
        <FileTree.File name="RUNTIMES.md" />
        <FileTree.File name="USAGE.md" />
        <FileTree.Folder name="docs">
          <FileTree.Folder name="models">
            <FileTree.Folder name="components">
              <FileTree.File name="author.md" />
              <FileTree.File name="authorwithid.md" />
              <FileTree.File name="authorwithname.md" />
              <FileTree.File name="fantasybook.md" />
              <FileTree.File name="httpmetadata.md" />
              <FileTree.File name="neworder.md" />
              <FileTree.File name="order.md" />
              <FileTree.File name="orderstreammessage.md" />
              <FileTree.File name="products.md" />
              <FileTree.File name="programmingbook.md" />
              <FileTree.File name="scifibook.md" />
              <FileTree.File name="security.md" />
              <FileTree.File name="status.md" />
              <FileTree.File name="user.md" />
            </FileTree.Folder>
            <FileTree.Folder name="operations">
              <FileTree.File name="addbookrequestbody.md" />
              <FileTree.File name="addbookresponse.md" />
              <FileTree.File name="addbookresponsebody.md" />
              <FileTree.File name="cover.md" />
              <FileTree.File name="createorderresponse.md" />
              <FileTree.File name="getallbooksresponse.md" />
              <FileTree.File name="getallordersresponse.md" />
              <FileTree.File name="getbookbyidrequest.md" />
              <FileTree.File name="getbookbyidresponse.md" />
              <FileTree.File name="getbookbyidresponsebody.md" />
              <FileTree.File name="getorderbyidrequest.md" />
              <FileTree.File name="getorderbyidresponse.md" />
              <FileTree.File name="getorderstreamresponse.md" />
              <FileTree.File name="responsebody.md" />
              <FileTree.File name="updatebookcoverbyidrequest.md" />
              <FileTree.File name="updatebookcoverbyidrequestbody.md" />
              <FileTree.File name="updatebookcoverbyidresponse.md" />
            </FileTree.Folder>
          </FileTree.Folder>
          <FileTree.Folder name="sdks">
            <FileTree.Folder name="books">
              <FileTree.File name="README.md" />
            </FileTree.Folder>
            <FileTree.Folder name="orders">
              <FileTree.File name="README.md" />
            </FileTree.Folder>
            <FileTree.Folder name="sdk">
              <FileTree.File name="README.md" />
            </FileTree.Folder>
          </FileTree.Folder>
        </FileTree.Folder>
        <FileTree.File name="jsr.json" />
        <FileTree.File name="package.json" />
        <FileTree.Folder name="src">
          <FileTree.Folder name="hooks">
            <FileTree.File name="hooks.ts" />
            <FileTree.File name="index.ts" />
            <FileTree.File name="registration.ts" />
            <FileTree.File name="types.ts" />
          </FileTree.Folder>
          <FileTree.File name="index.ts" />
          <FileTree.Folder name="lib">
            <FileTree.File name="base64.ts" />
            <FileTree.File name="config.ts" />
            <FileTree.File name="encodings.ts" />
            <FileTree.File name="event-streams.ts" />
            <FileTree.File name="http.ts" />
            <FileTree.File name="primitives.ts" />
            <FileTree.File name="retries.ts" />
            <FileTree.File name="schemas.ts" />
            <FileTree.File name="sdks.ts" />
            <FileTree.File name="security.ts" />
            <FileTree.File name="url.ts" />
          </FileTree.Folder>
          <FileTree.Folder name="models">
            <FileTree.Folder name="components">
              <FileTree.File name="author.ts" />
              <FileTree.File name="fantasybook.ts" />
              <FileTree.File name="httpmetadata.ts" />
              <FileTree.File name="index.ts" />
              <FileTree.File name="neworder.ts" />
              <FileTree.File name="order.ts" />
              <FileTree.File name="orderstreammessage.ts" />
              <FileTree.File name="programmingbook.ts" />
              <FileTree.File name="scifibook.ts" />
              <FileTree.File name="security.ts" />
              <FileTree.File name="user.ts" />
            </FileTree.Folder>
            <FileTree.Folder name="errors">
              <FileTree.File name="index.ts" />
              <FileTree.File name="sdkerror.ts" />
              <FileTree.File name="sdkvalidationerror.ts" />
            </FileTree.Folder>
            <FileTree.Folder name="operations">
              <FileTree.File name="addbook.ts" />
              <FileTree.File name="createorder.ts" />
              <FileTree.File name="getallbooks.ts" />
              <FileTree.File name="getallorders.ts" />
              <FileTree.File name="getbookbyid.ts" />
              <FileTree.File name="getorderbyid.ts" />
              <FileTree.File name="getorderstream.ts" />
              <FileTree.File name="index.ts" />
              <FileTree.File name="updatebookcoverbyid.ts" />
            </FileTree.Folder>
          </FileTree.Folder>
          <FileTree.Folder name="sdk">
            <FileTree.File name="books.ts" />
            <FileTree.File name="index.ts" />
            <FileTree.File name="orders.ts" />
            <FileTree.File name="sdk.ts" />
          </FileTree.Folder>
          <FileTree.Folder name="types">
            <FileTree.File name="blobs.ts" />
            <FileTree.File name="enums.ts" />
            <FileTree.File name="index.ts" />
            <FileTree.File name="operations.ts" />
            <FileTree.File name="rfcdate.ts" />
          </FileTree.Folder>
        </FileTree.Folder>
        <FileTree.File name="tsconfig.json" />
      </FileTree>
    </div>

  </div>
  <div className="md:w-1/2">

#### liblab SDK structure

liblab generates an SDK that at a glance looks less organized, considering the greater number of configuration files at the root of the project, the lack of a `docs` folder, and the way the `src` folder is structured by OpenAPI tags instead of models and operations.

    <div className="[&>div>div]:block">
      <FileTree>
        <FileTree.Folder name="examples">
          <FileTree.File name="package.json" />
          <FileTree.File name="README.md" />
          <FileTree.Folder name="src">
            <FileTree.File name="index.ts" />
          </FileTree.Folder>
          <FileTree.File name="tsconfig.json" />
        </FileTree.Folder>
        <FileTree.File name="install.sh" />
        <FileTree.File name="jest.config.json" />
        <FileTree.File name="LICENSE" />
        <FileTree.File name="package.json" />
        <FileTree.File name="README.md" />
        <FileTree.Folder name="src">
          <FileTree.File name="BaseService.ts" />
          <FileTree.Folder name="hooks">
            <FileTree.File name="Hook.ts" />
          </FileTree.Folder>
          <FileTree.Folder name="http">
            <FileTree.File name="Environment.ts" />
            <FileTree.Folder name="errors">
              <FileTree.File name="BadGateway.ts" />
              <FileTree.File name="BadRequest.ts" />
              <FileTree.File name="base.ts" />
              <FileTree.File name="Conflict.ts" />
              <FileTree.File name="ExpectationFailed.ts" />
              <FileTree.File name="FailedDependency.ts" />
              <FileTree.File name="Forbidden.ts" />
              <FileTree.File name="GatewayTimeout.ts" />
              <FileTree.File name="Gone.ts" />
              <FileTree.File name="HttpVersionNotSupported.ts" />
              <FileTree.File name="index.ts" />
              <FileTree.File name="InternalServerError.ts" />
              <FileTree.File name="LengthRequired.ts" />
              <FileTree.File name="Locked.ts" />
              <FileTree.File name="LoopDetected.ts" />
              <FileTree.File name="MethodNotAllowed.ts" />
              <FileTree.File name="MisdirectedRequest.ts" />
              <FileTree.File name="NetworkAuthenticationRequired.ts" />
              <FileTree.File name="NotAcceptable.ts" />
              <FileTree.File name="NotExtended.ts" />
              <FileTree.File name="NotFound.ts" />
              <FileTree.File name="NotImplemented.ts" />
              <FileTree.File name="PayloadTooLarge.ts" />
              <FileTree.File name="PaymentRequired.ts" />
              <FileTree.File name="PreconditionFailed.ts" />
              <FileTree.File name="PreconditionRequired.ts" />
              <FileTree.File name="ProxyAuthenticationRequired.ts" />
              <FileTree.File name="RangeNotSatisfiable.ts" />
              <FileTree.File name="RequestHeaderFieldsTooLarge.ts" />
              <FileTree.File name="RequestTimeout.ts" />
              <FileTree.File name="ServiceUnavailable.ts" />
              <FileTree.File name="TooEarly.ts" />
              <FileTree.File name="TooManyRequests.ts" />
              <FileTree.File name="Unauthorized.ts" />
              <FileTree.File name="UnavailableForLegalReasons.ts" />
              <FileTree.File name="UnprocessableEntity.ts" />
              <FileTree.File name="UnsufficientStorage.ts" />
              <FileTree.File name="UnsupportedMediaType.ts" />
              <FileTree.File name="UpgradeRequired.ts" />
              <FileTree.File name="UriTooLong.ts" />
              <FileTree.File name="VariantAlsoNegotiates.ts" />
            </FileTree.Folder>
            <FileTree.File name="HTTPClient.ts" />
            <FileTree.File name="httpExceptions.ts" />
            <FileTree.File name="HTTPLibrary.ts" />
            <FileTree.File name="QuerySerializer.ts" />
          </FileTree.Folder>
          <FileTree.File name="index.ts" />
          <FileTree.File name="models.ts" />
          <FileTree.Folder name="services">
            <FileTree.Folder name="books">
              <FileTree.File name="Books.ts" />
              <FileTree.File name="index.ts" />
              <FileTree.Folder name="models">
                <FileTree.File name="AddBookRequest.ts" />
                <FileTree.File name="AddBookResponse.ts" />
                <FileTree.File name="GetAllBooksResponse.ts" />
                <FileTree.File name="GetBookByIdResponse.ts" />
                <FileTree.File name="UpdateBookCoverByIdRequest.ts" />
              </FileTree.Folder>
            </FileTree.Folder>
            <FileTree.Folder name="common">
              <FileTree.File name="Author.ts" />
              <FileTree.File name="FantasyBook.ts" />
              <FileTree.File name="ProgrammingBook.ts" />
              <FileTree.File name="SciFiBook.ts" />
            </FileTree.Folder>
            <FileTree.Folder name="orders">
              <FileTree.File name="index.ts" />
              <FileTree.Folder name="models">
                <FileTree.File name="CreateOrderRequest.ts" />
                <FileTree.File name="GetAllOrdersResponse.ts" />
                <FileTree.File name="OrderStreamMessage.ts" />
                <FileTree.File name="Order.ts" />
                <FileTree.File name="User.ts" />
              </FileTree.Folder>
              <FileTree.File name="Orders.ts" />
            </FileTree.Folder>
            <FileTree.File name="README.md" />
          </FileTree.Folder>
        </FileTree.Folder>
        <FileTree.Folder name="test">
          <FileTree.Folder name="models" />
          <FileTree.Folder name="services">
            <FileTree.Folder name="books">
              <FileTree.File name="Books.test.ts" />
            </FileTree.Folder>
            <FileTree.Folder name="orders">
              <FileTree.File name="Orders.test.ts" />
            </FileTree.Folder>
          </FileTree.Folder>
        </FileTree.Folder>
        <FileTree.File name="tsconfig.eslint.json" />
        <FileTree.File name="tsconfig.json" />
      </FileTree>
    </div>

  </div>
</div>

### SDK code comparison

With the bird's-eye view out of the way, let's take a closer look at the code.

#### Runtime type checking

Speakeasy creates SDKs that are type safe from development to production. As our CEO recently wrote, [Type Safe is better than Type Faith](/post/type-safe-vs-type-faith).

The SDK created by Speakeasy uses [Zod](https://zod.dev/) to validate data at runtime. Data sent to the server and data received from the server are validated against Zod definitions in the client.

This provides safer runtime code execution and helps developers who use your SDK to provide early feedback about data entered by their end users. Furthermore, trusting data validation on the client side allows developers more confidence to build [optimistic UIs](https://medium.com/distant-horizons/using-optimistic-ui-to-delight-your-users-ac819a81d59a) that update as soon as an end user enters data, greatly improving end users' perception of your API's speed.

Let's see how Speakeasy's runtime type checking works in an example.

Consider the following `Book` component from our OpenAPI document:

```yaml mark=18:21
!from ./assets/openapi.yaml.txt 379:406
```

The highlighted `price` field above has type `integer`.

```typescript speakeasy-example.ts mark=17
// techbooks-speakeasy SDK created by Speakeasy
import { TechBooks } from "techbooks-speakeasy";

const bookStore = new TechBooks({
  apiKey: "123",
});

async function run() {
  await bookStore.books.addBook({
    author: {
      name: "Robert C. Martin",
      photo: "https://example.com/photos/robert.jpg",
      biography: 'Robert Cecil Martin, colloquially known as "Uncle Bob", is an American software engineer...',
    },
    category: "Programming",
    description: "A Handbook of Agile Software Craftsmanship",
    price: 29.99,
    title: "Clean Code",
  });
}

run();
```

The `price` field in the `Book` object in our test code is set to `29.99`, which is a floating-point number. This will cause a validation error before the data is sent to the server, as the `price` field is expected to be an integer.

[Handling Zod validation errors](https://zod.dev/?id=error-handling) is straightforward, and allows developers to provide meaningful feedback to their end users early in the process.

The same book object in code using the SDK generated by liblab will only be validated on the server. This means that the error will only be caught from the client's perspective _after_ the data is sent to the server, and the server responds with an error message.

If the server is not set up to validate the `price` field, the error will _not be caught at all_, leading to unexpected behavior in your developer-users' applications.

As a result, developers using the SDK generated by liblab may need to write additional client-side validation code to catch these errors before they are sent to the server.

#### Components compared

Speakeasy creates SDKs that contain rich type information for each component in your OpenAPI document. This includes clear definitions of enums, discriminated unions, and other complex types, augmented with runtime validation using Zod.

Let's compare the `Order` component from our OpenAPI document in the SDKs generated by Speakeasy and liblab.

Here's the `Order` component as generated by liblab:

```typescript liblab/services/orders/models/Order.ts
// This file was generated by liblab | https://liblab.com/

import { User } from './User';
import { FantasyBook } from '../../common/FantasyBook';
import { ProgrammingBook } from '../../common/ProgrammingBook';
import { SciFiBook } from '../../common/SciFiBook';

type Status = 'pending' | 'shipped' | 'delivered';

export interface Order {
  id: number;
  date: string;
  status: Status;
  user: User;
  products: (FantasyBook | ProgrammingBook | SciFiBook)[];
}
```

Note how the `products` field is defined as an array of `FantasyBook`, `ProgrammingBook`, or `SciFiBook`. This is a union type, but the SDK generated by liblab does not provide any runtime validation for this field, nor does it give any indication that this is a discriminated union.

Contrast this with the `Order` component as created by Speakeasy, which exports a useful `Products` type that is a discriminated union of `FantasyBook`, `ProgrammingBook`, and `SciFiBook`, along with a `Status` enum for use elsewhere in your code.

Verbose runtime validation is marked as `@internal` in the generated code, clearly indicating that it is not intended for direct use by developers, but rather for internal use by the SDK.

Here's the `Order` component created by Speakeasy:

```typescript speakeasy/models/components/order.ts
/*
 * Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT.
 */

import { FantasyBook, FantasyBook$ } from "./fantasybook";
import { ProgrammingBook, ProgrammingBook$ } from "./programmingbook";
import { SciFiBook, SciFiBook$ } from "./scifibook";
import { User, User$ } from "./user";
import * as z from "zod";

export enum Status {
    Pending = "pending",
    Shipped = "shipped",
    Delivered = "delivered",
}

export type Products =
    | (ProgrammingBook & { category: "Programming" })
    | (FantasyBook & { category: "Fantasy" })
    | (SciFiBook & { category: "Sci-fi" });

export type Order = {
    id: number;
    date: Date;
    status: Status;
    user: User;
    products: Array<
        | (ProgrammingBook & { category: "Programming" })
        | (FantasyBook & { category: "Fantasy" })
        | (SciFiBook & { category: "Sci-fi" })
    >;
};

/** @internal */
export namespace Status$ {
    export const inboundSchema = z.nativeEnum(Status);
    export const outboundSchema = inboundSchema;
}

/** @internal */
export namespace Products$ {
    export const inboundSchema: z.ZodType<Products, z.ZodTypeDef, unknown> = z.union([
        ProgrammingBook$.inboundSchema.and(
            z
                .object({ category: z.literal("Programming") })
                .transform((v) => ({ category: v.category }))
        ),
        FantasyBook$.inboundSchema.and(
            z
                .object({ category: z.literal("Fantasy") })
                .transform((v) => ({ category: v.category }))
        ),
        SciFiBook$.inboundSchema.and(
            z.object({ category: z.literal("Sci-fi") }).transform((v) => ({ category: v.category }))
        ),
    ]);

    export type Outbound =
        | (ProgrammingBook$.Outbound & { category: "Programming" })
        | (FantasyBook$.Outbound & { category: "Fantasy" })
        | (SciFiBook$.Outbound & { category: "Sci-fi" });
    export const outboundSchema: z.ZodType<Outbound, z.ZodTypeDef, Products> = z.union([
        ProgrammingBook$.outboundSchema.and(
            z
                .object({ category: z.literal("Programming") })
                .transform((v) => ({ category: v.category }))
        ),
        FantasyBook$.outboundSchema.and(
            z
                .object({ category: z.literal("Fantasy") })
                .transform((v) => ({ category: v.category }))
        ),
        SciFiBook$.outboundSchema.and(
            z.object({ category: z.literal("Sci-fi") }).transform((v) => ({ category: v.category }))
        ),
    ]);
}

/** @internal */
export namespace Order$ {
    export const inboundSchema: z.ZodType<Order, z.ZodTypeDef, unknown> = z.object({
        id: z.number().int(),
        date: z
            .string()
            .datetime({ offset: true })
            .transform((v) => new Date(v)),
        status: Status$.inboundSchema,
        user: User$.inboundSchema,
        products: z.array(
            z.union([
                ProgrammingBook$.inboundSchema.and(
                    z
                        .object({ category: z.literal("Programming") })
                        .transform((v) => ({ category: v.category }))
                ),
                FantasyBook$.inboundSchema.and(
                    z
                        .object({ category: z.literal("Fantasy") })
                        .transform((v) => ({ category: v.category }))
                ),
                SciFiBook$.inboundSchema.and(
                    z
                        .object({ category: z.literal("Sci-fi") })
                        .transform((v) => ({ category: v.category }))
                ),
            ])
        ),
    });

    export type Outbound = {
        id: number;
        date: string;
        status: string;
        user: User$.Outbound;
        products: Array<
            | (ProgrammingBook$.Outbound & { category: "Programming" })
            | (FantasyBook$.Outbound & { category: "Fantasy" })
            | (SciFiBook$.Outbound & { category: "Sci-fi" })
        >;
    };

    export const outboundSchema: z.ZodType<Outbound, z.ZodTypeDef, Order> = z.object({
        id: z.number().int(),
        date: z.date().transform((v) => v.toISOString()),
        status: Status$.outboundSchema,
        user: User$.outboundSchema,
        products: z.array(
            z.union([
                ProgrammingBook$.outboundSchema.and(
                    z
                        .object({ category: z.literal("Programming") })
                        .transform((v) => ({ category: v.category }))
                ),
                FantasyBook$.outboundSchema.and(
                    z
                        .object({ category: z.literal("Fantasy") })
                        .transform((v) => ({ category: v.category }))
                ),
                SciFiBook$.outboundSchema.and(
                    z
                        .object({ category: z.literal("Sci-fi") })
                        .transform((v) => ({ category: v.category }))
                ),
            ])
        ),
    });
}
```

#### OAuth client credentials handling

Only Speakeasy's SDKs handle OAuth 2.0 with client credentials, including managing the token lifecycle, retries, and error handling without any additional code.

Our bookstore API requires an OAuth 2.0 token with client credentials to access the API. Let's see how the SDKs handle this.

Consider the following OAuth 2.0 configuration from our OpenAPI document:

```yaml openapi.yaml
!from ./assets/openapi.yaml.txt 633:639
```

Speakeasy's generated SDK takes a `clientID` and `clientSecret` when instantiating the SDK. The SDK also includes `ClientCredentialsHook` class that implements `BeforeRequestHook` to check whether the token is expired and refresh it if necessary. The hook also checks whether the client has the necessary scopes to access the endpoint, and handles authentication errors.

```typescript speakeasy-example.ts
// techbooks-speakeasy SDK created by Speakeasy
import { TechBooks } from "techbooks-speakeasy";

const bookStore = new TechBooks({
  security: {
    // OAuth 2.0 client credentials
    clientID: "<YOUR_CLIENT_ID_HERE>",
    clientSecret: "<YOUR_CLIENT_SECRET_HERE>",
  },
});

async function run() {
  // The SDK handles the token lifecycle, retries, and error handling for you
  await bookStore.books.addBook({
    // Book object
  });
}

run();
```

The SDK generated by liblab does not support OAuth 2.0 client credentials at all.

#### Server-sent events (SSE) and streaming responses

Our bookstore API includes an operation that streams orders to the client using Server-Sent Events (SSE).

```yaml mark=15
paths:
  /orderstream:
    get:
      summary: Get a stream of orders
      operationId: getOrderStream
      description: Returns a stream of orders
      tags:
        - Orders
      security:
        - apiKey: []
      responses:
        "200":
          description: A stream of orders
          content:
            text/event-stream:
              schema:
                $ref: "#/components/schemas/OrderStreamMessage"
```

Let's see how the SDKs handle this.

[Speakeasy generates types and methods for handling SSE](/docs/customize-sdks/streaming) without any customization. Here's an example of how to use the SDK to listen for new orders:

```typescript speakeasy-example.ts
import { TechBooks } from "techbooks-speakeasy";

const bookStore = new TechBooks({
  apiKey: 'KEY123',
});

async function run() {
  const result = await bookStore.orders.getOrderStream();

  if (result.orderStreamMessage == null) {
    throw new Error('Failed to create stream: received null value');
  }

  const stream = result.orderStreamMessage.stream;

  if (!stream || typeof stream.getReader !== 'function') {
    throw new Error('Invalid stream: expected a ReadableStream');
  }

  const reader = stream.getReader();

  try {
    while (true) {
      const { done, value } = await reader.read();
      if (done) break;
      console.log(new TextDecoder().decode(value));
    }
  } catch (error) {
    console.error('Error reading stream', error);
  } finally {
    reader.releaseLock();
  }
}

run();
```

(The example above does not run against a local Prism server, but you can test it against [Stoplight's hosted Prism](https://stoplight.io/) server.)

liblab does not generate SSE handling code. Developers using the SDK generated by liblab will need to write additional code to handle SSE.

#### Streaming uploads

Speakeasy supports streaming uploads without any custom configuration. OpenAPI operations with `multipart/form-data` content types are automatically handled as streaming uploads.

The following example illustrates how to use an SDK created by Speakeasy to upload a large file:

```typescript speakeasy-example.ts
import { openAsBlob } from "node:fs";

import { SDK } from "@speakeasy/super-sdk";

async function run() {
  const sdk = new SDK();

  const fileHandle = await openAsBlob("./src/sample.txt");

  const result = await sdk.upload({ file: fileHandle });

  console.log(result);
}
run();
```


#### React Hooks

React Hooks simplify state and data management in React apps, enabling developers to consume APIs more efficiently.

liblab does not support React Hooks natively. Developers must manually integrate SDK methods into state management tools like React Context, Redux, or TanStack Query.

Speakeasy generates built-in React Hooks using [TanStack Query](https://tanstack.com/query/latest). These hooks provide features like intelligent caching, type safety, pagination, and seamless integration with modern React patterns such as SSR and Suspense.

Here's an example:

```typescript example/loadPosts.tsx
import { useQuery } from "@tanstack/react-query";

function Posts() {
  const { data, status, error } = useQuery([
    "posts" // Cache key for the query
  ], async () => {
    const response = await fetch("https://jsonplaceholder.typicode.com/posts");
    return response.json();
  });

  if (status === "loading") return <p>Loading posts...</p>;
  if (status === "error") return <p>Error: {error?.message}</p>;

  return (
    <ul>
      {data.map((post) => (
        <li key={post.id}>{post.title}</li>
      ))}
    </ul>
  );
}
```

For example, in this basic implementation, the `useQuery` hook fetches data from an API endpoint. The cache key ensures unique identification of the query. The `status` variable provides the current state of the query: `loading`, `error`, or `success`. Depending on the query status, the component renders `loading`, `error`, or the fetched data as a list.

#### Auto-pagination

Speakeasy's React Hooks also enable auto-pagination, which automatically fetches more data when the user scrolls to the bottom of the page. This feature is useful for infinite scrolling in social media feeds or search results.

```typescript example/PostsView.tsx
import { useInView } from "react-intersection-observer";

import { useActorAuthorFeedInfinite } from "@speakeasy-api/bluesky/react-query/actorAuthorFeed.js";

export function PostsView(props: { did: string }) {
  const { data, fetchNextPage, hasNextPage } = useActorAuthorFeedInfinite({
    actor: props.did,
  });

  const { ref } = useInView({
    rootMargin: "50px",
    onChange(inView) {
      if (inView) { fetchNextPage(); }
    },
  });

  return (
    <div>
      <ul className="space-y-4">
        {data?.pages.flatMap((page) => {
          return page.result.feed.map((entry) => (
            <li key={entry.post.cid}>
              <FeedEntry entry={entry.post} />
            </li>
          ));
        })}
      </ul>
      {hasNextPage ? <div ref={ref} /> : null}
    </div>
  );
```

liblab also supports pagination, however this requires additional configuration using the `liblab.config.json` file.

For an in-depth look at how Speakeasy generates React Hooks, see our [official release article](https://www.speakeasy.com/post/release-react-hooks).

### OpenAPI extensions and Overlays vs liblab config

Speakeasy embraces OpenAPI as the source of truth for generating SDKs. This means that Speakeasy does not require any additional configuration files to generate SDKs, apart from minimal configuration in the `gen.yaml` file.

Any configuration related to individual operations or components is done in the OpenAPI document itself, using OpenAPI extensions. Speakeasy provides a [list of supported OpenAPI extensions](/docs/customize-sdks) in its documentation.

If editing your OpenAPI document is not an option, Speakeasy also supports the [OpenAPI Overlays](/docs/prep-openapi/overlays/create-overlays) specification, which allows you to add or override parts of an OpenAPI document without modifying the original document.

This step can form part of your CI/CD pipeline, ensuring that your SDKs are always up-to-date with your API, even if your OpenAPI document is generated from code.

Speakeasy's CLI can also generate OpenAPI Overlays for you, based on the differences between two OpenAPI documents.

Instead of using OpenAPI extensions, liblab uses a [configuration file](https://developers.liblab.com/cli/config-file-overview/) to customize SDKs. This configuration overrides many of the aspects Speakeasy allows you to configure in the OpenAPI document itself, or using overlays.

### Linting and change detection

Speakeasy's CLI includes a detailed and accurate linter that checks your OpenAPI document and provides feedback. This is especially useful during development, but can also catch errors in your CI/CD pipeline.

Speakeasy also keeps track of changes in your OpenAPI document, and versions the SDKs it creates based on those changes.

### Building for the browser

Both Speakeasy and liblab generate SDKs that can be used in the browser. To use the SDKs in the browser, you need to bundle your application using a tool like webpack, Rollup, or esbuild.

Speakeasy creates SDKs that are tree-shakeable, meaning that you can include only the parts of the SDK that you need in your application. This can help reduce the size of your application bundle.

Because Speakeasy SDKs include runtime type checking, the Zod library is included in the bundle. However, if you use Zod in other parts of your application, you can share the Zod instance between the SDK and your application to reduce the bundle size.

Here's an example of how to bundle an application that uses the Speakeasy SDK for the browser without Zod using esbuild:

```bash Terminal mark=7
npx esbuild src/speakeasy-app.ts \
  --bundle \
  --minify \
  --target=es2020 \
  --platform=browser \
  --outfile=dist/speakeasy-app.js \
  --external:zod
```

## Speakeasy compared to open-source generators

If you are interested in seeing how Speakeasy stacks up against other SDK generation tools, check out our [post](/post/compare-speakeasy-open-source).


 This is the content for the doc blog/speakeasy-vs-openapi-generator/index.mdx 

 ---
title: "Speakeasy vs OpenAPI/Swagger Generator"
description: "Comparing Speakeasy's OpenAPI/Swagger SDK generators with the openapi-generator project"
keywords:
  [
    api,
    openapi,
    swagger,
    sdk generation,
    sdk,
    golan,
    go,
    go sdk,
    python sdk,
    python,
    typescript sdk,
    typescript,
    ts,
    java sdk,
    java,
    developer experience,
    devex,
    dx,
  ]
image: "/media/compare-speakeasy-open-source.png"
date: 2025-01-10
authors:
  - name: Sagar Batchu
  - image_url: /media/author-headshots/sagar.jpeg
tags:
  - API Advice
  - Building Speakeasy
featured_image: "/media/compare-speakeasy-open-source"
---
import { OSSComparisonData } from "~/data/shared/ossComparisons";
import { Callout, Testimonial } from "~/components";
import { IconGrid } from "~/features/shared/recipes";

## OpenAPI Generation Overview

The [OpenAPI Generator project](https://openapi-generator.tech/) is a popular open-source tool for generating SDKs from OpenAPI/Swagger specifications. It has been an indispensable tool for the increasing number of companies which provide SDKs to their users. But, as any past user will know, there is a gap between what it is possible to achieve with off-the-shelf OSS and what's required for supporting enterprise APIs.

Simply put, when users are paying for your API, they expect (and deserve) a high quality SDK: type-safety, authentication, pagination, retries and more. That is why **Speakeasy** was created. The platform has been designed to generate a best in class DevEx that can support enterprise APIs of any size & complexity.

In this article, we'll dive into the business and high level technical differences between using Speakeasy to generate SDKs and using the OpenAPI Generators. If you want a granular breakdown for a specific language, check out our comparison guides.

<div style={{ marginTop: "12px" }}>
  <IconGrid { ...OSSComparisonData } />
</div>

## The cost of using `openapi-generator`

<Testimonial
  variant="dark"
  avatar="/media/quote-headshots/roy-pereira.png"
  quoted="Roy Pereira, Unified.to CEO & Co-Founder"
>
  “OpenAPI gen doesn’t work very well — the code often doesn’t look and feel
  right, and certain aspects of OpenAPI just aren’t handled well. We would
  probably still have needed to spend a ton of engineer time working around its
  limitations and quirks, and we decided that the headache wasn’t worth it.”
</Testimonial>


Open-source software is free, but that doesn't mean it doesn't have a cost.

The open-source projects have a number of issues that make it difficult to use in an enterprise:

- **Spotty API feature coverage**: There are holes in the OpenAPI generators that make it difficult to support moderately complex APIs. If your API uses OAuth, if it has union types, if it requires pagination, you'll find that the generators fall short.
- **Non-idiomatic code**: The Open Source generators started off as a Java-based project. They are largely maintained by Java developers and consequently, many of the supported languages have a Java-like feel to them. This might not seem like a big deal, but it is massively off-putting to users if they are used to a language like Python or Typescript.
- **Huge number of bugs**: There are 4.5K open issues as of January 2025 — and growing ~10% every year.

The result of all these issues is that most enterprise users end up forking the repository and maintaining their own version of the Open Source generators with the fixes they need.

## Enterprise case study: using `openapi-generator` at Fastly

Don't just take our (or even our customers') word for it, however. See what the API Architect of a publicly traded company [posted](https://dev.to/fastly/better-fastly-api-clients-with-openapi-generator-3lno) in Nov 2022 to mark his team's completion of a project to develop SDKs using the Open Source generators. The post is equal parts celebration of the accomplishment and postmortem on the pain suffered.

Here are just a few key quotes from the post:

<Testimonial variant="dark">
  “To ensure we would be able to run the code-generation process within
  our Continuous Integration (CI) pipeline, we needed to use
  a Dockerised version of openapi-generator-cli (the coordination of which was a
  complex process).”
</Testimonial>

<Testimonial variant="dark">
  “Another challenge we encountered was the quality of the community-driven
  language templates. They worked but templates didn’t appear to be well
  maintained over time, nor did every feature in our OpenAPI specification have
  a corresponding implementation in the language templates.”
</Testimonial>

<Testimonial variant="dark">
  “Language templates **didn’t support the latest programming language
  version**, and the generated documentation wasn’t as good as we needed it to
  be.”
</Testimonial>

<Testimonial variant="dark">
  “Our OpenAPI specification files would cause problems in the generator… Each
  of these issues would result in hard-to-debug compilation errors within the
  code-generation pipeline, and so we would have to figure out which of the
  three potential layers the issue was stemming from: 1. The Fastly OpenAPI
  specification documents. 2. The [openapi-generator mustache
  templates](https://github.com/OpenAPITools/openapi-generator/tree/master/modules/openapi-generator/src/main/resources).
  3. The [openapi-generator language
  parsers](https://github.com/OpenAPITools/openapi-generator/tree/master/modules/openapi-generator/src/main/java/org/openapitools/codegen/languages) (written
  in Java).”
</Testimonial>

<Testimonial variant="dark">
  “We had to iterate on both ends of the integration, a bit like trying to fit a
  square peg into a round hole, then gradually changing the shape of both the
  peg and the hole until they fit.”
</Testimonial>

<Testimonial variant="dark">
  “Auto-generating our API clients has been a long project… The code generation
  itself hasn’t been easy: we’ve had to balance the complexity of coordinating
  changes across multiple repositories while handling errors over multiple
  layers, and producing API clients that are not only idiomatic to the language
  they’re built in but also correct and accessible.”
</Testimonial>

For an enterprise that wants to appeal to developers and showcase a compelling API experience, using Open Source successfully will require a significant investment in engineering resources, and significant time-to-market.

<Callout title="TIP" variant="success">
  Total cost of ownership for OSS tooling is likely to be 3+ FTEs at a minimum,
  depending on the API surface area and SDK languages required. This is an
  ongoing commitment.
</Callout>


## Generating handwritten SDKs with Speakeasy

When we set out to build our SDK generators, we wanted to deliver something that was 10x better than the existing generators. Our goal was to generate handwritten SDKs.

What constitutes a great SDK is somewhat subjective, but we set out some principles to guide development:

- **Type safe** - The SDKs we generate are fully typed, so that developers can catch errors early and often.
- **Human readable** - The SDKs we generate are easy for developers to read and debug. No convoluted abstractions.
- **Minimal dependencies** - Our SDKs are meant to be powerful but lean. We start with native language libraries and layer on third-party libraries only when the customer benefits far outweigh the cost of the extra dependency. We avoid adding unnecessary dependencies. 
- **Batteries-included** - The SDKs we generate include everything from oauth, to pagination and retries.

With every language we support, we're striving for an experience that's instantly familiar to developers. As an example, check out this code snippet from [Vercel's TypeScript SDK](https://github.com/vercel/sdk/tree/main), generated on the Speakeasy platform:

```typescript buyDomain.ts
import { Vercel } from "@vercel/sdk";

const vercel = new Vercel({
  bearerToken: "<YOUR_BEARER_TOKEN_HERE>",
});

async function run() {
  const result = await vercel.domains.buyDomain({
    teamId: "team_1a2b3c4d5e6f7g8h9i0j1k2l",
    slug: "my-team-url-slug",
    requestBody: {
      name: "example.com",
      expectedPrice: 10,
      renew: true,
      country: "US",
      orgName: "Acme Inc.",
      firstName: "Jane",
      lastName: "Doe",
      address1: "340 S Lemon Ave Suite 4133",
      city: "San Francisco",
      state: "CA",
      postalCode: "91789",
      phone: "+1.4158551452",
      email: "jane.doe@someplace.com",
    },
  });

  // Handle the result
  console.log(result);
}

run();
```

## Generator Comparison Table

| Feature | Speakeasy | `openapi-codegen` |
|---------|-----------|---------------------------|
| Type-safety | ✅ Using Zod | ❌ |
| Union types/polymorphism | ✅ | ✅ Without discriminator |
| Documentation generation | ✅ Full docs & examples | ❌ |
| OAuth 2.0 | ✅ | ❌ |
| Webhooks | ✅ | ❌ |
| Retries | ✅ | ❌ |
| Pagination | ✅ | ❌ |
| Package publishing | ✅ | ❌ |
| CI/CD integration | ✅ GitHub Actions | ❌ |


## Summary

The OpenAPI Generators are great for the ecosystem, because they establish a baseline. But our commitment at Speakeasy is create a platform that is 10x better than using `openapi-generator`. We encourage you to try it out for yourself and see the difference. 


 This is the content for the doc blog/speakeasy-vs-stainless/index.mdx 

 ---
title: "In Depth: Speakeasy vs Stainless"
description: "A detailed breakdown of the differences between Speakeasy and Stainless, two popular SDK-generation tools."
image: "/media/speakeasy-vs-stainless.png"
date: 2025-01-10
authors:
  - name: Nolan Sullivan
  - image_url: "/media/author-headshots/nolan.jpeg"
tags:
  - API Advice

featured_image: "/media/speakeasy-vs-stainless.png"
---

import { FileTree } from "nextra/components";
import { ScrollyCoding } from "~/components/codehike/Scrollycoding";
import { Callout } from "~/components";

<Callout title="NOTE" variant="info">
  This comparison of Speakeasy & Stainless is based on a snapshot of two developing companies as of January 2025. If you think we need to update this post, please let us know!
</Callout>

In this post, we'll compare generated SDKs, as well as the underlying philosophies that guide the development of the two companies. And while we acknowledge that our views may be biased, we'll show our work along with our conclusions so that readers can decide for themselves.

## In short: How is Speakeasy different?

### OpenAPI-native vs OpenAPI-compatible

Speakeasy is OpenAPI-native; Stainless is OpenAPI-compatible. Stainless is built on a custom DSL known as the [Stainless config](https://app.stainlessapi.com/docs/reference/config). This approach requires your team to manage an additional config file. Speakeasy has no intermediary DSL. Your OpenAPI spec is the only source of truth for SDK generation.

Being OpenAPI-native is beneficial for integration into an existing stack. Regardless of the API proxies, server-side code, or specific web framework that you're using, you can plug in Speakeasy's tools. Stainless is doubling down on a vertically integrated approach by building a [backend TypeScript framework](https://github.com/stainless-api/stl-api) which will become the foundation for their solution. Their product will work best when you buy the entire stack, Speakeasy will shine regardless of the other tools in your existing stack.

### Type-safe vs type-faith

There's [more on this topic](#runtime-type-checking) in the technical deep dive below. Speakeasy SDKs guarantee true end-to-end type safety, meaning that types are generated to validate both request and response objects defined in your API. Stainless SDKs, on the other hand, are mainly type-hinted, not guarding the API from bad inputs.

### Velocity and maturity

[Stainless was founded in 2021](https://www.sequoiacap.com/companies/stainless/) and has expanded its language support to seven languages. By comparison, Speakeasy launched in October 2022 and has released support for ten languages in less time. The Speakeasy platform is also broader, with support for additional generation features, like [webhooks](/post/release-webhooks-support), [React Hooks](/post/release-react-hooks), and [contract testing](/post/release-contract-testing), not supported by Stainless.

Both companies are financially secure, having raised $25M+ in funding.

## Platform

| Product                  | Speakeasy | Stainless |
| ------------------------ | :-------: | :-------: |
| **SDK generation**       |    ✅     |    ✅     |
| **Terraform generation** |    ✅     |    ✅     |
| **Docs generation**      |    ✅     |    ❌     |
| **Contract testing**     |    ✅     |    ❌     |
| **E2E testing**          |    ✅     |    ❌     |


## SDK generation

| Language           |          Speakeasy           | Stainless |
| ------------------ | :--------------------------: | :-------: |
| TypeScript         |              ✅              |    ✅     |
| Python             |              ✅              |    ✅     |
| Go                 |              ✅              |    ✅     |
| Java               |              ✅              |    ✅     |
| Kotlin             |  ⚠ Java is Kotlin-compatible |    ✅     |
| Ruby               |              ✅              |    ✅     |
| C#                 |              ✅              |    ❌     |
| PHP                |              ✅              |    ❌     |
| Swift              |              ✅              |    ❌     |
| Unity              |              ✅              |    ❌     |

If there's a language you require that we don't support, [add it to our roadmap](https://speakeasy.productlane.com/roadmap).

### SDK features

Breadth matters, but so does the depth of support for each language. The table below shows the current feature support for Speakeasy and Stainless's SDK generation.

| Feature                     | Speakeasy |        Stainless        |
| --------------------------- | :-------: | :---------------------: |
| Webhooks support            |    ✅     |           ❌            |
| React Hooks                 |    ✅     |           ❌            |
| OAuth 2.0                   |    ✅     |           ❌ (manual)   |
| React Hooks support         |    ✅     |           ❌ (manual)   |
| Retries                     |    ✅     |           ✅            |
| Pagination                  |    ✅     |           ✅            |
| Async functions             |    ✅     |           ✅            |
| Streaming uploads           |    ✅     |           ✅            |
| Custom SDK naming           |    ✅     |           ✅            |
| Union types                 |    ✅     |           ✅            |
| Discriminated union types   |    ✅     |           ❌            |
| Server-sent events          |    ✅     | ⚠ non-OpenAPI standard |
| Custom dependency injection |    ✅     |           ✅            |



## Pricing

In terms of pricing, both Speakeasy and Stainless offer free plans, as well as paid plans for startups and enterprises. The most significant pricing difference is in the enterprise plan. Existing customers indicate that Stainless's enterprise pricing is ~20% higher than Speakeasy's. Of course, this can vary, and we recommend reaching out to both companies for a quote.

| Plan       | Speakeasy                              | Stainless                            |
| ---------- | -------------------------------------- | ------------------------------------ |
| Free       | 1 free Published SDK                   | 1 free local SDK; max 50 endpoints   |
| Startup    | $250/mo/SDK; max 50 endpoints          | $250/mo/SDK; max 50 endpoints        |
| Business   | 600/mo/SDK ; max 200 endpoints         | $2,500/mo; max 5 SDKs; 150 endpoints |
| Enterprise | Custom                                 | Custom                               |

## Speakeasy vs Stainless: TypeScript SDK comparison

<Callout title="NOTE" variant="info">
  For this technical comparison, we'll create SDKs with Speakeasy and Stainless using an example bookstore API. You can find the complete OpenAPI document in this [example repository](https://github.com/speakeasy-api/speakeasy-stainless-comparison).
</Callout>

## SDK structure

<div className="md:flex gap-10">
  <div className="md:w-1/2">

### Speakeasy

    <div className="[&>div>div]:block">
      <FileTree>
        <FileTree.File name="README.md" />
        <FileTree.File name="RUNTIMES.md" />
        <FileTree.File name="USAGE.md" />
        <FileTree.Folder name="docs">
          <FileTree.Folder name="models">
            <FileTree.Folder name="components">
              <FileTree.File name="author.md" />
              <FileTree.File name="authorwithid.md" />
              <FileTree.File name="authorwithname.md" />
              <FileTree.File name="fantasybook.md" />
              <FileTree.File name="httpmetadata.md" />
              <FileTree.File name="neworder.md" />
              <FileTree.File name="order.md" />
              <FileTree.File name="orderstreammessage.md" />
              <FileTree.File name="products.md" />
              <FileTree.File name="programmingbook.md" />
              <FileTree.File name="scifibook.md" />
              <FileTree.File name="security.md" />
              <FileTree.File name="status.md" />
              <FileTree.File name="user.md" />
            </FileTree.Folder>
            <FileTree.Folder name="operations">
              <FileTree.File name="addbookrequestbody.md" />
              <FileTree.File name="addbookresponse.md" />
              <FileTree.File name="addbookresponsebody.md" />
              <FileTree.File name="cover.md" />
              <FileTree.File name="createorderresponse.md" />
              <FileTree.File name="getallbooksresponse.md" />
              <FileTree.File name="getallordersresponse.md" />
              <FileTree.File name="getbookbyidrequest.md" />
              <FileTree.File name="getbookbyidresponse.md" />
              <FileTree.File name="getbookbyidresponsebody.md" />
              <FileTree.File name="getorderbyidrequest.md" />
              <FileTree.File name="getorderbyidresponse.md" />
              <FileTree.File name="getorderstreamresponse.md" />
              <FileTree.File name="responsebody.md" />
              <FileTree.File name="updatebookcoverbyidrequest.md" />
              <FileTree.File name="updatebookcoverbyidrequestbody.md" />
              <FileTree.File name="updatebookcoverbyidresponse.md" />
            </FileTree.Folder>
          </FileTree.Folder>
          <FileTree.Folder name="sdks">
            <FileTree.Folder name="books">
              <FileTree.File name="README.md" />
            </FileTree.Folder>
            <FileTree.Folder name="orders">
              <FileTree.File name="README.md" />
            </FileTree.Folder>
            <FileTree.Folder name="sdk">
              <FileTree.File name="README.md" />
            </FileTree.Folder>
          </FileTree.Folder>
        </FileTree.Folder>
        <FileTree.File name="jsr.json" />
        <FileTree.File name="package.json" />
        <FileTree.Folder name="src">
          <FileTree.Folder name="hooks">
            <FileTree.File name="hooks.ts" />
            <FileTree.File name="index.ts" />
            <FileTree.File name="registration.ts" />
            <FileTree.File name="types.ts" />
          </FileTree.Folder>
          <FileTree.File name="index.ts" />
          <FileTree.Folder name="lib">
            <FileTree.File name="base64.ts" />
            <FileTree.File name="config.ts" />
            <FileTree.File name="encodings.ts" />
            <FileTree.File name="event-streams.ts" />
            <FileTree.File name="http.ts" />
            <FileTree.File name="primitives.ts" />
            <FileTree.File name="retries.ts" />
            <FileTree.File name="schemas.ts" />
            <FileTree.File name="sdks.ts" />
            <FileTree.File name="security.ts" />
            <FileTree.File name="url.ts" />
          </FileTree.Folder>
          <FileTree.Folder name="models">
            <FileTree.Folder name="components">
              <FileTree.File name="author.ts" />
              <FileTree.File name="fantasybook.ts" />
              <FileTree.File name="httpmetadata.ts" />
              <FileTree.File name="index.ts" />
              <FileTree.File name="neworder.ts" />
              <FileTree.File name="order.ts" />
              <FileTree.File name="orderstreammessage.ts" />
              <FileTree.File name="programmingbook.ts" />
              <FileTree.File name="scifibook.ts" />
              <FileTree.File name="security.ts" />
              <FileTree.File name="user.ts" />
            </FileTree.Folder>
            <FileTree.Folder name="errors">
              <FileTree.File name="index.ts" />
              <FileTree.File name="sdkerror.ts" />
              <FileTree.File name="sdkvalidationerror.ts" />
            </FileTree.Folder>
            <FileTree.Folder name="operations">
              <FileTree.File name="addbook.ts" />
              <FileTree.File name="createorder.ts" />
              <FileTree.File name="getallbooks.ts" />
              <FileTree.File name="getallorders.ts" />
              <FileTree.File name="getbookbyid.ts" />
              <FileTree.File name="getorderbyid.ts" />
              <FileTree.File name="getorderstream.ts" />
              <FileTree.File name="index.ts" />
              <FileTree.File name="updatebookcoverbyid.ts" />
            </FileTree.Folder>
          </FileTree.Folder>
          <FileTree.Folder name="sdk">
            <FileTree.File name="books.ts" />
            <FileTree.File name="index.ts" />
            <FileTree.File name="orders.ts" />
            <FileTree.File name="sdk.ts" />
          </FileTree.Folder>
          <FileTree.Folder name="types">
            <FileTree.File name="blobs.ts" />
            <FileTree.File name="enums.ts" />
            <FileTree.File name="index.ts" />
            <FileTree.File name="operations.ts" />
            <FileTree.File name="rfcdate.ts" />
          </FileTree.Folder>
        </FileTree.Folder>
        <FileTree.File name="tsconfig.json" />
      </FileTree>
    </div>

  </div>
  <div className="md:w-1/2">

### Stainless

    <div className="[&>div>div]:block">
      <FileTree>
        <FileTree.File name="Brewfile" />
        <FileTree.File name="CONTRIBUTING.md" />
        <FileTree.File name="LICENSE" />
        <FileTree.File name="README.md" />
        <FileTree.File name="SECURITY.md" />
        <FileTree.File name="api.md" />
        <FileTree.Folder name="bin">
          <FileTree.File name="publish-npm" />
        </FileTree.Folder>
        <FileTree.Folder name="examples" />
        <FileTree.File name="jest.config.ts" />
        <FileTree.File name="package.json" />
        <FileTree.Folder name="scripts">
          <FileTree.File name="bootstrap" />
          <FileTree.File name="build" />
          <FileTree.File name="format" />
          <FileTree.File name="lint" />
          <FileTree.File name="mock" />
          <FileTree.File name="test" />
          <FileTree.Folder name="utils">
            <FileTree.File name="check-is-in-git-install.sh" />
            <FileTree.File name="check-version.cjs" />
            <FileTree.File name="fix-index-exports.cjs" />
            <FileTree.File name="make-dist-package-json.cjs" />
            <FileTree.File name="postprocess-files.cjs" />
          </FileTree.Folder>
        </FileTree.Folder>
        <FileTree.Folder name="src">
          <FileTree.Folder name="_shims">
            <FileTree.File name="MultipartBody.ts" />
            <FileTree.File name="README.md" />
            <FileTree.Folder name="auto">
              <FileTree.File name="runtime-bun.ts" />
              <FileTree.File name="runtime-deno.ts" />
              <FileTree.File name="runtime-node.ts" />
              <FileTree.File name="runtime.ts" />
              <FileTree.File name="types-deno.ts" />
              <FileTree.File name="types-node.ts" />
              <FileTree.File name="types.d.ts" />
              <FileTree.File name="types.js" />
              <FileTree.File name="types.mjs" />
            </FileTree.Folder>
            <FileTree.File name="bun-runtime.ts" />
            <FileTree.File name="index-deno.ts" />
            <FileTree.File name="index.d.ts" />
            <FileTree.File name="index.js" />
            <FileTree.File name="index.mjs" />
            <FileTree.File name="manual-types.d.ts" />
            <FileTree.File name="manual-types.js" />
            <FileTree.File name="manual-types.mjs" />
            <FileTree.File name="node-runtime.ts" />
            <FileTree.File name="node-types.d.ts" />
            <FileTree.File name="node-types.js" />
            <FileTree.File name="node-types.mjs" />
            <FileTree.File name="registry.ts" />
            <FileTree.File name="web-runtime.ts" />
            <FileTree.File name="web-types.d.ts" />
            <FileTree.File name="web-types.js" />
            <FileTree.File name="web-types.mjs" />
          </FileTree.Folder>
          <FileTree.File name="core.ts" />
          <FileTree.File name="error.ts" />
          <FileTree.File name="index.ts" />
          <FileTree.Folder name="lib" />
          <FileTree.File name="resource.ts" />
          <FileTree.Folder name="resources">
            <FileTree.Folder name="books">
              <FileTree.File name="books.ts" />
              <FileTree.File name="cover.ts" />
              <FileTree.File name="index.ts" />
            </FileTree.Folder>
            <FileTree.File name="index.ts" />
            <FileTree.File name="order-stream.ts" />
            <FileTree.File name="orders.ts" />
          </FileTree.Folder>
          <FileTree.Folder name="shims">
            <FileTree.File name="node.ts" />
            <FileTree.File name="web.ts" />
          </FileTree.Folder>
          <FileTree.File name="uploads.ts" />
          <FileTree.File name="version.ts" />
        </FileTree.Folder>
        <FileTree.Folder name="tests">
          <FileTree.Folder name="api-resources">
            <FileTree.Folder name="books">
              <FileTree.File name="books.test.ts" />
              <FileTree.File name="cover.test.ts" />
            </FileTree.Folder>
            <FileTree.File name="order-stream.test.ts" />
            <FileTree.File name="orders.test.ts" />
          </FileTree.Folder>
          <FileTree.File name="form.test.ts" />
          <FileTree.File name="index.test.ts" />
          <FileTree.File name="responses.test.ts" />
          <FileTree.File name="stringifyQuery.test.ts" />
          <FileTree.File name="uploads.test.ts" />
        </FileTree.Folder>
        <FileTree.File name="tsc-multi.json" />
        <FileTree.File name="tsconfig.build.json" />
        <FileTree.File name="tsconfig.deno.json" />
        <FileTree.File name="tsconfig.dist-src.json" />
        <FileTree.File name="tsconfig.json" />
        <FileTree.File name="yarn.lock" />
      </FileTree>
    </div>

  </div>
</div>

Speakeasy maintains a clear separation of concerns. There are separate folders for models and operations, both in the documentation and in the source folder, and distinct files for each component and operation.

Stainless generates an SDK that, at a glance, looks less organized, considering the greater number of configuration files at the root of the project, no separation of models and operations, and more shims scattered throughout.

Structure might seem superficial at first, but keep in mind that SDK users form their first impressions of your SDK from the same high-level overview. Some of this may be a matter of opinion, but at Speakeasy, we aim to generate SDKs that are as organized as SDKs coded by hand.

## Generated types and type safety

Both Speakeasy and Stainless generate TypeScript types, enabling developers to see errors and hints during development. However, Stainless does not generate types for complex OpenAPI component schemas.

For example, consider the following `Author` component from our OpenAPI document.

```yaml openapi.yaml mark=15:21
!from ./assets/openapi.yaml.txt 476:501
```

The highlighted `anyOf` list is of particular interest. This list states that a valid `Author` object must have a `name` or an `id`, or both. An author with neither a `name` nor an `id` should not validate against this schema.

Let's take a look at the relevant types generated by each SDK generator:

<div className="md:flex gap-10">
  <div className="md:w-1/2">
    ```typescript speakeasy/author.ts
    // ...
    export type AuthorWithID = {
        // !mark
        // !callout[/:/] Only id is required
        id: number; 
        name?: string | undefined;
        photo?: string | undefined;
        biography?: string | undefined;
    };

    export type AuthorWithName = {
        id?: number | undefined;
        // !mark
        // !callout[/:/] Only name is required
        name: string;
        photo?: string | undefined;
        biography?: string | undefined;
    };

    // !mark
    export type Author = AuthorWithName | AuthorWithID;
    ```
  </div>
  <div className="md:w-1/2">
    ```typescript stainless/books.ts
    // ...
    export namespace FantasyBook {
      export interface Author {
        // !mark
        // !callout[/:/] Both id and name are optional
        id?: number;
        biography?: string;
        // !mark
        // !callout[/:/] Both id and name are optional
        name?: string;
        photo?: string;
      }
    }

    // Repeated for ProgrammingBook and SciFiBook
    ```
  </div>
</div>

Here, we see that Speakeasy generates three types for the `Author` schema: `AuthorWithID`, `AuthorWithName`, and a union of these, called `Author`. 

The equivalent type generated by Stainless is an `Author` interface for each book type, with both `id` and `name` marked as optional.

As a result, the following example code using the Stainless SDK will incorrectly compile without any warnings. The equivalent Speakeasy code will correctly catch the compilation error:

<div className="md:flex gap-10">
  <div className="md:w-1/2">
    ```typescript speakeasy-example.ts
    // techbooks-speakeasy SDK created by Speakeasy
    import { TechBooks } from "techbooks-speakeasy";

    const bookStore = new TechBooks({
      apiKey: "123",
    });

    async function run() {
      await bookStore.books.addBook({
        // !mark
        // !callout[/}/] Compilation error: Type '{}' is not assignable to type 'Author'.
        author: {},
        category: "Programming",
        description: "A Handbook of Agile Software Craftsmanship",
        price: 2999,
        title: "Clean Code",
      });
    }

    run();
    ```
  </div>
  <div className="md:w-1/2">

    ```typescript stainless-example.ts
    // techbooks SDK generated by Stainless
    import { Techbooks } from "techbooks";

    const bookStore = new Techbooks({
      apiKey: "My API Key",
      clientId: "My Client ID",
      clientSecret: "My Client Secret",
    });

    async function run() {
      const params: Techbooks.BookCreateParams = {
        // !mark
        // !callout[/}/] No compilation error, even though the author object is empty
        author: {},
        category: "Programming",
        description: "A Handbook of Agile Software Craftsmanship",
        price: 2999,
        title: "Clean Code",
      };

      const result: Techbooks.BookCreateResponse = await bookStore.books.create(
        params
      );
    }

    run();
    ```
  </div>
</div>

### Runtime type checking

This brings us to the next type error that should be caught: runtime type errors. Speakeasy creates SDKs that are type-safe from development to production. As our CEO wrote, [type safe is better than type faith](/post/type-safe-vs-type-faith).

The SDK generated by Speakeasy uses [Zod](https://zod.dev/) to validate the data sent to and received from the server. This provides safer runtime code execution and helps developers who use your SDK to receive early feedback about the data their app is sending. Furthermore, data validation on the client side gives users more confidence in your API's reliability by reducing the opportunity for unintended behavior caused by unexpected data.

To see how this works, let's look at what happens when the `price` field (an `integer` in the `Book` type from our example) is populated with a `float` value:

```yaml mark=18:21
!from ./assets/openapi.yaml.txt 379:406
```

```typescript speakeasy-example.ts
// techbooks-speakeasy SDK created by Speakeasy
import { TechBooks } from "techbooks-speakeasy";

const bookStore = new TechBooks({
  apiKey: "123",
});

async function run() {
  await bookStore.books.addBook({
    author: {
      name: "Robert C. Martin",
      photo: "https://example.com/photos/robert.jpg",
      biography: 'Robert Cecil Martin, colloquially known as "Uncle Bob", is an American software engineer...',
    },
    category: "Programming",
    description: "A Handbook of Agile Software Craftsmanship",
    // !mark
    // !callout[/:/] Validation error: Expected integer, received float
    price: 29.99,
    title: "Clean Code",
  });
}

run();
```

The `price` field in the `Book` object in our test code is set to `29.99`, which is a floating-point number. This will trigger a Zod validation error before the data is sent to the server, as the `price` field is expected to be an integer. [Handling Zod validation errors](https://zod.dev/?id=error-handling) is straightforward, and allows users to get fast feedback on where they are going wrong.

The same book object in code using the Stainless-generated SDK will only be validated on the server. This means that the error will only be caught from the client's perspective _after_ the data is sent to the server, and the server responds with an error message. If the server is not set up to validate the `price` field, the error will _not be caught at all_, leading to unexpected behavior in your users' applications.

As a result, developers using the SDK generated by Stainless may need to write additional client-side validation code to catch these errors before they are sent to the server.

## OAuth client credentials handling

Both Speakeasy and Stainless generate SDKs that handle OAuth 2.0 with client credentials. However, only Speakeasy's SDKs handle the token lifecycle, retries, and error handling without any additional code.

Our bookstore API requires an OAuth 2.0 token with client credentials to access the API. Let's see how the SDKs handle this.

Consider the following OAuth 2.0 configuration from our OpenAPI document:

```yaml openapi.yaml
!from ./assets/openapi.yaml.txt 633:639
```

Speakeasy's generated SDK takes a `clientID` and `clientSecret` when instantiating the SDK. The SDK also includes `ClientCredentialsHook` class that implements `BeforeRequestHook` to check whether the token is expired and refresh it if necessary. The hook also checks whether the client has the necessary scopes to access the endpoint, and handles authentication errors.

<div className="md:flex gap-10">
  <div className="md:w-1/2">
    ```typescript speakeasy-example/addbook.ts
    import { TechBooks } from "techbooks-speakeasy";
    
    const bookStore = new TechBooks({
      security: {
        // !mark(1:3)
        // OAuth 2.0 client credentials
        clientID: "<YOUR_CLIENT_ID_HERE>",
        clientSecret: "<YOUR_CLIENT_SECRET_HERE>",
        },
      });
      
    async function run() {
    // !mark
    // The SDK handles the token lifecycle, retries, and error handling for you
      await bookStore.books.addBook({
        // Book object
      });
    }

    run();
  ```
  </div>


  <div className="md:w-1/2">
    ```typescript stainless-example/addbook.ts
    import TechBooks from 'stainless-book-sdk';
    import axios from 'axios';

    const clientId = '<YOUR_CLIENT_ID_HERE>';
    const clientSecret = '<YOUR_CLIENT_SECRET_HERE>';

    async function getOAuthToken() {
      const response = await axios.post('https://api.bookstore.com/oauth/token', {
        grant_type: 'client_credentials',
        client_id: clientId,
        client_secret: clientSecret
      });
      return response.data.access_token;
    }

    const client = new TechBooks({
      retries: {
        maxRetries: 3
        }
    });

    async function run() {
      // !mark(1:2)
      // Need to manually fetch and manage token
      const token = await getOAuthToken();
      client.defaultHeaders = {
        // !mark
        'Authorization': `Bearer ${token}`,
        'Content-Type': 'application/json'
      };

      await client.books.addBook({
        // Book object
      });
    }

    run();
    ```
  </div>
</div>

The SDK generated by Stainless requires you to manually fetch and manage the OAuth token. This means that you'll need to write additional code to handle the token lifecycle, retries, and error handling. You'll also need to include additional configuration in the Stainless configuration file to use Bearer tokens.

```yaml stainless-config.yaml
client_settings:
  opts:
    access_token:
      type: string
      auth:
        security_scheme: BearerAuth
      read_env: MY_TEAM_ACCESS_TOKEN

security:
  - BearerAuth: []

security_schemes:
  BearerAuth:
    type: http
    scheme: bearer
```

Speakeasy does not require any additional configuration to handle OAuth 2.0 with client credentials. The SDK itself handles the token lifecycle, retries, and error handling.

## Webhooks support

Webhooks enable users to receive real-time updates from your API through HTTP callbacks in your SDK. Speakeasy and Stainless both generate SDKs that support webhooks, but Speakeasy's SDKs provide built-in support for webhook validation, payload parsing, and delivery.

Stainless doesn't provide out-of-the-box functionality for handling webhooks. You must implement your own logic for verifying event signatures, such as HMAC or RSA, defining event payload types, and managing retry mechanisms.

The example below shows how the `techbooks-speakeasy` SDK can validate and parse a `book.created` event, as well as the corresponding OpenAPI spec defining the webhook event.

<div className="md:flex gap-10">
  <div className="md:w-1/2">
    ```typescript speakeasy-example/webhook.ts
    // techbooks-speakeasy SDK created by Speakeasy
    import { TechBooks } from "techbooks-speakeasy";

    const bookStore = new TechBooks();

    async function handleWebhook(request: Request) {
      const secret = "my-webhook-secret";

      const res = await bookStore.webhooks.validateWebhook({ request, secret }); 

      if (res.error) {
        console.error("Webhook validation failed:", res.error);
        throw new Error("Invalid webhook signature");
      }

      // `res.data` is strongly typed based on your OpenAPI spec
      const { data, inferredType } = res;

      switch (data.type) {
        case "book.created":
          console.log("New Book Created:", data.title);
          // ...
          break;
        case "book.deleted":
          console.log("Book Deleted:", data.title);
          // ...
          break;
        default:
          console.warn(`Unhandled event type: ${inferredType}`);
      }
    }
    ```
  </div>
  <div className="md:w-1/2">

  ```yaml openapi.yaml
  # !focus(4:33)
  openapi: 3.1.1
  paths:
    ...
  x-speakeasy-webhooks:
    security:
      type: signature # a preset which signs the request body with HMAC
      name: x-signature # the name of the header
      encoding: base64 # encoding of the signature in the header
      algorithm: hmac-sha256
  webhooks:
    book.created:
      post:
        requestBody:
          required: true
          content:
            application/json:
              schema:
                type: object
                properties:
                  id:
                    type: string
                  title:
                    type: string
                required:
                  - id
                  - title
      responses:
        '200':
          description: Book creation event received
    book.deleted:
    ...
  ```
  </div>
</div>
      
You can read more about how Speakeasy handles webhooks in our [webhooks release post](/post/release-webhooks-support).

## React Hooks

React Hooks simplify state and data management in React apps, enabling developers to consume APIs more efficiently. Speakeasy generates built-in React Hooks using [TanStack Query](https://tanstack.com/query/latest). These hooks provide features like intelligent caching, type safety, pagination, and integration with modern React patterns like SSR and Suspense. Stainless does not generate React Hooks. 

```tsx speakeasy-example/booksView.tsx
import { useQuery } from "@tanstack/react-query";

function BookShelf() { // loads books from an API
  const { data, status, error } = useQuery([
    "books" // Cache key for the query
  ], async () => {
    const response = await fetch("https://api.example.com/books");
    return response.json();
  });

  if (status === "loading") return <p>Loading books...</p>;
  if (status === "error") return <p>Error: {error?.message}</p>;

  return (
    <ul>
      {data.map((book) => (
        <li key={book.id}>{book.title}</li>
      ))}
    </ul>
  );
}
```

For example, in this basic implementation, the `useQuery` hook fetches data from an API endpoint. The cache key ensures unique identification of the query. The `status` variable provides the current state of the query: `loading`, `error`, or `success`. Depending on the query status, the component renders `loading`, `error`, or the fetched data as a list.

For an in-depth look at how Speakeasy uses React Hooks, see our [official release article](/post/release-react-hooks).

## Summary

We've all experienced bad SDKs that make integration with the API harder, not easier. Speakeasy is building a generator to make poorly written, poorly maintained SDKs a thing of the past. To do so, our team has put an extraordinary level of thought into getting the details of SDK generation right. We think that the effort has earned us the position to compare favorably with any other generator.

If you are interested in seeing how Speakeasy stacks up against some of the popular open-source SDK-generation tools, check out [this post](/post/compare-speakeasy-open-source).


 This is the content for the doc blog/standalone-functions/index.mdx 

 ---
title: Lean SDKs with Standalone Functions
description: Standalone functions are a new way to access functionality in an SDK while maintaining smaller bundle sizes.
image: "/media/standalone-functions.png"
date: 2024-08-16
authors:
  - name: Georges Haidar
  - image_url: "/media/author-headshots/georges.jpeg"
tags:
  - Product Updates
featured_image: "/media/standalone-functions.png"
---

import { CodeWithTabs } from "~/components/codehike/CodeTabs";
import { Callout } from "~/components";

Today we're introducing a feature for every Speakeasy-generated TypeScript SDK,
called Standalone Functions. This feature makes it possible for your users to
build leaner apps on top of your API, that can run in the browser, or any other
environment where performance is an important consideration.

## The short version

Rather than needing to import the entire library, your SDK users will be able to
select specific functions they want to use. Here's what the change looks like
with [Dub's SDK](https://dub.co/):

```ts
import { Dub } from "dub";

async function run() {
  const dub = new Dub();

  const count = await dub.links.count();

  console.log("Link count:", count);
}

run();
```

Into this:

```ts
import { DubCore } from "dub/core.js";
import { linksCount } from "dub/funcs/linksCount.js";

async function run() {
  const dub = new DubCore();

  const result = await linksCount(dub);
  if (!result.ok) {
    throw result.error;
  }

  // Use the result
  console.log("Link count:", result.value);
}

run();
```

All the SDK's unused functionality: methods, Zod schemas, encoding/decoding
helpers and so on, will be excluded from the user's final application build. The
bundler will tree-shake the package and handle minification of the unused code
from within the modules.

Additionally, standalone functions return a `Result<Value, KnownErrors>` type
which brings about better error handling ergonomics.

<Callout title="Note" variant="info">
  Standalone functions _do not_ replace the existing class-based interface. All
  Speakeasy TypeScript SDKs now provide both functions and classes. We think
  they are both equally valid ways for developers to work with SDKs. The
  decision on which style to use can be based on the project you're building and
  what constraints are in place.
</Callout>

## Impact

Combining standalone functions with ES Modules yields massive savings as shown
in the bundle analysis for the sample programs above.

Using `dub@0.35.0` with the class-based API:

![Bundle size of about 324.4 kilobytes when using Dub v0.35.0 with the class-based API](/media/dub-0.35.0-impact.jpeg)

Using `dub@0.36.0` with the standalone functions API:

![Bundle size of about 82.1 kilobytes when using Dub v0.36.0 with the standalone functions API](/media/dub-0.36.0-impact.jpeg)

Please note that the sizes above are _before_ compressing the bundles with Gzip
or Brotli. The uncompressed size is a good proxy for metrics like JavaScript
parsing time in the browser. Regardless, it's a great idea to compress code
before serving it to browsers or using a CDN that handles this for you.

<Callout title="Note" variant="info">
  Our TypeScript SDKs use Zod to build great support for complex validation and
  (de)serialization logic. If you are already using Zod in your application then
  consider excluding its size (~50KB) when thinking about the numbers above. The
  impact is even more compelling in this case.
</Callout>

## The long version

Many SDKs are built around the concept of a class that you instantiate and,
through it, access various operations:

```ts
import { Beezy } from "@speakeasy-sdks/beezyai";

const beezy = new Beezy(); // The SDK class

const stream = await beezy.chat.stream({
  prompt: "What is the most consumed type of cheese?",
  model: "ex-30b",
});

// Use the result...
```

This works great from a developer experience perspective especially if you are
using an IDE with language server support. You can autocomplete your way to most
functionality and breeze through your work.

If we dig under the surface, we would likely find a typical SDK is arranged like
so:

<div style={{ height: 440 }}>
  <CodeWithTabs>

```typescript !!tabs src/index.ts
import { Chat } from "./chat.js";
import { Files } from "./files.js";

export class Beezy extends APIClient {
  chat = new Chat();
  files = new Files();
}
```

```typescript !!tabs src/chat.ts
import { ChatHistory } from "./chat-history.js";
import { createEventStream } from "./lib/event-streams.js"
import { encodeJSON } from "./lib/encodings.js"

class Chat extends APIClient {
  history = new ChatHistory();

  /**
   * Stream a response to a prompt.
   */
  async stream(req: ChatRequest): Promise<EventStream<ChatCompletion>> { /* ... */ }

  /**
   * Generate a complete response to a prompt.
   */
  async complete(req: CompletionRequest): Promise<ChatResponse> { /* ... */ }
}
```

```typescript !!tabs src/files.ts
import { encodeMultipart } from "./lib/encodings.js"

class Files extends APIClient {
  /**
   * Create a multipart request to upload files for fine tuning and other jobs.
   */
  async upload(req: FileUploadRequest): Promise<UploadResult> { /* ... */ }
}
```

```typescript !!tabs src/chat-history.ts
import { createPaginatedIterable } from "./lib/pagination.js"
import { encodeJSON } from "./lib/encodings.js"

class ChatHistory extends APIClient {
  /**
   * Paginated list of chat sessions.
   */
  async function list(req: ListChatsRequest): Promise<ChatSession[]> { /* ... */ }
}
```

  </CodeWithTabs>
</div>

However, if you're building a web app/site, there is a downside to this approach
that is not immediately apparent: the entire SDK will be included in your app's
bundle because there is little or no opportunity to tree-shake or exclude unused
code from the SDK. If we were to bundle the snippet of code above, then all the
code in the `Beezy`, `Chat`, `Files` and `ChatHistory` classes as well as all of
the code that supports those classes an their methods, such as pagination and
multipart request helpers, will be include in our app. Yet, we only called
`beezy.chat.stream()`.

### A brief crash course on bundlers and tree-shaking

A lot of web apps are built using front-end frameworks with bundlers such as
[Rollup][rollup], [Webpack][webpack], [ESBuild][esbuild],
[Turbopack][turbopack]. Bundlers are responsible for a bunch of tasks including
taking your TypeScript code and code from all the libraries you used, converting
into a JavaScript files that can be loaded on the browsers. They also employ
techniques to reduce the amount of JavaScript to load such as
[minifying][zod-minify] the code, splitting a bundle into smaller parts to load
functionality incrementally and tree-shaking to eliminate unused code from your
codebase and the libraries you've used.

[rollup]: https://rollupjs.org/
[webpack]: https://webpack.js.org/
[esbuild]: https://esbuild.github.io/
[turbopack]: https://turbo.build/pack/docs
[zod-minify]: /post/writing-zod-code-that-minifies

Tree-shaking is the process of identifying what parts of a JavaScript module
were used and only including that subsection of the module. Here's an example
from ESBuild:

![Example of bundling a simple app with ESBuild](/media/esbuild-bundle-example.jpeg)

([Playgound link for the screenshot above][esbuild-playground])

[esbuild-playground]: https://esbuild.github.io/try/#YgAwLjIzLjAALS1idW5kbGUgLS1mb3JtYXQ9ZXNtAGUAZW50cnkuanMAaW1wb3J0IHsgZ3JlZXQgfSBmcm9tICIuL21vZHVsZS1hLmpzIjsKCmNvbnNvbGUubG9nKGdyZWV0KCJHZW9yZ2VzIikpOwAAbW9kdWxlLWEuanMAZXhwb3J0IGZ1bmN0aW9uIGdyZWV0KG5hbWUpIHsKICByZXR1cm4gYEhlbGxvLCAke25hbWV9IWA7Cn0KCmV4cG9ydCBmdW5jdGlvbiBhZGQoYSwgYikgewogIHJldHVybiBhICsgYjsKfQoKZXhwb3J0IGNvbnN0IFBJID0gMy4xNDsKCmV4cG9ydCBjb25zdCBjb2xvcnMgPSB7CiAgcmVkOiAiI2ZmMDAwMCIsCiAgZ3JlZW46ICIjMDBmZjAwIiwKICBibHVlOiAiIzAwMDBmZiIsCn07

Notice how in the build output, the `add`, `PI` and `colors` exports were not
included. Most bundlers are capable of tree-shaking, some apply better or more
heuristics than others, but generally the rule is to analyze which module
exports were used and leave out the rest.

### And we're back

So if we understand how tree-shaking works, we can arrange our SDK code a little
differently and greatly reduce the impact of our package on a web app's total
bundle size. This is what's new in our recent changes to the generator. We now
create a folder in every TypeScript SDK at `src/funcs/` and emit standalone
functions. Here's a simplified example of one:

```typescript
import { BeezyCore } from "../core.js";

export async function chatStream(
  client: BeezyCore,
  req: ChatRequest
): Promise<
  Result<
    EventStream<ChatCompletion>,
    ForbiddenError | RateLimitError | TimeoutError
  >
> { /* ... */ }
```

The interesting change is that instead of attaching methods to classes, we
designed functions to take a tiny "client" as their first argument. This small
_inversion_ means bundlers can dial it up to the max with their tree-shaking
algorithms since functions are module-level exports.

## Playing the long game

When you peer into a function's source code today, you'll notice it's more
verbose than a one line call to a massive HTTP client abstraction. There's code
to validate data with Zod schemas, encode query, path and header parameters and
execute response matching logic. This was a deliberate decision because it
allows us, and by extension you, to have fine-grained control over tree-shaking.
Whereas deep abstractions are very appealing at first, they end up unnecessarily
dragging in all the functionality an SDK provides even if small subsets of it
are needed. We're choosing shallower abstractions instead and reaping the
benefits.

From the results we've seen so far, we think standalone functions are the right
building block for modern web apps. We're excited to see what you'll build with
them.


 This is the content for the doc blog/tags-best-practices-in-openapi/index.mdx 

 ---
title: "Tags Best Practices in OpenAPI"
description: "An actionable guide on how to correctly set tags in your OpenAPI schema to organize your API endpoints."
keywords: [openapi, swagger, tag, sdk generation, sdk]
image: "/media/openapi-tips-tags.png"
date: 2023-11-22
authors:
  - name: Nolan Sullivan
  - image_url: "/media/author-headshots/nolan.jpeg"
tags:
  - OpenAPI Tips
featured_image: "/media/openapi-tips-tags.png"
---

import { ScrollyCoding } from "~/components/codehike/Scrollycoding";
import { Callout } from "~/components";

<Callout title="Announcing: OpenAPI Reference" variant="success">
Hi! These blog posts have been popular, so we've built an entire [OpenAPI Reference Guide](/openapi/) to answer any question you have.

It includes detailed information on [**tags**](/openapi/tags).

Happy Spec Writing!

</Callout>

## Introduction

This article explains how to use [tags in OpenAPI](https://spec.openapis.org/oas/latest.html#tag-object).

Tags are the way to organize your API endpoints into groups to make them easier for users to understand.

## Definitions

Every separate feature in your API that a customer can call is named an **endpoint**.

An endpoint is an **operation** (an HTTP method like GET or POST) applied to a **path** (for example, `/users`).

Below is an example endpoint in an OpenAPI schema. The path is `play`, and the operation is a POST.

```yaml
paths:
  /play:
    post:
      description: Choose your jazz style.
      operationId: band#play
```

In informal conversation, people often refer to API endpoints and operations as if the terms are interchangeable.

Paths are the natural way to categorize your endpoints. You might have separate paths in your API for products, purchases, or accounts. However, paths are hierarchical. Each endpoint can be in only one path. This may make it difficult for users of your API to browse to the feature they are looking for if they assume it's under a different path.

By contrast, each endpoint may have multiple tags, so may be shown in multiple groups in your schema documentation.

## Example Schema

To demonstrate using tags, let's make a simple schema for a jazz club API with just three paths:

- `/play` — plays music.
- `/stop` — stops music.
- `/order` — orders a drink.

<ScrollyCoding className="ch-scrollycoding-full-height" fullHeight>

### !!steps API Information

Start with some basic information about your API.

```yaml !
# !focus(1:6)
openapi: 3.0.3
info:
  title: The Speakeasy Club
  description: A club that serves drinks and plays jazz.
  version: 1.0.0
servers: []
```

---

### !!steps Simple Tag

Add the `tags` root-level object with a tag for drink operations.

Only the tag `name` is mandatory.

```yaml !
# !focus(7:13)
openapi: 3.0.3
info:
  title: The Speakeasy Club
  description: A club that serves drinks and plays jazz.
  version: 1.0.0
servers: []
tags:
  - name: Drinks
```

---

### !!steps Detailed Tag

Add another tag with more detail. The **Music** tag has a `description` string and an `externalDocs` object with two required fields: `description` and `url`.

The URL points to information anywhere on the web that you want to use to describe the endpoint. Use `externalDocs` if you don't want to overcrowd your schema with unnecessary detail or if another department in your company maintains the documentation separately.

```yaml !
# !focus(9:13)
openapi: 3.0.3
info:
  title: The Speakeasy Club
  description: A club that serves drinks and plays jazz.
  version: 1.0.0
servers: []
tags:
  - name: Drinks
  - name: Music
    description: A band that plays jazz.
    externalDocs:
      description: List of jazz genres
      url: https://en.wikipedia.org/wiki/List_of_jazz_genres
```

---

### !!steps Paths

Now that we have tag definitions, we can tag our endpoints.

Here the `/play` and `/stop` endpoints are tagged with `Music`, and the `/order` endpoint is tagged with `Drinks`.

We could also make another tag called `Front of house` and apply it to both endpoints to organize them separately to `Backstage` endpoints.

```yaml !
# !focus(17,18,35,36,45,46)
openapi: 3.0.3
info:
  title: The Speakeasy Club
  description: A club that serves drinks and plays jazz.
  version: 1.0.0
servers: []
tags:
  - name: Drinks
  - name: Music
    description: A band that plays jazz.
    externalDocs:
      description: List of jazz genres
      url: https://en.wikipedia.org/wiki/List_of_jazz_genres
paths:
  /play:
    post:
      tags:
        - Music
      summary: Play music
      description: Choose your jazz style.
      operationId: band#play
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/PlayRequestBody"
            example:
              style: Bebop
      responses:
        "204":
          description: No Content response.
  /stop:
    post:
      tags:
        - Music
      summary: Stop music
      description: Stop playing.
      operationId: band#stop
      responses:
        "204":
          description: No Content response.
  /order:
    post:
      tags:
        - Drinks
      summary: Order tea
      description: Order a cup of tea.
      operationId: order#tea
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/TeaRequestBody"
            example:
              includeMilk: false
      responses:
        "204":
          description: No Content response.
```

</ScrollyCoding>

## The Full Schema Example

Below is the full example schema with `components` added to specify how to call the endpoints.

Paste the code into the [Swagger editor](https://editor.swagger.io/) to see it displayed as a formatted document. Note that operations in the Swagger output are grouped by `tag`.

```yaml
openapi: 3.0.3
info:
  title: The Speakeasy Club
  description: A club that serves drinks and plays jazz.
  version: 1.0.0
servers: []
tags:
  - name: Drinks
  - name: Music
    description: A band that plays jazz.
    externalDocs:
      description: List of jazz genres
      url: https://en.wikipedia.org/wiki/List_of_jazz_genres
paths:
  /play:
    post:
      tags:
        - Music
      summary: Play music
      description: Choose your jazz style.
      operationId: band#play
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/PlayRequestBody"
            example:
              style: Bebop
      responses:
        "204":
          description: No Content response.
  /stop:
    post:
      tags:
        - Music
      summary: Stop music
      description: Stop playing.
      operationId: band#stop
      responses:
        "204":
          description: No Content response.
  /order:
    post:
      tags:
        - Drinks
      summary: Order tea
      description: Order a cup of tea.
      operationId: order#tea
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/TeaRequestBody"
            example:
              includeMilk: false
      responses:
        "204":
          description: No Content response.
components:
  schemas:
    PlayRequestBody:
      type: object
      properties:
        style:
          type: string
          description: Style of music to play
          example: Bebop
          enum:
            - Bebop
            - Swing
      example:
        style: Bebop
      required:
        - style
    TeaRequestBody:
      type: object
      properties:
        includeMilk:
          type: boolean
          description: Whether to have milk.
          example: true
      example:
        includeMilk: false
```

Below is what it looks like in the editor.

![Swagger output](./assets/swagger_tag_example.png)

## Tags in Speakeasy

Speakeasy will split the SDKs and documentation it generates based on your tags.

You can add the [x-speakeasy-group](/docs/customize-sdks/namespaces#define-namespaces-without-tags) field to an endpoint to tell Speakeasy to ignore the endpoint's tag and group it under the custom group instead.

## Conclusion

That's everything you need to know about tags in OpenAPI.

There are just three more tag rules you might want to know:

- Tags are optional, both at the root level and on endpoints.
- Tags must have unique names in your schema.
- The tag `description` may use [CommonMark syntax](https://spec.commonmark.org/).


 This is the content for the doc blog/terraform-enhancing-validation/index.mdx 

 ---
title: "Enhancing Terraform Providers with Configuration Validation"
description: "A guide on adding configuration validation to Terraform Providers to improve efficiency, user experience, and resource management."
keywords: [terraform, terraform provider, validation, api, configuration]
image: "/media/terraform-enhancing-validation.png"
date: 2024-07-24
authors:
  - name: Ash Godfrey
  - image_url: "/media/author-headshots/ash.jpg"
tags:
  - Terraform
featured_image: "/media/terraform-enhancing-validation.png"
---

When working with APIs, ensuring that the values we send meet specific requirements, such as string lengths or numerical ranges, is crucial. This validation becomes even more critical when using Terraform Providers to interact with these APIs. Relying only on server-side validation can lead to slow feedback loops, errors during the apply phase, and frustrated users. Plan validation in Terraform Providers helps catch these issues earlier, improving the end-user experience by providing immediate feedback and preventing errors before they occur. This blog post explores how you can add configuration validation to your Terraform Providers.

### The Problem with Missing Validation

APIs often enforce strict value requirements, such as minimum and maximum string lengths, numerical ranges, or specific formats. When a Terraform Provider interacts with an API but lacks validation for these requirements, Terraform's validate and plan operations may proceed without issues. However, the apply operation can fail due to API errors, leading to frustrating and time-consuming feedback loops. These failures can occur in the middle of applying resources, causing further complications and delays.

Imagine you're deploying multiple resources, and halfway through the process, an API error occurs because of an invalid string length. You would need to fix the issue and rerun the apply operation, wasting valuable time and resources. The goal is to enhance the user experience by having Terraform raise validation errors before applying configurations, ensuring smoother deployments and reducing the risk of mid-apply failures.

### Why Does It Matter?

- **Efficiency**: Early error detection saves time and resources by preventing mid-apply failures.
- **User Experience**: Immediate feedback during validation enhances satisfaction and reduces frustration.
- **Resource Management**: Preventing mid-apply failures ensures infrastructure remains stable and consistent.
- **Scalability**: Early validation maintains a reliable deployment process as infrastructure grows.
- **Error Reduction**: Automating validation reduces the risk of human error and ensures consistent application of validation rules.

### Manual Validation in Terraform Providers

Adding validation to Terraform Providers involves implementing [validators](https://developer.hashicorp.com/terraform/plugin/framework/validation) within the resource schema.

Let's assume you are developing a Terraform provider for managing a simple resource, such as a "User" resource, which has a "username" attribute:

```go
func NewUserResource() resource.Resource {
    return &userResource{}
}

type userResource struct{}

func (r *userResource) Metadata(_ context.Context, req resource.MetadataRequest, resp *resource.MetadataResponse) {
    resp.TypeName = req.ProviderTypeName + "_user"
}

func (r *userResource) Schema(_ context.Context, _ resource.SchemaRequest, resp *resource.SchemaResponse) {
    resp.Schema = schema.Schema{
        Attributes: map[string]schema.Attribute{
            "username": stringattribute.String{
                Required:    true,
                Description: "The username of the user.",
                Validators: []validator.String{
                     stringvalidator.LengthBetween(6, 64),
                     stringvalidator.RegexMatches(
                        regexp.MustCompile(`^[a-z]+$`),
                        "must contain only lowercase alphanumeric characters",
                    ),
                },
            },
        },
    }
}
```

- The `username` attribute is defined with type `schema.TypeString` and marked as required.
- The `username` attribute is defined with string validation helpers from [`terraform-plugin-framework-validators`](https://pkg.go.dev/github.com/hashicorp/terraform-plugin-framework-validators) that checks if the length of the string is between 6 and 64 characters, as well as only lowercase characters.

Consider the following configuration:

```
resource "user" "test" {
  username = "abcd"
}
```

Running `terraform validate` will produce an error if the `username` length does not meet the specified criteria:

```go
- Error: Invalid value for field "username": String length must be between 6 and 64 characters.
- Error: Invalid value for field "username": must contain only lowercase alphabetic characters.
```

[See more in the terraform-plugin-framework-validators package here](https://pkg.go.dev/github.com/hashicorp/terraform-plugin-framework-validators).

Repeating this process for every field in your Terraform Provider is daunting, but necessary to enhance the user experience by catching errors early in the validation phase, preventing issues during the apply phase, and ensuring smoother deployments.

### Configuration Validation with Speakeasy

Speakeasy simplifies the process of adding configuration validation to Terraform Providers by automatically generating validation handlers based on your OpenAPI specification.

By default, these OpenAPI specification properties are automatically handled:

- For `string` types: `enum`, `maxLength`,`minLength`, and `pattern`
- For integer types: `enum`, `minimum` and `maximum`
- For `array` types: `maxItems`, `minItems`, and `uniqueItems`

For scenarios not covered by these default handlers, Speakeasy supports custom validation logic. If you’re interested in finding out more, see our [Terraform Provider generation documentation](/docs/create-terraform) and join our [Slack](https://speakeasy-dev.slack.com/ssb/redirect#/shared-invite/email) to chat with our engineering team.

### Conclusion: Enhancing Terraform Providers with Validation

Adding configuration validation to Terraform Providers is essential for improving the end user experience and ensuring smooth deployments. By implementing validation, whether manually or through generated providers like those created by Speakeasy, developers can ensure consistent, efficient, and reliable configurations, ultimately benefiting API consumers. With robust validation in place, the risk of errors is minimized, leading to more stable and predictable infrastructure management.


 This is the content for the doc blog/the-rest-template-project.mdx 

 ---
title: "The REST Template Project"
description: "The RESTful API template project is live. RESTful API templates for the most used programming languages – starting today with Go."
image: "/media/the-rest-template-project.png"
date: 2022-08-02
authors:
  - name: Tristan Cartledge
  - image_url: "https://uploads-ssl.webflow.com/62ccd7b208cab0723d026273/635ff12733f46637e91ced22_1516859875198.jpg"
tags:
  - Product Updates
featured_image: "/media/the-rest-template-project.png"
---

## Github Repository: [speakeasy-api/rest-template-go](https://github.com/speakeasy-api/rest-template-go)

Building a RESTful API can be daunting for developers who have never done it before (and even those who have). There are a number of choices and best practices that need to be considered as part of an API’s implementation; it can be hard to know where to start. That’s why we’re pleased to announce the [RESTful API template project.](https://github.com/speakeasy-api/rest-template-go) Over the coming months, we will release RESTful API templates for the most used programming languages – [starting today with Go](https://github.com/speakeasy-api/rest-template-go).

This is the template that our team forks from when we are building new APIs. The repo contains a CRUD API for a ‘user’ resource which incorporates the best practices needed for a basic REST service. Our hope is that developers can use this as a foundation upon which to build their own sets of APIs.

The service represents our team’s opinionated stance about what makes for good RESTful API code. Specifically, the template gives you a service which is:

- **Entity-based**: The resources available should represent the domain model. Each resource should have the CRUD methods implemented (even if not all are available to API consumers). In our template, we have a single resource defined (users.go). However other resources could be easily added by copying the template and changing the logic of the service layer.
- **Properly Abstracted**: The transport, service, and data layers are all cleanly abstracted from one another. This makes it easy to apply updates to your API endpoints.
- **Consistent**: It's important that consumers of a service have guaranteed consistency across the entire range of API endpoints and methods. In this service, responses are consistently formatted whether successfully returning a JSON object or responding with an error code. All the service's methods use shared response (http.go) and error (errors.go) handler functions to ensure consistency.
- **Tested**: We believe that a blend of unit and integration testing is important for ensuring that the service maintains its contract with consumers. The service repo therefore contains a collection of unit and integration tests for the various layers of the service.
- **Explorable**: It is important for developers to be able to play with an endpoint in order to understand it. We have provided Postman collections for testing out the REST endpoints exposed by the service. There is a Bootstrap Users collection that can be run using the Run collection tool in Postman that will create 100 users to test the search endpoint with.

We look forward to hearing from the community what they think of the repo. We’d love to know what else people would want to see included in a template: versioning, pagination, authentication?  Would people want to see more advanced features?


 This is the content for the doc blog/type-safe-vs-type-faith/index.mdx 

 ---
title: "Type Faith vs Type Safe"
description: "Type Faith vs Type Safe. What's the difference and why it matters."
keywords: [sdks, api, devex, typescript, developer experience]
image: "/media/type-safe-type-faith.png"
date: 2024-04-16
authors:
  - name: Sagar Batchu
  - image_url: "/media/author-headshots/sagar.jpeg"
tags:
  - API Advice
featured_image: "/media/type-safe-type-faith.png"
is_featured: true
---

### Type Faith vs Type Safe

### Introduction

Type safety is a core aspect of modern programming, ensuring that errors related to mismatched or incorrect data types are caught at compile time rather than during execution. 
The evolution of JavaScript—a language known for its flexibility and lack of strict type enforcement—saw a significant shift with the introduction of TypeScript. 
TypeScript, developed by Microsoft, brought static type checking to the JavaScript ecosystem, helping developers catch errors early in the development process.

However, TypeScript isn't without its limitations. While it enforces type safety within the codebase, it cannot guarantee the correctness of data coming from external sources like APIs. 
This becomes a critical issue when developers assert incorrect data types received from APIs, leading to potential runtime errors and system failures.

The good news for API builders is that it is now possible to provide end-to-end type safety in their libraries, ensuring that data types are consistent throughout the application and API interactions.

### Type Faith

Developers often opt out of implementing end-to-end type safety in their libraries due to the complexity and additional coding required. This decision places a significant burden on end users who 
must then ensure data type correctness in their applications, a process that is both error-prone and time-consuming.

For example, consider a scenario where an API is expected to return a list of user objects, but due to changes in the backend, it starts returning mixed types (users and admin objects). A client 
application relying on type faith—assuming the returned data matches the expected types without validation—may perform operations that are valid for user objects but not for admin objects, 
leading to runtime errors and application crashes.

### Type Safe

To achieve true type safety, developers can use tools like Zod to validate and enforce data types at runtime. Zod allows for the definition of schemas that describe the expected shape and type of data. 
Here's a simple example of how Zod can be used to enforce type safety when handling API responses

```typescript
import { z } from 'zod';

// Define a schema for the user object
const UserSchema = z.object({
  id: z.number(),
  name: z.string(),
  email: z.string().email(),
});

// Function to validate API response
function validateApiResponse(data: unknown) {
  try {
    // Validate data against the schema
    UserSchema.parse(data);
    console.log('Data is valid!');
  } catch (error) {
    console.error('Invalid data:', error);
  }
}

// Simulated API response
const apiResponse = {
  id: 1,
  name: "John Doe",
  email: "john@example.com",
};

validateApiResponse(apiResponse);
```

Using such validations, the end developer who consumes the API can trust that the data they are working with is correctly typed, reducing the risk of bugs and improving the reliability of the application.

### Conclusion

Implementing end-to-end type safety requires additional effort from the developers building the API libraries. However, the benefits in terms of application stability, security, and developer productivity are immense. 
As the ecosystem evolves, the tools and practices around type safety continue to improve, making it increasingly feasible to achieve robust type safety across the board. By adopting these practices, developers 
can ensure that their applications are not only functional but also secure and resilient against type-related errors.

 This is the content for the doc blog/vitest-vs-jest/index.mdx 

 ---
title: "Vitest vs Jest"
description: "A comparison of Jest and Vitest in terms of their features, performance, and developer experience to help you decide which JavaScript testing framework is best for your use case."
image: "/media/vitest-vs-jest.png" 
date: 2024-09-30
authors:
  - name: Nolan Sullivan
  - image_url: "/media/author-headshots/nolan.jpeg"
tags:
  - Testing
featured_image: "/media/vitest-vs-jest.png"
---

import { Callout } from '~/components'


<Callout title="NOTE" variant="info">
This article was updated in January 2025 to reflect the release of [Vitest 3](https://github.com/vitest-dev/vitest/releases/tag/v3.0.0), which introduces new features and improvements, as well as some breaking changes. Be sure to check the [official Vitest documentation](https://vitest.dev/blog/vitest-3.html) and migration guide for further details.
</Callout>

Effective testing frameworks are essential in building reliable JavaScript applications, helping you minimize bugs and catch them early to keep your customers happy. Choosing the right testing framework saves hours of configuration hassles and improves developer experience.

This post compares [Jest](https://jestjs.io/) and [Vitest](https://vitest.dev/), popular JavaScript testing frameworks that support unit testing, integration testing, and [snapshot testing](https://jestjs.io/docs/snapshot-testing).

**Jest** — created by the Facebook team, is the most widely used JavaScript testing framework.

**Vitest** — a fast-growing new testing framework. Originally built for [Vite](https://vite.dev/), the popular development server and JavaScript bundler, Vitest can now be used with any JavaScript project, not just those using Vite.

## Which JavaScript testing framework is right for you?

We think Vitest is best, unless you're using a framework or library that has better Jest support, such as React Native. The table below compares some features of the two testing frameworks. **If you're starting a new project, use Vitest**. With ES module, TypeScript, JSX, and PostCSS support out of the box, Vitest is the right choice for almost every modern JavaScript app. 

|                                  | Jest | Vitest |
|----------------------------------|------|--------|
| Battle tested by large companies | ✅    | ❌      |
| ES module support                | ✅\*  | ✅      |
| TypeScript support               | ✅+   | ✅      |
| Browser UI                       | ❌    | ✅\*    |
| Type testing                     | ❌    | ✅\*    |
| Benchmarking                     | ❌    | ✅      |
| In-source testing                | ❌    | ✅      |
| Browser mode                     | ❌    | ✅\*    |
| Multi-browser support            | ❌    | ✅      |
| Enhanced error matching          | ❌    | ✅      |
| Project-level configuration      | ✅    | ✅\*\*  |
| Snapshot testing                 | ✅    | ✅      |
| Interactive snapshot testing     | ✅    | ❌      |
| Code coverage                    | ✅    | ✅      |
| Concurrent testing               | ✅\*  | ✅      |
| Sharding support                 | ✅    | ✅      |
| Multi-project runner             | ✅    | ❌      |
| Mocking                          | ✅    | ✅      |

\* Experimental <br/>
\+ Using Babel <br/>
\*\* Includes inline workspace support


At Speakeasy, we've tried both Jest and Vitest, and ultimately chose Vitest – even without Vite in our setup.

We decided to document our experience and dive deeper into both Vitest and Jest, comparing the two testing frameworks in terms of their features, performance, and developer experience to further help you decide which is best for your use case. We'll also share our experience of migrating from Jest to Vitest for our TypeScript SDK and how we're using Vitest for our new automated API testing feature, which is currently in beta, for Speakeasy-created SDKs.

## Jest's beginnings: From Facebook to open source

Back in 2011, no JavaScript testing framework existed that met the Facebook (now Meta) team's testing needs, so they built Jest. Jest was open-sourced in 2014, shortly after React was open-sourced, and as React rapidly gained in popularity, so did Jest.

Popular React project starter [Create React App](https://create-react-app.dev/) integrated Jest as its default testing framework in 2016 and Jest soon became the go-to testing tool for React developers. When Next.js, the most popular React framework, included built-in Jest configuration in version 12, Jest's dominance in the React ecosystem was secured.

Ownership of Jest was transferred to the [OpenJS Foundation](https://engineering.fb.com/2022/05/11/open-source/jest-openjs-foundation/) in 2022 and the framework is currently maintained by a core group of contributors external to Meta.

## Jest features

Jest's popularity is in part thanks to the extensive Jest API that handles a variety of testing needs, including snapshots, mocking, and code coverage, making it suitable for most unit testing situations. Jest works with Node.js and frontend frameworks like React, Angular, and Vue, and can be used with TypeScript using Babel or the `ts-jest` library to transpile TypeScript to JavaScript.

Consider the following example snapshot test:

```javascript link.test.js.snap
test("Checkout link renders correctly", () => {
  const tree = renderer
    .create(<Link page="http://www.instagram.com">Go to checkout</Link>)
    .toJSON();
  expect(tree).toMatchSnapshot();
});
```

The [`test`](https://jestjs.io/docs/api#testname-fn-timeout) method runs a test. The Jest [`expect` API](https://jestjs.io/docs/expect) provides modifier and matcher (assertion) methods that simplify checking whether a value is what you expect it to be. Among the matcher methods available are:

- `toBe()`
- `toHaveProperty()`
- `toMatchSnapshot()`

Jest's extensive set of modifiers and matchers makes error messages more detailed, helping you pinpoint why a test fails. The [jest-extended](https://github.com/jest-community/jest-extended) library, maintained by the Jest community, provides additional matchers to expand testing functionality.

You can use Jest's [mock functions](https://jestjs.io/docs/mock-functions) to mock objects, function calls, and even npm modules for faster testing without relying on external systems. This is especially useful for avoiding expensive function calls like calling a credit card charging API in the checkout process of an app.

To run code before and after tests run, Jest provides handy [setup and teardown functions](https://jestjs.io/docs/setup-teardown): `beforeEach`, `afterEach`, `beforeAll`, and `afterAll`.

```javascript cityDb.test.js
beforeAll(() => {
  return initializeCityDatabase();
});

afterAll(() => {
  return clearCityDatabase();
});
```

```javascript cityDb.test.js
beforeEach(() => {
  initializeCityDatabase();
});

afterEach(() => {
  clearCityDatabase();
});

test("city database has Vienna", () => {
  expect(isCity("Vienna")).toBeTruthy();
});

test("city database has San Juan", () => {
  expect(isCity("San Juan")).toBeTruthy();
});
```

When running tests, you can add the `--watch` flag to only run tests related to changed files.

```shell
jest --watch
```

While Vitest doesn't have Jest's [Interactive Snapshot Mode](https://jestjs.io/docs/snapshot-testing#interactive-snapshot-mode), which enables you to update failed snapshots interactively in watch mode, this feature has been [added to Vitest's TODO list](https://github.com/vitest-dev/vitest/issues/2229).

Jest also has a multi-project runner for running tests across multiple projects, each with their own setup and configuration, using a single instance of Jest.

## Getting started with Jest

To set up a basic test, install Jest as a development dependency:

```shell
npm install --save-dev jest
```

Create a test file with `.test` in its name, for example, `sum.test.js`:

```javascript sum.test.js
const sum = require("./sum");

test("adds 1 + 2 to equal 3", () => {
  expect(sum(1, 2)).toBe(3);
});
```

This code imports a `sum` function that adds two numbers and then checks that `1` and `2` have been correctly added.

Add the following script to your `package.json` file:

```json package.json
{
  "scripts": {
    "test": "jest"
  }
}
```

Run the test using the following command:

```shell
npm run test
```

Jest finds the test files and runs them. Jest will print the following message in your terminal if the test passes:

```shell
PASS  ./sum.test.js
✓ adds 1 + 2 to equal 3 (5ms)
```

## The origin of Vitest: The need for a Vite-native test runner

The introduction of in-browser ES modules support led to the creation of the popular JavaScript bundler and development server Vite, which uses ES modules to simplify and speed up bundling during development. While it's possible to use Jest with Vite, this approach creates separate pipelines for testing and development. Among other factors, Jest requires separate configuration to transpile ES modules to CommonJS using Babel. A test runner that supports ES modules would integrate better with Vite and simplify testing. Enter Vitest.

Developed by core Vite team member, Anthony Fu, Vitest is built on top of Vite, but you can use it in projects that don't use Vite.

Vite's rise in popularity can be attributed to its simplicity and performance. Unlike traditional JavaScript bundlers that can be slow when running development servers for large projects, the Vite development server loads fast, as no bundling is required. Instead, Vite transforms and serves source code as ES modules to the browser on demand, functionality that allows for fast Hot Module Replacement (HMR) - the updating of modules while an app is running without a full reload - even for large applications.

In development, the main advantages of using Vitest with Vite are their performance during development, ease of integration, and shared configuration. Vitest's growing adoption is partly driven by the widespread success of Vite.

## Vitest features

Vitest has built-in ES module, TypeScript, JSX, and PostCSS support and many of the same features as Jest, like the `expect` API, snapshots, and code coverage. Vitest's Jest-compatible API makes migrating from Jest easy. Take a look at the differences between the frameworks in the [migrating from Jest guide](https://vitest.dev/guide/migration.html#migrating-from-jest) in the Vitest docs.

With Vitest 3, several features have been enhanced. The code coverage functionality now automatically excludes test files by default, providing cleaner coverage reports. The mocking capabilities have also been expanded, with the new version including spy reuse for already mocked methods, reducing test boilerplate, and adding powerful new matchers like `toHaveBeenCalledExactlyOnceWith`:

```javascript
test('vitest mocking example', () => {
  const mock = vi.fn();
  mock('hello');
  // New matcher for more precise assertions
  expect(mock).toHaveBeenCalledExactlyOnceWith('hello');
  
  // Spy reuse example
  const obj = {
    method: () => {}
  };
  const spy = vi.spyOn(obj, 'method');
  // Spy is automatically reused if spyOn is called again
  const sameSpy = vi.spyOn(obj, 'method');
  expect(spy === sameSpy).toBe(true);
});
```

In contrast to Jest, Vitest uses watch mode by default for a better developer experience. Vitest searches the ES module graph and only reruns affected tests when you modify your source code, similar to how Vite's HMR works in the browser. This makes test reruns fast - so fast that Vitest adds a delay before displaying test results in the terminal so that developers can see that the tests were rerun.

Vitest supports [Happy DOM](https://github.com/capricorn86/happy-dom) and [jsdom](https://github.com/jsdom/jsdom) for DOM mocking. While Happy DOM is more performant than jsdom, which is used by Jest, jsdom is a more mature package with a more extensive API that closely emulates the browser environment.

When running tests, Vitest runs a Vite dev server that provides a UI for managing your tests. Vitest 3 significantly improves the UI experience with several new features:

- Run individual tests or test suites right from the UI for easier debugging.
- Quickly spot and fix issues with automatic scrolling to failed tests.
- Get a clearer view of your test dependencies with toggleable `node_modules` visibility.
- Better organize your tests with improved filtering, search, and management controls.

To view the UI, install `@vitest/ui` and pass the `--ui` flag to the Vitest run command:

```shell
vitest --ui
```

![Vitest UI](./assets/vitest-ui.png)

Take a look at the StackBlitz [Vitest Basic Example](https://stackblitz.com/fork/github/vitest-dev/vitest/tree/main/examples/basic?initialPath=__vitest__/) for a live demo of the Vitest UI. At Speakeasy, we've found Vitest's UI to be a valuable tool for debugging. 

Vitest also has Rust-like [in-source testing](https://vitest.dev/guide/in-source) that lets you run tests in your source code:

```javascript add.ts
export function add(...args: number[]) {
  return args.reduce((a, b) => a + b, 0)
}

// in-source test suites
if (import.meta.vitest) {
  const { it, expect } = import.meta.vitest
  it('add', () => {
    expect(add()).toBe(0)
    expect(add(1)).toBe(1)
    expect(add(1, 2, 3)).toBe(6)
  })
}
```

While using separate test files is recommended for more complex tests, in-source testing is suitable for unit testing small functions and prototyping, making it especially useful for writing tests for JavaScript libraries.

Vitest's recent experimental [browser mode](https://vitest.dev/guide/browser/) feature allows you to run tests in the browser, instead of simulating them in Node.js. [WebdriverIO](https://webdriver.io/) is used for running tests, but you can use other providers. You can also browse in headless mode using WebdriverIO or [Playwright](https://playwright.dev/). Vitest developed browser mode to improve test accuracy by using a real browser environment and streamline test workflows, but you may find browser mode slower than using a simulated environment as it needs to launch a browser, handle page rendering, and interact with browser APIs.

Vitest 3 introduces powerful new CLI features that upgrade test execution flexibility. You can now exclude specific projects using patterns with `--project=!pattern`, making it easier to manage test runs in monorepos or large projects. The new line-number-based test filtering allows you to run specific tests by their location in the file:

```shell
# Run only the test at line 42
vitest path/to/test.ts:42

# Exclude all projects matching the pattern
vitest --project=!packages/internal-*
```

Other experimental features include [type testing](https://vitest.dev/guide/features.html#type-testing) and [benchmarking](https://vitest.dev/guide/features.html#benchmarking).

## Getting started with Vitest

The set up and execution of a basic test in Vitest is similar to Jest.

First, install Vitest as a development dependency:

```shell
npm install --save-dev vitest
```

Create a test file with `.test` or `.spec` in its name, for example, `sum.test.js`:

```javascript sum.test.js
import { expect, test } from "vitest";
import { sum } from "./sum.js";

test("adds 1 + 2 to equal 3", () => {
  expect(sum(1, 2)).toBe(3);
});
```

This code imports a `sum` function that adds two numbers and then checks that `1` and `2` have been correctly added.

Compared to Jest, this basic test is a little different. Vitest uses ES module imports, and for the sake of explicitness, it does not provide global APIs like `expect` and `test` by default. You can configure Vitest to provide [global APIs](https://vitest.dev/config/#globals) if you prefer or are migrating from Jest.

Add the following script to your `package.json` file:

```json package.json
{
  "scripts": {
    "test": "vitest"
  }
}
```

Run the test using the following command:

```shell
npm run test
```

Vitest finds the files and runs them, and will print the following message in your terminal if the test passes:

```shell
✓ sum.test.js (1)
  ✓ adds 1 + 2 to equal 3

Test Files  1 passed (1)
     Tests  1 passed (1)
  Start at  02:15:44
  Duration  311ms
```

Note that Vitest starts in watch mode by default in a development environment.

## Choosing between Vitest and Jest

Let's compare the two testing frameworks in terms of performance, developer experience, community and ecosystem, and their usage with Vite.

### Performance

Performance comparisons of Vitest and Jest have delivered conflicting results, as the outcome depends on what you're testing and how you configure the testing tool. One blog post reports that [Jest is faster than Vitest](https://bradgarropy.com/blog/jest-over-vitest) when running all the tests for the author's blog website. [Another comparison](https://dev.to/mbarzeev/from-jest-to-vitest-migration-and-benchmark-23pl), which performed 1,256 unit tests on a production web app that uses Vite and Vue, found that Vitest was faster than Jest in most tests. [Yet another comparison](https://uglow.medium.com/vitest-is-not-ready-to-replace-jest-and-may-never-be-5ae264e0e24a) found Jest to be almost twice as fast as Vitest for testing a production app.

Even if your benchmarking finds Jest is faster than Vitest, there are ways to improve Vitest's performance, as explained in the [improving performance guide](https://vitest.dev/guide/improving-performance.html#improving-performance) in the Vitest docs.

For example, you can disable test [isolation](https://vitest.dev/config/#isolate) for projects that don't rely on side effects and properly clean up their state, which is often the case for projects in a `node` environment. 

Vitest 3 introduces significant performance enhancements with several key changes. The test runner now supports better concurrent execution with suite-level test shuffling for improved parallelism. Snapshot handling has been optimized to reset state properly during retries and repeats, reducing test flakiness. The new version also improves memory usage through smarter spy handling, automatically reusing mocks for methods that have already been spied on instead of creating new ones.

In watch mode, Vitest often outperforms Jest when rerunning tests, as it only reruns tests affected by code changes. While Jest also only reruns changed tests in watch mode, it relies on checking uncommitted Git files, which can be less precise, as not all detected changes may be relevant to the tests you're running.

### Developer experience

Both Jest and Vitest have comprehensive, well-organized, and easy-to-search documentation. The Jest docs include guides for specific types of tests such as [timer mocks](https://jestjs.io/docs/timer-mocks) and using Jest with other libraries, databases, web frameworks, and React Native. Vitest's [getting started guide](https://vitest.dev/guide/) sets it apart. It includes StackBlitz examples that you can use to try Vitest in the browser without setting up a code example yourself. The getting started guide also has example GitHub repos and StackBlitz playgrounds for using Vitest with different web frameworks.

Vitest's ES module support gives it a significant advantage over Jest, which only offers [experimental support for ES modules](https://jestjs.io/docs/ecmascript-modules).

Jest uses [Babel](https://babeljs.io/) to transpile JavaScript ES Modules to CommonJS, using the [`@babel/plugin-transform-modules-commonjs`](https://babeljs.io/docs/babel-plugin-transform-modules-commonjs) plugin. By default, Babel excludes Node.js modules from transformation, which may be an issue if you use an [ES-module-only library](https://gist.github.com/sindresorhus/a39789f98801d908bbc7ff3ecc99d99c) like [`react-markdown`](https://remarkjs.github.io/react-markdown/), in which case you'll get this commonly seen error message:

```
SyntaxError: Unexpected token 'export'
```

To fix this issue, use the [`transformIgnorePatterns`](https://jestjs.io/docs/configuration#transformignorepatterns-arraystring) option in your `jest.config.js` file to specify that the Node module is an ES module package that needs to be transpiled by Babel:

```javascript jest.config.js
/** @type {import('jest').Config} */
const config = {
  ...
  "transformIgnorePatterns": [
    "node_modules/(?!(react-markdown)/)"
  ],
};

module.exports = config;
```

Jest supports TypeScript using Babel, which requires some [configuration](https://jestjs.io/docs/getting-started#using-typescript).

Overall, Jest requires some configuration to work with ES modules and TypeScript, which work out of the box with Vitest. Less configuration means happier developers.

[RedwoodJS](https://redwoodjs.com/), the full-stack, open-source web framework, [is in the process of migrating from Jest to Vitest](https://www.youtube.com/watch?v=zVY4Nv104Vk&t=271). The RedwoodJS team found Vitest much better suited to working with ES modules compared to Jest.

### Community and ecosystem

While [npm trends](https://npmtrends.com/jest-vs-vitest) show that Jest is downloaded more frequently than Vitest, Vitest usage is rapidly increasing, outpacing Jest in growth.

![npm trends graph: Jest vs. Vitest - number of npm downloads over time](./assets/npm-trends-jest-vs-vitest.png)

|        | GitHub<br/>stars | GitHub<br/>issues | Latest<br/>version | Creation<br/>date | Unpacked<br/>size |
|--------|------------------|-------------------|--------------------|-------------------|-------------------|
| Jest   | 44 456           | 271               | 29.7.0             | 2011              | 5.01 Mb           |
| Vitest | 13 705           | 281               | 3.0.5              | 2021              | 1.62 Mb           |

According to the [State of JS 2023 survey](https://2023.stateofjs.com/en-US/libraries/), Vitest has seen a rapid rise in popularity and positive opinions between 2021 and 2023. By contrast, Jest experienced a rapid rise in popularity and positive opinions between 2016 and 2020, but this momentum slowed between 2021 and 2023, with opinions becoming more mixed. This shift may be due to developers adopting Vitest, which solves one of the main pain points of Jest: ES Module support.

Vite and Vitest claimed many of the top spots in the [survey](https://2023.stateofjs.com/en-US/awards/), while Jest made an appearance as the second most most-loved library, after Vite.

Of the four most popular JavaScript frontend frameworks and libraries, two use Jest, and two use Vitest. React uses Jest and Angular added experimental Jest support in 2023 with the release of Angular version 16 to modernize its unit testing.

Jest's popularity and the fact that it's been around for longer means there are more blog posts and [Stack Overflow questions about Jest](https://stackoverflow.com/questions/tagged/jestjs) than [Vitest](https://stackoverflow.com/questions/tagged/vitest), which is useful for figuring out uncommon testing situations and debugging.

Many large companies use Jest, but Vitest is [gaining traction in prominent projects](https://vitest.dev/guide/#projects-using-vitest), including frameworks like Vue and Svelte. Many of the projects using Vitest are built with Vue. This is no surprise, as Evan You, the creator of Vue, also created Vite, and one of Vite's core team members developed Vitest.

For React developers, Jest's compatibility with mobile development using React Native and [Expo](https://expo.dev/) is an important advantage. React Native and Expo testing documentation recommend using Jest, and Expo provides the [`jest-expo`](https://github.com/expo/expo/tree/main/packages/jest-expo) library to simplify testing for Expo and React Native apps.

Vitest, meanwhile, offers support for React Native using the [`vitest-react-native`](https://github.com/sheremet-va/vitest-react-native) library, which is developed by a Vitest team member and is a work in progress.

Vitest is under more rapid development than Jest, as can be seen by the number of recent commits to the [Vitest GitHub repo](https://github.com/vitest-dev/vitest/commits/main/) compared to the [Jest GitHub repo](https://github.com/jestjs/jest/commits/main/).

Recently, Evan You founded [VoidZero](https://voidzero.dev/), a company building an open-source, unified development toolchain by bringing together some of the most popular JavaScript toolchain libraries: Vite, Vitest, Rolldown, and Oxc. With $4.6 million in seed funding, VoidZero is likely to accelerate Vitest's development and boost its popularity.

### Using with Vite

If Vite is part of your development toolchain, Vitest's easy integration with Vite is a compelling advantage, delivering a streamlined setup through shared configuration.

Jest is not fully supported by Vite, but you can get it to work using the vite-jest library, with some [limitations](https://github.com/haoqunjiang/vite-jest/tree/main/packages/vite-jest#limitations-and-differences-with-commonjs-tests).

Using Jest with Vite adds complexity as you need to manage testing and building your app as separate processes. However, Angular uses Vite and Jest. The Angular team considered using Vitest but chose Jest because of its widespread adoption among Angular developers and its maturity.

## Migrating from Jest to Vitest: Insights from our experience at Speakeasy

Our experience migrating from Jest to Vitest at Speakeasy revealed clear advantages, particularly in speed and ease of setup.

In January, when we rebuilt our TypeScript SDK, switching to Vitest gave us a noticeable runtime boost with zero configuration. Unlike Jest, which required Babel integration, TSJest setup, and multiple dependencies, Vitest worked out of the box, allowing us to drop five dependencies from our project. 

Vitest's compatibility with Jest's API made the migration smooth, and the intuitive UI provided a browser view with real-time test updates – a significant productivity boost. 

Since July, we've expanded Vitest's role in our process by introducing a test generation product, where clients can create Vitest tests for their API SDKs, maintaining minimal dependencies with only Zod and Vitest required. 

Vitest has quickly become a strong choice for future-proofing, advancing rapidly with the support of VoidZero and its integration into a modern toolchain that aligns with frameworks like Vue.

## Adding automated API testing for Speakeasy-created SDKs using Vitest

When we rebuilt our TypeScript SDK generation – which doesn't use Vite – we switched from Jest to Vitest and saw a significant improvement in performance. Vitest needed zero configuration – it just worked. Vitest's Jest-compatible API made the migration straightforward, and we've found that Vitest has most of Jest's features as well as some extras, like its feature-packed, intuitive UI for viewing and interacting with tests.

We are now in the process of expanding our use of Vitest to our customers' Speakeasy-generated SDKs with an [automated API testing feature](/product/api-testing) that generates API tests that will help you make more robust and performant APIs, faster and cheaper. Our own internal SDKs have Vitest tests, which we used to add this feature. 

<Callout title="EARLY ACCESS" variant="info">
  Speakeasy API test generation is in beta. Join the [early access program](/product/api-testing) to give it a try.
</Callout>

Test generation is currently available in Typescript, Python, and Go. Customers can enable test generation in a generated Speakeasy SDK using their OpenAPI doc or using a `tests.yaml` file. We have plans to further improve testing including:

- Providing a mock server to run the generated tests against.
- Adding integration with CI/CD using our GitHub Action.
- Adding support for more languages.
- Adding end-to-end testing using the [Arazzo specification](/openapi/arazzo), which allows for more complex testing scenarios.
- Integration with the Speakeasy web app.

## Conclusion: Which testing framework is better?

Vitest's many experimental features simplify testing and the framework is under active development, a fact that may skew this comparison even more in its favor in the coming years.

While both libraries are easy to get started with, Vitest is easier to set up for modern projects using ES modules and TypeScript, and it's easier to use with modern npm libraries that are ES modules only.

We think that Vitest is a good successor to Jest. Picking a technology means betting on the future, and we're betting on Vitest.


 This is the content for the doc blog/webhook-security/index.mdx 

 ---
title: The double standard of webhook security and API security
description: "Explore the surprisingly different security standards we apply to webhooks versus traditional API requests."
date: 2025-01-02
authors:
  - name: David Adler
  - image_url: '/media/author-headshots/david.jpg'
tags:
  - Webhooks
image: "/media/why-do-we-sign-webhooks.png"
featured_image: "/media/why-do-we-sign-webhooks.png"
is_featured: true
---

Interesting fact: [80% of API producers sign their webhook requests with HMAC-SHA256](https://ngrok.com/blog-post/get-webhooks-secure-it-depends-a-field-guide-to-webhook-security).

Request signing provides **authenticity** by enabling you, the webhook consumer, to verify who sent the webhook. However, webhooks aren’t so different from any other API request. They're just an HTTP request from one server to another. So why not use an API key just like any other API request to check who sent the request? Signing requests does give extra security points, but why do we collectively place higher security requirements on webhook requests than API requests?

## What is request signing?

Disclaimer: this is not an exhaustive explanation of cryptographic signatures. This is a practical introduction to what is meant by “request signing” in this article and by the average webhooks service.

```tsx
function sign_request(request) {
	// The secret is never included in the request
	// Also, the request contents form the signature input
	request.headers['x-signature'] = sign(secret, request.body)
}
```

When consuming the request, you'd do something like:

```tsx
function verify_request(request) {
	actual = request.headers['x-signature']
	// This is the same secret used for the sender and consumer
	expected = sign(secret, request.body)
	return actual == expected
}
```

## The three security benefits of signing requests

There are three benefits to signing your requests (in addition to encrypting the request in transit over TLS):

1. **Reduced risk of leaking secrets**: Though traditional API requests are likely over HTTPS, the application server is likely not the TLS-terminating gateway. Once decrypted, it's common for API Keys to leak into logs, queues, third parties and traverse several layers of infrastructure. Signed requests never contain the sensitive secret, so there's a smaller surface area that the secret will touch and thus reduced risk of leaking the secret.
2. **Replay protection**: With an API Key, you have weaker guarantees on when the message was sent. Since you can include a timestamp and/or a nonce in the signed message, you have stronger guarantees somebody didn't attempt to maliciously recycle the same request.
3. **Integrity**: With an API Key, you have fewer guarantees that the request contents were created by the same party that “owns” the API Key. Maybe some malicious HTTP client middleware added or modified it? With signing, the signature is built from the request contents.

## Why aren't most API requests signed?

If there are so many benefits, why aren't most API requests signed? While it's a lot less common, some big names like [Amazon](https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_sigv.html), [Azure](https://learn.microsoft.com/en-us/azure/azure-app-configuration/rest-api-authentication-hmac) and [Oracle](https://docs.oracle.com/en/cloud/saas/marketing/crowdtwist-develop/Developers/HMACAuthentication.html) all employ request signing in their APIs. Indeed, there is even a [standard for signing HTTP requests](https://datatracker.ietf.org/doc/rfc9421/). So are API keys just a phase?

I'll posit that the primary reason most people don’t opt for signing their API requests is because of herd mentality. That's a valid reason. If simple API Keys are [good enough for Stripe requests](https://docs.stripe.com/keys) then they're probably good enough for you, too. Is request signing really that much more secure? Security is like stacked slices of [Swiss cheese](https://en.wikipedia.org/wiki/Swiss_cheese_model) with lots of randomly placed holes. The more layers you have, the more holes the attacker has to find. Knowing when to stop adding layers is hard. There's always better security. Inline with mantras like "don't roll your own crypto” and “not invented here” it's safer and easier to follow the wisdom of the crowd.

Having said that, there are some principled reasons for why you wouldn't bother signing your API requests:

- **API Keys are good enough**: At least for the comparison in this article, you can assume the API producer does enforce HTTPS for both API requests and webhook endpoints. If the request will be encrypted over TLS, the risk of 2 & 3 above are massively diminished. TLS guarantees confidentiality and integrity. This makes the integrity guarantees provided by 3 somewhat redundant as the attacker would need to be able to view or modify the unencrypted request, which would likely require compromising the request sender’s machine or infrastructure. At which point, as the victim, requests being replayed is the least of your concerns.
- **Complexity of implementation**: For example, how you will sign server sent events or streams? Which parts of the HTTP request will be included in the signature input? Webhook requests are mostly small-ish POST requests which makes them practical to sign.
- **Performance overhead**: signed requests are guaranteed to be slower than traditional API key requests, especially for big payloads.

## Why do we place higher security requirements on webhooks?

<img src="/media/programming-opinions.png" alt="Programming opinions" />

It is valid to argue that webhook requests don’t inherently deserve stronger security measures than traditional API requests. The security benefits of request signing can provide value in either context. Therefore, there is a double standard. If you do decide to use shared secrets for webhooks, it is a reasonable decision and that doesn't mean your webhooks service is insecure.

Having said that, there are some reasons why webhooks often receive this different security treatment:
* **Webhooks are untrusted URLs**: It’s one thing if you accidentally hand your API key to a malicious site—now they can impersonate you. It’s another if Stripe, for example, sends a secret to a malicious site—now that site can impersonate Stripe. What is the risk of a misconfigured webhook URL vs a misconfigured API request? Then again, if a URL is truly untrusted, Stripe shouldn’t be sending data there in the first place. In practice, Stripe and similar providers trusts URLs their customers configure. By using a separate secret for each customer, a single compromised secret doesn’t compromise all customers.
* **Historical precedent**: This precedent likely dates back to the [PubSubHubbub standard from 2008](https://github.com/pubsubhubbub/PubSubHubbub/commit/3aec180d9170afdd816085e6d3d3301fd188c514#diff-99eb0f15a3e4d003ab1cbe7378d330f366134af4d473e79876812fee073d3d0bR140) and snowballed from there. Signing is also included as a best practice in the more recent [Standard Webhooks](https://www.standardwebhooks.com/). As before, most webhooks services follow the wisdom of the crowd.
* **Non-HTTPS Webhooks**: While increasingly rare, some webhooks still use plain HTTP. Request signing can provide some level of protection against potential man-in-the-middle attacks when TLS is absent. Most modern webhook providers, however, enforce HTTPS by default and still use signing.

Regardless, request signing adds valuable security layers to any type of request, which is why [we support API Producers to configure request signing in our generated SDKs at Speakeasy](https://www.speakeasy.com/docs/customize/webhooks). We’re following the wisdom of the crowd, too.


 This is the content for the doc blog/why-an-api-platform-is-important.mdx 

 ---
title: "API Experts - Why an API Platform is important"
description: "Roopak Venkatakrishnan, Director of Engineering at Bolt, explains why it's important to have an API platform & how to make the development seamless."
image: "/media/api-experts-roopak-venkatakrishnan.png"
date: 2022-08-04
authors:
  - name: Nolan Sullivan
  - image_url: 'https://uploads-ssl.webflow.com/62ccd7b208cab0723d026273/62cdf9e45dcbb4d20be59f5f_head.jpeg'
tags:
  - API Advice
featured_image: "/media/api-experts-roopak-venkatakrishnan.png"
---

This is the first in a series of conversations that we'll be having with leading API development engineers and managers about how they're approaching API development within their organizations. If you or someone you would like to sit down and talk to us, [please get in touch](https://rfnxkmu4ddz.typeform.com/to/b2bfTMUG).

Tl;dr

- API platforms are important for turning API development into a repeatable task for internal developers. Repeatability is critical for exposing a consistent experience to external developers.
- An API platform should handle all the API ops (every aspect of API creation that's not the business logic). Ideally, you should be able to put server code in, and get a production-ready API out.
- It's important to formalize an API strategy early, ideally long before you've launched anything publicly. A little upfront planning can avoid a pile of tech debt later.
- For most companies who sell to developers, APIs are at the heart of DevEx. API platforms can often become the foundation for the larger DevEx team.
- Webhooks are great and should be considered any time there's a "push" use case.

## Introduction

_Roopak Venkatakrishnan is a director of engineering at Bolt. He is responsible for managing the platform & infrastructure org, as well as the merchant org working to democratize commerce by providing one-click checkout to sellers. Prior to Bolt, Roopak was at Spoke (acq. by Okta) and held senior positions at Google and Twitter._

## What is an API Platform

**_Nolan: You've been working on building out Bolt's API platform. Could you explain what the purpose of an API platform is? If it is successfully built, how does it impact the day to day work of the developers in the company?_**

Roopak: Yeah, simply put, you want to give your internal developers a great experience when building APIs. And then when you ship an API as a product, you want to make sure the API is holistically thought through; that certain standards are followed throughout. So for example, when an external developer already uses two of your APIs, and then they go on to use a third API that you add later: the errors look the same, the endpoints, the style, the response objects, everything is the same. Generally, once they start working with your product, there should be no surprises. It should look similar and holistic.

So that's one part where an API platform can start helping. It can define a nice pattern for the teams, their product, and make sure APIs are treated holistically across the company. But the second, more interesting part of it, especially for internal teams, is there's going to be a lot of shared components. Things that you don't want to just be using. As an example, you don't want everyone to be building their own rate limiting. It could also be the way you do your docs, it could be guides, it could be, authentication. Every team shouldn't be trying to build their own, it should just be handled for you.

**So what I would say is that an API platform should take away all the API ops, basically everything that isn't business logic.** Let product developers handle the business logic and then the rest of it is handled by the API platform. An assembly line for APIs, raw business logic goes in, and a productized API comes out.

**_Nolan: Bolt is an API as a product company, but for lots of companies APIs are a secondary interface. How do you think this changes the need for an API platform?_**

Roopak: Interestingly, Bolt was not, until recently, an API-driven company. In the sense that, when I joined, one of the things that bothered me about our APIs was that it was just different all over the place. The way we handled authentication, the way we did rate limits, the way our docs were published, our errors, even our observability, across different APIs, it was inconsistent.

To go back to the question, whenever you start providing an API externally, you should have an API platform, and in fact, I think essentially every company does have an API platform. They just don't realize it's an actual thing that they maintain or provide. Usually, it's just two developers, who are kind of managing this in the style guides or runbooks they provide to the rest of the team. It's very similar to say, maintaining Dev & Prod in a company's early days, right? Like, you don't have a developer productivity engineer, when you are eight engineers, but someone still does it 30% of the time, you're just not accounting for it.

And I think you should just be thoughtful and realize that at some point, you do need to start accounting for it and be like, "hey, if we don't do this, we're just going to end up in a bad place." Ultimately, someone needs to be thinking about all these API concerns. Because, here's the worst part of it, this is not something you can go back and fix, right?

**Here's the problem with an API, you've released it, and then you're stuck with it. If you want to make a change, you have to beg every single external developer to make the change.** Let's just say you add a field to an API without realizing it. Even if it's not documented, you cannot remove it anymore. You know why? Because the minute it's out there, somebody's started using it. So, it's actually one of those things you should think about earlier, more than anything else, because it's no take backs.

## How to design API architecture

**_Nolan: Bolt's public APIs are RESTful, but you also provide webhooks. What're your thoughts on when to use different frameworks?_**

Roopak: I'm biased. I really, really like web hooks. I would say, in some sense, it's easier to offer web hooks to start off with, than to offer APIs. For example, I have built a lot of stuff off of some companies' web hooks before I started using their APIs. But I do think it's important that you offer both.

I think that web hooks are the push and APIs are the pull. Web hooks should be the way you notify customers about changes in your system. And I believe that almost any system which has an API is going to have changes in their system that they want to notify their customers about.

**_Nolan: If someone was designing their API architecture today, what advice would you give them?_**

Roopak: I have an anecdote. Spoke, the previous company I worked at was very interesting. I was an early employee, so we were building from the ground up. From day one, we said, "Hey, we're going to build our entire app on a public API". We're just not going to publish the documentation. So that way, whenever we want to become an API driven system, we are already there. I thought it was a genius idea!

But it was really tough. At some point, we finally realized that it was slowing us down. Because to make changes to a public API, you have to be really thoughtful, and you know, an internal endpoint not so much. So, we tried doing it all public, but it didn't end up working out.

And when we published our actual public API, it ended up that we didn't just take everything from what we already had, they were almost there, but still required changes. So, we published a style guide for public APIs. We said, "Okay, this is how our external APIs are gonna look."

But it was an interesting learning for me, I like that we did it. I just think that, in the end, the style guide approach kind of worked for us, at least for a while, we were small enough that we were not adding too many endpoints. Eventually though, it just becomes harder. Because the more engineers you have, there's just someone who's just not going to follow the guide. Someone is going to make a mistake, and then you need to have a group of people who review the API changes, and then it just starts getting more and more expensive. And that's why API platforms are ultimately necessary.

## The API Platform team at Bolt

**_Nolan: When did you create the API platform team at Bolt, and how did you know it was the right time to start it?_**

Roopak: Our APIs had existed for the people who needed them, but we weren't necessarily trying to be API-first. But at some point, we realized, you know, the kinds of customers we want, they actually need a good API. We can't publish something shitty, because that's just not going to work. So that's sort of when we realized we needed a formalized API platform.

I think the answer to the right time is, it's like, if you're a company, which is offering an API as a product, you should think about this on day one. But if you're starting to offer an API as a secondary interface, and even if you don't have a dedicated team around it, you should have a group of people who sit and then think through this and then say, "Hey, how are we going to make sure what we expose is what we want to expose." You better think through this, you can't do it after the fact. It has to be before. Otherwise, you're going to pay back a lot of tech debt.

**_Nolan: How would you define the mandate of the API platform team at Bolt_**

Roopak: It's actually slowly growing, right? Initially, it was, help our engineering teams do the basics of shipping an API. The team started with building our API tooling: detecting backward incompatible changes, helping with our Doc's, and so on and so forth. That is growing, it's going to be every part of the API lifecycle: key rotation, authentication – rate limiting is its own beast. Every part of API tooling is going to be something that this team does.

But the team is actually formally called DevEx, which is developer experience, because that's the ultimate goal.This team is going to to be the team that interfaces with developers every which way. One day, it may be a fully-fledged developer portal, but today it's mainly focused on tooling to produce consistently great APIs for our customers.

**_Nolan: What is something your team recently accomplished that you would like to shine a light on? Anything you're particularly proud of?_**

Roopak: We recently shifted API Doc generation to be much more in line with our code. We're creating the API reference directly from our server code, and having it live right beside the code. I'm very excited about that, mainly because I believe that API docs are super important; it's the end-product people see. You can have a beautiful API, but if you have bad API docs, you're going to be set a couple of steps back.

So we're using Open API 3.0. And we've constructed the whole thing where all the models are separate. Even when you're starting to build an API, you can be like, "Oh, what are the models that we use in our different APIs", and you can actually look them up. Here's the request models that we use, all the various different things. So you can look at them per request, and then you can look at what we use overall. And it's all right beside the code, which I'm personally a fan of because it encourages developers to think about what the customer will see if they are making a change to the code base. You can't just write the API code in isolation and throw it over the fence to someone else to write the API reference and documentation. The end-product is just not going to work well that way.

**_Nolan: What are currently the API platform team's biggest goals?_**

Roopak: Oh there's a lot of different things. I'm not going to jump into everything. We're redoing some of our authentication, our key rotation, all of that. The other big goal is improving how quickly we get our partner developers being able to use our APIs. That's one of the metrics that we're starting to track. How soon can a developer get a key and make their first successful API call? And there are so many more tiny things to improve the internal experience for developers that we're trying to get done.

**_Nolan: If you ask developers building public APIs at Bolt what their biggest challenge is, what would they say?_**

Roopak: Well, we do ask our developers this, and until recently, it was things like: I don't know where the docs are, how to edit them. It was very complicated. So we picked that up. I think, probably right now, it would be something like, I don't know what our definition for a good API is. And you know, that's something that we need to come up with, and evangelize. Like, we're redoing errors right now as an example. We just haven't published a comprehensive guide yet. And right now, it's much more informal, like you get guidance from this team. So I would say that's probably the next thing. We know how we want endpoints to look. We want to make it clear to our developers what's a good API, so new APIs are in-line with the rest of Bolt's existing APIs.

**_Nolan: Do internal APIs factor into an API platform team's remit?_**

Roopak: Right now it's handled differently. We're still trying to figure out how we want to do this. We want our API platform to focus on the external stuff first. That's more important to get in shape. And then internal stuff.

It's interesting, as long as the APIs are performing, even if the API change is backwards incompatible, it's not the end of the world. You can create an entirely new endpoint, and then make every service transition over because you can ping the team and be like, "hey, switch over," and then you can get rid of the old endpoint. Sure, it might take a week, and it's a little bit of a pain, but we're shipping a lot of new external APIs. So we want to make sure we got that in shape. So internal, not yet.

I do think there is an ideal world where I would like an API platform to manage both internal and external. Build a framework, maybe internally use something like gRPC. And, you know, the platform would help other teams generate internal docs for their endpoints, so that any team can easily provide a good DevEx internally. But, we're not big enough for that yet. As you become a much bigger company, you do want internal teams to be treated similarly to your external customers. But, you know, it all depends on the size of the company.

**_Nolan: A closing question we like to ask everyone: any new technologies or tools that you're particularly excited by? Doesn't have to be API related._**

Roopak: Ah, this is a very hard question, because for me, this changes every two days. I try out loads of new tools and then some of them just stick. So I can tell you all the random things that I have been trying out and using recently. I cannot pick a favorite because it's too hard! I got an invite to [Arc](https://thebrowser.company/), the new browser, so that is something which I've been playing with. I have switched my terminal to use [Warp](https://www.warp.dev/), and I use [Graphite](https://graphite.dev/) for code review. I think Graphite is just friggin great. This is on the tooling side. On the development side, it's been things like [Temporal](https://temporal.io/) and [Tailscale](https://tailscale.com/). And finally, I mean, this is not a new tool, but I'm moving all my personal projects that I build onto [Cloudflare](https://www.cloudflare.com/), trying to make everything run on workers and pages and whatever else they offer.


 This is the content for the doc blog/why-work-at-speakeasy/why-work-at-speakeasy.mdx 

 ---
title: "Why work on API developer experience?"
description: "The big question ! The Speakeasy team is growing. Learn more about our mission and why we're working on API developer experience."
keywords: [sdks, api, devex, hiring, founding team, growth, startup, developer experience]
image: "/media/why-work.png"
date: 2023-11-29
authors:
  - name: Sagar Batchu
  - image_url: "/media/author-headshots/sagar.jpeg"
tags:
  - Building Speakeasy
featured_image: "/media/why-work.png"
---

As the end of 2023 quickly approaches my internal calendar is reminding me of the natural slow down that happens. 
However on the ground reality at Speakeasy has not matched that expectation at all. December is shaping up to be our 
busiest month of the year! The holidays though have given me a moment to reflect on what we do and why we do it. 

There is a lot happening in the tech world right now. The Generative AI boom is in full swing. It feels like it's never been a more exciting
time to be a builder. Large language models are making new business and service creation less capital intensive. Natural language 
everything means an explosion of new products and a compression of the time to market. 

This also means it's an incredibly challenging time to be a builder. The number of frameworks and tools is exploding.
The number of apis is exploding. The burden of integration is exploding. Whether you're bootstrapping a startup, building at a scaleup, 
or innovating at a large enterprise, the number of choices you have to make is exploding. If you haven't caught my vibe yet it's really
:exploding_head: out there!

In the middle of all that noise the best companies have been able to clarify against competition by investing in community. They've built loyal developer
user groups by getting the details right. This is the fine points of day to day integration work that most don't obsess over. This is
developer experience. Specifically API developer experience. For me this is best captured by Twillio's sign off of the 101 freeway in San Francisco. 
"Ask your Developer". Not a question, not an answer. Just a statement with immense gravity and implication. Developer communities are loyal to great experiences. 
They're loyal to great products. Most companies fall short on this vision. To get it right you have to burn several percentage points of company time purely on conviction.

![Twilio billboard off the 101 - Ask your developer](./assets/ask-your-developer.jpeg)

Working at Speakeasy means working on the brass tacks. We're in the weeds of the experiences that best in class products truly standout.
We sweat the details so our customers don't have to. At its core today we're a unique code generation platform that takes massive burden
off API devs, teams and companies from worrying about staying up to date with every developer ecosystem. As an API company having a great SDK may 
seem like a narrow start. But it's the gateway drug to a suite of tooling that gives your customers the fabled "aha" moment and keeps them coming back for more. API first is out. SDK first is in. 

This isn't always flashy work. Through APIs of our customers we get to look at the guts of many different businesses across many verticals and then wrap those into easy to understand
experiences for millions of end users. Whether its Generative AI, Fintech, Infrastructure or something else we're giving a set of high leverage tools for 
builders to reach their customers in the best way possible.

Our mission and story doesn't end with developers. For the GTM half of businesses we ensure you never have to turn down a deal or risk customer success 
because of a lack or resources or prioritisation. The modern business is a balancing act between great product build and great distribution. We reduce that tension by taking the burden 
of distribution to your developer base.

Speakeasy is a very ambitious project. We're building a company/product/team that will power the next generation of APIs and developer adoption at the
fastest growing growing companies. REST API best practices may already have broad consensus but they definitely don't have broad practice. We have to meet our customers where they are. Sometimes
this means APIs being designed from the ground up and sometimes it means ones that support many 0's of RPS. This means we have to build extensibly, reliably and at scale. We have the privilege of sitting between producers and 
consumers and shepherding usage in a way that dictates the exact lines of code used. So very design decision we make can future proof our customers or cut their growth short. 
It's high stakes which also means it's a lot of fun :).

We're working on Speakeasy because the best businesses are increasingly being built on a community of developers. We ship fast so our customers
can ship fast and keep their customers happy. We have a lot of work to do to bring this reality to every business, it's going to a be an exciting 2024. 
If you're excited by our mandate check out our [open roles](https://jobs.ashbyhq.com/Speakeasy) - we'd love to hear from you!


 This is the content for the doc blog/writing-zod-code-that-minifies/index.mdx 

 ---
title: Writing Zod code that minifies
description:
image: "/media/zod-minify.png"
date: 2024-06-05
authors:
  - name: Georges Haidar
  - image_url: "/media/author-headshots/georges.jpeg"
tags:
  - Building Speakeasy
featured_image: "/media/zod-minify.png"
---

I don't think it's exaggerating when I say that [Zod][zod] has had a major
positive impact on how we write safe TypeScript code that also preserves its
safety guarantees at runtime. It's so powerful that we at Speakeasy based the
design of our [latest TypeScript SDK generator](/post/introducing-universal-ts) on it.

We've been iterating on the TypeScript code we're generating because we're going
through a phase of optimising the size of our SDKs so they work even better in
the browser and one interesting area has been around how we write Zod schemas.

Consider the following (contrived) example of a Zod schema:

```ts
import * as z from "zod";

export const person = z.object({
  name: z.string(),
  age: z.number().optional(),
  address: z.object({
    line1: z.string().optional(),
    line2: z.string().optional(),
    line3: z.string().optional(),
    line4: z.string().optional(),
    city: z.string(),
  }),
  pets: z.array(
    z.union([
      z.object({
        type: z.literal("dog"),
        name: z.string(),
      }),
      z.object({
        type: z.literal("cat"),
        name: z.string(),
      }),
    ])
  ),
});
```

This is a fairly common style of writing zod schemas: you import the whole
library as a single variable and use the powerful chaining API to describe
validation rules.

When running this code through a bundler like esbuild we're going to get subpar
minification performance. Esbuild will remove unnecessary spaces and newlines
but I'm going to keep them in for the sake of readability. Here's the formatted
result:

```ts
import * as t from "zod";

export const person = t.object({
  name: t.string(),
  age: t.number().optional(),
  address: t.object({
    line1: t.string().optional(),
    line2: t.string().optional(),
    line3: t.string().optional(),
    line4: t.string().optional(),
    city: t.string(),
  }),
  pets: t.array(
    t.union([
      t.object({ type: t.literal("dog"), name: t.string() }),
      t.object({ type: t.literal("cat"), name: t.string() }),
    ])
  ),
});
```

The actual minified code comes out to 379 bytes, down from 512 bytes. That's
rougly a 26% reduction.

Notice how not a lot has changed. In fact, the only thing that has changed is
that esbuild renamed `z` to `t`. The only net reduction in this minified code
can be attributed to the removal of unnecessary whitespace characters which
we've kept in here.

So on the current course, if your project is building up more and more Zod
schemas, you'll notice that the minified code isn't tremendously smaller than
the unminified code. The only real gains will be from compressing this code with
gzip or brotli (or whatever you prefer) but that doesn't impact the size of the
code that needs to be parsed. Furthermore, minified can still compress well and
result in overall less text to send down the wire and to parse.

The way to improve the impact of minification on our code will come from using
local variables that can be rewritten by the minifier. Fortunately, Zod exports
much of its API as a standalone functions that can be separately imported.

Lets rewrite the code above using these standalone functions:

```ts
import { object, string, number, array, union, literal, optional } from "zod";

export const person = object({
  name: string(),
  age: optional(number()),
  address: object({
    line1: optional(string()),
    line2: optional(string()),
    line3: optional(string()),
    line4: optional(string()),
    city: string(),
  }),
  pets: array(
    union([
      object({
        type: literal("dog"),
        name: string(),
      }),
      object({
        type: literal("cat"),
        name: string(),
      }),
    ])
  ),
});
```

... and the minified result:

```ts
import {
  object as t,
  string as e,
  number as i,
  array as o,
  union as r,
  literal as a,
  optional as n,
} from "zod";
export const person = t({
  name: e(),
  age: n(i()),
  address: t({
    line1: n(e()),
    line2: n(e()),
    line3: n(e()),
    line4: n(e()),
    city: e(),
  }),
  pets: o(
    r([t({ type: a("dog"), name: e() }), t({ type: a("cat"), name: e() })])
  ),
});
```

That did better. The actual result is now 290 bytes, down from 512 bytes. That's
roughly a 43% reduction!

You can see how the minifier was able to re-alias all the imports to single
letter variables and use that to shrink the remaining code.

The new style of writing Zod schemas might be a little more tedious because you
are no longer carrying the entire library with you with a single variable.
However, if optimising for bundle size is a real concern for you, then this is a
neat trick to keep in your backpocket.

[tsv2]: (/post/introducing-universal-ts)
[zod]: https://zod.dev/


 This is the content for the doc changelog/categories/[category].mdx 

 ---
  title: "Changelog"
  description: "Speakeasy Changelog covers the latest product releases and feature updates."
  
---

import {
  Category,
  getStaticPaths as getCategoryStaticPaths,
  getStaticProps as getCategoryStaticProps,
} from "~/features/changelog/category";

<Category />

export const getStaticPaths = getCategoryStaticPaths;
export const getStaticProps = getCategoryStaticProps;


 This is the content for the doc changelog/changelog-1/index.mdx 

 ---
title: "Changelog #1: OpenAPI Spec Drift Detection"
description: "Changes to the Speakeasy platform - August 17, 2022"
keywords: [api, openapi, typescript sdk, typescript, schema drift]
image: "/media/changelog1.png"
date: 2022-08-17
authors:
  - name: Nolan Sullivan
  - image_url: "/media/author-headshots/nolan.jpeg"
featured_image: "/media/changelog1.png"
---

### New Features

- **Know when your API drifts from your docs** - The Speakeasy SDK now checks API traffic against your uploaded OpenAPI schema. When traffic that is not present in your schema is served by your API, your team will be able to diff schemas and see where drift has occurred.

import portal_url_1 from "./changelog-august-17-2022-image-01.mp4";

{" "}

<video
  controls={false}
  loop={true}
  autoPlay={true}
  muted={true}
  width="100%"
  alt="The Speakeasy SDK now checks API traffic against your uploaded OpenAPI schema"
>
  <source src={portal_url_1} type="video/mp4" />
</video>

- **Push Alerts to the whole team** \- To enable automation, Speakeasy pushes an event to your webhook for each unknown endpoint when drift is detected. Integrate your team's tooling with our webhooks to create automatic Slack alerts so you know as soon as something changes!

import portal_url_2 from "./changelog-august-17-2022-image-02.mp4";

{" "}

<video
  controls={false}
  loop={true}
  autoPlay={true}
  muted={true}
  width="100%"
  alt="Speakeasy pushes an event to your webhook"
>
  <source src={portal_url_2} type="video/mp4" />
</video>

### Smaller Improvements

- Speakeasy is now available for APIs written in **typescript**, thanks to our typescript SDK!


 This is the content for the doc changelog/changelog-10/index.mdx 

 ---
title: "Changelog #10: API Key Management"
description: "Changes to the Speakeasy platform - November 9, 2022."
keywords:
  [
    api,
    api key,
    key,
    key management,
    dark mode,
    devex,
    dx,
    developer experience,
    sdk,
  ]
image: "/media/changelog10.png"
date: 2022-11-09
authors:
  - name: Nolan Sullivan
  - image_url: "/media/author-headshots/nolan.jpeg"
featured_image: "/media/changelog10.png"
---

You spend your time building the perfect API: the error messages are insightful, the external abstractions are flawless – but before anyone can use your beautiful API, they need the keys. That might mean someone spending a week hacking together a passable API key management system (it can’t rotate keys, but we’ll get to it next quarter). Or it could also mean the team manually sharing keys via OneTimeSecret with every client that needs onboarding. Neither scenario is great.

Or you could let Speakeasy do it for you. We now offer a self-service API key management embed, which can be easily integrated with your API gateway. One less thing you need to worry about when you’re launching your new API.

## New Features

**API Key Management** - We’re working on making the entire API user journey self-serve and that journey starts with enabling key management for your API users. With Speakeasy’s key management embed, your users can create and revoke API keys in your developer experience portal. Set up is easy: Speakeasy integrates directly with your API gateway to externalize key management through an OpenAPI Spec extension; it works with any API Gateways that supports OIDC2 workflows and external token sources. This includes Google Cloud Endpoints, Kong, Apigee, AWS API Gateway and more. If there’s a gateway not on this list that you’d like to use, reply to this email, or [come talk to us in Slack](https://join.slack.com/t/speakeasy-dev/shared_invite/zt-1cwb3flxz-lS5SyZxAsF_3NOq5xc8Cjw).

import portal_url_1 from "./changelog-november-9-2022-image-01.mp4";

{" "}

<video
  controls={false}
  loop={true}
  autoPlay={true}
  muted={true}
  width="100%"
  alt="Changelog November 9th"
>
  <source src={portal_url_1} type="video/mp4" />
</video>

## Incremental Improvements

**Dark Mode** - Ensure your users have a consistent developer experience. Speakeasy’s dev portal embeds now fit seamlessly into your existing developer portal. All our embeds now respect dark mode settings at the operating system and site level to make sure the developer experience in your portal is consistent, dark, and handsome.

import portal_url_2 from "./changelog-november-9-2022-image-02.mp4";

{" "}

<video
  controls={false}
  loop={true}
  autoPlay={true}
  muted={true}
  width="100%"
  alt="Changelog November 9th 2"
>
  <source src={portal_url_2} type="video/mp4" />
</video>


 This is the content for the doc changelog/changelog-11/index.mdx 

 ---
title: "Changelog #11: DevEx portals as a service"
description: "Changes to the Speakeasy platform - November 17, 2022."
keywords: [api, openapi, api portal, devex, dx, developer experience, sdk]
image: "/media/changelog11.png"
date: 2022-11-17
authors:
  - name: Nolan Sullivan
  - image_url: "/media/author-headshots/nolan.jpeg"
featured_image: "/media/changelog11.png"
---

If there’s a time gap between your user signup and first successful request, if your team has to dig through request logs to troubleshoot integrations, if you’re not seeing users’ API usage expand over time, then you probably need to consider investing in your API developer experience.

Our new API DevEx portal makes it easy.  We’ve assembled Speakeasy’s individual embeds into an end-to-end nextjs app with the tooling needed to enable your users to:

- Manage their API keys
- Analyze request and response logs
- Understand their API usage
- Test new use cases

If you're interested in using the portal builder [Come talk to us on Slack!](https://0ups4.mjt.lu/lnk/AUYAAALJkTsAAAACClAAAAdr36kAAAAAsgAAAKEtAB4vvABjdplmc9MHjT-3TiiH1LFBD3SrAAAcp_g/4/YBur1zqdc_mlc8y5mk2MCg/aHR0cHM6Ly9qb2luLnNsYWNrLmNvbS90L3NwZWFrZWFzeS1kZXYvc2hhcmVkX2ludml0ZS96dC0xY3diM2ZseHotbFM1U3laeEFzRl8zTk9xNXhjOENqdw)

## New Features

**API DevEx Portal Builder** - We talked two weeks ago about how Client SDKs are a pillar of good API DevEx. Portals are another. If APIs are the powerful bare metal capabilities you offer to your clients, developer experience portals are the packaging that make them an easy-to-use product. A well-built portal unlocks fast initial integration, seamless usage expansion, and self-service troubleshooting by making your API:

- **Accessible**: there is zero friction to begin sending API requests.
- **Understandable**: users are able to get immediate feedback on their API usage – and to self-service troubleshoot issues when they do occur.
- **Usable**: It is trivially easy for users to discover and test out new use cases for your API that naturally expand their usage.

See it in action!

import portal_url_1 from "./changelog-november-17-2022-image-01.mp4";

{" "}

<video
  controls={false}
  loop={true}
  autoPlay={true}
  muted={true}
  width="100%"
  alt="Changelog November 17"
>
  <source src={portal_url_1} type="video/mp4" />
</video>

We take care of the API developer experience, so you can focus on the stuff that makes your API special.


 This is the content for the doc changelog/changelog-12/index.mdx 

 ---
title: "Changelog #12: SDKs and Our March of Progress"
description: "Changes to the Speakeasy platform - December 01, 2022."
keywords:
  [
    api,
    openapi,
    swagger,
    sdk,
    sdk generation,
    openapi extension,
    extension,
    readme,
    code comments,
    http clients,
    devex,
    dx,
    developer experience,
  ]
image: "/media/changelog12.png"
date: 2022-12-01
authors:
  - name: Nolan Sullivan
  - image_url: "/media/author-headshots/nolan.jpeg"
featured_image: "/media/changelog12.png"
---

SDK generators are attractive because they’re easy. Hand Rolling SDKs requires time and broad language expertise. The downside has always been that generated SDKs sacrifice developer experience. Generated SDKs feel like they exist so that someone could tick a box and claim they offered SDKs, even though those SDKs would never be something a developer would want to use.

We’re determined to make an SDK generator that is not only easy to use, but makes SDKs that are great for your users. Since we rolled out the beta of our SDK generator, we’ve continued to add features that add the type of finishing touches that take an SDK from usable to enjoyable.

## New Features

**Easy OpenAPI Extension: Multiple Servers** - OpenAPI is great, but it has some glaring holes. One is that, when there are multiple servers, it doesn’t provide a strongly typed way to define which server to use by default. Speakeasy provides an extension to the OpenAPI spec that allows you to define an ID for each server in the Servers array. This can be done using the x-speakeasy-server-id property on the server object. [Read more about how in our documentation](/docs/customize-sdks/).

```yaml
openapi: 3.0.3
info:
  title: Example
  version: 0.0.1
servers:
  - url: https://prod.example.com # Used as the default URL by the SDK
    description: Our production environment
    x-speakeasy-server-id: prod
  - url: https://sandbox.example.com
    description: Our sandbox environment
    x-speakeasy-server-id: sandbox
```

Servers are just the start. We're building out extensions for retries and pagination and are [looking for customers interested in being alphas users](https://app.speakeasy.com/).

**Readmes & Code Comments** - SDKs are more than just the functions in the library. They’re also the business context in which they exist. That’s why the Speakeasy generator creates a Readme with install instructions and usage examples, and generates code comments & usage snippets based on your OpenAPI operation’s descriptions. Read more about how in our documentation: [Readme & Code comments](/docs/customize-sdks/).

**Custom HTTP Client Support** - We know that SDKs don’t exist in a vacuum. That’s why our SDKs are built to be optionally used with a custom HTTP Client. This allows you to use HTTP Clients that are setup to use proxies, provide custom telemetry or be preconfigured with global headers or any additional configuration. [Read more about how, in our documentation](/docs/customize-sdks/).

## Small Improvements

Google Login - Users now have the option of logging in with their google account in addition to github. More auth providers to come!

import portal_url_1 from "./changelog-12-google-login.mp4";

{" "}

<video
  controls={false}
  loop={true}
  autoPlay={true}
  muted={true}
  width="100%"
  alt="Google login"
>
  <source src={portal_url_1} type="video/mp4" />
</video>


 This is the content for the doc changelog/changelog-13/index.mdx 

 ---
title: "Changelog #13: Java SDKs & Telemetry"
description: "Changes to the Speakeasy platform - December 8, 2022."
keywords:
  [
    api,
    openapi,
    swagger,
    sdk,
    sdk generation,
    java sdk,
    sdk telemetry,
    telemetry,
    devex,
    dx,
    developer experience,
  ]
image: "/media/changelog13.png"
date: 2022-12-08
authors:
  - name: Nolan Sullivan
  - image_url: "/media/author-headshots/nolan.jpeg"
featured_image: "/media/changelog13.png"
---

In 2022, we’ve seen the acceleration of a trend: the dispersal of programming language usage. There’s no sign of that trend abating anytime soon. That’s great for nerding out over language design, but it’s a pain if you’re on the hook for building your API’s client libraries. Whereas 15 years ago you could have covered most programmers with 3-4 libraries, it’s now probably closer to 8-10.

Language dispersal makes it harder to provide the same level of service to your users and makes it harder to keep track of how users are interfacing with your product.

We’re committed to giving people the tools they need to manage this new reality. We’re constantly working to add more languages to [our SDK generator](/docs/create-client-sdks/): the alpha for Java is live! And we’ve baked telemetry into all of the SDKs we create so you can get a clear picture of how your users experience your API.

## New Features

**Client SDKs: Java (Alpha)** - Love it or hate it, there’s no denying the importance of Java. As one of the most widely-used server-side programming languages, anyone building an API should be sure to make sure they have SDKs for the Java community. We’ve built our Java SDKs to make sure they follow Java conventions and design patterns to provide a consistent interface for developers interacting with your API:

- **Minimal Dependencies**: we use [Jackson Libary](https://github.com/FasterXML/jackson) to (de)serialize models, and use java.net HttpClients to make HTTP requests.
- **Annotations for all generated models**: this allows us to append per field metadata to correctly serialize and deserialize models based on the OpenAPI document.
- **A utils module**: to contain methods for configuring the SDK and serializing/deserializing the types we generate, to avoid duplication of code in each method reducing the readability.

To see the SDKs for yourself, just download our CLI:

**_brew install speakeasy-api/homebrew-tap/speakeasy_**
**_speakeasy generate sdk -s openapi.yaml --output ./sdk -l java_**

**SDK Usage Telemetry** - If you don’t know which SDKs developers are using to access your API, then you’ve got a blind spot in your understanding of your users. Github stars offer an imperfect metric: they help you understand interest rather than SDK usage. We’ve addressed this common gap in telemetry with our SDKs. When you integrate Speakeasy into your API, you will get SDK usage telemetry out of the box! SDK Language and version are now available as filter criteria in the usage dashboard and request viewer, so you can easily get a clear picture of which languages your users favor.

import portal_url_1 from "./changelog-13-usage-telemetry.mp4";

{" "}

<video
  controls={false}
  loop={true}
  autoPlay={true}
  muted={true}
  width="100%"
  alt="Usage telemetry"
>
  <source src={portal_url_1} type="video/mp4" />
</video>

## Small Improvements

**New UX** - Same product with a fresh coat of paint. New icons, colors, and navigation for a much improved user experience. You’ve probably noticed a difference in our latest Gifs, so head over to our app to experience it yourself.

import portal_url_2 from "./changelog-13-new-ux.mp4";

{" "}

<video
  controls={false}
  loop={true}
  autoPlay={true}
  muted={true}
  width="100%"
  alt="New UX"
>
  <source src={portal_url_2} type="video/mp4" />
</video>


 This is the content for the doc changelog/changelog-14/index.md 

 ---
title: "Changelog #14: Terraform Generation Alpha"
description: "Changes to the Speakeasy platform - December 21, 2022."
keywords:
  [
    api,
    openapi,
    swagger,
    terraform provider,
    terraform,
    sdk,
    sdk generation,
    retries,
    devex,
    dx,
    developer experience,
  ]
image: "/media/changelog14.png"
date: 2022-12-21
authors:
  - name: Nolan Sullivan
  - image_url: "/media/author-headshots/nolan.jpeg"
featured_image: "/media/changelog14.png"
---

If you are interested in being an alpha user for our Terraform provider generator, please respond to this email to let us know!

Github’s 2022 annual review crowned HCL (hashicorp configuration language) as the fastest growing language (56%), even beating out developer darling, Rust, for the top spot. It is a testament to the establishment of infrastructure as code (IaC) as a leading development practice and the popularity of Terraform as the medium for infrastructure management.

The best developer companies meet their users where they already are, to flatten the learning curve and provide a great DevEx. For some API companies that increasingly means a terraform provider so that the resources exposed by the API can be managed in concert with any related infrastructure. However, like SDKs, a terraform provider becomes another artifact that needs ongoing investment & management. That’s why we’ve been working on a way to enable teams to auto-generate terraform providers from their OpenAPI definition.

## Alpha Release

**Terraform Provider Generation** - Just add annotations to your OpenAPI specification’s entities and operations. Speakeasy will then process your spec to produce and maintain a terraform-registry compliant provider plugin, that will create, update and destroy persistent resources by interacting with your APIs. As an example, imagine the pet entity from the canonical petshop example:

```yaml
paths:
 /pet:
   post:
     tags:
       - pet
     summary: Add a new pet to the store
     x-speakeasy-entity-operation: Pet#create
     description: Add a new pet to the store
     operationId: addPet
     responses:
       '200':
         description: Successful operation
         content:
           application/json:
             schema:
               $ref: '#/components/schemas/Pet'
     requestBody:
       description: Create a new pet in the store
       required: true
       content:
         application/json:
           schema:
             $ref: '#/components/schemas/Pet'
…
Pet:
 x-speakeasy-entity: Pet
 required:
   - name
   - photoUrls
 properties:
   id:
     type: integer
     format: int64
     example: 10
   name:
     type: string
   category:
     $ref: '#/components/schemas/Category'
   photoUrls:
     type: array
     items:
       type: string
…
```

Adding the `x-speakeasy-entity` annotation to a resource-based API, along with annotations to each operation such as:

- `x-speakeasy-entity-operation: Pet#create`
- `x-speakeasy-entity-operation: Pet#delete`
- `x-speakeasy-entity-operation: Pet#update`

are all that’s required to generate a valid terraform provider with terraform-registry documentation, usable like the following:

```HCL
resource "petstore_pet" "myPet" {
 name = "Freddie"
 photo_urls = ["https://example.com/example.jpg"]
 tags = {
   name = "foo"
 }
}
```

Speakeasy will output this provider plugin to a github repository, annotating resources with Computed, ReadOnly, Required and ForceNew attributes based upon the semantics of how they’re used in Create/Update operations.

If you would like us to generate a terraform provider from your OpenAPI definition, please get in touch! We’re actively looking for design partners for whom we can generate/maintain terraform providers for your API.

## New Features

**SDK Retries** - Every SDK should have retries. It’s one of the things that makes for a great DevEx. End-users shouldn’t be left to figure out what errors should trigger retries, which shouldn’t, and how long you should wait before resending. Nobody knows an API better than the builder, and that’s who should be determining when a retry is appropriate. That’s why we’ve added the ability for our users to extend their OpenAPI spec and configure retry logic for their SDKs.

```yaml
x-speakeasy-retries:
  strategy: backoff
  backoff:
    initialInterval: 100 # 100 ms
    maxInterval: 30000 # 30s
    exponent: 2 # backoff delay doubles from 100ms until 30s
    maxElapsedTime: 300000 # After 5 minutes, returns a failure to the callee
  statusCodes: # a list of status codes to retry on (supports XX wildcards)
    - 429
    - 5XX
  retryConnectionErrors: true # whether to retry connection errors
```


 This is the content for the doc changelog/changelog-15/index.mdx 

 ---
title: "Changelog #15: Easy Validation For OpenAPI"
description: "Changes to the Speakeasy platform - January 10, 2023."
keywords:
  [
    api,
    openapi,
    swagger,
    openapi validation,
    validation,
    sdk,
    sdk generation,
    devex,
    dx,
    developer experience,
  ]
image: "/media/changelog15.png"
date: 2023-01-10
authors:
  - name: Nolan Sullivan
  - image_url: "/media/author-headshots/nolan.jpeg"
featured_image: "/media/changelog15.png"
---

New Year means new product shipping!

When you encounter an error while troubleshooting, you want to know **where** the error occurred and **what** caused it. Anyone who’s tried to do code generation from an OpenAPI spec is unfortunately very familiar with the anguish of hunting through a thousand-line yaml file to track down opaque errors without line numbers to guide you.

With the latest release of our CLI, that should hopefully be a problem of the past. We’ve baked in an OpenAPI validator that will help you optimize your spec for code generation workflows and make troubleshooting any issues a breeze. See it in action below.

### **New Features**

**OpenAPI Validation** - OpenAPI validation is baked into [our SDK generator](/docs/create-client-sdks/), but can also be used on its own: `speakeasy validate openapi -s openapi.yaml`. The validator provides you with both `warnings`: implementation that is bad practice, but not incorrect and `errors`: implementation that violates the OpenAPI spec. The best part is that the warnings and errors returned are actionable. The error messages are human-readable, and include a line number to make it easy to track down:

```yaml
Error: validation error: [line 12] validate-servers - Server URL is not valid: no hostname or path provided
```

import portal_url_1 from "./openapi-validation.mp4";

{" "}

<video
  controls={false}
  loop={true}
  autoPlay={true}
  muted={true}
  width="100%"
  alt="Spec validator"
>
  <source src={portal_url_1} type="video/mp4" />
</video>

To try it out yourself, download the CLI:

```bash
***brew install speakeasy-api/homebrew-tap/speakeasy***
```

```bash
***speakeasy validate openapi -s openapi.yaml***
```


 This is the content for the doc changelog/changelog-16/index.mdx 

 ---
title: "Changelog #16: Seamlessly Managed SDK Versions"
description: "Changes to the Speakeasy platform - January 17, 2023."
keywords:
  [
    api,
    openapi,
    swagger,
    github action,
    github,
    pull request,
    sdk versioning,
    sdk,
    sdk generation,
    devex,
    dx,
    developer experience,
  ]
image: "/media/changelog16.png"
date: 2023-01-17
authors:
  - name: Nolan Sullivan
  - image_url: "/media/author-headshots/nolan.jpeg"
featured_image: "/media/changelog16.png"
---

Updating an API is a harrowing task. There’s plentiful opportunity to introduce issues that could lead to unintended functionality in your product. So why make it even harder on yourself by then hand rolling the changes out to all of your client libraries in a variety of languages? At that point, you’re just asking for there to be inconsistencies between SDKs that require painful client migrations to address in the future.

That’s why Speakeasy is making it easy with automatic generation & versioning of your API’s SDKs. All you need to do is review and approve.

### **New Features**

**PRs for New Versions** - Speakeasy provides both a github workflow & action to automate SDK creation. When a new version of your OpenAPI spec is published, we’ll create new commits on a PR branch with the changes for each SDK and then an associated Github release upon merge. We can even automate publishing to package managers.

import portal_url_1 from "./gh-workflow.mp4";

{" "}

<video
  controls={false}
  loop={true}
  autoPlay={true}
  muted={true}
  width="100%"
  alt="Github workflow"
>
  <source src={portal_url_1} type="video/mp4" />
</video>

If you’re interested in end to end automation for your SDK management, get in touch.


 This is the content for the doc changelog/changelog-17/index.md 

 ---
title: "Changelog #17: OpenAPI Webhook Support"
description: "Changes to the Speakeasy platform - January 24, 2023."
keywords:
  [
    api,
    openapi,
    swagger,
    webhooks,
    sdk,
    sdk generation,
    devex,
    dx,
    developer experience,
  ]
image: "/media/changelog17.png"
date: 2023-01-24
authors:
  - name: Nolan Sullivan
  - image_url: "/media/author-headshots/nolan.jpeg"
featured_image: "/media/changelog17.png"
---

Where would we be without Webhooks? Inefficient polling leading to unnecessary load on our APIs. And although Webhooks are an important part of most companies with an API strategy, they often have a less robust Developer Experience than API endpoints.

At Speakeasy, we’re doing our part to make sure that webhooks aren’t treated differently from other API endpoints. That’s why we’ve added support for OpenAPI webhook definitions in our SDK generator.

## New Features

**Webhook Support** - For each defined webhook in your OpenAPI spec, Speakeasy will generate the types for your webhook’s request, and response objects. This makes sure that whatever the endpoint type, your users have a consistent experience interfacing with your API.

**OpenAPI**

```yaml
webhooks:
  newPet:
    post:
      requestBody:
        description: Information about a new pet in the system
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/Pet"
      responses:
        "200":
          description: Return a 200 status
```

**SDK Output**

```go
package webhooks

import (
    "openapi/pkg/models/shared"
)

type NewPetRequest struct {
  Request *shared.Pet `request:"mediaType=application/json"`
}

type NewPetResponse struct {
  ContentType string
  StatusCode  int64
}
```

## Small Improvements

**http.ServeMux Support** - For those interested in getting request & response logs by integrating Speakeasy server-side, we now offer support for any router based on http.ServeMux, for example: [httptrace.Mux](https://pkg.go.dev/gopkg.in/DataDog/dd-trace-go.v1/contrib/net/http).

**“Does Not Contain” filters** - A nice quality of life improvement. When you’re filtering logs in the Speakeasy request viewer, you can now use the “does not contain” operator to build your filters.


 This is the content for the doc changelog/changelog-18/index.mdx 

 ---
title: "Changelog #18: Build Custom Workflows - Sneak Peak!"
description: "Changes to the Speakeasy platform - February 07, 2023."
keywords:
  [
    api,
    openapi,
    swagger,
    webassembly,
    plugins,
    sdk generation,
    devex,
    dx,
    developer experience,
  ]
image: "/media/changelog18.png"
date: 2023-02-07
authors:
  - name: Nolan Sullivan
  - image_url: "/media/author-headshots/nolan.jpeg"
featured_image: "/media/changelog18.png"
---

Nothing is more frustrating than a platform standing in the way of you solving your problem. That is why the best platforms provide users extensibility. When a use case is not served by the core platform, users can extend the platform with customized functionality to address their use case.

The Speakeasy API platform is no different. We’ve packed a lot of functionality into it, but we can’t do everything. Which is why we’re excited to give our users the ability to build plugins that add custom functionality to the platform.

## New Features

**Speakeasy** **Plugins [Alpha]:** Users can now define custom javascript functions (powered by WebAssembly!) to run on the API request & response data that flows into the Speakeasy platform. The possible applications are endless, but some common uses would be like custom field validation script, defining a derived field from the raw data, or tracing a user onboarding onto your API. The newly defined fields are then added to the existing set of api requests for you to view. We plan for plugins to be hosted on Github with an extendable base template to get you started. Eventually, we want to explore exposing these to directly to your end users. We can’t wait to see what you all come up with!

See the new feature in action below:

import portal_url_1 from "./plugins.mp4";

{" "}

<video
  controls={false}
  loop={true}
  autoPlay={true}
  muted={true}
  width="100%"
  alt="Plugins"
>
  <source src={portal_url_1} type="video/mp4" />
</video>

## Small Improvements

**[Bug fix] CLI Auth for Safari & Brave** - After reports of CLI authentication running into CORS issues on Safari & Brave browsers, we’ve switched our authentication method to one compatible with all browsers.

**CLI Safe Cleanup** - Our CLI is getting smarter! It now tracks which files it generates when building SDKs and will only purge previously created files before new output is saved.


 This is the content for the doc changelog/changelog-19/index.md 

 ---
title: "Changelog #19: PHP SDKs Now Available!"
description: "Changes to the Speakeasy platform - February 15, 2023."
keywords:
  [api, openapi, swagger, php, sdk generation, devex, dx, developer experience]
image: "/media/changelog19.png"
date: 2023-02-15
authors:
  - name: Nolan Sullivan
  - image_url: "/media/author-headshots/nolan.jpeg"
featured_image: "/media/changelog19.png"
---

PHP is like the cockroach of the programming ecosystem, people love to hate on it and yet it will likely outlive all of us.

Some 80% of websites use PHP, with especially strong use in E-commerce & finance. So if you’re building an API, support for the PHP community should be at the top of your priority list. Which is why we’re excited to announce that Speakeasy now supports PHP SDK creation!

## PHP SDK Creation

As with all Speakeasy SDKs, our PHP SDKs place an emphasis on being idiomatic and type-safe. We’ve made several choices to give PHP users an experience they would expect:

- **Type hints & doc strings** wherever possible to guide the end user to use the right data types.
- [**Jms/serializer**](https://jmsyst.com/libs/serializer) to accurately serialize and deserialize json bodies
- [**Guzzle**](https://docs.guzzlephp.org/en/stable/) as the HTTP client of choice. However, like all our SDKs, we make it easy to swap in a custom client to be used if desired.

PHP is live the Speakeasy CLI, so just upgrade to the latest version and create a great SDK for your PHP users:

```bash
speakeasy generate sdk -s openapi.yaml -o ./php-sdk -l php
```

And here’s some example output from the canonical Petstore example API for an `addPet` method:

```php
/**
     * addPet - Creates a new pet in the store. Duplicates are allowed
    */
    public function addPet(\PetstoreAPI\models\operations\AddPetRequest $request): \PetstoreAPI\models\operations\AddPetResponse
    {
        $baseUrl = $this->_serverUrl;
        $url = utils\Utils::generateURL($baseUrl, '/pets');

        $options = ['http_errors' => false];
        $body = utils\Utils::serializeRequestBody($request);
        if (is_null($body)) {
            throw new \Exception('Request body is required');
        }
        $options = array_merge_recursive($options, $body);


        $client = $this->_defaultClient;
        $httpRes = $client->request('POST', $url, $options);

        $contentType = $httpRes->getHeader('Content-Type')[0] ?? '';

        $res = new \PetstoreAPI\models\operations\AddPetResponse();
        $res->statusCode = $httpRes->getStatusCode();
        $res->contentType = $contentType;

        if ($httpRes->getStatusCode() == 200) {
            if (utils\Utils::matchContentType($contentType, 'application/json')) {
                $serializer = utils\JSON::createSerializer();
                $res->pet = $serializer->deserialize($httpRes->getBody()->__toString(), 'PetstoreAPI\models\shared\Pet', 'json');
            }
        }
        else {
            if (utils\Utils::matchContentType($contentType, 'application/json')) {
                $serializer = utils\JSON::createSerializer();
                $res->error = $serializer->deserialize($httpRes->getBody()->__toString(), 'PetstoreAPI\models\shared\Error', 'json');
            }
        }

        return $res;
    }
```


 This is the content for the doc changelog/changelog-2/index.md 

 ---
title: "Changelog #2: Sensitive Data Masking"
description: "Changes to the Speakeasy platform - August 23, 2022."
keywords:
  [
    api,
    devex,
    dx,
    developer experience,
    openapi,
    mask sensitive data,
    middleware,
    sdk,
  ]
image: "/media/changelog2.png"
date: 2022-08-23
authors:
  - name: Nolan Sullivan
  - image_url: "/media/author-headshots/nolan.jpeg"
featured_image: "/media/changelog2.png"
---

### New Features

- **Mask sensitive data** - Whether it's request/response fields, headers or cookies, use the middleware controller to prevent sensitive fields from entering the platform. Alternatively, ignore entire routes by not assigning the Speakeasy middleware to the endpoint's router.

```go
func MyHandler(w http.ResponseWriter, r *http.Request) {
    ctrl := speakeasy.MiddlewareController(req)
    ctrl.Masking(speakeasy.WithRequestHeaderMask("Authorization")) // Masked header
    // the rest of your handlers code
}
```

- **Get a customer-specific view** - When you're looking at API logs, you need to be able to filter down to a single customer. By configuring the Speakeasy SDK to pick up your customer-key, you can easily breakdown to get a customer-specific view.

```go
func MyHandler(w http.ResponseWriter, r *http.Request) {
    ctrl := speakeasy.MiddlewareController(req)
    ctrl.CustomerID("a-customers-id") // Specify customer ID
    // the rest of your handlers code
}
```

### Smaller Changes

- **Easy service discovery** - Search APIs registered with the Speakeasy platform via associated metadata i.e. search by team label, version label.


 This is the content for the doc changelog/changelog-20/index.mdx 

 ---
title: "Changelog #20: Self-Serve SDK Creation Pipeline [Alpha]"
description: "Changes to the Speakeasy platform - February 22, 2023."
keywords:
  [api, openapi, swagger, sdk generation, devex, dx, developer experience]
image: "/media/changelog20.png"
date: 2023-02-22
authors:
  - name: Nolan Sullivan
  - image_url: "/media/author-headshots/nolan.jpeg"
featured_image: "/media/changelog20.png"
---

Even though we are a team of lovely people, we understand that not everyone wants to talk to us to get their SDK creation pipeline set up. That’s why we’re hard at work building a self-serve pipeline. With just a few simple clicks in our platform UI, production-ready SDKs will magically appear in your Github. If you want to see the final result, check out this [Python SDK repo](https://github.com/speakeasy-sdks/openai-python-sdk) for OpenAI API, and its [PyPi package](https://pypi.org/project/speakeasy-openai/).

We’re currently running user feedback sessions, so if you’re interested in getting your hands on this new feature ASAP, [sign up for a testing slot](https://calendly.com/d/yy2-6r6-3d4/alpha-test-latest-speakeasy-release) before they fill up!

## New Features

**Self-serve SDK Creation Pipeline:** You can now go from spec to published package in a couple clicks. Our pipeline runs as part of your CI/CD, so you’ll never need to worry about SDKs getting out of sync with your spec again. To get started, all you need to do is:

1. Upload your OpenAPI spec.
2. Select your target languages.
3. Optionally add publishing information.
4. Click ‘Create’ — thats it !

Check it out in action below:

import portal_url_1 from "./sdk-pipeline.mp4";

{" "}

<video
  controls={false}
  loop={true}
  autoPlay={true}
  muted={true}
  width="100%"
  alt="SDK pipeline"
>
  <source src={portal_url_1} type="video/mp4" />
</video>

## Improvements

**Publishing for Java**: You can now publish your Java SDKs to Maven. Just add your Maven API key and start publishing!

**Test coverage for SDKs**: SDKs are a critical product surface area, and we treat them as such. We’ve revamped our test coverage and developed a set of language specific test suites to prevent any regressions in the SDKs we create.


 This is the content for the doc changelog/changelog-2023-10-19/index.md 

 ---
title: "Changelog: Unity and C# now available as generation targets!"
description: "New features to the Speakeasy Platform - October 19th, 2023."
keywords: [api, openapi, swagger, sdk generation, devex, dx, developer experience]
image: "/media/changelog-2023-10-19.png"
date: 2023-10-19
authors:
  - name: Anuraag Nalluri
  - image_url: "/media/author-headshots/anuraag.jpeg"
featured_image: "/media/changelog-2023-10-19.png"
---

While we haven’t had a Changelog post for a minute, the Eng team here at Speakeasy has been heads down building out a laundry list of new features and capabilities. In this Changelog we share a few of these new features including the addition of Unity and C# as generation targets.

## New Features

### C# generation

C# has an active community of developers and diverse uses across desktop, web, mobile, cloud, IoT, ML, and gaming apps. We’re excited to announce that Speakeasy now supports C# SDK creation! Speakeasy C# SDKs are designed to be easy to use and easy to debug. Our SDK design is guided by:

- Minimal dependencies and relying on the C# standard library as much as possible.
- SDK & sub SDKs implement full interfaces so that the SDKs are ready for dependency-injection.
- Requests are async so that you can await them or run them asynchronously.
- Nullable fields for optional objects, including fields/parameters/response and request bodies, to ensure that the user can differentiate between a field not being set and a field being set to a zero value.
- Compatible with net5.0 projects for partial Unity support.

### Unity generation

Unity is used by developers of all sizes, from small indie studios to large AAA studios. And now, all of these developers can take advantage of Speakeasy’s newly launched support of Unity SDK creation! Our Unity SDK offers:

- Native `UnityWebRequest` support so it’ll work on all of Unity’s target platforms
- Models are Serializable and can be used with Unity Editor and plugins
- Supports streaming downloads
- Works with async/await and coroutines

### Multi-level Namespacing

Our SDKs now support multi-level namespacing to enable interfaces that more closely match your organization’s resource structure! You can read more about it [here](/docs/customize-sdks/namespaces/#multi-level-namespacing)

### Monkey Patching SDKs via .genignore

We now support the use of `.genignore` to monkey patch your SDKs with any custom business logic, usage snippets, or documentation that regeneration won’t override! You can read more about it [here](/docs/customize-sdks/monkey-patching)

## 🐜 Improvements and Bug Fixes 🐛

### Managed SDKs and Terraform providers

- Python - id / object keywords
- Ruby / Swift - Empty request body issues
- publishing of typescript docs folders
- validation of oneOf objects with nested references
- Mandatory entity support in terraform
- Support for arbitrary names in multipart file upload for Typescript

### Product onboarding

- Moved API key creation for SDK generation to the backend
- Long term fix for the issue where repos were getting created without the SPEAKEASY_API_KEY secret
- Guarantees that each workspace will have exactly one key used for generation in GitHub and that that key is always added as a secret to every repo that gets created for that workspace
- Speakeasy API Key not attached on new SDK repos

For the latest on feature and bug status, check out the [Speakeasy Public Roadmap](https://speakeasy.productlane.com/roadmap) and follow us on [X](https://twitter.com/speakeasydev?s=20) and [LinkedIn](https://www.linkedin.com/company/speakeasyapi/). Have a feature request or bug to report? Message us on [Slack](https://join.slack.com/t/speakeasy-dev/shared_invite/zt-22t74wuw4-AvdeauhFtUPEBk~CIhg1HQ) or log an [issue](https://github.com/orgs/speakeasy-api/repositories) on GitHub.


 This is the content for the doc changelog/changelog-2023-11-15/index.mdx 

 ---
title: "Changelog: Customisable Imports, OpenAPI Overlays, and Terraform generation improvements!"
description: "New features to the Speakeasy Platform - November 15th, 2023."
keywords:
  [api, openapi, openapi, sdk generation, devex, dx, developer experience]
image: "/media/changelog-2023-11-14.png"
date: 2023-11-15
authors:
  - name: Sagar Batchu
  - image_url: "/media/author-headshots/sagar.jpeg"
featured_image: "/media/changelog-2023-11-14.png"
---

import { ScrollyCoding } from "~/components/codehike/Scrollycoding";
import { Callout } from "~/components";

Welcome to another edition of the Speakeasy Changelog. In this issue, we'll give you a sneak peek into our support for [OpenAPI Overlays](https://github.com/OAI/Overlay-Specification) and how we're leveraging them to help customers customize their SDKs and other generated artifacts without changing the underlying specification.

We'll also be diving into new DevEx improvements that let you customize SDK imports, as well as exciting Terraform releases, including Pulumi support!

Sound good?

Ok, let’s go! 🚀

## OpenAPI Overlays

What is an Overlay, you ask? You can think of them as miniature OpenAPI documents that can be used to customize certain details of your API without altering the source document.
Why would you want to maintain one?

- You might want to customize your OpenAPI spec for SDK creation, but changing your spec is hard because it's generated from an API framework like FastAPI, tsoa, JOI, etc.
- You have a lot of teams at your company creating OpenAPI specs, and asking one of them to make a change is a tough process.
- You are setting up a Terraform provider for your OSS product and need different server URLs configured so users only hit a hosted API.

Let's look at an example. Here's a simple spec for the Speakeasy bar with only two `tags` defined, `drinks` and `orders`.

```yaml
openapi: 3.1.0
info:
  title: The Speakeasy Bar
  version: 1.0.0
  summary: A bar that serves drinks.
servers:
  - url: https://speakeasy.bar
    description: The production server.
security:
  - apiKey: []
tags:
  - name: drinks
    description: The drinks endpoints.
  - name: orders
    description: The orders endpoints.
paths:
  /dinner/:
    post: ...
    get: ...
  /drinks/:
    post: ...
```

To make an easy-to-use SDK, we've decided that a public interface should use `snacks`, i.e., `sdk.snacks.get_orders()`. As the owner of the company's SDK, you want to make this change, but that would mean making an actual
code change with the team that owns the drinks and orders service. Worse yet, it's all microservices, and there is no one team that owns all the services. You can get around this sustainably with
an overlay.

This overlay includes a `target` that you want to modify in your source document and an `action` to modify the target.

```yaml
overlay: 1.0.0
info:
  title: Overlay to fix the Speakeasy bar
  version: 0.0.1
actions:
  - target: "$.tags"
    description: Add a Snacks tag to the global tags list
    update:
      - name: Snacks
        description: All methods related to serving snacks
  - target: "$.paths['/dinner']"
    description: Remove all paths related to serving dinner
    remove: true
```

Specify that we want to add a new tag to the global tags list `$.tags` and add a description of the edit you're making. Under the update label, add the name and description of the tag you want to add.
Now you can use the Speakeasy CLI to merge these two documents right before generating the SDK:

```bash
speakeasy overlay apply -s openapi.yaml -o overlay.yaml >> combined.yaml
```

Time to celebrate 🎉 You've just created a new OpenAPI document that you can use to generate an SDK with the `snacks` tag. More on how to use Overlays [here](/docs/prep-openapi/overlays/create-overlays).

## 📦 Customizable Imports

At Speakeasy, we believe that automated doesn't mean no input. Certain aspects of SDK design need to be in the hands of the API builders. That's why we've built a platform which is flexible enough to let developers craft the devex for their users. To that end, we've released customizable imports. You can now configure the structure of the `import` paths in your SDK, and how they are referenced by your users. As an example, for Typescript:

<ScrollyCoding>

## !!steps

By default, our SDKs have created models in directories dictated by the OpenAPI spec, i.e. `models/components`, `models/operations` and `models/errors`. This is great for keeping your SDK organized, but it could be a bit verbose for your users, especially
for less structured languages like Typescript and Python where global imports are the norm.

```yaml !
sdk/
├─ models/
│  ├─ components/
│  │  ├─ user.ts
│  │  ├─ drink.ts
│  │  └─ ...
│  ├─ operations/
│  │  ├─ getuser.ts
│  │  ├─ updateuser.ts
│  │  ├─ getdrink.ts
│  │  ├─ updatedrink.ts
│  │  └─ ...
│  └─ errors/
│     ├─ sdkerror.ts
│     ├─ responseerror.ts
│     └─ ...
└─ ...
```

The import structure in this case would look like:

```typescript !
import { SDK } from '@speakeasy/bar'
import { User } from '@speakeasy/bar/dist/models/components/user'
import { GetDrinkRequest } from '@speakeasy/bar/dist/models/operations/user'
```

</ScrollyCoding>

<ScrollyCoding>
## !!steps

As an API producer, you can now configure your SDK to generate models into a single directory and import them from there. For Typescript, this would result in:

```yaml !
/
├─ src
│  ├─ models/
│  │  ├─ user.ts
│  │  ├─ drink.ts
│  │  ├─ getuser.ts
│  │  ├─ updateuser.ts
│  │  ├─ getdrink.ts
│  │  ├─ updatedrink.ts
│  │  ├─ sdkerror.ts
│  │  ├─ responseerror.ts
│  │  ├─ index.ts
│  │  └─ ...
│  └─ ...
└─ ...
```

## !!steps

With an import structure that is flat and supports a global path as follows:

```typescript !
import { User, GetDrinkRequest, SDK } from '@speakeasy/bar'
```

</ScrollyCoding>

More documentation on how to configure this in your SDK's `gen.yaml` file can be found [here](/docs/customize-sdks/imports).

## 🚢 Improvements and Bug Fixes 🐛

#### [Speakeasy v119.1](https://github.com/speakeasy-api/speakeasy/releases/tag/v1.119.1)

### Terraform

🚢 Pulumi support for generated Terraform providers\
🚢 Importing resources with Integer IDs\
🚢 DataSources with no required arguments (Empty Datasources)\
🚢 `x-speakeasy-conflicts-with` extension

### Python

🚢 Oauth support for Python SDKs

### Php

🚢 Support for customizable imports

### Typescript

🐛 Ensure `contentType` variable doesn't conflict with common parameter names\
🐛 Correctly handle `x-www-form-urlencode` in Typescript\
🚢 unset baseURL on default axios client

### Golang

🐛 `BigInt` & `Decimal` type support within a `Union` type

### Other:

🚢 Allow optional properties in usage snippets to be conditionally rendered\
🚢 Support for customizing input/output model suffixes\
🚢 Maintain OpenAPI Order in generated models\
🚢 Automatic Authentication documentation generated in READMEs\
🚢 Automatic Retry documentation generated in READMEs when retry extensions are used


 This is the content for the doc changelog/changelog-2023-11-30/index.mdx 

 ---
title: "Changelog: Early Access for Universal Typescript SDK and SDK Docs"
description: "New features to the Speakeasy Platform - November 30th, 2023."
keywords: [api, openapi, openapi, sdk generation, devex, dx, developer experience]
image: "/media/changelog-2023-11-30.png"
date: 2023-11-30
authors:
  - name: Sagar Batchu
  - image_url: "/media/author-headshots/sagar.jpeg"
featured_image: "/media/changelog-2023-11-30.png"
---

Welcome to another edition of the Speakeasy Changelog. In this issue, we will give you a sneak peek into products rolling hot off the press--our latest Typescript release as well as SDK Documentation. 

Sound good?

Ok, let’s go! 🚀

## (Early Access) Universal Typescript SDK

We're super excited to announce early access to our newest Typescript SDK. This SDK is designed to be a truly universal interface created to run
on servers and in the browser, and in any Javascript runtime! Powered by [fetch](https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API) and [Zod](https://zod.dev/), it has a minimal code footprint while providing a rich toolkit 
for one of the fastest-growing and evolving language communities. Other goodies include:

* Built-in runtime validation for types, 
* Support for union types and Bigints,  
* Native streaming upload and download support. Got an AI product that streams megabytes of data per request and response? No problem, we've got your users covered.

Check out that slick interface:

```typescript
import { Speakeasybar } from "speakeasy";
import { DrinkType } from "speakeasy";

async function run() {
  const sdk = new Speakeasybar({
        apiKey: "my_key",
    });

  const drinkType = DrinkType.Spirit;
  const res = await sdk.drinks.listDrinks(drinkType);

  if (res?.statusCode !== 200) {
    throw new Error("Unexpected status code: " + res?.statusCode || "-");
  }

  // handle response
}

run();
```
Read more about it [here](../post/introducing-tsv2)! Or join our [Slack](https://join.slack.com/t/speakeasy-dev/shared_invite/zt-1cwb3flxz-lS5SyZxAsF_3NOq5xc8Cjw) for early access!

## (Early Access) SDK Documentation

We're also excited to announce SDK Docs into early access! We've always believed that great developer experience starts with type safe experiences and rapid time to 200s. We believe this should 
extend to your documentation as well. That's why we're releasing support for generating great SDK docs straight from your OpenAPI spec. Get a fully working NextJS powered app with embedded usage snippets
just by running `speakeasy generate docs .... `! Or plug into our automation and get a working docs site that stays up to date with every API and SDK change. 

![API docs with SDKs featured](./sdk-docs.png)

We've built SDK docs to provide a language-specific guide that gets your users to a fully working integration with just a single copy-paste. Let's face it: 3-pane API references are out of date!
It's time for something new. 

Join our [Slack](https://join.slack.com/t/speakeasy-dev/shared_invite/zt-1cwb3flxz-lS5SyZxAsF_3NOq5xc8Cjw) to get early access to SDK Docs!

## New OpenAPI Guides: 

We have two new posts in our OpenAPI tips series covering best practices when working with tags and servers in your OpenAPI document. These simple concepts, when used effectively, can greatly improve the developer experience for your end users. 

* [Working with Servers](../post/openapi-servers): The servers block can be a great way to provide your users with convenient access to production, staging, sandbox and other
environments you might have. Maybe your API supports tenancy? No problem! You can template out your server endpoints with variables. 

* [Working with Tags](../post/tags-best-practices-in-openapi): Tags can be your best friend when organising your API resources into logical groups for your users. `sdk.payments.list` ? That's 
nice and easy to use :)  

## 🚢 Improvements and Bug Fixes 🐛

#### [Speakeasy v1.125.1](https://github.com/speakeasy-api/speakeasy/releases/tag/v1.125.1)

🚢 Improved preferred usage examples selection\
🚢 Server selection section automatically added to Readmes\
🚢 Complex serialization of deep objects in additionalProperties

### Terraform

🐛 Importing of external array of enums

### Python

🐛 Unused imports in Python for errors\
🐛 Relaxed urllib3 dependency in Python to support boto3

### Java

🚢 Nullable support\
🚢 Header capture in operation responses

### C#

🚢 Support for server variables\
🐛 Class names conflicting with namespaces and SDKs in C#/Unity


 This is the content for the doc changelog/changelog-2024-01-15/index.mdx 

 ---
title: "Changelog: SDK Docs in Beta & a 2024 Sneak Peek"
description: "New features to the Speakeasy Platform - January 15th, 2024"
keywords: [api, openapi, docs, sdk generation, devex, dx, developer experience]
image: "/media/changelog-2024-01-15.png"
date: 2024-01-15
authors:
  - name: Sagar Batchu
  - image_url: "/media/author-headshots/sagar.jpeg"
featured_image: "/media/changelog-2024-01-15.png"
---

Welcome to the first Speakeasy changelog of 2024! 🎉 We're excited to share the updates we snuck in at the end of 2023 and also give you a sneak peek of what's coming up in 2024.

Sound good?

Ok, let’s go! 🚀

## SDK Documentation in Beta

Your users are code-native. Your docs should be too. Today, we're releasing our SDK docs product into Beta!

What does code-native mean? It means fully integrating your SDKs into your documentation so that your documentation reflects how users will actually interact with your API. Let's face it: the best way to code is to copy and paste.

![API docs with SDKs featured](./sdk-docs.png)

Some of the highlights from the beta launch include:

* Code snippets that are compilable and feature the latest version of your SDKs;
* Request & response objects presented in terms of your SDK's type system;
* Generated sections for authentication, pagination, error handling, and more;
* Easily customizable theming;
* Deep linking & single page scroll so that you can navigate and share any level of your API reference;
* Built on best-in-class open-source tools like MDX, Next.js, and CodeHike.

Read more about it [in our release post](../post/release-sdk-docs).

## What's Coming Up in 2024

When we set out to build Speakeasy, we saw that dev teams everywhere were spending more time on API tooling than building the API itself. Let's face it: REST APIs are unruly. They neither have the flexibility of GraphQL nor the standardization of gRPC. However,
they're still the simplest way for companies to expose their data and services to the world. We started our journey addressing the needs of API producers by taking on the burden of building the various interfaces needed to consume APIs. This experience has solidified our mission of 
making APIs everywhere easy to create and consume.

This year, we're continuing our journey by moving upstream and providing API producers with all the tooling they need to build great APIs. Great external DevEx starts with great internal DevEx. New features to look out for: 

* More great SDK generation targets, including v2 Java generator, v2 of our Terraform generation to support multiple API calls per resource, and GA versions of Ruby, PHP, C#, Swift, and Kotlin; 
* "Level 2 SDKs" - chain calls in your client libraries; 
* A central registry to track and manage your API definitions and SDK packages;
* Visibility of API changes across your organization;  
* Ability to define your own governance policies and enforce them on various artifacts.

Onward and upwards! 🚀

## New Posts: 

As you know, we love writing about all things API design, DevEx, and OpenAPI. Here are our latest blog posts.

* [Working with Webhooks and Callbacks](../post/openapi-tips-webhooks-callbacks): Since OpenAPI3.1, the new `webhooks` keyword is a top-level element alongside paths. Webhooks are a mechanism that allows an API to send real-time data to a user as soon as an event occurs (without requiring the user to take any action). The user simply needs to subscribe to the event stream and provide a URL to start receiving data.
These can now be described in your OpenAPI document alongside your regular APIs, enabling all API models to be described in a single place.

* [Speakeasy SDKs vs OpenApi-Generator OSS](../post/compare-speakeasy-open-source): The pre-existing OpenAPI generator ecosystem has been a great inspiration for us, but we've felt the quality and flexibility of code gen is short of what's needed for production APIs. We've recently redone our Speakeasy vs OSS comparison to highlight where we've gone the extra mile in bringing you best-in-class SDKs.

## 🚢 Improvements and Bug Fixes 🐛

#### [Speakeasy v1.136.3](https://github.com/speakeasy-api/speakeasy/releases/tag/v1.136.3)

🚢 Support for OpenAPI-based ordering in generated SDKs\
🐛 Improved server selection and retry usage snippets\
🐛 Comparison of extensions when merging schemas

### Typescript

🚢 Support for extensionless import\
🐛 Missing imports for form-encoded requests\
🐛 Support for async iterators\
🐛 Support for default and const values

### Go

🐛 consts and defaults with an optional attribute

### Terraform

🐛 consts and defaults with an optional attribute

### Python

🚢 Nullable support\
🚢 Support for configurable license file\
🐛 More robust retry connection logic

### Java

🚢 Oauth support through security callbacks\
🚢 Javav2 released into preview in CLI. Try `--lang javav2` when generating SDKs\
🐛 Fixed gradlew file permissions

### SDK Docs

🚢 Improved page performance for large OpenAPI specs\
🚢 Support for language-specific sections and links\
🚢 Support for rate limit tables\
🚢 Support for Speakeasy error extensions







 This is the content for the doc changelog/changelog-2024-01-30/index.mdx 

 ---
title: "Changelog: SDK and Terraform Generation Improvements "
description: "New features to the Speakeasy Platform - January, 2024"
keywords: [api, openapi, docs, sdk generation, devex, dx, developer experience]
image: "/media/changelog-2024-01-30.png"
date: 2024-01-30
authors:
  - name: Sagar Batchu
  - image_url: "/media/author-headshots/sagar.jpeg"
featured_image: "/media/changelog-2024-01-30.png"
---

## 🚢 Improvements and Bug Fixes 🐛

#### Most recent version: [Speakeasy v1.160.0](https://github.com/speakeasy-api/speakeasy/releases/tag/v1.160.0)

🚢 Vacuum reports to validation output\
🚢 feat: added validation for invalid const/default values\
🐛 Ensure serialization method suffix is retain when overriding method names

### Typescript

🚢 Add support for server sent events (SSE)\
🐛 Correctly resolve union references and imports\
🐛 remove Type from reserved words


### Java

🚢 Use primitives for required boolean/numeric values\
🚢 support const (primitives only, not operation parameters)\
🚢 support file streaming for downloads\
🐛 prevent namespace collisions with `java.lang.Object`



### Python

🐛 Correctly resolve union references and imports short global and server variable names and conflicts with reserved type keyword\
🚢 Add support for server sent events (SSE)

### Go

🐛 Ensure global security callbacks are always an option\
🚢 Add support for server sent events (SSE)\
🚢 bump minimum go version to 1.20


### C#

🚢 Add pagination section to readme\
🚢 add authentication readme section\
🚢 implement global security flattening\
🚢 support applying Bearer prefix for oauth2 and oidc scheme\
🐛 fixed handling of sdks without servers\
🐛 `serverIndex` not used during SDK instantiation


### Terraform

🚢 default value for big floats (type: number)\
🚢 push default values into Computed + Optional fields explicitly; such that it's available as terraform plan output\
🐛 type reconciliation of enums + non-enums could sometimes cause attributes (e.g. computed) from not being applied


### Ruby

🐛 imports and module issues fixed

 This is the content for the doc changelog/changelog-2024-02-29/index.mdx 

 ---
title: "Changelog: Terraform v2 & CLI Upgrade"
description: "New features to the Speakeasy Platform - February, 2024"
keywords: [api, openapi, docs, sdk generation, devex, dx, developer experience]
image: "/media/changelog-2024-02-29.png"
date: 2024-02-29
authors:
  - name: Sagar Batchu
  - image_url: "/media/author-headshots/sagar.jpeg"
featured_image: "/media/changelog-2024-02-29.png"
---

import quickstart_url from './cli-quickstart.mp4';

Following on from our TypeScript work in January, we've kept our focus on upleveling our developer experience of both our platform and our generation targets. This month our CLI got an overhaul, and Terraform got a package of upgrades. The result is an experience that is more intuitive, more powerful, and more flexible for both our users and their end users.

Let's jump into it 🚀

## Terraform v2

Terraform is the go to tool for businesses implementing a strict disaster recovery plan.  For any SaaS businesses trying to sell API usage to these enterprises, that makes offering a Terraform Provider a must-have. 

Our Terraform generation has made maintaining a provider trivially easy and unlocked our customers ability to win large enterprise contracts. We've been working hard to extend that opportunity to every API. That's why we're excited to announce the release of Terraform v2 with a range of new features to support increasingly complex APIs:

- Collapse multiple API endpoints into a single Terraform Entity.
- Add Custom Plan Validators to your Provider
- Automatically enforced Runtime Validations
- Support for `default` and `const` attributes
- Handling of Batch Endpoints

For the details, please read the full release notes [here](/post/release-terraform-v2).

## Upgraded CLI - Enhanced Quickstart

We received a lot of feedback from our users about the CLI being their preferred interface for generating SDKs. We've therefore invested in creating what we think is one of the best CLI experiences available anywhere today. The principles that guided our rebuild were:

- ✨ No magic incantations required
- 😀 Flattened command hierarchy
- 👩‍🔧 Design for humans

Tangibly it means you don't need any context or docs to use the CLI. Our interactive prompts will make setting up your SDKs a breeze. 

<div className='mt-10'>
  <video controls={false} loop={true} autoPlay={true} width="100%" >
    <source src={ quickstart_url } type="video/mp4" />
  </video>
</div>

If you're interested in learning how we built the new CLI, [the code is open source](https://github.com/speakeasy-api/speakeasy) and a detailed blog post is available [here](/post/how-we-built-cli).

## 🚢 Improvements and Bug Fixes 🐛

#### Most recent version: [Speakeasy v1.200.1](https://github.com/speakeasy-api/speakeasy/releases/tag/v1.200.1)

🚢 Generation of SSE usage examples in `Readme.md`\
🐛 Correct construction of input statements when readOnly: true\
🚢 use defaults for usage snippet rendering if example not available\
🚢 support disabling security for a single operation\
🐛 don't regenerate if no version bump detected\
🐛 handle nullable enums correctly\

### Typescript

🚢 Support for [Retry-After](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Retry-After) headers\
🚢 Support for URL based cursor based pagination\
🚢 Allow string enums to be used in SSE data\
🚢 Make const fields optional on the client\
🚢 Improve validation errors thrown from SDK methods\
🚢 Introduce new response format with http metadata\
🚢 Support SDKs that do not have global servers

### Java

🚢 Support for new Sonatype Central Publishing\
🚢 Support bigint, decimal format\
🚢 Retries support\
🐛 Handle non-numeric cursors for pagination\
🐛 Fixed imports and handling of security builder field names\
🐛 Pagination response constructor signature, internal whitespace/ordering

### Python

🐛 Invalid dataclasses if method has params both with and without default value

### Ruby

🐛 fix server param in docstring\
🐛 handle named servers\
🐛 improve security and parameter handling\
🐛 improve unmarshalling of complex data types\
🐛 change base64 encodingtechnique to support long credentials

### Terraform

🚢 Allow for arrays of non-string enums\
🚢 Support for custom plan validators

### C#

🚢 example generation for complex objects\
🚢 add support for nullable request bodies\
🚢 support .NET5 compilation checks\
🚢 extend BigInteger/Decimal support to arrays and maps\
🚢 add support for global security callbacks\
🐛 revert dotnet version default to 5.x

### Go

🚢 Allow string enums to be used in SSE data






 This is the content for the doc changelog/changelog-2024-03-15/index.mdx 

 ---
title: "Changelog: Java General Availability and managed OAuth support"
description: "New features to the Speakeasy Platform - March, 2024"
keywords: [api, openapi, docs, sdk generation, devex, dx, developer experience]
image: "/media/changelog-2024-03-15.png"
date: 2024-03-15
authors:
  - name: Sagar Batchu
  - image_url: "/media/author-headshots/sagar.jpeg"
featured_image: "/media/changelog-2024-03-15.png"
---

Another changelog, another massive improvement to our SDK generation. This month, it's Java's turn for a GA makeover. But our other languages aren't gathering dust. We've added support for managed OAuth2.0 client credentials flow, and flattened response objects.

Let's jump into it 🚀

## Java General Availability

Java is inevitable. You can have your head turned by all the new & exciting languages that are being created, but if you are serving a large organization, you will need to be ready to support Java.

Which is why we are excited to announce that Java is now Generally Available on the Speakeasy Platform! General availability means that every feature of our generation platform is now available for Java. As a bonus, we've taken this work as an opportunity to completely revamp the developer experience. Here are the highlights of what's changed: 

- Enhanced `null` safety and `Optional` support
- Builder patterns for better readability, discoverability, and convenient overloads
- Lists instead of arrays for collections
- No direct field access (getter methods are used now)
- A simplified Gradle project structure
- Support for non-discriminated `oneOf`s
- Auto-Pagination
- Retry support
- OAuth2.0 support

Check out the new interface:
  
```java
public class Application {

    public static void main(String[] args) {
        try {
            MyPlatform sdk = MyPlatform.builder()
                .security(Security.builder()
                    .authHeader("Basic BASE_64_ENCODED(API_KEY)")
                    .build())
                .build();

            UserRequestBody req = UserRequestBody.builder()
                .name("Saj Batchu")
                .role(RoleType.ADMIN)
                .workspaces(java.util.List.of(
                    workspaceRef.builder()
                        .id("60d2fa12-8a04-11ee-b9d1-0242ac120002")
                        .build()))
                .build();

            CreateUserResponse res = sdk.user().create()
                .request(req)
                .call();

            if (res.user().isPresent()) {
                // handle response
            }
        } catch (Exception e) {
            // handle exception
        }
    }
}
```

For the details, please read the full announcement [here](/post/release-java-ga).

## 🚢 Improvements and Bug Fixes 🐛

**Based on most recent version: [Speakeasy v1.210.0](https://github.com/speakeasy-api/speakeasy/releases/tag/v1.210.0)**

🚢 Handle flat responses for empty status codes \
🚢 Fail schema validation if missing a server \
🚢 Propagate defaults for examples in parameters

### Typescript

🚢 Support Empty Error types \
🚢 Add support for response formats and flat responses \
🚢 Add managed OAuth2.0 client credentials flow support (as a SDK hook) \
🚢 Handle null enums fields and union members \
🐛 Fix missing imports with flat responses

### Java

🚢 Support passing in additional dependencies in the SDK \
🚢 Support `callAsStream` autopagination syntax \
🐛 Fix typo in README.md Error Handling section

### Python

🚢 Add support for response formats and flat responses

### Terraform

🚢 Use the default http client in TF to remove timeouts

### C#

🚢  Support naming servers

### Go

🚢  Add support for response formats and flat responses







 This is the content for the doc changelog/changelog-2024-04-04/index.mdx 

 ---
title: "Changelog: SDK hooks, OpenAPI Reference & more!"
description: "New features to the Speakeasy Platform - April 4, 2024"
keywords: [api, openapi, docs, sdk generation, devex, dx, developer experience]
image: "/media/changelog-2024-04-04.png"
date: 2024-04-04
authors:
  - name: Sagar Batchu
  - image_url: "/media/author-headshots/sagar.jpeg"
featured_image: "/media/changelog-2024-04-04.png"
---

import { Callout } from '~/components'
import openapi_ref from './assets/openapi-ref.mp4';

We've got a jam packed changelog that includes the introduction of new extensibility into our code gen platform and a comprehensive OpenAPI reference guide.

Let's get into it 👇

## SDK Hooks

Since Speakeasy started, we've carefully balanced the extensibility and dependability of our code generator. We want users to customize their SDKs without creating a maintenance burden. It can be a difficult balance to strike. Which is why we're excited to announce the biggest addition of extensibility to our platform yet – SDK Hooks! 

With SDK Hooks, you are no longer constrained to what is defined in your OpenAPI document. You can now safely inject custom logic into your SDKs where you need it. 

![Diagram showing SDK Hooks](./assets/sdk-hooks.png)

[Read more here](/post/release-sdk-hooks)

## OpenAPI Reference

OpenAPI was designed to be capable of describing any HTTP API, whether that be REST or something more akin to RPC-based calls. By design, it has **a lot** of flexibility baked-in. That is great, but it makes it really hard to grok if you're new to the format (and often even when you're experienced).

That’s why we built the reference documentation that we wished we had when we were starting out. It's a comprehensive guide to the OpenAPI format, with examples, explanations, and links to the relevant sections of the OpenAPI specification.

And even better, it's AI-enabled! Ask any OpenAPI question, and the reference guide will get you sorted out.

<div className='mt-10'>
  <video controls={false} loop={true} autoPlay={true} width="100%" >
    <source src={ openapi_ref } type="video/mp4" />
  </video>
</div>

[Check out the full reference here](/openapi)

## 🚢 Improvements and Bug Fixes 🐛

<Callout title="NOTE" variant="info">
Based on most recent CLI version: [**Speakeasy v1.231.0**](https://github.com/speakeasy-api/speakeasy/releases/tag/v1.231.0)
</Callout>

🚢  Offer sample OpenAPI Document during quickstart \
🚢  Make example generation much, much faster  \
🚢  Generate code samples in speakeasy run \
🚢  New CLI command: `speakeasy openapi diff`\
🚢  Validate `gen.yaml` during speakeasy run

### TypeScript

🐛 Fix hoisting operation security and TypeScript basic auth support

### Java

🚢 Add `wait`, `notify`, `notifyAll`, `clone` as reserved words

### Python

🚢 Add support for additional metadata url

### Terraform

🚢 Capability to wrap classes and unions \
🚢 Mix wrapped with non-wrapped resources in a multi-operation terraform resource \
🐛 Read data sources during multiple read requests dropping unnecessary attributes 

### C#

🚢  Introduce conventional namespaces into  C# & Unity


 This is the content for the doc changelog/changelog-2024-04-16/index.mdx 

 ---
title: "Changelog: Integrate with Your Favorite Docs Provider!"
description: "New features to the Speakeasy Platform - April 16, 2024"
keywords: [api, openapi, docs, sdk generation, devex, dx, developer experience]
image: "/media/changelog-2024-04-16.png"
date: 2024-04-16
authors:
  - name: Nolan Sullivan
  - image_url: "/media/author-headshots/nolan.jpeg"
featured_image: "/media/changelog-2024-04-16.png"
---

import { Callout } from '~/components'

As we roll into summer, the days are getting longer but your APIs' time to `200` will be getting shorter thanks to our new integration with API documentation providers! More on this exciting new feature below, as well as the regular deluge of updates to our code generator!

Let's get into it 👇

## SDK Docs Integration

Production integration involves a lot more than just making an HTTP request. So why does your API reference have a generic `fetch` call? Authentication, error handling, pagination parsing, request retries, all need to be considered.

Thankfully, SDKs abstract a lot of these concerns for users, making it possible to provide a code snippet that is both concise and useful to your users. And with our new docs integration, it's now possible to automatically update your SDK code snippets with every new version of your SDKs!

Building a production-ready integration is as easy as ⌘C, ⌘V.

import snippets_url from './assets/snippet-docs.mp4';

<div className='mt-10'>
  <video controls={false} loop={true} autoPlay={true} width="100%" >
    <source src={ snippets_url } type="video/mp4" />
  </video>
</div>

Head to [**our docs**](/docs/mintlify) to start integrating SDKs into **your docs**!

## 🚢 Improvements and Bug Fixes 🐛

<Callout title="NOTE" variant="info">
Based on the most recent CLI version: [**Speakeasy v1.253.3**](https://github.com/speakeasy-api/speakeasy/releases/tag/v1.231.0)
</Callout>

### The Platform

🚢 Speed up validation runs by skipping name resolution \
🚢 Global parameters can now be hidden from method signatures by configuring `maxMethodParams` with extensions \
🚢 Support for flattened globals \
🚢 `deprecated` OpenAPI keyword now respected for globals

### Terraform

🚢 Always instantiate arrays to empty slices to avoid `null` being sent over the wire \
🚢 Capability to generate resource state upgraders \
🚢 Custom set validators, bump `terraform-plugin-framework` to 1.7.0 with custom dependencies \
🚢 Set types in Terraform, `x-speakeasy-xor-with` / `x-speakeasy-required-with` validators \
🐛 Fix: extensions being ignored when under an `allOf` \
🐛 Fix Terraform support in `quickstart` command \
🐛 Fix: only hoist union subtypes that are primitive to avoid a provider error 

### C#

🚢 Support multi-level package naming and non-camel case namespaces

### Python

🚢 Bump pylint version to `3.1.0` in Python \
🚢 Better `additionalDeps` validation in your `gen.yaml` file


 This is the content for the doc changelog/changelog-2024-05-01/index.mdx 

 ---
title: "Changelog: C# General Availability & our AI-enhanced CLI"
description: "New features to the Speakeasy Platform - May 1, 2024"
keywords: [api, openapi, cli, sdk generation, devex, dx, developer experience]
image: "/media/changelog-2024-05-01.png"
date: 2024-05-01
authors:
  - name: Sagar Batchu
  - image_url: "/media/author-headshots/sagar.jpeg"
featured_image: "/media/changelog-2024-05-01.png"
---

import speakeasy_ask_url from './assets/speakeasy-ask.mp4';
import { Callout } from '~/components'

The release of our C# SDK marks an important milestone for Speakeasy. Over half of the languages we support are now in GA! As always, a massive thank you to all our customers and users for their feedback and support. We couldn't have done it without you 🎉 And it goes without saying, we won't stop here. More to come very shortly!

## C# General Availability

Microsoft acolytes and fintech employees rejoice! We're excited to announce that C# is now generally available. General availability means that the public interface is now stable, and every feature of Speakeasy's generation platform is accessible. A few of the highlights that have us excited include:

- Configurable support for `.NET 5.X` and above
- `Async`/`Await` support
- OAuth2.0 support
- Support for complex number types:
  - `System.Numbers.BigInteger`
  - `System.Decimal`
- Strong-typing with IntelliSense support

The full details can be found [here](/docs/sdk-design/csharp/methodology-csharp)

## Speakeasy Ask

We're excited to announce the release of [Speakeasy Ask](/docs/speakeasy-cli/ask), our AI-enhanced CLI. Speakeasy Ask is a new feature that allows you to ask questions about your OpenAPI spec and SDKs without leaving our CLI. This feature is designed to make it easy to access the Speakeasy knowledge base wherever your work happens. 

No more side by side windows or switching between tabs. Just ask your question and get the answer you need.

<div className='mt-10'>
  <video controls={false} loop={true} autoPlay={true} width="100%" >
    <source src={ speakeasy_ask_url } type="video/mp4" />
  </video>
</div>

## 🚢 Improvements and Bug Fixes 🐛

<Callout title="NOTE" variant="info">
Based on the most recent CLI version: [**Speakeasy v1.277.4**](https://github.com/speakeasy-api/speakeasy/releases/tag/v1.277.4)
</Callout>

🚢 `ClientCredentialSecurityAccess` for combined security options\
🚢 Postman generation in alpha\
🚢 Improved performance of `speakeasy validate` by making sure validation runs resolve names

### Python

🐛 Improved handling of errors returned by the `after_error` hook \
🚢 Added support for unions as errors \
🚢 Ensure classes can't use `Undefined` reserved word in Python 

### Golang

🚢 Added support for unions as errors

### Java

🚢 Support added for SDK Hooks\
🐛 Applied workaround for `jackson-databind` boolean serialization issue\
🐛 Removed `jsonpath` dependency if pagination is not configured\
🐛 Removed redundant imports in usage snippets\
🐛 Used wildcard generic types as input only\
🚢 Added `SuppressWarnings` unchecked annotations, report unchecked in build

### C#

🐛 Fixed missing import for flattened operation parameters\
🚢 Added support for injection of additional dependencies

### Typescript

🐛 Removed excess comma when templating SSE responses with headers\
🐛 Computed accept types from success responses\
🐛 Added better error messages for `content type` mismatches\
🚢 Updated SDKs to use `zod 3.23.4`\
🚢 JSR publishing available out of the box \
🚢 Added support for unions as errors\
🚢 Added handling of optional security when using client credentials auth

### Terraform

🐛 Arrays are now instantiated as empty slices to avoid null being sent over the wire


 This is the content for the doc changelog/changelog-2024-05-15/index.mdx 

 ---
title: "Changelog: API Linting & Postman Generation"
description: "New features to the Speakeasy Platform - May 15, 2024"
keywords: [api, openapi, docs, sdk generation, devex, dx, developer experience]
image: "/media/changelog-2024-05-15.png"
date: 2024-05-15
authors:
  - name: Nolan Sullivan
  - image_url: "/media/author-headshots/nolan.jpeg"
featured_image: "/media/changelog-2024-05-15.png"
---

import { Callout } from '~/components'
import linting_video from './assets/linting.mp4';

Two exciting new features are coming to Speakeasy this week: API Linting and Postman Collection Generation.

Let's get into it 👇

<div className='mt-10'>
  <video controls={false} loop={true} autoPlay={true} width="100%" >
    <source src={linting_video} type="video/mp4" />
  </video>
</div>

## API Linting

Where does API developer experience start? SDKs are super important, but they're the final step in the integration process. The first step is the API itself and making sure that a consistent interface is being exposed. How do you ensure that your API is consistent, especially as the number of developers contributing grows? With an API linter of course!

Now, linters don't have the greatest reputation in the developer community, but that bad reputation is deserved. Most linters have been a drag on developer productivity. They throw up opaque warnings and unnecessarily block progress on feature development. We saw an opportunity to do better.

We've focused on making sure the Speakeasy linter will speed up development, rather than slows it down. Here's how our linter is different:

- It runs where your work happens:
  - Speakeasy CLI
  - VS Code extension
  - CI/CD pipelines
- The output is human-readable and clearly actionable
- It comes with our robust default ruleset that can be easily customized with spectral rules to match your org's API style guide.

To get started just update to the latest version of the Speakeasy CLI and run `speakeasy lint`.

## Postman Collection Generation [Alpha]

Ready your curl requests, because Speakeasy is now able to generate high quality Postman Collections from your OpenAPI document.

Postman Collections facilitate the easy adoption, development, and testing of your APIs. They allow users to understand the API's capabilities quickly through executing API requests without the need to set up a coding environment.

As with any API artifact, a collection is only as useful as it is up-to-date. Speakeasy's Postman Collection generation is designed to be a seamless part of your API development workflow.

Collection generation is free while it's in alpha, so give it a try and let us know what you think!

## 🚢 Improvements and Bug Fixes 🐛

<Callout title="NOTE" variant="info">
Based on the most recent CLI version: [**Speakeasy v1.253.3**](https://github.com/speakeasy-api/speakeasy/releases/tag/v1.231.0)
</Callout>

### The Platform

🚢 Perf: Speed up validation runs by skipping name resolution

### Typescript

🧹 Chore: Remove some unused inbound zod types

### Terraform

🚢 Feat: Support mapping environment variables to provider configuration\
🚢 Feat: Composite Import support\
🚢 Feat: Generate import.sh snippets for additional terraform resource documentation\
🚢 Feat: Support custom (non generated) resources and datasources being added into the provider\
🐛 Fix: always instantiate required arrays to empty slices to avoid `null` being sent over the wire\
🐛 Fix: extensions being ignored when under an `allOf`

### JavaV2

🚢 Feat: Better examples

### C#

🎉 Now in GA! 🎉\
🚢 Feat: Retries\
🚢 Feat: oneOf (union) support\
🧹 Chore: Reduced HttpClient instantiation

### Python

🐛 Fix: after_error hook better error handling


 This is the content for the doc changelog/changelog-2024-05-31/index.mdx 

 ---
title: "API Change Detection & Open Enums"
description: "New features to the Speakeasy Platform - May 29, 2024"
keywords: [api, openapi, docs, sdk generation, devex, dx, developer experience]
image: "/media/changelog-2024-05-29.png"
date: 2024-05-29
authors:
  - name: Nolan Sullivan
  - image_url: "/media/author-headshots/nolan.jpeg"
featured_image: "/media/changelog-2024-05-29.png"
---

import { Callout } from '~/components'
import change_detection_video from './assets/change-detection.mp4';

Two exciting new features are coming to Speakeasy this week: API Change Detection and Open Enum support.

Let's get into it 👇

<div className='mt-10'>
  <video controls={false} loop={true} autoPlay={true} width="100%" >
    <source src={change_detection_video} type="video/mp4" />
  </video>
</div>

## API Change Detection

For as long as there have been APIs, the dreaded "unintended breaking change" has tortured API developers everywhere. Countless hours spent debugging, untold numbers of damage control meetings with unhappy customers, the inevitable "who broke the API?" finger-pointing; it's not pretty.

And yet decades later, it still feels like it's needlessly difficult for organizations to get good observability into how their API is changing. This is why we're so excited to be tackling this problem head-on. Today's release of API change detection is just the beginning.

Whenever there's a change to your OpenAPI document, Speakeasy will automatically detect it and notify you. The changes will be summarized directly in your pull request, with a callout for when changes are breaking. If you want to dive into the details, head to our dashboard for the full breakdown.

---

```typescript
import { SDK } from "@acme/cms";
import { Unrecognized } from "@acme/cms/types";

const cms = new SDK();
const post = await cms.posts.get('open-enums');

let icon: "📸" | "🎨" | "🏈" | "❓";
switch (post.category) {
  case "lifestyle":
    icon = "🎨";
    break;
  case "photography":
    icon = "📸";
    break;
  case "sports":
    icon = "🏈";
    break;
  default:
    post.category satisfies Unrecognized<string>;
    icon = "❓";
    break;
}
```

## Open Enum Support

Both the power and the pain of enums come from their rigidity. Defining a fixed scope helps guide users towards intended use cases and makes enhanced type-safety possible. But the time will come when you need to alter the accepted values of an enum in your API, and it will be painful. How do you alter the set of accepted values without breaking existing code? 

To soften the pain, some languages have native support for the concept of "open" enums (other languages don't, but you can achieve the same results with custom classes). Open enums allow for unknown values to be passed through without erroring. For APIs that are rapidly evolving, this can help prevent some of the typical pain associated with making changes.

And now for TypeScript, Python and Go, Speakeasy supports open enums. You can use our new extension: `x-speakeasy-unknown-values: allow` and your SDK will generate a type that includes the enum values and a catch-all type that represents any unrecognized value. This allows you to handle unknown values gracefully in your code.

For the deep dive, read [our release post](/post/open-enums)

---

## 🚢 Improvements and Bug Fixes 🐛

<Callout title="NOTE" variant="info">
Based on the most recent CLI version: [**Speakeasy v1.297.0**](https://github.com/speakeasy-api/speakeasy/releases/tag/v1.297.0)
</Callout>

### The Platform

🚢 Standardize publishing secret names created by `configure publishing` command\
🐛 Circular reference handling within unions\
🐛 Don't panic on bad validation lineNums\
🐛 ClientCredentials hooks incorrect import\
🐛 Mitigations for Github rate limiting\
🐛 Nested namespaces in usage snippets

### Typescript
🐛 Jest compatibility fixes and leaner error models for Typescript\
🚢 Safer weakly typed unions

### Go
🚢 Support Open Enums in Golang\
🚢 Safer weakly typed unions\
🚢 Support pointer request objects

### Terraform

🚢 Improve terraform diff suppression by instantiating arrays to `[]`\
🐛 Fix Set datatype in Terraform

### Java

🚢 Sandbox (Dev Containers) support for Java\
🚢 Support for Server Sent Events\
🐛 Correct logic when retries and pagination are used together
 
### C#

🚢 .NET8 LTS support for C#\
🚢 Simplify SpeakeasyHttpClient configuration\
🐛 General Usage snippet reliability improvemenets\
🐛 Flattened security field sanitizing in usage snippets C#

### Python

🚢 Support Open Enums in Python


 This is the content for the doc changelog/changelog-2024-06-18/index.mdx 

 ---
title: "Windows Support, Quickstart, and a V1 Sunset"
description: "New features to the Speakeasy Platform - June 19, 2024"
keywords: [api, openapi, docs, sdk generation, devex, dx, developer experience]
image: "/media/changelog-2024-06-19.png"
date: 2024-06-19
authors:
  - name: Nolan Sullivan
  - image_url: "/media/author-headshots/nolan.jpeg"
featured_image: "/media/changelog-2024-06-19.png"
---

import { Callout } from "~/components";

Before everyone dissipates into the BBQ smoke of the summer holidays, we've got a few more updates to share. This week, amid the usual slew of improvements and fixes, we're excited to announce the release of Windows support, a smarter Quickstart, and the coming sunset TypeScript V1.

Let's get into it 👇

## Full CLI Support for Windows

With last month's [GA release of our C# SDK generation](/changelog/changelog-2024-05-01), it's as good a time as any to make sure that the CLI is as easy to use on Windows as it is on MacOS and Linux. And so we're happy to announce that Windows is now a fully supported platform.

We've made sure that our CLI's interactive mode works seamlessly, and our CLI's integration testing has been updated to include Windows environments.

Install our CLI on Windows:

```bash
choco install speakeasy
```

## A Quicker Quickstart

```bash
# !focus(8)
│ Workflow - success
│ └─Target: my-first-target - success
│   └─Source: openapi - success
│     └─Tracking OpenAPI Changes - success
│       └─Snapshotting OpenAPI Revision - success
│       └─Storing OpenAPI Revision - success
│     └─Validating Document - success
│   └─Retrying with minimum viable document - success
│     └─Source: openapi - success
│       └─Applying Overlays - success
│         └─Apply 1 overlay(s) - success
│       └─Tracking OpenAPI Changes - success
│         └─Snapshotting OpenAPI Revision - success
│         └─Storing OpenAPI Revision - success
│       └─Validating Document - success
│   └─Validating gen.yaml - success
│   └─Generating Typescript SDK - success
│     └─Setup Environment - success
│     └─Load and Validate Document - success
│     └─Generate SDK - success
│     └─Compile SDK - success
│   └─Cleaning up - success
```

We would love to think that every OpenAPI spec is error-free, but we know that not every company is using [our linter](/docs/linting/linting) (yet). That's why we've rebuilt Speakeasy Quickstart to be able to persevere through errors to help teams get to a minimally viable SDK faster.

Instead of blocking generation when there's an error in the OpenAPI syntax, `quickstart` will pare down your spec to the validly documented operations and generate an SDK with just those. The error logs will be logged separately so that you can go back and make your fixes. Just another small change in the name of getting users their SDKs sooner.

## TypeScript V1 Rides Off Into The Sunset

Just as important as the new products you roll out, are the old products you retire. And so, we're officially announcing the sunset of TypeScript V1 on **August 9th, 2024**.

We [rolled out TypeScript v2 in December 2023](/post/introducing-universal-ts), and since then, we've been working to make sure that all of our users have had the time to migrate. We're at almost 100% migration, and so we're ready to say goodbye to TypeScript V1.

If anyone needs reminding of the benefits of switching, here's the summary of the changes:

- Dependencies​: v1 used Axios; v2 uses the Fetch API.
- Compatibility​: v2 supports Node.js, Deno, Bun, and React Native.
- Validation​: v2 integrates Zod for robust runtime data validation.
- Polymorphic Types​: v2 handles complex API schemas better.

Switching is as easy as a 1 line change in your SDK's `gen.yaml` file:

```yaml gen.yaml
# !focus(4)
configVersion: 1.0.0
# Rest of gen.yaml omitted
typescript:
  templateVersion: v2
```

---

## 🚢 Improvements and Bug Fixes 🐛

<Callout title="NOTE" variant="info">
  Based on the most recent CLI version: [**Speakeasy
  v1.309.1**](https://github.com/speakeasy-api/speakeasy/releases/tag/v1.309.1)
</Callout>

### The Platform

🐛 Fix: Handle edge case where `.yaml` looks like `.json`\
🐛 Fix: Handle empty responses in webhooks

### Typescript

🐛 Fix: Added explicit types for exported enum schemas

### Terraform

🐛 Fix: Edge case with combination of oneOf and non-oneOf in TF

### Java

🚢 Feat: Add support for client credentials to java \
🚢 Feat: Support user customization of `build.gradle` \
🐛 Fix: Addressed compiler errors for pagination-enabled methods that exceed `maxMethodParameters`

### C#

🚢 Feat: `Nuget.md` file is generated for published C# packages \
🐛 Fix: Handle missing C# imports for unions

### Unity

🐛 Fix: Address bugs related to Unity's support for only `.Net5`


 This is the content for the doc changelog/changelog-2024-06-28/index.mdx 

 ---
title: "On Demand Publishing & Pre-Releases"
description: "New features to the Speakeasy Platform - June 27, 2024"
keywords: [api, openapi, docs, sdk generation, devex, dx, developer experience]
image: "/media/changelog-2024-06-28.png"
date: 2024-06-28
authors:
  - name: Nolan Sullivan
  - image_url: "/media/author-headshots/nolan.jpeg"
featured_image: "/media/changelog-2024-06-28.png"
---

import { Callout } from '~/components'
import publishing_video from './assets/on-demand-publishing.mp4';
import YouTube from 'react-youtube';

You've just generated your SDK, and you're feeling good, but in the immortal words of Kobe Bryant, "Jobs not finished. SDK published? I don't think so." 

<div className="mt-10 flex justify-center items-center" >
  <YouTube
    videoId="fY7l2pcxdHM"
  />
</div>

Until it's published, your SDK is NOT done. Fortunately, with our recent release it's easier than ever to not only generate, but also publish your SDKs "On Demand". 

## Pre-Releases & On-Demand Publishing

<div className='mt-10'>
  <video controls={false} loop={true} autoPlay={true} width="100%" >
    <source src={publishing_video} type="video/mp4" />
  </video>
</div>

You can now add any pre-release version identifiers that you want to tag your SDK with: `-alpha`, `-beta`, etc. As you update your SDK, we'll automatically version bump while retaining the pre-release tags. Then when you're ready, you can remove the tag and publish your new version.

And now, all this can be done from the Speakeasy dashboard, just head to the publishing tab and re-publish your SDKs whenever you want.

---

## 🚢 Improvements and Bug Fixes 🐛

<Callout title="NOTE" variant="info">
Based on the most recent CLI version: [**Speakeasy v1.309.1**](https://github.com/speakeasy-api/speakeasy/releases/tag/v1.309.1)
</Callout>

### The Platform

🚢 Feat: Turn on Github Sandboxes by default for typescript, go and python SDKs \
🚢 Feat: Imroved default target SDK naming from the classname \
🐛 Fix: Improved handling of discriminated union handling

### Terraform

🚢 Feat: `x-speakeasy-match` supports subkeys for Terraform


### Java

🚢 Feat: Enabled custom base package naming in `gen.yaml`
🚢 Feat: License included in build.gradle \
🚢 Feat: Improved comment syntax \
🐛 Fix: `ClientCredentialsHook` compiles when global security absent
 
### C#

🚢 Feat: Added tolerance for extra json fields in union deserialization \
🐛 Fix: Resolved union handling




 This is the content for the doc changelog/changelog-2024-07-10/index.mdx 

 ---
title: "Python Alpha Release: Pydantic & Async"
description: "New features to the Speakeasy Platform - July 10, 2024"
keywords: [api, openapi, docs, sdk generation, python, devex, dx, developer experience]
image: "/media/changelog-2024-07-10.png"
date: 2024-07-10
authors:
  - name: Nolan Sullivan
  - image_url: "/media/author-headshots/nolan.jpeg"
featured_image: "/media/changelog-2024-07-10.png"
---

import { Callout } from '~/components'
import beezy_ide_video from './assets/beezy-ide.mp4';

One benefit of having a UK-based engineering hub — no Independence Day! As the US celebrated last week, our UK colleagues were hard at work on the next iteration of our Python SDK Generator. 

And it's thanks to those efforts that we're able to announce the alpha release of our new Python Generator with support for Async & Pydantic models! 

## Python Alpha Release: Pydantic & Async

<div className='mt-10'>
  <video controls={false} loop={true} autoPlay={true} width="100%" >
    <source src={beezy_ide_video} type="video/mp4" />
  </video>
</div>

The new generator takes full advantage of the best tooling available in the Python ecosystem to introduce true end-to-end type safety, support for asynchronous operations, and a streamlined developer experience:

- Full type safety with [Pydantic](https://github.com/pydantic/pydantic) models for all request and response objects,
- Support for both asynchronous and synchronous method calls using `HTTPX`,
- Support for typed dicts as method inputs for an ergonomic interface,
- `Poetry` for dependency management and packaging,
- Improved IDE compatibility for a better type checking experience,
- A DRYer and more maintainable internal library codebase.

Check out the [release post](/post/release-python-v2-alpha) for the full details. 

If you want to test the new Python Generator, please fill out [our Typeform](https://speakeasyapi.typeform.com/python-v2), or message us on Slack. We will provide you with the necessary information to get started. 

---

## TypeScript Bundle Size Reduction

Bundle Size does matter! Which is why we've been working hard to reduce the size of our TypeScript SDKs, and we're happy to announce that we've made significant progress. Bundle size has dropped an average of 30% with some SDKs seeing reductions of up to 50%. This is down to a couple recent efforts: 

- **Support for ESM** - We've implemented support for ECMAScript Modules (ESM) alongside CommonJS. This dual bundling approach improves the ability to tree-shake by allowing developers to choose the format that works best for their needs.
- **DRYer library code** - We intentionally prioritize readability and debuggability in our SDKs, but that can sometimes mean duplication. We identified some key areas where we could reduce duplication without sacrificing readability.

This is just the beginning. With the upcoming release of Zod v4 we'll be able to tree-shake the Zod dependency, and further reduce the bundle size. Stay tuned for further updates!


## 🐝 New Features and Bug Fixes 🐛

<Callout title="NOTE" variant="info">
Based on the most recent CLI version: [**Speakeasy v2.361.11**](https://github.com/speakeasy-api/openapi-generation/releases/tag/v2.361.11)
</Callout>

### The Platform

🐛 Fix: Correctly display `x-speakeasy-error-message` \
🐛 Fix: Patch broken usage snippets for SSE-based SDK methods

### TypeScript

🐝 Feat: Support building SDKs to ESM or ESM and CJS \
🐝 Feat: Refactored Zod Schemas for tree-shaking \
🐛 Fix: Omit barrel exports in ESM for unused model scopes \
🐛 Fix: Added missing imports for open enums in TS

### Python

🐛 Fix: use None as arg default instead of UNSET for optional method arguments 

### Terraform

🐝 Feat: Support for custom plan modifiers \
🐝 Feat: Derive json schema types from const values when not specified

### Go

🐝 Feat: Move retry logic out of utils and into a public package

### Java

🐛 Fix:  Patched compilation error in client credentials hook when security not flattened
 





 This is the content for the doc changelog/changelog-2024-07-24/index.mdx 

 ---
title: "Mintlify Integration, Plan Validators, and Python Async Beta"
description: "New features to the Speakeasy Platform - July 24, 2024"
keywords:
  [api, openapi, docs, sdk generation, python, devex, dx, developer experience]
image: "/media/changelog-2024-07-24.png"
date: 2024-07-24
authors:
  - name: Nolan Sullivan
  - image_url: "/media/author-headshots/nolan.jpeg"
featured_image: "/media/changelog-2024-07-24.png"
---

import { Callout } from "~/components";
import beezy_ide_video from "./assets/beezy-ide.mp4";
import mintlify_setup from "./assets/mintlify.mp4";

Generation targets grow up so fast. You announce their alpha release, and before you know it, they're off to beta... And it's not only the Python Generator that's maturing.

The Mintlify integration is now self-serve, and Terraform Generation just got even more fully featured with the addition of OpenAPI-based Plan Validators.

Read on for the details!

## Mintlify Integration - Now Self-Serve

<div className="mt-10">
  <video controls={false} loop={true} autoPlay={true} width="100%">
    <source src={mintlify_setup} type="video/mp4" />
  </video>
</div>

Making your API documentation SDK-based is easier than ever with our Mintlify integration now available for self-serve.

1. Select the SDKs you want to include in your docs.
2. Point Speakeasy workflow at your Mintlify repo.

That's it! Now every new generation of your SDKs will automatically update your Mintlify repo.

---

## Terraform Plan Validators

```go
func (r *userResource) Schema(_ context.Context,
_ resource.SchemaRequest, resp *resource.SchemaResponse) {
  resp.Schema = schema.Schema{
    Attributes: map[string]schema.Attribute{
      "username": stringattribute.String{
        Required:    true,
        Description: "The username of the user.",
        Validators: []validator.String{
          stringvalidator.LengthBetween(6, 64),
          stringvalidator.RegexMatches(
            regexp.MustCompile(`^[a-z]+$`),
            "must contain only lowercase alphanumeric characters",
          ),
        },
      },
    },
  }
}
```

With the latest Speakeasy release, Terraform Provider generation will now automatically convert additional OAS validation properties into Terraform configuration validators. This will ensure that Terraform users will receive upfront feedback about invalid configurations before they are applied.

Automatic OAS -> Terraform validation now includes:

- For `string` types: `​maxLength​`, `​minLength​`, and `​pattern`
- For `integer` types: `​maximum​` and `​minimum`
- For `array` types: `​maxItems​`, `​minItems​`, and `​uniqueItems`

Refer to [the docs](/docs/terraform/extensions#configuration-validation) for more on validation capabilities.

## Python Beta Release: Pydantic & Async

<div className="mt-10">
  <video controls={false} loop={true} autoPlay={true} width="100%">
    <source src={beezy_ide_video} type="video/mp4" />
  </video>
</div>

Last changelog we announced the alpha release of our new Python Generator with support for Async & Pydantic models. We're now excited to announce the new generator is in beta!

All new SDKs will use the new generator by default. Existing production SDKs will be migrated by request.

For all the details on the new generator, read about [our Python SDK design](/docs/sdk-design/python/methodology-python)

## 🐝 New Features and Bug Fixes 🐛

<Callout title="NOTE" variant="info">
  Based on the most recent CLI version: [**Speakeasy
  v1.345.0**](https://github.com/speakeasy-api/openapi-generation/releases/tag/v1.345.0)
</Callout>

### The Platform

🐝 Feat: SSE Sentinel - enables API builders to specify a sentinel which indicates that a streaming response has no more content to send. \
🐝 Feat: `deepObject` style Params now supported \
🐛 Fix: Optional fields for error models are correctly marked.

### TypeScript

🐛 Fix: Handle renamed object fields using `x-speakeasy-name-override`

### Python

🐝 Feat: Make Python `unset` falsy \
🐝 Feat: Support defaults and usage snippets for flattened request bodies \
🐛 Fix: Fix handling of single member unions \
🐛 Fix: Allow model\_ prefixes on model fields \
🐛 Fix: Handle renamed object fields using `x-speakeasy-name-override` \
🐛 Fix: Added support for string unions

### Terraform

🐝 Feat: Plan modifiers created automatically from OpenAPI attributes \
🐝 Feat: Move custom plan modifiers to the same folder as the normal plan modifiers

### C#

🐝 Feat: Improve `NuGet` metadata

### Go

🐝 Feat: Add support for populating globals from env variables


 This is the content for the doc changelog/changelog-2024-08-07/index.mdx 

 ---
title: "Test Suite Generation Early Access"
description: "New features to the Speakeasy Platform - August 7, 2024"
keywords:
  [api, openapi, docs, sdk generation, python, devex, dx, developer experience]
image: "/media/changelog-2024-08-07.png"
date: 2024-08-07
authors:
  - name: Nolan Sullivan
  - image_url: "/media/author-headshots/nolan.jpeg"
featured_image: "/media/changelog-2024-08-07.png"
---

import { CodeWithTabs } from "~/components/codehike/CodeTabs";
import { Callout } from "~/components";
import beezy_ide_video from "./assets/beezy-ide.mp4";
import mintlify_setup from "./assets/mintlify.mp4";

<Callout title="Get Access" variant="success">
  If you are interested in participating in early access, please fill out [this
  form](https://speakeasyapi.typeform.com/testing-early), or, if you're an
  existing customer, drop a note in your Speakeasy Slack connect channel.
</Callout>

If at first you don't succeed test, test, test again.

We're excited to announce the early access release of our new Test Generation feature. It empowers developer teams to ship SDKs with confidence that they work as intended for end users.

## Test Generation

<CodeWithTabs>

```typescript !!tabs analysis.test.js
"use strict";

Object.defineProperty(exports, "__esModule", { value: true });
const index_js_1 = require("../index.js");
const vitest_1 = require("vitest");
(0, vitest_1.test)("Analysis Analyze Text", async () => {
    const beezy = new index_js_1.Beezy({
        security: {
            clientID: process.env("BEEZY_CLIENT_ID"),
            clientSecret: process.env("BEEZY_CLIENT_SECRET"),
        },
    });
    const result = await beezy.analysis.analyzeText({
        text: "What is the difference between OpenAPI and Swagger?",
        analysisTypes: ["keywords"],
        model: "ex-7b",
    });
    (0, vitest_1.expect)(result).toEqual({
        results: [
            {
                keywords: ["<value>"],
            },
        ],
    });
});
```

```python !!tabs test_analysis.py
from beezyai import Beezy
from beezyai.models import shared


def test_analysis_analyze_text():
    s = Beezy(
        security=shared.Security(
            client_id="<YOUR_CLIENT_ID_HERE>",
            client_secret="<YOUR_CLIENT_SECRET_HERE>",
        ),
    )

    assert s is not None

    res = s.analysis.analyze_text(request={
        "text": "What is the difference between OpenAPI and Swagger?",
        "analysis_types": [
            shared.AnalysisTypes.KEYWORDS,
        ],
        "model": shared.Model.EX_7B,
    })

    assert res is not None
    assert res is not None
    assert res == shared.TextAnalysisResponse(
        results=[
            shared.KeywordAnalysis(
                keywords=[
                    "<value>",
                ],
            ),
        ],
    )
```

```go !!tabs analysis_test.go
package tests

import (
	"beezyai"
	"beezyai/models/shared"
	"context"
	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"
	"testing"
)

func TestAnalysis_AnalyzeText(t *testing.T) {
	s := beezyai.New(
		beezyai.WithSecurity(shared.Security{
			ClientID:     "<YOUR_CLIENT_ID_HERE>",
			ClientSecret: "<YOUR_CLIENT_SECRET_HERE>",
		}),
	)
	var text string = "What is the difference between OpenAPI and Swagger?"

	analysisTypes := []shared.AnalysisTypes{
		shared.AnalysisTypesKeywords,
	}

	var model *shared.Model = shared.ModelEx7b.ToPointer()
	ctx := context.Background()
	res, err := s.Analysis.AnalyzeText(ctx, text, analysisTypes, model)
	require.NoError(t, err)
	require.NotNil(t, res)
	assert.Equal(t, shared.TextAnalysisResponse{
		Results: []shared.Results{
			shared.CreateResultsKeywordAnalysis(
				shared.KeywordAnalysis{
					Keywords: []string{
						"<value>",
					},
				},
			),
		},
	}, *res.TextAnalysisResponse)
}

```

</CodeWithTabs>

### What's Included

- Support for TypeScript, Python, and Go,
- Test creation based on the examples in your OpenAPI spec,
- The ability to specify custom requests and responses for your tests.

### How It Works

1. Specify the examples you want to use in your OpenAPI spec.
2. Optionally specify custom examples via a `tests.yaml`.
3. Speakeasy generates tests for your SDKs based on the examples you provided.

The generated tests will be created in a new `tests` directory in your SDK. For each language, we've selected a popular testing framework for the generated tests:

- TypeScript: [Vitest](https://vitest.dev/)
- Python: [Pytest](https://docs.pytest.org/en/stable/)
- Go: [Testify](https://github.com/stretchr/testify) along with Go's built-in testing package

---

## 🐝 New Features and Bug Fixes 🐛

<Callout title="NOTE" variant="info">
  Based on the most recent CLI version: [**Speakeasy
  v1.353.1**](https://github.com/speakeasy-api/openapi-generation/releases/tag/v1.353.1)
</Callout>

### TypeScript

🐝 Feat: Readme's render with environment variable usage \
🐛 Fix: Updated `.gitignore` rules for TS SDKs

### Python

🐝 Feat: Readme's render with environment variable usage \
🐝 Feat: Added Python debug logger interface \
🐛 Fix: Buffering of streaming responses and TypedDict unmarshalling in pythonv2 \
🐛 Fix: Handle `consts` in non-json

### Go

🐝 Feat: Readme's render with environment variable usage

### Terraform

🐛 Fix: Dependencies upgraded \
🐛 Fix: Prevent creating attribute validators for invalid or RE2 engine incompatible OAS pattern \
🐛 Fix: Support for flattened security env vars

### Java

🐝 Feat: Support for discriminated oneOf

### C#

🐝 Feat: Implemented support for `x-speakeasy-enums`


 This is the content for the doc changelog/changelog-2024-09-04/index.mdx 

 ---
title: "Lean TypeScript SDKs for the browser"
description: "New features to the Speakeasy Platform - September 4, 2024"
keywords:
  [api, openapi, docs, sdk generation, python, devex, dx, developer experience]
image: "/media/changelog-2024-08-28.png"
date: 2024-08-28
authors:
  - name: Nolan Sullivan
  - image_url: "/media/author-headshots/nolan.jpeg"
featured_image: "/media/changelog-2024-08-28.png"
---

import { CodeWithTabs } from "~/components/codehike/CodeTabs";
import { Callout } from "~/components";

What's better than an ergonomic, type-safe TypeScript SDK? A **lean**, ergonomic, type-safe TypeScript SDK that's optimized for the browser! We've made some major improvements to our TypeScript generation so that you can better serve your users who are building web applications.

And best of all, no breaking changes are required on your end. Just rerun your TypeScript generation and get the latest and greatest 🎉

## Lean TypeScript SDKs with standalone functions

When SDKs are large, they can bloat the bundle size of your user's app, even if they're only using a small portion of your SDK's functionality. That matters because the smaller the bundle, the faster the app loads, the better the user experience. If your SDK is too large, it may be a non-starter for your users.

To address this, we've introduced a new feature for TypeScript SDKs called **Standalone Functions** to make your SDKs tree-shakable. That will allow your users to import only the functions they need, resulting in a smaller bundle size and a more performant application.

Here's an example of standalone functions in action via [Dub's SDK](https://github.com/dubinc/dub-ts):

<CodeWithTabs>

```typescript !!tabs function_based.ts
import { DubCore } from "dub/core.js";
import { linksCount } from "dub/funcs/linksCount.js";

async function run() {
  const dub = new DubCore();

  const result = await linksCount(dub);
  if (!result.ok) {
    throw result.error;
  }

  // Use the result
  console.log("Link count:", result.value);
}

run();
```

```typescript !!tabs class_based.ts
import { Dub } from "dub";

async function run() {
  const dub = new Dub();

  const count = await dub.links.count();

  console.log("Link count:", count);
}

run();
```

</CodeWithTabs>

The performance benefits are enormous. In a benchmark test using a single function from the Dub SDK, bundle-size reduced from **324.4 kb -> 82.1 kb**. That's a **75% reduction** in bundle size!

If you want the juicy technical details, check out the [full blog post](/post/standalone-functions).

---

## Regenerate Github SDKs from the CLI

![Speakeasy run github](./assets/github-run-cli.png)

You can now remotely generate your SDKs on GitHub directly from your terminal! Just use the `​--github`​ flag with `​speakeasy run​` to kick off a remote generation.

If you haven’t installed the GitHub app yet, don’t worry. Follow the prompts in your workspace to complete the setup. This will ensure the Speakeasy Github app has access to your managed repositories within your organization.

Ready to streamline your workflow? Give it a try!

## 🐝 New features and bug fixes 🐛

<Callout title="NOTE" variant="info">
  Based on the most recent CLI version: [**Speakeasy
  v1.388.0**](https://github.com/speakeasy-api/speakeasy/releases/tag/v1.388.0)
</Callout>

### Generation platform

🐝 Feat: Add Summary and ToC sections to Readme generation

### TypeScript

🐝 Feat: support added for custom compile commands \
🐝 Feat: support for streaming file uploads in test generation \
🐛 Fix: pagination when used alongside error handling

### Python

🐛 Fix: pagination when used alongside error handling \
🐛 Fix: correct implementation of unions of arrays \
🐛 Fix: add errorUnions handling to usage snippets

### Go

🐝 Feat: Support added for streaming uploads

### C#

🐛 Fix: prevent conflicts with `System` namespace

### PHP

🐛 Fix: handle empty global parameters array


 This is the content for the doc changelog/changelog-2024-09-18/index.mdx 

 ---
title: "PHP Beta & SSO for Enterprises"
description: "New features to the Speakeasy Platform - September 18, 2024"
keywords:
  [api, openapi, php, docs, sdk generation, python, devex, dx, developer experience]
image: "/media/changelog-2024-09-18.png"
date: 2024-09-18
authors:
  - name: Nolan Sullivan
  - image_url: "/media/author-headshots/nolan.jpeg"
featured_image: "/media/changelog-2024-09-18.png"
---

import { Callout } from "~/components";
import sso_url from "./assets/sso.png";

[Laravel raised $57M in Series A funding](https://laravel-news.com/laravel-raises-57-million-series-a) 💰 making it clear that PHP is back in a big way. That makes it the perfect time to announce the beta release of our new PHP SDK Generator! We're bringing modern type safety and a streamlined developer experience to PHP SDKs generated on our platform.

And in less splashy (but still important) news, we're launching Single Sign-On (SSO) support on the Speakeasy platform!

Read on for more details.

## Type-Safe PHP Generation is now in Beta

```php
declare(strict_types=1);

require 'vendor/autoload.php';

use Dub;
use Dub\Models\Components;
use Dub\Models\Operations;

$security = new Components\Security(
    token: "DUB_API_KEY",
);

$sdk = Dub\Dub::builder()->setSecurity($security)->build();

try {
    $request = new Operations\CreateLinkRequestBody(
        url: 'https://google.com',
        tagIds: '...',
        externalId: '123456',
    );
    $response = $sdk->links->create($request);

    if ($response->linkSchema !== null) {
        // handle response
    }
} catch (Throwable $e) {
    // handle exception
}
```

Here's a quick rundown of what our new PHP SDK Generator brings to the table:

- **Robust type safety** with carefully typed properties for all models
- **Support for union types**, embracing PHP 8's modern type system
- **Readability**, a streamlined, object-oriented approach for easy debugging
- **Minimal external dependencies** for a lightweight footprint
- **IDE compatibility** for a superior development experience

We can't wait to hear what people think! Please don't hesitate to reach out with feedback and questions.

[Read the release post here](/post/release-php).

---

## SSO for Enterprises

![SSO](./assets/sso.png)

We're excited to announce the launch of Single Sign-On (SSO) support on the Speakeasy platform. Our SSO is compatible with any IDP that uses SAML or OIDC (i.e. Okta).

We're committed to providing robust, enterprise-grade solutions to businesses of every size.

If you're interested in enabling SSO for your organization, please reach out to your account manager for access.

---

## 🐝 New features and bug fixes 🐛

<Callout title="NOTE" variant="info">
  Based on the most recent CLI version: [**Speakeasy
  v1.398.0**](https://github.com/speakeasy-api/speakeasy/releases/tag/v1.398.0)
</Callout>

### Generation platform

🐝 Feat: initialize `git` repository during quickstart

### Python

🐝 Feat: upgrade to Pydantic 2.9 \
🐛 Fix: ensure async client is used for async request building \
🐛 Fix: handle additional properties in models with nullable fields \
🐛 Fix: add usage snippets for `next` pagination func

### Go

🐛 Fix: Handle default streaming responses in go 

### Terraform

🐝 Feat: add `resources` & `data sources` to terraform documentation

### PHP

🐝 Feat: add multi-level tagging support \
🐝 Feat: add nullable support \
🐛 Fix: improve handling of associative arrays contained in unions




 This is the content for the doc changelog/changelog-2024-09-30/index.mdx 

 ---
title: "OpenAPI Studio, Laravel Integration, and 'what in Zod's name?'"
description: "New features to the Speakeasy Platform - September 30, 2024"
keywords:
  [api, openapi, php, docs, sdk generation, python, devex, dx, developer experience]
image: "/media/changelog-2024-09-30.png"
date: 2024-09-30
authors:
  - name: Nolan Sullivan
  - image_url: "/media/author-headshots/nolan.jpeg"
featured_image: "/media/changelog-2024-09-30.png"
---

import { Callout } from "~/components";
import openapi_studio from "./assets/openapi-studio.mp4";

If you like scrolling through `yaml` & `json` documents, ignore this update. If you'd be quite happy to get some help editing your OpenAPI spec, then read on!

And if [last week's PHP announcement](/changelog/2024-09-18) got you excited, then prepare yourself for more good things: Laravel integration support!

## AI-powered spec improvement with OpenAPI Studio

<div className="mt-10">
  <video controls={false} loop={true} autoPlay={true} width="100%">
    <source src={openapi_studio} type="video/mp4" />
  </video>
</div>

Speakeasy's new AI-powered OpenAPI Studio has arrived!

Here's what you can expect:

- **AI-suggested improvements**: Our AI will analyze your OpenAPI document and provide tailored suggestions to enhance it for optimal SDK creation.
- **Local sync**: the OpenAPI Studio stays in perfect sync with changes made to your locally saved spec to maintain a single source of truth.
- **Clean versioning with overlays**: All edits are saved in OpenAPI overlay files, keeping your root OpenAPI spec pristine while allowing for flexible, version-controlled improvements.

This feature is designed to streamline your workflow, ensuring your APIs are always primed for top-notch SDK generation.

## Laravel-compatible packages for every API

```php
use Dub\Dub;
use Illuminate\Contracts\View\View;
use Illuminate\Http\Request;

final readonly class LinksController
{
    public function __construct(
        private Dub $dub,
    ) {}
    
    public function index(Request $request): View
    {
        return view('links.index', [
            'links' => $this->dub->links->list(),
        ]);
    }
}
```

Building on our recent [type-safe PHP generation release](/post/release-php), we're excited to introduce Laravel integration support. Now, when you generate PHP SDKs with Speakeasy, you can opt to create a Laravel-compatible package.

What's included:

- Automatic Service Provider Creation: We'll generate the necessary service provider for your package.
- Configuration File Setup: Get config files tailored for the Laravel ecosystem.
- Laravel Package Structure: Your SDK will be structured as a proper Laravel package, ready for distribution.

It's never been easier to make your API native to the Laravel ecosystem!

## What in Zod's name?

![Zod.fyi screenshot](./assets/zod-fyi.jpeg)

[Zod](https://zod.dev/) powers runtime validation in our TypeScript generation. Depending on the complexity of a Zod schema, the resulting validation error message can contain a wall of JSON text - the serialised issues that were recorded during validation.

We've created a small tool to help better visualize and parse the errors. It's built as a web UI which provides yo with sharable URLs for easy collaboration.

We hope it will help the TypeScript community be able to more easily build with Zod!

Try it out at [zod.fyi](https://zod.fyi)!

---

## 🐝 New features and bug fixes 🐛

<Callout title="NOTE" variant="info">
  Based on the most recent CLI version: [**Speakeasy
  v1.398.0**](https://github.com/speakeasy-api/speakeasy/releases/tag/v1.398.0)
</Callout>

### Generation platform

🐝 Feat: improvements to the error handling readme section \
🐝 Feat: support path, header, and query parameter assertions in mock server \
🐝 Feat: improved snapshot, and performance testing \
🐛 Fix: address missing examples and improve number examples

### Python

🐛 Fix: patched implementation of optional responses \
🐛 Fix: enable const support for Python 3.9.x environments


### TypeScript

🐛 Fix: pagination now works when parameter flattening is enabled

### PHP

🐝 Feat: Laravel integration support \
🐝 Feat: improved PHP usage snippet generation





 This is the content for the doc changelog/changelog-2024-10-16/index.mdx 

 ---
title: "Automate your OAuth flows and streamline publishing"
description: "New features to the Speakeasy Platform - October 16, 2024"
keywords:
  [api, openapi, php, docs, sdk generation, python, devex, dx, developer experience]
image: "/media/changelog-2024-10-16.png"
date: 2024-10-16
authors:
  - name: Nolan Sullivan
  - image_url: "/media/author-headshots/nolan.jpeg"
featured_image: "/media/changelog-2024-10-16.png"
---

import { Callout } from "~/components";

This week, we're excited to announce two major improvements to the Speakeasy platform: enhanced OAuth support and a more flexible publishing workflow. These updates are designed to make your API integration process smoother and more efficient than ever before.

## OAuth Authorization Flow Support with Custom Security Schemes

```typescript
import { SDK } from "SDK";

const sdk = new SDK();

async function run() {
  const result = await sdk.oAuth2.getToken({
    Id: process.env["SDK_ID"] ?? "",
    Secret: process.env["SDK_SECRET"] ?? "",
  }, {
    grantType: "authorization_code",
    code: "1234567890",
    redirectUri: "https://example.com/oauth/callback",
  });

  // Handle the result
  console.log(result);
}

run();
```

We've introduced robust support for OAuth authorization flows using custom security schemes. This new feature allows for greater flexibility in implementing various OAuth flows, particularly the Authorization Code flow.

Key improvements include:

- Custom Security Schemes: Define your own security scheme to match your specific OAuth implementation.
- Flexible Secret Handling: Support for various formats of client ID and secret combinations.
- Pre-Request Hooks: Customize request headers and parameters before they're sent to the server.

This enhancement makes it easier than ever to integrate OAuth-protected APIs into your projects, with the SDK handling the complexities of token exchanges and header generation.

---

## Streamlined Publishing Workflow

![Manually trigger publishing](./assets/publishing.png)

We've completely revamped our publishing workflow to give you more control and flexibility. Now, you can publish your SDK without being tied to GitHub-specific generation processes.

Here's what's new:

- **Decoupled from GitHub Actions**: Publish directly from your branch, regardless of where the last generation occurred (local, GitHub, etc.).
- **Simplified First-Time Publishing**: Follow a straightforward process: `quickstart` → configure GitHub → push to repo → kick off publishing.
- No-Op for Existing Versions: If you attempt to publish a version that's already been released, the system will automatically skip the process, preventing accidental overwrites.

This update eliminates the need to regenerate in GitHub Actions or worry about forcing changes. It's now easier than ever to get your SDK published and into the hands of your users.

---

## 🐝 New features and bug fixes 🐛

<Callout title="NOTE" variant="info">
  Based on the most recent CLI version: [**Speakeasy
  v1.418.4**](https://github.com/speakeasy-api/speakeasy/releases/tag/v1.418.4)
</Callout>

### TypeScript

🐛 Fix: error handling in SSE methods \
🐛 Fix: support for gracefully aborting SSE streams

### Python

🐝 Feat: export `__title__`, `__version__` and `VERSION` values from the root of a python package \
🐛 Fix: error handling in SSE methods \
🐛 Fix: support for gracefully aborting SSE streams \
🐛 Fix: address pydantic `union_tag_invalid` errors on Python 3.11 and later 

### Go

🐛 Fix: ensure response body is closed after reading \
🐛 Fix: ensure OAuth2 client credentials hook logic is valid for multiple security schemes

### Java

🐛 Fix: support union of arrays (account for erasure)

### PHP

🐝 Feat: PHP Complex Number support (bigint and decimal) \
🐝 Feat: const and default support added


 This is the content for the doc changelog/changelog-2024-10-30/index.md 

 ---
title: "Our Series A fundraise"
description: "Same mission, new resources."
keywords:
  [api, openapi, php, docs, sdk generation, python, devex, dx, developer experience]
image: "/media/announcement-series-a.png"
date: 2024-10-30
authors:
  - name: Nolan Sullivan
  - image_url: "/media/author-headshots/nolan.jpeg"
featured_image: "/media/announcement-series-a.png"
---

import { Callout } from "~/components";

No Changelog this week. Just a big thank you to our customers, partners, and team for helping us reach this milestone. We're excited to continue building the future of developer experience with you all.

[**Read more about our latest funding 🚀**](/post/fundraising-series-a)

 This is the content for the doc changelog/changelog-2024-11-13/index.mdx 

 ---
title: "Label-Based Versioning, OpenAPI Transformations, and Overlay Insights"
description: "New features to the Speakeasy Platform - November 13, 2024"
keywords: [api, openapi, versioning, github, developer experience, devex, dx]
image: "/media/changelog-2024-11-13.png"
date: 2024-11-13
authors:
  - name: Nolan Sullivan
  - image_url: "/media/author-headshots/nolan.jpeg"
featured_image: "/media/changelog-2024-11-13.png"
---

import { Callout } from "~/components";

Ever wished managing SDK versions was as simple as adding a label? Or wanted your OpenAPI transformations to just work™️ every time you regenerate? We've got you covered with some powerful new features that will make iterating on your SDK a breeze.

## GitHub-Native Version Management

import label_versioning from "./assets/label-versioning.mp4";

<div className="mt-10">
  <video controls={false} loop={true} autoPlay={true} width="100%">
    <source src={label_versioning} type="video/mp4" />
  </video>
</div>

Managing SDK versions should be as natural as any other GitHub workflow. Now it is! With label-based versioning, you can control your SDK's version bumps right from your pull request:

- **Automated Version Detection**: By default, we'll analyze your changes and suggest the appropriate semantic version bump. You'll see our suggested version label on your generated PR.
- **Manual Override**: Want to override our suggestion? Just remove the current label and add a `major`, `minor`, or `patch` label to your PR.
- **Persistent Preferences**: Your chosen version bump persists across regenerations until you change it.
- **Pre-release Support**: Planning a beta release? When you are ready to move off your pre-release, simply add the label `graduate`.

This feature is automatically active in all SDK generation workflows today. If you would also like generation to kick off immediately after adding a label, just add the following to your GitHub workflow file:

```yaml
# !focus(7,21:22)
name: Generate
permissions:
    checks: write
    contents: write
    pull-requests: write
    statuses: write
"on":
    workflow_dispatch:
        inputs:
            force:
                description: Force generation of SDKs
                type: boolean
                default: false
            push_code_samples_only:
                description: Force push only code samples from SDK generation
                type: boolean
                default: false
            set_version:
                description: optionally set a specific SDK version
                type: string
    pull_request:
        types: [labeled]
    schedule:
        - cron: 0 0 * * *
```

## OpenAPI Transformations

```yaml workflow.yaml
# !focus(7:12)
workflowVersion: 1.0.0
speakeasyVersion: latest
sources:
  my-source:
    inputs:
      - location: ./openapi.yaml
    transformations:
      - removeUnused: true
      - filterOperations:
          operations: getPets, createPet
          include: true # exclude: true
      - cleanup: true
```

OpenAPI transformations are now a first-class citizen in your generation workflow. Instead of manually running transforms or building custom pipelines, transformations are automatically applied every time your SDK is generated.

Available transforms:
- **`filterOperations`**: Include or exclude specific operations from your SDK
- **`removeUnused`**: Automatically clean up unused schemas and components
- **`cleanup`**: Fix and standardize your OpenAPI spec's formatting

The best part? Transformations adapt to your spec changes. For example, if you're filtering to include specific operations, newly added operations matching your filter will automatically flow through to your SDK.

## Overlay Summaries

import overlay_output from "./assets/overlay-output.mp4";

<div className="mt-10">
  <video controls={false} loop={true} autoPlay={true} width="100%">
    <source src={overlay_output} type="video/mp4" />
  </video>
</div>

When applying OpenAPI overlays, it's crucial to understand exactly how they're modifying your spec. Our new overlay summaries provide clear, actionable insights into the changes.

These summaries help you:
- Quickly validate your overlay changes,
- Understand the impact on your API spec,
- Debug overlay application issues.

---

## 🐝 New features and bug fixes 🐛

<Callout title="NOTE" variant="info">
  Based on the most recent CLI version: [**Speakeasy v1.404.0**](https://github.com/speakeasy-api/speakeasy/releases/tag/v1.404.0)
</Callout>

### Generation platform

🐝 Feat: improved markdown tables in `README.md` \
🐝 Feat: `defaultErrorName` config param added to enable custom naming of unhandled API error class \
🐛 Fix: improved handling of complex allOf schemas that merge multiple types \
🐛 Fix: remove duplication of error types \
🐝 Feat: warn users about optional request bodies

### PHP

🐝 Feat: replace JMS serializer with custom serializer for better union support \
🐝 Feat: handle multiple servers \
🐛 Fix: ensure PHP compile dependency version matches composer

### Terraform

🐝 Feat: added `default` object support \
🐝 Feat: new `x-speakeasy-terraform-alias-to` extension for mapping to specific values in an array \
🐝 Feat: support default empty array in terraform \
🐛 Fix: prevent compilation errors caused by missing response schemas

### Java

🐝 Feat: support added for `additionalProperties`

### Python

🐛 Fix: Prevent compilation errors on macOS, and if the source code directory changes 

### TypeScript

🐝 Feat: allow hooks to trigger retries in TS SDKs


 This is the content for the doc changelog/changelog-2024-12-06/index.mdx 

 ---
title: "Launch week 0 round up: webhooks, react query support & more!"
description: "5 days, 5 new features - December 06, 2024"
keywords: [api, openapi, react hooks, webhooks, php, contract testing, sdks, developer experience, devex, dx]
image: "/media/changelog-2024-12-06.png"
date: 2024-12-06
authors:
  - name: Nolan Sullivan
  - image_url: "/media/author-headshots/nolan.jpeg"
featured_image: "/media/changelog-2024-12-06.png"
---

import { Callout } from "~/components";

Last week we took a break from our normal changelog schedule. We instead joined Supabase and other outstanding dev tool companies for [​Mega Launch Week​](https://launchweek.dev/lw/2024/MEGA) ⚡ Over the course of 5 days, we launched ​5​ ​new products ​/features for you to get your hands on.

The launch week page can be found [here](/launch-week). Below is the summary for those of you who weren't following along live. If you're interested in any of the features, send us a slack message and we can help you get set up!

## Day 1 ​- API contract testing

![API contract testing](./assets/day1-testing.png)

We’re fully automating API testing. Use the Speakeasy platform to generate comprehensive test suites using your favorite testing framework (Vitest, pytest, etc.) with AI-generated test data to cover every test case.

[Read the release →](/post/release-contract-testing)

## Day 2 - SDK generation with webhooks support

![SDK generation with webhooks support](./assets/day2-webhooks.png)

We've added webhook support to our SDK generation platform. The new feature provides type-safe webhook handlers and built-in security verification, all powered by native OpenAPI support.


[Read the release →](/post/release-webhooks-support)

## Day 3 - Speakeasy API docs

![Speakeasy docs powered by Scalar](./assets/day3-scalar.png)

Scalar's best-in-class documentation platform is now seamlessly integrated into the Speakeasy platform. Generate beautiful, branded documentation that stay in-sync with your SDKs.

[Read the release →](/post/release-speakeasy-docs)

## Day 4 - Enhanced PHP generation

![Enhanced PHP generation](./assets/day4-php.png)

We're delivering a whole batch of new features for PHP generation. In addition to Laravel service provider creation, we've added support for pagination, Oauth 2.0 and hooks for custom code.

[Read the release →](/post/release-php)

## Day 5 - React query hook generation

![React query hook generation](./assets/day5-react.png)

We've added React hooks to our TypeScript SDK generation platform. The new feature provides type-safe hooks for all your API operations, powered by Tanstack Query.

[Read the release →](/post/release-react-hooks)

---

You'll be hearing more about these new features in coming changelogs, so stay tuned!


 This is the content for the doc changelog/changelog-2024-12-31/index.mdx 

 ---
title: "Last changelog of the year, looking ahead, and a thank you!"
description: "Last changelog of the year, what's coming up, and a thank you! - December 30, 2024"
keywords: [api, openapi, react hooks, webhooks, php, contract testing, sdks, developer experience, devex, dx]
image: "/media/changelog-2024-12-31.png"
date: 2024-12-31
authors:
  - name: Sagar Batchu
  - image_url: "/media/author-headshots/sagar.jpeg"
featured_image: "/media/changelog-2024-12-31.png"
---

import { Callout } from "~/components";

## 2024, a year in review 📅

As we wrap up 2024, I wanted to take a moment to reflect on the year. It's been a year of growth, learning and building. We've launched some exciting new features, 
expanded our team and continued to push the boundaries of what's possible with code generation.

Here are some of the highlights from 2024:

- We continued the march towards our vision of "generating handwritten SDKs" for REST APIs. Our TypeScript generation led the charge adding [functional support](/post/standalone-functions), [react hooks](/release-react-hooks) and [webhooks](/post/release-webhooks-support). Other languages followed with [PHP adding support for Laravel](/post/release-php) and Python with [async functions and Pydantic2.0 type-safety](/post/release-python-v2-alpha).
- We launched our [API contract testing](/post/release-contract-testing/) feature to help you automate your API testing leveraging the completeness of SDKs.
- We brought on several new team members across engineering, support and GTM. This team is on 🔥.
- We raised a [Series A](/post/fundraising-series-a/) to fuel our growth and expand our product offerings!

## 2025, what's coming up? 🚀

As I look ahead to 2025 the API landscape is rapidly evolving for consumers with AI agents and LLMs changing how we manage and execute API calls. I'm absolutely thrilled for 
what we're cooking behind the scenes. Here's a sneak peek at what's coming up in 2025:

- An exciting new way to design your SDKs ! 🎨
- Expanding on [our initial foray into API testing]() with more Arazzo support, multi endpoint testing and a new testing experience. 
- Support for more non-HTTP protocols: webhooks, events and internal API landscapes
- Make it really easy for LLMs to discover and connect with your APIs. All your AI tools, generated.
- Leverage the power of executable code samples through prompts. No more 3 pane doc sites.

Simply put, the job's not finished ! 🚧

![The job's not finished](./assets/jobs_not_finished.gif)

## A Thank You ! 🎉

Finally we'd love to thank you all for making this year a success. We're excited to continue building the future of APIs in 2025. We're so grateful for your continued support. 🙏 

A few special shoutouts:

### To our Customers

Thank you for your invaluable feedback and for trusting us with your API needs. You help us push the bar everyday!

### To our Team

Thank you for your hard work and dedication. I'm grateful to be surrounded a very talented group of folks who are relentless. This team cooks!

### To our Partners

Thank you for your collaboration and support.

- Colin McDonnell for continuing to push Zod forward. We're lucky to build on the shoulders of giants.
- The team at Vercel for driving us towards functional and performance-optimized SDKs.
- The Pydantic team for prioritizing fixes and improvements in Pydantic2.0.
- Marc and Scalar Team for iterating with us as product partner. Scalar Docs + Speakeasy SDKs is a game changer! 
- Our amazing blog contributors: The team at Ritza, Phil Sturgeon, Steve McDougall and many more.
- Paul, Flo and the folks at Supabase for bringing some of the best dev tools together for Mega Launch Week.

### To our Investors

Thank you for backing us and supporting our vision 🚀 

## 🐝 New features and bug fixes 🐛

<Callout title="NOTE" variant="info">
  Based on the most recent CLI version: [**v1.460.3**](https://github.com/speakeasy-api/speakeasy/releases/tag/v1.460.3)
</Callout>

### Generation platform

🐝 feat: added a new `normalise` transform to available OpenAPI `transforms` \
🐛 fix: improved handling of complex allOf schemas that merge multiple types \
🐛 fix: validate custom linting rulesets before execution

## API testing

🐝 feat: Mock API server automatically generated with test generation \
🐛 fix: improvement to result variable names in tests \
🐝 feat: add simple support for multiple operations in contract tests

## TypeScript

🐛 fix extraneous HTTP Authorization header in TypeScript \
🐝 feat: support for custom webhook security in TS \
🐛 fix: flattening with hidden parameters and allow server urls to allows be overridable per-method \
🐛 fix: improve typescriptv2 readme errors \
🐛 fix: make React hooks peer dependencies optional

## PHP

🐝 feat: support for retries in PHP \
🐝 feat: support sdk hooks for custom code


## Java

🐝 feat: open enum support \

 ## Ruby

🐛 fix: ruby rubocop linting issues \

 ## Python
 
🐛 fix: flattening with hidden parameters and allow server urls to allows be overridable per-method \
🐝 feat: support for injecting headers \
🐛 fix: python usage snippet imports and handle property names made up of illegal characters only \
🐛 fix: avoid unnecessary content-type header in empty python requests 

 ## Golang

🐛 fix: flattening with hidden parameters and allow server urls to allows be overridable per-method \
🐛 fix: Support go target oneOf types in deepObject style query parameters \
🐝 feat: support for injecting headers 

 ## Terraform

🐛 fix: bugs with missing terraform types \
🐛 fix: make useragent better in terraform \
🐝 feat: add option for disabling deduplication of types

 This is the content for the doc changelog/changelog-2025-01-15/index.mdx 

 ---
title: "Custom code regions & an Overlay playground!"
description: "The Speakeasy generator just got more flexible, and writing overlays just got even easier"
keywords:
  [api, openapi, sdk generation]
image: "/media/changelog-2025-01-15.png"
date: 2025-01-15
authors:
  - name: Emre Tezisci
  - image_url: "/media/author-headshots/emre.jpeg"
featured_image: "/media/changelog-2025-01-15.png"
---

import { Callout } from "~/components";

🎉 Welcome to our first changelog of 2025! This update focuses on customization, introducing powerful tools like Custom Code Regions for direct SDK enhancements and the Overlay Playground, a new open-source tool for modular spec-level changes. These features, combined with other improvements and fixes, make tailoring your SDKs and OpenAPI workflows easier than ever. Let’s explore what’s new!

## Custom Code Regions
```typescript codeRegions.ts
import { ClientSDK } from "./lib/sdks.js";
// !mark gold
// #region imports
import chalk from 'chalk';
// !mark gold 
// #endregion imports

class Acme extends ClientSDK {
  // ... generated code ...
  // !mark gold
  // #region sdk-class-body
  greet(name: string): string {
    return chalk.green(`Hello, ${name}!`);
  }
  // !mark gold
  // #endregion sdk-class-body
}
```

**Custom Code Regions** give you the flexibility to embed custom logic directly into your SDK without modifying the OpenAPI spec. Using foldable regions in your codebase, you can add anything from helper methods to third-party integrations. Your customizations persist across regenerations, keeping your work intact and formatted.

✨ **Why choose Custom Code Regions?**  
- **Direct control**: Insert your logic directly into the SDK.  
- **Seamless updates**: Custom code remains untouched during regenerations.  
- **Ultimate flexibility**: From logging to integrations, you can do anything.

### **How Does Everything Fit Together?**  

With **Custom Code Regions**, **Hooks**, and **Overlays**, Speakeasy offers three distinct ways to customize your SDKs:  

| **Customization Tool**    | **Purpose**                                                                 | **Key Use Case**                                         |
|----------------------------|-----------------------------------------------------------------------------|---------------------------------------------------------|
| **Overlays**               | Modify the OpenAPI spec for structural or schema-related changes.           | Adding paths, tweaking parameters, or updating models.  |
| **Hooks**                  | Intercept and modify SDK generation programmatically during the build.      | Dynamic updates, injecting logic at specific stages.    |
| **Custom Code Regions**    | Insert custom logic directly into the generated SDK code at runtime.        | Adding helper methods, third-party integrations, or SDK-specific tweaks. |

Each tool offers unique capabilities, and together, they provide unparalleled flexibility for tailoring your SDKs to your needs.  

> 📖 Learn more in our release post:  
> 🔗 [Custom Code Regions: Ultimate SDK Customization](/post/release-custom-code-regions)  

> 📚 Dive into the documentation:  
> 🔗 [Custom Code Regions Documentation](/docs/customize/code/code-regions/overview)

---

## Overlay Playground  

The [**Overlay Playground**](https://overlay.speakeasy.com) is an open-source tool for managing OpenAPI overlays in a more user-friendly way. Instead of dealing with raw YAML or JSON, you can create, edit, and validate overlays through a visual interface with real-time previews. Once you’re done, export your overlays and integrate them into your workflows or CI/CD pipeline. Whether you work solo or with a team, the Playground can reduce the complexity of overlay management.

import overlay_playground from "./assets/overlay-playground.mp4";

<div className="mt-10">
  <video controls={false} loop={true} autoPlay={true} width="100%">
    <source src={overlay_playground} type="video/mp4" />
  </video>
</div>

#### **Key Features**  

- **Interactive Editor**: A visual editor for overlays with real-time updates.  
- **Validation**: Ensures overlays conform to OpenAPI standards.  
- **Export and Share**: Save overlays as reusable `.overlay.yaml` files.  
- **Open Source**: Fully extensible and open for contributions at [github.com/speakeasy-api/jsonpath](https://github.com/speakeasy-api/jsonpath).

Start customizing your OpenAPI specs today with the Overlay Playground at [overlay.speakeasy.com](https://overlay.speakeasy.com). 🌟  

---

## 🐝 New Features and Bug Fixes 🐛

<Callout title="NOTE" variant="info">
  Based on the most recent CLI version: [**Speakeasy v1.493.8**](https://github.com/speakeasy-api/openapi-generation/releases/tag/v2.493.8)
</Callout>

### Generation Platform  

🐝 Feat: enabled feature flag-based licensing  
🐝 Feat: defaulted to API key authentication when a security scheme is missing  
🐛 Fix: resolved test generation issues and improved enum handling  

### Python  

🐝 Feat: upgraded to Poetry 2.0 for modern dependency management  
🐝 Feat: bumped minimum Python version to 3.9  
🐝 Feat: exposed SDK versioning data as constants  
🐛 Fix: added missing imports for per-operation servers  
🐛 Fix: updated Mypy for Python 3.13 compatibility  

### TypeScript  

🐝 Feat: added support for asymmetric webhook signatures  
🐛 Fix: improved webhook security parsing  

### Go  

🐛 Fix: standardized deprecated comments for linter compatibility  

### Java


🐝 Feat: added support for JUnit test report generation  
### Ruby  

🐝 Feat: updated bundler for Ruby 3.4 support  


 This is the content for the doc changelog/changelog-2025-01-30/index.mdx 

 ---
title: "Automated Code Samples & Overlay Management in Speakeasy Studio!"
description: "Streamline your API workflows with automated Code Sample URLs and simplified overlay management in Speakeasy Studio."
keywords:
  [api, openapi, sdk generation, overlay, codeSamples]
image: "/media/changelog-2025-01-30.png"
date: 2025-01-30
authors:
  - name: Emre Tezisci
  - image_url: "/media/author-headshots/emre.jpeg"
featured_image: "/media/changelog-2025-01-30.png"
---

import { Callout } from "~/components";

Speakeasy is introducing two powerful updates to enhance your API workflows:

✨ **Automated Code Sample URLs** 
<br />We now provide you with a single, stable URL that automatically displays up-to-date SDK code examples. Simply paste this URL into your documentation platform once, and we'll ensure your code samples stay synchronized with your latest API changes.

🔄 **Overlay Management in Speakeasy Studio** 
<br />You can now edit your OpenAPI specifications directly within Speakeasy Studio, with every change automatically preserved as an overlay. This means you can freely modify your specs in a familiar environment while keeping your source files unchanged.


## Automated Code Sample URLs

Automated Code Sample URLs give you a stable, auto-updating link for SDK code samples. All you have to do is drop that link into your docs platform, and your code examples will stay in sync with your API. Behind the scenes, we dynamically generate SDK-specific code snippets using the x-codeSamples extension in your OpenAPI spec, ensuring your documentation always shows the latest, most accurate examples for your developers.

#### What’s New?

- **Automated SDK Code Samples:** Generate and apply SDK usage examples to your OpenAPI specs effortlessly.
- **Seamless Integration:** Supported by popular documentation platforms, including Scalar, Bump.sh, Mintlify, Redocly and ReadMe.
- **Always Up-to-Date:** Automatically syncs with your latest SDK updates, ensuring accurate and consistent code snippets.

#### How It Works

Speakeasy tracks your base OpenAPI document and overlays containing SDK code samples. When you generate an SDK via GitHub Actions and merge the changes to the main branch, Speakeasy automatically creates a Combined Spec that includes all OpenAPI operations along with the generated `x-codeSamples` extensions. These overlays ensure your API documentation includes accurate, language-specific examples tailored to each operation ID.

📖 [Learn more about Automated Code Sample URLs](/docs/automated-code-sample-urls)

---

## Overlay Management in Speakeasy Studio

We've made managing OpenAPI specs in Speakeasy Studio simpler and more intuitive. Now you can edit your API specs directly in the Studio, and your changes are automatically saved as overlays—no manual overlay creation needed. This means you can modify your specs without affecting the source, all while staying in the Studio. 

Here's a quick look at how it works:

import code_sample_urls from "./assets/code-sample-urls.mp4";

<div className="mt-10">
  <video controls={false} loop={true} autoPlay={true} width="100%">
    <source src={code_sample_urls} type="video/mp4" />
  </video>
</div>

### Why This Matters

- **Edit without worry:** Make changes directly to your specs and they're automatically saved as overlays
- **Stay focused:** Manage all your API modifications in one place
- **Learn overlays:** Get greater visibility into overlay functionality while making edits.
- **Automatic SDK regeneration:** SDKs are regenerated with each save, ensuring your changes are always reflected.

📖 [Learn More about Overlays](/docs/prep-openapi/overlays/create-overlays)

---

## 🐝 New Features and Bug Fixes 🐛

### Platform
- 🐝 Feat: Introduced Automated Code Sample URLs for simplified SDK example management.
- 🐝 Feat: Added overlay management to the Speakeasy Studio.
- 🐛 Fix: Resolved issues with outdated examples, missing imports, and incorrect status code handling in test and example generation.
- 🐛 Fix: Fixed generation of `example.file` during usage snippet generation.

### Go
- 🐛 Fix: Improved mockserver robustness and union usage templating.

### TypeScript
- 🐛 Fix: Corrected parameter and global matching for `x-speakeasy-globals`.
- 🐛 Fix: Ensured dual-module npm packages include correct metadata.

### Python
- 🐛 Fix: Unpinned Python dependencies to prevent conflicts with newer versions.
- 🐛 Fix: Added finalizers to close HTTP clients and prevent memory leaks.

### Terraform
- 🐝 Feat: Added support for mapping operations to data sources or resources.
- 🐝 Feat: Initial support for `x-speakeasy-soft-delete-property`.

### PHP
- 🐝 Feat: Enabled unions of arrays and circular unions.
- 🐛 Fix: Fixed PHP pagination imports and improved consistency in templating.

 This is the content for the doc changelog/changelog-21/index.mdx 

 ---
title: "Changelog #21: A MonoRepo For Your SDKs"
description: "Changes to the Speakeasy platform - March 07, 2023."
keywords:
  [api, openapi, swagger, sdk generation, devex, dx, developer experience]
image: "/media/changelog21.png"
date: 2023-03-07
authors:
  - name: Nolan Sullivan
  - image_url: "/media/author-headshots/nolan.jpeg"
featured_image: "/media/changelog21.png"
---

We’re living in the age of the monorepo. And SDKs are no different.

The SDK monorepo sturcture was popularized by Amazon, but it’s become an increasingly common pattern for companies that are offering multiple APIs. The main benefit of providing SDKs in a monorepo is that it can help users with service discovery, with the downside that the SDKs are much larger in size.

Ultimately it’s a choice of personal preference. But whether you want your SDKs to adhere to the more traditional “repo per API” or you decide to adopt the monorepo, Speakeasy can create SDKs that your users will love, in the structure you prefer.

## New Features

**Support for MonoRepo Structure:** Centralize your APIs’ SDKs in one repository to make service discovery easy for your users. Although services are grouped together, individual API updates and publishing can still be managed granularly, so your team maintains the same shipping velocity.

See an example of a monorepo below:

import portal_url_1 from "./monorepo.mp4";

<video
  controls={false}
  loop={true}
  autoPlay={true}
  muted={true}
  width="100%"
  alt="Example of a monorepo SDK in github"
>
  <source src={portal_url_1} type="video/mp4" />
</video>

**Manage API Keys Without a Gateway**: Our self-serve API key solution is built to easily plug into any major gateway provider and help you externalize your API key management. However, a gateway doesn’t always make sense for company that’s just starting their API journey.

## Improvements

**Improved Usage Snippets**: People are going to copy/paste example code, so we’ve made sure the generated examples in Readme’s are accurate and compilable.


 This is the content for the doc changelog/changelog-22/index.md 

 ---
title: "Changelog #22: Improved DevEX with Flattened SDKs"
description: "Changes to the Speakeasy platform - March 14, 2023."
keywords:
  [api, openapi, swagger, sdk generation, devex, dx, developer experience]
image: "/media/changelog22.png"
date: 2023-03-14
authors:
  - name: Nolan Sullivan
  - image_url: "/media/author-headshots/nolan.jpeg"
featured_image: "/media/changelog22.png"
---

Despite what some NBA players may believe, the world is not flat. But Speakeasy-created SDKs now are!

As the user of an API, you don’t want to have to understand the technical detail of the API you are using. You just want to understand what input is expected, and what output I should expect in return. Everything else is a distraction.

We're raising the bar for API developer experience, and ensuring the SDKs produced by Speakeasy are as easy to use as possible. That’s why we’re excited to release a new flattened structure to our SDKs.

## New Features

**Flattened SDKs:** Users no longer need to understand whether the inputs to your API are query params, path params, headers, or request bodies. The SDK abstracts away all those details. Users just need to provide the relevant data as key-value pairs -- the SDK will construct the correct call to the API.

That means less code that your users need to write, more easily understood interfaces, faster integration times, and an overall improved developer experience.

You don’t need to do anything to generate with the new SDK structure. If you’ve set up an automated pipeline, it will run with flattened requests as the new default. If you’re using the CLI, then simply upgrade to the latest version.

Here's an example of before and after the new flattened structure, using the Speakeasy API (SDK) for adding a user to a workspace.

**Old:**

```python
import speakeasy
from speakeasy.models import operations, shared

s = speakeasy.SDK()
s.config_security(
    security=shared.Security(
        api_key_authentication=shared.SchemeAPIKeyAuthentication(
            api_key="YOUR_API_KEY_HERE",
        )
    )
)
req = operations.AddUserToWorkspaceRequest(
    path_params=operations.AddUserToWorkspacePathParams(
        project_id=548814,
    ),
    request=shared.AddUserToWorkspaceRequest(
        user="nolan",
    )
)
res = s.workspace.add_user_to_workspace(req)
if res.generic_api_response is not None:
    # handle response
```

**New**:

```python
import speakeasy
from speakeasy.models import operations, shared

s = speakeasy.SDK(api_key="YOUR_API_KEY_HERE")
req = operations.AddUserToWorkspaceRequest(
    project_id=548814,
    add_user_to_workspace_request=shared.AddUserToWorkspaceRequest(
        user="nolan",
    ),
)
res = s.workspace.add_user_to_workspace(req)
if res.generic_api_response is not None:
    # handle response
```


 This is the content for the doc changelog/changelog-26/index.md 

 ---
title: "Changelog #26: A Copilot for your API spec and Pagination"
description: "New features to the Speakeasy Platform - May 31st, 2023."
keywords:
  [api, openapi, swagger, sdk generation, devex, dx, developer experience]
image: "/media/changelog26.png"
date: 2023-05-31
authors:
  - name: Nolan Sullivan
  - image_url: "/media/author-headshots/nolan.jpeg"
featured_image: "/media/changelog26.png"
---

May has been the most heads down month till date ! All of us at Speakeasy have been busy onboarding customers and gearing up for a few exciting announcements coming up (stay tuned 🚀!). To that end we’ve got some exciting feature releases from this month all in the theme making maintenance and usage of your complex API simpler than ever.

On an unrelated note, Speakeasy is growing rapidly and if you'd like to learn more about our engineering, marketing and sales roles please feel free to email back or check out our jobs page!

## New Features

LLM powered spec maintenance:: Go further with speakeasy validations with suggestions that suggest actionable changes to your API spec powered by ChatGPT.

Maintaining an API spec is hard work and error prone. As APIs and the organizations they support get larger your API spec becomes an important artifact that

deserves its own maintenance workflow. Our goal is to ease that burden with a simple speakeasy suggest command. Our LLM powered API will

suggest changes to your spec in service of making your API better documented and having more ergonomic SDKs. Soon to be available through our

Github pull request workflow - one click merge changes around the corner!

![gif of a speakeasy suggest command](https://storage.googleapis.com/speakeasy-design-assets/emails/changelog26/ezgif-1-263696a906.gif)

## Auto Pagination

Speakeasy Managed SDKs now support the ability to generate SDKs that have your pagination rules built-in.

Adding pagination into your SDK can reduce the burden on your users by removing the need to manually manage multiple pages of responses.

If your API is paginated we will provide an iterable object that users can use to loop over. For end users this means an experience that resembles:

```python
response = sdk.paginatedEndpoint(page=1)
while response is not None:
    # handle response

    response = response.next()
```

Our SDKs, starting with python, go and typescript come with support for `cursor` and `offsetLimit` pagination.

This is enabled per-operation using the `x-speakeasy-pagination` extension. Getting pagination added to your SDK is as easy as adding a configurable extension to your spec.

```yaml
x-speakeasy-pagination:
  type: offsetLimit
  inputs:
    - name: page
      in: parameters
      type: page
  outputs:
    results: $.resultArray
```

More on that [here](/docs/customize-sdks/pagination/) !

## Improvements and Bug Fixes

- Managed SDKs:
  - All languages: Support for deprecations. Get strike through IDE hints for deprecated operations
  - Terraform: Support for byte arrays and additional properties
- Speakeasy CLI
  - Now supports an interactive mode !
  - Support for chocolatey package manager for windows


 This is the content for the doc changelog/changelog-3/index.mdx 

 ---
title: "Changelog #3: React Embeds"
description: "Changes to the Speakeasy platform - August 30, 2022."
keywords:
  [
    api,
    devex,
    dx,
    developer experience,
    react embed,
    react,
    typescript,
    big query openapi,
    sdk,
  ]
image: "/media/changelog3.png"
date: 2022-08-30
authors:
  - name: Nolan Sullivan
  - image_url: "/media/author-headshots/nolan.jpeg"
featured_image: "/media/changelog3.png"
---

### New Features

- **React Embeds** - The Speakeasy platform web app is always there if you need it, but if you already have a homegrown platform, you can alternately [add us in as a React embed](/docs/introduction/introduction). Check out the below demo of Alexa, from our engineering team, adding Speakeasy embeds into a web app

import portal_url_1 from "./changelog-august-30-2022-image-01.mp4";

{" "}

<video
  controls={false}
  loop={true}
  autoPlay={true}
  muted={true}
  width="100%"
  alt="Embed request viewer in web app"
>
  <source src={portal_url_1} type="video/mp4" />
</video>

(plus [bonus footage](https://www.loom.com/share/ce17b0e28c3746b0aaf704460fdf34a8) of Alexa setting up filtering for the embeds)

### Smaller Changes

- **\[Typescript\] Mask sensitive data** - Customers using the typescript SDK can now prevent sensitive fields from entering the platform. [See our docs for how to set up field masking](/docs/introduction/introduction).
- **\[Self Hosting\] Support for BigQuery storage** - Store API logs in your data warehouse. User’s self-hosting Speakeasy on GCP can now store requests in BigQuery.


 This is the content for the doc changelog/changelog-4/index.mdx 

 ---
title: "Changelog #4: Replay Requests"
description: "Changes to the Speakeasy platform - September 6, 2022."
keywords:
  [
    api,
    openapi,
    swagger,
    ambassador,
    emissary ingress,
    self-host,
    devex,
    dx,
    developer experience,
    sdk,
  ]
image: "/media/changelog4.png"
date: 2022-09-06
authors:
  - name: Nolan Sullivan
  - image_url: "/media/author-headshots/nolan.jpeg"
featured_image: "/media/changelog4.png"
---

## New Features

- **Request Replay** - It can be difficult to reproduce API issues that users are seeing in production: there’s so many variables that need to be accounted for. Now you can use the request viewer to find and replay the exact request you need. All the headers and request objects are editable so that you can make sure you have a high fidelity replica to test with.

[Speakeasy Request Replays - Watch Video](https://www.loom.com/share/07b41e6d6f5b406a8853947d77487cc1)

import portal_url_1 from "./changelog-september-6-2022-image-01.mp4";

{" "}

<video
  controls={false}
  loop={true}
  autoPlay={true}
  muted={true}
  width="100%"
  alt="Request viewer to find and replay the exact request you need"
>
  <source src={portal_url_1} type="video/mp4" />
</video>

## Smaller Changes

- **OpenAPI Schema Validation - Catch errors in your OpenAPI schema before your clients do. If you upload an OpenAPI spec, Speakeasy will run a validation before applying it to your managed APIs. It will inform you of any errors in the spec, so you can address them.**
- **\[self-hosting\] Ambassador Support** - Speakeasy self-hosting now supports clients using Ambassador. Just configure the values.yaml file to get set up. 


 This is the content for the doc changelog/changelog-5/index.mdx 

 ---
title: "Changelog #5: One-click Request Sharing"
description: "Changes to the Speakeasy platform - September 13, 2022."
keywords:
  [
    api,
    openapi,
    swagger,
    json schema,
    big query,
    devex,
    dx,
    developer experience,
    sdk,
  ]
image: "/media/changelog5.png"
date: 2022-09-13
authors:
  - name: Nolan Sullivan
  - image_url: "/media/author-headshots/nolan.jpeg"
featured_image: "/media/changelog5.png"
---

## New Features

- **One-Click Request Sharing** - When you're combing through API traffic to debug customer issues and you find something you want to flag to your team, don’t worry about taking a screenshot or formatting a payload. You can now share the URL of the filtered traffic or specific API request to any teammate on the Speakeasy team account, so that they can easily open up, and replay or export the request. Also available in the Request Viewer react embed.

[Permalink Sharing - Watch Video](https://www.loom.com/share/91813dca7b1d4531b9b640c4fb004327)

import portal_url_1 from "./changelog-september-13-2022-image-01.mp4";

{" "}

<video
  controls={false}
  loop={true}
  autoPlay={true}
  muted={true}
  width="100%"
  alt="Share the URL of the filtered traffic or specific API request to any teammate on the Speakeasy team account"
>
  <source src={portal_url_1} type="video/mp4" />
</video>

- **API Quickstart** - Get your API set up with Speakeasy in a minute. Our revamped API set up process makes it easy to get started whether you have an OpenAPI schema or are starting from scratch.

[API Quickstart - Watch Video](https://www.loom.com/share/8752648ec6804b3c968a6d0bf55bc1f7)

import portal_url_2 from "./changelog-september-13-2022-image-02.mp4";

{" "}

<video
  controls={false}
  loop={true}
  autoPlay={true}
  muted={true}
  width="100%"
  alt="Get your API set up with Speakeasy in a minute"
>
  <source src={portal_url_2} type="video/mp4" />
</video>

## Smaller Changes

- **JSON Schema Support - Upload your API existing schema without any alterations.  We now support .json API schemas in addition to .yaml. Come with your API as it is, and get started using Speakeasy.**
- **\[Bug Fix\] Big Query Schema Gen - If you are self-hosting Speakeasy on GCP, you can now accurately generate an OpenAPI schema off of API traffic stored in BigQuery.**


 This is the content for the doc changelog/changelog-6/index.mdx 

 ---
title: "Changelog #6: Dynamic Dev Portals with Speakeasy Components"
description: "Changes to the Speakeasy platform - September 21, 2022."
keywords:
  [
    api,
    openapi,
    api portal,
    react,
    python,
    api request viewer,
    devex,
    dx,
    developer experience,
    sdk,
  ]
image: "/media/changelog6.png"
date: 2022-09-21
authors:
  - name: Nolan Sullivan
  - image_url: "/media/author-headshots/nolan.jpeg"
featured_image: "/media/changelog6.png"
---

## New Features

- **React-native Request Viewer** - Enable your users to troubleshoot broken API implementations on their own – dramatically reducing support costs and mean time-to-resolution. Just embed our request viewer in your developer portal or any customer facing app. The embed is fully featured: users can **filter requests (time, status code, endpoint, etc.), replay them immediately in-app, or share as a permalink** with your customer support team (no more emailed/slacked logs!). [Check out our NPM package here](https://www.npmjs.com/package/@speakeasy-api/webapp).

[Start Here: Speakeasy API Platform and Dev portal Embeds - Watch Video](https://www.loom.com/share/bac492a4bbf34d62b7d241f87376986a)

import portal_url_1 from "./changelog-september-21-2022-image-01.mp4";

{" "}

<video
  controls={false}
  loop={true}
  autoPlay={true}
  muted={true}
  width="100%"
  alt="Changelog sept. 21st"
>
  <source src={portal_url_1} type="video/mp4" />
</video>

- **Python support for client-sdk generation** - Struggling to use the buggy open source openapi-generator libraries? We’ve added support for an idiomatic Python3 client SDK generated straight from your OpenAPI spec. Reach out if you're interested to try it out. It will soon be freely available through a standalone CLI.
- **Run Speakeasy locally** - Start testing Speakeasy ASAP. Our latest release includes docker compose support, so you can easily run Speakeasy locally.

## Smaller Changes

- **New API Dashboard UI - Our API dashboard has a fresh coat of paint. Overviews of every API are now represented by horizontal cards with all the relevant key stats and labels.** [**Login and check it out**](https://app.speakeasy.com/)**!**


 This is the content for the doc changelog/changelog-7/index.mdx 

 ---
title: "Changelog #7: Rust, AWS & API Usage Visualization"
description: "Changes to the Speakeasy platform - September 27, 2022."
keywords:
  [api, openapi, aws, rust, api portal, devex, dx, developer experience, sdk]
image: "/media/changelog7.png"
date: 2022-09-27
authors:
  - name: Nolan Sullivan
  - image_url: "/media/author-headshots/nolan.jpeg"
featured_image: "/media/changelog7.png"
---

## New Features

- **API Usage Dashboards \[Embed\]** \- Make it easy for your developers and API users to understand API errors and traffic patterns with our out-of-the-box usage dashboards. With a click or two, users can see data across various time spans, and group by API endpoints, customer, and status code. The dashboards are of course available as an embed that can be incorporated into your own developer portal or any customer facing app. [Watch Chase walkthrough the new embed!](https://www.loom.com/share/637bbadcbdba499e949a4ec86ca39246)

import portal_url_1 from "./changelog-september-27-2022-image-01.mp4";

{" "}

<video
  controls={false}
  loop={true}
  autoPlay={true}
  muted={true}
  width="100%"
  alt="Changelog September 27"
>
  <source src={portal_url_1} type="video/mp4" />
</video>

- **Rust SDK** - Speakeasy is now available to anyone building their API stack in Rust! The new SDK has full support for Speakeasy features like field masking, path hints, and more. Check out [the full SDK in our public github repository.](https://github.com/speakeasy-api/speakeasy-rust-sdk)

- **Self-Host on AWS** - If AWS is your cloud of choice, you can now run Speakeasy!  Our solution is now fully operational for those who want to self-host on AWS.

## Incremental Improvements & Fixes

- **Delete API Endpoints** - No more clutter! You can now remove APIs and API endpoints you’ve added to your Speakeasy workspace.


 This is the content for the doc changelog/changelog-8/index.mdx 

 ---
title: "Changelog #8: A Dev Portal on Demand"
description: "Changes to the Speakeasy platform - October 4, 2022."
keywords:
  [api, openapi, api portal, react, devex, dx, developer experience, sdk]
image: "/media/changelog8.png"
date: 2022-10-04
authors:
  - name: Nolan Sullivan
  - image_url: "/media/author-headshots/nolan.jpeg"
featured_image: "/media/changelog8.png"
---

## New Features

- **EasyShares** - Building a robust developer portal takes time. Don’t wait months to get the benefits. Install the Speakeasy SDK, and auto-generate your client-specific dev portal in minutes. Make it easy for your API users to troubleshoot errors, and save your developers time that would otherwise be spent on zoom meetings. With a couple clicks you have a unique site that can be shared with your customer, with full control over the data. Set the site to expire after an hour, a day, a week, however long it takes your customer to finish the task at hand! [Watch Alexa walkthrough the new feature!](https://www.loom.com/share/17bd5adcd2ab44a6bb91a7d4e0d6abbb)

import portal_url_1 from "./changelog-october-4-2022-image-01.mp4";

{" "}

<video
  controls={false}
  loop={true}
  autoPlay={true}
  muted={true}
  width="100%"
  alt="Changelog October 4th"
>
  <source src={portal_url_1} type="video/mp4" />
</video>

## Incremental Improvements & Fixes

- **\[Bug Fix\] Scaled Schema Differ** - Those with large APIs no longer need worry! The OpenAPI schema differ now works with obscenely large OpenAPI schemas, so you can see changes to your API no matter its size.
- \[**Improvement**\] **Auto-reload on filter changes** - The usage Dashboards now auto-refresh when you change your filters.


 This is the content for the doc changelog/index.mdx 

 ---
  title: "Changelog"
  description: "Speakeasy changelog"
---

import { Changelog } from "~/features/changelog/home";

# Changelog

#### What we're shipping

<Changelog />


 This is the content for the doc docs/api-contract-tests.mdx 

 ---
title: "Configure Custom API Contract Tests"
description: "Learn how to generate contract and end-to-end tests for your API and SDKs using the Arazzo workflow specification."
---

import { Tabs } from "@speakeasy/nextra-theme";

# Custom End-to-End API Contract Tests with Arazzo

Speakeasy can also be used to create custom end-to-end contract tests that run against a real API.

This document will walk through how to write those more complex tests via the Arazzo specification.
It will also walk through key configuration features for these tests such as:
- Server URLs
- Security credentials
- Environment Variable Provided Values

[Arazzo](/openapi/arazzo) is a simple, human-readable, and extensible specification for defining API workflows. Arazzo powers test generation, allowing you to define custom tests for any use case and define rich tests capable of:
- Testing multiple operations.
- Testing different inputs.
- Validating the correct response is returned.
- Run against a real API or mock server.
- Configure setup and teardown routines for complex E2E tests.

The Arazzo Specification allows you to define sequences of API operations and their dependencies for contract testing, enabling you to validate that your API behaves correctly across multiple interconnected endpoints and complex workflows.

When a `.speakeasy/tests.arazzo.yaml` file is found in your SDK repo, the Arazzo workflow will be used to generate tests for each of the workflows defined in the file.

## Prerequisites

The following are requirements for generating tests:

- [Testing feature prerequisites](/docs/testing#prerequisites) are met.

## Writing custom End-to-End tests

The following is an example Arazzo document defining a simple E2E test for the life cycle of a user resource in the example API.

```yaml
arazzo: 1.0.0
info:
  title: Test Suite
  summary: E2E tests for the SDK and API.
  version: 0.0.1
sourceDescriptions:
  - name: The API
    url: https://example.com/openapi.yaml
    type: openapi
workflows:
  - workflowId: user-lifecycle
    steps:
      - stepId: create
        operationId: createUser
        requestBody:
          contentType: application/json
          payload: {
            "email": "Trystan_Crooks@hotmail.com",
            "first_name": "Trystan",
            "last_name": "Crooks",
            "age": 32,
            "postal_code": 94110,
            "metadata": {
              "allergies": "none",
              "color": "red",
              "height": 182,
              "weight": 77,
              "is_smoking": true
            }
          }
        successCriteria:
          - condition: $statusCode == 200
          - condition: $response.header.Content-Type == application/json
          - condition: $response.body#/email == Trystan_Crooks@hotmail.com
          - condition: $response.body#/postal_code == 94110
        outputs:
          id: $response.body#/id
      - stepId: get
        operationId: getUser
        parameters:
          - name: id
            in: path
            value: $steps.create.outputs.id
        successCriteria:
          - condition: $statusCode == 200
          - condition: $response.header.Content-Type == application/json
          - condition: $response.body#/email == Trystan_Crooks@hotmail.com
          - condition: $response.body#/first_name == Trystan
          - condition: $response.body#/last_name == Crooks
          - condition: $response.body#/age == 32
          - condition: $response.body#/postal_code == 94110
        outputs:
          user: $response.body
          age: $response.body#/age
      - stepId: update
        operationId: updateUser
        parameters:
          - name: id
            in: path
            value: $steps.create.outputs.id
        requestBody:
          contentType: application/json
          payload: $steps.get.outputs.user
          replacements:
            - target: /postal_code
              value: 94107
            - target: /age
              value: $steps.get.outputs.age
        successCriteria:
          - condition: $statusCode == 200
          - condition: $response.header.Content-Type == application/json
          - condition: $response.body#/email == Trystan_Crooks@hotmail.com
          - condition: $response.body#/first_name == Trystan
          - condition: $response.body#/last_name == Crooks
          - condition: $response.body#/age == 32
          - condition: $response.body#/postal_code == 94107
        outputs:
          email: $response.body#/email
          first_name: $response.body#/first_name
          last_name: $response.body#/last_name
          metadata: $response.body#/metadata
      - stepId: updateAgain
        operationId: updateUser
        parameters:
          - name: id
            in: path
            value: $steps.create.outputs.id
        requestBody:
          contentType: application/json
          payload: {
            "id": "$steps.create.outputs.id",
            "email": "$steps.update.email",
            "first_name": "$steps.update.first_name",
            "last_name": "$steps.update.last_name",
            "age": 33,
            "postal_code": 94110,
            "metadata": "$steps.update.metadata"
          }
        successCriteria:
          - condition: $statusCode == 200
          - condition: $response.header.Content-Type == application/json
          - condition: $response.body#/email == Trystan_Crooks@hotmail.com
          - condition: $response.body#/first_name == Trystan
          - condition: $response.body#/last_name == Crooks
          - condition: $response.body#/age == 33
          - condition: $response.body#/postal_code == 94110
      - stepId: delete
        operationId: deleteUser
        parameters:
          - name: id
            in: path
            value: $steps.create.outputs.id
        successCriteria:
          - condition: $statusCode == 200
```

The above workflow defined 4 steps that each feed into the next, representing the creation of a user, retrieving that user via its new ID, updating the user, and finally deleting the user. Outputs have been defined for certain steps that are then used as inputs for the following steps.

It will generate the test shown below:

<Tabs items={['TypeScript', 'Python', 'Go']}>

<Tabs.Tab>

```typescript
// src/__tests__/sdk.test.ts

import { assert, expect, it, test } from "vitest";
import { SDK } from "../index.js";
import { assertDefined } from "./assertions.js";
import { createTestHTTPClient } from "./testclient.js";

test("Sdk User Lifecycle", async () => {
  const sdk = new SDK({
    serverURL: process.env["TEST_SERVER_URL"] ?? "http://localhost:18080",
    httpClient: createTestHTTPClient("user-lifecycle"),
  });

  const createResult = await sdk.createUser({
    email: "Trystan_Crooks@hotmail.com",
    firstName: "Trystan",
    lastName: "Crooks",
    age: 32,
    postalCode: "94110",
    metadata: {
      allergies: "none",
      additionalProperties: {
        "color": "red",
        "height": "182",
        "weight": "77",
        "is_smoking": "true",
      },
    },
  });
  expect(createResult.httpMeta.response.status).toBe(200);
  expect(createResult.user?.email).toEqual("Trystan_Crooks@hotmail.com");
  expect(createResult.user?.postalCode).toBeDefined();
  expect(createResult.user?.postalCode).toEqual("94110");

  const getResult = await sdk.getUser(assertDefined(createResult.user?.id));
  expect(getResult.httpMeta.response.status).toBe(200);
  expect(getResult.user?.email).toEqual("Trystan_Crooks@hotmail.com");
  expect(getResult.user?.firstName).toBeDefined();
  expect(getResult.user?.firstName).toEqual("Trystan");
  expect(getResult.user?.lastName).toBeDefined();
  expect(getResult.user?.lastName).toEqual("Crooks");
  expect(getResult.user?.age).toBeDefined();
  expect(getResult.user?.age).toEqual(32);
  expect(getResult.user?.postalCode).toBeDefined();
  expect(getResult.user?.postalCode).toEqual("94110");

  const user = assertDefined(getResult.user);
  user.postalCode = "94107";
  user.age = getResult.user?.age;
  const updateResult = await sdk.updateUser(
    assertDefined(createResult.user?.id),
    assertDefined(getResult.user),
  );
  expect(updateResult.httpMeta.response.status).toBe(200);
  expect(updateResult.user?.email).toEqual("Trystan_Crooks@hotmail.com");
  expect(updateResult.user?.firstName).toBeDefined();
  expect(updateResult.user?.firstName).toEqual("Trystan");
  expect(updateResult.user?.lastName).toBeDefined();
  expect(updateResult.user?.lastName).toEqual("Crooks");
  expect(updateResult.user?.age).toBeDefined();
  expect(updateResult.user?.age).toEqual(32);
  expect(updateResult.user?.postalCode).toBeDefined();
  expect(updateResult.user?.postalCode).toEqual("94107");

  const updateAgainResult = await sdk.updateUser(
    assertDefined(createResult.user?.id),
    {
      id: assertDefined(createResult.user?.id),
      email: assertDefined(updateResult.user?.email),
      firstName: updateResult.user?.firstName,
      lastName: updateResult.user?.lastName,
      age: 33,
      postalCode: "94110",
      metadata: updateResult.user?.metadata,
    },
  );
  expect(updateAgainResult.httpMeta.response.status).toBe(200);
  expect(updateAgainResult.user?.email).toEqual("Trystan_Crooks@hotmail.com");
  expect(updateAgainResult.user?.firstName).toBeDefined();
  expect(updateAgainResult.user?.firstName).toEqual("Trystan");
  expect(updateAgainResult.user?.lastName).toBeDefined();
  expect(updateAgainResult.user?.lastName).toEqual("Crooks");
  expect(updateAgainResult.user?.age).toBeDefined();
  expect(updateAgainResult.user?.age).toEqual(33);
  expect(updateAgainResult.user?.postalCode).toBeDefined();
  expect(updateAgainResult.user?.postalCode).toEqual("94110");

  const deleteResult = await sdk.deleteUser(
    assertDefined(createResult.user?.id),
  );
  expect(deleteResult.httpMeta.response.status).toBe(200);
});
```

</Tabs.Tab>

<Tabs.Tab>

```python
# tests/test_sdk.py

import io
import openapi
from openapi import SDK
import os
import pytest
from tests.test_client import create_test_http_client


def test_sdk_user_lifecycle():
    with SDK(
        server_url=os.getenv("TEST_SERVER_URL", "http://localhost:18080"),
        client=create_test_http_client("user-lifecycle"),
    ) as sdk:
        assert sdk is not None

        create_res = sdk.create_user(
            request=openapi.BaseUser(
                email="Trystan_Crooks@hotmail.com",
                first_name="Trystan",
                last_name="Crooks",
                age=32,
                postal_code="94110",
                metadata=openapi.Metadata(
                    allergies="none",
                    **{
                        "color": "red",
                        "height": "182",
                        "weight": "77",
                        "is_smoking": "true",
                    },
                ),
            )
        )
        assert create_res is not None
        assert create_res.email == "Trystan_Crooks@hotmail.com"
        assert create_res.postal_code is not None
        assert create_res.postal_code == "94110"

        get_res = sdk.get_user(id=create_res.id)
        assert get_res is not None
        assert get_res.email == "Trystan_Crooks@hotmail.com"
        assert get_res.first_name is not None
        assert get_res.first_name == "Trystan"
        assert get_res.last_name is not None
        assert get_res.last_name == "Crooks"
        assert get_res.age is not None
        assert get_res.age == 32
        assert get_res.postal_code is not None
        assert get_res.postal_code == "94110"

        user = get_res
        user.postal_code = "94107"
        user.age = get_res.age

        update_res = sdk.update_user(id=create_res.id, user=user)
        assert update_res is not None
        assert update_res.email == "Trystan_Crooks@hotmail.com"
        assert update_res.first_name is not None
        assert update_res.first_name == "Trystan"
        assert update_res.last_name is not None
        assert update_res.last_name == "Crooks"
        assert update_res.age is not None
        assert update_res.age == 32
        assert update_res.postal_code is not None
        assert update_res.postal_code == "94107"

        update_again_res = sdk.update_user(
            id=create_res.id,
            user=openapi.User(
                id=create_res.id,
                email=update_res.email,
                first_name=update_res.first_name,
                last_name=update_res.last_name,
                age=33,
                postal_code="94110",
                metadata=update_res.metadata,
            ),
        )
        assert update_again_res is not None
        assert update_again_res.email == "Trystan_Crooks@hotmail.com"
        assert update_again_res.first_name is not None
        assert update_again_res.first_name == "Trystan"
        assert update_again_res.last_name is not None
        assert update_again_res.last_name == "Crooks"
        assert update_again_res.age is not None
        assert update_again_res.age == 33
        assert update_again_res.postal_code is not None
        assert update_again_res.postal_code == "94110"

        sdk.delete_user(id=create_res.id)
```

</Tabs.Tab>

<Tabs.Tab>

```go
// tests/sdk_test.go

package sdk_test

import (
	"context"
	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"
	"openapi"
	"openapi/internal/utils"
	"os"
	"testing"
)

func TestSDK_UserLifecycle(t *testing.T) {
	ctx := context.Background()

	s := openapi.New(
		openapi.WithServerURL(utils.GetEnv("TEST_SERVER_URL", "http://localhost:18080")),
		openapi.WithClient(createTestHTTPClient("user-lifecycle")),
	)

	createRes, err := s.CreateUser(ctx, openapi.BaseUser{
		Email:      "Trystan_Crooks@hotmail.com",
		FirstName:  openapi.String("Trystan"),
		LastName:   openapi.String("Crooks"),
		Age:        openapi.Float64(32),
		PostalCode: openapi.String("94110"),
		Metadata: &openapi.Metadata{
			Allergies: openapi.String("none"),
			AdditionalProperties: map[string]string{
				"color":      "red",
				"height":     "182",
				"weight":     "77",
				"is_smoking": "true",
			},
		},
	})
	require.NoError(t, err)
	assert.Equal(t, 200, createRes.HTTPMeta.Response.StatusCode)
	assert.Equal(t, "Trystan_Crooks@hotmail.com", createRes.User.Email)
	assert.NotNil(t, createRes.User.PostalCode)
	assert.Equal(t, openapi.String("94110"), createRes.User.PostalCode)

	getRes, err := s.GetUser(ctx, createRes.User.ID)
	require.NoError(t, err)
	assert.Equal(t, 200, getRes.HTTPMeta.Response.StatusCode)
	assert.Equal(t, "Trystan_Crooks@hotmail.com", getRes.User.Email)
	assert.NotNil(t, getRes.User.FirstName)
	assert.Equal(t, openapi.String("Trystan"), getRes.User.FirstName)
	assert.NotNil(t, getRes.User.LastName)
	assert.Equal(t, openapi.String("Crooks"), getRes.User.LastName)
	assert.NotNil(t, getRes.User.Age)
	assert.Equal(t, openapi.Float64(32), getRes.User.Age)
	assert.NotNil(t, getRes.User.PostalCode)
	assert.Equal(t, openapi.String("94110"), getRes.User.PostalCode)

	user := *getRes.User
	user.PostalCode = openapi.String("94107")
	user.Age = getRes.User.Age

	updateRes, err := s.UpdateUser(ctx, createRes.User.ID, user)
	require.NoError(t, err)
	assert.Equal(t, 200, updateRes.HTTPMeta.Response.StatusCode)
	assert.Equal(t, "Trystan_Crooks@hotmail.com", updateRes.User.Email)
	assert.NotNil(t, updateRes.User.FirstName)
	assert.Equal(t, openapi.String("Trystan"), updateRes.User.FirstName)
	assert.NotNil(t, updateRes.User.LastName)
	assert.Equal(t, openapi.String("Crooks"), updateRes.User.LastName)
	assert.NotNil(t, updateRes.User.Age)
	assert.Equal(t, openapi.Float64(32), updateRes.User.Age)
	assert.NotNil(t, updateRes.User.PostalCode)
	assert.Equal(t, openapi.String("94107"), updateRes.User.PostalCode)

	updateAgainRes, err := s.UpdateUser(ctx, createRes.User.ID, openapi.User{
		ID:         createRes.User.ID,
		Email:      updateRes.User.Email,
		FirstName:  updateRes.User.FirstName,
		LastName:   updateRes.User.LastName,
		Age:        openapi.Float64(33),
		PostalCode: openapi.String("94110"),
		Metadata:   updateRes.User.Metadata,
	})
	require.NoError(t, err)
	assert.Equal(t, 200, updateAgainRes.HTTPMeta.Response.StatusCode)
	assert.Equal(t, "Trystan_Crooks@hotmail.com", updateAgainRes.User.Email)
	assert.NotNil(t, updateAgainRes.User.FirstName)
	assert.Equal(t, openapi.String("Trystan"), updateAgainRes.User.FirstName)
	assert.NotNil(t, updateAgainRes.User.LastName)
	assert.Equal(t, openapi.String("Crooks"), updateAgainRes.User.LastName)
	assert.NotNil(t, updateAgainRes.User.Age)
	assert.Equal(t, openapi.Float64(33), updateAgainRes.User.Age)
	assert.NotNil(t, updateAgainRes.User.PostalCode)
	assert.Equal(t, openapi.String("94110"), updateAgainRes.User.PostalCode)

	deleteRes, err := s.DeleteUser(ctx, createRes.User.ID)
	require.NoError(t, err)
	assert.Equal(t, 200, deleteRes.HTTPMeta.Response.StatusCode)
}
```

</Tabs.Tab>

</Tabs>

## Input and Outputs

### Inputs

Inputs can be provided to steps in a number of ways, either via inputs defined in the workflow, references from previous steps, or via values defined inline .

**Workflow Inputs**

[Workflow inputs](/openapi/arazzo#workflow-object) are a way to provide input parameters to the workflow that can be used by any step defined in the workflow. The `inputs` field of a workflow is a JSON Schema object that defines a property for each input the workflow wants to expose.

Test Generation can use any examples defined for a property in the `inputs` json schemas as literal values to use as inputs for the test. As tests are none interactive, if no examples are defined, the test generation will just randomly generate values for the inputs, as it can't ask the user for input.

```yaml
arazzo: 1.0.0
# ....
workflows:
  - workflowId: some-test
    inputs: # This is the JSON Schema for the inputs each property in the inputs object represents a workflow input
      type: object
      properties:
        email:
          type: string
          examples:
            - Trystan_Crooks@hotmail.com # Examples defined will be used as literal values for the test
        firstName:
          type: string
          examples:
            - Trystan
        lastName:
          type: string
          examples:
            - Crooks
    steps:
      - stepId: create
        operationId: createUser
        requestBody:
          contentType: application/json
          payload: {
            "email": "$inputs.email", # The payload will be populated with the literal value defined in the inputs
            "first_name": "$inputs.firstName",
            "last_name": "$inputs.lastName",
          }
        successCriteria:
          - condition: $statusCode == 200
```

**Step References**

Parameters and request body payloads can reference values via [Runtime Expressions](/openapi/arazzo#runtime-expressions) from previous steps in the workflow. This allows for the generation of tests that are more complex than a simple sequence of operations. Speakeasy's implementation currently only allows the referencing of a previous step's outputs, which means you will need to define what values you want to expose to future steps.

```yaml
arazzo: 1.0.0
# ....
workflows:
  - workflowId: some-test
    steps:
      - stepId: create
        operationId: createUser
        requestBody:
          contentType: application/json
          payload: #....
        successCriteria:
          - condition: $statusCode == 200
          - condition: $response.header.Content-Type == application/json
          - condition: $response.body#/email == Trystan_Crooks@hotmail.com
        outputs:
          id: $response.body#/id # The id field of the response body will be exposed as an output for the next step
      - stepId: get
        operationId: getUser
        parameters:
          - name: id
            in: path
            value: $steps.create.outputs.id # The id output from the previous step will be used as the value for the id parameter
        successCriteria:
          - condition: $statusCode == 200        
```

**Inline Values**

For any parameters or request body payloads a step defines, literal values can be provided inline to populate the tests if static values are suitable for the test.

```yaml
arazzo: 1.0.0
# ....
workflows:
  - workflowId: some-test
    steps:
      - stepId: update
        operationId: updateUser
        parameters:
          - name: id
            in: path
            value: "some-test-id" # A literal value can be provided inline for parameters that matches the json schema of the parameter as defined in the associated operation
        requestBody:
          contentType: application/json
          payload: { # literals values that match the content type of the request body can be provided inline
            "email": "Trystan_Crooks@hotmail.com",
            "first_name": "Trystan",
            "last_name": "Crooks",
            "age": 32,
            "postal_code": 94110,
            "metadata": {
              "allergies": "none",
              "color": "red",
              "height": 182,
              "weight": 77,
              "is_smoking": true
            }
          }
        successCriteria:
          - condition: $statusCode == 200
```

**Payload Values**

When using the `payload` field of a request body input, the value can be a static value to use, a value with interpolated [Runtime Expressions](/openapi/arazzo#runtime-expressions) or a [Runtime Expression](/openapi/arazzo#runtime-expression) by itself.

The payload value can then be overlayed using the `replacements` field which represents a list of targets within the payload to replace with the value of the replacements, which themselves can be a static valuue or a [Runtime Expression](/openapi/arazzo#runtime-expression).

```yaml
arazzo: 1.0.0
# ....
workflows:
  - workflowId: some-test
    steps:
      - stepId: get
        # ...
        outputs:
          user: $response.body
      - stepId: update
        operationId: updateUser
        parameters:
          - name: id
            in: path
            value: "some-test-id"
        requestBody:
          contentType: application/json
          payload: $steps.get.outputs.user # use the response body of the previous step as the payload for this step
          replacements: # overlay the payload with the below replacements
            - target: /postal_code # overlays the postal_code field with a static value
              value: 94107
            - target: /age # overlays the age field with the value of the age output of a previous step
              value: $steps.some-other-step.outputs.age
        successCriteria:
          - condition: $statusCode == 200
```

### Outputs

As shown above, outputs can be defined for each step in a workflow allowing values from things such as the response body to be used as values in following steps.

Current Speakeasy supports only referencing values from a response body, using the [Runtime Expressions](/openapi/arazzo#runtime-expressions) syntax and json-pointers.

Any number of outputs can be defined for a step.

```yaml
arazzo: 1.0.0
# ....
workflows:
  - workflowId: some-test
    steps:
      - stepId: create
        operationId: createUser
        requestBody:
          contentType: application/json
          payload: #....
        successCriteria:
          - condition: $statusCode == 200
          - condition: $response.header.Content-Type == application/json
          - condition: $response.body#/email == Trystan_Crooks@hotmail.com
        outputs: # Outputs are a map of an output id to a runtime expression that will be used to populate the output
          id: $response.body#/id # json-pointers are used to reference fields within the response body
          email: $response.body#/email
          age: $response.body#/age
          allergies: $response.body#/metadata/allergies
```

## Success Criteria

The `successCriteria` field of a step is a list of [Criterion Objects](/openapi/arazzo#criterion-object) that are used to validate the success of the step. For test generation these will form the basis of the test assertions.

`successCriteria` can be as simple as a single condition testing the status code of the response, or as complex as testing multiple individual fields within the response body.

Speakeasy's implementation currently only supports `simple` criteria and the equality operator `==` for comparing values, and testing status codes, response headers and response bodies.

For testing values within the response body, criteria for testing the status code and content type of the response are also required, to help the generator determine which response schema to validate against due to the typed nature of the SDKs.

```yaml
arazzo: 1.0.0
# ....
workflows:
  - workflowId: some-test
    steps:
      - stepId: create
        operationId: createUser
        requestBody:
          contentType: application/json
          payload: #....
        successCriteria:
          - condition: $statusCode == 200
          - condition: $response.header.Content-Type == application/json
          - condition: $response.body#/email == Trystan_Crooks@hotmail.com
          # or
          - context: $response.body
            type: simple
            condition: |
              {
                "email": "Trystan_Crooks@hotmail.com",
                "first_name": "Trystan",
                "last_name": "Crooks",
                "age": 32,
                "postal_code": 94110,
                "metadata": {
                  "allergies": "none",
                  "color": "red",
                  "height": 182,
                  "weight": 77,
                  "is_smoking": true
                }
              }
```

## Testing operations requiring binary data

Some operations will required providing binary data to test uploading or downloading files etc. In these cases test files can be provided to the test using the `x-file` directive in the example for that field.

```yaml
arazzo: 1.0.0
# ....
workflows:
  - workflowId: postFile
    steps:
      - stepId: test
        operationId: postFile
        requestBody:
          contentType: multipart/form-data
          payload:
            file: "x-file: some-test-file.txt"
        successCriteria:
          - condition: $statusCode == 200
          - condition: $response.header.Content-Type == application/octet-stream
          - context: $response.body
            condition: "x-file: some-other-test-file.dat"
            type: simple
```

The files will be sourced from the `.speakeasy/testfiles` directory in the root of your SDK repo, where the path provided in the `x-file` directive is relative to the testfiles directory.

The contents of the sourced file will be used as the value for the field being tested.

## Configuring an API to Test Against

By default, tests will be generated to run against Speakeasy's mock server (URL of `http://localhost:18080`) which will validate the SDKs are functioning correctly but not guaranteeing the correctness of the API.

The generator can be configured to run all tests against another URL or just individual tests. This is done through the use `x-speakeasy-test-server` extensions in the `.speakeasy/tests.arazzo.yaml` file.

If the extension is found at the top level of the Arazzo file then all workflows/tests will be configured to run againsts the specified server URL. If the extension is found within a workflow then only that workflow will be configured to run against the specified server URL.

The server URL can either be a static URL or a `x-env: EXAMPLE_ENV_VAR` value that will be pull the value from the environment variable `EXAMPLE_ENV_VAR` where the name of the environment variable can be any specified name.


```yaml
arazzo: 1.0.0
# ...
x-speakeasy-test-server: 
  baseUrl: "https://api.example.com" # If specified at the top level of the Arazzo file, all workflows will be configured to run against the specified server URL
workflows:
  - workflowId: some-test
    x-speakeasy-test-server: 
      baseUrl: "x-env: TEST_SERVER_URL" # If specified within a workflow, only that workflow will be configured to run against the specified server URL. This will override any top level configuration.
    # ...
```

A default value can be provided in the `x-env` directive if the environment variable is not set. This can be useful for local development or non-production environments.

```yaml
x-speakeasy-test-server: 
  baseUrl: "x-env: TEST_SERVER_URL; http://localhost:18080" # Run against the local mock server if the environment variable is not set
```

If all tests are configured to run against other server URLs, mock server generation can be disabled within the `.speakeasy/gen.yaml` file.

```yaml
# ...
generation:
  # ...
  mockServer:
    disabled: true # Setting this to true will disable mock server generation
```

## Configuring security credentials for Contract tests

When running tests against a real API, the SDK may need to be configured with security credentials to authenticate with the API. This can be done by adding the `x-speakeasy-test-security` extension to the document, a workflow or a individual step.

The `x-speakeasy-test-security` extension allows static values or values pulled from the environment to be used when instantiating an SDK instance and making requests to the API.

```yaml
arazzo: 1.0.0
# ...
x-speakeasy-test-security: # Defined at the top level of the Arazzo file, all workflows will be configured to use the specified security credentials
  value:
    # The keys in the value map are the names of the security schemes defined in the OpenAPI document.
    # For simple schemes, the values is for example the API key value required.
    # For schemes like basic auth or OAuth2 that require multiple values, the value is a map of the required values.
    apiKey: x-env: TEST_API_KEY # Values can be pulled from the environment
    basicAuth:
      username: "test-user" # Or defined as static values
      password: x-env: TEST_PASSWORD
workflows:
  - workflowId: some-test
    x-speakeasy-test-security: # Security can be defined/overridden for a specific workflow
      value:
        apiKey: "test-key"
    # ...
    steps:
      - stepId: step1
        x-speakeasy-test-security: # Or security can be defined/overridden for a specific step
          value:
            authToken: x-env: TEST_AUTH_TOKEN
        # ...
      - stepId: step2
        # ...
```

## Configuring environment variable provided values for Contract tests

When running tests against a real API, you may need to fill in certain input values from dynamic environment variables. This can be done using the Speakeasy environment variable extension.

```yaml
arazzo: 1.0.0
# ....
workflows:
  - workflowId: my-env-var-test
    steps:
      - stepId: update
        operationId: updateUser
        parameters:
          - name: id
            in: path
            value: "x-env: TEST_ID; default" # Provide an environment variable and an optional default value if that env variable is not present.
        requestBody:
          contentType: application/json
          payload: {
            "email": "x-env: TEST_EMAIL; default, # Provide an environment variable and an optional default value if that env variable is not present.
            "first_name": "Trystan",
            "last_name": "Crooks",
            "age": 32,
            "postal_code": 94110,
            "metadata": {
              "allergies": "none",
              "color": "red",
              "height": 182,
              "weight": 77,
              "is_smoking": true
            }
          }
        successCriteria:
          - condition: $statusCode == 200
```

 This is the content for the doc docs/api-devex.mdx 

 ---
title: Why API DevEx?
description: "Why API developer experience?"
---
import sdk_example from './assets/why-speakeasy/sdk-example.mp4'

# Why API developer experience?

In 2011, following years of development, Stripe launched their Transactions API product and upturned conventional B2B product building. The Stripe API-first approach transformed how companies build and sell into enterprises. Lengthy sales and systems integrations have been replaced by developers making a simple `curl` request from their terminal. As Stripe took the world by storm, companies scrambled to redefine their interfaces and shift to an API-first strategy.

Fast-forward to today, and API products are everywhere. Most B2B companies expose their core functionality via API, yet their businesses haven't exploded like Stripe's did. **Poor developer experience still blocks the potential of offering your products as APIs.** API users are still held back by having to dig through unhelpful API reference pages and write scrolls of boilerplate code before they can even test out an API.

![API docs with SDKs featured](./assets/why-speakeasy/sdk-docs.png)

## Why choose Speakeasy?

Speakeasy is an infrastructure for building delightful API experiences. We focus on building foundational products that enable companies to construct awesome API experiences in a matter of minutes, not months.

- **Crafted experiences** – We believe great integration experiences come down to the details. We obsess over the little things so that you don't have to. Whether it's the ergonomics of iterating a paginated response or managing a complex OAuth flow, we've got you covered.
- **Best-in-class support as a feature** – We're your experts on call. Struggling with OpenAPI polymorphic types? No problem! We're ready to dive in with you. Reach out to us, and you'll always point in the direction that best suits your end users.
- **Prolific product velocity**  – We ship every day. We're constantly adding new features and improving our existing ones. Our [roadmap](https://speakeasy.productlane.com/roadmap) is public, and we're always looking for feedback.
- **Maximize your API spec** – You've probably already invested a lot of time in managing and documenting your API types. We believe nurturing your API spec and treating it like a first-class citizen can lead to great outcomes for everyone in your API lifecycle, whether internal or external to your organization. To that end, we've built a toolchain that will assist you in making API changes and iteration easy and foolproof.
- **Quality and reliability** – You're trusting us with key product surfaces. We take that responsibility seriously. We're committed to providing you with a reliable and high-quality product that you can ship with confidence.

## What is the product?

We're building toward a complete suite of tooling to make API development delightful. Our products are modular, so you can take what you want and leave what you don't. Here's the breakdown:

### Production-ready SDKs

Don't put the burden of API integration on your users. Provide idiomatic SDKs in 8+ languages, making API integration as easy as writing a single line of code. Speakeasy automatically creates SDKs from your OpenAPI spec that are:

- **Type safe** – Generated code is fully typed. The most complex APIs are mapped to the most idiomatic types in each language.
- **Idiomatic** – Generated code adheres to common language conventions. As the ecosystem evolves, you can trust dependencies will always stay up to date.
- **Human readable** – Generated code feels handcrafted, complete with comments and READMEs to make it easier for developers to read and debug.
- **Batteries included** – Packages include everything needed for an enterprise-grade integration, including authentication, error handling, retries, pagination, and more.


<video controls={false} loop={true} autoPlay={true} muted={true} width="100%" >
   <source src={sdk_example} type="video/mp4" />
</video>

### Terraform providers

Make your API available as infrastructure. Annotate your OpenAPI spec and create providers that enable your users to:

- **Unlock multi-cloud use cases** - Companies are increasingly multi-cloud, and Terraform is the tool of choice for making your infrastructure cloud-agnostic.
- **Gain environment consistency** - Make your API available to your users consistently across all their environments.
- **Set up disaster recovery** - Enable customers to store state. In the event of a disaster, they can easily recover the resources managed via your API.

### SDK-first documentation

Move beyond curl. Too many APIs out there leave users hanging with a classic three-pane reference. These can look snazzy but rarely reduce the time to the first successful `200` response. 

We believe documentation should be SDK-first, not API-first. That's why our documentation focuses on what integrations look like in the API consumer's language of choice. Upload your OpenAPI spec to give your users docs that get them from zero to `200` fast, with:

- **Usage snippets** – Make your documentation rich with compilable code examples to help users get started. No examples? No problem.
- **Synced docs** – Sync the docs in your installable library, GitHub repo, and website for a consistent developer experience.
- **Sandboxes** – Enable users to test your API using SDKs directly from your docs.


 This is the content for the doc docs/code-samples/automated-code-sample-urls.mdx 

 ---
description: "How to automatically generate code sample URLs from your SDK."
sidebar_label: "Automated Code Sample URLs"
slug: "/automated-code-sample-urls/"
---

import { Callout } from "~/components";

# Automated code sample URLs

For paid accounts, Speakeasy can automatically apply code samples to your base OpenAPI document in the cloud, with no intervention required.
This is the most elegant solution for exposing code samples to documentation providers.

In the **APIs** tab of the dashboard, look for an entry marked as **Combined Spec**.
Click into the entry to see a breakdown of the base OpenAPI document and code samples overlays that were used to produce it.

<Screenshot darkened>
  ![Screenshot of the dashboard showing a Combined
  Spec.](../assets/code-samples/combined-spec.png)
</Screenshot>

<Screenshot darkened>
  ![Screenshot of the dashboard showing Combined Spec
  details.](../assets/code-samples/combined-spec-details.png)
</Screenshot>

To configure one of these combined code sample specs as a public URL for documentation providers, visit the **Docs** tab in the Speakeasy dashboard.

## How Speakeasy automates code sample URLs

Speakeasy automatically tracks your base OpenAPI document and code samples when you generate an SDK using GitHub Actions and merge the changes to the main branch.
Based on this, Speakeasy generates a combined spec in the background that contains all your existing OpenAPI operations along with any added `x-code-samples` extensions.

## Requirements for using automated code sample URLs

If you have not yet completed your SDK setup in GitHub, you may see a notification like the following in the **Docs** tab.

<Screenshot darkened>
  ![Automatic code sample URLs not
  available.](../assets/code-samples/automatic-code-samples-url-unavailable.png)
</Screenshot>

To use automated code sample URLs, your SDK must meet the following requirements:

- Each SDK's `workflow.yaml` file must include the following:
  - The `source` (your OpenAPI document) with a specified `registry` location.
  - The `target` (your SDK) with a `codeSamples` section that includes a specified `registry` location.
- The SDK must be generated with GitHub Actions and merged to main.
- The SDK GitHub Action must be in `direct` mode, or the `sdk-publish` action must be configured. While publishing to a package manager is _not_ necessary, release tagging must be handled by this action.
- The base OpenAPI document must not include `x-codeSamples` extensions, as they will not be overwritten.

When your setup is correct, the following will be available in the **APIs** tab of the Speakeasy dashboard:

- An entry for your base OpenAPI document (for example, `my-source`).
- For each SDK you include, a corresponding code samples overlay (for example, `my-source-{lang}-code-samples`).

Revisions to the base OpenAPI document and code sample overlays must be tagged with `main`, which is why using GitHub Actions is required.

<Callout title="Alternatives to configuring sdk-publish.yaml:" variant="warning">
If you are not ready to set up publishing, you can temporarily set up the following tagging action in each of your SDK repos.

```yaml .github/workflows/tagging.yaml
name: Speakeasy Tagging
permissions:
  checks: write
  contents: write
  pull-requests: write
  statuses: write
"on":
  push:
    branches:
      - main
    paths: []
  workflow_dispatch: {}
jobs:
  tag:
    uses: speakeasy-api/sdk-generation-action/.github/workflows/tag.yaml@v15
    with:
      registry_tags: main
    secrets:
      github_access_token: ${{ secrets.GITHUB_TOKEN }}
      speakeasy_api_key: ${{ secrets.SPEAKEASY_API_KEY }}
```

</Callout>


 This is the content for the doc docs/code-samples/code-samples-api.mdx 

 ---
slug: /code-samples-api/
title: The Code Samples API
description: "Fetch usage snippets for Speakeasy-generated SDKs using the Code Samples API."
---

import { Callout } from "~/components";

# The Code Samples API

<Callout title="NOTE" variant="info">

This feature is for **Speakeasy Enterprise** customers. To inquire about
access, please contact a Speakeasy representative, or [book a demo].

</Callout>

[book a demo]: /book-demo

## Overview

The Speakeasy Code Samples API is a streamlined solution for accessing rich,
up-to-date SDK usage examples for Speakeasy managed SDK's. These examples can be
easily integrated into an organization's documentation sites, tools, or 
developer portal, and they'll stay up to date automatically.

This API is ideal for organizations who:

- Use Speakeasy to generate SDKs from OpenAPI specifications,
- Need reliable, up-to-date SDK usage examples for their APIs, and
- Want custom tooling for SDK code samples in their documentation.

## Usage

### Prerequisites

<Callout title="IMPORTANT" variant="warning" className="[&_ul]:list-['✓__']">

To use the Code Samples API, the following prerequisites are required:

- A Speakeasy Enterprise Subscription,
- An [Automated Code Sample URL], configured for the desired
  Speakeasy SDK, and
- A Speakeasy API Key for the workspace associated with the desired SDK.

</Callout>

[Automated Code Sample URL]: /docs/code-samples/automated-code-sample-urls

### TypeScript SDK

The Code Samples SDK can be used in TypeScript projects to fetch snippets. The
library also ships with some convenient features such as **React Query hooks**, and
a **React Component**.

For instructions on how to install and use the TypeScript SDK, refer to the
[GitHub repo's README file].

[GitHub repo's README file]: https://github.com/speakeasy-api/speakeasy-code-samples-ts/tree/main?tab=readme-ov-file#sdk-example-usage

#### The React Component

This library includes a React component that fetches and highlights code
snippets using [highlight.js], using React Query under the hood. Along with
displaying the snippet, it shows a loading state during fetching and provides a
fallback view if an error occurs.

The component can be used as follows:

```tsx App.tsx
import { SpeakeasyCodeSamplesCore } from "@speakeasyapi/code-samples/core";
import {
  CodeSample,
  SpeakeasyCodeSamplesProvider,
} from "@speakeasyapi/code-samples/react";
import { QueryClient, QueryClientProvider } from "@tanstack/react-query";

const queryClient = new QueryClient();

const speakeasyCodeSamples = new SpeakeasyCodeSamplesCore({
  apiKey: "<SPEAKEASY_API_KEY_HERE>",
  registryUrl: "https://spec.speakeasy.com/org/ws/my-source",
});

// Retries are handled by the underlying SDK.
queryClient.setQueryDefaults(["@speakeasyapi/code-samples"], { retry: false });

queryClient.setMutationDefaults(["@speakeasyapi/code-samples"], {
  retry: false,
});

function App() {
  return (
    <QueryClientProvider client={queryClient}>
      <SpeakeasyCodeSamplesProvider client={speakeasyCodeSamples}>
        <CodeSample operationId="getPetById" language="typescript" />
      </SpeakeasyCodeSamplesProvider>
    </QueryClientProvider>
  );
}
```

<Callout title="NOTE" variant="info">

The rendered code snippet will not be styled. To style the rendered code
snippet, add a highlight.js theme to theme project. Themes can be 
downloaded from the [highlight.js GitHub Repository], and previewed on 
their [demo page][highlight.js demo page].

</Callout>

[highlight.js]: https://highlightjs.org/
[highlight.js demo page]: https://highlightjs.org/demo
[highlight.js GitHub Repository]: https://github.com/highlightjs/highlight.js/tree/main/src/styles


## REST API Reference

<h3 className="_tracking-tight _text-slate-900 dark:_text-white _mt-10 _text-h4-mobile md:_text-h4">Retrieve usage snippets</h3>

`GET /v1/code_sample`

Retrieves usage snippets from an OpenAPI document stored in the registry. The endpoint supports filtering by programming language and operation ID.

<h4 className="_tracking-tight _text-slate-900 dark:_text-white _mt-10 _text-h5-mobile md:_text-h5">Query Parameters</h4>

<div className="[&>table]:table-auto mt-6">

  | Parameter       | Type                                   | Required | Description                                          | Example                                                    |
  | --------------- | ---------------------------------------| -------- | ---------------------------------------------------- | ---------------------------------------------------------- |
  | `registry_url`  | `string`                               | Yes      | The registry URL from which to retrieve the snippets | `https://spec.speakeasy.com/my-org/my-workspace/my-source` |
  | `operation_ids` | `string[]`                             | No       | The operation IDs to retrieve snippets for           | `getPets`                                                  |
  | `method_paths`  | `{ method: string, path: string }[]`   | No       | The method paths to retrieve snippets for            | `[{"method": "get", "path": "/pets"}]`                     |
  | `languages`     | `string[]`                             | No       | The programming languages to retrieve snippets for   | `["python", "javascript"]`                                 |

</div>

<h4 className="_tracking-tight _text-slate-900 dark:_text-white _mt-10 _text-h5-mobile md:_text-h5">Example Request</h4>

```shell example-request.sh
curl -G "https://app.speakeasy.com/v1/code_sample" \
  -H "X-Api-Key: <SPEAKEASY_API_KEY_HERE>" \
  --data-urlencode "registry_url=https://spec.speakeasy.com/my-org/my-workspace/my-source" \
  -d "languages=go" \
  -d "languages=typescript" \
  -d "operation_ids=getPets"
```

<h4 className="_tracking-tight _text-slate-900 dark:_text-white _mt-10 _text-h5-mobile md:_text-h5">Example Response</h4>

```json 200 - Success
{
  "snippets": [
    {
      "operationId": "getPetById",
      "path": "/pet/{id}",
      "method": "get",
      "language": "typescript",
      "code": "import { Petstore } from \"petstore-sdk\";\n\nconst petstore = new Petstore({\n  apiKey: \"<YOUR_API_KEY_HERE>\",\n});\n\nasync function run() {\n  const result = await petstore.pet.getById({\n    id: 137396,\n  });\n\n  // Handle the result\n  console.log(result);\n}\n\nrun();"
    }
  ]
}
```

```json 4XX - Error
{
  "status_code": 404,
  "message": "no snippets found for given operation IDs and languages -- err_not_found: not found"
}
```



 This is the content for the doc docs/code-samples/generate-code-samples.mdx 

 ---
description: "How to generate code samples for your OpenAPI document that match your SDK."
sidebar_label: "Generate Code Samples"
slug: "/code-samples/"
---

import { Callout } from "~/components";

# Generating code samples for your SDK

This guide explains how code samples are generated for an SDK and how to apply them to an OpenAPI document.

## What is the code samples extension?

Many API documentation providers provide code snippets in multiple languages to help developers understand how to use the API. However, these snippets
may not correspond to a usage snippet from an existing SDK provided by the API, which reduces the value of the API documentation and can lead to inconsistent integrations, depending on whether a user discovers the API docs or the SDK first.

The `x-codeSamples` extension (previously called `x-code-samples`) is a widely accepted OpenAPI Specification extension that enables the addition of custom code samples in multiple languages to operation IDs in an OpenAPI document.
When custom code samples are added using the code samples extension, documentation providers will render the usage snippet in the right-hand panel of the documentation page:

For a full breakdown of the code samples extension, see our [guide](/guides/openapi/x-codesamples).

## Configuring code samples

Speakeasy provides code samples in the form of [overlays](/docs/prep-openapi/overlays/create-overlays#what-are-overlays). This ensures that your code samples can be trivially applied to your OpenAPI document without needing to upstream the changes.

The setup for using overlays to apply code samples is configured in your workflow file, as follows:

```yaml .speakeasy/workflow.yaml
# ...
targets:
  my-target:
    target: typescript
    source: my-source
    codeSamples:
      output: code-samples.yaml # Optional, if you would like a local copy of your code samples to be produced
      registry:
        location: registry.speakeasy.com/my-org/my-workspace/my-source-typescript-code-samples
      blocking: false # Optional, defaults to true if not present
```

In the above example, a code samples overlay containing TypeScript usage snippets for all operations in the `my-source` OpenAPI document will be
generated and written to `code-samples.yaml` and pushed to the Speakeasy registry.

<Callout title="Why use the registry?" variant="success">
  Speakeasy will automatically load code samples that are pushed to the registry and apply them to your OpenAPI document.
  This saves you from having to manually configure a workflow to integrate your code samples into your base document.
  Removing the `registry` section from your workflow file will disable this feature and require you to manually apply code samples to your OpenAPI document.
</Callout>

### Overrides

To override the `lang` and `label` values, you can add either or both of the following options to the `codeSamples` section in your `workflow.yaml` file:

```yaml
targets:
  my-target:
    codeSamples:
      # ...
      langOverride: <any string> # set `lang` to this value in all code samples
      labelOverride:
        omit: true # omit the label field entirely from the output
        # OR
        fixedValue: <any string> # set the label to this value in all code samples
```

### Styles

For certain documentation providers like ReadMe, you will need to override the default style of code samples in your OpenAPI document.
To override the default style, modify the following option in the `codeSamples` section of your `workflow.yaml` file:

```yaml
targets:
  my-target:
    codeSamples:
      # ...
      style: readme # Default is 'standard'
```

## Automatic code sample URLs

For paid accounts, Speakeasy provides an elegant solution for exposing code samples to documentation providers through its automated code sample URLs product.

For a full breakdown of the feature, see the [guide](/docs/automated-code-sample-urls).

## Manually applying code samples to an OpenAPI document

Alternatively, you can manually set up code sample integrations by pulling together code sample images in your repository with a simple workflow.

```yaml .speakeasy/workflow.yaml
workflowVersion: 1.0.0
speakeasyVersion: latest
sources:
  docs-source:
    inputs:
      - location: { { your_api_spec } } # local or remote references supported
    overlays:
      - location: registry.speakeasyapi.dev/<org>/<workspace>/my-typescript-sdk-code-samples # location of the code samples from previous step
      - location: registry.speakeasyapi.dev/<org>/<workspace>/my-go-sdk-code-samples
      - location: registry.speakeasyapi.dev/<org>/<workspace>/my-python-sdk-code-samples
    output: openapi.yaml
targets: {}
```

```yaml .github/workflows/sdk_generation.yaml
name: Generate
permissions:
  checks: write
  contents: write
  pull-requests: write
  statuses: write
"on":
  workflow_dispatch:
    inputs:
      force:
        description: Force generation of SDKs
        type: boolean
        default: false
  schedule:
    - cron: 0 0 * * *
jobs:
  generate:
    uses: speakeasy-api/sdk-generation-action/.github/workflows/workflow-executor.yaml@v15
    with:
      force: ${{ github.event.inputs.force }}
      mode: pr
    secrets:
      github_access_token: ${{ secrets.GITHUB_TOKEN }}
      speakeasy_api_key: ${{ secrets.SPEAKEASY_API_KEY }}
```

Now you can run `speakeasy run`. If you use registry references, the source and code samples will always be up to date with the main branch of your SDK repos.



 This is the content for the doc docs/core-concepts.mdx 

 ---
title: Core concepts
description: "Core concepts of the Speakeasy Platform."
---

# Core Concepts

The core concepts explained on this page are essential to understanding the Speakeasy platform. To skip to getting started with the platform, [go here](./introduction/introduction.mdx).

## Workflows

A workflow is how the Speakeasy platform defines the process of generating a [target](#Target) from a [source](#Source). A workflow is defined in a `workflow.yaml` file stored in the root of the target repository in the `.speakeasy` directory. A workflow is run using the `speakeasy run` command.

### Workflow File Syntax

The `workflow.yaml` workflow file is a YAML file that defines the steps of a workflow. The file is broken down into the following sections:

```yaml
workflowVersion: 1.0.0
speakeasyVersion: latest
sources:
  my-source:
    inputs:
      - location: ./openapi.yaml
      - location: ./overlay.yaml
      - location: ./another-openapi.yaml
      - location: ./another-overlay.yaml
      # .... more openapi documents and overlays can be added here
  # more inputs can be added here through `speakeasy configure sources` command
  # ....
  # ....
targets:
  python-sdk:
    target: python
    source: my-source
  # more inputs can be added here through `speakeasy configure targets` command
  # ....
  # ....
```

The workflow file syntax allows for 1:1, 1:N, or N:N mapping of `sources` to `targets`. A common use case for 1:N mapping is setting up a monorepo of SDKs. See our [monorepo guide](/guides/sdks/creating-a-monorepo) for details.

## Sources

A source is one or more OpenAPI documents and overlays merged to create a single OpenAPI document. Sources are defined in the `workflow.yaml` file.

## Targets

A target is an SDK, Terraform provider, or other code generated from sources. Sources are defined in the `workflow.yaml` file.

## SDK Generation

The following concepts are specific to the SDK generation type of target. Please see our [`template-sdk`](https://github.com/speakeasy-sdks/template-sdk/tree/main) for examples of the concepts.

## The Generation Config File

The Speakeasy CLI uses the `gen.yaml` generation config file to generate a [target](#Target). The `gen.yaml` file is stored in the root of a target repository in the `.speakeasy` directory. For a full reference of the `gen.yaml` file, see [the reference doc](./gen-reference.mdx).

## The Generation State File

The Speakeasy CLI uses the `gen.lock` generation state file to track the state of a generation. The `gen.lock` file includes a generation UUID, `management` and `feature` versions, and the list of generated files managed through the Speakeasy CLI. The file is stored in the root of a target repository in the `.speakeasy` directory.

## Releases and Versioning

Speakeasy automatically creates releases and versions for your target artifacts. The release and version are defined in the `gen.yaml` file and used to track the state of a generation and create a release on the target repository. [Releases](https://docs.github.com/en/repositories/releasing-projects-on-github/about-releases) are used synonymously with GitHub Releases, the primary way Speakeasy distributes artifacts. For more information on how to manage versioning, see our [versioning reference](/docs/manage/versioning).

## GitHub Workflow

The GitHub Workflow is a set of GitHub actions used to automate the generation of a target. The GitHub Workflow is defined in the `.github/workflows` directory of a target repository. For a complete reference of the GitHub Workflow, see the documentation. These files can be set up using the `speakeasy configure github` CLI command.

## OpenAPI Specification (OAS)

The OpenAPI Specification (OAS) is a widely accepted REST specification for building APIs. An OpenAPI document is a JSON or YAML file that defines the structure of an API. The Speakeasy platform uses OpenAPI documents as the source for generating SDKs and other code.

## Overlay

An overlay is a JSON or YAML file used to add, remove, or modify parts of an OpenAPI document and customize the generated code. Overlays used to alter an OpenAPI document are defined in the `workflow.yaml` file.

## Linting

Linting is the process of checking an OpenAPI document for errors and style issues. The Speakeasy platform defines linting rules used to validate an OpenAPI document. Linting is done using the `speakeasy lint` command, and linting rules are defined in the `lint.yaml` file.

## Validation

Validation is the process of checking if an OpenAPI document is ready for code generation. The Speakeasy platform defines validation rules used to validate an OpenAPI document. Validation is done using the `speakeasy validate` command, and validation rules are defined in the `lint.yaml` file.
By default the `validate` CLI command will use the `speakeasy-default` linting ruleset if custom rules are not defined.


 This is the content for the doc docs/create-client-sdks.mdx 

 ---
title: SDK Creation Overview
description: "Learn how to create production-ready SDKs from your OpenAPI / Swagger spec using Speakeasy."
---

import { Callout } from "~/components";
import { SupportedLanguagesData } from "~/data/shared/supportedLanguages"; 
import { IconGrid } from "~/features/shared/recipes";

# SDK Creation Overview

<IconGrid { ...SupportedLanguagesData } />

## Prerequisites

- Install the Speakeasy CLI using one of the following methods:

```bash
# Homebrew (macOS)
brew install speakeasy-api/homebrew-tap/speakeasy

# Script Installation (macOS and Linux)
curl -fsSL https://go.speakeasy.com/cli-install.sh | sh

# Windows Installation
# Using winget:
winget install speakeasy

# Using Chocolatey:
choco install speakeasy
```

For manual installation, download the latest release from the [releases page](https://github.com/speakeasy-api/speakeasy/releases), extract the binary, and add it to the system path.

- Provide an API specification in one of the supported formats:

| Spec Format         | Supported |
| ------------------- | :-------: |
| OpenAPI 3.0         |    ✅     |
| OpenAPI 3.1         |    ✅     |
| JSON Schema         |    ✅     |
| Postman Collections |    🔜     |

<Callout title="TIP" variant="success">
  If your spec is in an unsupported format, use one of the following tools to convert it:

- [Swagger 2.0 -> OpenAPI 3.0](https://editor.swagger.io/): go to **Edit > Convert to OpenAPI 3.0**
- [Postman -> OpenAPI 3.0](https://kevinswiber.github.io/postman2openapi/)

</Callout>

## Interactive SDK Generation With CLI Quickstart

For first-time SDK generation with Speakeasy, start with `speakeasy quickstart`. Install the Speakeasy CLI using `brew install speakeasy-api/tap/speakeasy`.

Run the following command to start the quickstart process:

```bash
speakeasy quickstart
```

This command initiates an interactive session for SDK generation. The process requires creating a workspace on the [dashboard](https://app.speakeasy.com/).

<Screenshot variant="cli" docs={true}>
  ![Screenshot of the terminal after running speakeasy
  quickstart.](./assets/create-sdks/quickstart-1.png)
</Screenshot>

The next step prompts for SDK language selection:

<Screenshot variant="cli" docs={true}>
  ![Screenshot of the terminal prompting user to select
  language.](./assets/create-sdks/quickstart-2.png)
</Screenshot>

Complete the prompted parameter configuration:

<Screenshot variant="cli" docs={true}>
  ![Screenshot of the terminal with optional
  parameters.](./assets/create-sdks/quickstart-3.png)
</Screenshot>

Speakeasy validates the specifications and generates the SDK after receiving all inputs. The process executes [`speakeasy run`](/docs/speakeasy-reference/cli/run) to validate, generate, compile, and set up the SDK. A confirmation message displays the generated SDK details upon successful completion:

<Screenshot variant="cli" docs={true}>
  ![Screenshot of the terminal showing
  success.](./assets/create-sdks/quickstart-4.png)
</Screenshot>

Re-run the `speakeasy run` command after making changes to the OpenAPI document or SDK configuration.

Set up the SDK on GitHub for a fully managed experience. See the GitHub setup guide [here](/docs/manage/github-setup).

## Traditional SDK Generation

The non-interactive approach allows specifying all parameters in a single command, suitable for script integration and automation. This method requires manual configuration of the workflow to validate, generate, compile, and publish the SDK.

The recommended approach remains using `speakeasy quickstart` and `run` as shown in the [quickstart section](#interactive-sdk-generation-with-cli-quickstart) above.

```shell
speakeasy generate sdk --out <output_directory> --schema <specification_path_or_url> [options]
```

### Required Parameters:

```
--out: Destination for the generated SDK.
--schema: Path or URL to your API spec.
```

### Additional Options

```
  -y, --auto-yes                 auto answer yes to all prompts
  -d, --debug                    enable writing debug files with broken code
  -H, --header string            header key to use if authentication is required for downloading schema from remote URL
  -h, --help                     help for sdk
  -i, --installationURL string   the language specific installation URL for installation instructions if the SDK is not published to a package manager
  -l, --lang string              language to generate sdk for (available options: [csharp, go, java, php, python, ruby, swift, terraform, typescript, unity]) (default "go")
  -p, --published                whether the SDK is published to a package manager or not, determines the type of installation instructions to generate
  -r, --repo string              the repository URL for the SDK, if the published (-p) flag isn't used this will be used to generate installation instructions
  -b, --repo-subdir string       the subdirectory of the repository where the SDK is located in the repo, helps with documentation generation
      --token string             token value to use if authentication is required for downloading schema from remote URL
```

## Next Step: Customize Your SDK

Generating SDKs is the first step but there are several optimizations you can make to improve the quality of your SDKs. Check out the following guide on [customizing your SDKs](/docs/customize-sdks/).


 This is the content for the doc docs/create-terraform.mdx 

 ---
title: "Generate Terraform provider from OpenAPI / Swagger"
slug: /create-terraform/
sidebar_label: Overview
description: "Generate a Terraform provider from your OpenAPI / Swagger spec."
---

import { Callout } from "~/components";

# Generate a Terraform provider from OpenAPI / Swagger

Terraform is an infrastructure-as-code tool that uses providers to manage cloud infrastructure through API calls. Creating and maintaining Terraform providers, which are typically written in Go, requires specialized skills and frequent updates to keep up with API changes.

Speakeasy simplifies creating and maintaining Terraform providers by generating providers from OpenAPI documents. This eliminates the need for Go expertise, keeps providers up-to-date, and reduces the complexity of developing and maintaining providers for cloud environments.

For a detailed overview of supported features, refer to the [Terraform support matrix](/docs/terraform-support-matrix).

## Prerequisites

To create a Terraform provider with Speakeasy, you need:

- The [Speakeasy CLI](speakeasy-cli/getting-started)
- An API spec in a supported format:

| Spec Format        | Supported |
| ------------------ | :-------: |
| OpenAPI 3.0        |    ✅     |
| OpenAPI 3.1        |    ✅     |
| JSON Schema        |    ✅     |
| Postman Collection |    🔜     |

<Callout title="TIP" variant="success">
If you are using an unsupported spec format, use these tools to help you convert to a supported format:

- [Swagger2.0 -> OpenAPI v3.0](https://github.com/swagger-api/swagger-converter)
- [Postman -> OpenAPI v3.0](https://kevinswiber.github.io/postman2openapi/)
</Callout>

## Add annotations

Use the `x-speakeasy-entity` annotation to specify objects to be included as Terraform entities in the provider.

```yaml
paths:
 /pet:
   post:
     ...
     x-speakeasy-entity-operation: Pet#create
     ...
Pet:
 x-speakeasy-entity: Pet
 ...

```

Terraform Usage:

```HCL
resource "petstore_pet" "myPet" {
  ...
}
```

Speakeasy infers Terraform types from your JSON Schema, focusing on the semantics of the `CREATE` and `UPDATE` requests and responses. You **don't need to** define any specific Terraform types in your OpenAPI document.

1. **Required vs. optional:** If a property is required in the `CREATE` request body, it's marked as `Required: true`; otherwise, it's `Optional: true`.
2. **Computed properties:** Properties that appear in a response body but are absent from the `CREATE` request are marked as `Computed: true`. This indicates that Terraform will compute the properties' values.
3. **The `ForceNew` property:** If a property exists in the `CREATE` request but is not present in the `UPDATE` request, it's labeled `ForceNew`.
4. **Enum validation:** When an attribute is defined as an enum, Speakeasy configures a `Validator` for runtime type checks. This ensures that all request properties precisely match one of the enumerated values.
5. **`READ`, `UPDATE`, and `DELETE` dependencies**: Every parameter essential for `READ`, `UPDATE`, or `DELETE` operations must either be part of the `CREATE` API response body or be consistently required in the `CREATE` API request. This ensures that all necessary parameters are available for these operations.

<Callout title="TIP" variant="success">
  Use additional [`x-speakeasy` annotations](/docs/terraform) to
  customize your provider as necessary.
</Callout>

## Enhance generated documentation

Speakeasy helps you autogenerate documentation using the HashiCorp `terraform-plugin-docs` tools and packages. For best results, we recommend:

1. **Include descriptions:** Ensure your OpenAPI document contains detailed descriptions of resources, attributes, and operations. Clear and concise descriptions help users understand the purpose and use of each component.
2. **Provide examples:** Use examples in your OpenAPI document to illustrate how resources and attributes should be configured. Speakeasy leverages these examples to generate usage snippets that users can refer to when starting with your provider.

The Swagger Pet Store generates the following usage snippet for the pet resource:

```go "petstore_pet" "my_pet" {
    id   = 10
    name = "doggie"
    photo_urls = [
        "...",
    ]
}.
```

## Generate a Terraform provider

Run the Speakeasy `quickstart` command:

```bash
speakeasy quickstart
```

Follow the interactive guide, providing the necessary information when prompted, including the path to the spec. Select `terraform` as the language. 

When you've completed the quickstart, you can regenerate the Terraform provider at any time by running `speakeasy run`.

## Frequently Asked Questions


**Do the generated Terraform providers support importing resources?**

Yes, generated Terraform providers support importing resources. However, certain prerequisites and considerations must be taken into account:

**Prerequisites**

1. **API specification:** Ensure the OpenAPI document defines an annotated and type-complete API operation for reading each resource. Tag the operation with `x-speakeasy-entity-operation: MyEntity#read`.

2. **Complete `READ` operation:** Attributes of a resource not defined in the `READ` API are set to `null` by Terraform during the import process.

**Simple keys**

A simple key is a single required ID field that is directly exposed to `terraform import` operations. For example, if the `pet` resource has a single `id` field, the import command will look like this: `terraform import petstore_pet.my_pet my_pet_id`.

**Handling composite keys**

Speakeasy natively supports the direct import of resources with multiple ID fields. Speakeasy generates code that enables import functionality by requiring users to provide a JSON-encoded object with all necessary parameters. In addition to generating documentation, Speakeasy generates appropriate error messages to be displayed if the proper syntax is not followed.

**Import composite keys by block**

An import block allows you to import a resource into the Terraform state by generating the corresponding Terraform configuration. Using a composite key, the import block will look like this:

```hcl test.tf
import {
  id = jsonencode({
    primary_key_one: "9cedad30-2a8a-40f7-9d65-4fabb04e54ff"
    primary_key_two: "e20c40a0-40e8-49ac-b5d0-6e2f41f9e66f"
  })
  to = my_test_resource.my_example
}
```

```bash
terraform plan -generate-config-out=generated.tf
```

**Import composite keys using the CLI**

To import a resource with composite keys using the Terraform CLI, use the `terraform import` command:

```bash
terraform import my_test_resource.my_example '{ "primary_key_one": "9cedad30-2a8a-40f7-9d65-4fabb04e54ff", "primary_key_two": "e20c40a0-40e8-49ac-b5d0-6e2f41f9e66f" }'
```


 This is the content for the doc docs/customize-testing/bootstrapping-test-generation.mdx 

 ---
title: "Bootstrapping SDK Tests"
description: "Learn how to automatically generate contract testing for your API and SDKs."
---

import { ScrollyCoding } from "~/components/codehike/Scrollycoding";

# Bootstrapping SDK Tests

Automatically generate tests for your SDKs. Speakeasy can boostrap tests for all your operations including any new operations added in the future.

These tests use any examples available in your OpenAPI document if available, or autogenerate examples based on the field name, type, and format of your schemas.

Multiple tests per operation can be configured using the named examples detailed for your parameters, request bodies and responses.

By default these tests will run against a mock server to validate the correctness of your SDK's serialization and deserialization.

Tests are boostrapped into a `.speakeasy/tests.arazzo.yaml` file in your SDK repo. Once the test exists it can be customized from that `.speakeasy/tests.arazzo.yaml` without being overwritten.

## Prerequisites

The following are requirements for generating tests:

- [Testing feature prerequisites](/docs/testing#prerequisites) are met.

## Enabling Test Generation

Navigate to your SDK repo and run the following command:

```bash
speakeasy configure tests
```

<ScrollyCoding>

### !!steps `generation`

Test generation and mock API server generation will be enabled when the following exist in the `generation` section of the configuration.

```yaml ! gen.yaml
# !focus(2)
configVersion: 2.0.0
generation:
  # ... other existing configuration ...
  tests:
    generateNewTests: true
```

---

### !!steps `tests`

Enable automated generation of tests for new operations found.
When enabling for the first time this will generate tests for all operations in your OpenAPI document.
Then going forward it will only generate tests for any operations not already found in your `.speakeasy/tests.arazzo.yaml` file.

```yaml ! gen.yaml
# !focus(4:5)
```

---

</ScrollyCoding>

After enabling test generation, if you wish to disable generation of tests for a specific operation, you can explicitly set `x-speakeasy-test: false`:

```yaml
paths:
  /example1:
    get:
      # This operation, without being explicitly disabled, will generate testing.
      # ... operation configuration ...
  /example2:
    get:
      # This operation will not generate testing.
      # ... other operation configuration ...
      x-speakeasy-test: false
```

### Generated Test Location

Generated test files are written in language-specific locations, relative to the root of the SDK:

| Language | Location |
|---|---|
| Go | `tests/` |
| Python | `tests/` |
| TypeScript | `src/__tests__` |

If the mock server is also generated, its output will be in a `mockserver` directory under these locations.

## Running Tests

Run testing, via any of these options, depends on your desired use case:

- Directly via the [`speakeasy test`](/docs/speakeasy-reference/cli/test) CLI command.
- In [GitHub Actions workflows](/docs/customize-testing/github-actions).
- In the [`speakeasy run`](/docs/speakeasy-reference/cli/run) CLI command and existing GitHub Actions generation workflow with additional Speakeasy workflow configuration.

For `speakeasy run` support, modify the Speakeasy workflow configuration (`.speakeasy/workflow.yaml`).

<ScrollyCoding>

### !!steps `targets`

Enable running tests during Speakeasy workflows by adding to one or more of the targets in the  `targets` section of the configuration.

```yaml ! workflow.yaml
# !focus(1)
targets:
  example-target:
    # ... other existing configuration ...
    testing:
      enabled: true
```

---

### !!steps `testing`

Enable testing for the target.

```yaml ! workflow.yaml
# !focus(4:5)
targets:
  example-target:
    # ... other existing configuration ...
    testing:
      enabled: true
```

---

</ScrollyCoding>


## Next Steps

- [Customize your SDK tests](/docs/customize-testing/customizing-sdk-tests)
- [Setup testing in GitHub Actions](/docs/customize-testing/github-actions)


 This is the content for the doc docs/customize-testing/customizing-sdk-tests.mdx 

 ---
title: "Customizing SDK Tests"
description: "Learn how to customize SDK tests after they are boostrapped."
---

import { ScrollyCoding } from "~/components/codehike/Scrollycoding";

# Customizing SDK Tests

## Disable auto generation of tests for specific operations

When `generateNewTests` is enabled in the `.speakeasy/gen.yaml` file, all new operations found on the next generation after they are added will automatically have workflows created for then in the `.speakeasy/tests.arazzo.yaml` file and therefore tests will be generated for them.

To disable auto generation of tests for specific operations, the `x-speakeasy-test` extension can be added to the operation in the OpenAPI document.

```yaml
openapi: 3.1.0
# ...
paths:
  /example1:
    get:
      x-speakeasy-test: false # Disables auto generation of tests for this operation
      # ...
# ...
```

alternatively if a workflow/test already exists that references the operation in the `.speakeasy/tests.arazzo.yaml` file, then no new workflow will be created for the operation.


## Grouping tests

By default, all tests will be generated into a single file related to the main SDK class for example `sdk.test.ts` or `test_sdk.py`. This can be configured by adding a `x-speakeasy-test-group` extension to the workflow which will determine which tests will be grouped together in seperate test files.

```yaml
arazzo: 1.0.0
# ...
workflows:
  - workflowId: some-test
    x-speakeasy-test-group: user # All tests in the user group will end up in the `user.test.ts`/`test_user.py`/`user_test.go` files
    # ...
```


## Generate tests only for specific targets

By default, all tests will be generated for all supported targets. But using the `x-speakeasy-test-targets` extension, it is possible to generate tests only for specific targets. This may be useful if tests are either not needed for certain languages or they may be failing in a certain language.

```yaml
arazzo: 1.0.0
# ...
workflows:
  - workflowId: some-test
    x-speakeasy-test-targets: # Only generate tests for the typescript target
      - typescript
    # ...
```

## Data Handling

The definition of each operation will determine what data is used in generated testing. In addition to the [data type system](/openapi/schemas/dataTypes) shaping data, OpenAPI Specification supports [examples](/openapi/examples). Test generation will automatically use defined examples when available. In the absense of defined examples, the test generation will attempt to use a realistic example based on the `type`, `format` (if set), and property name (if applicable).

#### Example Property

By default, a single test will be created based on any `example` properties found throughout any defined operation `parameters`, `requestBody`, and `responses`.

In this example, a single test is created for the `updatePet` operation with `id`, `name`, and `photoUrls` data:

<ScrollyCoding>

### !!steps `paths[/pet].put.operationId`

This test is created for the `updatePet` operation.

```yaml ! openapi.yaml
# !focus(8)
paths:
  "/pet":
    put:
      tags:
      - pet
      summary: Update an existing pet
      description: Update an existing pet by Id
      operationId: updatePet
      requestBody:
        description: Update an existent pet in the store
        content:
          application/json:
            schema:
              "$ref": "#/components/schemas/Pet"
        required: true
      responses:
        '200':
          description: Successful operation
          content:
            application/json:
              schema:
                "$ref": "#/components/schemas/Pet"
components:
  schemas:
    Pet:
      required:
      - name
      - photoUrls
      type: object
      properties:
        id:
          type: integer
          format: int64
          example: 10
        name:
          type: string
          example: doggie
        category:
          "$ref": "#/components/schemas/Category"
        photoUrls:
          type: array
          items:
            type: string
        tags:
          type: array
          items:
            "$ref": "#/components/schemas/Tag"
        status:
          type: string
          description: pet status in the store
          enum:
          - available
          - pending
          - sold
```

---

### !!steps `paths[/pet].put.requestBody`

The operation uses the `Pet` shared component for both the request body and response.

```yaml ! openapi.yaml
# !focus(9,14,16,22)
```

---

### !!steps `components.schemas.Pet.required`

The `Pet` shared component is an object type with required `name` and `photoUrls` properties.

```yaml ! openapi.yaml
# !focus(25:29)
```

---

### !!steps `components.schemas.Pet.id`

While not required, the `Pet` object `id` property has an `example` property, which will be automatically included in the test.

```yaml ! openapi.yaml
# !focus(31,34)
```

---

### !!steps `components.schemas.Pet.name`

The required `Pet` object `name` property has an `example` property, which will be included in the test.

```yaml ! openapi.yaml
# !focus(35,37)
```

---

### !!steps `components.schemas.Pet.photoUrls`

The required `Pet` object `photoUrls` property does not include an `example` property, however it will have an example value automatically created since it is required.

```yaml ! openapi.yaml
# !focus(40:43)
```

---

</ScrollyCoding>

This definition creates a test with `Pet` object request body and response data:

```yaml
id: 10
name: doggie
photoUrls:
  - <value>
```

#### Examples Property

Define multiple tests for an operation using the `examples` property, which in this context is a mapping of example name string keys to example values. Prevent missing or mismatched test generation by ensuring the same example name key is used across all necessary `parameters`, `requestBody`, and `responses` parts of the operation. If desired, [define reusable examples under components](/openapi/examples) similar to schemas.

In this example, multiple tests (`fido` and `rover`) are created for the `addPet` operation:

<ScrollyCoding>

### !!steps `paths[/pet].post.operationId`

These tests are created for the `addPet` operation.

```yaml ! openapi.yaml
# !focus(8)
paths:
  "/pet":
    post:
      tags:
      - pet
      summary: Add a new pet to the store
      description: Add a new pet to the store
      operationId: addPet
      requestBody:
        description: Create a new pet in the store
        content:
          application/json:
            schema:
              "$ref": "#/components/schemas/Pet"
            examples:
              fido:
                summary: fido request
                description: fido example requestBody for test generation
                value:
                  name: Fido
                  photoUrls:
                    - https://www.example.com/fido.jpg
                  status: available
              rover:
                summary: rover request
                description: rover example requestBody for test generation
                value:
                  name: Rover
                  photoUrls:
                    - https://www.example.com/rover1.jpg
                    - https://www.example.com/rover2.jpg
                  status: pending
        required: true
      responses:
        '200':
          description: Successful operation
          content:
            application/json:
              schema:
                "$ref": "#/components/schemas/Pet"
              examples:
                fido:
                  summary: fido response
                  description: fido example response for test generation
                  value:
                    id: 1
                    name: Fido
                    photoUrls:
                      - https://www.example.com/fido.jpg
                    status: available
                rover:
                  summary: rover response
                  description: rover example response for test generation
                  value:
                    id: 2
                    name: Rover
                    photoUrls:
                      - https://www.example.com/rover1.jpg
                      - https://www.example.com/rover2.jpg
                    status: pending
```

---

### !!steps `paths[/pet].post.requestBody`

This operation includes both request body and response examples.

```yaml ! openapi.yaml
# !focus(9,15,34,41)
```

---

### !!steps `examples.fido`

An `addPet` operation `fido` test is created with example request body and response data.

```yaml ! openapi.yaml
# !focus(16:23,42:50)
```

---

### !!steps `examples.rover`

An `addPet` operation `rover` test is created with example request body and response data.

```yaml ! openapi.yaml
# !focus(24:32,51:60)
```

---

</ScrollyCoding>

#### Ignoring Data

Data properties can be explicitly ignored in testing via the `x-speakeasy-test-ignore` annotation.

In this example, the `other` property will be omitted from test generation:

```yaml
paths:
  /example:
    get:
      # ... other operation configuration ...
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                type: object
                properties:
                  data:
                    type: string
                  other:
                    type: string
                    x-speakeasy-test-ignore: true
```

## Next Steps

- [Setup testing in GitHub Actions](/docs/customize-testing/github-actions)


 This is the content for the doc docs/customize-testing/github-actions.mdx 

 ---
title: "Testing in GitHub Actions"
description: "Learn how to customize testing for your API and SDKs in GitHub Actions."
---

import { Callout } from '~/components';

# Testing in GitHub Actions

Automatically run Speakeasy tests on SDK pull requests or other events in a GitHub repository via GitHub Actions.

<Screenshot
  darkened
  url="github.com"
>
  ![A screenshot of a successful test check](../assets/configure-github/testing-run.png)
</Screenshot>


## Setting up a Github Actions Check

This requires you to have previously completed the [Github Setup](/docs/manage/github-setup).
Assuming that has been completed navigate to your SDK repository and run the following command:

```bash
# It's okay to run this command multiple times if you have already configured tests locally
speakeasy configure tests
```


This will produce a Github Actions workflow like the following that allows you to run SDK tests as a Github check on your Pull Requests.

```yaml
name: Test SDKs
permissions:
  checks: write
  contents: write
  pull-requests: write
  statuses: write

on:
  workflow_dispatch:
    inputs:
      target:
        description: Specific target to test
        type: string
  pull_request:
    paths:
      - '**'
    branches:
      - main
jobs:
  test:
    uses: speakeasy-api/sdk-generation-action/.github/workflows/sdk-test.yaml@v15
    with:
      target: ${{ github.event.inputs.target }}
    secrets:
      github_access_token: ${{ secrets.GITHUB_TOKEN }}
      speakeasy_api_key: ${{ secrets.SPEAKEASY_API_KEY }}
```


## Ensuring Tests Run on Automated PR Creation

<Callout title="Warning" variant="warning">

  Pull requests created by the action using the default GITHUB_TOKEN cannot trigger other workflows. 
  When you have on: pull_request or on: push workflows acting as checks on pull requests, they will not run by default.

</Callout>

To ensure that your testing checks run by default when an SDK PR is created you must implement one of the following options.

### Installing the Speakeasy Github App

If you install the Speakeasy Github App and give the App access to your SDK repository, the app will be able to trigger testing runs after a PR is created.
To install the app visit this [link](https://github.com/apps/speakeasy-github) or following instructions in the CLI or dashboard.

### Setting up your own Github PAT

If you choose not to install the Github App, another option is to create your own Github Personal Access Token (PAT) that will be used to create PRs in your SDK repository.
This is a workaround [recommended](https://docs.github.com/en/actions/writing-workflows/choosing-when-your-workflow-runs/triggering-a-workflow#triggering-a-workflow-from-a-workflow) by Github.

1. Create your [fine-grained](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens#creating-a-fine-grained-personal-access-token) PAT with `Pull requests Read/Write` permissions. Make sure it at least has access to your SDK repository. We also recommend setting this to no expiration.

<Screenshot
  darkened
  url="github.com"
>
  ![Setting up your PAT](../assets/configure-github/pr-pat-part1.png)
</Screenshot>

<Screenshot
  darkened
  url="github.com"
>
  ![Providing access to a specific repo](../assets/configure-github/pr-pat-part2.png)
</Screenshot>

<Screenshot
  darkened
  url="github.com"
>
  ![Pull request permissions](../assets/configure-github/pr-pat-part3.png)
</Screenshot>

2. In all of your SDK repositories navigate to `Settings > Secrets and variables > Actions` and save your PAT as a Repository secret under the name `PR_CREATION_PAT`.

<Screenshot
  darkened
  url="github.com"
>
  ![Providing access to a specific repo](../assets/configure-github/pr-creation-token.png)
</Screenshot>

3. In all of your for sdk_generation.yaml workflows add the `pr-creation-token` as a provided secret at the bottom.

```yaml
# !focus(4)
secrets:
  github_access_token: ${{ secrets.GITHUB_TOKEN }}
  speakeasy_api_key: ${{ secrets.SPEAKEASY_API_KEY }}
  pr_creation_pat: ${{ secrets.PR_CREATION_PAT }}
```

## Running in Direct mode

If your generation action is running in `direct` mode where SDK updates get immediately pushed to main, testing will run as part of the generation action.
If tests fail, the generation action will fail and not push your SDK changes to main.

 This is the content for the doc docs/customize/authentication/configuration.mdx 

 ---
slug: "/authentication-configuration"
sidebar_label: Customize Authentication
description: "Customize your security and authentication SDK settings for OAuth."
---

import { Tabs } from "@speakeasy/nextra-theme";
import { Callout } from "~/components";

# Customize Security and Authentication

## Scope Authentication

### Global

Global security allows users to configure the SDK once and reuse the security configuration for all subsequent calls.

To use global security, define the security configuration in the `security` block at the root of the SDK.

```yaml
paths:
  /drinks:
    get:
      operationId: listDrinks
      summary: Get a list of drinks.
      description: Get a list of drinks, if authenticated this will include stock levels and product codes otherwise it will only include public information.
      tags:
        - drinks
components:
  securitySchemes:
    api_key:
      type: apiKey
      name: api_key
      in: header
security: # Here
  - api_key: []
```

In the resulting SDK, the user can define the security configuration in the SDK's instantiation. It will then be automatically applied to all subsequent method calls without needing to be passed in as an argument:

<Tabs items={['TypeScript', 'Python', 'Go', 'Java', 'C#']}>

<Tabs.Tab>

```typescript
import { SDK } from "speakeasy";

async function run() {
  const sdk = new SDK({
    apiKey: "<YOUR_API_KEY_HERE>",
  });

  const result = await sdk.drinks.listDrinks();

  // Handle the result
  console.log(result);
}

run();
```

</Tabs.Tab>

<Tabs.Tab>

```python
import sdk

s = sdk.SDK(
    api_key="<YOUR_API_KEY_HERE>",
)


res = s.drinks.list_drinks()

if res.drinks is not None:
    # handle response
    pass
```

</Tabs.Tab>

<Tabs.Tab>

```go
package main

import (
	"context"
	"log"
	"speakeasy"
	"speakeasy/models/components"
)

func main() {
	s := speakeasy.New(
		speakeasy.WithSecurity("<YOUR_API_KEY_HERE>"),
	)

	ctx := context.Background()
	res, err := s.Drinks.ListDrinks(ctx)
	if err != nil {
		log.Fatal(err)
	}
	if res.Drinks != nil {
		// handle response
	}
}
```

</Tabs.Tab>

<Tabs.Tab>

```java
package hello.world;

import dev.speakeasyapi.speakeasy.SDK;
import dev.speakeasyapi.speakeasy.models.components.*;
import dev.speakeasyapi.speakeasy.models.components.Security;
import dev.speakeasyapi.speakeasy.models.operations.*;
import dev.speakeasyapi.speakeasy.models.operations.ListDrinksResponse;
import java.math.BigDecimal;
import java.math.BigInteger;
import java.time.LocalDate;
import java.time.OffsetDateTime;
import java.util.Optional;
import static java.util.Map.entry;

public class Application {

    public static void main(String[] args) {
        try {
            SDK sdk = SDK.builder()
                .apiKey("<YOUR_API_KEY_HERE>")
                .build();

            ListDrinksResponse res = sdk.drinks().listDrinks()
                .call();

            if (res.drinks().isPresent()) {
                // handle response
            }
        } catch (dev.speakeasyapi.speakeasy.models.errors.SDKError e) {
            // handle exception
        } catch (Exception e) {
            // handle exception
        }
    }
}
```

</Tabs.Tab>

<Tabs.Tab>

```csharp
using Speakeasy;
using Speakeasy.Models.Components;

var sdk = new SDK(
    security: new Security() { ApiKey = "<YOUR_API_KEY_HERE>" }
);

try
{
    var res = await sdk.Drinks.ListDrinksAsync();

    if (res.Drinks != null)
    {
        // handle response
    }
}
catch (Exception ex)
{
   // handle exception
}
```

</Tabs.Tab>

</Tabs>

### Per-Operation Security

<Callout title="NOTE" variant="info">

**Security Hoisting:** In cases where global security is **not** defined, Speakeasy automatically hoists the most commonly occurring operation-level security to be considered global. This will simplify SDK usage.

</Callout>

Operation-specific security configuration overrides the default authentication settings for an endpoint. This is commonly used for operations that do not require authentication or are part of an authentication flow, such as obtaining a short-lived access token.

Define `security` within an operation's scope to apply operation-specific security:

```yaml
paths:
  /drinks:
    get:
      operationId: listDrinks
      summary: Get a list of drinks.
      description: Get a list of drinks, if authenticated this will include stock levels and product codes otherwise it will only include public information.
      security: # Here
        - apiKey: []
      tags:
        - drinks
components:
  securitySchemes:
    api_key:
      type: apiKey
      name: api_key
      in: header
security:
  - {}
```

In the SDK, the user can pass in a specific security configuration as an argument to the method call:

<Tabs items={['TypeScript', 'Python', 'Go', 'Java', 'C#']}>

<Tabs.Tab>

```typescript
import { SDK } from "speakeasy";

async function run() {
  const sdk = new SDK();

  const operationSecurity = "<YOUR_API_KEY_HERE>";

  const result = await sdk.drinks.listDrinks(operationSecurity);

  // Handle the result
  console.log(result);
}

run();
```

</Tabs.Tab>

<Tabs.Tab>

```python
import sdk

s = sdk.SDK()

res = s.drinks.list_drinks("<YOUR_API_KEY_HERE>")

if res.drinks is not None:
    # handle response
    pass
```

</Tabs.Tab>

<Tabs.Tab>

```go
package main

import (
	"context"
	"log"
	"speakeasy"
	"speakeasy/models/operations"
)

func main() {
	s := speakeasy.New()

	operationSecurity := operations.ListDrinksSecurity{
		APIKey: "<YOUR_API_KEY_HERE>",
	}

	ctx := context.Background()
	res, err := s.Drinks.ListDrinks(ctx, operationSecurity)
	if err != nil {
		log.Fatal(err)
	}
	if res.Drinks != nil {
		// handle response
	}
}
```

</Tabs.Tab>

<Tabs.Tab>

```java
package hello.world;

import dev.speakeasyapi.speakeasy.SDK;
import dev.speakeasyapi.speakeasy.models.components.*;
import dev.speakeasyapi.speakeasy.models.components.Security;
import dev.speakeasyapi.speakeasy.models.operations.*;
import dev.speakeasyapi.speakeasy.models.operations.ListDrinksResponse;
import java.math.BigDecimal;
import java.math.BigInteger;
import java.time.LocalDate;
import java.time.OffsetDateTime;
import java.util.Optional;
import static java.util.Map.entry;

public class Application {

    public static void main(String[] args) {
        try {
            SDK sdk = SDK.builder()
                .build();

            ListDrinksResponse res = sdk.drinks().listDrinks()
                .security(ListDrinksSecurity.builder()
                    .apiKey("<YOUR_API_KEY_HERE>")
                    .build())
                .call();

            if (res.drinks().isPresent()) {
                // handle response
            }
        } catch (dev.speakeasyapi.speakeasy.models.errors.SDKError e) {
            // handle exception
        } catch (Exception e) {
            // handle exception
        }
    }
}
```

</Tabs.Tab>

<Tabs.Tab>

```csharp
using Speakeasy;
using Speakeasy.Models.Components;

var sdk = new SDK(
    security: new Security() { ApiKey = "<YOUR_API_KEY_HERE>" }
);

try
{
    var res = await sdk.Drinks.ListDrinksAsync();

    if (res.Drinks != null)
    {
        // handle response
    }
}
catch (Exception ex)
{
   // handle exception
}
```

</Tabs.Tab>

</Tabs>

## Environment Variables

A common pattern for setting global parameters and security options in an SDK is by using environment variables. Speakeasy supports this with environment variable prefixes. To enable this feature, set the `envVarPrefix` variable in the language section of the SDK's `gen.yaml` file.

Global parameters can then be provided via environment variables in the format `{PREFIX}_{GLOBALNAME}`. Documentation for this will be automatically included in the README.

Security options can also be set via environment variables if not provided directly to the SDK. For example, a security field like `api_key` can be set with the variable `{PREFIX}_{API_KEY}`.

```ts
const SDK = new SDK({
  apiKey: process.env["SDK_API_KEY"] ?? "",
});
```

<Callout title="NOTE" variant="info">

Note: In some cases, adding `envVarPrefix` may alter the structure of security options. Required global security will become optional to allow setting it via environment variables.

</Callout>

For details on enabling this feature during generation, see the language-specific `gen.yaml` [configuration reference](/docs/speakeasy-reference/generation/gen-yaml).


 This is the content for the doc docs/customize/authentication/custom-security-schemes.mdx 

 ---
slug: "custom-schemes"
sidebar_label: Customize Security Schemes
description: "Customize your security and authentication SDK settings for OAuth."
---

import { Tabs } from "@speakeasy/nextra-theme";
import { Callout } from "~/components";

# Custom Security Schemes

Custom Security Schemes define a JSON Schema for SDK security options. Combined with [SDK Hooks](/docs/customize/code/sdk-hooks), custom authentication and authorization schemes can be implemented beyond OpenAPI's capabilities.

<Callout title="Availability" variant="info">
  Custom Security Schemes are only available for [Business and Enterprise users](/pricing).

</Callout>

### Language support

| TypeScript | Python | Go  | C#  | Java | PHP | Swift | Ruby |
| ---------- | ------ | --- | --- | ---- | --- | ----- | ---- |
| ✅         | ✅     | ✅  | 🏗️  | 🏗️   | 🏗️  | 🏗️    | 🏗️   |

### Define a custom security scheme

Define the custom security scheme under `components -> securitySchemes` and reference it in the `security` section. Set the `type` to `http` and the `scheme` to `custom`. Use the `x-speakeasy-custom-security-scheme` extension to specify a JSON Schema. This schema must include at least one property and can accommodate multiple properties with different schema definitions.

```yaml
openapi: 3.1.0
info:
  title: Custom Security Scheme Example
  version: 1.0.0
security:
  - myCustomScheme: [] # reference to the custom security scheme defined below
# ...
components:
  securitySchemes:
    myCustomScheme: # defined as usual under components -> securitySchemes
      type: http
      scheme: custom # type: http, scheme: custom is used to identify the custom security scheme
      x-speakeasy-custom-security-scheme: # A JSON Schema is then provided via the x-speakeasy-custom-security-scheme extension
        schema:
          type: object # the JSON Schema MUST be defined as an object with at least one property, but can then have any number of properties with any schema
          properties:
            appId:
              type: string
              example: app-speakeasy-123
            secret:
              type: string
              example: MTIzNDU2Nzg5MDEyMzQ1Njc4OTAxMjM0NTY3ODkwMTI
          required:
            - appId
            - secret
```

### Initialize the custom security scheme

Once the SDK is regenerated, the custom security scheme can be configured globally or per operation, depending on the `security` definitions.

<Tabs items={['TypeScript', 'Python', 'Go']}>

<Tabs.Tab>
```typescript
import { SDK } from "openapi";

const sdk = new SDK({
security: {
appId: "app-speakeasy-123",
secret: "MTIzNDU2Nzg5MDEyMzQ1Njc4OTAxMjM0NTY3ODkwMTI",
},
});

```
</Tabs.Tab>
<Tabs.Tab>
```python
import openapi
from openapi import SDK

s = SDK(
  security=openapi.Security(
      app_id="app-speakeasy-123",
      secret="MTIzNDU2Nzg5MDEyMzQ1Njc4OTAxMjM0NTY3ODkwMTI",
  ),
)
````

</Tabs.Tab>
<Tabs.Tab>
```go
package main

import (
	"context"
	"log"
	"openapi"
	"openapi/models/components"
)

s := openapi.New(
openapi.WithSecurity(components.Security{
AppID: "app-speakeasy-123",
Secret: "MTIzNDU2Nzg5MDEyMzQ1Njc4OTAxMjM0NTY3ODkwMTI",
}),
)

```
</Tabs.Tab>
</Tabs>

### Use the custom security scheme

Use [SDK Hooks](/docs/customize/code/sdk-hooks) to access user-provided security values and enable custom authentication workflows, like adding headers to requests.

The following example illustrates accessing a custom security scheme in a hook and adding headers to a request:

<Tabs items={['TypeScript', 'Python', 'Go']}>

<Tabs.Tab>
```typescript
import { Security$outboundSchema } from "../models/components/security.js";
import { BeforeRequestContext, BeforeRequestHook } from "./types.js";

export class CustomSecurityHook implements BeforeRequestHook {
  beforeRequest(hookCtx: BeforeRequestContext, request: Request): Request {
    let sec = hookCtx.securitySource;
    if (typeof sec === "function") {
      sec = sec();
    }
    if (!sec) {
      throw new Error("security source is not defined");
    }

    // Use the Zod schema to parse the security object
    const customSec = Security$outboundSchema.parse(sec);

    // Access the values from the parsed object and add them to the request headers
    request.headers.set("X-Security-App-Id", customSec.appId);
    request.headers.set("X-Security-Secret", customSec.secret);

    return request;
  }
}
```

</Tabs.Tab>
<Tabs.Tab>
```python
import requests
from openapi import SDK
from typing import Union
from .types import BeforeRequestContext, BeforeRequestHook

class CustomSecurityHook(BeforeRequestHook):
def before_request(self, hook_ctx: BeforeRequestContext, request: requests.PreparedRequest) -> Union[requests.PreparedRequest, Exception]:
security = hook_ctx.security_source

    if not security.app_id or not security.secret:
        raise ValueError("Missing security credentials")

    # Add security headers to the request
    request.headers["X-Security-App-Id"] = security.app_id
    request.headers["X-Security-Secret"] = security.secret

    return request

```
</Tabs.Tab>
<Tabs.Tab>
```go
package hooks

import (
	"errors"
	"net/http"
	"openapi/models/components"
)

type CustomSecurityHook struct{}

func (h *CustomSecurityHook) BeforeRequest(hookCtx BeforeRequestContext, req *http.Request) (*http.Request, error) {
	// Access security values from hookCtx.Security
	security, ok := hookCtx.Security.(*components.Security)
	if !ok {
		return nil, errors.New("security context is not properly defined")
	}

	appId := security.GetAppID()
	secret := security.GetSecret()

	if appId == "" || secret == "" {
		return nil, errors.New("missing security credentials")
	}

	// Add security values to the request headers
	req.Header.Set("X-Security-App-Id", appId)
	req.Header.Set("X-Security-Secret", secret)

	return req, nil
}

```

</Tabs.Tab>
</Tabs>


 This is the content for the doc docs/customize/authentication/oauth.mdx 

 ---
slug: "/oauth"
sidebar_label: OAuth Methods
description: "Customize your security and authentication SDK settings for OAuth."
---

import { Tabs } from "@speakeasy/nextra-theme";
import { Callout } from "~/components";

# OAuth 2.0 authentication

Speakeasy fully supports the OAuth 2.0 security implementation. This includes type generation for OAuth schemas and in many cases
the complete management of the token refresh flow. End users of Speakeasy SDKs don’t need to retrieve and manage access tokens manually.

API builders also have the option to leverage Speakeasy's [custom security schemes](./custom-security-schemes.mdx`) to implement custom OAuth flows that aren't part of
the standard OpenAPI specification.

This document covers the following types of OAuth 2.0 flows:

| Oauth 2.0 type               | Description                                                                                 | 
| ---------------------------- | --------------------------------------------------------------------------------------------|
| `client credentials`         | [Docs](#client-credentials-flow)         |   
| `authorization flow`         | [Docs](#authorization-code-flow)         | 
| `resource owner password credentials flow`      | [Docs](#resource-owner-password-credentials-flow)                   |
| `custom token refresh flow`  | [Docs](#custom-refresh-token-flow)       |

Other custom flows can be implemented using a combination of [hooks](/docs/customize/code/sdk-hooks) and [custom security schemes](/docs/customize/authentication/custom-security-schemes).      

## Client credentials flow

OAuth 2.0 defines several methods for building a request to the `tokenUrl` endpoint.

| Client authentication method | Description                                                                                  | Speakeasy support |
| ---------------------------- | -------------------------------------------------------------------------------------------- | ----------------- |
| `client_secret_post`         | The secret is provided in the request body as `application/x-www-form-urlencoded` form data  | ✅                |
| `client_secret_basic`        | The secret is provided in the `Authorization` header using the `Basic` authentication scheme | ✅ with hooks     |
| `authorization-code`         | The secret is passed during the code token (see [Authorization](## Authorization code flow)) | ✅ with hooks     |
| Other                        |                                                                                              | ✅ with hooks and [custom security schemes](./custom-security-schemes.mdx)    |

Define `type: oauth2` and `flows: clientCredentials` to prompt users for a client ID and client secret when instantiating the SDK. The client credentials flow is used to obtain an access token for API requests.

```yaml
paths:
  /drinks:
    get:
      operationId: listDrinks
      summary: Get a list of drinks.
      description: Get a list of drinks, if authenticated this will include stock levels and product codes otherwise it will only include public information.
      security:
        - clientCredentials:
            - read:drinks
      tags:
        - drinks
components:
  securitySchemes:
    clientCredentials:
      type: oauth2
      flows:
        clientCredentials:
          tokenUrl: https://speakeasy.bar/oauth2/token/
          scopes: {}
security:
  - clientCredentials:
      - read:basic
```

Global scopes defined for the OAuth 2.0 scheme are requested alongside any operation-specific scopes when making API requests.

To enable client credentials flow in the SDK, add the following to the `gen.yaml` file:

```yaml
configVersion: 2.0.0
generation:
  auth:
    OAuth2ClientCredentialsEnabled: true
```

<Tabs items={['TypeScript', 'Python', 'Go', 'Java', 'C#']}>

<Tabs.Tab>

```typescript
import { SDK } from "speakeasy";

async function run() {
  const sdk = new SDK({
    security: {
      clientID: "<YOUR_CLIENT_ID_HERE>",
      clientSecret: "<YOUR_CLIENT_SECRET_HERE>",
    },
  });

  const result = await sdk.drinks.listDrinks();

  // Handle the result
  console.log(result);
}

run();
```

</Tabs.Tab>

<Tabs.Tab>

```python
import speakeasy
from speakeasy.models import components

s = speakeasy.SDK(
    security=components.Security(
        client_id="<YOUR_CLIENT_ID_HERE>",
        client_secret="<YOUR_CLIENT_SECRET_HERE>",
    ),
)


res = s.drinks.list_drinks()

if res.drinks is not None:
    # handle response
    pass
```

</Tabs.Tab>

<Tabs.Tab>

```go
package main

import (
	"context"
	"log"
	"speakeasy"
	"speakeasy/models/components"
)

func main() {
	s := speakeasy.New(
		speakeasy.WithSecurity(components.Security{
			ClientID:     "<YOUR_CLIENT_ID_HERE>",
			ClientSecret: "<YOUR_CLIENT_SECRET_HERE>",
		}),
	)

	ctx := context.Background()
	res, err := s.Drinks.ListDrinks(ctx)
	if err != nil {
		log.Fatal(err)
	}
	if res.Drinks != nil {
		// handle response
	}
}
```

</Tabs.Tab>

<Tabs.Tab>

```java
package hello.world;

import dev.speakeasyapi.speakeasy.SDK;
import dev.speakeasyapi.speakeasy.models.components.*;
import dev.speakeasyapi.speakeasy.models.components.Security;
import dev.speakeasyapi.speakeasy.models.operations.*;
import dev.speakeasyapi.speakeasy.models.operations.ListDrinksResponse;
import java.math.BigDecimal;
import java.math.BigInteger;
import java.time.LocalDate;
import java.time.OffsetDateTime;
import java.util.Optional;
import static java.util.Map.entry;

public class Application {

    public static void main(String[] args) {
        try {
            SDK sdk = SDK.builder()
                .clientCredentials(ClientCredentials.builder()
                    .clientID("<YOUR_CLIENT_ID_HERE>")
                    .clientSecret("<YOUR_CLIENT_SECRET_HERE>")
                    .build())
                .build();

            ListDrinksResponse res = sdk.drinks().listDrinks()
                .call();

            if (res.drinks().isPresent()) {
                // handle response
            }
        } catch (dev.speakeasyapi.speakeasy.models.errors.SDKError e) {
            // handle exception
        } catch (Exception e) {
            // handle exception
        }
    }
}
```

</Tabs.Tab>

<Tabs.Tab>

```csharp
using Speakeasy;
using Speakeasy.Models.Components;

var sdk = new SDK(
    security: new Security()
    {
        ClientID = "<YOUR_CLIENT_ID_HERE>",
        ClientSecret = "<YOUR_CLIENT_SECRET_HERE>"
    }
);

try
{
    var res = await sdk.Drinks.ListDrinksAsync();

    if (res.Drinks != null)
    {
        // handle response
    }
}
catch (Exception ex)
{
   // handle exception
}
```

</Tabs.Tab>

</Tabs>

## Resource Owner Password Credentials flow
Also known informally as OAuth 2.0 Password flow.

Resource Owner Password Credentials (ROPC) flow is designed for obtaining access tokens directly in exchange for a username and password. 

Below is an example of how ROPC Flow is configured in `openapi.yaml`. You'll note that 
`oauth2` security scheme is linked to the `listProducts` operation and that the scope `products:read` is 
required by the `listProducts` operation.

```yaml
paths:
  /products:
    get:
      operationId: listProducts
      summary: List all products.
      responses:
        "200":
          description: Successful response.
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/Products"
      security:
        - oauth2: [products:read]

components:
  securitySchemes:
      oauth2:
        type: oauth2
        flows:
          password:
            tokenUrl: http://localhost:35456/oauth2/token
            scopes:
              products:read: Permission to read/list products
              products:create: Permission to create products
              products:delete: Permission to delete products
              admin: Full permission including managing product inventories
```
To enable OAuth 2.0 ROPC flow in the SDK, add the following to the `gen.yaml` file:
```yaml
configVersion: 2.0.0
generation:
  auth:
    OAuth2PasswordEnabled: true
```

When making a call using this flow, the SDK security is configured with these parameters:

| Parameter                    | Notes                                                                                  | 
| ---------------------------- | --------------------------------------------------------------------------------------------|
| `username`         | mandatory         |   
| `password`         | mandatory         | 
| `clientID`         | optional          |
| `clientSecret`     | optional          |

Below are usage examples in different languages:

<Tabs items={['TypeScript','Java']}>
<Tabs.Tab>
```typescript Typescript
const sdk = new SDK({
    oauth2: {
      username: "testuser",
      password: "testpassword",
      clientID: "beezy",
      clientSecret: "secret",
    }
  });

const result = await sdk.listProducts();
```
</Tabs.Tab>
<Tabs.Tab>
```java Java
SDK sdk = SDK.builder() 
    .oauth2(Oauth2Input.of( 
        Oauth2Credentials.builder()
            .username("testuser") 
            .password("testpassword") 
            .clientID("beezy") 
            .clientSecret("secret") 
            .build()))
    .build();
ListProductsResponse res = sdk.listProducts().call();
```
</Tabs.Tab>
</Tabs>

It is also possbile to bypass token retrievals by passing an explicit token to the SDK object:

<Tabs items={['TypeScript','Java']}>
<Tabs.Tab>
```typescript Typescript
const sdk = new SDK({
    oauth2: "THE_TOKEN"
}};

const result = await sdk.listProducts();
```
</Tabs.Tab>
<Tabs.Tab>
```java Java
SDK sdk = SDK.builder() 
    .oauth2(Oauth2Input.of("THE_TOKEN"))
    .build();
ListProductsResponse res = sdk.listProducts().call();
```
</Tabs.Tab>
</Tabs>

## Authorization code flow

Authorization code flows can vary in implementation, but there are typically some secret values that need to be passed during the code token exchange.

The format for the secret values can also vary but a very common format is:

```html
<Term>
  <Base64><Client ID />:<Client Secret /></Base64
></Term>
```

- `<Term>` often being `Basic` or `Bearer`
- The following string being some format of Client ID and Client Secret, combined with a `:` and then base64 encoded.

To allow for any possible formatting Speakeasy offers support for Hooks, these hooks allow you to alter a request before it is sent to the server.

For this example we will be using the names `id` and `secret`, but you can use any names you like.

First we will define a custom security schema, documention for that [can be found here](/docs/customize/authentication/custom-security-schemes)

```yaml
tokenRequest:
  type: http
  scheme: custom
  x-speakeasy-custom-security-scheme:
    schema:
      properties:
        id:
          type: string
          example: app-speakeasy-123
        secret:
          type: string
          example: MTIzNDU2Nzg5MDEyMzQ1Njc4OTAxMjM0NTY3ODkwMTI
      required:
        - id
        - secret
  description: The string `Basic` with your ID and Secret separated with colon (:), Base64-encoded. For example, Client_ID:Client_Secret Base64-encoded is Q2xpZW50X0lEOkNsaWVudF9TZWNyZXQ=.
```

This security schema will then be applied to our OAuth token exchange endpoint.

```yaml
paths:
  /oauth/token:
    post:
      tags:
        - OAuth2
      summary: OAuth2 Token
      description: Get an OAuth2 token for the API.
      operationId: getToken
      security:
        - tokenRequest: []
```

This custom security schema allows us to supply the Id and Secret needed for the token exchange directly to that method, and generate the unique header value needed with a hook.

Next we add the hook to generate that header.

<Tabs items={['Typescript']}>

<Tabs.Tab>

```typescript
import type {BeforeRequestContext, BeforeRequestHook, Hooks} from "./types.js";
import {GetTokenSecurity} from "../models/operations/gettoken.js";
import {stringToBase64} from "../lib/base64.js";

class OAuthTokenRequestHook implements BeforeRequestHook {
  beforeRequest(hookCtx: BeforeRequestContext, request: Request): Request {
    switch (hookCtx.operationID) {
      case "getToken": {
        let sec = hookCtx.securitySource;
        if (typeof sec === "function") {
          sec = sec();
        }
        if (!sec) {
          throw new Error("security source is not defined");
        }

        const customSec = sec as GetTokenSecurity;
        const encoded = stringToBase64(
          [customSec.Id || "", customSec.Secret || ""].join(":"),
        );
        request.headers.set("Authorization", `Basic ${encoded}`);

        break;
      }
    }

    return request;
  }
}
```

</Tabs.Tab>

</Tabs>

Now that the hook is added, when you are using the SDK to acquire an OAuth token, you can pass in the values and the hook will generate the special header for you.

<Tabs items={['Typescript']}>

<Tabs.Tab>

```typescript
import { SDK } from "SDK";

const sdk = new SDK();

async function run() {
  const result = await sdk.oAuth2.getToken({
    Id: process.env["SDK_ID"] ?? "",
    Secret: process.env["SDK_SECRET"] ?? "",
  }, {
    grantType: "authorization_code",
    code: "1234567890",
    redirectUri: "https://example.com/oauth/callback",
  });

  // Handle the result
  console.log(result);
}

run();
```

</Tabs.Tab>

</Tabs>

## Custom refresh token flow

To enable custom OAuth refresh token handling, implement [security callbacks](/docs/customize/authentication/security-callbacks) along with additional configuration outside the OpenAPI spec.

### Step 1: Define OAuth security in the OpenAPI spec

```yaml
  /oauth2/token:
    get:
      operationId: auth
      security:
        - []
      responses:
        200:
          description: OK
          content:
            application/json:
              schema:
                type: object
                properties:
                  access_token: string
                required:
                  - access_token
  /example:
    get:
      operationId: example
      responses:
        200:
          description: OK
components:
  securitySchemes:
    auth:
      type: oauth2
      flows:
        clientCredentials:
          tokenUrl: https://speakeasy.bar/oauth2/token/
          scopes: {}
security:
  - auth: []
```

### Step 2: Add a callback function to the SDK

Add a file called `oauth` with the appropriate file extension for the programming language (for example, `oauth.ts` for TypeScript, `oauth.py` for Python, `oauth.go` for Go, and so on) to implement OAuth token exchange logic.

<Tabs items={['TypeScript', 'Typescript-Axios (v1)', 'Python', 'Go', 'Java', 'C#']}>

<Tabs.Tab>

```typescript
import * as z from "zod";
import { SDK_METADATA } from "./lib/config";

// TypeScript SDKs use Zod for runtime data validation. We can use Zod
// to describe the shape of the response from the OAuth token endpoint. If the
// response is valid, Speakeasy can safely access the token and its expiration time.
const tokenResponseSchema = z.object({
  access_token: z.string(),
  expires_in: z.number().positive(),
});

// This is a rough value that adjusts when we consider an access token to be
// expired. It accounts for clock drift between the client and server
// and slow or unreliable networks.
const tolerance = 5 * 60 * 1000;

/**
 * A callback function that can be used to obtain an OAuth access token for use
 * with SDKs that require OAuth security. A new token is requested from the
 * OAuth provider when the current token has expired.
 */
export function withAuthorization(
  clientID: string,
  clientSecret: string,
  options: { tokenStore?: TokenStore; url?: string } = {},
) {
  const {
    tokenStore = new InMemoryTokenStore(),
    // Replace this with your default OAuth provider's access token endpoint.
    url = "https://oauth.example.com/token",
  } = options;

  return async (): Promise<string> => {
    const session = await tokenStore.get();

    // Return the current token if it has not expired yet.
    if (session && session.expires > Date.now()) {
      return session.token;
    }

    try {
      const response = await fetch(url, {
        method: "POST",
        headers: {
          "content-type": "application/x-www-form-urlencoded",
          // Include the SDK's user agent in the request so requests can be
          // tracked using observability infrastructure.
          "user-agent": SDK_METADATA.userAgent,
        },
        body: new URLSearchParams({
          client_id: clientID,
          client_secret: clientSecret,
          grant_type: "client_credentials",
        }),
      });

      if (!response.ok) {
        throw new Error("Unexpected status code: " + response.status);
      }

      const json = await response.json();
      const data = tokenResponseSchema.parse(json);

      await tokenStore.set(
        data.access_token,
        Date.now() + data.expires_in * 1000 - tolerance,
      );

      return data.access_token;
    } catch (error) {
      throw new Error("Failed to obtain OAuth token: " + error);
    }
  };
}

/**
 * A TokenStore is used to save and retrieve OAuth tokens for use across SDK
 * method calls. This interface can be implemented to store tokens in memory,
 * a shared cache like Redis or a database table.
 */
export interface TokenStore {
  get(): Promise<{ token: string; expires: number } | undefined>;
  set(token: string, expires: number): Promise<void>;
}

/**
 * InMemoryTokenStore holds OAuth access tokens in memory for use by SDKs and
 * methods that require OAuth security.
 */
export class InMemoryTokenStore implements TokenStore {
  private token = "";
  private expires = Date.now();

  constructor() {}

  async get() {
    return { token: this.token, expires: this.expires };
  }

  async set(token: string, expires: number) {
    this.token = token;
    this.expires = expires;
  }
}
```

</Tabs.Tab>

<Tabs.Tab>

```typescript
import axios from "axios";

// eslint-disable-next-line @typescript-eslint/no-unused-vars
export function withAuthorization(clientID: string, clientSecret: string) {
  return async (): Promise<{ auth: string }> => {
    const tokenEndpoint = "https://speakeasy.bar/oauth2/token/";
    const data = {
      grant_type: "client_credentials",
      client_id: clientID,
      client_secret: clientSecret,
    };
    try {
      const response = await axios.post(tokenEndpoint, data);
      return { auth: response.data.access_token };
    } catch (error) {
      throw new Error("Failed to obtain OAuth token");
    }
  };
}
```

</Tabs.Tab>

<Tabs.Tab>

```python
import requests
from sdk.components import Security


def with_authorization(client_id: str, client_secret: str) -> Security:
  token_endpoint = 'https://speakeasy.bar/oauth2/token/'
  data = {
      'grant_type': 'client_credentials',
      'client_id': client_id,
      'client_secret': client_secret,
  }
  try:
      response = requests.post(token_endpoint, data=data)
      response.raise_for_status()
      return Security(auth=response.json()['access_token'])
  except Exception as e:
      raise Exception(f'Failed to obtain OAuth token: {str(e)}')
```

</Tabs.Tab>

<Tabs.Tab>

```go
package speakeasy

import (
	"speakeasy/components"
)

func withAuthorization(clientID string, clientSecret string) func(context.Context) (components.Security, error) {
	return func(ctx context.Context) (components.Security, error) {

      // Please implement callback here

      return components.Security{Auth: "<YOUR_OAUTH_TOKEN>"}, nil
	}
}
```

</Tabs.Tab>

<Tabs.Tab>

```java
import dev.speakeasyapi.speakeasy.SecuritySource;
import dev.speakeasyapi.speakeasy.models.components.Security;


class OAuth implements SecuritySource {

    private String clientID;
    private String clientSecret;

    public OAuth(String clientID, String clientSecret) {
        this.clientID = clientID;
        this.clientSecret = clientSecret;
    }

    public Security getSecurity() {

        // Please implement callback here

        return Security.builder()
            .auth("<YOUR_OAUTH_TOKEN>")
            .build();
    }
}
```

</Tabs.Tab>

<Tabs.Tab>

```csharp
namespace Speakeasy.Callbacks
{
    using Speakeasy;
    using Speakeasy.Models.Components;

    public static class OAuth
    {

        public static Security withAuthorization(string clientID, string clientSecret)
        {
            // Please implement callback here

            return new Security { Auth = "<YOUR_OAUTH_TOKEN>"}
        }
    }
}
```

</Tabs.Tab>

</Tabs>

### Step 3: Pass the callback function in SDK instantiation

Update the README to show how to pass the callback function when instantiating the SDK:

<Tabs items={['TypeScript', 'Python', 'Go', 'Java', 'C#']}>

<Tabs.Tab>

```typescript
import { SDK } from "speakeasy";

const sdk = new SDK({
  security: withAuthorization("client_id", "client_secret"),
});

await s.drinks.listDrinks();
```

</Tabs.Tab>

<Tabs.Tab>

```python
import sdk

s = sdk.SDK(security=with_authorization("<YOUR_CLIENT_ID>", "<YOUR_CLIENT_SECRET>"))
res = s.drinks.list_drinks()
```

</Tabs.Tab>

<Tabs.Tab>

```go
import (
	"context"
  sdk "speakeasy"
)

s := sdk.New(
    sdk.WithSecuritySource(withAuthorization(
        "<YOUR_CLIENT_ID>",
        "<YOUR_CLIENT_SECRET>",
    )),
)
ctx := context.Background()
s.Drinks.ListDrinks(ctx)
```

</Tabs.Tab>

<Tabs.Tab>

```java
import dev.speakeasyapi.speakeasy.OAuth;
import dev.speakeasyapi.speakeasy.SDK;

OAuth securitySource = new OAuth("<YOUR_CLIENT_ID>", "<YOUR_CLIENT_SECRET>");

SDK s = SDK.builder()
    .securitySource(securitySource)
    .build();

ListDrinksResponse res = s.Drinks.listDrinks().call();
```

</Tabs.Tab>

<Tabs.Tab>

```csharp
using Speakeasy;
using Speakeasy.Callbacks;

var sdk = new SDK(securitySource: OAuth.withAuthorization)

var res = await sdk.Drinks.ListDrinksAsync();
```

</Tabs.Tab>

</Tabs>

## OAuth 2.0 scopes

### Global security with OAuth 2.0 scopes

When defining global security settings for OAuth 2.0, the SDK automatically requests the necessary scopes for all operations. This setup is useful for APIs where most endpoints share the same level of access. Global scopes are defined in the OpenAPI specification and applied to all requests unless specifically overridden.

The following OpenAPI definition applies global OAuth 2.0 scopes:

```yaml
components:
  securitySchemes:
    oauth2:
      type: oauth2
      flows:
        clientCredentials:
          tokenUrl: https://speakeasy.bar/oauth2/token/
          scopes:
            read: Grants read access
            write: Grants write access

security:
  - oauth2:
      - read # Apply the read scope globally
      - write # Apply the write scope globally
```

The SDK automatically generates tokens with both `read` and `write`` scopes. When making a request, the SDK checks whether the token contains the required scopes for the operation. If the token lacks the necessary scopes or has expired, a new token is requested with the correct scopes.

In the SDK, global OAuth 2.0 scopes can be defined when the SDK is instantiated:

```ts
import { SDK } from "speakeasy";

const sdk = new SDK({
  security: {
    clientID: "<YOUR_CLIENT_ID_HERE>",
    clientSecret: "<YOUR_CLIENT_SECRET_HERE>",
    oAuth2Scopes: ["read"], // Global scope applied to all operations by default
  },
});
```

### Per-operation security with OAuth 2.0 scopes

For more control over specific API operations, per-operation security settings can be used. This allows different scopes to be applied to individual operations, overriding the global settings.

The following OpenAPI definition applies an operation-specific OAuth scope for the `listDrinks` operation:

```yaml
paths:
  /drinks:
    get:
      operationId: listDrinks
      summary: Get a list of drinks.
      description: Retrieves a list of drinks, requiring the `read` scope.
      security:
        - oauth2:
            - read # Apply the read scope for this operation
```

In this case, the SDK requests a token with the `read` scope only when calling the `listDrinks` operation. If the token does not meet the required scope for the operation or has expired, the SDK regenerates the token with the correct scope.

Here’s how the SDK can be used with per-operation security:

```ts
import { SDK } from "speakeasy";

const sdk = new SDK({
  security: {
    clientID: "<YOUR_CLIENT_ID_HERE>",
    clientSecret: "<YOUR_CLIENT_SECRET_HERE>",
  },
});

const result = await sdk.drinks.listDrinks({
  security: {
    oAuth2Scopes: ["read"], // Specify the scope for this operation
  },
});
```


 This is the content for the doc docs/customize/authentication/overview.mdx 

 ---
slug: "/authenticate-sdks"
sidebar_label: Customize Authentication
description: "Customize your security and authentication SDK settings for OAuth."
---

import { Tabs } from "@speakeasy/nextra-theme";
import { Callout } from "~/components";

# Security and authentication

## Authentication overview

Speakeasy-created SDKs have authentication automatically configured based on the `securitySchemes` defined in the [OpenAPI specification](/openapi/security).

APIs authenticated with simple schemes, such as Basic HTTP auth, API keys, and bearer tokens, work out of the box. For APIs using short-lived tokens (OAuth), additional configuration is required to simplify setup.

| Authentication Mechanism                           | Language Support                                                                                                  |
| -------------------------------------------------- | ----------------------------------------------------------------------------------                                |
| HTTP Basic authentication                          | ✅  [Docs](/docs/customize/authentication/simple-schemes#basic-http-authentication)                               |
| API key [header, query]                            | ✅  [Docs](/docs/customize/authentication/simple-schemes#api-key-authentication)                                  |
| Bearer Token authentication                        | ✅  [Docs](/docs/customize/authentication/configuration)                                                          |
| OAuth                                              | ✅  [All GA and some beta languages](/docs/customize/authentication/oauth)                                        |
| mTLS                                               | ✅  [Using hooks](/docs/customize/code/sdk-hooks)                                                                 |
| Custom security schemes                            | ✅  [Using Speakeasy custom security schemes extension](/docs/customize/authentication/custom-security-schemes)   |


 This is the content for the doc docs/customize/authentication/security-callbacks.mdx 

 ---
slug: "/security-callbacks"
sidebar_label: Customize Authentication
description: "Customize your security and authentication SDK settings for OAuth."
---

import { Tabs } from "@speakeasy/nextra-theme";

# Security callbacks

Instead of providing credentials once during SDK instantiation, you can pass a custom authentication function that allows end users to manage secrets dynamically. Custom authentication functions can be used to automatically refresh tokens or retrieve secrets from a secret store.

## Language support

| TypeScript | Python | Go  | C#  | Java | PHP | Swift | Ruby |
| ---------- | ------ | --- | --- | ---- | --- | ----- | ---- |
| ✅         | ✅     | ✅  | ✅️ | ✅   | 🏗️  | 🏗️    | 🏗️   |

## Example: Bearer authentication

In this example, bearer authentication is used as the only security scheme:

```yaml
security:
  - bearerAuth: []
components:
  securitySchemes:
    bearerAuth:
      type: http
      scheme: bearer
```

The callback function passed when initializing the SDK acts as a _security source_ and is called whenever a request is made, allowing tokens to be refreshed if needed.

<Tabs items={['TypeScript', 'Python', 'Go', 'Java', 'C#']}>

<Tabs.Tab>

```typescript
import { SDK } from "<packageName>";
import { Security } from "<packageName>/models";

const sdk = new SDK({
  security: async (): Promise<Security> => {
    // refresh token here
    const token = "<YOUR_JWT>";
    return { bearerAuth: token };
  },
});
```

</Tabs.Tab>

<Tabs.Tab>

```python
import requests
import sdk
from sdk.components import Security

def callback() -> Security:
    # refresh token here
    token = "<YOUR_JWT>"
    return Security(bearer_auth=token)

s = sdk.SDK(security=with_authorization(callback))
```

</Tabs.Tab>

<Tabs.Tab>

```go
import (
	"context"
  sdk "speakeasy"
	"speakeasy/components"
)

s := sdk.New(
    sdk.WithSecuritySource(func(ctx context.Context) (components.Security, error) {
        // refresh token here
        token := "<YOUR_JWT>"
        return components.Security{BearerAuth: token}, nil
    }),
)
```

</Tabs.Tab>

<Tabs.Tab>

```java
import dev.speakeasyapi.speakeasy.SDK;
import dev.speakeasyapi.speakeasy.SecuritySource;
import dev.speakeasyapi.speakeasy.models.components.Security;


class BearerSource implements SecuritySource {

    public Security getSecurity() {
        // refresh token here
        return Security.builder()
            .bearerAuth("<YOUR_JWT>")
            .build();
    }
}
```

```java
import dev.speakeasyapi.speakeasy.SDK;
import dev.speakeasyapi.speakeasy.SecuritySource;
import dev.speakeasyapi.speakeasy.models.components.Security;

SDK s = SDK.builder()
    .securitySource(new BearerSource())
    .build();
```

</Tabs.Tab>

<Tabs.Tab>

```csharp
using Speakeasy;
using Speakeasy.Models.Components;


Func<Security> tokenSource = () =>
{
    // refresh token here
    var token = "<YOUR_JWT>"

    return new Security { BearerAuth = token}
}

var sdk = new SDK(securitySource: tokenSource);
```

</Tabs.Tab>

</Tabs>


 This is the content for the doc docs/customize/authentication/simple-schemes.mdx 

 ---
slug: "/simple-schemes"
sidebar_label: Customize Authentication
description: "Customize your security and authentication SDK settings for OAuth."
---

import { Tabs } from "@speakeasy/nextra-theme";
import { Callout } from "~/components";

# Simple security schemes

## Basic HTTP authentication

Basic HTTP authentication is supported in all languages.

Define `type: http` and `scheme: basic` to generate authentication that prompts users for a username and password when instantiating the SDK. The SDK will encode the username and password into a Base64 string and pass it in the `Authorization` header.

```yaml
paths:
  /drinks:
    get:
      operationId: listDrinks
      summary: Get a list of drinks.
      description: Get a list of drinks, if authenticated this will include stock levels and product codes otherwise it will only include public information.
      tags:
        - drinks
components:
  securitySchemes:
    auth:
      type: http
      scheme: basic
security:
  - auth: []
```

<Tabs items={['TypeScript', 'Python', 'Go', 'Java', 'C#']}>

<Tabs.Tab>

```typescript
import { SDK } from "speakeasy";

async function run() {
  const sdk = new SDK({
    security: {
      username: "<YOUR_USERNAME_HERE>",
      password: "<YOUR_PASSWORD_HERE>",
    },
  });

  const result = await sdk.drinks.listDrinks();

  // Handle the result
  console.log(result);
}

run();
```

</Tabs.Tab>

<Tabs.Tab>

```python
import speakeasy
from speakeasy.models import components

s = speakeasy.SDK(
    security=components.Security(
        username="<YOUR_USERNAME_HERE>",
        password="<YOUR_PASSWORD_HERE>",
    ),
)

res = s.drinks.list_drinks()

if res.drinks is not None:
    # handle response
    pass
```

</Tabs.Tab>

<Tabs.Tab>

```go
package main

import (
	"context"
	"log"
	"speakeasy"
	"speakeasy/models/components"
)

func main() {
	s := speakeasy.New(
		speakeasy.WithSecurity(components.Security{
			Username: "<YOUR_USERNAME_HERE>",
			Password: "<YOUR_PASSWORD_HERE>",
		}),
	)

	ctx := context.Background()
	res, err := s.Drinks.ListDrinks(ctx)
	if err != nil {
		log.Fatal(err)
	}
	if res.Drinks != nil {
		// handle response
	}
}
```

</Tabs.Tab>

<Tabs.Tab>

```java
package hello.world;

import dev.speakeasyapi.speakeasy.SDK;
import dev.speakeasyapi.speakeasy.models.components.*;
import dev.speakeasyapi.speakeasy.models.components.Security;
import dev.speakeasyapi.speakeasy.models.operations.*;
import dev.speakeasyapi.speakeasy.models.operations.ListDrinksResponse;
import java.math.BigDecimal;
import java.math.BigInteger;
import java.time.LocalDate;
import java.time.OffsetDateTime;
import java.util.Optional;
import static java.util.Map.entry;

public class Application {

    public static void main(String[] args) {
        try {
            SDK sdk = SDK.builder()
                .security(Security.builder()
                    .username("<YOUR_USERNAME_HERE>")
                    .password("<YOUR_PASSWORD_HERE>")
                    .build())
                .build();

            ListDrinksResponse res = sdk.drinks().listDrinks()
                .call();

            if (res.drinks().isPresent()) {
                // handle response
            }
        } catch (dev.speakeasyapi.speakeasy.models.errors.SDKError e) {
            // handle exception
        } catch (Exception e) {
            // handle exception
        }
    }
}
```

</Tabs.Tab>

<Tabs.Tab>

```csharp
using Speakeasy;
using Speakeasy.Models.Components;

var sdk = new SDK(
    security: new Security()
    {
        Username = "<YOUR_USERNAME_HERE>",
        Password = "<YOUR_PASSWORD_HERE>",
    }
);

try
{
    var res = await sdk.Drinks.ListDrinksAsync();

    if (res.Drinks != null)
    {
        // handle response
    }
}
catch (Exception ex)
{
   // handle exception
}
```

</Tabs.Tab>

</Tabs>

## API key authentication

API key authentication is supported in all languages.

Define `type: apiKey` and `in: [header,query]` to generate authentication that prompts users for a key when instantiating the SDK. The SDK passes the key in a header or query parameter, depending on the `in` property, and uses the `name` field as the header or key name.

```yaml
paths:
  /drinks:
    get:
      operationId: listDrinks
      summary: Get a list of drinks.
      description: Get a list of drinks, if authenticated this will include stock levels and product codes otherwise it will only include public information.
      tags:
        - drinks
      responses:
        "200":
          description:
            OK
            #...
components:
  securitySchemes:
    api_key:
      type: apiKey
      name: api_key
      in: header
security:
  - api_key: []
```

<Tabs items={['TypeScript', 'Python', 'Go', 'Java', 'C#']}>

<Tabs.Tab>

```typescript
import { SDK } from "speakeasy";

async function run() {
  const sdk = new SDK({
    apiKey: "<YOUR_API_KEY_HERE>",
  });

  const result = await sdk.drinks.listDrinks();

  // Handle the result
  console.log(result);
}

run();
```

</Tabs.Tab>

<Tabs.Tab>

```python
import speakeasy

s = speakeasy.SDK(
    api_key="<YOUR_API_KEY_HERE>",
)

res = s.drinks.list_drinks()

if res.drinks is not None:
    # handle response
    pass
```

</Tabs.Tab>

<Tabs.Tab>

```go
package main

import (
	"context"
	"log"
	"speakeasy"
	"speakeasy/models/components"
)

func main() {
	s := speakeasy.New(
		speakeasy.WithSecurity("<YOUR_API_KEY_HERE>"),
	)

	ctx := context.Background()
	res, err := s.Drinks.ListDrinks(ctx)
	if err != nil {
		log.Fatal(err)
	}
	if res.Drinks != nil {
		// handle response
	}
}

```

</Tabs.Tab>

<Tabs.Tab>

```java
package hello.world;

import dev.speakeasyapi.speakeasy.SDK;
import dev.speakeasyapi.speakeasy.models.components.*;
import dev.speakeasyapi.speakeasy.models.components.Security;
import dev.speakeasyapi.speakeasy.models.operations.*;
import dev.speakeasyapi.speakeasy.models.operations.ListDrinksResponse;
import java.math.BigDecimal;
import java.math.BigInteger;
import java.time.LocalDate;
import java.time.OffsetDateTime;
import java.util.Optional;
import static java.util.Map.entry;

public class Application {

    public static void main(String[] args) {
        try {
            SDK sdk = SDK.builder()
                .apiKey("<YOUR_API_KEY_HERE>")
                .build();

            ListDrinksResponse res = sdk.drinks().listDrinks()
                .call();

            if (res.drinks().isPresent()) {
                // handle response
            }
        } catch (dev.speakeasyapi.speakeasy.models.errors.SDKError e) {
            // handle exception
        } catch (Exception e) {
            // handle exception
        }
    }
}
```

</Tabs.Tab>

<Tabs.Tab>

```csharp
using Speakeasy;
using Speakeasy.Models.Components;

var sdk = new SDK(
    security: new Security() { ApiKey = "<YOUR_API_KEY_HERE>" }
);

try
{
    var res = await sdk.Drinks.ListDrinksAsync();

    if (res.Drinks != null)
    {
        // handle response
    }
}
catch (Exception ex)
{
   // handle exception
}
```

</Tabs.Tab>

</Tabs>

## Bearer token authentication

Bearer token authentication is supported in all languages.

Define `type: http` and `scheme: bearer` to generate authentication that prompts users for a token when instantiating the SDK.
The SDK will pass the token in the `Authorization` header using the `Bearer` scheme, appending the `Bearer` prefix to the token if not already present.

```yaml
paths:
  /drinks:
    get:
      operationId: listDrinks
      summary: Get a list of drinks.
      description: Get a list of drinks, if authenticated this will include stock levels and product codes otherwise it will only include public information.
      tags:
        - drinks
components:
  securitySchemes:
    auth:
      type: http
      scheme: bearer
security:
  - auth: []
```

<Tabs items={['TypeScript', 'Python', 'Go', 'Java', 'C#']}>

<Tabs.Tab>

```typescript
import { SDK } from "speakeasy";

async function run() {
  const sdk = new SDK({
    auth: "<YOUR_BEARER_TOKEN_HERE>",
  });

  const result = await sdk.drinks.listDrinks();

  // Handle the result
  console.log(result);
}

run();
```

</Tabs.Tab>

<Tabs.Tab>

```python
import speakeasy

s = speakeasy.SDK(
    auth="<YOUR_BEARER_TOKEN_HERE>",
)

res = s.drinks.list_drinks()

if res.drinks is not None:
    # handle response
    pass
```

</Tabs.Tab>

<Tabs.Tab>

```go
package main

import (
	"context"
	"log"
	"speakeasy"
	"speakeasy/models/components"
)

func main() {
	s := speakeasy.New(
		speakeasy.WithSecurity("<YOUR_BEARER_TOKEN_HERE>"),
	)

	ctx := context.Background()
	res, err := s.Drinks.ListDrinks(ctx)
	if err != nil {
		log.Fatal(err)
	}
	if res.Drinks != nil {
		// handle response
	}
}
```

</Tabs.Tab>

<Tabs.Tab>

```java
package hello.world;

import dev.speakeasyapi.speakeasy.SDK;
import dev.speakeasyapi.speakeasy.models.components.*;
import dev.speakeasyapi.speakeasy.models.components.Security;
import dev.speakeasyapi.speakeasy.models.operations.*;
import dev.speakeasyapi.speakeasy.models.operations.ListDrinksResponse;
import java.math.BigDecimal;
import java.math.BigInteger;
import java.time.LocalDate;
import java.time.OffsetDateTime;
import java.util.Optional;
import static java.util.Map.entry;

public class Application {

    public static void main(String[] args) {
        try {
            SDK sdk = SDK.builder()
                .auth("<YOUR_BEARER_TOKEN_HERE>")
                .build();

            ListDrinksResponse res = sdk.drinks().listDrinks()
                .call();

            if (res.drinks().isPresent()) {
                // handle response
            }
        } catch (dev.speakeasyapi.speakeasy.models.errors.SDKError e) {
            // handle exception
        } catch (Exception e) {
            // handle exception
        }
    }
}
```

</Tabs.Tab>

<Tabs.Tab>

```csharp
using Speakeasy;
using Speakeasy.Models.Components;

var sdk = new SDK(
    security: new Security() { Auth = "<YOUR_BEARER_TOKEN_HERE>" }
);

try
{
    var res = await sdk.Drinks.ListDrinksAsync();

    if (res.Drinks != null)
    {
        // handle response
    }
}
catch (Exception ex)
{
   // handle exception
}
```

</Tabs.Tab>

</Tabs>


 This is the content for the doc docs/customize/basics.mdx 

 ---
 title: "Customization basics"
 description: "Discover recommended and optional customizations you can make to your Speakeasy SDK pipeline to enhance the user experience."
---

# Customization Basics

The Speakeasy SDK pipeline uses sensible defaults to generate SDKs, but various customizations can improve the user experience. Customizations can be applied using the following methods:

1. Modifying the OpenAPI spec.
2. Adding `x-speakeasy` extensions to the OpenAPI spec.
3. Editing the `gen.yaml` file in the SDK repository.

---

## 1. Modifying the OpenAPI Spec

The OpenAPI spec is the foundation of SDK generation. Modifications to the OpenAPI spec influence the structure, naming conventions, and functionality of generated SDKs.

Learn more about OpenAPI in [the reference documentation](/openapi).

### Modifying the OpenAPI Spec With Overlays

Speakeasy supports OpenAPI overlays, which you can use to customize and extend existing OpenAPI specifications without directly modifying them. Overlays are especially useful for applying different configurations or updates to the spec for various environments or SDKs without altering the base spec.

Overlays work by referencing and extending parts of the base OpenAPI spec. They can add, override, or remove elements such as paths, schemas, parameters, or security configurations.

![Screenshot showing a speakeasy extension in VS code editor.](../assets/overlay.png)

[Learn more about overlays](/docs/prep-openapi/overlays/create-overlays).

---

## 2. Using `x-speakeasy` Extensions

Proprietary Speakeasy extensions provide fine-tuned control over the SDK, enabling you to modify behaviors like retries, pagination, error handling, and other advanced SDK features.

Add Speakeasy extensions to the OpenAPI spec. 

![Screenshot showing a speakeasy extension in VS code editor.](../assets/speakeasy-extensions.png)

For a complete list of available extensions, see the [Speakeasy extensions reference](/docs/speakeasy-extensions).

---

## 3. Editing the `gen.yaml` File

Further customize Speakeasy-generated SDKs by editing the `gen.yaml` file, typically located in the `.speakeasy` folder at the root of the SDK. This configuration file contains both language-agnostic and language-specific settings, offering more control over the structure and behavior of the SDK beyond what the OpenAPI spec provides.

Edit the `gen.yaml` file to modify elements like class names, method parameters, and response formatting.

![Screenshot showing the gen.yaml in VS code editor.](../assets/genyaml.png)

For a complete list of available options, refer to the [`gen.yaml` reference](/docs/gen-reference).


 This is the content for the doc docs/customize/code/code-regions/overview.mdx 

 ---
title: Custom code regions
description: "Learn how to use custom code regions to generate code in a specific location."
---

# Custom code regions

import { Callout } from "~/components";

<Callout title="Availability" variant="info">
  Custom code regions are only available for [Enterprise users](/pricing).
</Callout>

Generally, the Speakeasy code generator "owns" the files it generates. If
modifications are made to them, then the next code generation run will overwrite
any edits that were made. One way to persist modifications to generated files is
to add them to `.genignore`, but this has a significant drawback: those files
will stop receiving updates during generation, and thus risk build failures in
the future.

**Custom code regions** allow developers to add code to specific sections of a
generated file that the generator knows to carry forward. Speakeasy can continue
to own and update files while providing a constrained way to add bespoke
functionality to SDKs.

## Syntax

Custom code regions are defined by adding a start and end comments to prescribed
sections of a generated file. The comments follow Visual Studio Code's format
for [creating code folds][vsc-folds].

[vsc-folds]: https://code.visualstudio.com/docs/editor/codebasics#_folding

## Language support

Custom code regions are currently supported in the following languages:

- [Python](/docs/customize/code/code-regions/python)
- [TypeScript](/docs/customize/code/code-regions/typescript)

 This is the content for the doc docs/customize/code/code-regions/python.mdx 

 ---
title: Custom code regions in Python
description: "Learn how to use custom code regions in Python SDKs."
---

# Custom code regions in Python

To enable custom code regions for Python SDKs, update the project's
`.speakeasy/gen.yaml` file like so:

```diff .speakeasy/gen.yaml
configVersion: 2.0.0
generation:
  # ...
python:
  # ...
+ enableCustomCodeRegions: true
```

## Full example

The Speakeasy examples repository has a [full example][example] of a Python SDK
that uses custom code regions.

[example]: https://github.com/speakeasy-api/examples/tree/main/customcode-sdkclasses-python

## Regions

Below are the available code regions in Python SDKs.

### SDK classes

Python SDK classes can have two code regions:

* `# region imports` - allows the addition of imports to an SDK file needed for
custom methods and properties. This region must be located at the top of the
file alongside generated imports.
* `# region sdk-class-body` - allows the addition of custom methods and
properties to an SDK class. This region must be located in the body of a Python
SDK class alongside generated methods and properties.

## Managing dependencies

When adding custom code that requires external packages, you'll need to configure these dependencies in your `.speakeasy/gen.yaml` file to prevent them from being removed during SDK regeneration. Use the `additionalDependencies` configuration to specify your package dependencies:

```yaml .speakeasy/gen.yaml
python:
  additionalDependencies:
    main:
      markdown: "^3.4.0"
      beautifulsoup4: "^4.12.0"
    dev:
      pytest: "^7.0.0"
      black: "^23.0.0"
```

This ensures your dependencies persist across SDK regenerations and are properly included in the generated `pyproject.toml`.

```python src/todos_sdk/todos.py
"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from .basesdk import BaseSDK
from todos_sdk import models, utils
from todos_sdk._hooks import HookContext
from todos_sdk.types import OptionalNullable, UNSET
from typing import Mapping, Optional

# !focus(1:3)
# region imports
import markdown
# endregion imports

class Todos(BaseSDK):
    # !focus(1:7)
    # region sdk-class-body
    def render_todo(self, id: str) -> str:
        todo = self.get_one(id=id)

        return markdown.markdown(f"# {todo.title}\n\n{todo.description}")

    # endregion sdk-class-body

    def get_one(
        self,
        *,
        id: int,
        retries: OptionalNullable[utils.RetryConfig] = UNSET,
        server_url: Optional[str] = None,
        timeout_ms: Optional[int] = None,
        http_headers: Optional[Mapping[str, str]] = None,
    ) -> models.Todo:
        ...


    async def get_one_async(
        self,
        *,
        id: int,
        retries: OptionalNullable[utils.RetryConfig] = UNSET,
        server_url: Optional[str] = None,
        timeout_ms: Optional[int] = None,
        http_headers: Optional[Mapping[str, str]] = None,
    ) -> models.Todo:
        ...
```


 This is the content for the doc docs/customize/code/code-regions/typescript.mdx 

 ---
title: Custom code regions in TypeScript
description: "Learn how to use custom code regions in TypeScript SDKs."
---

# Custom code regions in TypeScript

To enable custom code regions for TypeScript SDKs, update the project's
`.speakeasy/gen.yaml` file like so:

```diff .speakeasy/gen.yaml
configVersion: 2.0.0
generation:
  # ...
typescript:
  # ...
+ enableCustomCodeRegions: true
```

## Full example

The Speakeasy examples repository has a [full example][example] of a TypeScript
SDK that uses custom code regions.

[example]: https://github.com/speakeasy-api/examples/tree/main/customcode-sdkclasses-typescript

## Regions

Below are the available code regions in TypeScript SDKs.

### SDK classes

TypeScript SDK classes can have two code regions:

* `// #region imports` - allows the addition of imports to an SDK file needed for
custom methods and properties. This region must be located at the top of the
file alongside generated imports.
* `// #region sdk-class-body` - allows the addition of custom methods and
properties to an SDK class. This region must be located in the body of a TypeScript
SDK class alongside generated methods and properties.

## Managing dependencies

When adding custom code that requires external packages, you'll need to configure these dependencies in your `.speakeasy/gen.yaml` file to prevent them from being removed during SDK regeneration. Use the `additionalDependencies` configuration to specify your package dependencies:

```yaml .speakeasy/gen.yaml
typescript:
  additionalDependencies:
    dependencies:
      marked: "^5.0.0"
      dompurify: "^3.0.0"
    devDependencies:
      "@types/dompurify": "^3.0.0"
    peerDependencies:
      react: "^18.0.0"
```

This ensures your dependencies persist across SDK regenerations and are properly included in the generated `package.json`.

```typescript src/sdk/todos.ts
/*
 * Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.
 */

import { todosGetOne } from "../funcs/todosGetOne.js";
import { ClientSDK, RequestOptions } from "../lib/sdks.js";
import * as operations from "../models/operations/index.js";
import { unwrapAsync } from "../types/fp.js";

// !focus(1:5)
// #region imports
import DOMPurify from 'dompurify';
import marked from "marked";
import type { Todo } from "../models/components/todo.js"; 
// #endregion imports

export class Todos extends ClientSDK {
  // !focus(1:11)
  // #region sdk-class-body
  async renderTodo(id: string): Promise<string> {
    const todo = await this.getOne({ id });

    const html = await marked.parse(`# ${todo.title}\n\n${todo.description}`, {
      async: true,
    });

    return DOMPurify.sanitize(html);
  }
  // #endregion sdk-class-body

  async getOne(request: operations.TodosGetOneRequest, options?: RequestOptions): Promise<operations.TodosGetOneResponse> {
    return await unwrapAsync(todosGetOne(this, request, options));
  }
}
```


 This is the content for the doc docs/customize/code/monkey-patching.mdx 

 ---
title: "Monkey patching"
description: "Hard-code custom features by overriding the generated SDK with your own code."
slug: "/customize-sdks/monkey-patching/"
---
import { Callout } from '~/components'

# Monkey Patching

<Callout title="CAUTION" variant="warning"> **Advanced Technique:** Monkey patching is an advanced feature and should be used with caution. It requires additional maintenance effort for the SDK and may introduce complexity. </Callout>

Monkey patching allows custom code to override a module, library, or code generator. It can address bugs, add features, or implement workarounds not supported by the original source. In Speakeasy, this means modifying generated SDK code, documentation, or examples.

However, monkey patching increases maintenance effort, potentially causing inconsistencies, failures, and discrepancies in SDKs. Consider the trade-offs carefully, as it can add significant overhead.

## Recommended Use Cases

Monkey patching may be beneficial in these low-impact scenarios:

- Customizing usage snippets or example code.
- Modifying generated documentation.
- Encoding business logic not handled by the API.

When possible, avoid patching generated code or package dependencies, as these changes may introduce issues during SDK generation or lead to failures.

## Mark Files With `.genignore`

To begin monkey patching, add a `.genignore` file to the project. This file behaves similarly to `.gitignore` but signals that the files it matches are managed manually rather than by the SDK generator.

Rules in `.genignore` follow this syntax:

- Blank lines match nothing and improve readability.
- Lines starting with `#` are comments. Escape `#` with a backslash (`\#`) to match a file starting with `#`.
- Trailing spaces are ignored unless escaped with `\`, which preserves spaces.
- Lines starting with `!` denote negative matches (files matching that line will not be ignored).
- Lines ending with `/` match directories only.
- Text is interpreted as a glob (e.g., `*.go` matches all `.go` files).
- Wildcards (`*`, `?`) do not match directory separators.
- `**` matches multiple directory levels.
- Lines starting with `/` match from the current directory.

Once a file is included in `.genignore`, the generator will no longer modify it.

Files generated by Speakeasy include the following header:


```go
// Code generated by Speakeasy (https://www.speakeasyapi.dev). DO NOT EDIT.
```

To mark a file as manually maintained, update the header manually:

```go
// Code originally generated by Speakeasy (https://www.speakeasyapi.dev).
```

## Caveats

Monkey patching can introduce the following issues:

- **Duplicated Code:** Changes in naming conventions during generation may result in duplicate symbols between patches and generated code.
- **Missing Code:** Internal generator changes could lead to symbols being replaced or renamed, causing patches to break.
- **Dead Code:** Patches may become obsolete if no longer referenced by the SDK, leading to unused code.

Each SDK generation event can introduce these or other maintenance challenges. It is recommended to use monkey patching only when necessary.

## Recovering from Monkey Patching Issues

To resolve issues caused by monkey patching, follow these steps:

1. Comment out the affected lines in `.genignore`.
2. Regenerate the SDK using the Speakeasy CLI or GitHub Action.
3. Compare changes between the unpatched SDK and the patched code using `git diff`.
4. Modify patches as necessary, then uncomment or remove lines from `.genignore` to reapply the patches.
5. Commit changes to maintain synchronization between patches and the SDK.

 This is the content for the doc docs/customize/code/sdk-hooks.mdx 

 ---
title: Custom code with SDK hooks
description: "Learn how to use SDK hooks to customize code generation."
---

import { Tabs } from "@speakeasy/nextra-theme";
import { Callout } from "~/components";

# Custom Code With SDK Hooks

<Callout title="Availability" variant="info">
  SDK Hooks are available for [Business and Enterprise users](/pricing) only.
</Callout>

SDK Hooks enable custom logic to be added to SDK functions and request lifecycles across supported SDKs. These hooks allow for transformations, tracing, logging, validation, and error handling during different stages of the SDK's lifecycle.

Hooks can be applied to the following lifecycle events:

- **On SDK initialization:** Modify the base server URL, wrap or override the HTTP client, add tracing, inject global headers, and manage authentication.
- **Before request:** Cancel an outgoing request, transform the request contents, or add tracing.
- **After success:** When a successful response is received, add tracing and logging, validate the response, return an error, or transform the raw response before deserialization.
- **After error:** On connection errors or unsuccessful responses, add tracing and logging or transform the returned error.

## Add a Hook

Hooks are supported in SDKs generated with the latest Speakeasy CLI. Each supported language includes a hooks directory in the generated code:

| Language    | Directory Path                       |
| ----------- | ------------------------------------ |
| Go          | `internal/hooks`                     |
| Python      | `src/{sdk_name}/_hooks`              |
| TypeScript  | `src/hooks`                          |
| Java        | `src/main/java/{package_path}/hooks` |
| C#          | `{root_path}/Hooks`                  |

### Steps to Add a Hook

1. **Create a hook implementation.**

Add the custom hook implementation in a new file inside the `hooks` directory. The generator won’t override files added to this directory.

2. **Locate the registration file.**

Find the appropriate registration file for the language:

| Language    | Registration File Path                             |
| ----------- | -------------------------------------------------- |
| Go          | `internal/hooks/registration.go`                   |
| Python      | `src/{sdk_name}/_hooks/registration.py`            |
| TypeScript  | `src/hooks/registration.ts`                        |
| Java        | `src/main/java/{package_path}/hooks/SDKHooks.java` |
| C#          | `{root_path}/Hooks/HookRegistration.cs`            |

3. **Instantiate and register your hook.**

In the registration file, find the method `initHooks/init_hooks/initialize/InitHooks`. This method includes a hooks parameter, allowing hooks to be registered for various lifecycle events.

Instantiate the hook here and register it for the appropriate event.

<Tabs items={['Go', 'Python', 'TypeScript', 'Java', 'C#']}>
  <Tabs.Tab>

```go
package hooks

func initHooks(h *Hooks) {
    myHook := &ExampleHook{}
    h.registerBeforeRequestHook(myHook)
}
```

  </Tabs.Tab>
  <Tabs.Tab>

```python
from .customhooks import ExampleHook
from .types import Hooks


def init_hooks(hooks: Hooks):
    hooks.register_before_request_hook(ExampleHook())
```

  </Tabs.Tab>
  <Tabs.Tab>

```typescript
import { Hooks } from "./types";

export function initHooks(hooks: Hooks) {
    const myHook = new ExampleHook();
    hooks.registerBeforeRequestHook(myHook);
}
```

  </Tabs.Tab>
  <Tabs.Tab>

```java
package com.package.hooks;

public final class SDKHooks {

    public static final void initialize(com.package.utils.Hooks hooks) {
        ExampleHook exampleHook = new ExampleHook();
        hooks.registerBeforeRequestHook(exampleHook);
    }

}
```

  </Tabs.Tab>
  <Tabs.Tab>

```csharp
namespace <namespace>
{
    public static class HookRegistration
    {
        public static void InitHooks(IHooks hooks)
        {
            var exampleHook = new ExampleHook();
            hooks.RegisterBeforeRequestHook(exampleHook);
        }
    }
}
```

  </Tabs.Tab>
</Tabs>

<Callout title="Note" variant="info">
The registration file is generated once and will not be overwritten. After the initial generation, you have full control and ownership of it.
</Callout>

Here are example hook implementations for each of the lifecycle events across different languages:

<Tabs items={['Go', 'Python', 'TypeScript', 'Java', 'C#']}>
  <Tabs.Tab>

```go
package hooks

import (
	"net/http"
)

type ExampleHook struct{}

var (
	_ sdkInitHook       = (*ExampleHook)(nil)
	_ beforeRequestHook = (*ExampleHook)(nil)
	_ afterSuccessHook  = (*ExampleHook)(nil)
	_ afterErrorHook    = (*ExampleHook)(nil)
)

func (i *ExampleHook) SDKInit(baseURL string, client HTTPClient) (string, HTTPClient) {
	// modify the baseURL or wrap the client used by the SDK here and return the updated values
	return baseURL, client
}

func (i *ExampleHook) BeforeRequest(hookCtx BeforeRequestContext, req *http.Request) (*http.Request, error) {
	// modify the request object before it is sent, such as adding headers or query parameters, or return an error to stop the request from being sent
	return req, nil
}

func (i *ExampleHook) AfterSuccess(hookCtx AfterSuccessContext, res *http.Response) (*http.Response, error) {
	// modify the response object before deserialization or return an error to stop the response from being deserialized
	return res, nil
}

func (i *ExampleHook) AfterError(hookCtx AfterErrorContext, res *http.Response, err error) (*http.Response, error) {
	// modify the response before it is deserialized as a custom error or the error object before it is returned or return an error wrapped in the FailEarly error in this package to exit from the hook chain early
	return res, err
}
```

  </Tabs.Tab>
  <Tabs.Tab>

```python
from typing import Optional, Tuple, Union

import httpx

from ..types import (
    AfterErrorContext,
    AfterErrorHook,
    AfterSuccessContext,
    AfterSuccessHook,
    BeforeRequestContext,
    BeforeRequestHook,
    HttpClient,
    SDKInitHook,
)


class ExampleHook(SDKInitHook, BeforeRequestHook, AfterSuccessHook, AfterErrorHook):

    def sdk_init(self, base_url: str, client: HttpClient) -> Tuple[str, HttpClient]:
        # modify the base_url or wrap the client used by the SDK here and return the
        # updated values

        return base_url, client

    def before_request(
        self, hook_ctx: BeforeRequestContext, request: httpx.Request
    ) -> Union[httpx.Request, Exception]:
        # modify the request object before it is sent, such as adding headers or query
        # parameters, or raise an exception to stop the request

        return request

    def after_success(
        self, hook_ctx: AfterSuccessContext, response: httpx.Response
    ) -> Union[httpx.Response, Exception]:
        # modify the response object before deserialization or raise an exception to stop
        # the response from being returned

        return response

    def after_error(
        self,
        hook_ctx: AfterErrorContext,
        response: Optional[httpx.Response],
        error: Optional[Exception],
    ) -> Union[Tuple[Optional[httpx.Response], Optional[Exception]], Exception]:
        # modify the response before it is deserialized as a custom error or the error
        # object before it is returned or raise an exception to stop processing of other
        # error hooks and return early

        return response, error
```

  </Tabs.Tab>
  <Tabs.Tab>

```typescript
import { HTTPClient } from "../lib/http";
import {
  AfterErrorContext,
  AfterErrorHook,
  AfterSuccessContext,
  AfterSuccessHook,
  BeforeRequestContext,
  BeforeRequestHook,
  SDKInitHook,
  SDKInitOptions,
} from "./types";

export class ExampleHook
  implements SDKInitHook, BeforeRequestHook, AfterSuccessHook, AfterErrorHook
{
  sdkInit(opts: SDKInitOptions): SDKInitOptions {
    const { baseURL, client } = opts;

    // modify the baseURL or wrap the client used by the SDK here and return the updated values
    return { baseURL: baseURL, client: client };
  }

  beforeRequest(hookCtx: BeforeRequestContext, request: Request): Request {
    // modify the request object before it is sent, such as adding headers or query parameters, or throw an error to stop the request from being sent
    return request;
  }

  afterSuccess(hookCtx: AfterSuccessContext, response: Response): Response {
    // modify the response object before deserialization or throw an error to stop the response from being deserialized
    return response;
  }

  afterError(
    hookCtx: AfterErrorContext,
    response: Response | null,
    error: unknown,
  ): { response: Response | null; error: unknown } {
    // modify the response before it is deserialized as a custom error or the error object before it is returned or throw an error to stop processing of other error hooks and return early
    return { response, error };
  }
}
```

  </Tabs.Tab>
  <Tabs.Tab>

```java
package dev.speakeasyapi.speakeasy.hooks;

import dev.speakeasyapi.speakeasy.utils.Utils;
import dev.speakeasyapi.speakeasy.utils.Hook.AfterError;
import dev.speakeasyapi.speakeasy.utils.Hook.AfterErrorContext;
import dev.speakeasyapi.speakeasy.utils.Hook.AfterSuccess;
import dev.speakeasyapi.speakeasy.utils.Hook.AfterSuccessContext;
import dev.speakeasyapi.speakeasy.utils.Hook.BeforeRequest;
import dev.speakeasyapi.speakeasy.utils.Hook.BeforeRequestContext;
import dev.speakeasyapi.speakeasy.utils.Hook.SdkInit;
import dev.speakeasyapi.speakeasy.utils.Hook.SdkInitData;

import java.io.InputStream;
import java.net.http.HttpRequest;
import java.net.http.HttpResponse;
import java.util.Optional;

final class ExampleHook implements BeforeRequest, AfterError, AfterSuccess, SdkInit {

    @Override
    public SdkInitData sdkInit(SdkInitData data) {
        // modify the baseURL or wrap the client used by the SDK here and return the updated values
        return new SdkInitData(data.baseUrl(), data.client());
    }

    @Override
    public HttpRequest beforeRequest(BeforeRequestContext context, HttpRequest request) throws Exception {
        // modify the request object before it is sent, such as adding headers or query parameters
        // or throw an error to stop the request from being sent

        // Note that HttpRequest is immutable. With JDK 16 and later you can use
        // `HttpRequest.newBuilder(HttpRequest, BiPredicate<String, String>)` to copy the request
        // and modify it (the predicate is for filtering headers). If that method is not
        // available then use `Helpers.copy` in the generated `utils` package.

        return request;
    }

    @Override
    public HttpResponse<InputStream> afterSuccess(AfterSuccessContext context, HttpResponse<InputStream> response)
            throws Exception {
        // modify the response object before deserialization or throw an exception to stop the
        // response from being deserialized
        return response;
    }

    @Override
    public HttpResponse<InputStream> afterError(AfterErrorContext context,
            Optional<HttpResponse<InputStream>> response, Optional<Exception> error) throws Exception {
        // modify the response before it is deserialized as a custom error or the exception
        // object before it is thrown or throw a  FailEarlyException to stop processing of
        // other error hooks and return early
        return response;
    }
}
```

  </Tabs.Tab>
  <Tabs.Tab>

```csharp
namespace Speakeasy.Hooks
{
    using Speakeasy.Utils;
    using Speakeasy.Models.Components;

    public class ExampleHook : ISDKInitHook, IBeforeRequestHook, IAfterSuccessHook, IAfterErrorHook
    {
        public (string, ISpeakeasyHttpClient) SDKInit(string baseURL, ISpeakeasyHttpClient client)
        {
            // modify the baseURL or wrap the client used by the SDK here and return the updated values
            return (baseURL, client);
        }

        public async Task<HttpRequestMessage> BeforeRequestAsync(BeforeRequestContext hookCtx, HttpRequestMessage request)
        {
            // modify the request object before it is sent, such as adding headers or query parameters, or throw an exception to stop the request from being sent
            return request;
        }

        public async Task<HttpResponseMessage> AfterSuccessAsync(AfterSuccessContext hookCtx, HttpResponseMessage response)
        {
            // modify the response object before deserialization or throw an exception to stop the response from being returned
            return response;
        }

        public async Task<(HttpResponseMessage?, Exception?)> AfterErrorAsync(AfterErrorContext hookCtx, HttpResponseMessage? response, Exception error)
        {
            // modify the response before it is deserialized as a custom error
            // return (response, null);

            // OR modify the exception object before it is thrown
            // return (null, error);

            // OR abort the processing of subsequent AfterError hooks
            // throw new FailEarlyException("return early", error);

            // response and error cannot both be null
            return (response, error);
        }
    }
}
```

  </Tabs.Tab>

</Tabs>

## Adding Dependencies

To add dependencies needed for SDK hooks, configure the `additionalDependencies` section in the `gen.yaml` file. <br/><br/>

<Tabs items={['Go', 'Python', 'TypeScript', 'Java', 'C#']}>
  <Tabs.Tab>

```yaml
configVersion: 2.0.0
go:
additionalDependencies:
  # Pass a map of Go package names to the version to be added to the `go.mod` file of the SDK.
  "github.com/google/uuid": v1.6.0
```

  </Tabs.Tab>
  <Tabs.Tab>
 
```yaml
configVersion: 2.0.0
python:
  additionalDependencies:
    dev:
      - "pytest>=6.0.0"
      - "flake8>=3.9.0"
    main:
      - "requests>=2.25.0"
      - "pydantic>=1.8.0"
```

  </Tabs.Tab>
  <Tabs.Tab>

```yaml
typescript:
additionalDependencies:
  #  Pass a map of npm package names to their version pattern for `dependencies`, `devDependencies`, or `peerDependencies`.
  dependencies:
    uuid: ^9.0.1
  devDependencies:
    "@types/uuid": "^9.0.8"
  peerDependencies: {}
```

  </Tabs.Tab>
  <Tabs.Tab>
 
```yaml
java:
additionalDependencies:
  # Pass an array of `scope:groupId:artifactId:version` strings, for example, `implementation:com.fasterxml.jackson.core:jackson-databind:2.16.2`.
  - implementation:com.fasterxml.jackson.core:jackson-databind:2.16.0
  - api:org.apache.commons:commons-compress:1.26.1
```

  </Tabs.Tab>
  <Tabs.Tab>

```yaml
csharp:
  additionalDependencies:
    - package: RestSharp
      version: 106.12.0
      includeAssets: all
      privateAssets: contentFiles; build; native; analyzers; buildTransitive
      excludeAssets: none
```

  </Tabs.Tab>
</Tabs>


 This is the content for the doc docs/customize/data-model/complex-numbers.mdx 

 ---
title: "OpenAPI: Complex numbers"
description: "How to use complex numbers in your OpenAPI document and maintain arbitrary precision through serialization and deserialization."
slug: "/customize-sdks/complex-numbers/"
---

# Complex numbers

OpenAPI does not provide support natively for complex numbers. The highest precision integer type is an `integer` with an `int64` format, while the highest precision decimal value in the spec is a type `number` with a `double` format.

To support arbitrary precision numbers, Speakeasy introduces two new formats you can use in your OpenAPI document: `bigint`, which represents arbitrary precision integers, and `decimal`, which represents arbitrary precision decimal numbers. When these formats are used, the generated SDK will use the language-appropriate types to allow natively interacting with them.

## Preserve precision when serializing

Generated SDKs treat `bigint` and `decimal` values as arbitrary precision and ensure their precision is maintained.

During serialization, however, the value will be cast into the `type` of the field, which may result in a loss of precision. To prevent this, avoid using a numeric `type` in your OpenAPI document, and rather use the `string` type with a `bigint` or `decimal` format. This ensures that the value is serialized as a string, preserving its full precision, subject to the typical limitations of arbitrary precision decimal values in your language of choice.



 This is the content for the doc docs/customize/data-model/enums.mdx 

 ---
title: "OpenAPI: Enums"
description: "How to customize enums in your OpenAPI document to generate strongly typed enums in your SDKs."
slug: "/customize-sdks/enums/"
---

import { Callout } from "~/components";

# Customize enums

## Enum value naming

### Basic conversion

Enum values are named according to their values, with adjustments made to form valid identifiers:

* Invalid characters are removed.
* Values are converted to fit the case style of the target programming language.
* Special characters (for example, `+`, `-`, and `.`) are converted to words (like `Plus`, `Minus`, and `Dot`).

### Name conflicts

If naming conflicts arise after sanitization, deduplication is attempted by modifying case styles or adding suffixes.

For example, given the following schema:

```yaml
schema:
  type: string
  enum:
    - foo
    - Foo
    - FOO
```

Resulting enum values will be `FOO_LOWER`, `FOO_MIXED`, and `FOO_UPPER`.

If unique names cannot be resolved, a validation error will prompt you to resolve conflicts, potentially using the `x-speakeasy-enums` extension.


```yaml
schema:
  type: integer
  enum:
    - 1
    - 2
    - 3
  x-speakeasy-enums:
    - NOT_STARTED
    - IN_PROGRESS
    - COMPLETE
```

Ensure the order in the enum array corresponds to the custom names in the `x-speakeasy-enums` array.

## Enum class naming

Use the `x-speakeasy-name-override` attribute to customize enum class names:

```yaml
  Enum:
      x-speakeasy-name-override: example_override
      type: string
      enum:
        - foo
        - FOO
```

This schema will produce: 

```python
class ExampleOverride(str, Enum):
    FOO_LOWER = 'foo'
    FOO_UPPER = 'FOO'
```

### Name conflict considerations

Some cases (like open enums) may pose unique name resolutions challenges, particularly when similar names occur in the schema. 

In name conflict cases, the parent schema is given the original name, while the child schema's name is concatenated with the parent's name.

For example, the following schema:

```yaml
enum_field:
  oneOf:
    - type: string
    - type: string
      enum:
        - foo
        - FOO
      x-speakeasy-name-override: enum_field
```

Results in: 

```python
class EnumFieldEnumField(str, Enum):
  FOO_LOWER = 'value'
  FOO_UPPER = 'value'
```

To avoid naming conflicts, additional overrides may be necessary. For example:

```yaml
enum_field:
  x-speakeasy-name-override: enum_field_parent
          oneOf:
            - type: string
            - type: string
              enum:
                - foo
                - Foo
              x-speakeasy-name-override: enum_field
```

This will result in: 

```python
class EnumField(str, Enum):
  FOO_LOWER = 'value'
  FOO_UPPER = 'value'
```

## Open vs closed enums

<Callout title="NOTE" variant="info">
This feature is currently supported in Go, Python, TypeScript, and Java SDKs.
</Callout>

By default, enums defined in OpenAPI are considered closed during code
generation. This means that introducing a new member to an enum can become a
breaking change for consumers of older versions of the SDK. Sometimes, this is
desirable because particular enums can be rigidly defined and not changing in
the foreseeable future (country codes might be a good example of this).

However, in some cases, you might want to make room for future iteration and the
introduction of new enum members. This is where open enums can help. Use the
`x-speakeasy-unknown-values` extension to mark an enum as open:

```yaml
components:
  schemas:
    BackgroundColor:
      type: string
      x-speakeasy-unknown-values: allow
      enum:
        - red
        - green
        - blue
```

When an SDK is generated with this type, the API is able to send values beyond
what is specified in the enum and these will be captured and returned to the user
in a type-safe manner. 

Here's an example of what this schema looks like in TypeScript:

```typescript
type BackgroundColor = 'red' | 'green' | 'blue' | Unrecognized<string>;
```

## Native enums vs union of strings

Languages like Python and TypeScript support string or integer literal unions as
well as native enum types. When generating SDKs for these targets, you can
specify which style you prefer using the `enumFormat` option in the
`.speakeasy/gen.yaml` config file where the SDK is generated.

For example, in your `gen.yaml`:

```yaml
typescript:
  enumFormat: union
```

This will cause all enums to be generated as a union of strings:

```typescript
type Color = "sky-blue" | "dark-gray" | "stone";
```

```typescript
import { SDK } from "cool-sdk";

const sdk = new SDK();

const result = await sdk.themes.create({
    name: "flashy",
    background: "dark-gray",
});
```

Whereas this:

```yaml
typescript:
  enumFormat: enum
```

Will result in the following output:

```typescript
enum Color {
  SkyBlue = 'sky-blue',
  DarkGray = 'dark-gray',
  Stone = 'stone',
}
```

```typescript
import { SDK } from "cool-sdk";
import { Color } from "cool-sdk/models/color";

const sdk = new SDK();

const result = await sdk.themes.create({
    name: "flashy",
    background: Color.DarkGray,
});
```

The main trade-offs to consider between the two styles are that literal unions
do not require SDK users to import any additional types or values from the SDK
package. The user starts typing a string or number and their IDE's autocompletion
interface will suggest from the valid set of values. 

Native enums need to be
imported from within the SDK but benefit from having members with clear names
and documentation on each. This is particularly useful when you define enums
that do not map well to spoken language, such as `enum: ["+", "_", "*", "!"]`.
Using the `x-speakeasy-enums` extension will allow you to customise the name of
each native enum member.

In TypeScript and Python, native enums are nominally typed, which means that
users cannot pass in any string value they have or another native enum that
overlaps with the desired one without triggering a type-checker error. In some
of these instances, they may need to write some code to map values to native
enum members.

### Mixing enum formats

While `enumFormat` is a global setting, it is possible to mix and match the enum
format on a per-schema basis using the `x-speakeasy-enum-format` extension:

```yaml
# `enumFormat` is set to `union` in the gen.yaml
components:
  schemas:
    BackgroundColor:
      type: int
      x-speakeasy-enum-format: enum
      enum:
        - 1
        - 2
        - 3
      x-speakeasy-enums:
        - Red
        - Green
        - Blue
```

In this case, the `BackgroundColor` enum will be generated as a native enum in
the target language, while the rest of the enums will be generated as a union of
values.


 This is the content for the doc docs/customize/data-model/oneof-schemas.mdx 

 ---
title: "OpenAPI: OneOf schemas"
description: "Support for OpenAPI `oneOf` types with idiomatic unions."
slug: "/customize-sdks/oneof-schemas/"
---

import { Tabs } from "@speakeasy/nextra-theme";

# The `oneOf` keyword

In support of the OpenAPI Specification `oneOf` schemas, Speakeasy SDKs provide language-specific implementations based on idiomatic unions (when available) or using generated supporting objects that allow type safety by using an `enum` discriminator.

## Supporting objects

Assuming your OpenAPI document has a `Pet` component, consider this `oneOf` block:

```yaml
oneOf:
  - type: string
  - type: integer
  - $ref: "/components/schemas/Pet"
```

How Speakeasy generates supporting objects for your SDK depends on the language of the SDK.

<Tabs items={['TypeScript', 'Go', 'Python', 'C#', 'Java']}>
  <Tabs.Tab>
 Speakeasy leverages native TypeScript support for unions to represent `oneOf` schemas. A union type is generated to represent the different possible types defined in the `oneOf` schema.

  </Tabs.Tab>
  <Tabs.Tab>

Go does not provide a native `union` data type, so Speakeasy will create a supporting `struct` with a corresponding _pseudo enum_ that is used for discrimination. The supporting object will be named differently depending on whether it is used as part of a request or included as a response.

The generated object can optionally accept any of the `oneOf` types but should only store one at a time. The `Type` field should store the corresponding `const` value:

```go

type FetchPetRequestBodyType string

const (
	FetchPetRequestBodyTypeStr          FetchPetRequestBodyType = "str"
	FetchPetRequestBodyTypeInteger      FetchPetRequestBodyType = "integer"
	FetchPetRequestBodyTypePet          FetchPetRequestBodyType = "pet"
)

type FetchPetRequestBody struct {
	Str          *string
	Integer      *int64
	Pet *shared.Pet

	Type FetchPetRequestBodyType
}
```

An SDK user shouldn&apos;t construct a `FetchPetRequestBody` object. Instead, they should call one of the supporting `Create` methods that set the content value and discriminator.

```go

func CreateFetchPetRequestBodyStr(str string) FetchPetRequestBody {
	typ := FetchPetRequestBodyTypeStr

	return FetchPetRequestBody{
		Str:  &str,
		Type: typ,
	}
}

func CreateFetchPetRequestBodyInteger(integer int64) FetchPetRequestBody {
	typ := FetchPetRequestBodyTypeInteger

	return FetchPetRequestBody{
		Integer: &integer,
		Type: typ,
	}
}

func CreateFetchPetRequestBodyPet(pet shared.Pet) FetchPetRequestBody {
	typ := FetchPetRequestBodyTypePet

	return FetchPetRequestBody{
		Pet: &pet,
		Type: typ,
	}
}
```

  </Tabs.Tab>
  <Tabs.Tab>

Speakeasy uses Python&apos;s built-in `typing.Union` objects and will not create special objects for any `oneOf` keywords in your OpenAPI document.

  </Tabs.Tab>
  <Tabs.Tab>

```csharp
public class FetchPetRequestBodyType
{
  private FetchPetRequestBodyType(string value) { Value = value; }

  public string Value { get; private set; }
  public static FetchPetRequestBodyType Str { get { return new FetchPetRequestBodyType("str"); } }

  public static FetchPetRequestBodyType Integer { get { return new FetchPetRequestBodyType("integer"); } }

  public static FetchPetRequestBodyType Pet { get { return new FetchPetRequestBodyType("pet"); } }

  // ..snip
}

public class FetchPetRequestBody
{
  public FetchPetRequestBody(FetchPetRequestBodyType type) {
      Type = type;
  }
  public string? Str { get; set; }
  public long? Integer { get; set; }
  public Pet Pet { get; set; }

  public FetchPetRequestBodyType Type { get; set; }

  public static FetchPetRequestBody CreateString(string str) {
      FetchPetRequestBodyType typ = FetchPetRequestBodyType.Str;

      FetchPetRequestBody res = new FetchPetRequestBody(typ);
      res.Str = str;
      return res;
  }

  public static FetchPetRequestBody CreateInteger(long integer) {
      FetchPetRequestBodyType typ = FetchPetRequestBodyType.Integer;

      FetchPetRequestBody res = new FetchPetRequestBody(typ);
      res.Integer = integer;
      return res;
  }

  public static FetchPetRequestBody CreatePet(Pet pet) {
      FetchPetRequestBodyType typ = FetchPetRequestBodyType.Pet;

      FetchPetRequestBody res = new FetchPetRequestBody(typ);
      res.Pet = pet;
      return res;
  }
}
```

  </Tabs.Tab>
  <Tabs.Tab>

For a `oneOf` type, Speakeasy generates a Java class that wraps the different value types and provides static factory methods (`of*`) for creation.

For read purposes, the `value()` method should be inspected with the Java `instanceof` operator to determine the type for casting the `value()` method result. The `equals`, `hashCode`, and `toString` methods are all implemented.

```java
@JsonDeserialize(using = FetchPetRequestBody._Deserializer.class)
public class FetchPetRequestBody {

    @JsonValue
    private TypedObject value;

    private FetchPetRequestBody(TypedObject value) {
        this.value = value;
    }

    public static FetchPetRequestBody of(String value) {
        Utils.checkNotNull(value, "value");
        return new FetchPetRequestBody(TypedObject.of(value, JsonShape.DEFAULT, new TypeReference<String>(){}));
    }

    public static FetchPetRequestBody of(long value) {
        Utils.checkNotNull(value, "value");
        return new FetchPetRequestBody(TypedObject.of(value, JsonShape.DEFAULT, new TypeReference<java.lang.Long>(){}));
    }

    public static FetchPetRequestBody of(Pet value) {
        Utils.checkNotNull(value, "value");
        return new FetchPetRequestBody(TypedObject.of(value, JsonShape.DEFAULT, new TypeReference<Pet>(){}));
    }

    /**
     * Returns an instance of one of these types:
     * <ul>
     * <li>{@code java.lang.String}</li>
     * <li>{@code long}</li>
     * <li>{@code pet.store.simple.models.shared.Pet}</li>
     * </ul>
     *
     * <p>Use {@code instanceof} to determine what type is returned. For example:
     *
     * <pre>
     * if (obj.value() instanceof String) {
     *     String answer = (String) obj.value();
     *     System.out.println("answer=" + answer);
     * }
     * </pre>
     *
     * @return value of oneOf type
     **/
    public java.lang.Object value() {
        return value.value();
    }

    @Override
    public boolean equals(java.lang.Object o) {
        if (this == o) {
            return true;
        }
        if (o == null || getClass() != o.getClass()) {
            return false;
        }
        FetchPetRequestBody other = (FetchPetRequestBody) o;
        return Objects.deepEquals(this.value.value(), other.value.value());
    }

    @Override
    public int hashCode() {
        return Objects.hash(value.value());
    }

    @SuppressWarnings("serial")
    public static final class _Deserializer extends OneOfDeserializer<FetchPetRequestBody> {

        public _Deserializer() {
            super(FetchPetRequestBody.class, false,
                  TypeReferenceWithShape.of(new TypeReference<Long>() {}, JsonShape.DEFAULT),
                  TypeReferenceWithShape.of(new TypeReference<String>() {}, JsonShape.DEFAULT),
                  TypeReferenceWithShape.of(new TypeReference<Pet>() {}, JsonShape.DEFAULT));
        }
    }

    @Override
    public String toString() {
        return Utils.toString(FetchPetRequestBody.class,
                "value", value);
    }

}
```

  </Tabs.Tab>
</Tabs>

## Requests

Assume you have an operation that allows the user to fetch a pet by submitting the pet's name, ID, or complete pet object:

```yaml
/pet:
  get:
    operationId: fetchPet
    requestBody:
      description: identifier of pet to fetch
      required: true
      content:
        application/json:
          schema:
            oneOf:
              - type: string
              - type: integer
              - $ref: "/components/schemas/Pet"
    responses:
      "200":
        description: fetched pet
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/Pet"
```

<Tabs items={['TypeScript', 'Go', 'Python', 'C#', 'Java']}>
<Tabs.Tab>

```typescript
const sdk = new SDK();
sdk.pets.fetchPet("Fido"); // string
sdk.pets.fetchPet(123);    // number
sdk.pets.fetchPet({ id: "p-123" }); // Pet object
```

</Tabs.Tab>
  <Tabs.Tab>

You can use the object returned from the supporting `Create` function as a parameter in the operation&apos;s request:

```go
s := sdk.New()

req := shared.CreateFetchPetRequestBodyInteger(1)

res, err := s.Pets.FetchPet(context.Background(), req)

```

  </Tabs.Tab>
  <Tabs.Tab>

Speakeasy uses native Python unions internally, so using `oneOf` types in your Python SDK is intuitive: Directly use the type you want to submit as the request object (in this case, a `str`, `int`, or `Pet` object).

```python
s = SDK()

res = s.pets.fetch_pet(request=1)
```

  </Tabs.Tab>
  <Tabs.Tab>

The C# SDKs use a custom object-oriented approach to supporting union types. Speakeasy generates a supporting `class` with a corresponding **pseudo enum**, which is used for discrimination. The supporting object is named differently depending on whether it is used as part of a request or included as a response.

The generated object can optionally accept any of the `oneOf` types but should only store one at a time. The `Type` field should store the corresponding `enum` value:

```csharp
s = new SDK()

req = CreateFetchPetRequestBodyInteger(1)

var res = s.Pets.FetchPet(req)

```

An SDK user should not construct a `FetchPetRequestBody` object. Instead, they should call one of the supporting `Create` methods that set the content value and discriminator.

  </Tabs.Tab>
<Tabs.Tab>

```java
SDK sdk = SDK.builder().build();
// fetch pet by integer id
FetchPetResponse res = sdk.fetchPet(FetchPetRequestBody.of(123));
```
</Tabs.Tab>
</Tabs>

## Responses

Sometimes you may have a response that specifies a `oneOf` schema. For languages that do not natively support unions, Speakeasy will create supporting objects to deserialize the `oneOf` response into the correct object type. No supported objects are needed for languages with native union types, so Speakeasy will deserialize into the native type.

For example, this schema:

```
/pet_id:
  get:
    operationId: petId
    responses:
      "200":
        description: OK
        content:
          application/json:
            schema:
              title: res
              oneOf:
                - type: string
                - type: integer
```

Will result in these response types:

<Tabs items={['TypeScript', 'Go', 'Python', 'C#', 'Java']}>
<Tabs.Tab>
```typescript
type PetIdRes = string | number;
```
    </Tabs.Tab>
  <Tabs.Tab>

```go
type petIdResType string
const (
	PetIdResTypeStr          petIdResType = "str"
	PetIdResTypeInteger      petIdResType = "integer"
)
type petIdRes struct {
	Str          *string
	Integer      *int64

	Type petIdResType
}
type FetchPetResponse struct {
	// ..snip
	Res *petIdRes
}

```

  </Tabs.Tab>
  <Tabs.Tab>

```python

@dataclasses.dataclass
class FetchPetResponse:
    # ..snip
    res: Optional[Union[str, int]] = dataclasses.field(default=None)
```

  </Tabs.Tab>
  <Tabs.Tab>

```csharp

public class PetIdResType
{
  public static PetIdResType Str { get { return new PetIdResType("str"); } }

  public static PetIdResType Integer { get { return new PetIdResType("integer"); } }

  // ..snip
}


public class PetIdRes {
    public string? Str { get; set; }
    public long? Integer { get; set; }

    public PetIdResType Type { get; set; }
    // ..snip
}

public class FetchPetResponse {
	// ..snip
	public PetIdRes? res { get; set; }
}
```

  </Tabs.Tab>
  <Tabs.Tab>

To access the fetched pet from the response object, call the `res()` method below. Notice that it returns an `Optional`. However, this is a holdover from previous generator versions. Recent generators ensure that a response is always present when calling `res()`, but `Optional` is still used to maintain backward compatibility.

```java
public class FetchPetResponse {

/\*\*
_ fetched pet
_/
public Optional<Pet> res() {
...
}

...
}

````
  </Tabs.Tab>
</Tabs>

### Splitting `oneOf` schema types

By defining similar operations with aligned but different schemas, you can apply `x-speakeasy-type-override: any` for untyped operations and use `oneOf` to define stricter types in others. This allows you to use methods like `DoSomething(StrictObject{...})` alongside `DoSomethingUntyped({...})`, providing flexibility across SDK methods based on the required schema type.

This approach is particularly useful when dealing with endpoints that require you to split `oneOf` schema types into separate SDK methods.

Example:

```yaml
/sources#SellerPartner:
  post:
    requestBody:
      content:
        application/json:
          schema:
            $ref: "#/components/schemas/SourceSellerPartnerCreateRequest"
    tags:
      - "Sources"
    responses:
      "200":
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/SourceResponse"
        description: "Successful operation"
      "400":
        description: "Invalid data"
      "403":
        description: "Not allowed"
    operationId: "createSourceSellerPartner"
    summary: "Create a source"
    description: "Creates a source given a name, workspace ID, and a JSON blob containing the configuration for the source."
    x-use-speakeasy-middleware: true
    x-speakeasy-entity-operation: Source_SellerPartner#create
````


 This is the content for the doc docs/customize/data-model/types.mdx 

 ---
title: Types
---

# Types

## Type naming

Speakeasy tries to name your types using the shortest name possible, which is achieved by deducing a name from its surrounding context.

Types defined using components generally result in better type names. Where possible, Speakeasy uses the component's key name as the type name.

For example, given the following schema:

```yaml
components:
  schemas:
    User:
      type: object
      properties:
        id:
          type: string
        name:
          type: string
```

The type name for the `User` schema will be `User` where possible. If a conflict arises with another type in the same namespace, name resolution will kick in: The earliest encountered type will be named `User` and types encountered subsequently will have prefixes or suffixes added to the name based on context to avoid conflicts.

If a component name is unavailable (for example, the type is defined inline in a schema, request, response, or parameter), Speakeasy will determine the type name based on context in the following order:

- The `x-speakeasy-name-override` extension value in the schema
- The `title` property in the schema
- The `$anchor` property in the schema
- Any other context of the schema

Types that are named this way are `objects` that become classes, `integer` and `string` types that have `enum` values defined in the schema, or `oneOf` or `anyOf` schemas that become union types.

Inline schemas are more likely to have name conflicts with other types, which can result in context-based prefixes or suffixes being added to type names until the conflict is resolved. For example:

```yaml
paths:
  /users:
    get:
      operationId: getUsers
      responses:
        '200':
          content:
            application/json:
              schema: 
                type: array
                items:
                  type: object # inline schema that will be named based on surrounding context
                  title: User
                  properties:
                    id:
                      type: string
                    name:
                      type: string
  /user:
    get:
      operationId: getUser
      responses:
        '200':
          content:
            application/json:
              schema: 
                type: object # inline scheme that will be named based on surrounding context
                title: User
                properties:
                  id:
                    type: string
                  name:
                    type: string
```

Here, both inline schemas are candidates for the name `User`. As there will be a conflict (Speakeasy doesn't perform any inference to assess whether the schemas are the same type), the second schema will be given a name with a context-based prefix to avoid a conflict with the first schema.

Some of the context prefixes and suffixes that can be added to type names are:

- Reference type
- Reference name
- Property name
- Operation name
- Tag name
- Request
- Response
- Position in `oneOf` or `anyOf` schema

Should Speakeasy run out of context to use in naming the type, it will add numbers to type names as suffixes.

To avoid unexpected type names and ensure you get the names you expect, use unique component names for your schemas wherever possible.

## Input and output models

Speakeasy will generate separate input and output models for schemas that are used in both request and response bodies and define `readOnly` and `writeOnly` flags in their properties.

For example, given the following schema:

```yaml
paths:
  /drinks/{id}:
    post:
      operationId: updateDrink
      parameters:
        - name: id
          in: path
          required: true
          schema:
            type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/Drink'
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Drink'
components:
  schemas:
    Drink:
      type: object
      properties:
        id:
          type: string
          readOnly: true
        stockUpdate:
          type: integer
          writeOnly: true
        name:
          type: string
        category:
          type: string
        stock:
          type: integer
          readOnly: true
```

The `Drink` component is used both as a request body and response body schema, but it uses fields that can only be set when updating the drink and read when getting the returned drink.

In this case, Speakeasy will generate two models `DrinkInput` and `DrinkOutput`.

The `DrinkInput` model will have the following properties:
  - stockUpdate
  - name
  - category

The `DrinkOutput` model will have the following properties:
  - id
  - name
  - category
  - stock

If a schema has only `readOnly` flags and no `writeOnly` flags or vice versa, Speakeasy will still generate two models if used in both request and response bodies, but the `Input` or `Output` schema will be added only to the relevant models based on the flags.

The `Input` and `Output` suffixes can be reconfigured using the `inputModelSuffix` and `outputModelSuffix` options in the `gen.yaml` file. See the [gen.yaml reference](/docs/gen-reference) for more infomation.

## Handling constants and defaults

If a schema has a `const` or `default` value defined in it, Speakeasy will generate code to handle these wherever possible.

### `const`

Using `const` allows you to specify a value that must be transmitted to the server and is always expected to be received from the server.

For example:

```yaml
components:
  schemas:
    Drink:
      type: object
      properties:
        type:
          type: string
          const: 'drink'
```

The `type` property has a `const` value of `drink`, so the SDK will be generated with this field as non-configurable, as the value `drink` will always be transmitted. A `const` getter will be generated to access the value if required.

### `default`

Default values allow you to specify a value to be transmitted to the server if none is provided by the end user.

For example:

```yaml
components:
  schemas:
    Drink:
      type: object
      properties:
        category:
          type: string
          default: 'spirits'
      required:
        - category
```

The `category` property has a default of `spirits`. Although `category` is marked as `required`, the SDK will be generated with this field set to optional, and the value `spirits` will be transmitted if no other value is provided by the end user.


## Examples

If a type includes an `example` or `examples` field, Speakeasy will use the values (if valid for the defined schema) to populate usage snippets in the generated SDKs.

If more than one example is provided in the `examples` field, a random example will be chosen.

## Including Unused Schema Components

When working with OpenAPI specifications, there might be cases where you want to include schema components in your generated SDKs even if they aren't directly referenced by any API endpoints. This is particularly useful for:

- Webhook payload types in OpenAPI versions below 3.1 (before webhooks were officially supported)
- Types that are used in async operations or events
- Shared types that might be used in future endpoints

### Using x-speakeasy-include

To include an unused schema component in your generated SDK, add the `x-speakeasy-include: true` extension to the schema component definition:

```yaml
components:
  schemas:
    WebhookPayload:
      x-speakeasy-include: true  # This schema will be included in the SDK even if unused
      type: object
      properties:
        event_type:
          type: string
        data:
          type: object
```

### Important Notes

- This extension only works in the main OpenAPI document. It is not supported in referenced documents (e.g., components in separate files).
- The schema will be included in your SDK regardless of whether it's referenced by any endpoints.
- This is particularly useful for webhook payloads in OpenAPI versions before 3.1, where webhook support wasn't built into the specification.


 This is the content for the doc docs/customize/deprecations.mdx 

 ---
title: "Deprecations"
description: "Learn how to use deprecations to sunset parts of your API."
slug: "/customize-sdks/deprecations/"
---

import { Tabs } from "@speakeasy/nextra-theme";

# Deprecations

The OpenAPI Specification allows you to deprecate parts of your API, such as methods, parameters, and properties. When you deprecate a part of your API, the SDK will generate relevant `deprecated` annotations in the code and add a `⚠️ Deprecated` label to the SDK docs.

In addition to labeling deprecated parts of an API, Speakeasy extensions are available to customize the messaging of deprecated items.

## Deprecate Methods

Deprecate methods in an SDK using the `deprecated` field in the OpenAPI schema. This will add a `deprecated` annotation to the generated method and a `⚠️ Deprecated` label to the SDK docs.

Use the `x-speakeasy-deprecation-message` extension to customize the deprecation message displayed in code and the SDK docs.

Use the `x-speakeasy-deprecation-replacement` extension to specify the method that should be used instead of the deprecated method.

```yaml
paths:
  /drinks:
    get:
      operationId: listDrinks
      deprecated: true
      x-speakeasy-deprecation-message: This API will be removed in our next release, please refer to the beverages endpoint.
      x-speakeasy-deprecation-replacement: listBeverages
      responses:
        "200":
          description: OK
      tags:
        - drinks
  /beverages:
    get:
      operationId: listBeverages
      responses:
        "200":
          description: OK
      tags:
        - beverages
```

<Tabs items={['TypeScript','Python','Go','Java', 'C#']}>
  <Tabs.Tab>

    ```typescript
    /**
     * Get a list of drinks.
     *
     * @remarks
     * Get a list of drinks, if authenticated this will include stock levels and product codes otherwise it will only include public information.
     *
     * @deprecated method: This API will be removed in our next release, please refer to the beverages endpoint. Use listBeverages instead.
     */
    async listDrinks(
        input: operations.ListDrinksRequest,
        options?: RequestOptions
    ): Promise<operations.ListDrinksResponse> {}
    ```

  </Tabs.Tab>
  <Tabs.Tab>

    ```python
    def list_drinks(self, request: operations.ListDrinksRequest) -> operations.ListDrinksResponse:
        r"""Get a list of drinks.
        Get a list of drinks, if authenticated this will include stock levels and product codes otherwise it will only include public information.

        Deprecated method: This API will be removed in our next release, please refer to the beverages endpoint. Use list_beverages instead.
        """
    ```

  </Tabs.Tab>
  <Tabs.Tab>

    ```go
    // ListDrinks - Get a list of drinks.
    // Get a list of drinks, if authenticated this will include stock levels and product codes otherwise it will only include public information.
    //
    // Deprecated method: This API will be removed in our next release, please refer to the beverages endpoint. Use ListBeverages instead.
    func (s *Drinks) ListDrinks(ctx context.Context, request operations.ListDrinksRequest) (*operations.ListDrinksResponse, error) {}
    ```

  </Tabs.Tab>
  <Tabs.Tab>

    ```java
    /**
     * Get a list of drinks.
     * Get a list of drinks, if authenticated this will include stock levels and product codes otherwise it will only include public information.
     * @param request The request object containing all of the parameters for the API call.
     * @return The response from the API call.
     * @throws Exception if the API call fails.
     * @deprecated method: This API will be removed in our next release, please refer to the beverages endpoint. Use listBeverages instead.
     */
    @Deprecated
    public org.openapis.openapi.models.operations.ListDrinksResponse listDrinks(
            org.openapis.openapi.models.operations.ListDrinksRequest request) throws Exception {}
    ```

  </Tabs.Tab>
  <Tabs.Tab>
    ```csharp
    [Obsolete("This method will be removed in a future release, please migrate away from it as soon as possible. Use ListBeverages instead")]
    public async Task<ListDrinksResponse> ListDrinksAsync() {}
    ```
  </Tabs.Tab>
</Tabs>

## Deprecate Parameters

Deprecate parameters in an SDK using the `deprecated` field in the OpenAPI schema. This will add a `deprecated` annotation to the corresponding field in the generated objects and remove the parameter from any relevant usage examples in the SDK docs.

Use the `x-speakeasy-deprecation-message` extension to customize the deprecation message displayed in code and the SDK docs.

```yaml
paths:
  /drinks:
    get:
      operationId: listDrinks
      summary: Get a list of drinks.
      description: Get a list of drinks, if authenticated this will include stock levels and product codes otherwise it will only include public information.
      tags:
        - drinks
      parameters:
        - name: ingredient
          in: query
          description: Filter by ingredient.
          required: false
          schema:
            type: string
            example: "vodka"
        - name: name
          in: query
          description: Filter by name.
          required: false
          deprecated: true
          x-speakeasy-deprecation-message: We no longer support filtering by name.
          schema:
            type: string
            example: "martini"
        - name: limit
          in: query
          description: Limit the number of results.
          required: false
          schema:
            type: integer
            minimum: 1
            maximum: 100
            example: 100
```

<Tabs items={['TypeScript','Python','Go','Java', 'C#']}>
  <Tabs.Tab>
```typescript
export type ListDrinksRequest = {
    /**
     * Filter by ingredient.
     */
    ingredient?: string | undefined;
    /**
     * Filter by name.
     *
     * @deprecated field: We no longer support filtering by name.
     */
    name?: string | undefined;
    /**
     * Limit the number of results.
     */
    limit?: number | undefined;
};
```   
  </Tabs.Tab>
  <Tabs.Tab>

    ```python

@dataclasses.dataclass
class ListDrinksRequest:
ingredient: Optional[str] = dataclasses.field(default=None, metadata={'query_param': { 'field_name': 'ingredient', 'style': 'form', 'explode': True }})
r"""Filter by ingredient."""
name: Optional[str] = dataclasses.field(default=None, metadata={'query_param': { 'field_name': 'name', 'style': 'form', 'explode': True }})
r"""Filter by name.

    Deprecated field: We no longer support filtering by name.
    """
    limit: Optional[int] = dataclasses.field(default=None, metadata={'query_param': { 'field_name': 'limit', 'style': 'form', 'explode': True }})
    r"""Limit the number of results."""
    ```

  </Tabs.Tab>
  <Tabs.Tab>
    ```go
type ListDrinksRequest struct {
	// Filter by ingredient.
	Ingredient *string `queryParam:"style=form,explode=true,name=ingredient"`
	// Filter by name.
	//
	// Deprecated field: We no longer support filtering by name.
	Name *string `queryParam:"style=form,explode=true,name=name"`
	// Limit the number of results.
	Limit *int64 `queryParam:"style=form,explode=true,name=limit"`
}
    ```
  </Tabs.Tab>
  <Tabs.Tab>
    ```java
public class ListDrinksRequest {

    /**
     * Filter by ingredient.
     */
    @SpeakeasyMetadata("queryParam:style=form,explode=true,name=ingredient")
    private Optional<? extends String> ingredient;

    /**
     * Filter by name.
     * @deprecated field: We no longer support filtering by name.
     */
    @SpeakeasyMetadata("queryParam:style=form,explode=true,name=name")
    @Deprecated
    private Optional<? extends String> name;

    /**
     * Limit the number of results.
     */
    @SpeakeasyMetadata("queryParam:style=form,explode=true,name=limit")
    private Optional<? extends Long> limit;

}
```

  </Tabs.Tab>
  <Tabs.Tab>
    ```csharp
public class ListDrinksRequest
{

    /// <summary>
    /// Filter by ingredient.
    /// </summary>
    [SpeakeasyMetadata("queryParam:style=form,explode=true,name=ingredient")]
    public string? Ingredient { get; set; }

    /// <summary>
    /// Limit the number of results.
    /// </summary>
    [SpeakeasyMetadata("queryParam:style=form,explode=true,name=limit")]
    public long? Limit { get; set; }

    /// <summary>
    /// Filter by name.
    /// </summary>
    [Obsolete("This field will be removed in a future release, please migrate away from it as soon as possible")]
    [SpeakeasyMetadata("queryParam:style=form,explode=true,name=name")]
    public string? Name { get; set; }

}
```

  </Tabs.Tab>
</Tabs>

## Deprecate Properties

Deprecate properties in an SDK using the `deprecated` field in the OpenAPI schema. This will add a `deprecated` annotation to the corresponding property in the generated objects and remove the property from any relevant usage examples in the SDK docs.

Use the `x-speakeasy-deprecation-message` extension to customize the deprecation message displayed in code and the SDK docs.

```yaml
components:
  schemas:
    Drink:
      type: object
      properties:
        name:
          type: string
        stock:
          type: integer
        productCode:
          type: string
        sku:
          type: string
          deprecated: true
          x-speakeasy-deprecation-message: We no longer support the SKU property.
      required:
        - name
        - stock
        - productCode
```

<Tabs items={['TypeScript','Python','Go','Java', 'C#']}>
  <Tabs.Tab>
    ```typescript
    export type Drink = {
        name: string;
        stock: number;
        productCode: string;
        /**
        * @deprecated field: We no longer support the SKU property.
        */
        sku?: string | undefined;
    };
    ```
  </Tabs.Tab>
  <Tabs.Tab>

    ```python
    @dataclass_json(undefined=Undefined.EXCLUDE)
    @dataclasses.dataclass
    class Drink:
        name: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('name') }})
        stock: int = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('stock') }})
        product_code: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('productCode') }})
        sku: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('sku'), 'exclude': lambda f: f is None }})
        r"""Deprecated field: We no longer support the SKU property."""
    ```

  </Tabs.Tab>
  <Tabs.Tab>
    ```go
    type Drink struct {
        Name        string `json:"name"`
        Stock       int64  `json:"stock"`
        ProductCode string `json:"productCode"`
        // Deprecated field: We no longer support the SKU property.
        Sku *string `json:"sku,omitempty"`
    }
    ```
  </Tabs.Tab>
  <Tabs.Tab>
    ```java
    public class Drink {

        @JsonProperty("name")
        private String name;

        @JsonProperty("stock")
        private long stock;

        @JsonProperty("productCode")
        private String productCode;

        /**
        * @deprecated field: We no longer support the SKU property.
        */
        @JsonInclude(Include.NON_ABSENT)
        @JsonProperty("sku")
        @Deprecated
        private Optional<? extends String> sku;
    }
    ```

  </Tabs.Tab>
  <Tabs.Tab>
```csharp
    public class Drink
    {
        [SpeakeasyMetadata("queryParam:name=name")]
        public string Name { get; set; } = default!;

        [SpeakeasyMetadata("queryParam:name=productCode")]
        public string ProductCode { get; set; } = default!;

        [Obsolete("This field will be removed in a future release, please migrate away from it as soon as possible")]
        [SpeakeasyMetadata("queryParam:name=sku")]
        public string? Sku { get; set; }

        [SpeakeasyMetadata("queryParam:name=stock")]
        public long Stock { get; set; } = default!;
    }

```
</Tabs.Tab>
</Tabs>
```


 This is the content for the doc docs/customize/globals.mdx 

 ---
title: "Define global parameters"
description: "How to define global parameters in your OpenAPI spec and automatically populate related operation parameters."
slug: "/customize-sdks/globals/"
---

import { Tabs } from "@speakeasy/nextra-theme";
import { Callout } from "~/components";

# Define global parameters

Use the `x-speakeasy-globals` extension to define parameters that can be configured globally on the main SDK instance. These parameters will be automatically populated for any operations that use them. This is especially useful for configurations that are required across all operations, such as customer IDs.

```yaml
openapi: 3.1.0
info:
  title: Test
  version: 0.0.1
servers:
  - url: https://httpbin.org
x-speakeasy-globals:
  parameters:
    - name: customerId
      in: path
      schema:
        type: string
paths:
  /api/{customerId}:
    get:
      operationId: getTest
      parameters:
        - name: customerId # If this matches a global parameter it will be populated automatically
          in: path
          schema:
            type: string
          required: true
      responses:
        "200":
          description: OK
```

If the `name`, `in`, and `schema` values of a global parameter match a parameter in an operation, the global parameter will be populated automatically. If the global parameter is not used in the operation, it will be ignored.

## Preferred method: Using component references

The preferred way to define global parameters is by referencing a component. This ensures consistency and reusability:

```yaml
openapi: 3.1.0
info:
  title: Test
  version: 0.0.1
servers:
  - url: https://httpbin.org
x-speakeasy-globals:
  parameters:
    - $ref: "#/components/parameters/CustomerId"
paths:
  /api/{customerId}:
    get:
      operationId: getTest
      parameters:
        - $ref: "#/components/parameters/CustomerId"
      responses:
        "200":
          description: OK
components:
  parameters:
    CustomerId:
      name: customerId
      in: path
      schema:
        type: string
```

## Supported parameter types

Global parameters can be used with `in: query`, `in: path`, or `in: header` fields. Only primitive types such as `string`, `number`, `integer`, `boolean`, and `enums` are supported for global parameters.

The global parameter definitions in the sample above will generate the following output:

<Tabs items={['TypeScript', 'Python', 'Go', 'Java', 'C#']}>

<Tabs.Tab>

```typescript
import { Speakeasybar } from "speakeasy";

async function run() {
    const sdk = new Speakeasybar({
        customerId: "1291fbe8-4afb-4357-b1de-356b65c417ca", // customerId can be set when instantiating the SDK and is used for all compatible operations
    });

    const result = await sdk.getCustomer({});

    // Handle the result
    console.log(result);
}

run();
```

</Tabs.Tab>

<Tabs.Tab>

```python
import speakeasy
from speakeasy.models import operations

s = speakeasy.SDK(
    customer_id='1291fbe8-4afb-4357-b1de-356b65c417ca', # customer_id can be set when instantiating the SDK and is used for all compatible operations
)

req = operations.GetCustomerRequest()

res = s.get_customer(req)

if res is not None:
    # handle response
    pass
```

</Tabs.Tab>

<Tabs.Tab>

```go
package main

import (
	"context"
	"log"
	"speakeasy"
	"speakeasy/models/operations"
)

func main() {
	s := speakeasy.New(
		speakeasy.WithCustomerID(speakeasy.String("1291fbe8-4afb-4357-b1de-356b65c417ca")), // CustomerID can be set when instantiating the SDK and is used for all compatible operations
	)

	ctx := context.Background()
	res, err := s.GetCustomer(ctx, operations.GetCustomerRequest{})
	if err != nil {
		log.Fatal(err)
	}
	if res != nil {
		// handle response
	}
}
```

</Tabs.Tab>

<Tabs.Tab>

```java
package hello.world;

import java.math.BigDecimal;
import java.math.BigInteger;
import java.time.LocalDate;
import java.time.OffsetDateTime;
import java.util.Optional;
import org.openapis.openapi.SDK;
import org.openapis.openapi.models.components.*;
import org.openapis.openapi.models.operations.*;
import org.openapis.openapi.models.operations.GetCustomerRequest;
import org.openapis.openapi.models.operations.GetCustomerResponse;
import static java.util.Map.entry;

public class Application {

    public static void main(String[] args) {
        try {
            SDK sdk = SDK.builder()
                .customerId("1291fbe8-4afb-4357-b1de-356b65c417ca") // customerId can be set when instantiating the SDK and is used for all compatible operations
                .build();

            GetCustomerRequest req = GetCustomerRequest.builder()
                .build();

            GetCustomerResponse res = sdk.getCustomer()
                .request(req)
                .call();

            // handle response
        } catch (org.openapis.openapi.models.errors.SDKError e) {
            // handle exception
        } catch (Exception e) {
            // handle exception
        }
    }
}
```

</Tabs.Tab>

<Tabs.Tab>

```csharp
using Openapi;
using Openapi.Models.Components;
using Openapi.Models.Operations;

var sdk = new SDK(
    customerId: "1291fbe8-4afb-4357-b1de-356b65c417ca");

try {
  var res = await sdk.GetCustomer(new GetCustomerRequest());
  // handle response
} catch (SDKException ex) {
  // handle exception
}
```

</Tabs.Tab>

</Tabs>

## Hiding global parameters from method signatures

<Callout variant="warning" title="Limited Support">
  Currently, this feature is only supported in Go, Python, and TypeScript.
</Callout>

To hide global parameters from method signatures, use the `x-speakeasy-globals-hidden` extension. This is useful when you want the global parameter to be set only once during SDK instantiation and not be overridden in individual operations.

```yaml
openapi: 3.1.0
info:
  title: Test
  version: 0.0.1
servers:
  - url: https://httpbin.org
x-speakeasy-globals:
  parameters:
    - name: customerId
      in: path
      schema:
        type: string
      x-speakeasy-globals-hidden: true # This will hide the global parameter from all operations
paths:
  /api/{customerId}:
    get:
      operationId: getTest
      parameters:
        - name: customerId
          in: path
          schema:
            type: string
          required: true
      responses:
        "200":
          description: OK
```

You can control the visibility of the global parameter by setting `x-speakeasy-globals-hidden` to `true` on the global parameter definition or on the operation parameter that matches the global parameter. Setting it globally hides the parameter from all operations. Setting it on a specific operation hides it only for that operation.


 This is the content for the doc docs/customize/methods.mdx 

 ---
title: "Customize methods"
description: "Learn how to customize method signatures, rename methods, and exclude specific methods from your SDK."
slug: "/customize-sdks/methods/"
---

import { Tabs } from "@speakeasy/nextra-theme";

# Customize methods

## Change method names

Speakeasy uses your OpenAPI schema to infer names for class types, methods, and parameters. However, you can override these names to tailor the generated SDK to your preferences.

The `x-speakeasy-name-override` extension can be used to override the name of a class, method, or parameter. Depending on where this extension is placed in an OpenAPI schema, names can be overridden at different scopes, such as globally or for specific operations and parameters.

For example, the `x-speakeasy-name-override` extension can be used to override the generated name for a method generated from an operation.

This extension can be applied globally by placing it at the root of the OpenAPI schema, allowing all methods with an `operationId` that matches the provided `operationId` regex to be overridden with `methodNameOverride`.

```yaml
openapi: 3.1.0
info:
  title: Test
  version: 0.0.1
servers:
  - url: https://httpbin.org
security:
  - basicAuth: []
x-speakeasy-name-override:
  - operationId: ^get.*
    methodNameOverride: get
  - operationId: ^post.*
    methodNameOverride: create
paths:
  /test:
    get:
      operationId: getTest
      responses:
        "200":
          description: OK
    post:
      operationId: postTest
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/Test"
      responses:
        "200":
        description: OK
```

Since `getTest` and `postTest` match the `^get.*` and `^post.*` regexes defined by the global `x-speakeasy-name-override` extension, these method names will be generated as `get` and `create`, respectively.

Alternatively, `x-speakeasy-name-override` can be used at the operation level to override the generated method name for that specific operation only. If the OpenAPI schema includes the extension at both the global and operation levels, the operation-level extension will take precedence. 

Consider the same schema shown above with an operation-level extension added to the `get` operation:

```yaml
---
get:
  operationId: getTest
  x-speakeasy-name-override: getRandomTest
  responses:
    "200":
      description: OK
```

Now, `postTest` will be generated as `create` as before, but `getTest` will be generated as `getRandomTest`.

## Configuring method signatures

To customize method signatures in an SDK, control how parameters are passed to the method by setting the `maxMethodParams` configuration option in the `gen.yaml` file.

Here is an example of how to set the `maxMethodParams` configuration option in your `gen.yaml` file:

```yaml
configVersion: 2.0.0
generation:
  # ...
typescript:
  maxMethodParams: 4
  # ...
```

Here, the `maxMethodParams` configuration option is set to `4`, so the generated SDK will have a maximum of four parameters for each method, including the request body parameter.

If the number of parameters for a method exceeds the `maxMethodParams` configuration option, the generated SDK will use a single request object parameter to encapsulate all the parameters.

To ensure the generator always creates a request object for an SDK, set `maxMethodParams` to `0`. This approach is useful for enabling request objects to evolve gracefully, avoiding breaking changes to the method signature when adding parameters in the future.

Here are examples of an SDK with `maxMethodParams` set to `4` and `0`:

<Tabs items={['TypeScript','Python','Go', 'Java', 'C#']}>
  <Tabs.Tab>
```typescript
// Example of SDK with maxMethodParams set to 4
import { Speakeasybar } from "speakeasy";

async function run() {
const sdk = new Speakeasybar();

    const ingredient = "vodka";
    const name = "martini";
    const limit = 100;

    const result = await sdk.drinks.listDrinks(ingredient, name, limit);

    // Handle the result
    console.log(result);

}

run();

// Example of SDK with maxMethodParams set to 0
import { Speakeasybar } from "speakeasy";

async function run() {
const sdk = new Speakeasybar();

    const result = await sdk.drinks.listDrinks({
        ingredient: "vodka",
        name: "martini",
        limit: 100,
    });

    // Handle the result
    console.log(result);

}

run();

````
  </Tabs.Tab>
  <Tabs.Tab>
```python
# Example of SDK with maxMethodParams set to 4
import sdk

s = sdk.SDK()


res = s.drinks.list_drinks(ingredient='vodka', name='martini', limit=100)

if res.drinks is not None:
    # handle response
    pass

# Example of SDK with maxMethodParams set to 0
import sdk
from sdk.models import operations

s = sdk.SDK()

req = operations.ListDrinksRequest(
    ingredient='vodka',
    name='martini',
    limit=100,
)

res = s.drinks.list_drinks(req)

if res.drinks is not None:
    # handle response
    pass
````

  </Tabs.Tab>
  <Tabs.Tab>
```go
// Example of SDK with maxMethodParams set to 4
package main

import (
	"context"
	"log"
	"speakeasy"
)

func main() {
s := speakeasy.New()

    var ingredient *string = speakeasy.String("vodka")

    var name *string = speakeasy.String("martini")

    var limit *int64 = speakeasy.Int64(100)

    ctx := context.Background()
    res, err := s.Drinks.ListDrinks(ctx, ingredient, name, limit)
    if err != nil {
    	log.Fatal(err)
    }
    if res.Drinks != nil {
    	// handle response
    }

}

// Example of SDK with maxMethodParams set to 0
package main

import (
	"context"
	"log"
	"speakeasy"
	"speakeasy/models/operations"
)

func main() {
s := speakeasy.New()

    ctx := context.Background()
    res, err := s.Drinks.ListDrinks(ctx, operations.ListDrinksRequest{
    	Ingredient: speakeasy.String("vodka"),
    	Name:       speakeasy.String("martini"),
    	Limit:      speakeasy.Int64(100),
    })
    if err != nil {
    	log.Fatal(err)
    }
    if res.Drinks != nil {
    	// handle response
    }

}

````
  </Tabs.Tab>
  <Tabs.Tab>
```java
// Example of SDK with maxMethodParams set to 4
package hello.world;

import java.math.BigDecimal;
import java.math.BigInteger;
import java.time.LocalDate;
import java.time.OffsetDateTime;
import java.util.Optional;
import org.openapis.openapi.SDK;
import org.openapis.openapi.models.components.*;
import org.openapis.openapi.models.operations.*;
import org.openapis.openapi.models.operations.ListDrinksRequest;
import org.openapis.openapi.models.operations.ListDrinksResponse;
import static java.util.Map.entry;

public class Application {

    public static void main(String[] args) {
        try {
            SDK sdk = SDK.builder()
                .build();

            ListDrinksResponse res = sdk.drinks().listDrinks()
                .ingredient("vodka")
                .name("martini")
                .limit(100L)
                .call();

            if (res.drinks().isPresent()) {
                // handle response
            }
        } catch (org.openapis.openapi.models.errors.SDKError e) {
            // handle exception
        } catch (Exception e) {
            // handle exception
        }
    }
}

// Example of SDK with maxMethodParams set to 0
package hello.world;

import java.math.BigDecimal;
import java.math.BigInteger;
import java.time.LocalDate;
import java.time.OffsetDateTime;
import java.util.Optional;
import org.openapis.openapi.SDK;
import org.openapis.openapi.models.components.*;
import org.openapis.openapi.models.operations.*;
import org.openapis.openapi.models.operations.ListDrinksRequest;
import org.openapis.openapi.models.operations.ListDrinksResponse;
import static java.util.Map.entry;

public class Application {

    public static void main(String[] args) {
        try {
            SDK sdk = SDK.builder()
                .build();

            ListDrinksRequest req = ListDrinksRequest.builder()
                .ingredient("vodka")
                .name("martini")
                .limit(100L)
                .build();

            ListDrinksResponse res = sdk.drinks().listDrinks()
                .request(req)
                .call();

            if (res.drinks().isPresent()) {
                // handle response
            }
        } catch (org.openapis.openapi.models.errors.SDKError e) {
            // handle exception
        } catch (Exception e) {
            // handle exception
        }
    }
}
````

  </Tabs.Tab>
  <Tabs.Tab>
```csharp
// Example of SDK with maxMethodParams set to 4
using Openapi;
using Openapi.Models.Operations;
using Openapi.Models.Shared;
using NodaTime;

var sdk = new SDK();

var res = await sdk.Drinks.ListDrinksAsync("vodka", "martini", 100);

// handle response

// Example of SDK with maxMethodParams set to 0
using Openapi;
using Openapi.Models.Operations;
using Openapi.Models.Shared;
using NodaTime;

var sdk = new SDK();

var req = new ListDrinksRequest()
{
Ingredient = "vodka",
Name = "martini",
Limit = 100
};

var res = await sdk.Drinks.ListDrinksAsync(req);

// handle response

````
  </Tabs.Tab>
</Tabs>

You can also set `maxMethodParams` using the `x-speakeasy-max-method-params` extension in your OpenAPI document, either globally at the root of the document or at the operation level.

The order of precedence for configuration is:

- Operation-level `x-speakeasy-max-method-params`
- Global-level `x-speakeasy-max-method-params`
- The `maxMethodParams` configuration option in the `gen.yaml` file

The configuration set in `gen.yaml` or through the extension at the root of the document will apply to all operations unless an operation-level extension overrides it.

### Exclude parameters from signatures

To exclude certain parameters from the generated SDK, use the `x-speakeasy-ignore` extension.

The following example uses `x-speakeasy-ignore: true` to exclude a parameter:

```yaml
paths:
  /test/user/{user_id}:
    parameters:
      - name: user_id
        in: path
        required: true
        schema:
          type: string
      - name: status
        x-speakeasy-ignore: true
        in: query
        required: true
        schema:
          type: string
    get:
      operationId: getUser
      responses:
        "200":
          description: OK
          ...
````

## Exclude methods from an SDK

Use the `x-speakeasy-ignore` extension to exclude certain methods from the generated SDK.

The following example illustrates several instances of `x-speakeasy-ignore: true` used across a schema.

```yaml
paths:
  /test:
    get:
      x-speakeasy-ignore: true
      operationId: getTest
      responses:
        "200":
          description: OK
```



 This is the content for the doc docs/customize/responses/errors.mdx 

 ---
title: Customize error handling
description: "Learn how to customize error handling in Speakeasy SDKs."
slug: "/customize-sdks/errors/"
---

# Customize Error Handling

Below is a structured guide on how to configure and customize error handling in Speakeasy-generated SDKs.


## Default Error Handling (no configuration)

By default, Speakeasy SDKs handle errors as follows:

1. **Validation Errors**: If the server response doesn't match the SDK's expected data schema, validation errors will be raised.
2. **4XX and 5XX Status Codes**: Responses with these status codes are treated as errors.
3. **Connection Errors**: If the SDK fails to connect to your server (DNS, timeouts, TLS errors), it raises a connection-related error/exception.


<details>
<summary>Example OpenAPI file</summary>
```yaml
openapi: 3.1.0
info:
  title: The Speakeasy Bar
  version: 1.0.0
servers:
  - url: https://speakeasy.bar
paths:
  /drinks:
    get:
      operationId: listDrinks
      summary: Get a list of drinks
      responses:
        "200":
          description: A list of drinks
          content:
            application/json:
              schema:
                type: array
                items:
                  $ref: "#/components/schemas/Drink"
components:
  schemas:
    Drink:
      type: object
      title: Drink
      properties:
        name:
          type: string
```
</details>


<details open>
<summary>TypeScript SDK Default Error Handling</summary>

```typescript
// !focus(15:37)
import { Drinks } from "drinks";
import { 
  SDKValidationError,
  SDKError,
  HTTPClientError,
} from "drinks/models/errors/index.js";

const drinks = new Drinks();

async function run() {
  let result;
  try {
    result = await drinks.listDrinks();
    console.log(result);
  } catch (err) {
    // 1. Validation Errors: Server response didn't match the SDK's expected data schema
    if (err instanceof SDKValidationError) {
      // Raw value will be type `unknown`
      console.error(err.rawValue);
      // Validation errors can be pretty-printed
      console.error(err.pretty());
      return;
    }

    // 2. 4XX and 5XX Status Codes: Server returned an error code an unexpected content type
    // Use `typescript.defaultErrorName` to change the name of `SDKError` in `gen.yaml`
    if (err instanceof SDKError) {
      console.error(err.statusCode);
      console.error(err.rawResponse.body);
      return;
    }

    // 3. Connection Errors: The SDK didn't even get a response from the server
    if (err instanceof HTTPClientError) {
      console.error(err.name);
      console.error(err.message);
    }

    throw err;
  }
}
```
</details>



## Recommended Configuration

To improve the DX for the end user of the SDK, we recommend that you have named error classes for certain types of errors eg `UnauthorizedError`, `NotFoundError`, etc. It is also common that your API will return structured JSON errors for your 4XX responses. Here is an example of how you could configure this in your OpenAPI document:

```yaml
#!focus(21:40)
openapi: 3.1.0
info:
  title: The Speakeasy Bar
  version: 1.0.0
servers:
  - url: https://speakeasy.bar
paths:
  /drinks:
    get:
      operationId: listDrinks
      summary: Get a list of drinks
      responses:
        "200":
          description: A list of drinks
          content:
            application/json:
              schema:
                type: array
                items:
                  $ref: "#/components/schemas/Drink"
        "401":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/UnauthorizedError"
        "403":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ForbiddenError"
        "404":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/NotFoundError"
        "429":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/TooManyRequestsError"
components:
  schemas:
    Drink:
      type: object
      title: Drink
      properties:
        name:
          type: string
    UnauthorizedError:
      type: object
      title: UnauthorizedError
      properties:
        message:
          type: string
          x-speakeasy-error-message: true
    ForbiddenError:
      type: object
      title: ForbiddenError
      properties:
        message:
          type: string
          x-speakeasy-error-message: true
    NotFoundError:
      type: object
      title: NotFoundError
      properties:
        message:
          type: string
          x-speakeasy-error-message: true
    TooManyRequestsError:
      type: object
      title: TooManyRequestsError
      properties:
        message:
          type: string
          x-speakeasy-error-message: true
```

Note, we don't tend to recommend defining 5XX responses as your server is not always in control of the response. If you do specify a JSON schema for a 5XX response and the response doesn't match the schema, the SDK will raise a `SDKValidationError`.

Note the use of `x-speakeasy-error-message: true` to configure the error message to be used by the SDK, which will be propagated to `err.message` in the SDK.


<details open>
<summary>TypeScript SDK Default Error Handling</summary>

```typescript
// !focus(15:43)
import { Drinks } from "drinks";
import { 
  SDKValidationError,
  SDKError,
  HTTPClientError,
  UnauthorizedError,
  ForbiddenError,
  NotFoundError,
  TooManyRequestsError,
} from "drinks/models/errors/index.js";

const drinks = new Drinks();

async function run() {
  let result;
  try {
    result = await drinks.listDrinks();
    console.log(result);
  } catch (err) {
    // Unauthorized
    if (err instanceof UnauthorizedError) {
      console.error(err.message);
      return;
    }

    // Forbidden
    if (err instanceof ForbiddenError) {
      console.error(err.message);
      return;
    }

    // Not Found
    if (err instanceof NotFoundError) {
      console.error(err.message);
      return;
    }

    // Too Many Requests
    if (err instanceof TooManyRequestsError) {
      console.error(err.message);
      return;
    }
    
    // 1. Validation Errors: Server response didn't match the SDK's expected data schema
    if (err instanceof SDKValidationError) {
      // Raw value will be type `string`
      console.error(err.rawValue);
      // Validation errors can be pretty-printed
      console.error(err.pretty());
      return;
    }

    // 2. 4XX and 5XX Status Codes: Server returned an error code an unexpected content type
    // Use `typescript.defaultErrorName` to change the name of `SDKError` in `gen.yaml`
    if (err instanceof SDKError) {
      console.error(err.statusCode);
      console.error(err.rawResponse.body);
      return;
    }

    // 3. Connection Errors: The SDK didn't even get a response from the server
    if (err instanceof HTTPClientError) {
      console.error(err.name);
      console.error(err.message);
    }

    throw err;
  }
}
```
</details>


## Advanced Configuration


### Renaming Generated Error Classes

Any unhandled API Error will raise a exception of the default `SDKError`/`APIError`/`APIException` class depending on the SDK language. To change the name of the default error class, edit the `defaultErrorName` parameter in your `gen.yaml` file for the corresponding SDK language:

  ```yaml
  python:
    defaultErrorName: MyError
  ```

To rename other generated error classes, please refer to the [Customizing Types](/docs/customize-sdks/types) documentation to rename generated error classes.

### Handling the Default Error Response

The `default` response code is a catch-all for any status code not explicitly defined. By default, Speakeasy SDKs treat default responses as non-error responses. To treat it as a specific error type, define the default response in the `x-speakeasy-errors` extension on any operation:

```yaml
x-speakeasy-errors:
  statusCodes:
    - "default"
```

### Disabling Default Error Handling

In certain cases, you may want to disable the default error handling behavior of SDKs. For example, you may not want to throw an error for a 404 status code.

You can use the `x-speakeasy-errors` extension to override the default error-handling behavior of SDKs.

Apply the `x-speakeasy-errors` extension at the `paths`, `path item`, or `operation` level. Deeper levels merge or override parent behavior.

The `x-speakeasy-errors` extension is an object with the following properties:

| Property      | Type       | Description                                                                                                                                                                                                                                                                                                                       |
| ------------- | ---------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `override`    | `boolean`  | If `true`, the statusCodes list overrides any parent `x-speakeasy-errors` extension for this object and its children. Defaults to `false`.   |
| `statusCodes` | `[string]` | An array of status codes to handle as errors. Merges with any parent `x-speakeasy-errors` extension unless override is `true`. Each status code must be in quotation marks (e.g., `"503"`) for JSON and YAML compatibility. Wildcards (e.g., `5XX`) are supported. |

If the `statusCodes` array contains undocumented status codes, the SDK returns an SDK error object with the status code, response body as a string, and the raw response object. Otherwise, if `content-type` is `application/json`, it returns an error object from the response object in the OpenAPI document.

Example:

```yaml
paths:
  x-speakeasy-errors:
    statusCodes: # Defines status codes to handle as errors for all operations
      - 4XX # Wildcard to handle all status codes in the 400-499 range
      - 5XX
  /drinks:
    x-speakeasy-errors:
      override: true # Forces this path and its operations to only handle 404 and 500 as errors, overriding the parent x-speakeasy-errors extension at the paths level
      statusCodes:
        - 404
        - 500
    get:
      x-speakeasy-errors:
        statusCodes: # As override is not set to true, this operation will handle 404, 401, 500, and 503 as errors, merging with the parent x-speakeasy-errors extension at the path item level
          - 401
          - 503
      operationId: getDrinks
      responses:
        200:
          description: OK
          content:
            application/json:
              schema:
                type: array
                items:
                  $ref: "#/components/schemas/Drink"
        401:
          description: Unauthorized
          content:
            application/json: # As an application/json response is defined, the schema will generate a custom error object (for example `AuthError`) that will be returned and can be tested for
              schema:
                $ref: "#/components/schemas/AuthError"
        404:
          description: Not Found # As no application/json response is defined, the SDK will return a standard SDK error object.
        500:
          description: Internal Server Error
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/Error"
        503:
          description: Service Unavailable
```

Another way to disable default error handling is to set the `clientServerStatusCodesAsErrors` option to `false` in your `gen.yaml` file for the SDK language:

```yaml
  go:
    clientServerStatusCodesAsErrors: false
```


 This is the content for the doc docs/customize/responses/responses.mdx 

 ---
title: Customize responses
description: "Learn how to customize response formats."
slug: "/customize-sdks/responses/"
---

import { Tabs } from "@speakeasy/nextra-theme";

# Customize responses

## Response formats

When generating SDKs, response formats determine the structure of response types in supported languages. You can choose from three available response formats.

Configure the response format for a given target in the `gen.yaml` file:

```yaml
typescript:  # Python and Go can be configured in a similar way
  responseFormat: flat  # Or envelope-http, or envelope

  packageName: @acme/super-sdk
  version: 0.1.0
  author: Speakeasy

  templateVersion: v2
  clientServerStatusCodesAsErrors: true
  maxMethodParams: 4
  flattenGlobalSecurity: true
  inputModelSuffix: input
  outputModelSuffix: output
  additionalDependencies:
    dependencies: {}
    devDependencies: {}
    peerDependencies: {}
  imports:
    option: openapi
    paths:
      callbacks: models/callbacks
      errors: models/errors
      operations: models/operations
      shared: models/components
      webhooks: models/webhooks
```

The following sections will reference this specification:

```yaml
  /payments/{id}:
    get:
      operationId: getPayment
      parameters:
        - name: id
          in: path
          required: true
          schema:
            type: string
      responses:
        "200":
          description: Details about a payment
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/Payment"
components:
  schemas:
    Payment:
      type: object
      required: [id,amount,currency]
      properties:
        id:
          type: integer
        amount:
          type: number
        currency:
          type: string
```

### `responseFormat: flat`

The flat response format is the simplest and most ergonomic option, as it avoids generating a wrapper type, giving SDK users direct access to the response value.

When `responseFormat: flat` is enabled, the generated SDK code will return the `Payment` type directly with no indirection:

<Tabs items={['TypeScript','Python','Go', 'C#']}>
  <Tabs.Tab>

    ```typescript
    export class SDK extends ClientSDK {
      async getPayment(id: string, options?: RequestOptions): Promise<components.Payment> {}
    }
    ```

  </Tabs.Tab>

  <Tabs.Tab>

    ```python
    class SDK:
        def get_payment(self, id: str) -> components.Payment:
    ```

  </Tabs.Tab>

  <Tabs.Tab>

    ```go
    func (s *SDK) GetPayment(ctx context.Context, id string) (*components.Payment, error) {}
    ```

  </Tabs.Tab>

  <Tabs.Tab>

    ```csharp
    public async Task<Payment> GetPaymentAsync(string id){}
    ```

  </Tabs.Tab>
</Tabs>

To debug HTTP metadata, users can pass a [custom client][custom-http] to the SDK instance.

[custom-http]: /docs/customize-sdks/custom-http-client

### `responseFormat: envelope-http`

The `envelope-http` format builds response types with a wrapper that holds the response value and associated HTTP metadata.

When `envelope-http` is enabled, the generated SDK code will produce the response types below:

<Tabs items={['TypeScript','Python','Go', 'C#']}>
  <Tabs.Tab>

    ```typescript
    class SDK extends ClientSDK {
        async getPayment(id: string, options?: RequestOptions): Promise<operations.GetPaymentResponse> {}
    }
    ```

    ```typescript
    export type GetPaymentResponse = {
        httpMeta: components.HTTPMetadata;

        /**
         * Details about a payment
         */
        payment?: components.Payment | undefined;
    };
    ```

    ```typescript
    export type HTTPMetadata = {
      /**
       * Raw HTTP response; suitable for custom response parsing
       */
      response: Response;
      /**
       * Raw HTTP request; suitable for debugging
       */
      request: Request;
    };
    ```

  </Tabs.Tab>

  <Tabs.Tab>

    ```python
    class SDK:
        def get_payment(self, id: str) -> operations.GetPaymentResponse:
    ```

    ```python
    @dataclasses.dataclass
    class GetPaymentResponse:
        http_meta: components_httpmetadata.HTTPMetadata = dataclasses.field()

        payment: Optional[components_payment.Payment] = dataclasses.field(default=None)
        r"""Details about a payment"""
    ```

    ```python
    @dataclass_json(undefined=Undefined.EXCLUDE)
    @dataclasses.dataclass
    class HTTPMetadata:
        response: requests.Response = dataclasses.field(metadata={'dataclasses_json': { 'exclude': lambda f: True }})
        r"""Raw HTTP response; suitable for custom response parsing"""
        request: requests.Request = dataclasses.field(metadata={'dataclasses_json': { 'exclude': lambda f: True }})
        r"""Raw HTTP request; suitable for debugging"""
    ```

  </Tabs.Tab>

  <Tabs.Tab>

    ```go
    func (s *SDK) GetPayment(ctx context.Context, id string) (*operations.GetPaymentResponse, error) {}
    ```

    ```go
    type GetPaymentResponse struct {
      HTTPMeta components.HTTPMetadata

      // Details about a payment
      Payment *components.Payment
    }
    ```

    ```go
    type HTTPMetadata struct {
      // Raw HTTP response; suitable for custom response parsing
      Response *http.Response `json:"-"`
      // Raw HTTP request; suitable for debugging
      Request *http.Request `json:"-"`
    }
    ```

  </Tabs.Tab>

  <Tabs.Tab>

    ```csharp
    Task<GetPaymentResponse> GetPaymentAsync(string id);
    ```

    ```csharp
    public class GetPaymentResponse
    {
        public HTTPMetadata HttpMeta { get; set; } = default!;
        // Details about a payment
        public Payment? Payment { get; set; } = default!;
    }
    ```

    ```csharp
    public class HTTPMetadata
    {

        /// <summary>
        /// Raw HTTP response; suitable for custom response parsing
        /// </summary>
        [JsonProperty("-")]
        public HttpResponseMessage Response { get; set; } = default!;

        /// <summary>
        /// Raw HTTP request; suitable for debugging
        /// </summary>
        [JsonProperty("-")]
        public HttpRequestMessage Request { get; set; } = default!;
    }
    ```

  </Tabs.Tab>
</Tabs>

Built-in HTTP metadata is included in both custom and built-in error types that are thrown or returned from the SDK.

Of the three response formats, `envelope-http` provides the most details about the underlying HTTP requests but adds a layer of indirection with a wrapper value.

### `responseFormat: envelope`

The `responseFormat: envelope` format builds response types with a wrapper that holds the response value and minimal information about the underlying HTTP response.

> Using `envelope-http` instead of `envelope` is recommended as it
> provides a more complete view of the HTTP request and response.

When `responseFormat: envelope` is enabled, the generated SDK code will produce the response types below:

<Tabs items={['TypeScript','Python','Go', 'C#']}>
  <Tabs.Tab>

    ```typescript
    class SDK extends ClientSDK {
        async getPayment(id: string, options?: RequestOptions): Promise<operations.GetPaymentResponse> {}
    }
    ```

    ```typescript
    export type GetPaymentResponse = {
      /**
       * HTTP response content type for this operation
       */
      contentType: string;
      /**
       * HTTP response status code for this operation
       */
      statusCode: number;
      /**
       * Raw HTTP response; suitable for custom response parsing
       */
      rawResponse: Response;
      /**
       * Details about a payment
       */
      payment?: components.Payment | undefined;
    };
    ```

  </Tabs.Tab>

  <Tabs.Tab>

    ```python
    class SDK:
        def get_payment(self, id: str) -> operations.GetPaymentResponse:
    ```

    ```python
    @dataclasses.dataclass
    class GetPaymentResponse:
        http_meta: components_httpmetadata.HTTPMetadata = dataclasses.field()

        payment: Optional[components_payment.Payment] = dataclasses.field(default=None)
        r"""Details about a payment"""
    ```

    ```python
    @dataclasses.dataclass
    class GetPaymentResponse:
        content_type: str = dataclasses.field()
        r"""HTTP response content type for this operation"""
        status_code: int = dataclasses.field()
        r"""HTTP response status code for this operation"""
        raw_response: requests_http.Response = dataclasses.field()
        r"""Raw HTTP response; suitable for custom response parsing"""
        payment: Optional[components_payment.Payment] = dataclasses.field(default=None)
        r"""Details about a payment"""
    ```

  </Tabs.Tab>

  <Tabs.Tab>

    ```go
    func (s *SDK) GetPayment(ctx context.Context, id string) (*operations.GetPaymentResponse, error) {}
    ```

    ```go
    type GetPaymentResponse struct {
      // HTTP response content type for this operation
      ContentType string
      // HTTP response status code for this operation
      StatusCode int
      // Raw HTTP response; suitable for custom response parsing
      RawResponse *http.Response
      // Details about a payment
      Payment *components.Payment
    }
    ```

  </Tabs.Tab>

  <Tabs.Tab>

    ```csharp
    Task<GetPaymentResponse> GetPaymentAsync(string id);
    ```

    ```csharp
    public class GetPaymentResponse
    {

        /// <summary>
        /// HTTP response content type for this operation
        /// </summary>
        public string? ContentType { get; set; } = default!;

        /// <summary>
        /// HTTP response status code for this operation
        /// </summary>
        public int StatusCode { get; set; } = default!;

        /// <summary>
        /// Raw HTTP response; suitable for custom response parsing
        /// </summary>
        public HttpResponseMessage RawResponse { get; set; } = default!;

        /// <summary>
        /// OK
        /// </summary>
        public Payment? Res { get; set; }
    }
    ```

  </Tabs.Tab>
</Tabs>


 This is the content for the doc docs/customize/runtime/custom-http-client.mdx 

 ---
title: Custom HTTP clients
description: "Learn how to customize Speakeasy SDKs & provide custom HTTP clients to use a proxy, enable custom telemetry, add headers, or use preconfigured options."
slug: "/customize-sdks/custom-http-client/"
---

import { Tabs } from "@speakeasy/nextra-theme";

# Use Custom HTTP Clients

SDK users can provide a custom HTTP client when initializing SDKs. This is useful for modifying or debugging requests and responses in flight.

See below for per-language examples:

<Tabs items={['Go','Python', 'Typescript', 'Java', 'C#']}>
  <Tabs.Tab>

The Go SDK will accept a client that implements a `Do(*http.Request) (*http.Response, error)` method similar to the standard library&apos;s `http.Client`.

```go
// A custom HTTP client that implements caching
c := NewCachedClient(&http.Client{}, cache)

opts := []sdk.SDKOption{
    sdk.WithClient(c),
}

s := sdk.New(opts)
```

  </Tabs.Tab>
  <Tabs.Tab>

The Python SDK will accept any client that implements the `HttpClient` interface from the SDK. Here&apos;s an example using the [`requests`](https://requests.readthedocs.io/en/latest/) library:

```python mark=7
import requests
from sdk import SDK, HttpClient

# Define a custom HTTP client using Requests
class RequestsHttpClient(HttpClient):
    def __init__(self):
        self.session = requests.Session()

    def send(self, request, **kwargs):
        return self.session.send(request.prepare())

    def build_request(
        self,
        method,
        url,
        *,
        content = None,
        headers = None,
        **kwargs,
    ):
        return requests.Request(
            method=method,
            url=url,
            data=content,
            headers=headers,
        )

# Initialize the custom client
client = RequestsHttpClient()

# Initialize the SDK with the custom client
sdk = SDK(client=client)

# Use the SDK client
res = sdk.method_name()
```

  </Tabs.Tab>
  <Tabs.Tab>

The TypeScript SDK makes API calls using an `HTTPClient` that wraps the native[Fetch API](https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API). This client is a thin wrapper around `fetch` and provides the ability to attach hooks around the request lifecycle that can be used to modify the request or handleerrors and response.

```typescript
import { SDK } from "openapi";
import { HTTPClient } from "openapi/lib/http";

// Create an HTTPClient instance with the default fetcher
const httpClient = new HTTPClient({
   // fetcher takes a function that has the same signature as native `fetch`.
  fetcher: async (request) => fetch(request),
});

httpClient.addHook("requestError", (err) => {
  console.log(`Request failed: ${err}`);
});

// Initialize the SDK with the custom HTTP client
const sdk = new SDK({ httpClient });

```

  </Tabs.Tab>
  <Tabs.Tab>

The Java SDK will accept a client that implements the `HTTPClient` interface in the `utils` package. This will wrap a `java.net.http.HttpClient` instance and the call to `send`.

```java
// Your custom HTTP client
YouHttpClient client = new YourHttpClient();

SDK.Builder builder = SDK.builder();

builder.setClient(client);

SDK sdk = builder.build();
```

  </Tabs.Tab>
  <Tabs.Tab>
```csharp
// YourHttpClient must implement the ISpeakeasyHttpClient interface
var httpClient = new YourHttpClient();
// Initialize the SDK with your custom HTTP client
var sdk = new SDK(client: httpClient);
```
  </Tabs.Tab>
</Tabs>


 This is the content for the doc docs/customize/runtime/override-accept-headers.mdx 

 ---
title: Override accept headers
description: "APIs can support multiple content types for responses. Learn how to use headers in Speakeasy SDKs to receive the data in the format you prefer."
slug: "/customize-sdks/override-accept-headers/"
---

import { Tabs } from "@speakeasy/nextra-theme";

# Override Accept Headers

The OpenAPI specification makes it easy for you to use the `content` directive to specify which endpoints in your API support multiple content types.

In this example, our get-all-users endpoint can return a response encoded either as unstructured `text/plain` data or as a structured `application/json` document.

```yaml
/getall:
  get:
    operationId: getAll
    tags:
      - users
    responses:
      "200":
        description: OK
        content:
          text/plain:
            schema:
              type: string
          application/json:
            schema:
              type: string
```

When invoking the operation normally, your Speakeasy SDK will automatically default to the first option in the list, in this case, `text/plain`.

For any API operations that specify multiple accept headers in your OpenAPI specification, your Speakeasy SDK provides a mechanism to override the accept header so that you can receive your data in the format you prefer.

## Accept Header Override in Go

In Go, all types from all operations are collected into a global `AcceptHeaderEnum` type that can be found in `sdk/operations/options.go`.

```go
type AcceptHeaderEnum string

const (
	AcceptHeaderEnumApplicationJson        AcceptHeaderEnum = "application/json"
	AcceptHeaderEnumTextPlain              AcceptHeaderEnum = "text/plain"
)
```

By invoking the `WithAcceptHeaderOverride` function with the appropriate `AcceptHeaderEnum`, you can create the optional parameter that you can then pass to your operation:

```go
s := sdk.New()
ctx := context.Background()
res, err := s.Users.GetAll(ctx, operations.WithAcceptHeaderOverride(operations.AcceptHeaderEnumApplicationJSON))
```

## Accept Header Override in Python and TypeScript

In Python and TypeScript, each operation with multiple specified accept headers will have an enum created that provides the acceptable options. The name of the enum will be the tag name, followed by the operation name, followed by `AcceptEnum`. For the example above, that would be `UsersGetAllAcceptEnum`.

<Tabs items={['Typescript', 'Python']}>
  <Tabs.Tab>

    ```typescript
    import { UsersGetAllAcceptEnum } from "../src/sdk/users";

    const s = new SDK({});

    const res = await s.users.getAll(undefined, undefined, UsersGetAllAcceptEnum.applicationJSON);
    ```

  </Tabs.Tab>
  <Tabs.Tab>

    ```python
    from sdk.users import ResponseBodyOptionalGetAcceptEnum

    s = SDK()

    res = s.users.get_all(
        accept_header_override=UsersGetAllAcceptEnum.APPPLICATION_JSON
    )
    ```

  </Tabs.Tab>
</Tabs>

## Unspecified Accept Headers

While we strongly recommend adding all accept headers to your OpenAPI spec, in Go, it is possible to override the accept header to an unspecified value.

```go
s := sdk.New()
ctx := context.Background()
res, err := s.Users.GetAll(ctx, operations.WithAcceptHeaderOverride("application/json+debug"))
```

There is no support for unspecified accept headers in Python or TypeScript.


 This is the content for the doc docs/customize/runtime/pagination.mdx 

 ---
description: "Learn how to simplify pagination in Speakeasy-managed SDKs by creating SDKs with built-in pagination rules."
sidebar_label: "Add Pagination"
slug: "/customize-sdks/pagination/"
---

# Adding Pagination to Your SDK

Customize pagination rules for each API operation using the `x-speakeasy-pagination` extension.

Adding pagination to an SDK enhances the developer experience by providing a structured way to handle paginated API responses.

```python
response = sdk.paginatedEndpoint(page=1)
while response is not None:
    # handle response

    response = response.next()
```

The `next()` function returns `nil, nil` when there are no more pages to retrieve, indicating the end of pagination rather than an error

## Configuring Pagination

To configure pagination, add the `x-speakeasy-pagination` extension to your OpenAPI specification.

```yaml
/paginated/endpoint:
  get:
    parameters:
      - name: page
        in: query
        schema:
          type: integer
        required: true
    responses:
      "200":
        description: OK
        content:
          application/json:
            schema:
              title: res
              type: object
              properties:
                resultArray:
                  type: array
                  items:
                    type: integer
              required:
                - resultArray
    x-speakeasy-pagination:
      type: offsetLimit
      inputs:
        - name: page
          in: parameters
          type: page
      outputs:
        results: $.resultArray
```

The `x-speakeasy-pagination` configuration supports `offsetLimit`, `cursor`, and `url` implementations of pagination.

### Offset and Limit Pagination

For `type: offsetLimit pagination`, specify at least one of the following `inputs`: `offset` or `page`.

```yaml
x-speakeasy-pagination:
  type: offsetLimit
  inputs:
    - name: page # This input refers to the value called `page`
      in: parameters # In this case, page is an operation parameter (header, query, or path)
      type: page # The page parameter will be used as the page-value for pagination, and will be incremented when `next()` is called
    - name: limit # This input refers to the value called `limit`
      in: parameters # In this case, limit is an operation parameter (header, query, or path)
      type: limit # The limit parameter will be used as the limit-value for pagination
  outputs:
    results: $.data.resultArray # The data.resultArray value of the response will be used to infer whether there is another page
```

At least one response object must have the following structure:

```json
{
  "data": {
    "resultArray": []
  }
}
```

If `inputs.limit` is defined in the pagination configuration, `next()` will return `null` when `$.data.resultArray` has a length of less than the `inputs.limit` value. If `inputs.limit` is omitted, `next()` will return `null` when the length of `$.data.resultArray` is zero.

When using the page input, `output.numPages` can be used instead of `output.results` to determine when the pages for the operation are exhausted.

```yaml
x-speakeasy-pagination:
  type: offsetLimit
  inputs:
    - name: page # This input refers to the value called `page`
      in: parameters # In this case, page is an operation parameter (header, query, or path)
      type: page # The page parameter will be used as the page, and will be incremented when `next()` is called
  outputs:
    numPages: $.data.numPages # The data.numPages value of the response will be used to infer whether there is another page
```

If `output.numPages` is provided, `next()` returns `null` when the incremented page number is greater than the `numPages` value.

At least one response object must have the following structure:

```json
{
  "data": {
    "numPages": 1
  }
}
```

For example, in the following `inputs.offset` configuration, `inputs.limit` has the same effect as in the `inputs.page` example.

```yaml
x-speakeasy-pagination:
  type: offsetLimit
  inputs:
    - name: offset # This offset refers to the value called `offset`
      in: parameters # In this case, offset is an operation parameter (header, query, or path)
      type: offset # The offset parameter will be used as the offset, which will be incremented by the length of the `output.results` array
  outputs:
    results: $.data.resultArray # The length of data.resultArray value of the response will be added to the `offset` value to determine the new offset
```



### Cursor-Based Pagination

For `type: cursor pagination`, configure the `nextCursor` output.

The following is an example `inputs.cursor` configuration.

```yaml
x-speakeasy-pagination:
  type: cursor
  inputs:
    - name: since
      in: requestBody
      type: cursor
  outputs:
    nextCursor: $.data.resultArray[(@length-1)].created_at
```

Because the input above is `in` the `requestBody`, this operation must take a request body with **at least** the following structure:

```json
{
  "since": ""
}
```

At least one response object must have the following structure:

```json
{
  "data": {
    "resultArray": [
      {
        "created_at": ""
      }
    ]
  }
}
```

The `[@length-1]` syntax in `outputs.nextCursor` indicates the last value in an array. Ensure the type of `requestBody.since` matches the type of `outputs.nextCursor`.

### URL-Based Pagination

When your API returns a URL for the next page, you can use the `url` type in `x-speakeasy-pagination`. Here's an example configuration:

```yaml
/paginated/endpoint:
  get:
    parameters:
      - name: page
        in: query
        schema:
          type: integer
        required: true
    responses:
      "200":
        description: OK
        content:
          application/json:
            schema:
              title: PaginatedResponse
              type: object
              properties:
                results:
                  type: array
                  items:
                    type: object
                next:
                  type: string
                  format: uri
              required:
                - results
                - next
    x-speakeasy-pagination:
      type: url
      outputs:
        nextUrl: $.next
```

The `x-speakeasy-pagination` configuration specifies the type as `url` and uses a JSONPath expression to extract the `nextUrl` from the response.

The response object for the URL-based pagination should have the following structure:

```json
{
  "results": [{ "field": "value" }],
  "next": "http://some_url?page=2"
}
```

## Inputs

**`name`**

With `in: parameters`, this is the name of the parameter to use as the input value.

With `in: requestBody`, this is the name of the request-body property to use as the input value.

**`in`**

Indicates whether the input should be passed into the operation as a path or query parameter (`in: parameters`) or in the request body (`in: requestBody`). Only simple objects are permitted as values in the request body.

**`type`**

| Type     | Description                                                                                                                                           |
| -------- | ----------------------------------------------------------------------------------------------------------------------------------------------------- |
| `page`   | The variable that will be incremented on calling `next()`.                                                                                            |
| `offset` | The variable that will be incremented by the number of results returned by the previous execution. **Note:** Requires `outputs.Results`.              |
| `limit`  | When provided, `next()` returns `null` (or equivalent) when the number of results returned by the previous execution is less than the value provided. |

## Outputs

All the outputs are expected to be strings adhering to the [JSONPath](https://goessner.net/articles/JsonPath/) schema.

| Key          | Description                                                                                                                                          |
| ------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------- |
| `numPages`   | When provided, `next()` returns `null` if the `page` input value exceeds the value found at the provided JSON path. **Note:** Requires `page` input. |
| `results`    | When provided, `next()` returns `null` if the array found at the provided JSON path is empty. **Note:** Required by `offset` input.                  |
| `nextCursor` | Populates `cursor` with the value found at the provided JSON path when calling `next()`. **Note:** Required by `type: cursor`.                       |

If the JSONPath value provided for an output does not match the response returned, `next()` returns `null` because pagination cannot be continued.


 This is the content for the doc docs/customize/runtime/retries.mdx 

 ---
title: Retries
description: "Automatically retry failed requests in your Speakeasy SDKs. Enable retries globally or per request."
slug: "/customize-sdks/retries/"
---

import { Tabs } from "@speakeasy/nextra-theme";

# Retries

With Speakeasy, you can generate SDKs that will automatically retry requests that fail due to network errors or any configured HTTP status code. You can enable retries globally for all requests or on a per-request basis by using the `x-speakeasy-retries` extension in your OpenAPI document. The SDK end user can then override the default configuration by passing in a `RetryConfig` object to the operation at runtime.

## Global Retries

```yaml
openapi: 3.0.3
info:
  title: Swagger Petstore - OpenAPI 3.0
  version: 1.0.11
servers:
  - url: https://petstore3.swagger.io/api/v3
x-speakeasy-retries:
  strategy: backoff
  backoff:
    initialInterval: 500 # 500 milliseconds
    maxInterval: 60000 # 60 seconds
    maxElapsedTime: 3600000 # 5 minutes
    exponent: 1.5
  statusCodes:
    - 5XX
  retryConnectionErrors: true
```

If you add the `x-speakeasy-retries` extension to the root of the OpenAPI document, the SDK Generator will generate a global retry configuration that will be used for all requests made by the SDK. The `x-speakeasy-retries` extension supports the following properties:

| Property                  | Type      | Description                                                             | Required |
| ------------------------- | --------- | ----------------------------------------------------------------------- | -------- |
| `strategy`                | `string`  | The retry strategy to use. Only `backoff` is currently supported.       | Yes      |
| `backoff`                 | `object`  | The configuration of the backoff strategy, if chosen.                   | No       |
| `backoff.initialInterval` | `integer` | The initial interval to use for the backoff strategy (in milliseconds). | No       |
| `backoff.maxInterval`     | `integer` | The maximum interval between retries (in milliseconds).                 | No       |
| `backoff.maxElapsedTime`  | `integer` | The maximum elapsed time to retry for (in milliseconds).                | No       |
| `backoff.exponent`        | `number`  | The exponent used to increase the interval between retries.             | No       |
| `statusCodes`             | `array`   | The HTTP status codes to retry on.                                      | Yes      |
| `retryConnectionErrors`   | `boolean` | Whether to retry any connection errors.                                 | No       |

The `statusCodes` property supports passing a list of distinct HTTP status codes or a wildcard range to retry requests on. For example, `5XX` will retry requests on all status codes between 500 (inclusive) and 600 (exclusive).

Set the `retryConnectionErrors` property to `true` to configure retrying requests that fail due to network errors like DNS resolution errors or connection refused errors.

The defaults for the backoff strategy are:

- `initialInterval`: 500
- `maxInterval`: 60000
- `maxElapsedTime`: 3600000
- `exponent`: 1.5

## Per-request Retries

Add the `x-speakeasy-retries` extension to any operation to override the global retry configuration for that operation, or to configure retries for the operation if retries aren't defined globally. For example, you might want to configure retries for an operation on a different set of HTTP status codes or specify different intervals between retries.

```yaml
openapi: 3.0.3
info:
  title: Swagger Petstore - OpenAPI 3.0
  version: 1.0.11
servers:
  - url: https://petstore3.swagger.io/api/v3
paths:
  /pet/findByStatus:
    get:
      operationId: findPetsByStatus
      x-speakeasy-retries:
        strategy: backoff
        backoff:
          initialInterval: 500 # 500 milliseconds
          maxInterval: 60000 # 60 seconds
          maxElapsedTime: 3600000 # 5 minutes
          exponent: 1.5
        statusCodes:
          - 408
          - 500
          - 502
          - 503
        retryConnectionErrors: true
      parameters:
        - name: status
          in: query
          description: Status values that need to be considered for filter
          required: false
          explode: true
          schema:
            type: string
            default: available
            enum:
              - available
              - pending
              - sold
      responses:
        "200":
          description: successful operation
          content:
            application/json:
              schema:
                type: array
                items:
                  $ref: "#/components/schemas/Pet"
            application/xml:
              schema:
                type: array
                items:
                  $ref: "#/components/schemas/Pet"
        "400":
          description: Invalid status value
```

Per-request retries are configured the same way as global retries.

## SDK Usage Override

Users of the SDK can override the retry strategy globally or at the request level by providing a `utils.RetryConfig` object. This object supports most of the same properties as the `x-speakeasy-retries` extension, except for the status codes to retry on.

### Global

To override the retry strategy globally, initialize the SDK object with the appropriate options parameter. In all cases, if no override is provided, the retry configuration provided in the OpenAPI document will be used.

In this example, we use the `RetryConfig` object to disable retries globally:

<Tabs items={['TS', 'Python', 'Go', 'Java', 'C#']}>
  <Tabs.Tab>

```typescript
const sdk = new SDK({retryConfig: {strategy: "none"}});
```

  </Tabs.Tab>
  <Tabs.Tab>

```python
s = SDK(retry_config=RetryConfig(
  strategy='none',
  backoff=None,
  retry_connection_errors=False
))
```

  </Tabs.Tab>
  <Tabs.Tab>

```go
s := sdk.New(sdk.WithRetryConfig(utils.RetryConfig{Strategy: "none"}))
```

  </Tabs.Tab>
  <Tabs.Tab>

```java
SDK s = SDK.builder()
    .retryConfig(RetryConfig.noRetries())
    .build();
```

  </Tabs.Tab>
  <Tabs.Tab>

```csharp
var sdk = new SDK(
    retryConfig: new RetryConfig(
        strategy: RetryConfig.RetryStrategy.NONE
));
```

  </Tabs.Tab>
</Tabs>

### Request-Level Override

Any endpoints that support retries allow retry configuration to be overridden. In Go, override request-level retry configuration with `operations.WithRetries`. In Python and TypeScript, the optional `retries` is accepted.

<Tabs items={['TS', 'Python', 'Go', 'Java', 'C#']}>
<Tabs.Tab>

```typescript
const sdk = new SDK({});
await sdk.findPetsByStatus(request, {
  strategy: "backoff",
  backoff: {
    initialInterval: 100,
    maxInterval: 10000,
    exponent: 1.1,
    maxElapsedTime: 60000,
  },
  retryConnectionErrors: false,
});
```

  </Tabs.Tab>
  <Tabs.Tab>

```python
s = sdk()
res = s.find_pets_by_status(request, RetryConfig(strategy='backoff',
  backoff=BackoffStrategy(
    initial_interval=100,
    max_interval=10000,
    exponent=1.1,
    max_elapsed_time=60000),
    retry_connection_errors=False
))
```

  </Tabs.Tab>
  <Tabs.Tab>

```go
s := sdk.New()
s.FindPetsByStatus(&operations.FindPetsByStatusRequest{},
  operations.WithRetries(utils.RetryConfig{
    Strategy: "backoff",
    Backoff: &utils.BackoffStrategy{
      InitialInterval: 100,
      MaxInterval: 10000,
      MaxElapsedTime: 60000,
      Exponent: 1.1,
    },
    RetryConnectionErrors: false,
  },
)
```

  </Tabs.Tab>
  <Tabs.Tab>

```java
import <namepace>.SDK;
import <namepace>.models.operations.FindPetsByStatusResponse

SDK s = SDK.builder().build();
FindPetsByStatusResponse res = sdk.findPetsByStatus()
    .retryConfig(RetryConfig.builder()
                    .backoff(BackoffStrategy.builder()
                                .initialInterval(100L, TimeUnit.MILLISECONDS)
                                .maxInterval(10000L, TimeUnit.MILLISECONDS)
                                .maxElapsedTime(60000L, TimeUnit.MILLISECONDS)
                                .exponent(1.1f)
                                .retryConnectError(false)
                                .build())
                    .build())
    .call();
```

  </Tabs.Tab>
  <Tabs.Tab>

```csharp
var sdk = new SDK();

var res = await sdk.FindPetsByStatusAsync(retryConfig: new RetryConfig(
    strategy: RetryConfig.RetryStrategy.BACKOFF,
    backoff: new BackoffStrategy(
        initialIntervalMs: 100L,
        maxIntervalMs: 10000L,
        maxElapsedTimeMs: 60000L,
        exponent: 1.1
    ),
    retryConnectionErrors: false
));

```

  </Tabs.Tab>
</Tabs>

## Idempotency

If your endpoint has a defined idempotency header, the request will be retried with the exact idempotency key that was provided for the initial request.

```yaml
paths:
  /pet:
    put:
      operationId: putPet
      x-speakeasy-retries:
        strategy: backoff
        backoff:
          initialInterval: 500
          maxInterval: 60000
          maxElapsedTime: 3600000
          exponent: 1.5
        statusCodes:
          - 5XX
        retryConnectionErrors: false
      parameters:
        - name: Idempotency-Key
          schema:
            type: string
          in: header
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/Pet"
      responses:
        "200":
          description: successful operation
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/Pet"
          default:
            description: Error
```

## Respecting `Retry-After`

If your API returns an HTTP standard `retry-after` header, the SDK will respect that value as the retry interval as long as the time is in the future and below the max elapsed retry time.
You don't need to change any configurations to enable this; simply return a `retry-after` header from your API. We currently support this feature in TypeScript and will add support for additional languages in the future.

```yaml
responses:
  "429":
    description: Too Many Requests
    headers:
      Retry-After:
        description: The date and time after which the client can retry the request.
        schema:
          type: string
          format: date-time
          example: "Wed, 21 Oct 2023 07:28:00 GMT"
```

```yaml
responses:
  "429":
    description: Too Many Requests
    headers:
      Retry-After:
        description: The number of seconds to wait before retrying the request.
        schema:
          type: integer
          example: 120
```


 This is the content for the doc docs/customize/runtime/server-sent-events.mdx 

 ---
description: "Learn how to model streaming APIs built on top of server-sent events."
sidebar_label: "Enable Server-Sent Events"
slug: "/customize-sdks/server-sent-events/"
---

import { Callout } from "~/components";

# Enabling Event-Streaming Operations

Server-sent events (SSE) is a core web feature that provides servers with a low overhead solution to push real-time events to the client when they become available. SSE can be used to stream chat completions from a large language model, real-time stock prices, and sensor readings to clients.

SSE is similar to WebSockets in that it uses a persistent connection but differs in that it is unidirectional - only the server sends events. SSE is simpler to implement in many existing backend HTTP frameworks.

<Callout title="INFO" variant="info">
  Speakeasy makes it easy to build SSE into generated SDKs without vendor
  extensions or heuristics. Leverage SSE by modeling SSE streams as
  `text/event-stream` responses with pure OpenAPI.
</Callout>

Here's a short example of using an SDK to chat with an LLM and read its response as a stream:

```typescript
import { SDK } from '@speakeasy/sdk';

const sdk = new SDK()

const response = await sdk.chat.create({
  prompt: "What are the top 3 French cheeses by consumption?"
})

for await (const event of response.chatStream) {
  process.stdout.write(event.data);
}
```

<Callout title="INFO" variant="info">
  The SSE feature is currently supported in TypeScript, Python, Go, and Java.
  Let us know if you'd like to see support for other languages.
</Callout>

## Modeling SSE in OpenAPI

To implement SSE in a generated SDKs, model an API endpoint that serves an event
stream in an OpenAPI document. **Each server-sent event can contain up to four
types of fields:** `id`, `event`, `data`, and `retry`.

### Basic Implementation

The example below illustrates an operation that streams events containing only a `data` field that holds string content:

```yaml
paths:
  /chat:
    post:
      summary: Create a chat completion from a prompt
      operationId: create
      tags: [chat]
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/ChatRequest"
      responses:
        "200":
          description: Chat completion created
          content:
            text/event-stream:
              schema:
                $ref: "#/components/schemas/ChatStream"
components:
  schemas:
    ChatRequest:
      type: object
      required: [prompt]
      properties:
        prompt:
          type: string
    ChatStream:
      description: A server-sent event containing chat completion content
      type: object
      required: [data]
      properties:
        data:
          type: string
```

### When `data` is a JSON Object

SSE implementation isn't limited to string data. If `data` is specified as an
object instead of a string, then SDKs will assume the field will contain JSON
content. Raw data received from the server will be deserialized into an object
for the application code to consume.

```yaml
components:
  schemas:
    ChatStream:
      description: A server-sent event containing chat completion content
      type: object
      required: [data]
      properties:
        data:
          type: object
          properties:
            content:
              type: string
            model:
              type: string
              enum: ["foo-gpt-tiny", "foo-gpt-small"]
            created:
              type: integer
```

The Speakeasy-generated TypeScript SDK for the example above will allow users to access this object:

```typescript
for await (const event of response.chatStream) {
  const { content, model, created } = event.data;

  process.stdout.write(content);
}
```

### Handling Multiple Event Types

Other streaming APIs send multiple types of events with the `id` and `event`
fields. These event types can be described as a union (`oneOf`) with the `event`
field acting as a discriminator:

```yaml
components:
  schemas:
    ChatStream:
      oneOf:
        - $ref: "#/components/schemas/HeartbeatEvent"
        - $ref: "#/components/schemas/ChatEvent"
      discriminator:
        propertyName: event
        mapping:
          ping: "#/components/schemas/HeartbeatEvent"
          completion: "#/components/schemas/ChatEvent"

    HeartbeatEvent:
      description: A server-sent event indicating that the server is still processing the request
      type: object
      required: [event]
      properties:
        event:
          type: string
          const: "ping"
    ChatEvent:
      description: A server-sent event containing chat completion content
      type: object
      required: [id, event, data]
      properties:
        id:
          type: string
        event:
          type: string
          const: completion
        data:
          type: object
          required: [content]
          properties:
            content:
              type: string
```

### Endpoints with Multiple Response Types

For APIs that handle both JSON responses and streaming events, use **URL
fragments** to define separate paths for each response type. Each fragment maps
to a specific behavior—either returning a complete JSON response or streaming
data. This approach allows Speakeasy to generate distinct SDK methods with clear
return types while maintaining API flexibility.

```yaml
paths:
  /chat:
    post:
      summary: >
        Create a chat completion from a prompt. The entire response is 
        returned as a single JSON object.
      operationId: create
      tags: [chat]
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/ChatRequestJson"
      responses:
        "200":
          description: Chat completion created
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ChatResponse"
  /chat#streamed:
    post:
      summary: >
        Create a chat completion from a prompt. The response is streamed in 
        chunks as it is generated.
      operationId: createStreamed
      tags: [chat]
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/ChatRequestStream"
      responses:
        "200":
          description: Chat completion created
          content:
            text/event-stream:
              schema:
                $ref: "#/components/schemas/ChatStream"
components:
  schemas:
    ChatRequest:
      # ...
    ChatRequestJson:
      allOf:
        - $ref: "#/components/schemas/ChatRequest"
        - type: object
          properties:
            # !mark(1:4)
            stream:
              type: boolean
              enum: [false]
              default: false
    ChatRequestStream:
      allOf:
        - $ref: "#/components/schemas/ChatRequest"
        - type: object
          properties:
            # !mark(1:4)
            stream:
              type: boolean
              enum: [true]
              default: true
    ChatResponse:
      # ...
    ChatStream:
      # ...
```

<Callout title="IMPORTANT" variant="info">
  The `stream` properties in the `ChatRequestJson` and `ChatRequestStream`
  schemas are treated as constants, ensuring that each request type always has a
  fixed stream value (false for JSON responses and true for streamed responses).
  In OpenAPI 3.0, this is achieved using single-value enums. For OpenAPI 3.1,
  simplify schema by using the `const` field instead of `enum`, which
  explicitly defines the property as having a constant value. This makes the
  specification more concise and easier to maintain.

See the [Speakeasy OpenAPI reference on enums](/openapi/schemas/enums) for
more information.

</Callout>

Use `chat` for the non-streaming endpoint and `chatStreamed` for the streaming
endpoint:

```typescript
import { SDK } from '@speakeasy/sdk';

const sdk = new SDK()

// Non-streaming method
const jsonResponse = await sdk.chat.create({
  prompt: "What are the top 3 French cheeses by consumption?"
});

console.log(jsonResponse.content);

// Streaming method
const stream = await sdk.chat.createStreamed({
  prompt: "What are the top 3 French cheeses by consumption?"
});

for await (const event of response.chatStream) {
  process.stdout.write(event.data);
}
```

<Callout title="NOTE" variant="info">
  Accross all of these examples, the schema for the events only ever specifies
  one or more of the four recognized fields. Adding other fields will trigger a
  validation error when generating an SDK with the Speakeasy CLI or GitHub
  action.
</Callout>

## Sentinel events

Some SSE APIs will terminate the stream by sending a final, special event. This sentinel event is only used to signal that there are no more events and is not intended for application code to handle.

In the example below, the final `data: [DONE]` event is the sentinel event:

```
HTTP/1.1 200 OK
Content-Type: text/event-stream; charset=utf-8
Date: Fri, 12 Jul 2024 14:29:22 GMT
Keep-Alive: timeout=5, max=1000
Connection: Keep-Alive

data: {"content": "there"}

data: {"content": "are 7"}

data: {"content": "continents in the world"}

data: [DONE]
```

To hide this final event in generated SDK methods, use the `x-speakeasy-sse-sentinel: <string>` extension on a `text/event-stream` media object:

```diff
paths:
  /chat:
    post:
      summary: Create a chat completion from a prompt
      operationId: create
      tags: [chat]
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ChatRequest'
      responses:
        '200':
          description: Chat completion created
          content:
            text/event-stream:
+             x-speakeasy-sse-sentinel: '[DONE]'
              schema:
                $ref: '#/components/schemas/ChatEvent'

components:
  schemas:
    ChatEvent:
      description: A server-sent event containing chat completion content
      type: object
      required: [data]
      properties:
        data:
          type: object
          required: [content]
          properties:
            content:
              type: string
```

Application code like the following TypeScript sample will behave as expected. The async iteration loop will finish when the sentinel event is encountered:

```ts
const llm = new LLM();

const stream = await llm.chat.create({
  prompt: "How many continents are there?",
});

for await (const event of stream) {
//               ^? ChatEvent
  process.stdout.write(event.data.content);
}
```


 This is the content for the doc docs/customize/runtime/streaming.mdx 

 ---
description: "Learn how to model streaming APIs built on top of file streaming."
sidebar_label: "Enable streaming support"
slug: "/customize-sdks/file-streaming/"
---

import { Tabs } from "@speakeasy/nextra-theme";
import { Callout } from "~/components";

# Enabling file streaming operations

Support for streaming is critical for applications that need to send or receive large amounts of data between client and server without first buffering the data into memory, potentially exhausting this system resource.

## Streaming download

If you create an endpoint with a top-level binary response body, you can treat that response as a streamable, and iterate over it without loading the entire response into memory.
This is useful for large file downloads, long-running streaming responses, and more.

In an OpenAPI document, this can be modeled as a binary stream. Here's an example of a `get` operation with content type as `application/octet-stream`.

```yaml
/streamable:
  get:
    operationId: streamable
    responses:
      "200":
        description: OK
        content:
          application/octet-stream:
            schema:
              title: bytes
              type: string
              format: binary
```

<Tabs items={['TypeScript', 'Go']}>

<Tabs.Tab>

For response streaming in TypeScript SDKs, expose a `ReadableStream`, which is part of the [Streams API web standard](https://developer.mozilla.org/en-US/docs/Web/API/Streams_API/Using_readable_streams).

```typescript
import fs from "node:fs";
import { Writable } from "node:stream";
import { SDK } from "@speakeasy/super-sdk";

async function run() {
  const sdk = new SDK();

  const result = await sdk.streamable("UR123");

  const destination = Writable.toWeb(
    fs.createWriteStream("./report.csv")
  );

  await result.data.pipeTo(destination);
}

run();
```

</Tabs.Tab>

<Tabs.Tab>

Use any [`io.Reader`](https://pkg.go.dev/io#Reader) implementation to read the data, such as calling [`io.Copy()`](https://pkg.go.dev/io#Copy) to a file.

```go
ctx := context.Background()
s := sdk.New()

file, err := os.Create("./report.csv")

if err != nil {
  // ... error handling ...
}

response, err := s.streamable(ctx)

if err != nil {
  // ... error handling ...
}

defer response.Data.Close()

_, err = io.Copy(file, response.Data)
```

</Tabs.Tab>

</Tabs>

## Streaming uploads

Streaming is useful when uploading large files.
Certain SDK methods will be generated that accept files as part of a multipart request. It is possible (and recommended) to upload files as a stream rather than reading the entire contents into memory.
This avoids excessive memory consumption and potentially crashing with out-of-memory errors when working with large files.

In this example, a request to upload a file is managed as a `multipart/form-data` request.

```yaml
/file:
  post:
    summary: Upload file
    operationId: upload
    requestBody:
      content:
        multipart/form-data:
          schema:
            $ref: "#/components/schemas/UploadFileRequest"
      required: true
    responses:
      "200":
        description: ""
        headers:
          Action-Id:
            required: true
            schema:
              type: string
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/File"
```

<Tabs items={['TypeScript', 'Go']}>

<Tabs.Tab>

As an example, in Node.js v20, streaming a large file to a server using an SDK is only a handful of lines. On the browser,
users typically select files using `<input type="file">`, and the SDK call looks like the sample code below.

```typescript
import { openAsBlob } from "node:fs";

import { SDK } from "@speakeasy/super-sdk";

async function run() {
  const sdk = new SDK();

  const fileHandle = await openAsBlob("./src/sample.txt");

  const result = await sdk.upload({ file: fileHandle });

  console.log(result);
}
run();
```

Depending on your JavaScript runtime, convenient utilities can return a handle to a file without reading the entire contents into memory:

- **Node.js v20+:** Since version 20, Node.js comes with a native `openAsBlob` function in [`node:fs`](https://nodejs.org/docs/latest-v20.x/api/fs.html#fsopenasblobpath-options).
- **Bun:** The native [`Bun.file`](https://bun.sh/docs/api/file-io#reading-files-bun-file) function produces a file handle that can be used for streaming file uploads.
- **Browsers:** All supported browsers return an instance to a [`File`](https://developer.mozilla.org/en-US/docs/Web/API/File) when reading the value from an `<input type="file">` element.
- **Node.js v18:** A file stream can be created using the `fileFrom` helper from [`fetch-blob/from.js`](https://www.npmjs.com/package/fetch-blob).

</Tabs.Tab>

<Tabs.Tab>

Use any [`io.Reader`](https://pkg.go.dev/io#Reader) implementation, such as calling [`os.Open()`](https://pkg.go.dev/os#Open) on an existing file.

```go
ctx := context.Background()
s := sdk.New()

file, err := os.Open("./src/sample.txt")

if err != nil {
  // ... error handling ...
}

response, err := s.upload(ctx, file)
```

</Tabs.Tab>

</Tabs>


 This is the content for the doc docs/customize/runtime/timeouts.mdx 

 ---
title: Timeouts
description: "Add request timeouts to specific operations in an SDK. Enable timeouts globally or per operation."
slug: "/customize-sdks/timeouts/"
---

import { Tabs } from "@speakeasy/nextra-theme";

# Timeouts

With Speakeasy, you can configure request timeouts in an SDK using the `x-speakeasy-timeout` extension in your OpenAPI document. Timeouts can be enabled globally for all operations or on a per-operation basis. The SDK end user can override the default configuration by passing in a timeout option at runtime. 

Timeout values are always provided in milliseconds.

## Global timeouts

```yaml
openapi: 3.0.3
info:
  title: Swagger Petstore - OpenAPI 3.0
  version: 1.0.11
servers:
  - url: https://petstore3.swagger.io/api/v3
x-speakeasy-timeout: 1000
```

Adding the `x-speakeasy-timeout` extension to the root of the OpenAPI document configures a global timeout for all requests made by the SDK.

## Per-request timeouts

Adding the `x-speakeasy-timeout` extension to any operation overrides the global timeout configuration for that operation or sets a timeout if no global configuration exists.

```yaml
openapi: 3.0.3
info:
  title: Swagger Petstore - OpenAPI 3.0
  version: 1.0.11
servers:
  - url: https://petstore3.swagger.io/api/v3
paths:
  /pet/findByStatus:
    get:
      operationId: findPetsByStatus
      x-speakeasy-timeout: 2000
      parameters:
        - name: status
          in: query
          description: Status values that need to be considered for filter
          required: false
          explode: true
          schema:
            type: string
            default: available
            enum:
              - available
              - pending
              - sold
      responses:
        "200":
          description: successful operation
          content:
            application/json:
              schema:
                type: array
                items:
                  $ref: "#/components/schemas/Pet"
            application/xml:
              schema:
                type: array
                items:
                  $ref: "#/components/schemas/Pet"
        "400":
          description: Invalid status value
```

## Overriding timeout configuration

Users of the SDK can override the timeout configuration globally or at the request level.

### Globally overriding timeout configuration

To override the timeout configuration globally, initialize the SDK object with the appropriate options parameter. In all cases, if no override is provided, the timeout configuration provided in the OpenAPI document will be used.

<Tabs items={['TypeScript', 'Python', 'Go']}>
  <Tabs.Tab>

```typescript
const sdk = new SDK({timeoutMs: 100});
```

  </Tabs.Tab>
  <Tabs.Tab>

```python
s = SDK(timeout_ms=100)
```

  </Tabs.Tab>
  <Tabs.Tab>

```go
s := sdk.New(sdk.WithTimeout(100 * time.Millisecond))
```

  </Tabs.Tab>
</Tabs>

### Overriding timeout configuration at the request level

Users can override the timeout config on a per-operation basis.

<Tabs items={['TypeScript', 'Python', 'Go']}>
<Tabs.Tab>

```typescript
const sdk = new SDK({});
await sdk.findPetsByStatus(request, {
  timeoutMs: 1000,
});
```

  </Tabs.Tab>
  <Tabs.Tab>

```python
s = sdk()
res = s.find_pets_by_status(request, timeout_ms = 100)
```

  </Tabs.Tab>
  <Tabs.Tab>

```go
s := sdk.New()
s.FindPetsByStatus(&operations.FindPetsByStatusRequest{},
  operations.WithOperationTimeout(100 * time.Millisecond),
)
```

  </Tabs.Tab>
</Tabs>


 This is the content for the doc docs/customize/servers.mdx 

 ---
title: "Configure servers"
description: "Learn how to configure server behavior in your Speakeasy client SDKs. Customize URLs, define multiple servers, and use templated URLs."
slug: "/customize-sdks/servers/"
---

import { Tabs } from "@speakeasy/nextra-theme";
import { Callout } from "~/components";

# Configure Your Servers

## Default Behavior

The OpenAPI specification allows you to define an array of servers that can be used to make requests to the API. These servers are generally used to define different environments (for example, production, development, and testing) available for the API.

```yaml
openapi: 3.0.3
info:
  title: Example
  version: 0.0.1
servers:
  - url: https://prod.example.com # Used as the default URL by the SDK
    description: Our production environment
  - url: https://sandbox.example.com
    description: Our sandbox environment
```

The Speakeasy SDK Generator automatically selects the first server URL from the OpenAPI document's servers list as the default endpoint. While this default is commonly set to the production server, it's flexible to accommodate your application's development cycle by reordering or modifying the server list.

## Declare Base Server URL

Speakeasy SDKs are battery-included, meaning they are designed to work out of the box with minimal configuration from end users.

If your OpenAPI document lacks server definitions (both at the global level and for individual operations) or relies on relative paths for server URLs, it's essential to set a default server endpoint. Set the default server endpoint by specifying a `baseServerUrl` in your SDK Generator configuration file (`gen.yaml`). This ensures your SDK always has a primary server to connect to for its operations.

```yaml
# ...
generation:
  baseServerUrl: "https://prod.example.com"
```

## Use Templated URLs

[Templated](https://spec.openapis.org/oas/v3.0.3#server-object) URLs provide a dynamic method to customize server endpoints based on runtime parameters, making them ideal for applications that serve multiple clients or operate in varied environments.

```yaml
servers:
  - url: https://{customer}.yourdomain.com
    variables:
      customer:
        default: api
        description: The name of the customer sending API requests.
```

These placeholders can then be replaced with specific values at runtime, allowing for customer-specific or environment-specific configurations without altering the SDK.

<Callout title="NOTE" variant="info">
  Please note that the templating feature is only supported for global server
  URLs and is not yet supported for per-operation server URLs.
</Callout>

## Managing Multiple Servers With IDs

For a better developer experience, you can define an ID for each server using the `x-speakeasy-server-id` extension. This simplifies the process of selecting between servers at SDK initialization.

```yaml
openapi: 3.0.3
info:
  title: Example
  version: 0.0.1
servers:
  - url: https://prod.example.com # Used as the default URL by the SDK
    description: Our production environment
    x-speakeasy-server-id: prod
  - url: https://sandbox.example.com
    description: Our sandbox environment
    x-speakeasy-server-id: sandbox
```

## Dynamic Server Declaration at Runtime

Dynamic server selection allows developers to switch between multiple predefined servers at runtime, offering flexibility across different deployment environments or client configurations.

<Callout title="NOTE" variant="info">
  The Speakeasy README file accompanying your generated SDK will include
  SDK-specific examples to guide you through the process of dynamically
  selecting servers.
</Callout>

### Methods

#### Server Selection by Index

Specify a server from the predefined list based on its index.

<Tabs items={['Go', 'Python', 'TS', 'C#']}>
  <Tabs.Tab>

```go
s := sdk.New(
		sdk.WithServerIndex(1)
)
```

  </Tabs.Tab>
  <Tabs.Tab>

```python
s = sdk.SDK(
    server_idx=1,
)
```

  </Tabs.Tab>
  <Tabs.Tab>

```typescript
const sdk = new SDK({
    serverIdx: 1,
});
```

  </Tabs.Tab>
  <Tabs.Tab>

```csharp
const sdk = new SDK(serverIndex: 1);
```

  </Tabs.Tab>
</Tabs>

#### Global URL Override

Set a global server URL at SDK initialization, overriding the base URL.

<Tabs items={['Go', 'Python', 'TS', 'C#']}>
  <Tabs.Tab>

```go
s := sdk.New(
    // if the x-speakeasy-server-id extension is not used
		sdk.WithServerURL("https://sandbox.example.com")

    // with x-speakeasy-server-id extension
    sdk.WithServer("sandbox"),
)
```

  </Tabs.Tab>
  <Tabs.Tab>

```python
s = sdk.SDK(
  # if the x-speakeasy-server-id extension is not used
  server_url="https://sandbox.example.com"

  # with x-speakeasy-server-id extension
  server="sandbox"

)
```

  </Tabs.Tab>
  <Tabs.Tab>

```typescript
const sdk = new SDK({
    // if the x-speakeasy-server-id extension is not used
    serverURL: "https://sandbox.example.com",

    // with x-speakeasy-server-id extension
    server: "sandbox",
});
```

  </Tabs.Tab>
  <Tabs.Tab>

```csharp
const sdk = new SDK(
    // if the x-speakeasy-server-id extension is not used
    serverURL: "https://sandbox.example.com",

    // with x-speakeasy-server-id extension
    server: "sandbox",
);
```

  </Tabs.Tab>
</Tabs>

#### Per-Client or Per-Operation Override

Override the server URL for specific instances or API calls.

<Tabs items={['Go', 'Python', 'TS', 'C#']}>
  <Tabs.Tab>

```go
res, err := s.Tag1.ListTest1(
    ctx,
    operationSecurity,
    sdk.WithServerURL("https://sandbox.example.com"),
    page,
    headerParam1,
    queryParam1,
)
```

  </Tabs.Tab>
  <Tabs.Tab>

```python
res = s.tag1.list_test1(
    "<YOUR_API_KEY>",
    server_url="https://sandbox.example.com",
    page=100,
    header_param1='some example header param',
    query_param1='some {{example}} query param'
)
```

  </Tabs.Tab>
  <Tabs.Tab>

```typescript
const result = await sdk.tag1.listTest1(operationSecurity, page, headerParam1, queryParam1, {
    serverURL: "https://sandbox.example.com",
});
```

  </Tabs.Tab>
  <Tabs.Tab>

```csharp
var res = await sdk.Tag1.ListTest1Async(
    security: operationSecurity,
    page: page,
    headerParam1: headerParam1,
    queryParam1: queryParam1,
    serverURL: "https://sandbox.example.com"
);
```

  </Tabs.Tab>
</Tabs>

<Callout title="CAUTION" variant="warning">
  If you choose to configure the SDK URL at runtime and relative paths were used
  in the OpenAPI document, make sure that you account for the `baseURL` when
  initializing the SDK server configuration.
</Callout>


 This is the content for the doc docs/customize/structure/imports.mdx 

 ---
title: Customize imports
description: "How to customize the import paths and model locations of generated SDKs."
slug: "/customize-sdks/imports/"
---

import { Tabs } from "@speakeasy/nextra-theme";
import { ScrollyCoding } from "~/components/codehike/Scrollycoding";
import { Callout } from "~/components";

# Customize imports

Speakeasy allows you to customize the paths we generate models to and your users import models from.

By default, Speakeasy uses an OpenAPI-based naming scheme for the namespaces models are bucketed into, for example:

<Callout title="INFO" variant="info">
  Currently only supported for C#, Go, Python, TypeScript, and Unity SDKs. More
  languages will be added soon.
</Callout>

<ScrollyCoding>

#### !!steps `Components`

Models generated from components are placed in the `models/components` directory, or the target language idiomatic equivalent.

```yaml ! gen.yaml
# !focus(3:6)
sdk/
├─ models/
│  ├─ components/
│  │  ├─ user.ts
│  │  ├─ drink.ts
│  │  └─ ...
│  ├─ operations/
│  │  ├─ getuser.ts
│  │  ├─ updateuser.ts
│  │  ├─ getdrink.ts
│  │  ├─ updatedrink.ts
│  │  └─ ...
│  └─ errors/
│     ├─ sdkerror.ts
│     ├─ responseerror.ts
│     └─ ...
└─ ...
```

---

#### !!steps `Operations`

Models generated from operations are placed in the `models/operations` directory, or the target language idiomatic equivalent.

```yaml ! gen.yaml
# !focus(7:12)
```

---

#### !!steps `Errors`

Models that are used in error status codes are placed in the `models/errors` directory (or the idiomatic equivalent for the target language).

```yaml ! gen.yaml
# !focus(13:16)
```

</ScrollyCoding>

<Callout title="WARN" variant="info">
  The default names for the model directories are consistent across most
  target languages, but C# makes the exception that the `models/Operations` directory is
  called `models/Requests` by default.
</Callout>

## Customize import paths

<ScrollyCoding>

### !!steps `imports`

Customize where path models are generated to and imported from by modifying the configuration in the `gen.yaml` file.

Configuration like what is shown will result in a file structure as above.

```yaml ! gen.yaml
# !focus(6:13)
configVersion: 2.0.0
generation:
  # ...
typescript:
  version: 1.0.0
  imports:
    option: openapi
    paths:
      callbacks: models/callbacks
      errors: models/errors
      operations: models/operations
      shared: models/components
      webhooks: models/webhooks
  # ...
```

---

### !!steps `option`

The `option` key determines the type of bucketing scheme that is used for the models.

Only `openapi` is currently supported. This will bucket models into `components`, `operations`, `errors`, `callbacks`, and `webhooks` directories.

```yaml ! gen.yaml
# !focus(7)
```

---

### !!steps `paths`

The `paths` section contains a map of bucket names to paths relative to the root of the generated SDK.

- `shared` refers to the models generated from the `components` section of the OpenAPI specification. (Note: `shared` is a legacy name for the bucket, retained for backward compatibility.)
- `operations` refers to the models generated for the request and responses of operations in the OpenAPI specification.
- `errors` refers to the models generated for schemas referenced in error status codes responses.
- `callbacks` refers to models generated for schemas within the `callbacks` section of an operation.
- `webhooks` refers to models generated from the `webhooks` section of an OpenAPI 3.1 document.

```yaml ! gen.yaml
# !focus(8:13)
```

</ScrollyCoding>

You can customize these paths to any path that exists relative to the root of the SDK.

<Callout title="CAUTION" variant="warning">
  If you are providing custom path names, make sure there is no conflict with
  any of the existing directories in the SDK. Conflicts will result in
  compilation issues.
</Callout>

Different buckets can also be configured to use the same path, for example:

```yaml gen.yaml
typescript:
  ...
  imports:
    option: openapi
    paths:
      callbacks: models
      errors: models
      operations: models
      shared: models
      webhooks: models
```

This will result in all models being generated to the `models` directory. The generator will then resolve any class name conflicts by prefixing or suffixing class names to ensure they are unique.

## Customize global imports

You can configure the generator to work with a global import path for all models.

For example:

```typescript
import { User, GetDrinkRequest, SDK } from '@speakeasy/bar'
```

Instead of:

```typescript
import { SDK } from '@speakeasy/bar'
import { User } from '@speakeasy/bar/dist/models/components/user'
import { GetDrinkRequest } from '@speakeasy/bar/dist/models/operations/user'
```

You will configure global imports slightly differently for different languages:

<br></br>

<Tabs items={['Typescript', 'Python', 'Go', "C#", "Unity"]}>

<Tabs.Tab>
For TypeScript to configure global imports, the `imports` section of your `gen.yaml` needs to include the following:

```yaml gen.yaml
typescript:
  ...
  imports:
    option: openapi
    paths:
      callbacks: models
      errors: models
      operations: models
      shared: models
      webhooks: models

# OR

typescript:
  ...
  imports:
    option: openapi
    paths:
      callbacks: ""
      errors: ""
      operations: ""
      shared: ""
      webhooks: ""
```

For global imports in TypeScript, models will always be generated to the `models` directory, regardless of whether the `""` or `"models"` path is specified. However, global imports will only kick in if one of these two values is used for all buckets. This is to ensure the root directory isn&apos;t cluttered with files.

The configuration example above will result in a directory structure like this:

```yaml
/
├─ src
│  ├─ models/
│  │  ├─ user.ts
│  │  ├─ drink.ts
│  │  ├─ getuser.ts
│  │  ├─ updateuser.ts
│  │  ├─ getdrink.ts
│  │  ├─ updatedrink.ts
│  │  ├─ sdkerror.ts
│  │  ├─ responseerror.ts
│  │  ├─ index.ts
│  │  └─ ...
│  └─ ...
└─ ...
```

Import models like so:

```typescript
import { User, GetDrinkRequest, SDK } from '@speakeasy/bar'
```

</Tabs.Tab>

<Tabs.Tab>
For Python to configure global imports, the `imports` section of your `gen.yaml` needs to include the following:

```yaml gen.yaml
python:
  ...
  imports:
    option: openapi
    paths:
      callbacks: models
      errors: models
      operations: models
      shared: models
      webhooks: models

# OR

python:
  ...
  imports:
    option: openapi
    paths:
      callbacks: ""
      errors: ""
      operations: ""
      shared: ""
      webhooks: ""
```

For global imports in Python, models will always be generated to the `models` directory, regardless of whether the `""` or `"models"` path is specified. However, global imports will only kick in if one of these two values is used for all buckets. This is to ensure the root directory isn&apos;t cluttered with files.

The configuration example above will result in a directory structure as follows:

```yaml
/
├─ src
│  ├─ sdk/
│  │  ├─ models/
│  │  |  ├─ user.py
│  │  │  ├─ drink.py
│  │  │  ├─ getuser.py
│  │  │  ├─ updateuser.py
│  │  │  ├─ getdrink.py
│  │  │  ├─ updatedrink.py
│  │  │  ├─ sdkerror.py
│  │  │  ├─ responseerror.py
│  │  │  └─ __init__.py
│  │  └─ ...
│  └─ ...
└─ ...
```

Import like so:

```python
import speakeasybar
```

Instead of:

```python
import speakeasybar
from speakeasybar.models import operations, components
```

</Tabs.Tab>

<Tabs.Tab>
For Go to configure global imports, the `imports` section of your `gen.yaml` needs to include the following:

```yaml gen.yaml
go:
  ...
  imports:
    option: openapi
    paths:
      callbacks: ""
      errors: ""
      operations: ""
      shared: ""
      webhooks: ""
```

This configuration will instruct the generator to create models at the root of the SDK and result in the following directory structure:

```yaml
/
├─ user.go
├─ drink.go
├─ getuser.go
├─ updateuser.go
├─ getdrink.go
├─ updatedrink.go
├─ sdkerror.go
├─ responseerror.go
└─ ...
```

Note: This configuration will result in the root directory being cluttered with files.

Import models like so:

```go
import (
  "github.com/speakeasy/bar"
)
```

Instead of:

```go
import (
  "github.com/speakeasy/bar"
  "github.com/speakeasy/bar/models/operations"
  "github.com/speakeasy/bar/models/components"
)
```

</Tabs.Tab>

<Tabs.Tab>
For C# to configure global imports, the `imports` section of your `gen.yaml` needs to include the following:

```yaml gen.yaml
csharp:
  ...
  imports:
    option: openapi
    paths:
      callbacks: Models
      errors: Models
      operations: Models
      shared: Models
      webhooks: Models

# OR

csharp:
  ...
  imports:
    option: openapi
    paths:
      callbacks: ""
      errors: ""
      operations: ""
      shared: ""
      webhooks: ""
```

For global imports in C#, models will always be generated to the `Models` directory, regardless of whether the `""` or `"Models"` path is specified. However, global imports will only kick in if one of these two values is used for all buckets. This is to ensure the root directory isn&apos;t cluttered with files.

The above configuration will result in a directory structure like this:

```yaml
/
├─ {{packageName}}/
│  ├─ Models/
│  │  ├─ User.cs
│  │  ├─ Drink.cs
│  │  ├─ GetUserRequest.cs
│  │  ├─ GetUserResponse.cs
│  │  ├─ UpdateUserRequest.cs
│  │  ├─ UpdateUserResponse.cs
│  │  ├─ GetDrinkRequest.cs
│  │  ├─ GetDrinkResponse.cs
│  │  ├─ UpdateDrinkRequest.cs
│  │  ├─ UpdateDrinkResponse.cs
│  │  ├─ SDKError.cs
│  │  ├─ ResponseError.cs
│  │  └─ ...
│  └─ ...
└─ ...
```

As all the models will be under the root namespace of the SDK, import models like so:

```csharp
using SpeakeasyBar;
```

</Tabs.Tab>

<Tabs.Tab>
For Unity to configure global imports, the `imports` section of your `gen.yaml` needs to include the following:

```yaml gen.yaml
unity:
  ...
  imports:
    option: openapi
    paths:
      callbacks: Models
      errors: Models
      operations: Models
      shared: Models
      webhooks: Models

# OR

unity:
  ...
  imports:
    option: openapi
    paths:
      callbacks: ""
      errors: ""
      operations: ""
      shared: ""
      webhooks: ""
```

For global imports in Unity, models will always be generated to the `Models` directory, regardless of whether the `""` or `"Models"` path is specified. However, global imports will only kick in if one of these two values is used for all buckets. This is to ensure the root directory isn&apos;t cluttered with files.

The configuration example above will result in a directory structure like this:

```yaml
/
├─ {{packageName}}/
│  ├─ Models/
│  │  ├─ User.cs
│  │  ├─ Drink.cs
│  │  ├─ GetUserRequest.cs
│  │  ├─ GetUserResponse.cs
│  │  ├─ UpdateUserRequest.cs
│  │  ├─ UpdateUserResponse.cs
│  │  ├─ GetDrinkRequest.cs
��  │  ├─ GetDrinkResponse.cs
│  │  ├─ UpdateDrinkRequest.cs
│  │  ├─ UpdateDrinkResponse.cs
│  │  ├─ SDKError.cs
│  │  ├─ ResponseError.cs
│  │  └─ ...
│  └─ ...
└─ ...
```

As all the models will be under the root namespace of the SDK, import models like so:

```csharp
using SpeakeasyBar;
```

</Tabs.Tab>

</Tabs>

<Callout title="CAUTION" variant="warning">
Global imports will cause namespace pollution for the import and file clutter in the directory models are generated to.

Large APIs containing many models (especially many inline models) will inevitably lead to name conflicts. Rename types verbosely to ensure each class is unique within the namespace.

</Callout>


 This is the content for the doc docs/customize/structure/namespaces.mdx 

 ---
title: Customize namespaces
description: "Group API methods into namespaces for a better object-oriented SDK interface. Learn how to namespace your Speakeasy SDKs today."
slug: "/customize-sdks/namespaces/"
---

import { CodeWithTabs } from "~/components/codehike/CodeTabs";

# Customize Namespaces

When you're exposing your API to users, you may want to group API methods into namespaces to give your SDK an object-oriented interface. This type of interface can help users better conceptualize the objects they are manipulating when they use the API.

## Default Behavior

By default, Speakeasy will use the `tags` in your OpenAPI spec as the organizing principles for namespaces. For each `tag` in your spec, Speakeasy will create a namespace.

Each method will then be added to namespaces corresponding with its `tags`. If a method does not have an associated `tag`, it will be added to the root SDK class of the generated client library. If a method has multiple tags associated with it, the operation will appear as a method in multiple classes.

The following example illustrates the method `sdk.Drinks.ListDrinks()` assigned to the `Drinks` namespace and another method `sdk.ListLocations()` kept in the default class:

```yaml Tags
# !focus(21:22)
paths:
  /bar_locations:
    get:
    operationId: listLocations
    summary: List all locations of the Speakeasy bar
    description: Get a list of all the bars being run by Speakeasy
    responses:
      "200":
        description: A list of bars
        content:
          application/json:
            schema:
              type: array
              items:
                $ref: "#/components/schemas/BarLocation"
  /drinks:
    get:
      operationId: listDrinks
      summary: List all drinks
      description: Get a list of all drinks served by the bar
      tags:
        - drinks
      responses:
        "200":
          description: A list of drinks
          content:
            application/json:
              schema:
                type: array
                items:
                  $ref: "#/components/schemas/Drink"
tags:
  - name: drinks
    description: Everything about our Drinks on offer
```

The generated SDK will include methods that can be invoked as follows:

```go
// Method added into the Drinks namespace
sdk.Drinks.ListDrinks()
// Default method
sdk.ListLocations()
```

## Define Namespaces Without Tags `x-speakeasy-group`

Sometimes the `tags` in an OpenAPI spec may already be used for an unrelated purpose (for example, autogenerating documentation). In this scenario, you may want to use something other than `tags` to organize your methods.

The `x-speakeasy-group` field allows you to define custom namespaces. Add this field to any operation in your OpenAPI spec to override any `tags` associated with that method. For example:

```yaml x-speakeasy-group
# !focus(16)
paths:
  /drinks/{drink_type}/get_vintage:
    get:
      operationId: getVintage
      summary: Check the vintage of the wine
      description: Get the vintage of a drink served by the bar
      parameters:
        - name: drink_type
          in: path
          description: The type of drink
          required: true
          schema:
            type: string
      tags:
        - drinks
      x-speakeasy-group: wine
      responses:
        "200":
          description: A list of drinks
          content:
            application/json:
              schema:
                type: array
                items:
                  $ref: "#/components/schemas/Drink"
tags:
  - name: drinks
    description: Everything about Drinks on offer
```

The generated SDK will include a method, which can be invoked as follows:

```go
// GetVintage - get the vintage of the wine
sdk.wine.GetVintage("wine")
```

## Define Multi-Level Namespaces

You can use `tags` or the `x-speakeasy-group` extension to define nested namespaces for your operations using `.` notion. There is no limit to the number of levels you can define.

<CodeWithTabs>

```yaml !!tabs Tags
# !focus(6:7)
paths:
  /drink/{drink_type}/get_vintage/:
    get:
      operationId: getVintage
      summary: Check the vintage of the wine
      tags:
        - drinks.wine
      parameters:
        - name: drink_type
          in: path
          description: The type of drink
          required: true
          schema:
            type: string
      responses:
        "200":
          description: the wine vintage
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/Vintage"
```

```yaml !!tabs x-speakeasy-group
# !focus(6)
paths:
  /drink/{drink_type}/get_vintage/:
    get:
      operationId: getVintage
      summary: Check the vintage of the wine
      x-speakeasy-group: drinks.wine
      parameters:
        - name: drink_type
          in: path
          description: The type of drink
          required: true
          schema:
            type: string
      responses:
        "200":
          description: the wine vintage
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/Vintage"
```

</CodeWithTabs>

The generated SDK will include a method, invoked as follows:

```go
// Get the Vintage of a specified wine.
sdk.Drinks.Wine.GetVintage("wine")
```

## Multiple Namespaces

If you want to add a method to multiple namespaces, list multiple values in `tags` or the `x-speakeasy-group` extension. Both accept an array of values:

<CodeWithTabs>

```yaml !!tabs Tags
# !focus(6:8)
paths:
  /drink/{drink_type}/get_vintage/:
    get:
      operationId: getVintage
      summary: Check the vintage of the wine
      tags:
        - drinks
        - wine
      parameters:
        - name: drink_type
          in: path
          description: The type of drink
          required: true
          schema:
            type: string
      responses:
        "200":
          description: the wine vintage
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/Vintage"
```

```yaml !!tabs x-speakeasy-group
# !focus(6:8)
paths:
  /drink/{drink_type}/get_vintage/:
    get:
      operationId: getVintage
      summary: Check the vintage of the wine
      x-speakeasy-group:
        - drinks
        - wine
      parameters:
        - name: drink_type
          in: path
          description: The type of drink
          required: true
          schema:
            type: string
      responses:
        "200":
          description: the wine vintage
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/Vintage"
```

</CodeWithTabs>
The generated SDK will include methods that can be invoked as follows:

```go
// Get the Vintage
sdk.Drinks.GetVintage("wine")
sdk.Wine.GetVintage("wine")
```


 This is the content for the doc docs/customize/typescript/additional-index-exports.mdx 

 ---
title: Additional index exports
---

# Additional index exports

You may want to export additional modules, such as utilities and constants, from the main `index.ts` file of your SDK. 

As Speakeasy generates the contents of `src/index.ts`, you should not edit that file directly.

Instead, create an `index.extras.ts` file in the `src/` directory to define additional exports from the index file (`src/index.ts`) of your SDK.

If an `index.extras.ts` file is present, the SDK generator will automatically re-export its contents from the main `index.ts` file:

```ts <sdk-root>/src/index.ts
// { Speakeasy generated exports }

export * from "./index.extras.ts";
```


 This is the content for the doc docs/customize/typescript/configuring-module-format.mdx 

 ---
title: Configuring module format
---

import { Callout } from "~/components";

# Configuring Module Format

Modern SDKs need to balance compatibility with performance. The `moduleFormat` option in the SDK generator allows developers to control whether an SDK is built for CommonJS (CJS), ECMAScript Modules (ESM), or both. This choice impacts bundle size, tree-shaking performance, and compatibility with Node.js and modern bundlers.

## How to Configure Module Format

To configure the module format, update `gen.yaml` (which is often located in the SDK’s `.speakeasy` directory) file under the `typescript` section:

```yaml <sdk-root>/.speakeasy/gen.yaml
typescript:
  # add or modify `moduleFormat`
  moduleFormat: "commonjs" # or "esm" or "dual"
  # other Typescript configuration options...
```

### Supported Options

- **`"commonjs"` (default)**: Builds SDK for CommonJS. Widely supported across Node.js environments but less optimized for modern bundlers and tree-shaking.
- **`"esm"`**: Builds SDK for ECMAScript Modules, the modern standard for JavaScript modules. Provides optimal tree-shaking and significantly smaller bundles when used with bundlers like Webpack, Rollup, or Vite.
- **`"dual"`**: Builds SDK for both CJS and ESM formats. Provides the best of both worlds - ESM's superior tree-shaking and bundle optimization while maintaining compatibility with older CommonJS environments. The slight build time increase is often worth the flexibility and performance benefits.

## Module Format Overview

`moduleFormat` determines the module system targeted during SDK build. It impacts:

- Node.js project compatibility,
- Bundler tree-shaking capabilities,
- SDK bundle size, and
- Build performance.

### Example Outputs for Each Option

#### CommonJS (Default)

When configured with `commonjs`:

```javascript example.js
// CommonJS import in consumer code
const { ApiError } = require("petstore/errors/apierror.js");

// ESM import (interop code included)
import { ApiError } from "petstore/errors/apierror.js";
```

#### ESM

When configured with `esm`:

```javascript example.js
// Native ESM import in consumer code
import { ApiError } from "petstore/errors/apierror.js";

// ❌ Will not work in CommonJS-only environments
```

#### Dual

When configured with `dual`:

```javascript example.js
// ESM import (no interop code)
import { ApiError } from "petstore/errors/apierror.js";

// CommonJS import (still works seamlessly)
const { ApiError } = require("petstore/errors/apierror.js");
```

## How to Decide Which Format to Use

**Use CommonJS (`commonjs`) if...**

- The SDK is used primarily in Node.js environments or older projects.
- Bundle size optimization is not a critical requirement.
- You need maximum compatibility with legacy systems.

**Use ESM (`esm`) if...**

- SDK consumers use modern bundlers like Vite, Webpack, or Rollup.
- Tree-shaking and bundle size optimization are top priorities.
- Your project is already using ESM throughout.
- You want to leverage the latest JavaScript features and tooling.

**Use Dual Mode (`dual`) if...**

- You need to support both modern and legacy environments.
- You want ESM's superior tree-shaking while maintaining CommonJS compatibility.
- Your SDK will be used in diverse environments with different module requirements.
- You prioritize developer experience and want to provide maximum flexibility.

<Callout title="Recommendation" variant="info">
For most modern projects, we recommend using `dual` format. This ensures your SDK works seamlessly in any environment while still providing the performance benefits of ESM when used with modern bundlers.
</Callout>

## Additional Reading

- [Typescript Configuration Options](/docs/gen-reference/ts-config)
- [Lean SDKs with Standalone Functions](/post/standalone-functions)


 This is the content for the doc docs/customize/typescript/disabling-barrel-files.mdx 

 ---
title: Disabling barrel files
---

import { Callout } from "~/components";

# Disabling Barrel Files

By default, the SDK generator creates "barrel files" or "index.ts" files that centralize module re-exports within an SDK package.

## Configuring Barrel File Generation

The `useIndexModules` configuration option controls barrel file generation, which centralizes module re-exports. Configure this option by adding or modifying `useIndexModules` in `gen.yaml` file under the `typescript` section:

```yaml <sdk-root>/.speakeasy/gen.yaml
typescript:
  # add or modify `useIndexModules`
  useIndexModules: true # or false
  # other Typescript configuration options...
```

With `useIndexModules` set to `true` (the default), Speakeasy will generate barrel files that look like this:

```typescript <sdk-root>/src/models/errors/index.ts
// petstore sdk
export * from "./apierror.js";
export * from "./apierrorinvalidinput.js";
export * from "./apierrornotfound.js";
export * from "./apierrorunauthorized.js";
export * from "./httpclienterrors.js";
export * from "./sdkvalidationerror.js";
```

Consumers of the SDK could then import from the barrel file:

```typescript example.ts
// somewhere in a consumer's code code
import {
  ApiErrorInvalidInput,
  ApiErrorNotFound,
  ApiErrorUnauthorized,
  SDKValidationError,
} from "petstore/models/errors";
```

Conversely, with `useIndexModules` set to `false`, Speakeasy will not generate these barrel files. Consumers would need to import directly from the individual module files:

```typescript example.ts
// somewhere in a consumer's code
import { ApiErrorInvalidInput } from "petstore/models/errors/apierrorinvalidinput.js";
import { ApiErrorNotFound } from "petstore/models/errors/apierrornotfound.js";
import { ApiErrorUnauthorized } from "petstore/models/errors/apierrorunauthorized.js";
import { SDKValidationError } from "petstore/models/errors/sdkvalidationerror.js";
```

## Pros and Cons of Using Barrel Files

Barrel files, or `index.ts` files, provide a convenient way to centralize imports for SDK consumers. When `useIndexModules` is `true`, users can import from a single entry point rather than having to supply the exact file structure of the package's resources.

On the other hand, disabling barrel files can have some advantages:

- **Superior Tree Shaking Performance**: Barrel files can significantly impair effective tree shaking in modern bundlers. When importing from a barrel file, bundlers often struggle to determine which exports are actually used, leading to the inclusion of unused code. By disabling barrel files, you ensure that bundlers can accurately track dependencies and exclude unused code, resulting in smaller production bundles.

- **Enhanced Developer Tooling**: Without barrel files, your IDE's "Go to Definition" feature (e.g., CMD/Ctrl + Click) takes you directly to the source file containing the implementation, rather than navigating through an intermediate barrel file. This improves code navigation and makes it easier to understand the codebase structure.

- **Faster Build Performance**: Barrel files create additional import chains that your build tools must process. By removing these intermediary files:
  - Build tools process fewer files during compilation
  - Module dependency graphs become simpler and more efficient
  - Hot module replacement (HMR) becomes more precise
  - TypeScript type checking performance improves

<Callout title="Performance tip" variant="info">
When combined with `moduleFormat: dual`, disabling barrel files provides optimal tree-shaking performance. The ESM format&apos;s static analysis capabilities work best with direct imports, allowing bundlers to eliminate unused code more effectively.
</Callout>

## Making the Right Choice

The decision to use `useIndexModules` depends on your project's priorities:

- **Disable barrel files** (`useIndexModules: false`) when:
  - Bundle size optimization is critical
  - You're using modern bundlers like Webpack, Rollup, or Vite
  - Build performance is important
  - Your team values clear dependency paths
  
- **Keep barrel files** (`useIndexModules: true`) when:
  - Import convenience is more important than bundle optimization
  - Your project doesn't use a bundler with tree-shaking
  - You prefer centralized import management

<Callout title="Recommendation" variant="info">
For modern web applications, we recommend setting `useIndexModules: false`. While barrel files offer convenient imports, the performance benefits of direct imports typically outweigh this convenience, especially when using modern IDEs with good import management features.
</Callout>

<Callout title="Note" variant="info">
  Note: This article draws information from the following sources: - [Why you
  should avoid barrel files in
  Javascript](https://laniewski.me/blog/pitfalls-of-barrel-files-in-javascript-modules/)
  by Bartosz Łaniewski - [Please Stop Using Barrel
  Files](https://tkdodo.eu/blog/please-stop-using-barrel-files) by Dominik
  Dorfmeister
</Callout>

## Additional Reading

- [Typescript Configuration Options](/docs/customize/typescript/configuring-module-format)
- [Lean SDKs with Standalone Functions](/post/standalone-functions)


 This is the content for the doc docs/customize/typescript/model-validation-and-serialization.mdx 

 ---
title: Model validation and serialization
---

# Model validation and serialization

Speakeasy TypeScript SDKs support model validation and serialization backed by Zod. This feature allows you to validate data against your models and easily serialize or deserialize data to and from JSON.

## Example

As an example, consider the following model definition:

```typescript <sdk-root>/src/models/components/book.ts
import * as z from "zod";

export type Book = {
  /**
   * The unique identifier for the book
   */
  id: string;
  /**
   * The title of the book
   */
  title: string;
  /**
   * The author of the book
   */
  author: string;
};
```

### From JSON

```typescript example.ts
import { bookFromJSON, bookToJSON } from "my-sdk/models/components/book";

const result = bookFromJSON('{"id":"1","title":"1984","author":"George Orwell"}');
if (result.ok) {
  console.log(result.value);
  //                 👆 result.value is of type `Book`
} else {
  // Handle validation errors
  console.error(result.error);
}
```

### To JSON

```typescript example.ts
const jsonString = bookToJSON({ id: "1", title: "1984", author: "George Orwell" });
// jsonString is of type `string`
```




 This is the content for the doc docs/customize/typescript/react-hooks.mdx 

 ---
title: React hooks with TanStack Query
---

import { Callout } from "~/components";

# React hooks with TanStack Query

<Callout title="Availability" variant="info">
  React hooks are available for [Business and Enterprise users](/pricing). You
  can trial this feature when you first sign up or [reach out][contact] to us
  to get access.

  [contact]: mailto:support@speakeasy.com
</Callout>

In addition to the core SDK, you can also generate React hooks that can help
supercharge users building web applications with your APIs.

To get started, update your `gen.yaml` file to enable this feature:

```yaml <sdk-root>/.speakeasy/gen.yaml
typescript:
  enableReactQuery: true
  # other Typescript configuration options...
```

## Customising React hooks

The default naming convention for React hooks follows that of standalone
functions. For example, a standalone function called `productsGetById` will have
a corresponding React hook called `useProductsGetById`.

Sometimes, these names are not ideal for React hooks. In those instances, the
`x-speakeasy-react-hook` OpenAPI extension can be used to override the name:

```yaml openapi.yaml
paths:
  /products/{id}:
    get:
      operationId: getById
      tags: [products] 
      x-speakeasy-react-hook:
        name: Product
      # ...
```

With the example above, the React hook will be called `useProduct` and under the
hood, it will use the `productsGetById` standalone function.

### Queries and mutations

By default, `GET` / `HEAD` / `QUERY` operations will result in React query hooks
being generated while other operations will result in mutation hooks. This isn't
always correct since certain operations may be "read" operations exposed under
`POST` endpoint. A great example of this is complex search APIs that take a
request body with filters and other arguments. You can override these OpenAPI
operations to come out as query hooks using the `x-speakeasy-react-hook`
extension: 

```yaml openapi.yaml
paths:
  /search/products:
    post:
      operationId: productsSearch
      x-speakeasy-react-hook:
        name: Search
        type: query
      # ...
```

### Disabling React hooks for an operation

React hooks may not be useful or relevant for all operations in your API. You
can disable React hooks generation for an operation by setting the `disabled`
flag under the `x-speakeasy-react-hook` extension:

```yaml openapi.yaml
paths:
  /admin/reports:
    post:
      operationId: generateReport
      x-speakeasy-react-hook:
        disabled: true
      # ...
```

 This is the content for the doc docs/customize/webhooks.mdx 

 ---
title: "Add webhooks to your SDKs"
description: "Learn how to generate webhook types in your Speakeasy client SDKs and define incoming webhook requests and responses for consistent API interactions."
slug: "/customize-sdks/webhooks/"
---

import { Callout } from '~/components'

# Add webhooks to your SDKs

## Why use the webhooks feature?

* **Built-in SDK support:** It simplifies webhook adoption through built-in SDK support.
* **Abstracted complexity:** Consumers don't need to worry about cryptographic operations or dependencies.
* **Default security:** Consumers have to verify the signature in order to unpack the webhook data.
* **Type-safe consumption:** Consumers get schema-validated data and types.
* **Type-safe sending:** Producers can send schema-validated data through type-safe SDK methods.

## Getting started

<Callout title="INFO" variant="info">
  Webhooks are a paid add-on, [reach out to us to discuss pricing](https://www.speakeasy.com/book-demo).
</Callout>

1. You must have a [Speakeasy Business or Enterprise plan](/pricing).
2. Run the following command to activate webhooks in your SDK generation configuration:

```bash
speakeasy billing activate -f webhooks
```

## Example

<Callout title="GitHub example source code" variant="info">
  You can see the full source code for this example in the [webhooks example repo](https://github.com/speakeasy-api/examples/tree/main/webhooks-ts).
</Callout>

### OpenAPI

```yaml
# !focus(1,20:50,59,71)
openapi: 3.1.0 # You must use OpenAPI 3.1.0 or higher
info:
  title: Petstore API
  version: 1.0.0
servers:
  - url: https://petstore.swagger.io/v2
paths:
  /pets:
    post:
      operationId: addPet
      requestBody:
        required: true
        content:
          application/json: 
            schema:
              $ref: '#/components/schemas/Pet'
      responses:
        '200':
          description: Okay
x-speakeasy-webhooks:
  security:
    type: signature
    headerName: x-signature
    signatureTextEncoding: base64
    algorithm: hmac-sha256
webhooks:
  pet.created:
    post:
      operationId: sendPetCreated
      requestBody:
        required: true
        content:
          application/json: 
            schema:
              $ref: '#/components/schemas/PetCreated'
      responses:
        '200':
          description: Okay
  pet.deleted:
    post:
      operationId: sendPetDeleted
      requestBody:
        required: true
        content:
          application/json: 
            schema:
              $ref: '#/components/schemas/PetDeleted'
      responses:
        '200':
          description: Okay
components:
  schemas:
    PetCreated:
      type: object
      properties:
        type:
          type: string
          enum:
            - pet.created # This is the payload discriminator
        pet:
          $ref: '#/components/schemas/Pet'
      required:
        - type
        - pet
    PetDeleted:
      type: object
      properties:
        type:
          type: string
          enum:
            - pet.deleted # This is the payload discriminator
        id:
          type: string
      required:
        - type
        - id
    Pet:
      type: object
      properties:
        id:
          type: string
      required:
        - id
```

### For webhook consumers

<Callout title="">
The `validateWebhook()` function is currently only implemented in the TypeScript SDK, with support for additional languages planned for future releases. While other languages will generate webhook types, this discriminator method is TypeScript-only.
</Callout>

```typescript
import { Petstore } from "petstore";
const sdk = new Petstore();

const data = await sdk.validateWebhook({
  request,
  secret: "<secret>",
});

console.log(data);

if (data.type === "pet.created") {
  console.log("Pet created", data.pet);
}

if (data.type === "pet.deleted") {
  console.log("Pet deleted", data.id);
}
```

**Error handling**

```typescript
import { Petstore } from "petstore";
import { SDKValidationError } from "petstore/models/errors/sdkvalidationerror.js";
import { WebhookAuthenticationError } from "petstore/types/webhooks.js";

const sdk = new Petstore();

try {
  await sdk.validateWebhook({
    request,
    secret: "<secret>",
  });
} catch (error) {
  if (error instanceof WebhookAuthenticationError) {
      // Thrown when signature verification fails, usually due to:
      // - Incorrect webhook secret
      // - Modified request payload
      // - Wrong signature format
      console.error("Webhook authentication failed", error);
  }
  if (error instanceof SDKValidationError) {
    // Thrown when the webhook request body is unrecognised, usually due 
    // to an outdated SDK version or un-docummented payloads
    console.error("Webhook request body is invalid", error);
  }
  throw error;
}

```

### For webhook producers

```typescript
import { Petstore } from "petstore";

const sdk = new Petstore();

const data = await sdk.sendPetCreated(
  {
    url: "https://example.com/my-webhook-handler",
    secret: "<secret>",
  },
  {
    type: "pet.created",
    pet: { id: "dog" },
  }
);
```

## `x-speakeasy-webhooks`

The `x-speakeasy-webhooks` extension is used to define the webhooks for your API.

| Property      | Type       | Description                                                                                                                                                                                                                                                                                                                       |
| ------------- | ---------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `security`    | `WebhookSecurity`   | The security configuration for the webhooks.                                                                                                                                                                                                                                                                                     |

### `x-speakeasy-webhooks.security`

| Property      | Type       | Description                                                                                                                                                                                                                                                                                                                       |
| ------------- | ---------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `type`        | `string`   | The type of security to use for the webhooks. Valid values are `signature` and `custom`.                                                                                                                                                                                                                                                                                   |
| `headerName`  | `string`   | The name of the header to use for the security token / signature.                                                                                                                                                                                                                                                                                  |
| `signatureTextEncoding` | `string`   | The text encoding of the signature. Applicable to `type: signature`.                                                                                                                                                                                                                                                                                        |
| `algorithm`   | `string`   | The algorithm to use for the signature. Valid values are: `hmac-sha256`. |

### `x-speakeasy-webhooks.security.type: signature`

```yaml
x-speakeasy-webhooks:
  security:
    type: signature
    headerName: x-signature
    signatureTextEncoding: base64
    algorithm: hmac-sha256
```

This will apply HMAC SHA256 to the body of the webhook request and put it in a header.

### `x-speakeasy-webhooks.security.type: custom`

```yaml
x-speakeasy-webhooks:
  security:
    type: custom
```

This generates the `src/hooks/webhooks-custom-security.ts` boilerplate file, which you can then use to modify the security logic.

See the source code for this example in the [GitHub repo](https://github.com/speakeasy-api/examples/tree/main/webhooks-custom-security-ts).


 This is the content for the doc docs/enterprise-support.mdx 

 ---
title: "Enterprise support"
description: "How Speakeasy supports our enterprise customers"
---

import { Callout } from "~/components";

# How Speakeasy Supports Our Enterprise Customers

## 1. Automatic SDK Maintenance

A core aspect of Speakeasy's value proposition is keeping your SDKs up to date with key changes in languages, frameworks, and dependencies.

We ensure that these updates are propagated to the SDKs we maintain on your behalf, and post such updates automatically in the SDK pull requests we create.

<Callout title="Note" variant="info">
  We recommend upgrading to the newest version of Speakeasy to ensure your SDKs benefit from the latest updates. Customers using Speakeasy via GitHub Actions will automatically use the most recent version.
</Callout>


## 2. Support SLAs

Speakeasy is committed to providing rapid response and resolution to any issues you raise. With this in mind, we offer:
* A dedicated customer support channel (Slack, Teams).
* Prioritized ticket resolution based on severity (P0, P1, P2 SLAs).
* SLAs for question response and ticket triage are detailed below.

| Priority level | Definition | SLA | Initiation | Credits |
| -------- | -------- | -------- | -------- | -------- |
| P0 | Generated Terraform providers or SDKs do not work (severe functional issues) | First response within 1 hour | E-mail support@speakeasy.com | 5% of the fee applicable in the month per incident of SLA breach |
| P1 | Generated Terraform providers or SDKs have severe ergonomic or minor functional impact on customers | First response within 3 hours | E-mail support@speakeasy.com | 2% of the fee applicable in the month per incident of SLA breach |
| P2 | Generated Terraform providers or SDKs have bugs with minor ergonomic impact on customers, feature requests | Prioritize as part of standard Speakeasy development practice, visible in public roadmap | E-mail support@speakeasy.com | n/a |


## 3. Uptime SLAs

Core systems (code generation, app, CLI) uptime: 99.99% uptime per calendar month
- Calculation: Total uptime minutes per calendar month / total minutes per calendar month
- Credit on SLA breach:
  - Uptime between 95% - 99.99%: 10% of the fee applicable in that month
  - Uptime less than 95%: 20% of the fee applicable in that month

Current and historical metrics can be viewed at https://status.speakeasyapi.dev/.

In no instance will the total credits in a given month for Technical Support SLA breaches or Uptime SLA breaches exceed the total fee applicable from the customer in that month.


 This is the content for the doc docs/index.mdx 

 ---
title: Documentation
description: "Read Speakeasy documentation for more information on our features and how to use them."
---

import { SearchBarDocs } from "~/lib/inkeep/base";
import { Banner, GenerateSDK, GenerateTerraformProviders, TestApis, GovernApis, Support } from "~/features/docs/home";

<Banner />

<SearchBarDocs />

<GenerateSDK />
<GenerateTerraformProviders />
<TestApis />
<GovernApis />

<Support />



 This is the content for the doc docs/integrations/_get-public-url-snippet.mdx 

 {/* This snippet is made to be reused in docs that require instruction on grabbing the Public URL. */}

# Get Public URL from Registry

First, navigate to the [Speakeasy Dashboard](https://app.speakeasy.com) and open
the API Registry tab. Once there, open the `*-with-code-samples` entry for the
desired API.

<Screenshot darkened docs={true}>
  ![Speakeasy OpenAPI
  Registry](../assets/code-samples/openapi-registry-and-combined-spec.png)
</Screenshot>

> NOTE: If this entry is not labeled with `Combined Spec`, ensure that the API
> has an [Automatic Code Sample
> URL](/docs/code-samples/automated-code-sample-urls) configured.

From the registry entry's page, copy the provided public URL.

<Screenshot darkened docs={true}>
  ![Combined Spec Registry
  Entry](../assets/code-samples/copy-combined-spec-url.png)
</Screenshot>


 This is the content for the doc docs/integrations/bump.mdx 

 ---
slug: /bump/
sidebar_label: Integrate With Bump.sh
title: Integrate Speakeasy With Bump.sh
description: "Learn how to integrate Speakeasy SDKs into Bump.sh docs."
---

import { Callout } from "~/components";
import GetPublicUrlSnippet from "./_get-public-url-snippet.mdx";

# Integrate Speakeasy With Bump.sh

---

## Overview

Bump.sh is a hosted solution for simple API documentation, API catalogs, and API
explorers, which makes it a great tool to use in conjunction with [Speakeasy's
Automated Code Samples feature](/docs/code-samples/automated-code-sample-urls).
Embed your SDKs right into the API documentation, making it easier for
developers to get started with your API.

<Screenshot darkened url="docs.myapi.com" docs={true}>
  ![Bump.sh Docs with Speakeasy SDK code samples](../assets/code-samples/bump-with-speakeasy-openapi.png)
</Screenshot>

## Setting up the Integration

### Prerequisites

<Callout title="IMPORTANT" variant="warning">
  Before continuing with this guide, ensure that the following prerequisites
  have been met:
  <br />
  <ul className="list-disc pl-5">
    <li className="marker:content-['✓__']">
      {"An "}
      <a href="/docs/code-samples/automated-code-sample-urls">
        {"Automated Code Sample URL"}
      </a>
      {" has been configured for the desired Speakeasy SDK, and"}
    </li>
    <li className="marker:content-['✓__']">
      {"Created an account on "} <a href="https://bump.sh">Bump.sh</a>
      {"."}
    </li>
  </ul>
  Once those requirements have been met, proceed with the following steps.
</Callout>

### Locate & Copy the Combined Spec URL

<GetPublicUrlSnippet />

### Import the Combined Spec URL into Bump.sh

Next, head over to your Bump.sh dashboard and either create "New Documentation",
or open existing API documentation. Click "Settings" and open the "Automatic Deployment" tab.

<Screenshot darkened url="bump.sh/dashboard" docs={true}>
  ![Bump.sh Auotmatic Deployment Settings](../assets/code-samples/bump-automatic-deployment-settings.png)
</Screenshot>

Pick whether you want to deploy via GitHub Actions or CLI, and copy the
appropriate example which will include the Doc ID and the API token for you.

If you're just starting out, let's start with the CLI. Open your terminal and run the following command:

```bash
npm install -g bump-cli

bump deploy https://spec.speakeasy.com/walker/walker/book-club-oas-with-code-samples
  --token=<your-api-token>
  --doc=<your-doc-id>
```

After the import has completed, the API documentation will be rendered, and your
SDKs will be embedded as code samples in each OpenAPI operation.

<Screenshot darkened url="bump.sh/your-docs" docs={true}>
  ![Bump.sh Docs with Speakeasy Code Samples](../assets/code-samples/bump-with-speakeasy-openapi.png)
</Screenshot>

## What Next?

This is a basic setup, so for more advanced configurations, you can refer to the
[Bump.sh and Speakeasy integration
guide](https://docs.bump.sh/guides/bump-sh-tutorials/generate-sdks-with-speakeasy/)
which will demonstrate using GitHub Actions to automate deployments.

Bump.sh is much more than just an OpenAPI spec renderer, it offers API catalogs,
discovering, and playgrounds. Learn more about Bump.sh on their [official
documentation](https://docs.bump.sh/).


 This is the content for the doc docs/integrations/mintlify.mdx 

 ---
slug: /mintlify/
sidebar_label: Integrate With Mintlify
title: Integrate Speakeasy With Mintlify
description: "Learn how to integrate Speakeasy code generation into Mintlify docs."
---

import { Callout } from "~/components";
import GetPublicUrlSnippet from "./_get-public-url-snippet.mdx";

# Integrate Speakeasy With Mintlify

---

## Overview

Auto-generated code snippets from Speakeasy SDKs can be integrated directly into
Mintlify API reference documentation. SDK usage snippets are shown in the
[interactive playground](https://mintlify.com/docs/api-playground/overview) of
Mintlify-powered documentation sites.

<Screenshot url="docs.myapi.com" docs={true}>
  ![Speakeasy code snippets with
  Mintlify.](../assets/code-samples/mintlify-with-speakeasy-openapi.png)
</Screenshot>

## Setting up the Integration

### Prerequisites

<Callout title="IMPORTANT" variant="warning">
  Before continuing with this guide, ensure that the following prerequisites
  have been met:
  <br />
  <ul className="list-disc pl-5">
    <li className="marker:content-['✓__']">
      {"An "}
      <a href="/docs/code-samples/automated-code-sample-urls">
        {"Automated Code Sample URL"}
      </a>
      {" has been configured for the desired Speakeasy SDK, and"}
    </li>
    <li className="marker:content-['✓__']">
      {"A "}
      <a href="https://mintlify.com/docs/quickstart#creating-the-repository">
        {"Mintlify documentation repository"}
      </a>
      {" has been created."}
    </li>
  </ul>
  Once those requirements have been met, proceed with the following steps.
</Callout>

### Locate & Copy the Combined Spec URL

<GetPublicUrlSnippet />

### Update Mintlify config, aka `mint.json`

OpenAPI specifications can be added to **Anchors**, or **Tabs** in the
`mint.json` file of a Mintlify repository. Anchors are displayed as a list of
links on the left side of the documentation, while Tabs are displayed as tabs on
the top of the documentation.

To add an OpenAPI specification to **Anchors**, update the `anhchor` field in
`mint.json` file with:

```json mint.json
{
  "anchors": [
    {
      "name": "API Reference",
      // !mark
      "openapi": "SPEAKEASY_COMBINED_SPEC_URL",
      "url": "api-reference",
      "icon": "square-terminal"
    }
  ]
}
```

To add an OpenAPI specification to **Tabs**, update the `tab` field in
`mint.json` file with:

```json mint.json
{
  "tabs": [
    {
      "name": "API Reference",
      "url": "api-reference",
      // !mark
      "openapi": "SPEAKEASY_COMBINED_SPEC_URL"
    }
  ]
}
```

Mintlify offers useful customizations for API references generated from OpenAPI
specifications. For more information on, refer to the [Mintlify
documentation](https://mintlify.com/docs/api-playground/openapi/setup).

## What Next?

After completing the steps above, code snippets generated by Speakeasy can be
viewed in the Mintlify API reference documentation. To see the code snippets in
action, navigate to the [interactive
playground](https://mintlify.com/docs/api-playground/overview) of the
Mintlify-powered documentation site.


 This is the content for the doc docs/integrations/readme.mdx 

 ---
slug: /readme/
sidebar_label: Integrate With ReadMe
title: Integrate Speakeasy With ReadMe
description: "Learn how to integrate Speakeasy code generation into ReadMe docs."
---

import { ScrollyCoding } from "~/components/codehike/Spotlight";
import { Callout } from "~/components";
import GetPublicUrlSnippet from "./_get-public-url-snippet.mdx";

# Integrate Speakeasy With ReadMe

---

## Overview

Auto-generated code snippets from Speakeasy SDKs can be integrated directly into
a ReadMe documentation site.

<Screenshot url="docs.myapi.com" docs={true}>
  ![Speakeasy code snippets with
  Readme](../assets/code-samples/readme-oas-api-reference.webp)
</Screenshot>

## Setting up the Integration

### Prerequisites

<Callout title="IMPORTANT" variant="warning">
  Before continuing with this guide, ensure that the following prerequisites
  have been met:
  <br />
  <ul className="list-disc pl-5">
    <li className="marker:content-['✓__']">
      {"An "}
      <a href="/docs/code-samples/automated-code-sample-urls">
        {"Automated Code Sample URL"}
      </a>
      {" has been configured for the desired Speakeasy SDK, and"}
    </li>
    <li className="marker:content-['✓__']">
      {"A "}
      <a href="https://docs.readme.com/main/docs/quickstart-guide#step-1-creating-your-project">
        {"ReadMe project"}
      </a>
      {" has been created."}
    </li>
  </ul>
  Once those requirements have been met, proceed with the following steps.
</Callout>

### Configure `workflow.yaml` for ReadMe

To display code samples generated by Speakeasy SDKs in ReadMe, you must update
the `workflow.yaml` configuration file to support their proprietary OpenAPI
extension.

Simply change the `codeSamples.style` field for your desired target in the
`workflow.yaml` file to `readme`:

```yaml /.speakeasy/workflow.yaml
targets:
  my-target:
    target: typescript
    codeSamples:
      # !mark(1:2)
      style: readme
      langOverride: javascript # see note below
      registry:
        location: registry.speakeasyapi.dev/...
      blocking: false
    ...
```

<Callout title="Note for Typescript">
  If the `target` value is set to `typescript`, the `langOverride` field must be
  set to `javascript`, or else generated code samples will _not_ be displayed in
  ReadMe.
  {` `}
  If `target` is _not_ set to `typescript`, then `langOverride` should be set to
  `auto-detect`.
</Callout>

### Locate & Copy the Combined Spec URL

<GetPublicUrlSnippet />

### Upload the Combined Spec URL to ReadMe

Next, from the [ReadMe dashboard](https://dash.readme.com), open a project.

<Screenshot url="dash.readme.com" docs={true}>
  ![ReadMe Dashboard](../assets/code-samples/readme-dashboard.webp)
</Screenshot>

Click on the **API Reference** tab, then click **&plus; New API Definition**.

<Screenshot url="myapi.readme.io" docs={true}>
  ![ReadMe API Reference
  Page](../assets/code-samples/readme-project-to-upload-oas.webp)
</Screenshot>

In the form that appears, paste the copied URL into the text input below
**Import from URL**, then click **Import**.

<Screenshot url="myapi.readme.io" docs={true}>
  ![Filling the ReadMe OAS Import
  Form](../assets/code-samples/readme-importing-from-url.png)
</Screenshot>

## What Next?

After completing these steps, Speakeasy-generated code snippets are viewable in
the ReadMe project's API Reference section. For guidance on customizing ReadMe
API References generated from OpenAPI specifications, refer to the [ReadMe
OpenAPI Support Documentation](https://docs.readme.com/main/docs/openapi).


 This is the content for the doc docs/integrations/scalar.mdx 

 ---
slug: /scalar/
sidebar_label: Integrate With Scalar
title: Integrate Speakeasy With Scalar
description: "Learn how to integrate Speakeasy code generation into Scalar docs."
---

import { Callout } from "~/components";
import GetPublicUrlSnippet from "./_get-public-url-snippet.mdx";

# Integrate Speakeasy With Scalar

---

## Overview

**Scalar** makes creating and maintaining API documentation _very_ easy. It is
able to to render documentation by referencing a live OpenAPI spec, making it a
great tool to use in conjunction with [Speakeasy's Automated Code Samples
feature](/docs/code-samples/automated-code-sample-urls).

<Screenshot darkened url="docs.myapi.com" docs={true}>
  ![Scalar Docs with Successful Linked
  URL](../assets/code-samples/scalar-docs-url-imported.png)
</Screenshot>

## Setting up the Integration

### Prerequisites

<Callout title="IMPORTANT" variant="warning">
  Before continuing with this guide, ensure that the following prerequisites
  have been met:
  <br />
  <ul className="list-disc pl-5">
    <li className="marker:content-['✓__']">
      {"An "}
      <a href="/docs/code-samples/automated-code-sample-urls">
        {"Automated Code Sample URL"}
      </a>
      {" has been configured for the desired Speakeasy SDK, and"}
    </li>
    <li className="marker:content-['✓__']">
      {"Created an account on "} <a href="https://scalar.com">Scalar</a>
      {"."}
    </li>
  </ul>
  Once those requirements have been met, proceed with the following steps.
</Callout>

### Locate & Copy the Combined Spec URL

<GetPublicUrlSnippet />

### Import the Combined Spec URL into Scalar

Next, open a [Scalar project](https://docs.scalar.com), open the **Reference**
tab, then click **Import URL**.

<Screenshot darkened url="docs.scalar.com" docs={true}>
  ![Scalar Doc Maker](../assets/code-samples/scalar-reference-to-import-url.png)
</Screenshot>

Finally, paste the copied URL into the provided field, check **Create Live Link**
(optional), then click **Import**.

<Screenshot darkened url="docs.scalar.com" docs={true}>
  ![Linking Scalar to Speakeasy Public
  URL](../assets/code-samples/scalar-link-openapi-specification-modal.png)
</Screenshot>

After the import process has completed, the API documentation will be rendered.

<Screenshot darkened url="docs.scalar.com">
  ![Scalar Docs with Successful Linked
  URL](../assets/code-samples/scalar-docs-url-imported.png)
</Screenshot>

## What Next?

Scalar is much more than just an OpenAPI spec renderer. Continue to learn more
about Scalar by visiting their [official
documentation](https://guides.scalar.com/scalar/introduction).


 This is the content for the doc docs/introduction.mdx 

 ---
title: Introduction
description: "Introduction to Speakeasy."
---

import cli_quickstart from './assets/cli-quickstart.mp4';

import Image from "next/image";
import vsCodeImageUrl from "./assets/vscode.svg"

# Introduction to Speakeasy

Use Speakeasy to service your API community with a best-in-class developer experience, without building and maintaining SDKs yourself.

## Features

* Generate production-ready SDKs in over eight programming languages. 

* Customize and brand SDKs to suit your needs.

* Generate Terraform providers directly from your OpenAPI document.

* Use powerful primitives like sources and targets to design a code generation pipeline for local development and CI/CD.

* Automate your API supply chain to detect breaking changes, versioning, and release management to package managers.

* Build maintenance workflows on your OpenAPI document using [overlays](/docs/prep-openapi/overlays/create-overlays).

* Use a schema registry to build API provenance, enforce standards, and simplify governance.

## Getting started

Start locally and manage multiple APIs through our platform. It's as easy as following these steps: 

1. Create an account on [our platform](https://app.speakeasy.com).
2. Install the Speakeasy CLI using Homebrew or curl:
```bash
brew install speakeasy-api/tap/speakeasy
```
or
```bash
curl -fsSL https://go.speakeasy.com/cli-install.sh | sh
```
3. Run `speakeasy quickstart` in any code directory or follow the instructions on the dashboard.

And you're on your way! See our [complete getting started guide](/docs/create-client-sdks) for more details.
<br></br>

<video controls={false} loop={true} autoPlay={true} muted={true} width="100%" >
   <source src={cli_quickstart} type="video/mp4" />
</video>

## How does it work?

Speakeasy understands your API specification and creates a flexible representation to generate SDKs, Terraform providers, and more.

Everything can be run locally through the CLI. The Speakeasy platform tracks the different artifacts and versions you create, allowing you to manage them in one place. For more advanced use cases, the CLI can be tooled directly into your CI/CD pipelines. 

If you have questions, join our [community Slack](https://join.slack.com/t/speakeasy-dev/shared\_invite/zt-1df0lalk5-HCAlpcQiqPw8vGukQWhexw) or [book a time](https://calendly.com/d/5dm-wvm-2mx/chat-with-speakeasy-team) to speak with one of us.

## Work with Speakeasy in your IDE

<Image src={vsCodeImageUrl} width="20" height="20" style={{display: "inline-block"}} alt="VS Code icon" /> The [Speakeasy VS Code extension](https://marketplace.visualstudio.com/items?itemName=Speakeasy.speakeasy-vscode-extension) provides syntax highlighting, autocompletion for supported file types, and linting for OpenAPI documents.


 This is the content for the doc docs/languages/csharp/methodology-csharp.mdx 

 ---
title: "Generate C# SDKs from OpenAPI / Swagger"
description: "Learn how Speakeasy creates a C# client from an OpenAPI spec."
---


# Generate C# SDKs from OpenAPI / Swagger

## SDK Overview

The Speakeasy C# SDK is designed to support the .NET ecosystem, including publishing to [NuGet](https://www.nuget.org/).
The .NET version to build against is configurable to either `.NET 8.0` (default), `.NET 6.0`, or `.NET 5.0`.

The SDK is designed to be strongly typed, light on external dependencies, easy to debug, and easy to use. Some of its core features include:

- Interfaces for core components allow for dependency injection and mocking.
- Generated C# doc comments to enhance IntelliSense compatibility and developer experience.
- Async/await support for all API calls.
- Optional pagination support for supported APIs.
- Support for complex number types:
  - `System.Numbers.BigInteger`
  - `System.Decimal`
- Support for string- and integer-based enums.

The SDK includes minimal dependencies. The only external dependencies are:

- `newtonsoft.json` for JSON serialization and deserialization.
- `nodatime` for date and time handling.

## C# Package Structure

```yaml lib-structure.yaml
├── {sourceDirectory}                # The Source Directory (src by default)
|   ├── {packageName}                # The root namespace for the SDK (folder structure mirrors the dot-separated {packageName})
|   |   ├── {packageName}.csproj
|   |   ├── {sdkClassName}.cs        # The main SDK class
|   |   ├── ...                      # Other SDK classes
|   |   ├── Models                   # The namespace for the SDK's models
|   |   |   ├── Errors               # The namespace for the SDK's error response models, where custom exceptions are located
|   |   |   ├── Requests             # The namespace for the SDK's request models which generally houses the request/response models for each API (in older generations and other targets, this folder was called `Operations`)
|   |   |   |   ├── ...
|   |   |   └── Components           # The namespace for the SDK's models generated from components in the OpenAPI document (in older generations, this folder was called `Shared`)
|   |   |       ├── ...
|   |   └── Utils                    # The namespace for the SDK's utility classes
├── docs                             # Markdown files for the SDK's documentation
|   └── ...
├── {packageName}.sln                # The SDK's solution file
└── ...
```

## HTTP Client

By default, the C# SDK will instantiate its own `SpeakeasyHttpClient`, which uses the `System.Net.HttpClient` under the hood. The default client can be overridden by passing a custom HTTP client when initializing the SDK:
```csharp
var sdk = new SDK(client: new CustomHttpClient());
```

The provided HTTP client must implement the `ISpeakeasyHttpClient` interface as defined in `Utils.SpeakeasyHttpClient.cs`:
```csharp
using <NameSpace>.Utils;

public class CustomHttpClient : ISpeakeasyHttpClient
{
    public CustomHttpClient()
    {
        // initialize client
    }

    /// <summary>
    /// Sends an HTTP request asynchronously.
    /// </summary>
    /// <param name="request">The HTTP request message to send.</param>
    /// <returns>The value of the TResult parameter contains the HTTP response message.</returns>
    public virtual async Task<HttpResponseMessage> SendAsync(HttpRequestMessage request)
    {
        // implement the send method
    }

    /// <summary>
    /// Clones an HTTP request asynchronously.
    /// </summary>
    /// <remarks>
    /// This method is used in the context of Retries. It creates a new HttpRequestMessage instance
    /// as a deep copy of the original request, including its method, URI, content, headers, and options.
    /// </remarks>
    /// <param name="request">The HTTP request message to clone.</param>
    /// <returns>The value of the TResult parameter contains the cloned HTTP request message.</returns>
    public virtual async Task<HttpRequestMessage> CloneAsync(HttpRequestMessage request)
    {
       // implement the clone method
    }
}
```

This is useful if you're using a custom HTTP client that supports proxy settings or other custom configuration.

In the example below, a custom client inherits from the internal `SpeakeasyHttpClient` class, which implements the `ISpekeasyHttpClient` interface. This client adds a header to all requests before sending them:
```csharp
using <NameSpace>.Utils;

internal class CustomSpeakeasyHttpClient : SpeakeasyHttpClient
{
    public CustomSpeakeasyHttpClient() {}

    public override async Task<HttpResponseMessage> SendAsync(HttpRequestMessage request)
    {
        request.Headers.Add("X-Custom-Header", "custom value");
        return await base.SendAsync(request);
    }
}
```

## Data Types and Classes

The C# SDK uses as many native types from the standard library as possible, for example:

- `string`
- `System.DateTime`
- `int`
- `long`
- `System.Numberics.BigInteger`
- `float`
- `double`
- `decimal`
- `bool`

The C# SDK will only fall back on custom types when the native types are not suitable, for example:

- `NodaTime.LocalDate` for `date` types
- Custom `enum` types for `string` and `integer` based enums

Speakeasy will generate standard C# classes with public fields that use attributes to guide the serialization and deserialization processes.

## Parameters

If parameters are defined in the OpenAPI document, Speakeasy will generate methods with parameters.

The number of parameters defined should not exceed the `maxMethodParams` value configured in the `gen.yaml` file. If they do or the `maxMethodParams` value is set to `0`, Speakeasy will generate a request object that allows for all parameters to be passed in a single object.

## Errors

The C# SDK will throw exceptions for any network or invalid request errors.

For unsuccessful responses, if a custom error response is specified in your spec file, the SDK will unmarshal the HTTP response details into the custom error response and throw it as an exception. If no custom response is specified in your spec, the SDK will throw an `SDKException` containing details of the failed response.

```csharp
using Openapi;
using Openapi.Models.Shared;
using System;
using Openapi.Models.Errors;
using Openapi.Models.Operations;

var sdk = new SDK();

try
{
    var res = await sdk.Errors.StatusGetXSpeakeasyErrorsAsync(statusCode: 385913);
    // handle success
}
catch (Exception ex)
{
    if (ex is StatusGetXSpeakeasyErrorsResponseBody)
    {
        // handle custom exception response
    }
    else if (ex is Openapi.Models.Errors.SDKException)
    {
        // handle standard exception response
    }
}

```

## User Agent Strings

The C# SDK will include a [user agent](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/User-Agent) string in all requests that can be leveraged for tracking SDK usage amongst broader API usage. The format is as follows: 

```stmpl
speakeasy-sdk/csharp {{SDKVersion}} {{GenVersion}} {{DocVersion}} {{PackageName}}
```

- `SDKVersion` is the version of the SDK, defined in `gen.yaml` and released.
- `GenVersion` is the version of the Speakeasy generator.
- `DocVersion` is the version of the OpenAPI document.
- `PackageName` is the name of the package defined in `gen.yaml`.


 This is the content for the doc docs/languages/csharp/oss-comparison-csharp.mdx 

 ---
title: "Comparison guide: OpenAPI/Swagger C# client generation"
description: "Comparing the new Speakeasy C# SDK generator with the Open Source OpenAPI C# generator"
keywords: [api, openapi, swagger, sdk generation, sdk, C#, sdk, developer experience, devex, dx]
date: 2024-05-23
---

# Comparison guide: OpenAPI/Swagger C# client generation

Speakeasy produces idiomatic SDKs in various programming languages, including C#. The Speakeasy approach to SDK generation prioritizes a good developer journey to enable you as an API provider to focus on developing a streamlined experience for your users.

In this article, we'll compare creating a C# SDK using Speakeasy to creating one using the open-source OpenAPI Generator. The table below is a summary of the comparison:

| Feature/Aspect | Speakeasy | OpenAPI Generator |
|---------------|-----------|-------------------|
| **Framework Support** | ⚠️ Limited to .NET 5+ | ✅ Wider range (.NET Framework 4.7, .NET Standard 1.3-2.1, .NET 6+) |
| **.NET Features** | ✅ Full async/await support, interfaces for DI | ⚠️ Basic async/await support |
| **Dependencies** | ✅ Minimal - Only Newtonsoft.Json and NodaTime | ❌ Multiple dependencies including JsonSubTypes, Newtonsoft.Json, RestSharp, Polly, System.Web |
| **Code Style** | ✅ Modern, idiomatic C# with object initializers | ⚠️ Traditional C# with constructors and property setters |
| **HTTP client** | ✅ Uses built-in System.Net.Http | ❌ Relies on third-party RestSharp library |
| **Request retry** | ✅ Built-in configurable retry support with multiple strategies | ❌ No built-in retry support |
| **Model implementation** | ✅ Modern, concise approach using nullable types and attributes | ⚠️ Traditional approach with more verbose implementations |
| **Serialization** | ✅ Clean approach using JsonProperty attributes directly | ⚠️ More complex approach using DataContract and DataMember attributes |
| **Documentation** | ✅ Comprehensive documentation with detailed examples and error handling | ⚠️ Basic documentation focusing on setup and API routes |
| **Error handling** | ⚠️ Generic exceptions with stack traces | ✅ More descriptive custom exceptions |
| **Customization** | ✅ Supports hooks and custom configurations | ❌ Limited customization options |

You can explore the Speakeasy [C# SDK documentation](/docs/languages/csharp/methodology-csharp) for more information. 

For a detailed technical comparison, read on!

## Installing the CLIs

We'll start by installing the Speakeasy CLI and the OpenAPI Generator CLI.

### Installing the Speakeasy CLI

You can install the Speakeasy CLI by following the installation instructions [here](/docs/speakeasy-reference/cli/getting-started).

After installation, you can check the version to ensure the installation was successful:

```bash
speakeasy -v
```

If you encounter any errors, take a look at the [Speakeasy SDK creation documentation](/docs/create-client-sdks).

### Installing the OpenAPI Generator CLI

Install the OpenAPI Generator CLI by running the following command in an terminal:

```bash
curl -o openapi-generator-cli.jar https://repo1.maven.org/maven2/org/openapitools/openapi-generator-cli/7.2.0/openapi-generator-cli-7.2.0.jar
```

## Downloading the Swagger Petstore specification

We need an OpenAPI specification YAML file to generate SDKs. We'll use the Swagger Petstore specification, which you can find at [https://petstore3.swagger.io/api/v3/openapi.yaml](https://petstore3.swagger.io/api/v3/openapi.yaml).

In a terminal in your working directory, download the file and save it as `petstore.yaml` with the following command:

```bash
curl -o petstore.yaml https://petstore3.swagger.io/api/v3/openapi.yaml
```

## Validating the specification file

Let's validate the spec using both the Speakeasy CLI and OpenAPI Generator.

### Validating the Specification File Using Speakeasy

Validate the spec with Speakeasy using the following command:

```bash
speakeasy validate openapi -s petstore.yaml
```

The Speakeasy validator returns the following:

```bash

╭────────────╮╭───────────────╮╭────────────╮
│ Errors (0) ││ Warnings (10) ││ Hints (72) │
├────────────┴┘               └┴────────────┴────────────────────────────────────────────────────────────╮
│                                                                                                        │
│ │ Line 250: operation-success-response - operation `updatePetWithForm` must define at least a single   │
│ │ `2xx` or `3xx` response                                                                              │
│                                                                                                        │
│   Line 277: operation-success-response - operation `deletePet` must define at least a single `2xx` or  │
│   `3xx` response                                                                                       │
│                                                                                                        │
│   Line 413: operation-success-response - operation `deleteOrder` must define at least a single `2xx` o │
│   r                                                                                                    │
│   `3xx` response                                                                                       │
│                                                                                                        │
│   Line 437: operation-success-response - operation `createUser` must define at least a single `2xx` or │
│   `3xx` response                                                                                       │
│                                                                                                        │
│   Line 524: operation-success-response - operation `logoutUser` must define at least a single `2xx` or │
│   `3xx` response                                                                                       │
│                                                                                                        │
│   ••                                                                                                   │
└────────────────────────────────────────────────────────────────────────────────────────────────────────┘

 ←/→ switch tabs  ↑/↓ navigate  ↵ inspect  esc quit

```

The Speakeasy CLI validation result gives us a handy tool for switching between the errors, warnings, and hints tabs with the option to navigate through the results on each tab.

In this instance, Speakeasy generated ten warnings. Let's correct them before continuing.

Notice that some of the warnings contain a `default` response. For completeness, we'd like to explicitly return a `200` HTTP response. We'll make the following modifications in the `petstore.yaml` file.

When the `updatePetWithForm` operation executes successfully, we expect an HTTP `200` response with the updated `Pet` object to be returned.

Insert the following after `responses` on line 250:

```yaml
"200":
  description: successful operation
  content:
    application/xml:
      schema:
        $ref: "#/components/schemas/Pet"
    application/json:
      schema:
        $ref: "#/components/schemas/Pet"
```

Similarly, following successful `createUser` and `updateUser` operations, we'd like to return an HTTP `200` response with a `User` object.

Add the following text to both operations below `responses`:

```yaml
"200":
  description: successful operation
  content:
    application/xml:
      schema:
        $ref: "#/components/schemas/User"
    application/json:
      schema:
        $ref: "#/components/schemas/User"
```

Now we'll add the same response to four operations. Copy the following text:

```yaml
"200":
    description: successful operation
```

Paste this response after `responses` for the following operations:

- `deletePet`
- `deleteOrder`
- `logoutUser`
- `deleteUser`

We are left with three warnings indicating potentially unused or orphaned objects and operations.

For unused objects, locate the following lines of code and delete them:

```yaml
Customer:
  type: object
  properties:
    id:
      type: integer
      format: int64
      example: 100000
    username:
      type: string
      example: fehguy
    address:
      type: array
      xml:
        name: addresses
        wrapped: true
      items:
        $ref: "#/components/schemas/Address"
  xml:
    name: customer
Address:
  type: object
  properties:
    street:
      type: string
      example: 437 Lytton
    city:
      type: string
      example: Palo Alto
    state:
      type: string
      example: CA
    zip:
      type: string
      example: "94301"
  xml:
    name: address
```

To remove the unused request bodies, locate the following lines and delete them:

```yaml
requestBodies:
  Pet:
    description: Pet object that needs to be added to the store
    content:
      application/json:
        schema:
          $ref: "#/components/schemas/Pet"
      application/xml:
        schema:
          $ref: "#/components/schemas/Pet"
  UserArray:
    description: List of user object
    content:
      application/json:
        schema:
          type: array
          items:
            $ref: "#/components/schemas/User"
```

Now if you validate the file with the Speakeasy CLI, you'll notice there are no warnings:

```
╭────────────╮╭──────────────╮╭────────────╮
│ Errors (0) ││ Warnings (0) ││ Hints (75) │
├────────────┴┴──────────────┴┘            └─────────────────────────────────────────────────────────────╮
│                                                                                                        │
│ │ Line 51: missing-examples - Missing example for requestBody. Consider adding an example              │
│                                                                                                        │
│   Line 54: missing-examples - Missing example for requestBody. Consider adding an example              │
│                                                                                                        │
│   Line 57: missing-examples - Missing example for requestBody. Consider adding an example              │
│                                                                                                        │
│   Line 65: missing-examples - Missing example for responses. Consider adding an example                │
│                                                                                                        │
│   Line 68: missing-examples - Missing example for responses. Consider adding an example                │
│                                                                                                        │
│   •••••••••••••••                                                                                      │
└────────────────────────────────────────────────────────────────────────────────────────────────────────┘

 ←/→ switch tabs  ↑/↓ navigate  ↵ inspect  esc quit
```

### Validating the specification file using the OpenAPI Generator

OpenAPI Generator requires Java runtime environment (JRE) version 11 or later installed. Confirm whether JRE is installed on your system by executing the following command:

```bash
java --version
```

If Java is installed, information about the version should be displayed similar to this:

```bash
java 17.0.8 2023-07-18 LTS
Java(TM) SE Runtime Environment (build 17.0.8+9-LTS-211)
Java HotSpot(TM) 64-Bit Server VM (build 17.0.8+9-LTS-211, mixed mode, sharing)
```

If you get an error or the JRE version is older than version 11, you need to update or [install Java](https://docs.oracle.com/goldengate/1212/gg-winux/GDRAD/java.htm#BGBFJHAB).

Now you can validate the `petstore.yaml` specification file with OpenAPI Generator by running the following command in the terminal:

```bash
java -jar openapi-generator-cli.jar validate -i petstore.yaml
```

The OpenAPI Generator returns the following response, indicating no issues detected.

```
Validating spec (petstore.yaml)
No validation issues detected.
```

Now that we have made the `petstore.yaml` file more complete by fixing the warnings, let's use it to create SDKs.

## Creating SDKs

We'll create C# SDKs using Speakeasy and OpenAPI Generator and then compare them.

### Creating an SDK with Speakeasy

To create a C# SDK from the `petstore.yaml` specification file using Speakeasy, run the following command in the terminal:

```bash
# Generate Pet store SDK using Speakeasy CLI generator
speakeasy generate sdk --schema petstore.yaml --lang csharp --out petstore-sdk-csharp-speakeasy
```

The generator will return some logging results while the SDK is being created and a success indicator should appear upon completion.

```
SDK for csharp generated successfully ✓
```

### Creating an SDK with OpenAPI Generator

Run the following command in the terminal to generate a C# SDK using OpenAPI Generator:

```bash
# Generate Pet store SDK using OpenAPI generator
java -jar openapi-generator-cli.jar generate -i petstore.yaml -g csharp -o petstore-sdk-csharp-openapi
```

The generator returns various logs and finally a successful generation message.

```
################################################################################
# Thanks for using OpenAPI Generator.                                          #
# Please consider donation to help us maintain this project ?                  #
# https://opencollective.com/openapi_generator/donate                          #
#                                                                              #
# This generator's contributed by Jim Schubert (https://github.com/jimschubert)#
# Please support his work directly via https://patreon.com/jimschubert ?       #
################################################################################
```

## SDK code compared: Project structure

Let's compare the two project structures by printing a tree view of each SDK directory.

Run the following command to get the Speakeasy SDK structure:

```bash
tree petstore-sdk-csharp-speakeasy
```

The results of the project structure are displayed as follows:

```
petstore-sdk-csharp-speakeasy
│   .gitattributes
│   .gitignore
│   global.json
│   Openapi.sln
│   README.md
│   USAGE.md
│
├───.speakeasy
│       gen.lock
│       gen.yaml
│
├───docs
│   ├───Models
│   │   ├───Components
│   │   │       ApiResponse.md
│   │   │       Category.md
│   │   │       HTTPMetadata.md
│   │   │       Order.md
│   │   │       OrderStatus.md
│   │   │       Pet.md
│   │   │       Security.md
│   │   │       Status.md
│   │   │       Tag.md
│   │   │       User.md
│   │   │
│   │   └───Requests
│   │           AddPetFormResponse.md
│   │           AddPetJsonResponse.md
│   │           AddPetRawResponse.md
│   │           CreateUserFormResponse.md
│   │           CreateUserJsonResponse.md
│   │           CreateUserRawResponse.md
│   │           CreateUsersWithListInputResponse.md
│   │           DeleteOrderRequest.md
│   │           DeleteOrderResponse.md
│   │           DeletePetRequest.md
│   │           DeletePetResponse.md
│   │           DeleteUserRequest.md
│   │           DeleteUserResponse.md
│   │           FindPetsByStatusRequest.md
│   │           FindPetsByStatusResponse.md
│   │           FindPetsByTagsRequest.md
│   │           FindPetsByTagsResponse.md
│   │           GetInventoryResponse.md
│   │           GetInventorySecurity.md
│   │           GetOrderByIdRequest.md
│   │           GetOrderByIdResponse.md
│   │           GetPetByIdRequest.md
│   │           GetPetByIdResponse.md
│   │           GetPetByIdSecurity.md
│   │           GetUserByNameRequest.md
│   │           GetUserByNameResponse.md
│   │           LoginUserRequest.md
│   │           LoginUserResponse.md
│   │           LogoutUserResponse.md
│   │           PlaceOrderFormResponse.md
│   │           PlaceOrderJsonResponse.md
│   │           PlaceOrderRawResponse.md
│   │           Status.md
│   │           UpdatePetFormResponse.md
│   │           UpdatePetJsonResponse.md
│   │           UpdatePetRawResponse.md
│   │           UpdatePetWithFormRequest.md
│   │           UpdatePetWithFormResponse.md
│   │           UpdateUserFormRequest.md
│   │           UpdateUserFormResponse.md
│   │           UpdateUserJsonRequest.md
│   │           UpdateUserJsonResponse.md
│   │           UpdateUserRawRequest.md
│   │           UpdateUserRawResponse.md
│   │           UploadFileRequest.md
│   │           UploadFileResponse.md
│   │
│   └───sdks
│       ├───pet
│       │       README.md
│       │
│       ├───sdk
│       │       README.md
│       │
│       ├───store
│       │       README.md
│       │
│       └───user
│               README.md
│
└───Openapi
    │   Openapi.csproj
    │   Pet.cs
    │   SDK.cs
    │   Store.cs
    │   User.cs
    │
    ├───Hooks
    │       HookRegistration.cs
    │       HookTypes.cs
    │       SDKHooks.cs
    │
    ├───Models
    │   ├───Components
    │   │       ApiResponse.cs
    │   │       Category.cs
    │   │       HTTPMetadata.cs
    │   │       Order.cs
    │   │       OrderStatus.cs
    │   │       Pet.cs
    │   │       Security.cs
    │   │       Status.cs
    │   │       Tag.cs
    │   │       User.cs
    │   │
    │   ├───Errors
    │   │       SDKException.cs
    │   │
    │   └───Requests
    │           AddPetFormResponse.cs
    │           AddPetJsonResponse.cs
    │           AddPetRawResponse.cs
    │           CreateUserFormResponse.cs
    │           CreateUserJsonResponse.cs
    │           CreateUserRawResponse.cs
    │           CreateUsersWithListInputResponse.cs
    │           DeleteOrderRequest.cs
    │           DeleteOrderResponse.cs
    │           DeletePetRequest.cs
    │           DeletePetResponse.cs
    │           DeleteUserRequest.cs
    │           DeleteUserResponse.cs
    │           FindPetsByStatusRequest.cs
    │           FindPetsByStatusResponse.cs
    │           FindPetsByTagsRequest.cs
    │           FindPetsByTagsResponse.cs
    │           GetInventoryResponse.cs
    │           GetInventorySecurity.cs
    │           GetOrderByIdRequest.cs
    │           GetOrderByIdResponse.cs
    │           GetPetByIdRequest.cs
    │           GetPetByIdResponse.cs
    │           GetPetByIdSecurity.cs
    │           GetUserByNameRequest.cs
    │           GetUserByNameResponse.cs
    │           LoginUserRequest.cs
    │           LoginUserResponse.cs
    │           LogoutUserResponse.cs
    │           PlaceOrderFormResponse.cs
    │           PlaceOrderJsonResponse.cs
    │           PlaceOrderRawResponse.cs
    │           Status.cs
    │           UpdatePetFormResponse.cs
    │           UpdatePetJsonResponse.cs
    │           UpdatePetRawResponse.cs
    │           UpdatePetWithFormRequest.cs
    │           UpdatePetWithFormResponse.cs
    │           UpdateUserFormRequest.cs
    │           UpdateUserFormResponse.cs
    │           UpdateUserJsonRequest.cs
    │           UpdateUserJsonResponse.cs
    │           UpdateUserRawRequest.cs
    │           UpdateUserRawResponse.cs
    │           UploadFileRequest.cs
    │           UploadFileResponse.cs
    │
    └───Utils
        │   AnyDeserializer.cs
        │   BigIntStrConverter.cs
        │   DecimalStrConverter.cs
        │   EnumConverter.cs
        │   FlexibleObjectDeserializer.cs
        │   HeaderSerializer.cs
        │   IsoDateTimeSerializer.cs
        │   RequestBodySerializer.cs
        │   ResponseBodyDeserializer.cs
        │   SecurityMetadata.cs
        │   SpeakeasyHttpClient.cs
        │   SpeakeasyMetadata.cs
        │   URLBuilder.cs
        │   Utilities.cs
        │
        └───Retries
                BackoffStrategy.cs
                Retries.cs
                RetryConfig.cs
```

The OpenAPI Generator SDK structure can be created with:

```bash
tree petstore-sdk-csharp-openapi
```

The results look like this:

```
petstore-sdk-csharp-openapi
│   .gitignore
│   .openapi-generator-ignore
│   appveyor.yml
│   git_push.sh
│   Org.OpenAPITools.sln
│   README.md
│
├───.openapi-generator
│       FILES
│       VERSION
│
├───api
│       openapi.yaml
│
├───docs
│       Address.md
│       ApiResponse.md
│       Category.md
│       Customer.md
│       Order.md
│       Pet.md
│       PetApi.md
│       StoreApi.md
│       Tag.md
│       User.md
│       UserApi.md
│
└───src
    ├───Org.OpenAPITools
    │   │   Org.OpenAPITools.csproj
    │   │
    │   ├───Api
    │   │       PetApi.cs
    │   │       StoreApi.cs
    │   │       UserApi.cs
    │   │
    │   ├───Client
    │   │   │   ApiClient.cs
    │   │   │   ApiException.cs
    │   │   │   ApiResponse.cs
    │   │   │   ClientUtils.cs
    │   │   │   Configuration.cs
    │   │   │   ExceptionFactory.cs
    │   │   │   GlobalConfiguration.cs
    │   │   │   HttpMethod.cs
    │   │   │   IApiAccessor.cs
    │   │   │   IAsynchronousClient.cs
    │   │   │   IReadableConfiguration.cs
    │   │   │   ISynchronousClient.cs
    │   │   │   Multimap.cs
    │   │   │   OpenAPIDateConverter.cs
    │   │   │   RequestOptions.cs
    │   │   │   RetryConfiguration.cs
    │   │   │
    │   │   └───Auth
    │   │           OAuthAuthenticator.cs
    │   │           OAuthFlow.cs
    │   │           TokenResponse.cs
    │   │
    │   └───Model
    │           AbstractOpenAPISchema.cs
    │           Address.cs
    │           ApiResponse.cs
    │           Category.cs
    │           Customer.cs
    │           Order.cs
    │           Pet.cs
    │           Tag.cs
    │           User.cs
    │
    └───Org.OpenAPITools.Test
        │   Org.OpenAPITools.Test.csproj
        │
        ├───Api
        │       PetApiTests.cs
        │       StoreApiTests.cs
        │       UserApiTests.cs
        │
        └───Model
                AddressTests.cs
                ApiResponseTests.cs
                CategoryTests.cs
                CustomerTests.cs
                OrderTests.cs
                PetTests.cs
                TagTests.cs
                UserTests.cs
```

The Speakeasy-created SDK contains more generated files than the SDK from OpenAPI Generator, which is partly due to the Speakeasy SDK being less dependent on third-party libraries.

## Model and usage

The Speakeasy SDK follows an object-oriented approach to constructing model objects, leveraging C# support for object initializers. Here's an example of creating and updating a `Pet` object:

```csharp
var sdk = new SDK();
var req = new Models.Components.Pet();
{
    Id = 10,
    Name = "doggie",
    Category = new Category()
    {
        Id = 1,
        Name = "Dogs"
    },
    PhotoUrls = new List<string>() { "<value>" }
};

var res = await sdk.Pet.UpdatePetJsonAsync(req);
```

The model classes are defined as structured and type-safe, using C# classes and properties. Object initializer syntax makes it convenient to instantiate and populate model objects.

The OpenAPI Generator SDK takes a similar approach to constructing model objects. Here's an example of adding a new `Pet` object:

```csharp
// Configure API client
var config = new Configuration();
config.BasePath = "/api/v3";

//  using traditional constructor
//  var photo = new List<string>() {
//             "https://hips.hearstapps.com/hmg-prod/images/dog-puppy-on-garden-royalty-free-image-1586966191.jpg?crop=1xw:0.74975xh;center,top&resize=1200:*"
//             };
//  var cat = new Category(10);
//  var pet = new Pet(10,"openApiDoggie",cat,photo);

// Create an instance of the API class using object initializer
var apiInstance = new PetApi(config);
try
{   
    var pet = new Pet();
    {
        Id = 10,
        Name = "openAPiDoggie",
        Category = new Category() { Id = 10 },
        PhotoUrls = new List<string>() {
            "https://hips.hearstapps.com/hmg-prod/images/dog-puppy-on-garden-royalty-free-image-1586966191.jpg?crop=1xw:0.74975xh;center,top&resize=1200:*"
        },
    };

    Pet result = apiInstance.AddPet(pet);
    Console.WriteLine(result.ToString());

}
catch (ApiException e)
{
    Debug.Print("Exception when calling PetApi.AddPet: " + e.Message);
    Debug.Print("Status Code: " + e.ErrorCode);
    Debug.Print(e.StackTrace);
}

```

Model classes are defined using constructors and property setters. While this approach is more verbose, it follows a more traditional style that may be familiar to developers coming from other backgrounds. Note that modern language features in .NET allow classes to be initialized using object initializers too, as shown in the example above.

In the Speakeasy SDK, the model object is instantiated and populated using an object initializer, providing a more concise and fluent syntax. The OpenAPI Generator SDK, on the other hand, makes use of constructors and individual property setters, making the code more verbose, but also allowing the use of object initializers.

Both SDKs provide mechanisms for handling exceptions and error cases when interacting with the API.

## JSON serialization and deserialization

The Speakeasy SDK uses attributes from the `Newtonsoft.Json` library for the JSON serialization and deserialization of objects.

```csharp
#nullable enable
namespace Openapi.Models.Components
{
    using Newtonsoft.Json;
    using Openapi.Models.Components;
    using Openapi.Utils;
    using System.Collections.Generic;

    public class Pet
    {
        [JsonProperty("id")]
        [SpeakeasyMetadata("form:name=id")]
        public long? Id { get; set; }

        [JsonProperty("name")]
        [SpeakeasyMetadata("form:name=name")]
        public string Name { get; set; } = default!;

        [JsonProperty("category")]
        [SpeakeasyMetadata("form:name=category,json")]
        public Category? Category { get; set; }

        [JsonProperty("photoUrls")]
        [SpeakeasyMetadata("form:name=photoUrls")]
        public List<string> PhotoUrls { get; set; } = default!;

        [JsonProperty("tags")]
        [SpeakeasyMetadata("form:name=tags,json")]
        public List<Tag>? Tags { get; set; }

        /// <summary>
        /// pet status in the store
        /// </summary>
        [JsonProperty("status")]
        [SpeakeasyMetadata("form:name=status")]
        public Models.Components.Status? Status { get; set; }
    }
}

```

The `JsonProperty` attribute is used to map class properties to their corresponding JSON fields. The `SpeakeasyMetadata` attribute is used to provide additional metadata for form encoding and other purposes.

By contrast, the OpenAPI Generator SDK uses the `Newtonsoft.Json.Converters` namespace for JSON serialization and deserialization:

```csharp
/// <summary>
/// Pet
/// </summary>
 [DataContract(Name = "Pet")]
 public partial class Pet : IValidatableObject
 {
    /// <summary>
    /// pet status in the store
    /// </summary>
    /// <value>pet status in the store</value>
    [JsonConverter(typeof(StringEnumConverter))]
    public enum StatusEnum
    {
        /// <summary>
        /// Enum Available for value: available
        /// </summary>
        [EnumMember(Value = "available")]
        Available = 1,
        /// <summary>
        /// Enum Pending for value: pending
        /// </summary>
        [EnumMember(Value = "pending")]
        Pending = 2,
        /// <summary>
        /// Enum Sold for value: sold
        /// </summary>
        [EnumMember(Value = "sold")]
        Sold = 3
    }

    /// <summary>
    /// pet status in the store
    /// </summary>
    /// <value>pet status in the store</value>
    [DataMember(Name = "status", EmitDefaultValue = false)]
    public StatusEnum? Status { get; set; }
    /// <summary>
    /// Initializes a new instance of the <see cref="Pet" /> class.
    /// </summary>
    [JsonConstructorAttribute]
    protected Pet() { }
    /// <summary>
    /// Initializes a new instance of the <see cref="Pet" /> class.
    /// </summary>
    /// <param name="id">id.</param>
    /// <param name="name">name (required).</param>
    /// <param name="category">category.</param>
    /// <param name="photoUrls">photoUrls (required).</param>
    /// <param name="tags">tags.</param>
    /// <param name="status">pet status in the store.</param>
        public Pet(long id = default(long), string name = default(string), Category category = default(Category), List<string> photoUrls = default(List<string>), List<Tag> tags = default(List<Tag>), StatusEnum? status = default(StatusEnum?))
        {
            // to ensure "name" is required (not null)
            if (name == null)
            {
                throw new ArgumentNullException("name is a required property for Pet and cannot be null");
            }

            this.Name = name;

            // to ensure "photoUrls" is required (not null)
            if (photoUrls == null)
            {
                throw new ArgumentNullException("photoUrls is a required property for Pet and cannot be null");
            }

            this.PhotoUrls = photoUrls;
            this.Id = id;
            this.Category = category;
            this.Tags = tags;
            this.Status = status;

        }

        /// <summary>
        /// Gets or Sets Id
        /// </summary>
        /// <example>10</example>
        [DataMember(Name = "id", EmitDefaultValue = false)]
        public long Id { get; set; }
        /// <summary>
        /// Gets or Sets Name
        /// </summary>
        /// <example>doggie</example>
        [DataMember(Name = "name", IsRequired = true, EmitDefaultValue = true)]
        public string Name { get; set; }
}
```


The OpenAPI Generator SDK attempts to use default values in the constructor to handle nullable types by forcing default values.

The `DataContract` and `DataMember` annotations from the `System.Runtime.Serialization` namespace specify which properties of a class should be included during serialization and deserialization.

While both SDKs use the `Newtonsoft.Json` library, the Speakeasy SDK takes a more straightforward approach by directly using the `JsonProperty` attribute. The OpenAPI Generator SDK relies on `DataContract` and `DataMember` for the process.

## Model implementation

The Speakeasy SDK uses a more modern approach to defining model classes. Here's the `Pet` class implementation:

```csharp
#nullable enable
namespace Openapi.Models.Components
{
    using Newtonsoft.Json;
    using Openapi.Utils;
    using System.Collections.Generic;

    public class Pet
    {
        [JsonProperty("id")]
        [SpeakeasyMetadata("form:name=id")]
        public long? Id { get; set; }

        [JsonProperty("name")]
        [SpeakeasyMetadata("form:name=name")]
        public string Name { get; set; } = default!;

        [JsonProperty("category")]
        [SpeakeasyMetadata("form:name=category,json")]
        public Category? Category { get; set; }

        [JsonProperty("photoUrls")]
        [SpeakeasyMetadata("form:name=photoUrls")]
        public List<string> PhotoUrls { get; set; } = default!;

        [JsonProperty("tags")]
        [SpeakeasyMetadata("form:name=tags,json")]
        public List<Tag>? Tags { get; set; }

        /// <summary>
        /// pet status in the store
        /// </summary>
        [JsonProperty("status")]
        [SpeakeasyMetadata("form:name=status")]
        public Models.Components.Status? Status { get; set; }
    }
}

```

The Speakeasy SDK model class definitions follow a property-based approach, using properties decorated with `JsonProperty` attributes for JSON serialization and deserialization, and `SpeakeasyMetadata` attributes for additional metadata.

Null safety is ensured by the `#nullable enable` directive, and nullable types like `long?` and non-null default values like `= default!` help to prevent unexpected `NullReferenceException` issues.

By contrast, the OpenAPI Generator SDK's `Pet` class has a more traditional implementation:

```csharp
/// <summary>
/// Pet
/// </summary>
[DataContract(Name = "Pet")]
public partial class Pet : IValidatableObject
{
 /// <summary>
 /// pet status in the store
 /// </summary>
 /// <value>pet status in the store</value>

    [JsonConverter(typeof(StringEnumConverter))]
    public enum StatusEnum
    {
    /// <summary>
    /// Enum Available for value: available
    /// </summary>
    [EnumMember(Value = "available")]
    Available = 1,
    }

    /// <summary>
    /// pet status in the store
    /// </summary>
    /// <value>pet status in the store</value>
    [DataMember(Name = "status", EmitDefaultValue = false)]
    public StatusEnum? Status { get; set; }

    public Pet(long id = default(long), string name = default(string), Category category = default(Category), List<string> photoUrls = default(List<string>), List<Tag> tags = default(List<Tag>), StatusEnum? status = default(StatusEnum?))
    {
        // to ensure "name" is required (not null)
        if (name == null)
        {
            throw new ArgumentNullException("name is a required property for Pet and cannot be null");
        }
        this.Name = name;

        // to ensure "photoUrls" is required (not null)
        if (photoUrls == null)
        {
            throw new ArgumentNullException("photoUrls is a required property for Pet and cannot be null");
        }

        this.PhotoUrls = photoUrls;
        this.Id = id;
        this.Category = category;
        this.Tags = tags;
        this.Status = status;
    }

    /// <summary>
    /// Returns the JSON string presentation of the object
    /// </summary>
    /// <returns>JSON string presentation of the object</returns>
    public virtual string ToJson()
    {
        return Newtonsoft.Json.JsonConvert.SerializeObject(this, Newtonsoft.Json.Formatting.Indented);
    }

    /// <summary>
    /// To validate all properties of the instance
    /// </summary>
    /// <param name="validationContext">Validation context</param>
    /// <returns>Validation Result</returns>

    IEnumerable<System.ComponentModel.DataAnnotations.ValidationResult> IValidatableObject.Validate(ValidationContext validationContext)
    {
        yield break;
    }
}
```

The OpenAPI Generator SDK uses data contracts and attributes from the `System.Runtime.Serialization` namespace for serialization and deserialization, and includes additional `ToString()`, `ToJson()`, and `Validate()` methods. The `StatusEnum` property is implemented as a separate enum, which adds complexity to the model class.

The Speakeasy SDK model implementation is more concise and follows a modern and idiomatic approach to defining C# classes. The OpenAPI Generator SDK model implementation is more verbose and includes traditional features like validation and string representation methods.

## HTTP communication

The Speakeasy SDK handles HTTP communication using the `System.Net.Http` namespace, which is part of the .NET Base Class Library (BCL).

Here's an example of the `AddPetJsonAsync` method from the `Pet` class:

```csharp
public async Task<AddPetJsonResponse> AddPetJsonAsync(Models.Components.Pet request)
{
    string baseUrl = this.SDKConfiguration.GetTemplatedServerUrl();
    var urlString = baseUrl + "/pet";

    var httpRequest = new HttpRequestMessage(HttpMethod.Post, urlString);
    httpRequest.Headers.Add("user-agent", _userAgent);

    var serializedBody = RequestBodySerializer.Serialize(request, "Request", "json", false, false);

    if (serializedBody != null)
    {
        httpRequest.Content = serializedBody;
    }

    HttpResponseMessage httpResponse;
    try
    {
        httpResponse = await _client.SendAsync(httpRequest);
        // ... (handle response and exceptions)
    }
    catch (Exception error)
    {
     // ... (handle exceptions)
    }
    // ... (additional processing and return response)
}
```

The `AddPetJsonAsync` method constructs a `HttpRequestMessage` object with the appropriate method and URL. It then serializes the request body, sets the necessary headers, and applies security and hooks. It sends the request using the `SendAsync` method, which returns an `HttpResponseMessage`.

The OpenAPI Generator SDK has a more complicated approach to HTTP communication, defining several custom classes and types to manage the process. Ultimately, it relies on the `RestSharp` library and `RestSharp.Serializers` for executing the HTTP requests and handling serialization.

Here's the `AddPetAsync` method from the `PetApi` class:

```csharp
public async System.Threading.Tasks.Task<Pet> AddPetAsync(Pet pet, int operationIndex = 0, System.Threading.CancellationToken cancellationToken = default(System.Threading.CancellationToken))
{
    Org.OpenAPITools.Client.ApiResponse<Pet> localVarResponse = await AddPetWithHttpInfoAsync(pet, operationIndex, cancellationToken).ConfigureAwait(false);
    return localVarResponse.Data;
}
```

The `AddPetAsync` method calls the `AddPetWithHttpInfoAsync` method, which handles the HTTP communication details. To make the HTTP request and process the response, the SDK uses a custom `AsynchronousClient` class, which internally uses the third-party `RestSharp` library for HTTPS communication.

Both SDKs leverage async/await for asynchronous operations, but the Speakeasy SDK takes advantage of the built-in `System.Net.Http` namespace in .NET, providing a more integrated and efficient approach to HTTP communication. The custom HTTP communication implementation of the OpenAPI Generator SDK depends on a third-party library, which brings additional maintenance and compatibility considerations.

## Retries

The Speakeasy SDK provides built-in support for automatically retrying failed requests. You can configure retries globally or on a per-request basis using the `x-speakeasy-retries` extension in your OpenAPI specification document.

Here's how the `AddPetJsonAsync` method handles retries:

```csharp
public async Task<AddPetJsonResponse> AddPetJsonAsync(Models.Components.Pet request, RetryConfig? retryConfig = null)
{
    if (retryConfig == null)
    {
        if (this.SDKConfiguration.RetryConfig != null)
        {
            retryConfig = this.SDKConfiguration.RetryConfig;
        }
        else
        {
            var backoff = new BackoffStrategy(
                initialIntervalMs: 500L,
                maxIntervalMs: 60000L,
                maxElapsedTimeMs: 3600000L,
                exponent: 1.5
             );

            retryConfig = new RetryConfig(
                strategy: RetryConfig.RetryStrategy.BACKOFF,
                backoff: backoff,
                retryConnectionErrors: true
            );
        }
    }
    List<string> statusCodes = new List<string>
    {
        "5XX",
    };

    Func<Task<HttpResponseMessage>> retrySend = async () =>
    {
        var _httpRequest = await _client.CloneAsync(httpRequest);
        return await _client.SendAsync(_httpRequest);
    };

    var retries = new Openapi.Utils.Retries.Retries(retrySend, retryConfig, statusCodes);

    HttpResponseMessage httpResponse;
    try
    {
        httpResponse = await retries.Run();
         // ... (handle response and exceptions)
    }
    catch (Exception error)
    {
        // ... (handle exceptions)
    }

    // ... (additional processing and return response)
}

```

If no `RetryConfig` is provided, the method checks for a global `RetryConfig` in the `SDKConfiguration`. If no global `RetryConfig` is found, a default `BackoffStrategy` is created with values for initial interval, maximum interval, maximum elapsed time, and exponential backoff factor.

The `retrySend` function clones the original `HttpRequestMessage` prior to sending. This prevents it from being consumed by the `SendAsync` method, enabling subsequent resends.

An instance of the `Retries` class is created, taking the `retrySend` function, `retryConfig`, and status codes as arguments.

The `retries.Run()` method is then called to handle the entire retry logic and it returns the final `HttpResponseMessage`.

Various retry strategies, like backoff or fixed interval, are supported and most options are configurable. The `x-speakeasy-retries` extension can be used in an OpenAPI specification file to configure retries for specific operations or globally.

For more information on configuring retries in your SDK, take a look at the [retries documentation](/docs/customize-sdks/retries).

The OpenAPI Generator SDK does not provide built-in support for automatic retries, and you would need to implement this functionality manually or by using a third-party library.

### SDK dependencies

The Speakeasy SDK has the following external dependencies:

```xml
<PackageReference Include="Newtonsoft.Json" Version="13.0.3" />
<PackageReference Include="NodaTime" Version="3.1.9" />
```

- **Newtonsoft.Json:** A JSON framework for .NET used for JSON serialization and deserialization.
- **Noda Time:** A date and time API for .NET, providing a better implementation than the built-in `System.DateTime` components.

The OpenAPI Generator SDK has the following external dependencies:

- **JsonSubTypes:** A library used for handling JSON polymorphism, useful for dealing with inheritance hierarchies in JSON data.
- **Newtonsoft.Json:** a JSON framework for .NET, which is used for JSON serialization and deserialization in the SDK.
- **RestSharp:** A library for consuming RESTful web services in .NET, used for making HTTP requests and handling responses.
- **Polly:** A .NET resilience and transient-fault-handling library that allows developers to express policies such as Retry, Circuit Breaker, Timeout, Bulkhead Isolation, and Fallback in a fluent and thread-safe way.

The OpenAPI Generator SDK project file includes a reference to the `System.Web` assembly, which is part of the .NET Framework and provides classes for building web applications.

While both SDKs use the Newtonsoft.Json library for JSON handling, the Speakeasy SDK has a more minimalistic approach to dependencies and only includes the `NodaTime` library for date and time handling. The OpenAPI Generator SDK includes additional dependencies like `RestSharp` for HTTP communication, `JsonSubTypes` for JSON polymorphism, and `Polly` for resilience and fault handling.

The more dependencies an SDK has, the more prone it is to compatibility issues with new releases and internal complexity, making maintenance and enhancement more difficult.

## Handling non-nullable fields

Let's compare how the two SDKs handle non-nullable fields using the provided code snippets for the `Status` field and enum.

In the Speakeasy SDK the `Status` field is defined as follows:

```csharp
/// <summary>
/// pet status in the store
/// </summary>
[JsonProperty("status")]
[SpeakeasyMetadata("form:name=status")]
public Models.Components.Status? Status { get; set; }

```


The `Status` property is of type `Models.Components.Status?`, which is a nullable enum type. The `?` after the type name indicates that the property can be assigned a `null` value.

The `Status` enum is defined as follows:

```csharp

public enum Status
{
    [JsonProperty("available")]
    Available,

    [JsonProperty("pending")]
    Pending,

    [JsonProperty("sold")]
    Sold

}
```

The enum members are decorated with the `JsonProperty` attribute, which specifies the JSON property name for each member.

In the OpenAPI Generator SDK, the `Status` field is defined as follows:

```csharp
/// <summary>
/// pet status in the store
/// </summary>
/// <value>pet status in the store</value>
[DataMember(Name = "status", EmitDefaultValue = false)]
public StatusEnum? Status { get; set; }
```


The `Status` property is of type `StatusEnum?`, which is a nullable enum type.


The `StatusEnum` is defined as follows:

```csharp
/// <summary>
/// pet status in the store
/// </summary>
/// <value>pet status in the store</value>
[JsonConverter(typeof(StringEnumConverter))]
public enum StatusEnum
{
    /// <summary>
    /// Enum Available for value: available
    /// </summary>
    [EnumMember(Value = "available")]
    Available = 1,

    /// <summary>
    /// Enum Pending for value: pending
    /// </summary>
    [EnumMember(Value = "pending")]
    Pending = 2,

    /// <summary>
    /// Enum Sold for value: sold
    /// </summary>
    [EnumMember(Value = "sold")]
    Sold = 3
}
```

The `StatusEnum` is decorated with the `JsonConverter` attribute, which specifies that the `StringEnumConverter` should be used for JSON serialization and deserialization. The enum members are decorated with the `EnumMember` attribute, which specifies the JSON value for each member.

Both SDKs handle non-nullable fields similarly by using nullable types (`Status?` and `StatusEnum?`), allowing the SDK to accommodate scenarios where the API response may not include a value for the `Status` field.

The SDKs differ in how the enums are defined and decorated with attributes for JSON serialization and deserialization:

- The Speakeasy SDK uses the `JsonProperty` attribute directly on the enum members to specify the JSON property name.
- The OpenAPI Generator SDK uses the `JsonConverter` and `EnumMember` attributes to handle JSON serialization and deserialization for the enum.

The same goal is achieved in both cases, but the Speakeasy approach is more straightforward, as it directly maps the enum members to the corresponding JSON property names.

Let's look at how the two SDKs handle this when passing a null value to the `FindPetsByStatus` method.

When you run the following code from the Speakeasy SDK:

```csharp
try
{
    var res = await sdk.Pet.FindPetsByStatusAsync(null);
    if (res.Body != null)
    {
        //handle response
     }
}
catch (Exception ex)
{
    Console.WriteLine(ex.Message + "\\n" + ex.StackTrace);
}
```

The Speakeasy SDK throws an exception with the following output:

```
API error occurred
at Openapi.Pet.FindPetsByStatusAsync(Nullable`1 status) in C:\Users\devi\Documents\git\speak-easy\sdks\petstore-sdk-csharp-speakeasy\Openapi\Pet.cs:line 852
at Program.<Main>$(String[] args) in C:\Users\devi\Documents\git\speak-easy\sdks\petstore-sdk-csharp-speakeasy\conSpeakEasyTester\Program.cs:line 11
```

The Speakeasy SDK throws an `SDKException` with the message "API error occurred" when encountering an error during the API call. It also includes the stack trace, which can be helpful for debugging purposes.

When you run the following code from the OpenAPI Generator SDK:

```csharp
try
{
    // Add a new pet to the store
    // Pet result = apiInstance.AddPet(pet);
    var res = apiInstance.FindPetsByStatus(null);
    Debug.WriteLine(res);

}
catch (ApiException e)
{
    Console.WriteLine("Exception when calling PetApi.AddPet: " + e.Message);
    Console.WriteLine("Status Code: " + e.ErrorCode);
    Console.WriteLine(e.StackTrace);
}
```

The OpenAPI Generator SDK throws an `ApiException` with the following output:

```
Org.OpenAPITools.Client.ApiException: 'Error calling FindPetsByStatus: No status provided. Try again?'
```

The OpenAPI Generator SDK throws an `ApiException` with a more descriptive error message, but it does not include the stack trace by default.

Both SDKs handle the null value scenario by throwing an exception, which is a reasonable approach to prevent invalid data from being passed to the API.

The Speakeasy SDK throws a more generic "API error occurred" exception but provides the stack trace, which can be helpful for debugging. The OpenAPI Generator SDK throws a more descriptive `ApiException` with a customized error message, but it does not include the stack trace by default.

Let's see what happens when we pass an empty name field to the SDKs.

If we remove the name field from the class initialization or even set it to `null`, the Speakeasy SDK doesn't throw an error and creates a pet object with empty or null values provided.

To show the details of the pet object created, let's add a method to the `Pet` model class in `sdks\OpenApi\Models\Components\Pet.cs`:

```csharp
  public override string ToString()
 {
      string categoryString = Category != null ? Category.ToString() : "null";
      string photoUrlsString = PhotoUrls != null ? string.Join(", ", PhotoUrls) : "null";

      string tagsString = Tags != null ? string.Join(", ", Tags) : "null";
      string statusString = Status != null ? Status.ToString() : "null";

      return $"Pet:\n" +
             $"  Id: {Id}\n" +
             $"  Name: {Name}\n" +
             $"  Category: {categoryString}\n" +
             $"  PhotoUrls: {photoUrlsString}\n" +
             $"  Tags: {tagsString}\n" +
             $"  Status: {statusString}";
 }
```

Now if you run the following code:

```csharp
    var req = new Openapi.Models.Components.Pet()
    {
        Id = 10,
        Name = null,
        Category = new Category()
        {
            Id = 1
        },
        PhotoUrls = new List<string>()
        {
            "https://hips.hearstapps.com/hmg-prod/images/dog-puppy-on-garden-royalty-free-image-1586966191.jpg?crop=1xw:0.74975xh;center,top&resize=1200:*"
        },
    };

    Console.WriteLine(req.ToString());
```

You get the following result, showing that the pet object was created without a value for the `Name` field:

```
Pet:
  Id: 10
  Name:
  Category: Openapi.Models.Components.Category
  PhotoUrls: https://hips.hearstapps.com/hmg-prod/images/dog-puppy-on-garden-royalty-free-image-1586966191.jpg?crop=1xw:0.74975xh;center,top&resize=1200:*
  Tags: null
  Status: null
```

Let's do the same with the OpenAPI Generator SDK:

```csharp
    var pet = new Pet() 
    {
        Id = 10,
        Name = null,
        Category = new Category() { Id = 10 },
        PhotoUrls = new List<string>() {
            "https://hips.hearstapps.com/hmg-prod/images/dog-puppy-on-garden-royalty-free-image-1586966191.jpg?crop=1xw:0.74975xh;center,top&resize=1200:*"
        },
 };

    Pet result = apiInstance.AddPet(pet);
    Console.WriteLine(result.ToString());
```

The OpenAPI Generator SDK throws an `ArgumentNullException` error with a more descriptive error message:

```
    System.ArgumentNullException: 'Value cannot be null. (Parameter 'name is a required property for Pet and cannot be null')'
```

It appears that the error is thrown from the model class directly, so we cannot continue with bad data.

In this case, the OpenAPI Generator SDK handled the null or empty values better than the Speakeasy SDK when creating a Pet. The Speakeasy SDK allows you to create the pet with empty name values, a small issue that can be handled in development, but worth taking note of.

## Generated documentation

Both Speakeasy and OpenAPI Generator create SDK documentation for generated code.

The OpenAPI Generator README outlines the SDK dependencies and supported frameworks, provides steps for getting started (including installing dependencies and building the project in various operating systems), and describes available API routes. The Speakeasy README also provides API routes and includes more detailed getting-started examples.

OpenAPI Generator generates some documentation in a docs directory, but it is not very detailed.

Additional documentation generated by Speakeasy includes more detailed explanations of the models and operations; examples of creating, updating, and searching objects; error handling; and guidance on handling exceptions specific to the OpenAPI specification file.

Some default test cases are created for both but are only for guidance.

## Supported .NET versions

The Speakeasy-generated SDK supports .NET 5.+ environments. We successfully tested it with .NET 6.

The SDK generated by OpenAPI Generator claims to support a range of versions, including .NET Framework 4.7, .NET Standard 1.3-2.1, and .NET 6 and later. We targeted .NET 6 to ensure we have the same language features available in both SDKs.

Although more versions are supported in the OpenAPI Generator, .NET 5+ is the modern stack and will be used more in new developments.

## Summary

Compared to the SDK generated by OpenAPI Generator, the Speakeasy-generated SDK is lightweight, concise, and idiomatic, with a modern approach to model implementation and built-in retry support. The Speakeasy generator uses modern techniques that follow best practices, and the Speakeasy documentation makes it easy to get started.

If you are building an API that developers rely on and would like to publish full-featured SDKs that follow best practices, give the Speakeasy SDK generator a try.

[Join our Slack community](https://join.slack.com/t/speakeasy-dev/shared_invite/zt-1cwb3flxz-lS5SyZxAsF_3NOq5xc8Cjw) to let us know how we can improve our C# SDK generator or suggest features.


 This is the content for the doc docs/languages/golang/feature-support.mdx 

 ---
title: "Go Feature Reference"
description: "An overview of Go features supported by Speakeasy for SDK generation from an OpenAPI / Swagger spec."
---

# Go Feature Reference

## Authentication

|    Name    | Support |  Docs  |   Notes |
|------------|:---:|------------------|---------|
| HTTP Basic |   ✅    |     Docs         |         |
| API Key <br /> (bearer, header, cookie, query) |   ✅    |     Docs         |         |
| OAuth <br /> implicit flow |   ✅    |     Docs         |         |
| OAuth <br /> refresh token flow |   🏗️ Partial    |     Docs         |         |
| OAuth <br /> client credentials flow |   🏗️ Partial    |     Docs         |         |
| mTLS |   🏗️ Partial    |     Docs         |         |

## Server Configuration

|       Name     | Support |  Docs  |   Notes |
|----------------|:-------:|--------------|--------|
| URL Templating |    ✅    | [defining `variables`](/docs/customize-sdks/servers#use-templated-urls) |  |
| Multiple server|    ✅    | [`x-speakeasy-server-id` extension](/docs/customize-sdks/servers#declare-multiple-servers) |  |
| Describe server <br /> outside your spec  | ✅    | [`serverUrl` config](/docs/customize-sdks/servers#declare-base-server-url) |  |

## Data Types

### Basic Types

| Name | Support |  Docs  |   Notes |
|------|:-------:|--------------|--------|
| Numbers |    ✅    | [data-types](https://swagger.io/docs/specification/data-models/data-types/#numbers) | `float`, `double`, `int32`, `int64` |
| Strings |    ✅    | [data-types](https://swagger.io/docs/specification/data-models/data-types/#strings) |  |
| Date Time |    ✅    | [data-types](https://swagger.io/docs/specification/data-models/data-types/#date-time) |  |
| Boolean |    ✅    | [data-types](https://swagger.io/docs/specification/data-models/data-types/#booleans) |  |
| Binary |    ✅    | [data-types](https://swagger.io/docs/specification/data-models/data-types/#binary) |  |
| Enums |    ✅    | [data-types](https://swagger.io/docs/specification/data-models/data-types/#enumerations) |  |
| Arrays |    ✅    | [data-types](https://swagger.io/docs/specification/data-models/data-types/#arrays) |  |
| Maps |    ✅    | [data-types](https://swagger.io/docs/specification/data-models/data-types/#maps) |  |
| Objects |    ✅    | [data-types](https://swagger.io/docs/specification/data-models/data-types/#objects) |  |
| Any |    ✅    | [data-types](https://swagger.io/docs/specification/data-models/data-types/#any) |  |
| Null |    ✅    | [data-types](https://swagger.io/docs/specification/data-models/data-types/#nil) |  |

### Polymorphism

| Name | Support |  Docs  |   Notes |
|------|:-------:|--------------|--------|
| Union Types |    ✅    | [Using `oneOf`](https://swagger.io/docs/specification/data-models/oneof-anyof-allof-not/#oneof) | `anyOf` is treated as `oneOf` and will create a union type object. |
| Intersection Types |   🏗️ Partial     | [Using `allOf`](https://swagger.io/docs/specification/data-models/oneof-anyof-allof-not/#allof) |  |


## Methods

|     Name    | Support |  Docs  |   Notes |
|-------------|:-------:|--------------|--------|
| Namespacing |    ✅    | [grouping operations](/docs/customize-sdks/namespaces) |  |
| Multi-level Namespacing |    ✅    | [multi-level grouping](/docs/customize-sdks/namespaces#define-multi-level-namespaces) |  |
| Custom naming|    ✅    | [`x-speakeasy-name-override` extension](/docs/customize-sdks/methods#change-method-names) |  |
| Exclude Methods |    ✅    | [`x-speakeasy-ignore` extension](/docs/customize-sdks/methods#exclude-methods-from-sdk) |  |
| Deprecation |    ✅    | the [`deprecate` flag](/docs/customize-sdks/methods#deprecate-methods) |  |

## Parameters

|     Name    | Support |  Docs  |   Notes |
|-------------|:-------:|--------------|--------|
| Pass Inline |    ✅    | [flattening parameters](/docs/customize-sdks/methods#configuring-method-signatures) |  |
| Pass via Request Object |    ✅    | [request object](/docs/customize-sdks/methods#configuring-method-signatures) |  |
| Exclude Parameters |    ✅    | [`x-speakeasy-ignore` extension](/docs/customize-sdks/methods#exclude-parameters-from-signatures) |  |
| Deprecate Parameters |    ✅    | the [`deprecate` flag](/docs/customize-sdks/deprecations#deprecate-parameters) |  |
| Define globally |    ✅    | [global parameters](/docs/customize-sdks/globals) |  |

### Path Parameters Serialization

|     Name    | Support |  Docs  |   Notes |
|-------------|:-------:|--------------|--------|
| Default <br /> `(style = simple, explode = false)` |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#path/) |  |
| Basic types |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#path/) |  |
| Simple objects |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#path/) |  |
| `label` & `matrix` |    ❌    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#path/) |  |

### Query Parameters Serialization

|     Name    | Support |  Docs  |   Notes |
|-------------|:-------:|--------------|--------|
| `json` |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#query/) |  |
| `form` |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#query/) |  |
| `spaceDelimited` |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#query/) |  |
| `pipeDelimited` |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#query/) |  |
| `deepObject` |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#query/) |  |
| Basic types |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#query/) |  |
| Simple objects |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#query/) |  |

## Requests

|     Name    | Support |  Docs  |   Notes |
|-------------|:-------:|--------------|--------|
| Request headers |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#header/) |  |
| Request retries |    ✅    | [retries](/docs/customize-sdks/retries) |  |
| `json` |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#request-body/) | Both `application/json` and `text/json`  |
| form data |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#request-body/) |  |
| binary |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#request-body/) |  |
| raw byte |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#request-body/) |  |
| plain text |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#request-body/) |  |
| `x-www-form-urlencoded` |    🏗️ Partial    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#request-body/) | Including encoding, but not non-object types |
| XML |    ❌    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#request-body/) |  |
| Other media types |    ❌    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#request-body/) |  |

## Responses

|     Name    | Support |  Docs  |   Notes |
|-------------|:-------:|--------------|--------|
| Pagination |    ✅    | [`x-speakeasy-pagination` extension](/docs/customize-sdks/pagination) |  |
| Custom Errors |    ✅    | [`x-speakeasy-errors` extension](/docs/customize-sdks/errors) |  |
| json |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#response/) |  |
| plain text |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#response/) |  |
| binary |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#response/) |  |
| raw byte |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#response/) |  |
| XML |    ❌    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#response/) |  |
| Other media types   |    ❌    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#response/) |  |

## Documentation

|     Name    | Support |  Docs  |   Notes |
|-------------|:-------:|--------------|--------|
|  `README` generation |    ✅    | [README generation](/docs/customize-sdks/sdk-docs) |  |
|  Usage Snippet generation |    ✅    | [snippet generation](/docs/customize-sdks/sdk-docs#usage-examples) |  |
|  Documentation generation |    ✅    | [documentation generation](/docs/customize-sdks/sdk-docs) |  |


 This is the content for the doc docs/languages/golang/methodology-go.mdx 

 ---
title: "Create Go SDKs From OpenAPI / Swagger"
description: "Speakeasy-created Go SDKs are generated from OpenAPI / Swagger specs and prioritize minimal dependencies, type safety, and easy debugging."
---

# Create Go SDKs From OpenAPI (Swagger)

## SDK Overview

Speakeasy's Go SDK is designed to build idiomatic Go modules and uses language-standard features. The SDK is backward compatible, requiring only Go 1.14, and will work with all newer compilers.

The SDK is strongly typed, makes minimal use of third-party modules, and is straightforward to debug. 

Speakeasy-generated SDKs should feel familiar to Go developers. Some of the Speakeasy Go SDK design choices are opinionated in a thoughtful and deliberate way. For example, many Go developers prefer to rely on zero values rather than pointers for unset optional values. However, as many REST APIs have nuanced distinctions between zero and null values, this approach is not generally practical for interoperability. To balance this, Speakeasy-created Go SDKs use pointers but include `nil`-safe getters to help offset the increased risk of panics caused by mishandled pointers.

Core features of the Speakeasy Go SDK include:

- Struct field tags and reflection-based marshaling and unmarshaling of data.
- Pointers used for optional fields.
- Automatic getters that provide `nil`-safety and hooks for building interfaces.
- Context-aware method calls for programmatic timeouts and cancelation.
- A `utils` package that segments off common operations, making generated code easier to follow and understand.
- Variadic options functions are provided to simplify the construction process, whether you have many options or none.
- Authentication support for OAuth flows and standard security mechanisms like HTTP Basic and application tokens.
- Optional pagination support for supported APIs.
- Optional support for retries in every operation.
- Complex number types
  - `"github.com/ericlager/decimal".Big`
  - `"math/big".Int`
- Date and time types using RFC 3339 formats.
- Custom type enums using strings and ints.
- Union types and combined types.

The SDK includes minimal dependencies. The only third-party dependencies are:

- `github.com/ericlagergren/decimal` - providing big decimal support features.
- `github.com/cenkalti/backoff/v4` - implementing automatic retry support.
- `github.com/spyzhov/ajson` - to help implement pagination.

## Go Package Structure

```yaml lib-structure.yaml
|-- go.mod             # part of the standard go mod setup
|-- go.sum             # part of the standard go mod setup
|-- sdk.go             # defines the root SDK package and the generate SDK class and New() constructor
|-- ...                # Other SDK classes
|-- pkg                # Root for all additional provided packages
|   └-- models         # Namespace for the SDK's models
|   |   └-- operations # Namespace for the SDK's operations models, including request/response models for each API
|   |   |   └-- ...
|   |   └-- shared     # Namespace for the SDK's shared models, including those from OpenAPI components
|   |       └-- ...
|   |-- types          # Namespace for additional helper types used during marshaling and unmarshaling
|   |   └-- ...
|   └-- utils          # Namespace for utility classes and functions
|-- docs               # Markdown files for the SDK's documentation
|   └- ...
└-- ...
```

## HTTP Client

The Go SDK makes API calls that wrap an internal HTTP client. The requirements for the HTTP client are simple. It must match this interface:

```go
type HTTPClient interface {
	Do(req *http.Request) (*http.Response, error)
}
```

The built-in `net/http` client satisfies this interface and a default client based on the built-in is provided by default. To replace this default with a client of your own, you can implement this interface yourself or provide your own client configured as desired. Here's a simple example that adds a client with a 30-second timeout.

```go
import (
	"net/http"
	"time"
	"github.com/myorg/your-go-sdk"
)

var (
	httpClient = &http.Client{Timeout: 30 * time.Second}
	sdkClient  = sdk.New(sdk.WithClient(httpClient))
)
````

This can be a convenient way to configure timeouts, cookies, proxies, custom headers, and other low-level configuration.

## Go Client Data Types and Enums

The Speakeasy Go SDK has a strong preference for familiar built-in types. Because the Go language has a rich built-in type system, the Speakeasy Go SDK relies almost completely on it. Here is a list of types the SDK uses:

- `string`
- `time.Time`
- `int`
- `int64`
- `big.Int`
- `float32`
- `float64`
- `bool`


Speakeasy provides a few custom types in the `types` package, which aid with marshaling and unmarshaling data exchanged with the server-side API. For example, `types.Date` is a thin wrapper around `time.Time` that can decode and encode dates in the `"2006-01-02"` format.

Speakeasy also uses the `decimal.Big` class provided by `github.com/ericlagergren/decimal`. This is a better alternative to `big.Float`, as it provides high-precision floating point math that avoids the rounding errors that can sometimes occur with `big.Float`.

## Pointer Types for Optional Fields

When a field is optional or nullable in OpenAPI, Speakeasy uses pointer types in Go to represent these fields. This design choice allows for a clear distinction between unset values (nil) and zero values. For example:

```go
type Pet struct {
    Name   string  `json:"name"`    // required field
    ChipID *string `json:"chip_id"` // optional/nullable field
}
```

When serializing a Pet struct to JSON, a nil pointer will be correctly represented as `null`:
```go
pet := Pet{Name: "Finn"} // ChipID is nil
// Serializes to: {"name": "Finn", "chip_id": null}
```

To make working with pointer types more ergonomic, Speakeasy provides helper functions:

```go
// Helper function for string pointers
func String(s string) *string { return &s }

// Generic helper for any type
func Pointer[T any](v T) *T { return &v }
```

These helpers allow for cleaner initialization of structs with pointer fields:
```go
pet := Pet{
    Name:   "Finn",
    ChipID: Pointer("173105fe2"),
}
```

This approach eliminates the need for temporary variables when setting pointer fields while maintaining type safety and proper null handling.

Enumeration types are built according to typical Go practices. Speakeasy defines a type alias to `string`, `int`, or `int64` as appropriate. Constants of this type are defined for the predefined values. Note that these are true type aliases (using `type X = string`) rather than new types (using `type X string`), meaning they are interchangeable with their underlying types.

## Go SDK Generated Classes

The Go SDK generates a `struct` for each request and response object and each component object. All fields in the `struct` objects are public. Optional fields are given pointer types and may be set to `nil`. A getter method is also defined for each public field. The `Get` prefix distinguishes the getters from the public field names, which remain directly accessible. The getters work correctly even when called on a `nil` value, in which case they return the zero value of the field.

For example, the following code shows a nested component object where the inner object is optional, ensuring safety from `nil` pointer-related panics.

```go
var outer *shared.Outer
var safe string = outer.GetInner().GetName()
if safe == "" {
  fmt.Println("Don't Panic")
}
// output: Don't Panic
```

The getters also provide useful hooks for defining interfaces.

## Parameters

As described above, the Speakeasy SDK will generate a class with public fields for each request and response object. Each field will be tagged to control marshaling and unmarshaling into other data formats while interacting with the underlying API. However, if the `maxMethodParams` value is set in `gen.yaml`, the generated struct will be limited to that number of parameters. These parameters will be positioned in the operation method after the context object and before the request object.

```go
// maxMethodParams: 1
res, err := sdk.GetDrink(ctx, "Sangria")
if err != nil {
	return err
}

// work with res...
```

Compare this with the example in the next section where `maxMethodParams` is `0`.

## Errors

Following Go best practices, all operation methods in the Speakeasy SDK will return a response object and an error. Callers should always check for the presence of the error. The object used for errors is configurable per request. Any error response may return a custom error object. A generic error will be provided when any communication failure is detected during an operation.

Here's an example of custom error handling in a theoretical SDK:

```go
longTea := operations.GetDrinkRequest{Name: "Long Island Iced Tea"}
res, err := sdk.GetDrink(ctx, &longTea)
var apiErr sdkerrors.APIError
if errors.As(err, &apiErr) {
    return fmt.Errorf("failed to get drink (%d): %s", apiErr.GetCode(), apiErr.GetMessage())
} else if err != nil {
    return fmt.Errorf("unknown error getting drink: %w", err)
}

// work with res...
```

## User Agent Strings

The Go SDK will include a [user agent](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/User-Agent) string in all requests. This can be leveraged to track SDK usage amongst broader API usage. The format is as follows: 

```stmpl
speakeasy-sdk/go {{SDKVersion}} {{GenVersion}} {{DocVersion}} {{PackageName}}
```


- `SDKVersion` is the version of the SDK, defined in `gen.yaml` and released.
- `GenVersion` is the version of the Speakeasy generator.
- `DocVersion` is the version of the OpenAPI document.
- `PackageName` is the name of the package defined in `gen.yaml`.


 This is the content for the doc docs/languages/golang/oss-comparison-go.mdx 

 ---
title: "Comparison guide: OpenAPI/Swagger Go client generation"
description: "Comparing the new Speakeasy Go SDK generator with the most popular open source OpenAPI Go generators"
keywords: [api, openapi, swagger, sdk generation, go, golang, sdk, developer experience, devex, dx]
---

# Comparison guide: OpenAPI/Swagger Go client generation

Speakeasy generates idiomatic Go SDKs based on OpenAPI specifications.

In this post, we'll take a look at why many of our users choose to switch from OpenAPI Generate and other open-source generators to Speakeasy to generate their Go SDKs.

Open-source SDK generators play an important role in experimentation and smaller custom integrations but we believe that teams should publish high-quality SDKs for their APIs that offer the best developer experience. Usable SDKs drive adoption by making it easier for developers to switch to your API.

At Speakeasy, we generate idiomatic client SDKs in a variety of languages. Our generators follow principles that ensure we generate SDKs that offer the best developer experience so that you can focus on building your API, and your developer-users can focus on delighting their users.

## Go SDK generator options

We'll compare four Go SDK generators:

1.  The [Go generator](https://openapi-generator.tech/docs/generators/go/) from the [OpenAPI Generator](https://openapi-generator.tech/) project.
2.  [oapi-codegen](https://github.com/oapi-codegen/oapi-codegen), an open-source OpenAPI Client and Server Code Generator.
3.  [ogen](https://ogen.dev/), an open-source OpenAPI v3 code generator for Go.
4.  The [Speakeasy SDK generator](/docs/speakeasy-reference/cli/getting-started).

Below is the summary of how the four evaluated generators compare. Our recommendation is to use Speakeasy for generating Go SDKs for your APIs (1st SDK free). If you are committed to using an open source generator, we strongly recommend that you use [oapi-codegen](https://github.com/oapi-codegen/oapi-codegen)

| Feature | Speakeasy | OpenAPI Generator | oapi-codegen | ogen |
|---------|-----------|-------------------|--------------|------|
| **Version Support** | ✅ Go 1.14+ | ⚠️ Variable support | ✅ Good compatibility | ⚠️ Newer Go versions |
| **Dependencies** | ✅ 3 deps | ❌ 1500+ deps, requires Java | ✅ No external deps | ✅ No external deps |
| **Go Idiomaticity** | ✅ Native Go patterns | ❌ Non-idiomatic | ✅ Simple patterns | ⚠️ Custom patterns |
| **Nil-safe Getters** | ✅ Built-in safety | ❌ No safety | ❌ No safety | ❌ Custom optionals |
| **Union Types** | ✅ Full support | ❌ No support | ⚠️ Limited support | ✅ Full support |
| **Enums** | ✅ Type-safe | ❌ Strings only | ✅ Type-safe | ✅ Type-safe |
| **Complex Numbers** | ✅ Big decimal | ❌ Basic types | ❌ Basic types | ❌ Basic types |
| **Error Handling** | ✅ Custom types | ⚠️ Generic errors | ⚠️ Basic errors | ✅ Good errors |
| **Retries** | ✅ Built-in | ❌ No support | ❌ No support | ❌ No support |
| **Pagination** | ✅ Built-in | ⚠️ Manual only | ⚠️ Manual only | ⚠️ Manual only |
| **Documentation** | ✅ Complete docs | ⚠️ Basic docs | ❌ Minimal docs | ⚠️ Basic docs |
| **CI/CD Integration** | ✅ GitHub Actions | ❌ Manual only | ❌ Manual only | ❌ Manual only |

If you want the detailed technical breakdown, full of code comparisons, read on!

## Installing SDK generators

To start our comparison, we installed all four generators on a local machine running macOS.

### Installing the OpenAPI Generator CLI

OpenAPI Generator depends on Java, [which we covered at length previously](/post/speakeasy-oss-python-generator#our-experience-installing-the-openapi-generator-cli). We concluded that managing the OpenAPI Generator Java dependencies manually just wasn't worth the effort.

Installing `openapi-generator` using Homebrew installs `openjdk@11` and its many dependencies:

```bash
brew install openapi-generator
```

This adds the `openapi-generator` CLI to our path.

### Installing oapi-codegen

We install oapi-codegen using the Go package manager:

```bash
go install github.com/deepmap/oapi-codegen/cmd/oapi-codegen@latest
```

This command installs the oapi-codegen Go module and [its dependencies](https://github.com/deepmap/oapi-codegen/blob/master/go.mod).

### Installing ogen

We followed the [ogen quick start](https://ogen.dev/docs/intro) to install ogen:

```bash
go install -v github.com/ogen-go/ogen/cmd/ogen@latest
```

This installs the ogen Go module with [its dependencies](https://github.com/ogen-go/ogen/blob/main/go.mod).

### How to install the Speakeasy CLI

To install the Speakeasy CLI, follow the steps in the [Speakeasy Getting Started](/docs/speakeasy-reference/cli/getting-started) guide.

In the terminal, run:

```bash
brew install speakeasy-api/homebrew-tap/speakeasy
```

Next, authenticate with Speakeasy by running the following:

```bash
speakeasy auth login
```

This installs the Speakeasy CLI as a single binary without any dependencies.

## Downloading the Swagger Petstore specification

Before we run our generators, we'll need an OpenAPI specification to generate a Go SDK for. The standard specification for testing OpenAPI SDK generators and Swagger UI generators is the [Swagger Petstore](https://petstore3.swagger.io/).

We'll download the YAML specification at [https://petstore3.swagger.io/api/v3/openapi.yaml](https://petstore3.swagger.io/api/v3/openapi.yaml) to our working directory and name it `petstore.yaml`:

```bash
curl https://petstore3.swagger.io/api/v3/openapi.yaml --output petstore.yaml
```

## Validating the Spec

Both the OpenAPI Generator and Speakeasy CLI can validate an OpenAPI spec. We'll run both and compare the output.

### Validation using OpenAPI Generator

To validate `petstore.yaml` using OpenAPI Generator, run the following in the terminal:

```bash
openapi-generator validate -i petstore.yaml
```

The OpenAPI Generator returns two warnings:

```
Warnings:
	- Unused model: Address
	- Unused model: Customer

[info] Spec has 2 recommendation(s).
```

### Validation using Speakeasy

We'll validate the spec with Speakeasy by running the following in the terminal:

```bash
speakeasy validate openapi -s petstore.yaml
```

The Speakeasy validator returns ten warnings, seven hints that some methods don't specify any return values and three unused components. Each warning includes a detailed JSON-formatted error with line numbers.

Since both validators validated the spec with only warnings, we can assume that both will generate SDKs without issues.

## Generating an SDK

Now that we know our OpenAPI spec is valid, we can start generating SDKs.

We'll generate each SDK in a unique subdirectory, relative to where we saved the `petstore.yaml` spec file.

### OpenAPI generate

OpenAPI Generator features SDK generators for multiple languages, often with multiple options per language. We'll test the Go generator in this post.

We'll generate an SDK by running the following in the terminal:

```bash
# Generate Petstore SDK using go generator
openapi-generator generate \
  --input-spec petstore.yaml \
  --generator-name go \
  --output ./petstore-sdk-go-openapi
```

This command will print a list of files generated and populate the new `petstore-sdk-go-openapi` directory.

### Generating an SDK using oapi-codegen

Before we generate an SDK using oapi-codegen, we'll need to create a new directory for this SDK.

Run the following in the terminal:

```bash
mkdir petstore-sdk-go-oapi-codegen && cd petstore-sdk-go-oapi-codegen
```

Create a Go module in the new directory:

```bash
go mod init petstore-sdk-go-oapi-codegen
```

Then run the oapi-codegen Go module:

```bash
go run github.com/deepmap/oapi-codegen/cmd/oapi-codegen@latest -package petstore ../petstore.yaml > petstore.gen.go
```

### Generating an SDK using ogen

We followed the ogen quick start documentation.

Create a new directory for our ogen SDK and navigate to it in the terminal:

```bash
mkdir petstore-sdk-go-ogen && cd petstore-sdk-go-ogen
```

Create a new Go module in this directory:

```bash
go mod init petstore-sdk-go-ogen
```

Copy the `petstore.yaml` spec into this directory:

```bash
cp ../petstore.yaml .
```

Create a new file called `generate.go` with the following contents:

```go
package project

//go:generate go run github.com/ogen-go/ogen/cmd/ogen@latest --target petstore --clean --no-server petstore.yaml
```

Then run the following from our new directory:

```bash
go generate ./...
```

In our testing, this resulted in a stack trace and returned an error status:

```
INFO	convenient	Convenient errors are not available	{"reason": "operation has no \"default\" response", "at": "petstore.yaml:59:9"}
generate:
    main.run
        /Users/ritza/go/pkg/mod/github.com/ogen-go/ogen@v0.69.1/cmd/ogen/main.go:304
  - build IR:
    main.generate
        /Users/ritza/go/pkg/mod/github.com/ogen-go/ogen@v0.69.1/cmd/ogen/main.go:64
  - make ir:
    github.com/ogen-go/ogen/gen.NewGenerator
        /Users/ritza/go/pkg/mod/github.com/ogen-go/ogen@v0.69.1/gen/generator.go:112
  - operations:
    github.com/ogen-go/ogen/gen.(*Generator).makeIR
        /Users/ritza/go/pkg/mod/github.com/ogen-go/ogen@v0.69.1/gen/generator.go:130
  - path "/pet": put:
    github.com/ogen-go/ogen/gen.(*Generator).makeOps
        /Users/ritza/go/pkg/mod/github.com/ogen-go/ogen@v0.69.1/gen/generator.go:171
  - requestBody:
    github.com/ogen-go/ogen/gen.(*Generator).generateOperation
        /Users/ritza/go/pkg/mod/github.com/ogen-go/ogen@v0.69.1/gen/gen_operation.go:49
  - contents:
    github.com/ogen-go/ogen/gen.(*Generator).generateRequest
        /Users/ritza/go/pkg/mod/github.com/ogen-go/ogen@v0.69.1/gen/gen_request_body.go:27
  - media: "application/x-www-form-urlencoded":
    github.com/ogen-go/ogen/gen.(*Generator).generateContents
        /Users/ritza/go/pkg/mod/github.com/ogen-go/ogen@v0.69.1/gen/gen_contents.go:330
  - form parameter "tags":
    github.com/ogen-go/ogen/gen.(*Generator).generateFormContent
        /Users/ritza/go/pkg/mod/github.com/ogen-go/ogen@v0.69.1/gen/gen_contents.go:206
  - nested objects not allowed:
    github.com/ogen-go/ogen/gen.isParamAllowed
        /Users/ritza/go/pkg/mod/github.com/ogen-go/ogen@v0.69.1/gen/gen_parameters.go:184
exit status 1
generate.go:3: running "go": exit status 1
```

The function `isParamAllowed` in `gen/gen_parameters.go` on line 184 throws the error that nested objects are not allowed in form parameters. This seems to indicate that ogen does not yet support generating an SDK for a form request that takes nested objects as parameters, such as a pet's tags, when updating a pet in our schema.

The ogen documentation references a spec to download, so we'll replace `petstore.yaml` with their spec by running the following:

```bash
curl https://raw.githubusercontent.com/ogen-go/web/main/examples/petstore.yml --output petstore.yaml
```

With this new simplified spec, we'll try the generator again:

```bash
go generate ./...
```

The generator runs without errors and prints a log line:

```
INFO	convenient	Convenient errors are not available	{"reason": "operation has no \"default\" response", "at": "petstore.yaml:19:9"}
```

This log line seems to indicate that some operations don't return a default response.

### Speakeasy generate

Finally, we'll generate an SDK using the Speakeasy CLI.

```bash
# Generate Petstore SDK using Speakeasy go generator
speakeasy generate sdk \
    --schema petstore.yaml \
    --lang go \
    --out ./petstore-sdk-go-speakeasy/
```

This command prints a log of warnings and information, then completes successfully.

## SDK code compared: Package structure

We now have four different Go SDKs for the Petstore API:

* `./petstore-sdk-go-openapi/`, generated by OpenAPI Generator.
* `./petstore-sdk-go-oapi-codegen/`, generated by oapi-codegen.
* `./petstore-sdk-go-ogen/`, generated by ogen.
* `./petstore-sdk-go-speakeasy/`, generated by Speakeasy.

We'll start our comparison by looking at the structure of each generated SDK.

Let's print a tree structure for each SDK's directory. Run `tree` in the terminal from our root directory:

```bash
tree -L 3 -F petstore-sdk-go-*
```

We'll split the output by directory for each SDK below.

### OpenAPI Generator SDK structure

```bash
petstore-sdk-go-openapi/
├── README.md
├── api/
│   └── openapi.yaml
├── api_pet.go
├── api_store.go
├── api_user.go
├── client.go
├── configuration.go
├── docs/
│   ├── Address.md
│   ├── ApiResponse.md
│   ├── Category.md
│   ├── Customer.md
│   ├── Order.md
│   ├── Pet.md
│   ├── PetApi.md
│   ├── StoreApi.md
│   ├── Tag.md
│   ├── User.md
│   └── UserApi.md
├── git_push.sh
├── go.mod
├── go.sum
├── model_address.go
├── model_api_response.go
├── model_category.go
├── model_customer.go
├── model_order.go
├── model_pet.go
├── model_tag.go
├── model_user.go
├── response.go
├── test/
│   ├── api_pet_test.go
│   ├── api_store_test.go
│   └── api_user_test.go
└── utils.go
```

OpenAPI Generator creates a relatively flat directory structure, with dedicated directories only for a copy of the spec (`api/openapi.yaml`), documentation (`docs/`), and tests (`test/`).

### oapi-codegen SDK structure

```bash
petstore-sdk-go-oapi-codegen/
├── go.mod
└── petstore.gen.go
```

oapi-codegen creates only one file for all generated code, with no tests or documentation outside this file. This generator appears to be better suited to generating a small and specific client or server as part of a larger project, rather than generating a usable SDK that can be packaged for users.

### ogen SDK structure

```bash
petstore-sdk-go-ogen/
├── generate.go
├── go.mod
├── petstore/
│   ├── oas_cfg_gen.go
│   ├── oas_client_gen.go
│   ├── oas_interfaces_gen.go
│   ├── oas_json_gen.go
│   ├── oas_parameters_gen.go
│   ├── oas_request_encoders_gen.go
│   ├── oas_response_decoders_gen.go
│   ├── oas_schemas_gen.go
│   └── oas_validators_gen.go
└── petstore.yaml
```

ogen also generates relatively few files, which does not seem to be because this generation was based on a simpler spec. This generator does not seem to split schemas into different files and does not create any tests or documentation.

### Speakeasy SDK structure

```bash
petstore-sdk-go-speakeasy/
├── README.md*
├── USAGE.md*
├── docs/
│   ├── models/
│   │   ├── operations/
│   │   └── shared/
│   └── sdks/
│       ├── pet/
│       ├── sdk/
│       ├── store/
│       └── user/
├── files.gen*
├── gen.yaml*
├── go.mod*
├── go.sum*
├── pet.go*
├── pkg/
│   ├── models/
│   │   ├── operations/
│   │   └── shared/
│   ├── types/
│   │   ├── bigint.go*
│   │   ├── date.go*
│   │   └── datetime.go*
│   └── utils/
│       ├── contenttype.go*
│       ├── form.go*
│       ├── headers.go*
│       ├── pathparams.go*
│       ├── queryparams.go*
│       ├── requestbody.go*
│       ├── retries.go*
│       ├── security.go*
│       └── utils.go*
├── sdk.go*
├── store.go*
└── user.go*
```

Speakeasy generates a clear file structure, split into directories for models, types, and other utils. It also creates documentation, split by models and endpoints.

## Models

Let's compare how a pet is represented in each of the four SDKs:

### OpenAPI Generator pet model

```go
// OpenAPI Generator pet model
type Pet struct {
	Id *int64 `json:"id,omitempty"`
	Name string `json:"name"`
	Category *Category `json:"category,omitempty"`
	PhotoUrls []string `json:"photoUrls"`
	Tags []Tag `json:"tags,omitempty"`
	// pet status in the store
	Status *string `json:"status,omitempty"`
}
```

OpenAPI Generator does not seem to take the spec's enum for pet status when generating the pet model. Status in this model is a pointer to a string, while other generators create a type to validate the status field. This model includes struct tags for JSON only.

### oapi-codegen pet model

```go
// oapi-codegen pet model
type Pet struct {
	Category  *Category `json:"category,omitempty"`
	Id        *int64    `json:"id,omitempty"`
	Name      string    `json:"name"`
	PhotoUrls []string  `json:"photoUrls"`
	Status *PetStatus `json:"status,omitempty"`
	Tags   *[]Tag     `json:"tags,omitempty"`
}
```

The oapi-codegen pet model is similar to the OpenAPI Generator version, but it makes the `Tags` field a pointer to a slice of `Tag`, making it possible for this field to be `nil` (which would be omitted from the JSON due to `omitempty`).

The `Status` field is not a simple string pointer, but a pointer to `PetStatus`, which provides better type safety, since `PetStatus` is a type alias for `string` with specific allowable values.

### ogen pet model

```go
// ogen pet model
type Pet struct {
	ID        OptInt64     `json:"id"`
	Name      string       `json:"name"`
	PhotoUrls []string     `json:"photoUrls"`
	Status    OptPetStatus `json:"status"`
}
```

The pet model generated by ogen lacks the `Tags` and `Category` fields because these fields are not present in the simplified spec used.

This struct uses a different approach to optional fields. It uses `OptInt64` and `OptPetStatus` types. We'll look at how ogen differs from Speakeasy in terms of nullable fields below.

### Speakeasy pet model

```go
// Speakeasy pet model
type Pet struct {
	Category  *Category `json:"category,omitempty" form:"name=category,json"`
	ID        *int64    `json:"id,omitempty" form:"name=id"`
	Name      string    `json:"name" form:"name=name"`
	PhotoUrls []string  `json:"photoUrls" form:"name=photoUrls"`
	// pet status in the store
	Status *PetStatus `json:"status,omitempty" form:"name=status"`
	Tags   []Tag      `json:"tags,omitempty" form:"name=tags,json"`
}
```

This struct is similar to the OpenAPI Generator version but includes additional `form` struct tags, which are likely used to specify how these fields should be encoded and decoded when used in form data (such as in an HTTP POST request).

Like the oapi-codegen version, `Status` is a `*PetStatus` rather than a `*string`.

## Nullable fields

Let's focus on the difference between how ogen and Speakeasy handle the nullable `Status` field.

Here's the relevant code generated by ogen:

```go
type PetStatus string

const (
	PetStatusAvailable PetStatus = "available"
	PetStatusPending   PetStatus = "pending"
	PetStatusSold      PetStatus = "sold"
)

// OptPetStatus is optional PetStatus.
type OptPetStatus struct {
	Value PetStatus
	Set   bool
}
```

While much safer than the OpenAPI Generator's pointer to a string type, the ogen `OptPetStatus` is not idiomatic and provides no benefit over using pointers, as Speakeasy does:

```go
type PetStatus string

const (
	PetStatusAvailable PetStatus = "available"
	PetStatusPending   PetStatus = "pending"
	PetStatusSold      PetStatus = "sold"
)

func (e PetStatus) ToPointer() *PetStatus {
	return &e
}
```

The Speakeasy approach provides the same strong typing as the ogen version. It defines `PetStatus` as a custom string type and defines allowable values as constants. This practice ensures that you can't accidentally set a `PetStatus` to an invalid value.

The way Speakeasy handles the `PetStatus` type is more idiomatic to Go, which generally favors simplicity and readability. Instead of defining a new struct like `OptPetStatus`, Speakeasy uses a built-in language feature (pointers) to achieve the same effect. This approach is simpler, more consistent with the rest of the language, and easier to understand and use.

## SDK dependencies

The ogen and oapi-codegen SDKs don't add any dependencies to the generated modules, so we'll compare dependencies between OpenAPI Generator and Speakeasy SDKs.

We'll run the following for each of these two SDKs:

```bash
go mod graph
```

For Speakeasy, this command prints the following:

```
openapi github.com/cenkalti/backoff/v4@v4.2.0
openapi github.com/spyzhov/ajson@v0.8.0
```

The output for the OpenAPI Generator version is too long to show here, so we'll do a count instead:

```bash
go mod graph | wc -l
#> 1538
```

Speakeasy purposefully generates SDKs with fewer dependencies, which leads to faster installs, reduced build times, and less exposure to potential security vulnerabilities.

To see why the Speakeasy SDK depends on an exponential backoff module, let's discuss retries.

## Retries

The SDK generated by Speakeasy can automatically retry failed network requests or retry requests based on specific error responses, providing a straightforward developer experience for error handling.

To enable this feature, we need to use the Speakeasy `x-speakeasy-retries` extension to the OpenAPI spec. We'll update the OpenAPI spec to add retries to the `addPet` operation as a test.

Edit `petstore.yaml` and add the following to the `addPet` operation:

```yaml
      x-speakeasy-retries:
        strategy: backoff
        backoff:
          initialInterval: 500        # 500 milliseconds
          maxInterval: 60000          # 60 seconds
          maxElapsedTime: 3600000     # 5 minutes
          exponent: 1.5
```

Add this snippet to the operation:

```yaml
#...
paths:
  /pet:
    # ...
    post:
      #...
      operationId: addPet
      x-speakeasy-retries:
        strategy: backoff
        backoff:
          initialInterval: 500        # 500 milliseconds
          maxInterval: 60000          # 60 seconds
          maxElapsedTime: 3600000     # 5 minutes
          exponent: 1.5
```

Now we'll rerun the Speakeasy generator to enable retries for failed network requests when creating a new pet. It is also possible to enable retries for the SDK as a whole by adding global `x-speakeasy-retries` at the root of the OpenAPI spec.

## Generated documentation

Both Speakeasy and OpenAPI generate documentation for the generated code.

Each generator creates a `README.md` file at the base directory of the generated SDK. This file serves as a primary source of documentation for the SDK users. You have the option to [customize this README](/docs/customize-sdks/sdk-docs) using Speakeasy to suit your needs better. For example, you could add your brand's logo, provide links for support, outline a code of conduct, or include any other information that could be useful to the developers using the SDK.

The Speakeasy-generated documentation really shines when it comes to usage examples, which include working usage examples for all operations, complete with imports and appropriately formatted string examples. For instance, if a string is formatted as `email` in our OpenAPI spec, Speakeasy generates usage examples with strings that look like email addresses. Types formatted as `uri` will generate examples that look like URLs. This makes example code clear and scannable.

We'll test this by adding `format: uri` to the items in the `photoUrls` array. Let's compare the generated example code for the `addPet` endpoint after adding this string format.

### Usage example generated by OpenAPI

Here's the example from the OpenAPI-generated documentation:

```go
package main

import (
    "context"
    "fmt"
    "os"
    openapiclient "github.com/GIT_USER_ID/GIT_REPO_ID"
)

func main() {
    pet := *openapiclient.NewPet("doggie", []string{"PhotoUrls_example"}) // Pet | Create a new pet in the store

    configuration := openapiclient.NewConfiguration()
    apiClient := openapiclient.NewAPIClient(configuration)
    resp, r, err := apiClient.PetApi.AddPet(context.Background()).Pet(pet).Execute()
    if err != nil {
        fmt.Fprintf(os.Stderr, "Error when calling `PetApi.AddPet``: %v\n", err)
        fmt.Fprintf(os.Stderr, "Full HTTP response: %v\n", r)
    }
    // response from `AddPet`: Pet
    fmt.Fprintf(os.Stdout, "Response from `PetApi.AddPet`: %v\n", resp)
}
```

Note how the OpenAPI example only includes required fields and ignores the URI string format from our spec.

### Usage example generated by Speakeasy

This is what Speakeasy generates as a usage example:

```go
package main

import(
	"context"
	"log"
	"openapi"
	"openapi/pkg/models/shared"
	"openapi/pkg/models/operations"
)

func main() {
    s := sdk.New()

    ctx := context.Background()
    res, err := s.Pet.AddPetJSON(ctx, shared.Pet{
        Category: &shared.Category{
            ID: sdk.Int64(1),
            Name: sdk.String("Dogs"),
        },
        ID: sdk.Int64(10),
        Name: "doggie",
        PhotoUrls: []string{
            "https://ecstatic-original.info",
        },
        Status: shared.PetStatusSold.ToPointer(),
        Tags: []shared.Tag{
            shared.Tag{
                ID: sdk.Int64(681820),
                Name: sdk.String("Stacy Moore"),
            },
            shared.Tag{
                ID: sdk.Int64(697631),
                Name: sdk.String("Brenda Wisozk"),
            },
            shared.Tag{
                ID: sdk.Int64(670638),
                Name: sdk.String("Connie Herzog"),
            },
            shared.Tag{
                ID: sdk.Int64(315428),
                Name: sdk.String("Corey Hane III"),
            },
        },
    }, operations.AddPetJSONSecurity{
        PetstoreAuth: "",
    })
    if err != nil {
        log.Fatal(err)
    }

    if res.Pet != nil {
        // handle response
    }
}
```

The example generated by Speakeasy includes all available fields and correctly formats the example string in the `PhotoUrls` field.

We'll also compare how OpenAPI and Speakeasy generate documentation for the `Status` field in our pet model.

### OpenAPI generate does not document enums

The OpenAPI-generated documentation reflects the generated code's omission of valid options for the `Status` field. Here's the pet model documentation generated by OpenAPI:

#### Pet properties generated by OpenAPI

Name | Type | Description | Notes
------------ | ------------- | ------------- | -------------
**Id** | Pointer to **int64** |  | [optional] 
**Name** | **string** |  | 
**Category** | Pointer to **Category** |  | [optional] 
**PhotoUrls** | **[]string** |  | 
**Tags** | Pointer to **[]Tag** |  | [optional] 
**Status** | Pointer to **string** | pet status in the store | [optional]

Note how `Status` is simply a string, with no indication of possible values.

### Speakeasy generates documentation showing valid values

Here's how Speakeasy documents the pet model:

#### Pet fields generated by Speakeasy

| Field                                          | Type                                           | Required                                       | Description                                    | Example                                        |
| ---------------------------------------------- | ---------------------------------------------- | ---------------------------------------------- | ---------------------------------------------- | ---------------------------------------------- |
| `Category`                                     | *Category   | :heavy_minus_sign:                             | N/A                                            |                                                |
| `ID`                                           | **int64*                                       | :heavy_minus_sign:                             | N/A                                            | 10                                             |
| `Name`                                         | *string*                                       | :heavy_check_mark:                             | N/A                                            | doggie                                         |
| `PhotoUrls`                                    | []*string*                                     | :heavy_check_mark:                             | N/A                                            |                                                |
| `Status`                                       | *PetStatus | :heavy_minus_sign:                             | pet status in the store                        |                                                |
| `Tags`                                         | []Tag            | :heavy_minus_sign:                             | N/A                                            |                                                |

In the example above, `PetStatus` links to the following documentation:

#### PetStatus values generated by Speakeasy

| Name                 | Value                |
| -------------------- | -------------------- |
| `PetStatusAvailable` | available            |
| `PetStatusPending`   | pending              |
| `PetStatusSold`      | sold                 |

This further illustrates Speakeasy's attention to detail when it comes to documentation. 

## Automation

This comparison focuses on the installation and usage of command line generators, but the Speakeasy generator can also run as part of a CI workflow, for instance as a [GitHub Action](https://github.com/speakeasy-api/sdk-generation-action), to make sure your SDK is always up to date when your API spec changes.

## Summary

We've seen how Speakeasy generates lightweight, idiomatic SDKs for Go.

If you're building an API that developers rely on and would like to publish full-featured Go SDKs that follow best practices, we strongly recommend giving the [Speakeasy SDK generator](/docs/speakeasy-reference/cli/getting-started) a try.

[Join our Slack community](https://join.slack.com/t/speakeasy-dev/shared_invite/zt-1cwb3flxz-lS5SyZxAsF_3NOq5xc8Cjw) to let us know how we can improve our Go SDK generator or to suggest features.


 This is the content for the doc docs/languages/java/feature-support.mdx 

 ---
title: "Java Feature Reference"
description: "An overview of Java features supported by Speakeasy for SDK generation from an OpenAPI / Swagger spec."
---

# Java Feature Reference

## Authentication

|    Name    | Support |  Docs  |   Notes |
|------------|:---:|------------------|---------|
| HTTP Basic |   ✅    |     Docs         |         |
| API Key <br /> (bearer, header, cookie, query) |   ✅    |     Docs         |         |
| OAuth <br /> implicit flow |   ✅    |     Docs         |         |
| OAuth <br /> refresh token flow |   ✅ using security callbacks    |     Docs         |         |
| OAuth <br /> client credentials flow |   🏗️ Partial   |     Docs         |         |
| mTLS |   🏗️ Partial    |     Docs         |         |

## Server Configuration

|       Name     | Support |  Docs  |   Notes |
|----------------|:-------:|--------------|--------|
| URL Templating |    ✅    | [defining `variables`](/docs/customize-sdks/servers#use-templated-urls) |  |
| Multiple server|    ✅    | [`x-speakeasy-server-id` extension](/docs/customize-sdks/servers#declare-multiple-servers) |  |
| Describe server <br /> outside your spec  | ✅    | [`serverUrl` config](/docs/customize-sdks/servers#declare-base-server-url) |  |

## Data Types

### Basic Types

| Name | Support |  Docs  |   Notes |
|------|:-------:|--------------|--------|
| Numbers |    ✅    | [data-types](https://swagger.io/docs/specification/data-models/data-types/#numbers) | `float`, `double`, `int32`, `int64` |
| Strings |    ✅    | [data-types](https://swagger.io/docs/specification/data-models/data-types/#strings) |  |
| Date Time |    ✅    | [data-types](https://swagger.io/docs/specification/data-models/data-types/#date-time) |  |
| Boolean |    ✅    | [data-types](https://swagger.io/docs/specification/data-models/data-types/#booleans) |  |
| Binary |    ✅    | [data-types](https://swagger.io/docs/specification/data-models/data-types/#binary) |  |
| Enums |    ✅    | [data-types](https://swagger.io/docs/specification/data-models/data-types/#enumerations) |  |
| Arrays |    ✅    | [data-types](https://swagger.io/docs/specification/data-models/data-types/#arrays) |  |
| Maps |    ✅    | [data-types](https://swagger.io/docs/specification/data-models/data-types/#maps) |  |
| Objects |    ✅    | [data-types](https://swagger.io/docs/specification/data-models/data-types/#objects) |  |
| Any |    ✅    | [data-types](https://swagger.io/docs/specification/data-models/data-types/#any) |  |
| Null |    ✅    | [data-types](https://swagger.io/docs/specification/data-models/data-types/#nil) |  |

### Polymorphism

| Name | Support |  Docs  |   Notes |
|------|:-------:|--------------|--------|
| Union Types |    ✅    | [Using `oneOf`](https://swagger.io/docs/specification/data-models/oneof-anyof-allof-not/#oneof) | `anyOf` is treated as `oneOf` and will create a union type object. |
| Intersection Types |   🏗️ Partial     | [Using `allOf`](https://swagger.io/docs/specification/data-models/oneof-anyof-allof-not/#allof) |  |


## Methods

|     Name    | Support |  Docs  |   Notes |
|-------------|:-------:|--------------|--------|
| Namespacing |    ✅    | [grouping operations](/docs/customize-sdks/namespaces) |  |
| Multi-level Namespacing |    ✅    | [multi-level grouping](/docs/customize-sdks/namespaces#define-multi-level-namespaces) |  |
| Custom naming|    ✅    | [`x-speakeasy-name-override` extension](/docs/customize-sdks/methods#change-method-names) |  |
| Exclude Methods |    ✅    | [`x-speakeasy-ignore` extension](/docs/customize-sdks/methods#exclude-methods-from-sdk) |  |
| Deprecation |    ✅    | the [`deprecate` flag](/docs/customize-sdks/methods#deprecate-methods) |  |

## Parameters

|     Name    | Support |  Docs  |   Notes |
|-------------|:-------:|--------------|--------|
| Pass Inline |    ✅    | [flattening parameters](/docs/customize-sdks/methods#configuring-method-signatures) |  |
| Pass via Request Object |    ✅    | [request object](/docs/customize-sdks/methods#configuring-method-signatures) |  |
| Exclude Parameters |    ✅    | [`x-speakeasy-ignore` extension](/docs/customize-sdks/methods#exclude-parameters-from-signatures) |  |
| Deprecate Parameters |    ✅    | the [`deprecate` flag](/docs/customize-sdks/deprecations#deprecate-parameters) |  |
| Define globally |    ✅    | [global parameters](/docs/customize-sdks/globals) |  |

### Path Parameters Serialization

|     Name    | Support |  Docs  |   Notes |
|-------------|:-------:|--------------|--------|
| Default <br /> `(style = simple, explode = false)` |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#path/) |  |
| Basic types |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#path/) |  |
| Simple objects |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#path/) |  |
| `label` & `matrix` |    ❌    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#path/) |  |

### Query Parameters Serialization

|     Name    | Support |  Docs  |   Notes |
|-------------|:-------:|--------------|--------|
| `json` |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#query/) |  |
| `form` |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#query/) |  |
| `spaceDelimited` |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#query/) |  |
| `pipeDelimited` |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#query/) |  |
| `deepObject` |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#query/) |  |
| Basic types |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#query/) |  |
| Simple objects |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#query/) |  |

## Requests

|     Name    | Support |  Docs  |   Notes |
|-------------|:-------:|--------------|--------|
| Request headers |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#header/) |  |
| Request retries |    ✅    | [retries](/docs/customize-sdks/retries) |  |
| `json` |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#request-body/) | Both `application/json` and `text/json`  |
| form data |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#request-body/) |  |
| binary |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#request-body/) |  |
| raw byte |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#request-body/) |  |
| plain text |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#request-body/) |  |
| `x-www-form-urlencoded` |    🏗️ Partial    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#request-body/) | Including encoding, but not non-object types |
| XML |    ❌    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#request-body/) |  |
| Other media types |    ❌    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#request-body/) |  |

## Responses

|     Name    | Support |  Docs  |   Notes |
|-------------|:-------:|--------------|--------|
| Pagination |    ✅    | [`x-speakeasy-pagination` extension](/docs/customize-sdks/pagination) |  |
| Custom Errors |    ✅    | [`x-speakeasy-errors` extension](/docs/customize-sdks/errors) |  |
| json |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#response/) |  |
| plain text |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#response/) |  |
| binary |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#response/) |  |
| raw byte |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#response/) |  |
| XML |    ❌    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#response/) |  |
| Other media types   |    ❌    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#response/) |  |

## Documentation

|     Name    | Support |  Docs  |   Notes |
|-------------|:-------:|--------------|--------|
|  `README` generation |    ✅    | [README generation](/docs/customize-sdks/sdk-docs) |  |
|  Usage Snippet generation |    ✅    | [snippet generation](/docs/customize-sdks/sdk-docs#usage-examples) |  |
|  Documentation generation |    ✅    | [documentation generation](/docs/customize-sdks/sdk-docs) |  |


 This is the content for the doc docs/languages/java/methodology-java.mdx 

 ---
title: "Generate Java SDKs from OpenAPI / Swagger"
description: "This post explains how Speakeasy creates a Java client from a Swagger / OpenAPI spec."
---

import { Callout } from '~/components'

# Generate a Java SDK from OpenAPI / Swagger

## Java SDK overview

The Speakeasy Java SDK is designed to be easy to use and debug. This includes generating strongly typed classes that enforce required fields and other validations to ensure the messages sent are correct. This allows for a tighter development cycle so your API consumers can spend less time developing solutions using your API.

The core features of the SDK include:

- **Type-safety**: Strong typing is used extensively so that problems are seen at compile time, not runtime.
- **Null-safety**: Primitive types are used where possible, improving **compile-time** null safety.  For non-required and nullable fields, the `java.util.Optional` and `JSONNullable` classes are used. Passing Java `null` arguments will provoke an exception. 
- **Builders and method chaining for all SDK objects.** For example, to create a `Person` object:

```java
Person person = Person.builder()
    .firstName("Albert")
    .lastName("Einstein")
    .dateOfBirth(LocalDate.parse("1879-03-14"))
    .build();
```

- All-field constructors are available for most SDK objects, so a user can get a compile-time indication of changes to the OpenAPI document if required.
- **Readability**: Appropriately formatted method chaining is more understandable and maintainable.
- **Discoverability**: Method chaining and favorable naming strategies make life easier. For example, to build a `Person` object, you call `Person.builder()` and **not** `new Builders.PersonFactory()`.
- **Convenient overloads in builders.** For example, a `long` can be passed directly when the underlying field is `Optional<Long>`. 
- The `java.util.Optional` class is used for non-required arguments.
- The `JsonNullable` class is used for nullable arguments. 
- The Java platform `OffsetDateTime` and `LocalDate` types are used for `date-time` and `date`. 
- A `utils` package provides shared code used by generated classes, making the generated code easier to follow.
- Authentication support for OAuth flows and other standard security mechanisms.
- Custom enum types using string or integer values.
- Pagination support, including the option to return `java.util.Stream` so that paging is auto-handled. 
- Well-formatted source code to make debugging easier.

The SDK includes minimal dependencies. It requires:

- [Jackson Library](https://github.com/FasterXML/jackson) to serialize and deserialize data over the wire. 
- [Apache HttpClient](https://hc.apache.org/httpcomponents-client-4.5.x/index.html) to make HTTP requests.
- [Jayway JsonPath](https://github.com/json-path/JsonPath) to support JSON path expressions in Speakeasy metadata fields in OpenAPI documents.

## Java package structure

```yaml lib-structure.yaml
|-- build.gradle               # more Gradle configuration
|-- build-extras.gradle        # custom Gradle configuration (untouched by generation updates)
|-- build                      # directory that will contain built artifacts
|   └-- ...
|-- src                        # source code directory
|   └-- main                   # main source code directory
|       └-- {SDK Package Name} # sub-directories to the SDK package namespace
|           |-- SDK.java       # primary SDK class
|           |-- ...            # additional sub-SDK classes
|           |-- models         # package for model-related files
|           |   |-- operations # package for request/response operational models
|           |   |   └-- ...
|           |   └-- shared     # package for shared component models
|           |       └-- ...
|           └-- utils          # package for shared utility classes 
|               └-- ...
|-- docs                           # Markdown files for the SDK's documentation
|-- gradlew                        # Gradle shellscript to build/install the SDK
|-- gradlew.bat                    # Gradle batch file to build/install the SDK
|-- settings.gradle                # provided Gradle settings
|-- gradle
|   └-- ...                        # other Gradle-related files
└-- ...
```
## Build customization

The `build.gradle` file should not be edited because generation updates will overwrite changes. However, customization of `build.gradle` is possible:

- Additions to `build.gradle` can be made by editing `build-extras.gradle`, which is untouched by generation updates.
- However, `build-extras.gradle` does not allow for the addition of plugins. You need to use the `additionalPlugins` property in `gen.yaml` to add plugins to `build.gradle`:

```yaml
java:
  version: 0.2.0
  artifactID: openapi
...
  additionalPlugins: 
    - 'id("java")'
```

Dependencies can be customized in two ways:

- You can add a `dependencies` block to `build-extras.gradle`. Note that with standard Gradle techniques, you can exclude dependencies, exclude transitive dependencies, and modify dependencies in `build-extras.gradle`.

- You can use the `additionalDependencies` property in `gen.yaml`. For example, the fragment below overrides the `jackson-databind`  and adds `commons-compress`:

  ```yaml
  java:
    version: 0.2.0
  ...
    addditionalDependencies:
      - implementation:com.fasterxml.jackson.core:jackson-databind:2.16.0
      - api:org.apache.commons:commons-compress:1.26.1
  ```
  

## HTTP client

The Java SDK HTTP client is configurable using a class implementing the following interface and is found in the `util` package of the generated code:

```java
public interface HTTPClient {
    public HTTPResponse<byte[]> send(HTTPRequest request) 
      throws IOException, InterruptedException, URISyntaxException
}
```

A default implementation is provided based on `java.net.HttpClient`. Any developer using the SDK can easily replace this implementation with their own:

```java
MyHttpClient client = new MyHttpClient();

SDK sdkInstance = SDK.builder().setClient(client).build();
```

This gives developers using your Java SDK the flexibility to set up proxies, cookie jars, special headers, or any other low-level customization.

## Serialization and deserialization

Low-level customizations like request and response hooks or `HTTPClient`-based interceptions may require the serialization and deserialization of generated objects to and from JSON. 

You **must** use the generated custom Jackson `ObjectMapper` for these actions. The `ObjectMapper` is available as a Singleton in the generated `utils` package via `JSON.getMapper()`.

## Java SDK data types and classes

### Primitives and native types

Where possible, the Java SDK uses native types from the language and uses primitives to increase null safety. For example:

- `java.lang.String`
- `java.time.OffsetDateTime`
- `java.time.LocalDate`
- `java.math.BigInteger`
- `java.math.BigDecimal`
- `int` (or `java.lang.Integer`)
- `long` (or `java.lang.Long`)
- `float` (or `java.lang.Float`)
- `double` (or `java.lang.Double`)
- `boolean` (or `java.lang.Boolean`)


### Unlimited-precision numerics

Using high-precision decimal or integer types is crucial in certain applications, such as in code that manipulates monetary amounts and in situations where overflow, underflow, or truncation caused by precision loss can lead to significant incidents.

To mark a field as an unlimited-precision integer, you can use either an integer:

```yaml
  type: integer
  format: bigint
``` 

Or a string:

```yaml
  type: string
  format: bigint
```

The above types are mapped to `java.math.BigInteger` in the generated SDK. Object builders have convenient overloads that allow for passing integer values directly without wrapping them in `BigInteger`.

Similarly, for an unlimited-precision decimal, you can use either a number:

```yaml
  type: number
  format: decimal
```

Or a string: 

```yaml
  type: string
  format: decimal
```
The above types are mapped to `java.math.BigDecimal` in the generated SDK and object builders have convenient overloads that allow passing float and double values directly without wrapping them in `BigDecimal`.

**Note:** SDKs in other languages may choose to map to native high-precision types rather than unlimited-precision types. Check the documentation of the language you are interested in.

### Union types

Support for polymorphic types is critical to most production applications. In OpenAPI, these types are defined using the `oneOf` keyword. 

#### Non-discriminated `oneOf`

The subtypes of a non-discriminated `oneOf` type may be objects or primitives, so a **composition** approach is adopted to represent a `oneOf` type.

Consider this OpenAPI fragment:

```yaml
    Pet:
      oneOf:
      - $ref: "#/components/schemas/Cat"
      - $ref: "#/components/schemas/Dog"
```

Here's how a `Pet` is created in Java code:

```java
Cat cat = ...;
Dog dog = ...;

// Pet.of only accepts Cat or Dog types, and throws if passed null.
Pet pet = Pet.of(cat); 
``` 

Here is how a `Pet` is inspected:

```java
Pet pet = ...; // might be returned from an SDK call
if (pet.value() instanceof Cat) {
   Cat cat = (Cat) pet.value();
   // Do something with the cat.
} else if (pet.value() instanceof Dog) {
   Dog dog = (Dog) pet.value();
   // Do something with the dog.
} else {
   throw new RuntimeException("unexpected value, openapi definition has changed?");
}
```

Java versions 14+ also offer pattern-matching language features, which you can use as follows:

```java
Pet pet = ...; // might be returned from an SDK call
if (pet.value() instanceof Cat cat) {
   // Do something with the cat.
} else if (pet.value() instanceof Dog dog) {
   // Do something with the dog.
} else {
   throw new RuntimeException("unexpected value, openapi definition has changed?");
}
```

#### `oneOf` customization

In some circumstances, the `of` static factory method of a `oneOf` class may need to be differentiated by a suffix to avoid type erasure. For example, you would need to use a suffix to differentiate the two array subtypes in the following fragment:

```yaml
    Info:
      oneOf:
      - type: array
        items: 
          type: integer
        x-speakeasy-name-override: counts
      - type: array
        items: 
          type: string
        x-speakeasy-name-override: descriptions
```

Without accounting for this scenario, the static factory methods `Info.of(List<Long>)` and `Info.of(List<String>)` would conflict due to generic type erasure by the Java compiler and cause a compile error in the generated code. Code generation detects this scenario and adds an `of` method suffix. For the fragment above, the generated static factory methods are the following: 

- `ofCounts(List<Long>)`
- `ofDescriptions(List<String>)`

A suffix for `of` is selected according to the following priority (and only for subtypes with potential erasure conflicts):

- Use the `x-speakeasy-name-override` value, if present.
- Use the Speakeasy-calculated name of the type, if present.
- Use the Speakeasy-calculated name of the item type, if present.
- Use the 1-based subtype index.

#### Discriminated `oneOf`

The subtypes of a discriminated `oneOf` type must be objects, so an interface-based **inheritance** approach can be adopted, as it provides more polymorphic convenience than the composition approach.

Consider this OpenAPI fragment:

```yaml
    Pet:
      oneOf:
      - $ref: "#/components/schemas/Cat"
      - $ref: "#/components/schemas/Dog"
      discriminator:
        propertyName: petType
        mapping: 
          cat: '#/components/schemas/Cat'
          dog: '#/components/schemas/Dog'
```

Here's how a `Pet` is created in Java code:

```java
Pet cat = Cat.builder().name("Moggie").build();
Pet dog = Dog.builder().name("Fido").build();
```

`Pet` is a Java interface with a single `petType()` method, and `Cat` and `Dog` both implement that interface. 

The `discriminator` property should be marked as required in the `oneOf` subtypes. Considering the discriminator has a constant value in each `oneOf` subtype, it also makes sense to use a Singleton `enum` or a `const` for the `discriminator` property type.

The `enum` is used as follows:

```yaml
    Cat:
      type: object
      properties:
        name:
          type: string
        petType:
          type: string
          enum: [cat]
     required: [name, petType]
```

The `const` is used in the same way:

```yaml
    Cat:
      type: object
      properties:
        name:
          type: string
        petType:
          type: string
          const: cat
     required: [name, petType]
```

#### `oneOf` deserialization

Speakeasy currently uses a forgiving deserialization strategy for `oneOf`. If more than one match is found in the subtypes, a heuristic is used to select a **best** match (rather than throwing an exception). This strategy fits nicely with the auto-transformation of `anyOf` to `oneOf` while `anyOf` implementation options are being considered.

In short, the `oneOf` deserialization heuristic (only applied when a JSON object is being deserialized) is to return the first matching subtype that has the greatest number of properties.

#### `anyOf`

The `anyOf` keyword is frequently used when `oneOf` is appropriate. Speakeasy is still considering specific `anyOf` implementation options. For the moment, `anyOf` is always treated as a `oneOf`. The heuristic used for `oneOf` deserialization is described above and ensures compatibility with `anyOf`.

### Enums

An OpenAPI `enum` is represented using a normal Java `enum` such as the following:

```java
   public enum Color {

        RED("red"),
        GREEN("green"),
        BLUE("blue");

        @JsonValue
        private final String value;

        private ColorEnum(String value) {
            this.value = value;
        }

        public String value() {
            return value;
        }

        public static Optional<Console> fromValue(long value) {
            for (Color o: Color.values()) {
                if (Objects.deepEquals(o.value, value)) {
                    return Optional.of(o);
                }
            }
            return Optional.empty();
        }
    }
```

The above enum is **closed** in the sense that if a user attempts to deserialize an unexpected `enum` value (like `orange` for the `enum` above), then an exception will be thrown.

#### Open enums

Speakeasy also supports an **open enum** to ensure that an enum can evolve without breaking outdated API SDK usage. The addition of the `x-speakeasy-unknown-values: allow` extension to an `enum` changes the code generation to produce a concrete class rather than a Java `enum`.

Consider the following when using this concrete class:

- It looks like a Java `enum` and compiles without changes for simple usage. For example, `Color.RED` is used for both closed and open enums.
- Like a closed enum, it has a `value()` method that can hold an unknown value.
- It has an `isUnknown()` method to indicate that the value is not a declared `enum` member.
- It offers the `values()` method used to iterate all members of an enum. The same signature is used for both closed and open enums.
- Like a Java `enum`, it honors reference equality. For example, `Color.RED == Color.of("red")` and `Color.BROWN == Color.of("brown")`.
- Is not usable in a switch expression. It can only be used with `int`, `String`, and `enum` types in Java.
- You can use the convenience method `Optional<ColorEnum> asEnum()` to access a real `enum` if desired, for example, in a switch expression. However, you have to navigate the `Optional` value, and `ColorEnum` is only relevant for known `enum` values.
- It includes custom serialization and deserialization for ensuring Singleton references.

Be aware that migrating a closed enum to an open enum may bring about compile errors in an end-user's code, because the concrete class cannot be used in a switch expression in the way a Java `enum` can. This is a breaking change. For this reason, it is helpful to identify potentially **open** enums earlier rather than later.

## Parameters

If parameters are defined in the OpenAPI document, Speakeasy will generate methods with parameters as part of the method call itself rather than as part of a separate request object. 

The number of parameters defined should not exceed the `maxMethodParams` value configured in the `gen.yaml` file. If they do or the `maxMethodParams` value is absent or set to `0`, all generated methods require a single request object that contains all the parameters that may be used to call an endpoint in the API.

## Default values

The `default` keyword in the OpenAPI specification allows a user to omit a field or parameter and it will be set with a given default value. 

Default values are represented in the Java SDK with `java.util.Optional` wrappers. Passing `Optional.empty()`, or if you're using a builder, not setting the field or parameter, will mean that the default value in the OpenAPI document is used. 

Bear in mind that it's lazy-loaded (only loaded once) and that if the default value is not valid for the given type, an `IllegalArgumentException` will be thrown. For example, if `default: abc` is specified for `type: integer`, the exception is thrown.

If you encounter this situation, you have two options:

- Regenerate the SDK with a fixed default value in the OpenAPI document.
- Set the value of the field explicitly, so that the once-only lazy load of the default value never occurs. This technique is most likely the immediate workaround for a user who does not own the SDK repository.

## Constant values

The `const` keyword in the OpenAPI specification ensures that a field is essentially read-only and that its value will be the specified constant. Fields for `const` will not be settable in all-parameter constructors or builders, their value will be set internally. However, `const` fields are readable in terms of object getters. The `const` values are lazy-loaded once only (like `default` values). If the `const` value is not valid for the given type, then an `IllegalArgumentException` will be thrown. The best fix for this is to regenerate the SDK with a fixed `const` value in the OpenAPI document.

## Errors

To handle errors in the Java SDK, you need to check the status code of the response. If it is an error response, the `error` field of the response will contain the decoded error value.

<Callout title="Coming Soon" variant="info">
Support for throwing unsuccessful status codes as exceptions is coming soon.
</Callout>

## Pagination and `java.util.Stream`

Enabling pagination for an operation in your API is described [here](/docs/customize/runtime/pagination). 

If pagination is enabled for an operation, you have the option to run `.call()`, `.callAsStream()`, or `.callAsStreamUnwrapped()` when using the operation builder. 

- The `.call()` method will return the first page, and you will have to repeatedly check for the existence of another page and retrieve it. 
- The `callAsStream()` method returns a `java.util.Stream` of the pages, allowing you to use the convenient `java.util.Stream` API. Retrieving more pages when required and available is handled automatically.
- The `callAsStreamUnwrapped()` method returns a `java.util.Stream` of the concatenated items in the lists on each page. Concatenation and page retrieval are handled automatically.

Below is an example of `callAsStream()`:
 
```java
SDK sdk = SDK.builder() ... ;

sdk.searchDocuments()    // builder for the request
   .contains("simple")   // parameter
   .minSize(200)         // parameter
   .maxSize(400)         // parameter
   .callAsStream()       // returns Stream<DocumentsPageResponse>
   .flatMap(x -> x.res() // returns Optional<DocumentsPage>
                  .stream()
                  .flatMap(y -> y.documents().stream()))
   // we are now dealing with a Stream<Document>
   .filter(document -> "fiction".equals(document.category())
   .limit(200) // no more than 200 documents
   .map(document -> document.name())
   .forEach(System.out::println);
```

Note that the `flatMap` calls above concatenate the page lists. If you use `callAsStreamUnwrapped`, it concatenates the page lists for you, so you can omit `flatMap`:

```java
sdk.searchDocuments()    // builder for the request
   .contains("simple")   // parameter
   .minSize(200)         // parameter
   .maxSize(400)         // parameter
   .callAsStreamUnwrapped() 
   // we are now dealing with a Stream<Document>
   .filter(document -> "fiction".equals(document.category())
   .limit(200) // no more than 200 documents
   .map(document -> document.name())
   .forEach(System.out::println);
```

The `callAsStream` and `callAsStreamUnwrapped` methods throw an exception if a response page has a status code of 300 or higher. If you require a different behavior, use the `call` method to manually retrieve each page.

## Server-sent events

General Speakeasy support for server-sent events (SSE) is described [here](/docs/customize-sdks/server-sent-events). 

When an operation response has a content type of `text/event-stream`, the generated response class will have an `events()` method.

The `events()` method can be used to traverse the event stream using a `while` loop:

```java
// We use try-with-resources to ensure closure of the underlying HTTP connection.
try (EventStream<JsonEvent> events = response.events()) {
    Optional<JsonEvent> event;
    while ((event = events.next()).isPresent()) {
         processEvent(event.get());
    }
}
```

The `events()` method can also be used with `java.util.Stream`:

```java
// We use try-with-resources to ensure the closure of the underlying HTTP connection.
try (EventStream<JsonEvent> events = response.events()) {
    events.stream().forEach(event -> processEvent(event));
}
```

The `events()` method can also be used to aggregate events into a list:

```java
// closes for you
List<JsonEvent> events = response.events().toList();
events.forEach(event -> processEvent(event));
```

## User agent strings

The Java SDK will include a [user agent](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/User-Agent) string in all requests that can be used to track SDK usage among broader API usage. The format is as follows: 

```stmpl
speakeasy-sdk/java {{SDKVersion}} {{GenVersion}} {{DocVersion}} {{groupId.artifactId}}
```

- `SDKVersion` is the version of the SDK, defined in `gen.yaml` and released.
- `GenVersion` is the version of the Speakeasy generator.
- `DocVersion` is the version of the OpenAPI document.
- `groupId.artifactId` is the concatenation of the `groupId` and `artifactId` defined in `gen.yaml`.


 This is the content for the doc docs/languages/java/oss-comparison-java.mdx 

 ---
title: "Comparison guide: OpenAPI/Swagger Java client generation"
description: "Comparing the new Speakeasy Java SDK generator with the open-source OpenAPI Java generators"
keywords: [api, openapi, swagger, sdk generation, sdk, java, sdk, developer experience, devex, dx]
date: 2024-05-08
---

# Comparison guide: OpenAPI/Swagger Java client generation

At Speakeasy, we specialize in producing idiomatic SDKs in various programming languages, including Java. Our approach to SDK generation prioritizes a rich developer experience that enables you as an API provider to concentrate on refining your API and empowers your developer-users to efficiently leverage your services.

In this article, we'll compare creating a Java SDK using Speakeasy to creating one using the [OpenAPI Generator](https://github.com/OpenAPITools/openapi-generator).

Below is a table that summarizes the key differences between the two SDKs:

| Feature | Speakeasy | OpenAPI Generator |
|---------|-----------|------------------|
| Minimum version | Java 11+ (modern features) | Java 8+ (legacy support) |
| Dependencies | ✅ Minimal dependencies | ⚠️ Many third-party dependencies |
| HTTP client | Native Java 11 `java.net.http` | ⚠️ Third-party OkHttp dependency |
| JSON processing | ✅ [Jackson](https://github.com/FasterXML/jackson) (enterprise-ready, faster) | ⚠️ [Gson](https://github.com/google/gson) (simpler, limited config) |
| Builder pattern | ✅ Modern builder pattern | ❌ Traditional setters only |
| Null safety | ✅ Proactive with `Optional` support | ❌ Basic retrospective validation |
| Retry support | ✅ Built-in configurable retries | ❌ Not supported |
| Documentation | ✅ Comprehensive, with examples | ⚠️ Basic documentation |
| Collections | ✅ Modern list implementations | ⚠️ Mix of arrays and lists |
| Field access | ✅ Encapsulated (getter methods) | ❌ Direct field access |
| OAuth support | ✅ Built-in OAuth 2.0 | ⚠️ Requires additional library |
| Pagination | ✅ Supported | ❌ Not supported |

Read more about these headline features of Speakeasy-created Java SDKs in the [March 2024 release notes](/post/release-java-ga), or consult the [Speakeasy Java SDK documentation](/docs/languages/java/methodology-java).

For a detailed technical comparison, read on!

## Installing the CLIs

For this comparison, we need both the Speakeasy and OpenAPI Generator CLIs installed to generate the Java SDKs from the specification YAML file. We're using macOS, so we use Homebrew to install the CLIs.

### Installing the Speakeasy CLI

Install the Speakeasy CLI by running the following command in the terminal:

```bash
brew install speakeasy-api/homebrew-tap/speakeasy
```

You can check the version to ensure installation was successful:

```bash
speakeasy -v
```

If you encounter any errors, take a look at the [Speakeasy SDK creation documentation](/docs/create-client-sdks).

### Installing the OpenAPI Generator CLI

Install the OpenAPI Generator CLI by running the following command in the terminal:

```bash
brew install openapi-generator
```

You can check the version:

```bash
openapi-generator version
```

Browse the [OpenAPI Generator documentation](https://github.com/OpenAPITools/openapi-generator/blob/master/README.md) if any errors occur.

## Downloading the Swagger Petstore specification

We need an OpenAPI specification YAML file to generate SDKs for. We'll use the Swagger Petstore specification, which you can find at [https://petstore3.swagger.io/api/v3/openapi.yaml](https://petstore3.swagger.io/api/v3/openapi.yaml).

Download the file in and save it as `petstore.yaml` with the following command in the terminal:

```bash
curl https://petstore3.swagger.io/api/v3/openapi.yaml --output petstore.yaml
```

## Validating the specification file

Let's validate the spec using both the Speakeasy CLI and OpenAPI Generator.

### Validation using Speakeasy

Run the following command in the terminal where the specification file is located:

```bash
speakeasy validate openapi -s petstore.yaml
```

The Speakeasy validator returns the following:

```bash
╭────────────╮╭───────────────╮╭────────────╮
│ Errors (0) ││ Warnings (10) ││ Hints (72) │
├────────────┴┘               └┴────────────┴────────────────────────────────────────────────────────────╮
│                                                                                                        │
│ │ Line 250: operation-success-response - operation `updatePetWithForm` must define at least a single   │
│ │ `2xx` or `3xx` response                                                                              │
│                                                                                                        │
│   Line 277: operation-success-response - operation `deletePet` must define at least a single `2xx` or  │
│   `3xx` response                                                                                       │
│                                                                                                        │
│   Line 413: operation-success-response - operation `deleteOrder` must define at least a single `2xx` o │
│   r                                                                                                    │
│   `3xx` response                                                                                       │
│                                                                                                        │
│   Line 437: operation-success-response - operation `createUser` must define at least a single `2xx` or │
│   `3xx` response                                                                                       │
│                                                                                                        │
│   Line 524: operation-success-response - operation `logoutUser` must define at least a single `2xx` or │
│   `3xx` response                                                                                       │
│                                                                                                        │
│   ••                                                                                                   │
└────────────────────────────────────────────────────────────────────────────────────────────────────────┘
 ←/→ switch tabs  ↑/↓ navigate  ↵ inspect  esc quit
```

The Speakeasy CLI validation result gives us a handy tool for switching between the errors, warnings, and hints tabs with the option to navigate through the results on each tab.

In this instance, Speakeasy generated ten warnings. Let's correct them before continuing.

Notice that some of the warnings contain a `default` response. For completeness, we'd like to explicitly return a `200` HTTP response. We'll make the following modifications in the `petstore.yaml` file.

When the `updatePetWithForm` operation executes successfully, we expect an HTTP `200` response with the updated `Pet` object to be returned.

Insert the following after `responses` on line 250:

```
"200":
  description: successful operation
  content:
    application/xml:
      schema:
        $ref: '#/components/schemas/Pet'
    application/json:
      schema:
        $ref: '#/components/schemas/Pet'
```

Similarly, following successful `createUser` and `updateUser` operations, we'd like to return an HTTP `200` response with a `User` object.

Add the following text to both operations below `responses`:

```
"200":
  description: successful operation
  content:
    application/xml:
      schema:
        $ref: '#/components/schemas/User'
    application/json:
      schema:
        $ref: '#/components/schemas/User'
```

Now we'll add the same response to four operations. Copy the following text:

```
"200":
  description: successful operation
```

Paste this response after `responses` for the following operations:

- `deletePet`
- `deleteOrder`
- `logoutUser`
- `deleteUser`

We are left with three warnings indicating potentially unused or orphaned objects and operations.

For unused objects, locate the following lines of code and delete them:

```
Customer:
  type: object
  properties:
    id:
      type: integer
      format: int64
      example: 100000
    username:
      type: string
      example: fehguy
    address:
      type: array
      xml:
        name: addresses
        wrapped: true
      items:
        $ref: '#/components/schemas/Address'
  xml:
    name: customer
Address:
  type: object
  properties:
    street:
      type: string
      example: 437 Lytton
    city:
      type: string
      example: Palo Alto
    state:
      type: string
      example: CA
    zip:
      type: string
      example: "94301"
  xml:
    name: address
```

To remove the unused request bodies, locate the following lines and delete them:

```
requestBodies:
    Pet:
      description: Pet object that needs to be added to the store
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/Pet'
        application/xml:
          schema:
            $ref: '#/components/schemas/Pet'
    UserArray:
      description: List of user object
      content:
        application/json:
          schema:
            type: array
            items:
              $ref: '#/components/schemas/User'
```

Now if you validate the file with the Speakeasy CLI, you'll notice there are no warnings:

```
╭────────────╮╭──────────────╮╭────────────╮
│ Errors (0) ││ Warnings (0) ││ Hints (75) │
├────────────┴┴──────────────┴┘            └─────────────────────────────────────────────────────────────╮
│                                                                                                        │
│ │ Line 51: missing-examples - Missing example for requestBody. Consider adding an example              │
│                                                                                                        │
│   Line 54: missing-examples - Missing example for requestBody. Consider adding an example              │
│                                                                                                        │
│   Line 57: missing-examples - Missing example for requestBody. Consider adding an example              │
│                                                                                                        │
│   Line 65: missing-examples - Missing example for responses. Consider adding an example                │
│                                                                                                        │
│   Line 68: missing-examples - Missing example for responses. Consider adding an example                │
│                                                                                                        │
│   •••••••••••••••                                                                                      │
└────────────────────────────────────────────────────────────────────────────────────────────────────────┘

 ←/→ switch tabs  ↑/↓ navigate  ↵ inspect  esc quit
```

### Validation using OpenAPI Generator

To validate the `petstore.yaml` specification file with OpenAPI Generator, run the following command in the terminal:

```bash
openapi-generator validate -i petstore.yaml
```

The OpenAPI Generator returns the following response, indicating no issues detected.

```bash
Validating spec (petstore.yaml)
No validation issues detected.
```

Now that we have made the `petstore.yaml` file more complete by fixing the warnings, let's use it to create SDKs.

## Creating SDKs

We'll create Java SDKs using Speakeasy and OpenAPI Generator and then compare them.

### Creating an SDK with Speakeasy

Create a Java SDK from the `petstore.yaml` specification file using Speakeasy by running the following command in the terminal:

```bash
# Generate Petstore SDK using Speakeasy java generator
speakeasy generate sdk \
    --schema petstore.yaml \
    --lang java \
    --out ./sdks/petstore-sdk-java-speakeasy/
```

The generator will return some logging results while the SDK is being created and a success indicator on completion.

```bash
SDK for java generated successfully ✓
```

### Creating an SDK with OpenAPI Generator

Run the following command in the terminal to generate a Java SDK using OpenAPI Generator:

```bash
# Generate Petstore SDK using python generator
openapi-generator generate \
  --input-spec petstore.yaml \
  --generator-name java \
  --output ./sdks/petstore-sdk-java \
  --additional-properties=packageName=petstore_sdk,projectName=petstore-sdk-java
```

The generator returns various logs and finally a successful generation message.

```bash
################################################################################
# Thanks for using OpenAPI Generator.                                          #
# Please consider donation to help us maintain this project 🙏                 #
# https://opencollective.com/openapi_generator/donate                          #
################################################################################
```

## SDK code compared: Project structure

Let's compare the two project structures by printing a tree structure of each SDK directory's `src` folder.

Run the following command to get the Speakeasy SDK structure:

```bash
cd petstore-sdk-java-speakeasy/src/main/java
tree
```

The results of the project structure are displayed as follows:

```bash
||____org
| |____openapis
| | |____openapi
| | | |____Pet.java
| | | |____SecuritySource.java
| | | |____User.java
| | | |____utils
| | | | |____SpeakeasyMetadata.java
| | | | |____SecurityMetadata.java
| | | | |____LazySingletonValue.java
| | | | |____RetryConfig.java
| | | | |____TypedObject.java
| | | | |____BigDecimalString.java
| | | | |____Response.java
| | | | |____OneOfDeserializer.java
| | | | |____MultipartFormMetadata.java
| | | | |____JSON.java
| | | | |____Hooks.java
| | | | |____Deserializers.java
| | | | |____QueryParameters.java
| | | | |____Utils.java
| | | | |____QueryParamsMetadata.java
| | | | |____Retries.java
| | | | |____RequestBody.java
| | | | |____RequestMetadata.java
| | | | |____Security.java
| | | | |____Metadata.java
| | | | |____SpeakeasyHTTPClient.java
| | | | |____BackoffStrategy.java
| | | | |____SerializedBody.java
| | | | |____Types.java
| | | | |____HTTPClient.java
| | | | |____Options.java
| | | | |____HeaderMetadata.java
| | | | |____PathParamsMetadata.java
| | | | |____FormMetadata.java
| | | | |____Hook.java
| | | | |____HTTPRequest.java
| | | | |____BigIntegerString.java
| | | |____models
| | | | |____operations
| | | | | |____DeletePetRequest.java
| | | | | |____GetPetByIdSecurity.java
| | | | | |____UpdateUserFormResponse.java
| | | | | |____CreateUserFormResponse.java
| | | | | |____LoginUserRequestBuilder.java
| | | | | |____UpdateUserRawRequestBuilder.java
| | | | | |____DeletePetResponse.java
| | | | | |____GetOrderByIdRequestBuilder.java
| | | | | |____SDKMethodInterfaces.java
| | | | | |____UpdateUserJsonRequestBuilder.java
| | | | | |____Status.java
| | | | | |____FindPetsByStatusRequest.java
| | | | | |____DeleteOrderRequestBuilder.java
| | | | | |____CreateUserJsonResponse.java
| | | | | |____UpdateUserJsonResponse.java
| | | | | |____DeleteOrderRequest.java
| | | | | |____UpdateUserRawResponse.java
| | | | | |____UpdatePetFormResponse.java
| | | | | |____PlaceOrderJsonRequestBuilder.java
| | | | | |____AddPetFormResponse.java
| | | | | |____PlaceOrderRawRequestBuilder.java
| | | | | |____UpdatePetJsonRequestBuilder.java
| | | | | |____FindPetsByStatusRequestBuilder.java
| | | | | |____CreateUserRawRequestBuilder.java
| | | | | |____LoginUserRequest.java
| | | | | |____FindPetsByTagsRequestBuilder.java
| | | | | |____FindPetsByTagsRequest.java
| | | | | |____LogoutUserResponse.java
| | | | | |____FindPetsByStatusResponse.java
| | | | | |____DeleteUserRequest.java
| | | | | |____UpdateUserRawRequest.java
| | | | | |____AddPetFormRequestBuilder.java
| | | | | |____GetInventorySecurity.java
| | | | | |____DeleteUserRequestBuilder.java
| | | | | |____CreateUsersWithListInputResponse.java
| | | | | |____DeleteOrderResponse.java
| | | | | |____UpdateUserJsonRequest.java
| | | | | |____GetPetByIdRequestBuilder.java
| | | | | |____CreateUserFormRequestBuilder.java
| | | | | |____CreateUserRawResponse.java
| | | | | |____AddPetJsonResponse.java
| | | | | |____UpdatePetJsonResponse.java
| | | | | |____GetOrderByIdResponse.java
| | | | | |____UploadFileResponse.java
| | | | | |____DeletePetRequestBuilder.java
| | | | | |____UpdatePetWithFormResponse.java
| | | | | |____PlaceOrderJsonResponse.java
| | | | | |____UpdateUserFormRequestBuilder.java
| | | | | |____LoginUserResponse.java
| | | | | |____UploadFileRequest.java
| | | | | |____LogoutUserRequestBuilder.java
| | | | | |____FindPetsByTagsResponse.java
| | | | | |____GetPetByIdResponse.java
| | | | | |____UpdatePetWithFormRequest.java
| | | | | |____GetPetByIdRequest.java
| | | | | |____UpdatePetRawResponse.java
| | | | | |____CreateUsersWithListInputRequestBuilder.java
| | | | | |____AddPetRawResponse.java
| | | | | |____PlaceOrderFormResponse.java
| | | | | |____GetUserByNameResponse.java
| | | | | |____UpdatePetWithFormRequestBuilder.java
| | | | | |____GetOrderByIdRequest.java
| | | | | |____GetInventoryResponse.java
| | | | | |____PlaceOrderFormRequestBuilder.java
| | | | | |____UploadFileRequestBuilder.java
| | | | | |____GetInventoryRequestBuilder.java
| | | | | |____UpdatePetFormRequestBuilder.java
| | | | | |____UpdatePetRawRequestBuilder.java
| | | | | |____DeleteUserResponse.java
| | | | | |____CreateUserJsonRequestBuilder.java
| | | | | |____GetUserByNameRequest.java
| | | | | |____AddPetJsonRequestBuilder.java
| | | | | |____AddPetRawRequestBuilder.java
| | | | | |____GetUserByNameRequestBuilder.java
| | | | | |____UpdateUserFormRequest.java
| | | | | |____PlaceOrderRawResponse.java
| | | | |____components
| | | | | |____Order.java
| | | | | |____Status.java
| | | | | |____Tag.java
| | | | | |____ApiResponse.java
| | | | | |____Pet.java
| | | | | |____OrderStatus.java
| | | | | |____Category.java
| | | | | |____User.java
| | | | | |____Security.java
| | | | |____errors
| | | | | |____SDKError.java
| | | |____Store.java
| | | |____SDKConfiguration.java
| | | |____SDK.java
```

Now run the following command for the OpenAPI Generator SDK folder:

```bash
cd petstore-sdk-java/src/main/java
tree
```

The OpenAPI Generator SDK structure looks like this:

```bash
|____org
| |____openapitools
| | |____client
| | | |____ApiClient.java
| | | |____ApiException.java
| | | |____ProgressResponseBody.java
| | | |____Pair.java
| | | |____GzipRequestInterceptor.java
| | | |____auth
| | | | |____RetryingOAuth.java
| | | | |____HttpBasicAuth.java
| | | | |____ApiKeyAuth.java
| | | | |____OAuth.java
| | | | |____OAuthOkHttpClient.java
| | | | |____Authentication.java
| | | | |____OAuthFlow.java
| | | | |____HttpBearerAuth.java
| | | |____ApiResponse.java
| | | |____JSON.java
| | | |____ServerVariable.java
| | | |____StringUtil.java
| | | |____Configuration.java
| | | |____ServerConfiguration.java
| | | |____model
| | | | |____Order.java
| | | | |____ModelApiResponse.java
| | | | |____Customer.java
| | | | |____Tag.java
| | | | |____Pet.java
| | | | |____AbstractOpenApiSchema.java
| | | | |____Category.java
| | | | |____User.java
| | | | |____Address.java
| | | |____api
| | | | |____PetApi.java
| | | | |____UserApi.java
| | | | |____StoreApi.java
| | | |____ApiCallback.java
| | | |____ProgressRequestBody.java
```

The Speakeasy-created SDK contains more generated files than the SDK from OpenAPI Generator, which is partly due to the Speakeasy SDK being less dependent on third-party libraries.

## Model and usage

Let's take a look at how Speakeasy generates model classes for creating and updating a `Pet` object.

```java
Pet req = Pet.builder()
    .name("Snoopie")
    .photoUrls(java.util.List.of(
            "https://some_url.com/snoopie1.jpg"))
    .id(1)
    .category(Category.builder()
        .id(1)
        .name("Dogs")
        .build())
    .tags(java.util.List.of(
        Tag.builder()
            .build()))
    .status(Status.AVAILABLE)
    .build();

UpdatePetJsonResponse res = sdk.pet().updatePetJson()
    .request(req)
    .call();

if (res.body().isPresent()) {
    // handle response
}
```

The Speakeasy model follows the builder pattern to construct objects with many optional parameters, making the code more readable and easier to use.

Let's see how the OpenAPI Generator SDK performs the same operation:

```java
    ApiClient defaultClient = Configuration.getDefaultApiClient();
    defaultClient.setBasePath("/api/v3");

    // Configure OAuth2 access token for authorization: petstore_auth
    OAuth petstore_auth = (OAuth) defaultClient.getAuthentication("petstore_auth");
    petstore_auth.setAccessToken("YOUR ACCESS TOKEN");

    PetApi apiInstance = new PetApi(defaultClient);
    Pet pet = new Pet(); // Pet | Create a new pet in the store
    pet.setName("Snoopie");
    try {
      Pet result = apiInstance.addPet(pet);
      System.out.println(result);
    } catch (ApiException e) {
      System.err.println("Exception when calling PetApi#addPet");
      System.err.println("Status code: " + e.getCode());
      System.err.println("Reason: " + e.getResponseBody());
      System.err.println("Response headers: " + e.getResponseHeaders());
      e.printStackTrace();
    }
```

The OpenAPI Generator SDK focuses on manual serialization and deserialization using Gson, providing setter methods for individual properties of the `Pet` object.

The two SDKs have distinctly different approaches to handling object creation, validation, and JSON serialization, with the Speakeasy-generated SDK emphasizing fluid and declarative object creation using modern patterns and annotations for handling JSON data.

Let's look more closely at how the `Pet` model attributes are declared in each SDK.

Notice how the Speakeasy SDK uses Jackson annotations for the JSON serialization and deserialization of objects.

```java
public class Pet {
    @JsonInclude(Include.NON_ABSENT)
    @JsonProperty("id")
    @SpeakeasyMetadata("form:name=id")
    private Optional<? extends Long> id;

    @JsonProperty("name")
    @SpeakeasyMetadata("form:name=name")
    private String name;

    @JsonInclude(Include.NON_ABSENT)
    @JsonProperty("category")
    @SpeakeasyMetadata("form:name=x")
    private Optional<? extends Category> category;

    @JsonProperty("photoUrls")
    @SpeakeasyMetadata("form:name=photoUrls")
    private java.util.List<String> photoUrls;

    //Rest of Pet.java ....
```

Compare this to the OpenAPI Generator SDK `Pet` model that uses Gson annotations:

```java
public class Pet {
  public static final String SERIALIZED_NAME_ID = "id";
  @SerializedName(SERIALIZED_NAME_ID)
  private Long id;

  public static final String SERIALIZED_NAME_NAME = "name";
  @SerializedName(SERIALIZED_NAME_NAME)
  private String name;

  public static final String SERIALIZED_NAME_CATEGORY = "category";
  @SerializedName(SERIALIZED_NAME_CATEGORY)
  private Category category;

  public static final String SERIALIZED_NAME_PHOTO_URLS = "photoUrls";
  @SerializedName(SERIALIZED_NAME_PHOTO_URLS)
  private List<String> photoUrls = new ArrayList<>();

  //Rest of Pet.java ....
```

Let's take a moment and identify what the differences are between the Jackson vs GSON libraries and what features each has.

The Gson JSON library is easy to use and implement and well-suited to smaller projects. It provides an API for JSON support but doesn't support extensive configuration options.

On the other hand, Jackson is designed to be more configurable and flexible when it comes to JSON serialization and deserialization. Jackson is the standard JSON-support library in many popular Java frameworks (like Spring, Jersey, and RESTEasy), it's widely used in the Java community, and it's actively supported and frequently updated. Jackson is also generally faster and offers extensive configuration options.

The use of the Jackson library in the Speakeasy-generated SDK provides us with a firm foundation for building fast and scalable applications.

## HTTP communication

Java 11 (the minimum version supported by Speakeasy) significantly improved HTTP communication with the java.net.http package providing a powerful `HTTPClient` class for enhanced HTTP communication.

Given the OpenAPI Generator SDK is Java 8 compatible, we suspected it might use some third-party libraries. On inspection, our suspicions were confirmed: The SDK uses a third-party library to handle HTTP communication.

Take a look at the following method to add a new `Pet` object (from the `PetApi.java` file):

```java
  public Pet addPet(Pet pet) throws ApiException {
      ApiResponse<Pet> localVarResp = addPetWithHttpInfo(pet);
      return localVarResp.getData();
  }
```

The `addPet` method in turn calls the `addPetWithHttpInfo(pet)` method:

```java
  public ApiResponse<Pet> addPetWithHttpInfo(Pet pet) throws ApiException {
      okhttp3.Call localVarCall = addPetValidateBeforeCall(pet, null);
      Type localVarReturnType = new TypeToken<Pet>(){}.getType();
      return localVarApiClient.execute(localVarCall, localVarReturnType);
  }
```

Note how the method uses the `okhttp3.Call` object.

We examined the dependencies configured in the `build.gradle` file and discovered the `okhttp` dependency:

```groovy
implementation 'com.squareup.okhttp3:okhttp:4.10.0'
```

Having established that the OpenAPI Generator SDK uses the OkHttp library, we were curious to see how the Speakeasy-generated SDK handles HTTP communication.

Take a look at this extract from the `addPetJson` method in the `Pet.java` file of the Speakeasy SDK:

```java
HTTPRequest req = new HTTPRequest();
req.setMethod("POST");
req.setURL(url);
Object _convertedRequest = Utils.convertToShape(request, Utils.JsonShape.DEFAULT,
    new TypeReference<org.openapis.openapi.models.components.Pet>() {});
SerializedBody serializedRequestBody = org.openapis.openapi.utils.Utils.serializeRequestBody(
        _convertedRequest, "request", "json", false);
if (serializedRequestBody == null) {
    throw new Exception("Request body is required");
}
req.setBody(serializedRequestBody);

req.addHeader("Accept", "application/json;q=1, application/xml;q=0");
req.addHeader("user-agent", this.sdkConfiguration.userAgent);

HTTPClient client = org.openapis.openapi.utils.Utils.configureSecurityClient(
        this.sdkConfiguration.defaultClient, this.sdkConfiguration.securitySource.getSecurity());

HttpResponse<InputStream> httpRes = client.send(req);
```

This method uses `HTTPClient`, `HTTPRequest`, and `HTTPResponse` objects. If we look at the import statements, we can see that these objects are generated from the following classes:

```java
import org.openapis.openapi.utils.HTTPClient;
import org.openapis.openapi.utils.HTTPRequest;
import java.net.http.HttpResponse;
```

The `HTTPClient` and `HTTPRequest` interfaces are both generated by Speakeasy.

We can see the `HTTPClient` interface implemented in `SpeakeasyHTTPClient.java` to establish the HTTP communication method:

```java
import org.openapis.openapi.utils.HTTPClient;

import java.io.IOException;
import java.net.URISyntaxException;
import java.net.http.HttpClient;
import java.net.http.HttpRequest;
import java.net.http.HttpResponse;
import java.io.InputStream;

public class SpeakeasyHTTPClient implements HTTPClient {

    @Override
    public HttpResponse<InputStream> send(HttpRequest request)
            throws IOException, InterruptedException, URISyntaxException {
        HttpClient client = HttpClient.newHttpClient();
        return client.send(request, HttpResponse.BodyHandlers.ofInputStream());
    }
}
```

The Speakeasy SDK uses the Java HTTP APIs that were introduced in Java 11. Some of the benefits of using the built-in Java HTTP APIs are:

- **Standardization:** By using the HTTP Client API supported in Java 11, the SDK uses the standards provided and supported by modern Java SDK providers. The `HttpClient` class integrates more easily with the other Java APIs in the Java SDK.
- **Asynchronous support:** Asynchronous HTTP communication is not available in Java 8, making it harder to build scalable applications. The HTTP Client API asynchronous HTTP communication available in Java 11 provides a CompletableFuture object immediately after calling the API, which gives developers more control.
- **Performance and efficiency:** The HTTP Client is created using a builder and allows for configuring client-specific settings, such as the preferred protocol version (HTTP/1.1 or HTTP/2). It also supports Observable APIs.
- **Security, stability, and long-term support:** As a standard Java API, the HTTP Client is more stable and secure, and benefits from the long-term support cycles of new Java versions.

## Retries

The SDK created by Speakeasy can automatically retry requests.

You can enable retries globally or per request using the `x-speakeasy-retries` extension in your OpenAPI specification document.

Let's add the `x-speakeasy-retries` extension to the `addPet` method in the `petstore.yaml` file:

```yaml
# ...
paths:
  /pet:
    # ...
    post:
      #...
      operationId: addPet
      x-speakeasy-retries:
        strategy: backoff
        backoff:
          initialInterval: 500        # 500 milliseconds
          maxInterval: 60000          # 60 seconds
          maxElapsedTime: 3600000     # 5 minutes
          exponent: 1.5
        statusCodes:
          - 5XX
        retryConnectionErrors: true
```

If you re-generate the SDK now, the new retry configuration will be included.

For more information on configuring retries in your SDK, take a look at the [retries documentation](/docs/customize-sdks/retries).

## SDK dependencies

Let's compare dependencies in the two SDKs.

Here are the OpenAPI Generator SDK dependencies in `build.gradle`:

```groovy
implementation 'io.swagger:swagger-annotations:1.6.8'
implementation "com.google.code.findbugs:jsr305:3.0.2"
implementation 'com.squareup.okhttp3:okhttp:4.10.0'
implementation 'com.squareup.okhttp3:logging-interceptor:4.10.0'
implementation 'com.google.code.gson:gson:2.9.1'
implementation 'io.gsonfire:gson-fire:1.9.0'
implementation 'javax.ws.rs:jsr311-api:1.1.1'
implementation 'javax.ws.rs:javax.ws.rs-api:2.1.1'
implementation 'org.openapitools:jackson-databind-nullable:0.2.6'
implementation group: 'org.apache.oltu.oauth2', name: 'org.apache.oltu.oauth2.client', version: '1.0.2'
implementation group: 'org.apache.commons', name: 'commons-lang3', version: '3.12.0'
implementation "jakarta.annotation:jakarta.annotation-api:$jakarta_annotation_version"
testImplementation 'org.junit.jupiter:junit-jupiter-api:5.9.1'
testImplementation 'org.mockito:mockito-core:3.12.4'
testRuntimeOnly 'org.junit.jupiter:junit-jupiter-engine:5.9.1'
```

Here are the Speakeasy SDK dependencies from `build.gradle`:

```
implementation 'com.fasterxml.jackson.core:jackson-databind:2.16.2'
implementation 'com.fasterxml.jackson.datatype:jackson-datatype-jsr310:2.16.2'
implementation 'com.fasterxml.jackson.datatype:jackson-datatype-jdk8:2.16.2'
implementation 'org.openapitools:jackson-databind-nullable:0.2.6'
implementation 'org.apache.httpcomponents:httpclient:4.5.14'
implementation 'org.apache.httpcomponents:httpmime:4.5.14'
implementation 'com.jayway.jsonpath:json-path:2.9.0'
implementation 'commons-io:commons-io:2.15.1'
```

The OpenAPI Generator SDK implements more libraries than the Speakeasy SDK, possibly due to the compatibility requirements and limitations of Java 8. Depending on fewer third-party implementations provides the Speakeasy SDK with some advantages:

- **Less maintenance:** Projects with fewer dependencies have a lower maintenance overhead and less versioning to keep track of long term.
- **Reduced risk of dependency-related issues:** Third-party dependencies increase the risk of bugs and security failures that depend on the third-party provider to fix. A security flaw in a third-party dependency makes your application vulnerable.
- **Improved performance:** Code generally works better in standard Java APIs as they have been through rigorous testing and QA cycles before being made available to the public.
- **Easier adoption:** Projects tend to more readily accept SDK builds that rely on fewer third-party dependencies, due to strict policies regarding the use and management of these dependencies.

## Handling non-nullable fields

Let's see how Speakeasy's enhanced null safety and Optional support work on fields in the `Pet` object.

Take a look at the following declaration taken from the `Pet` object in the Speakeasy SDK `org.openapis.openapi.models.components.Pet.java` file:

```java
    @JsonInclude(Include.NON_ABSENT)
    @JsonProperty("status")
    @SpeakeasyMetadata("form:name=status")
    private Optional<? extends Status> status;
```

Note that the `@JsonInclude` annotation indicates it is `NON-ABSENT` and the `Optional` class is used. The status field here is an enum (`Status`) wrapped in the `Optional` class.

Let's examine the `Status` enum object:

```java
public enum Status {
    AVAILABLE("available"),
    PENDING("pending"),
    SOLD("sold");

    @JsonValue
    private final String value;

    private Status(String value) {
        this.value = value;
    }

    public String value() {
        return value;
    }
}
```

Let's compare the Speakeasy SDK `status` field declaration to the same field in the OpenAPI Generator SDK. The following declaration is taken from the `org.openapitools.client.model.Pet.java` file:

```java
public enum StatusEnum {
    AVAILABLE("available"),

    PENDING("pending"),

    SOLD("sold");

    private String value;

    StatusEnum(String value) {
      this.value = value;
    }

    public String getValue() {
      return value;
    }

    @Override
    public String toString() {
      return String.valueOf(value);
    }

    public static StatusEnum fromValue(String value) {
      for (StatusEnum b : StatusEnum.values()) {
        if (b.value.equals(value)) {
          return b;
        }
      }
      throw new IllegalArgumentException("Unexpected value '" + value + "'");
    }

    public static class Adapter extends TypeAdapter<StatusEnum> {
      @Override
      public void write(final JsonWriter jsonWriter, final StatusEnum enumeration) throws IOException {
        jsonWriter.value(enumeration.getValue());
      }

      @Override
      public StatusEnum read(final JsonReader jsonReader) throws IOException {
        String value =  jsonReader.nextString();
        return StatusEnum.fromValue(value);
      }
    }

    public static void validateJsonElement(JsonElement jsonElement) throws IOException {
      String value = jsonElement.getAsString();
      StatusEnum.fromValue(value);
    }
  }

  public static final String SERIALIZED_NAME_STATUS = "status";
  @SerializedName(SERIALIZED_NAME_STATUS)
  private StatusEnum status;
```

At first glance, the OpenAPI Generator SDK also uses an enum approach, representing the `status` field as an enum called `StatusEnum` with three possible values: `AVAILABLE`, `PENDING`, and `SOLD`. A lot of code is generated around this field to handle the enum, but the `Pet` object does not indicate that the OpenAPI Generator SDK `status` field is non-nullable at this point.

In contrast, Speakeasy uses a direct approach to non-nullable fields. The Speakeasy SDK also uses a `Status` enum for the `status` field, but it is wrapped in the `Optional` class provided by the Java standard APIs.

Declaring the `status` field as the `Status` type wrapped in the `Optional` class has some benefits to the developer:

- It helps to avoid possible `NullPointerException` errors when accessing a `null` value.
- It provides a modern way for developers to identify the absence of a value using the `isPresent()` method from the `Optional` class API and exposes other usable methods like `orElse()` and `orElseThrow()`.
- It clearly states the intent and use of the code, which helps to reduce bugs in the long run.

Let's see how client validation works by passing a `null` value to the `findPetsByStatus()` method, which expects `Optional<? extends Status> status`. We create the following builder pattern for a new request:

```java
FindPetsByStatusResponse res = sdk.pet().findPetsByStatus(null);

if (res.body().isPresent()) {
    // handle response
}
```

When we execute this bit of code, we get the following exception:

```
java.lang.IllegalArgumentException: status cannot be null
	at org.openapis.openapi.utils.Utils.checkNotNull(Utils.java:469)
	at org.openapis.openapi.models.operations.FindPetsByStatusRequest$Builder.status(FindPetsByStatusRequest.java:108)
	at org.openapis.openapi.Pet.findPetsByStatus(Pet.java:503)
```

The same exception is generated if we remove the `name` field from the `builder` declaration of a new `Pet` object:

```java
Pet req = Pet.builder()
    .id(1)
    .photoUrls(java.util.List.of(
        "https://hips.hearstapps.com/hmg-prod/images/dog-puppy-on-garden-royalty-free-image-1586966191.jpg?crop=1xw:0.74975xh;center,top&resize=1200:*"))
    .category(Category.builder()
        .id(1)
        .name("Dogs")
        .build())
    .tags(java.util.List.of(
        Tag.builder()
                .build()))
    .build();
```

When we execute the above code, we get the exception:

```bash
java.lang.IllegalArgumentException: name cannot be null
 at org.openapis.openapi.utils.Utils.checkNotNull(Utils.java:469)
 at org.openapis.openapi.models.components.Pet.<init>(Pet.java:62)
 at org.openapis.openapi.models.components.Pet$Builder.build(Pet.java:297)
 at org.openapis.openapi.Test.main(Test.java:40)
```

The null check validation generates this exception when the `Pet` object is initiated and certain values are null. If we look at the class constructor in our `Pet.java` model in the Speakeasy SDK:

```java
public Pet(
            @JsonProperty("id") Optional<? extends Long> id,
            @JsonProperty("name") String name,
            @JsonProperty("category") Optional<? extends Category> category,
            @JsonProperty("photoUrls") java.util.List<String> photoUrls,
            @JsonProperty("tags") Optional<? extends java.util.List<Tag>> tags,
            @JsonProperty("status") Optional<? extends Status> status) {
        Utils.checkNotNull(id, "id");
        Utils.checkNotNull(name, "name");
        Utils.checkNotNull(category, "category");
        Utils.checkNotNull(photoUrls, "photoUrls");
        Utils.checkNotNull(tags, "tags");
        Utils.checkNotNull(status, "status");
        this.id = id;
        this.name = name;
        this.category = category;
        this.photoUrls = photoUrls;
        this.tags = tags;
        this.status = status;
    }
```

We can see that the exception is generated in the `Utils.checkNotNull()` method:

```java
public static <T> T checkNotNull(T object, String name) {
    if (object == null) {
        // IAE better than NPE in this use-case (NPE can suggest internal troubles)
        throw new IllegalArgumentException(name + " cannot be null");
    }
    return object;
}
```

Therefore, if we omit the `name` field or pass a `null` value in the `findPetByStatus()` method, an exception is generated by the check null validation because the `name` and `status` fields explicitly set to `null` in this case.

Let's try creating a `Pet` object without a `name` field using the OpenAPI Generator SDK:

```java
PetApi apiInstance = new PetApi(defaultClient);
ArrayList<String> snoopyPhotos = new ArrayList<>();
snoopyPhotos.add("https://Snoopy.some_photo_platform.com");

Pet pet = new Pet(); // Pet | Create a new pet in the store
pet.setPhotoUrls(snoopyPhotos);
try {
    Pet result = apiInstance.addPet(pet);
} catch (ApiException e) {
    //handle exception
}
```

When we execute the above code, we get a mixed result. The following exception is generated:

```
Exception in thread "main" java.lang.IllegalArgumentException: The required field `name` is not found in the JSON string: {"id":9223372036854775807,"photoUrls":["https://Snoopy.some_photo_platform.com"],"tags":[]}
	at org.openapitools.client.model.Pet.validateJsonElement(Pet.java:361)
	at org.openapitools.client.model.Pet$CustomTypeAdapterFactory$1.read(Pet.java:422)
	at org.openapitools.client.model.Pet$CustomTypeAdapterFactory$1.read(Pet.java:412)
	at com.google.gson.TypeAdapter$1.read(TypeAdapter.java:204)
  ....
```

It appears that the `Pet` object was created on the API, but the call failed retrospectively on the client side. The exception was generated by the SDK's validation process, which checks the JSON response received from the API. You can see the created object in the JSON response included in the exception:

```json
{"id":9223372036854775807,"photoUrls":["https://Snoopy.some_photo_platform.com"],"tags":[]}
```

Validation failed because the name was missing from the JSON string. This validation method is not helpful, as it checks the response after the API call rather than before the request is sent. Consequently, an invalid object was created on the API and the client process failed.

Speakeasy's proactive client validation and method of handling non-nullable fields with the use of the `Optional` class is elegant. Code that is easy to read, understand, and use, and that also helps to build null safety is essential for building robust, maintainable SDKs.

## Generated documentation

Both Speakeasy and OpenAPI Generator generate SDK documentation for the generated code.

Each generator creates a README file to help users get started with the SDK. The OpenAPI Generator README outlines the SDK's compatibility with Java, Maven, and Gradle versions and identifies the available API routes. The Speakeasy README file is more complete and documents more examples.

Speakeasy also generates additional documentation in the `docs` directory, including more detailed explanations of the models and operations; examples of creating, updating, and searching objects; error handling; and guidance on handling exceptions specific to the OpenAPI specification file. A handy "Getting Started" section details how to build the SDK.

In general, we found the Speakeasy documentation to be more complete and helpful. We tested many API call examples from the documentation, and conclude that the Speakeasy docs are production-ready.

## Supported Java versions

The Speakeasy-generated SDK supports Java 11+ environments, and the SDK generated by OpenAPI Generator supports Java 8+.

While the OpenAPI SDK supports more codebases including those still using Java 8, the Speakeasy SDK leverages the enhancements provided by Java 11. Java 8 was released in March 2014, and was the most widely used version of Java until version 11 was released in September 2019.

In 2023, New Relic reported that Java 11 is used in around 56% of production applications, while Java 8 is still in use at around 33%. Both versions are important long-term support (LTS) versions.

## Summary

We've seen how easy it is to generate a powerful, idiomatic SDK for Java using Speakeasy.

If you're building an API that developers rely on and would like to publish full-featured Java SDKs that follow best practices, we highly recommend giving the Speakeasy SDK generator a try.

For more customization options for your SDK using the Speakeasy generator, please see the [Speakeasy documentation](/docs/customize-sdks).

Join our Slack community to let us know how we can improve our Java SDK generator or suggest features.


 This is the content for the doc docs/languages/java/param-encoding.mdx 

 ---
title: "Parameter encoding"
description: "How to allow reserved characters in path parameters to appear unencoded in request URLs."
slug: "/parameter-encoding/"
---

# Parameter encoding

## The `allowReserved` setting

OpenAPI 3.x supports the `allowReserved` setting, which applies exclusively to query parameters. This allows reserved characters, such as `:/?#[]@!$&'()*+,;=`, to appear unencoded in request URLs.

OpenAPI 3.x does not support the `allowedReserved` setting for path parameters, although API owners may occasionally want to model this behavior. Consider a URL with a path parameter `item`, such as `https://stuff.com/store/{item}`. The API might be designed to accept values like `most-popular` or `book/most-popular` for `{item}`, where the `/` character remains unencoded, resulting in a URL like `https://stuff.com/store/book/most-popular`.

The Speakeasy OpenAPI extension `x-speakeasy-param-encoding-override: allowReserved` can be applied to a path parameter to allow reserved characters, such as `:/?#[]@!$&'()*+,;=`, to appear unencoded in the URL.

Here's an example demonstrating the use of the path parameter encoding extension:

```yaml
  /store/{item}:
    get:
      operationId: item
      parameters:
        - name: item
          in: path
          schema:
            type: string
            example: most-popular
          required: true
          x-speakeasy-param-encoding-override: allowReserved
      responses:
        "200":
          ...
```

As of November 2024, the `x-speakeasy-param-encoding-override` extension is supported for Java. Let us know if you need support in another language.




 This is the content for the doc docs/languages/maturity.mdx 

 ---
description: "Explore Speakeasy's concepts for code generation and the types of support available for generated targets."
sidebar_position: 4
slug: /code-generation-concepts/
sidebar_label: Language Maturity
---

# Language Maturity Concepts

Speakeasy creates and maintains SDKs (generation targets) for your API. This page explains the terminology used to describe these generation targets.

## Maturity Levels


| Maturity Level         | Description                                                                                                                      |
|------------------------|----------------------------------------------------------------------------------------------------------------------------------|
| **Alpha**              | An early preview of upcoming features intended for gathering feedback. Alpha versions are less complete and likely to be unstable, with frequent updates and significant changes expected. |
| **Beta**               | A pre-release version that includes many features of GA but is still subject to significant modifications based on user feedback. The interface is considered stable enough for general usage and wide coverage of OpenAPI is available. |
| **General Availability (GA)** | A fully supported release that includes all functionalities altering the type interface from OpenAPI Specification keywords (for example, [`oneOf`](/docs/customize-sdks/oneof-schemas), [`anyOf`](/openapi/schemas/objects/polymorphism), [`allOf`](/openapi/schemas/objects/polymorphism), [`const`](/docs/customize-sdks/types#const), and [`default`](/docs/customize-sdks/types#default)). GA versions follow semantic versioning (SemVer) and maintain interface stability for non-breaking OpenAPI changes unless you opt into such changes. |

## Feature Support Levels

Feature support levels indicate the extent of additional functionalities provided.

| Feature Support Level | Description                                                                                                                                                                                                                              |
|-----------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **Gold**              | Indicates full feature support, including all opt-in enhancements such as [Pagination](/docs/customize-sdks/pagination), [Retries](/docs/customize-sdks/retries), [Server Templates](/docs/customize-sdks/servers), [Hooks](/docs/customize/code/sdk-hooks), [OAuth 2.0 Client Credentials](/docs/customize/authentication/oauth#client-credentials-flow), and more. A target can be in Beta and still have Gold-level feature support. |
| **Level 2**           | Extends the type interface by synthesizing multiple API calls into single interactions. This is achieved using specified [links](https://spec.openapis.org/oas/v3.1.0#link-object) (hyperlinks between API operations as defined by the OpenAPI Specification), [Arazzo workflows](https://github.com/OAI/Arazzo-Specification/blob/main/versions/1.0.0.md) (predefined sequences of API calls), and [Speakeasy extensions](/docs/terraform) (custom enhancements for better API integration). |
| **Level 1**           | Provides essential functionalities and basic support without the advanced features found in Gold or Level 2. Targets with Standard support are stable and reliable but do not include all opt-in enhancements or extended interface capabilities. |

## Target Language Support

| Target      | Maturity Level | Feature Support Level |
|-------------|----------------|-----------------------|
| [TypeScript](/docs/languages/typescript/methodology-ts) | GA | Gold |
| [Go](/docs/languages/golang/methodology-go) | GA | Gold |
| [Java](/docs/languages/java/methodology-java) | GA | Gold |
| [Python - Pydantic & Async](/docs/languages/python/methodology-python) | GA | Gold |
| [C#](/docs/languages/csharp/methodology-csharp) | GA | Gold |
| [Terraform](/docs/create-terraform) | GA | Level 2 |
| [Unity](/docs/languages/unity/methodology-unity) | Beta | Level 1 |
| [PHP](/docs/languages/php/methodology-php) | Beta | Level 1 |
| [Swift](/docs/languages/swift/methodology-swift) | Alpha | Level 1 |
| [Ruby](/docs/languages/ruby/methodology-ruby) | Alpha | Level 1 |
| Postman | Alpha | Level 1 |

## Deprecated Generation Targets

* TypeScript Beta (v1)
* Java Beta (v1)


 This is the content for the doc docs/languages/philosophy.mdx 

 ---
slug: /sdk-design/methodology/
title: Our Design Philosophy
description: "Learn about Speakeasy's SDK design methodology, which prioritizes minimal dependencies, type safety, and easy debugging."
---

import { IconGrid } from "~/features/shared/recipes";
import { SupportedLanguagesData } from "~/data/shared/supportedLanguages";
import { OSSComparisonData } from "~/data/shared/ossComparisons";

# Our Design Philosophy

SDKs are a critical interface for an API. We therefore put a lot of thought into what the developer experience should be:

- **Type safe** - The SDKs we generate are fully typed, ensuring customers can catch errors early and often.
- **Human readable** - The SDKs we generate are easy for developers to read and debug in the customer's IDE. We avoid convoluted abstractions.
- **Batteries-included** - The SDKs we generate include everything from telemetry and retries to pagination.
- **Fault tolerant** - Our generator is easy to use and outputs usable SDKs wherever possible. If we can't output a working SDK, we will validate your OpenAPI spec and alert you of the problems.
- **Beyond OpenAPI** - Our generator covers OpenAPI and can extend where OpenAPI falls short.
- **Minimal dependencies** - Our SDKs are meant to be powerful but lean. We start with native language libraries and layer on third-party libraries only when the customer benefits far outweigh the cost of the extra dependency. We avoid adding unnecessary dependencies. 

Please see the table below for language-specific details.

<IconGrid {...SupportedLanguagesData} />
<IconGrid {...OSSComparisonData} />


 This is the content for the doc docs/languages/php/methodology-php.mdx 

 ---
title: "Create PHP SDKs from OpenAPI documents"
description: "Learn how Speakeasy creates a PHP SDK from an OpenAPI document."
---

# Create PHP SDKs from OpenAPI documents

## PHP SDK overview

The Speakeasy PHP SDK is designed to be easy to use and debug, and uses object-oriented programming in PHP for a robust and strongly-typed experience.

Some core features of the SDK are:

- Class-based objects using reflection and property attributes to aid serialization.
- A `Utils` package for common operations, simplifying generated code and making it easier to debug.
- A convenient factory pattern manages the SDK configuration.
- Support for OAuth flows and other standard security mechanisms.

While this article discusses the main features of the PHP SDK creator, for code examples with a full OpenAPI document, please see the [Speakeasy comparison article with OpenAPI Generator](./oss-comparison-php).

## New PHP features

Since the release of PHP 8 in 2020, the language has introduced additional type features, enabling better support for OpenAPI. Some of the features we take advantage of are:

- Union types

  ```php
  private int|float $age;
- Enums

  ```php
  enum HTTPMethods: string {
   case GET = 'get';
   case POST = 'post';
  }
  ```

## External libraries

The Speakeasy PHP SDK seeks to support the majority of the OpenAPI Specification features, and as such, supports some features that aren't contained in the PHP standard library.

Speakeasy fills the gaps using some external dependencies, which are detailed below.

### Dates

PHP has only date-time objects, not date objects. Speakeasy uses [Brick\DateTime](https://github.com/brick/date-time) for date support. For example:

```php
public function deserializeDateTimeToJson(JsonDeserializationVisitor $visitor, string $data, array $type, Context $context): mixed
{
  return \Brick\DateTime\LocalDate::parse($data);
}
```

### Complex numbers

PHP doesn't have support for arbitrary precision numbers, so we use the [Brick\Math](https://github.com/brick/math) library for complex number support.

To learn more about Speakeasy's complex number support, please read [this page](/docs/customize/data-model/complex-numbers).

### HTTP client

The SDK uses [Guzzle](https://docs.guzzlephp.org/en/stable) to provide a default HTTP client implementation, `\GuzzleHttp\Client`, for making API calls, which can be overridden. The client must implement the `\GuzzleHttp\ClientInterface`.

To override the HTTP client, pass the client during construction:

```php
use GuzzleHttp\Client;

$client = new Client([
  'timeout' => 2.0,
]);

$sdk = SDK::builder()->setClient(
  $client
)->build();
```

This allows for full customization of low-level features, like proxies, custom headers, timeouts, cookies, and others.

### Exhaustive type system

Speakeasy uses a combination of the [phpDocumentor TypeResolver](https://github.com/phpDocumentor/TypeResolver) library and the built-in standard library type specifications to provide exhaustive type checking across all aspects of the generated SDK.  

### Serialization

Speakeasy uses [JMS Serializer](https://jmsyst.com/libs/serializer) for serialization due to its union support, which other serialization libraries lack.

JMS Serializer checks types received in responses at runtime, guaranteeing strong typing not only in comment annotations, but also while the application is in use and transferring data.

Files in the Speakeasy-created PHP SDK include the line `declare(strict_types=1);`, which causes PHP to throw a `TypeError` if a function accepts or returns an invalid type at runtime.

### Type checking and linting

Speakeasy uses a combination of [PHPStan](https://phpstan.org), [Laravel Pint](https://laravel.com/docs/11.x/pint), and [Rector](https://github.com/rectorphp/rector) for linting, performing quality control, and statically analyzing the SDK.

### Quality and security

Speakeasy also uses [Roave Security Advisories](https://github.com/Roave/SecurityAdvisories) to ensure that its dependencies do not have any known security advisories.

### Tests

[PHPUnit](https://phpunit.de/documentation.html) is included with the SDK for running tests. However, no tests are created for the SDK automatically.

## PHP SDK package structure

```sh
├── src/                # Root directory for all PHP source files
│   ├── SDK.php         # The main SDK class
│   ├── SDKBuilder.php
│   ├── SDKConfiguration.php
│   ├── ...             # Other SDK classes, one per tag
│   ├── Models/
│   │   ├── Components/ # Contains data types used in requests
│   │   ├── Operations/ # Contains all the functions in the API
│   │   └── Errors/
│   │       └── SDKException.php  # The error that all requests can throw
│   └── Utils/          # Contains shared utility classes for transforming data
│       └── ...
├── docs/               # Contains Markdown files for the SDK documentation
│   └── ...
├── composer.json       # Configuration for PHP Composer
└── vendor              # External dependencies
```

## PHP SDK data types and classes

The Speakeasy PHP SDK uses native types wherever possible:

- `string`
- `DateTime`
- `int`
- `float`
- `bool`

Where no native data types are available, the Speakeasy PHP SDK uses libraries:

- `Brick\DateTime\LocalDate`
- `Brick\Math\BigInteger`
- `Brick\Math\BigDecimal`

The generated classes are standard PHP classes with public properties. These classes use attributes and reflection to help guide serialization.

## Parameters

When configured, Speakeasy will include up to a specified number of parameters directly in the function signatures, rather than providing the list of parameters as an object to be passed to the operation methods.

The maximum number of parameters to be placed in the method signature is set in the `maxMethodParams` option in the `gen.yaml` file. If `maxMethodParams` is not set or is set to `0`, no method parameters will be added.

## Errors

The Speakeasy PHP SDK returns errors by throwing the appropriate `error` class as part of the SDK call. You can then wrap your requests in a `try` block to handle the error in the response.

## User agent strings

The PHP SDK includes a [user agent](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/User-Agent) string in all requests, which can be leveraged to track SDK usage amongst broader API usage. The format is as follows:

```stmpl
speakeasy-sdk/php {{SDKVersion}} {{GenVersion}} {{DocVersion}} {{PackageName}}
```

- `SDKVersion` is the version of the SDK defined in `gen.yaml` and released.
- `GenVersion` is the version of the Speakeasy generator.
- `DocVersion` is the version of the OpenAPI document.
- `PackageName` is the name of the package defined in `gen.yaml`.

## Feature examples

Let's take a look at how OpenAPI features are mapped to PHP code. We'll use snippets from the [Swagger PetStore 3.1](https://petstore31.swagger.io/) OpenAPI document, [`openapi.yaml`](https://petstore31.swagger.io/api/v31/openapi.yaml). If you're not familiar with the example, it provides operations for managing users, customers, pets, and orders for pets in a hypothetical pet store.

### Tags

Each `tag` in the OpenAPI document becomes one file of top-level operations, such as `Pet.php`, `Store.php`, and `User.php` for:

```yaml
tags:
  - name: pet
    description: Everything about your Pets
    externalDocs:
      description: Find out more
      url: http://swagger.io
...
```

### Security

The Swagger Petstore OpenAPI document uses API key security and OAuth 2.0:

```yaml
/pet/{petId}:
 security:
    - api_key: []
    - petstore_auth:
        - write:pets
        - read:pets
...
components:
  securitySchemes:
    petstore_auth:
      type: oauth2
      flows:
        implicit:
          authorizationUrl: https://petstore31.swagger.io/oauth/authorize
          scopes:
            write:pets: modify pets in your account
            read:pets: read your pets
    api_key:
      type: apiKey
      name: api_key
      in: header
```

The PHP SDK creates a security class you can call with either scheme:

```php
use OpenAPI\OpenAPI\Utils\SpeakeasyMetadata;
class GetPetByIdSecurity
{
 /**
  *
  * @var ?string $apiKey
  */
 #[SpeakeasyMetadata('security:scheme=true,type=apiKey,subtype=header,name=api_key')]
 public ?string $apiKey = null;

 /**
  *
  * @var ?string $petstoreAuth
  */
 #[SpeakeasyMetadata('security:scheme=true,type=oauth2,name=Authorization')]
 public ?string $petstoreAuth = null;

 /**
  * @param  ?string  $apiKey
  * @param  ?string  $petstoreAuth
  */
 public function __construct(?string $apiKey = null, ?string $petstoreAuth = null)
 {
  $this->apiKey = $apiKey;
  $this->petstoreAuth = $petstoreAuth;
 }
}

# Example call:

$requestSecurity = new Operations\GetPetByIdSecurity();
$requestSecurity->apiKey = '<YOUR_API_KEY_HERE>';
$response = $sdk->pet->getPetById($requestSecurity, 504151);
```

The implicit flow is the only OAuth flow currently supported.

### Enums

Speakeasy uses native types in PHP 8 for enums.

```php
enum Status: string
{
  case Available = 'available';
  case Pending = 'pending';
  case Sold = 'sold';
}
```

### Typed parameters

Consider the following example of an array of strings in `openapi.yaml`:

```yaml
/pet/findByTags:
 get:
   operationId: findPetsByTags
   parameters:
      - name: tags
        in: query
        required: false
        explode: true
        schema:
          type: array
          items:
            type: string
```

The PHP SDK types the parameter in a DocBlock.

```php
/** Finds Pets by tags
 * @param  ?array<string>  $tags
 * @return Operations\FindPetsByTagsResponse
 * @throws \OpenAPI\OpenAPI\Models\Errors\SDKException
 */
public function findPetsByTags(?array $tags = null,):   Operations\FindPetsByTagsResponse {
```

You can use `oneOf` in an OpenAPI document like this:

```yaml
Pet:
  type: object
  properties:
    age:
      oneOf:
      - type: integer
      - type: string
```

The `age` property will be typed as a union in PHP:

```php
/**
 *
 * @param  int|string|null  $age
 */
```

## Unsupported features

Speakeasy does not support the following OpenAPI features in PHP:

- XML requests and responses
- OAuth 2.0 flows other than implicit flow
- SDK hooks

As PHP SDK creation is still an beta release, not all [extension attributes](/docs/customize-sdks) (`x-speakeasy`) work. For example, [open enums](/docs/customize-sdks/enums#open-vs-closed-enums) and [automatic retries](/docs/customize-sdks/retries) are not supported.


 This is the content for the doc docs/languages/php/oss-comparison-php.mdx 

 import { Callout } from "~/components";

# OpenAPI PHP SDK creation: Speakeasy vs open source

Many of our users have switched from [OpenAPI Generator](https://openapi-generator.tech/) to Speakeasy for their PHP SDKs. Learn how to use both SDK creators in this guide, and the differences between them.

Open-source OpenAPI generators are great for experimentation but lack the reliability, performance, and intuitive developer experience required for critical applications. As an alternative, Speakeasy creates [idiomatic SDKs](/post/client-sdks-as-a-service) that meet the bar for enterprise use.

Here's the high-level summary of the differences between Speakeasy and OpenAPI Generator:

| Feature               | Speakeasy                    | OpenAPI Generator                      |
| --------------------- | ---------------------------- | -------------------------------------- |
| OpenAPI 3.0 support   | ✅                           | ✅                                     |
| OpenAPI 3.1 support   | ✅                           | ❌                                     |
| Laravel integration   | ✅                           | ❌                                     |
| Code readability      | Concise, human-readable code | Verbose, messy code                    |
| Files generated       | 84 granular separation       | 16 less separation                     |
| Code generated        | 3,915 lines                  | 6,316 lines                            |
| PHP version support   | PHP 8.1+                     | PHP 7.4+                               |
| Type safety           | ✅                           | ❌                                     |
| Runtime type checking | ✅ JMS Serializer            | ❌                                     |
| Serialization         | ✅ JMS Serializer            | ✅ PHP extensions                      |
| Enum support          | ✅                           | ⚠️ Uses constant strings and functions |
| OAuth 2.0 support       | ⚠️ Coming soon               | ❌                                     |
| Content type support  | JSON and form                  | JSON, form, and XML                    |
| Async support         | ❌                           | ✅                                     |
| Union type handling   | ✅                           | ⚠️ Creates custom implementation       |
| Documentation         | ✅                           | ⚠️ Examples may lack required fields   |
| CI/CD integration     | ✅                           | ❌                                     |

In this post, we'll do a technical deep dive on creating PHP SDKs using both Speakeasy and OpenAPI Generator, then we'll compare the generated SDKs.

## What is OpenAPI Generator?

**OpenAPI Generator** (not to be confused with a generic **OpenAPI generator**) is a community-run, open-source tool for generating SDKs from OpenAPI specifications, with a [focus on version 3](https://openapi-generator.tech/docs/fork-qna). OpenAPI Generator originated as a fork of [Swagger Codegen](https://swagger.io/tools/swagger-codegen), a similar tool maintained by Smartbear.

## Preparing the SDK generators

For our comparison, we ran Speakeasy and OpenAPI Generator in separate Docker containers, which work on Windows, macOS, and Linux. Using Docker instead of running code directly on your physical machine is safer, as the code cannot access files outside the folder you specify.

We used the PetStore 3.1 YAML schema file from the [Swagger editor](https://editor-next.swagger.io) examples menu.

To follow along with this guide, locate the PetStore file in **File -> Load Example -> OpenAPI 3.1 Petstore** and save it to a subfolder called `app` in your current path, such as `app/schema.yaml`.

OpenAPI Generator provides a Docker image, but Speakeasy does not. To install the Speakeasy CLI, you can either follow the steps in the [Speakeasy Getting Started guide](/docs/speakeasy-reference/cli/getting-started) to install the Go binary directly on your computer, or run it in Docker, as we did.

To use Docker, first create a `Dockerfile` with the content below, replacing `YourApiKey` with your key from the Speakeasy website.

```bash
FROM alpine:3.19
WORKDIR /app
RUN apk add bash go curl unzip sudo nodejs npm
RUN curl -fsSL https://go.speakeasy.com/cli-install.sh | sh;
ENV GOPATH=/root/go
ENV PATH=$PATH:$GOPATH/bin
ENV SPEAKEASY_API_KEY=YourApiKey
```

Then build the Speakeasy image with the command below.

```sh
docker build -t seimage .
```

## Validating the schemas

Both OpenAPI Generator and the Speakeasy CLI can validate an OpenAPI schema. We'll run both and compare the output.

### Validation using OpenAPI Generator

To validate `schema.yaml` using OpenAPI Generator, run the following in the terminal:

```bash
docker run --rm -v "./app:/local" openapitools/openapi-generator-cli validate -i /local/schema.yaml
```

OpenAPI Generator returns two warnings:

```
Warnings:
	- Unused model: Address
	- Unused model: Customer

[info] Spec has 2 recommendation(s).
```

### Validation using Speakeasy

Validate the schema with Speakeasy by running the following in the terminal:

```bash
docker run --rm -v "./app:/app" seimage speakeasy validate openapi -s /app/schema.yaml
```

The Speakeasy validator returns 72 hints about missing examples, seven warnings about missing responses, and three warnings about unused components. Each warning includes a detailed JSON-formatted error with line numbers.

Since both validators return only warnings and not errors, we can assume both generators will create SDKs without issues.

## Creating the SDKs

First, we'll create an SDK with OpenAPI Generator, and then we'll create one with Speakeasy.

### Creating an SDK with OpenAPI Generator

OpenAPI Generator includes three different PHP SDK creators (and six server creators). We'll use the stable [PHP creator](https://openapi-generator.tech/docs/generators/php), as the others are in beta testing and have fewer features.

To create an SDK from the schema file using OpenAPI Generator, we ran the command below, which we found in the [OpenAPI Generator README](https://github.com/OpenAPITools/openapi-generator#16---docker).

```sh
docker run --rm -v "./app:/local" openapitools/openapi-generator-cli generate -i /local/schema.yaml -g php -o /local/og
```

OpenAPI Generator creates three folders:

| Folder | Content                                                                                                                                                                                                                                                                                                                                                    |
| ------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `docs` | Documentation in `.md` files for each object.                                                                                                                                                                                                                                                                                                              |
| `lib`  | PHP code to call the API on the server, includes a `Model` folder containing a file for each object in the schema and an `Api` folder containing a file for each tag in the schema. If you pass [parameters](https://openapi-generator.tech/docs/generators/php#config-options) to the build command, you can rename `Api`, for example, to `PetstoreSdk`. |
| `test` | Unit test stubs for all objects and operations. The test stubs are empty, leaving testing logic to the developer.                                                                                                                                                                                                                                          |

A warning from OpenAPI Generator in the terminal read:

```
Generation using 3.1.0 specs is in development and is not officially supported yet.
```

The [OpenAPI Generator roadmap](https://openapi-generator.tech/docs/roadmap) hasn't been updated in almost two years.

### Creating an SDK with Speakeasy

Next, we'll create an SDK using the Speakeasy CLI with the command below.

```bash
docker run --rm -v "./app:/app" seimage speakeasy generate sdk --schema /app/schema.yaml --lang php --out /app/se
```

Speakeasy gives multiple warnings about `xml request bodies are not currently supported` and creates the following folders.

| Folder | Content                                                                                                                                                                                                                                  |
| ------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `docs` | Documentation in `.md` files for each component, operation, and SDK (tag).                                                                                                                                                               |
| `src`  | PHP code to call the API on the server, containing a `Models` folder for each object and operation in the schema. The `src` folder also contains a `Utils` folder containing code for common functions, like security and date handling. |

Speakeasy does not create test stubs, as unit testing is performed on Speakeasy's generator instead of the generated SDK. Shipping unit tests for generated SDKs adds unnecessary complexity and dependencies.

## Calling the server

Swagger provides a complete test server for the PetStore OpenAPI 3.1 schema at https://petstore31.swagger.io.

We called the pet operations given in each SDK's README file against the test server to check that the SDKs contain working code.

We used a [Docker Composer 2.7](https://hub.docker.com/layers/library/composer/2.7/images/sha256-692dd0a0b775cc25ea0cf3ed936b1470647191a6417047e6a77d757a9f29c956?context=explore) container, which is based on Alpine 3 and PHP 8.

### Calling the server with the OpenAPI Generator SDK

We used the `app/og/main.php` script below to call the API with the SDK generated by OpenAPI Generator. The example code was mostly given in the `README.md` file.

```php app/og/main.php
<?php
require_once(__DIR__ . '/vendor/autoload.php');

$config = OpenAPI\Client\Configuration::getDefaultConfiguration()->setAccessToken('test');
$apiInstance = new OpenAPI\Client\Api\PetApi(new GuzzleHttp\Client(), $config);
$pet = new \OpenAPI\Client\Model\Pet(); // \OpenAPI\Client\Model\Pet | Create a new pet in the store
$pet->setId(1);
$pet->setName("1");

try {
    $result = $apiInstance->addPet($pet);
    print_r($result);
} catch (Exception $e) {
    echo 'Exception when calling PetApi->addPet: ', $e->getMessage(), PHP_EOL;
}
```

To get access to the folder to create the script, give yourself permissions to the shared Docker volume with the command below, using your username.

```sh
sudo chown -R yourUsername ./app
```

Next, we ran the command below and received a successful response.

```sh
docker run --rm -v "./app/og:/app" -w "/app" composer:2.7 sh -c  "composer install && php main.php"
```

The response of `$apiInstance->addPet($pet)` is below.

```text Output
OpenAPI\Client\Model\Pet Object
(
    [openAPINullablesSetToNull:protected] => Array()
    [container:protected] => Array
        (
            [id] => 1
            [name] => 1
            [category] =>
            [photo_urls] => Array()
            [tags] => Array()
            [status] =>
        )
)
```

First, the command installs the PHP dependencies in the Docker container as recommended in the SDK `README.md` file, then it runs the sample `main.php` script to call the server using the SDK.

### Calling the server with the Speakeasy SDK

The SDK Speakeasy creates also calls the server successfully.

Below is an example script to call the API with the SDK created by Speakeasy. Save it as `app/se/main.php`.

```php app/se/main.php
<?php

declare(strict_types=1);

require 'vendor/autoload.php';

use OpenAPI\OpenAPI;
use OpenAPI\OpenAPI\Models\Components;

// Typed security object
$security = new Components\Security("<YOUR_PETSTORE_AUTH_HERE>");

$sdk = OpenAPI\SDK::builder()
    ->setSecurity($security->petstoreAuth)
    ->build();

try {
    // Fully typed SDK objects
    $request = new Components\Pet10(
        name: 'doggie',
        photoUrls: [
            'https://example.com/doggie.jpg',
            'https://example.com/doggie2.jpg',
        ],
        id: 10,
        tags: [
            new Components\Tag(
                id: 123,
                name: 'pets',
            ),
            new Components\Tag(
                id: 3,
                name: 'good-dogs',
            ),
            new Components\Tag(
                id: 900,
                name: 'not-cats',
            ),
        ],
        // Typed subobjects
        category: new Components\Category(
            id: 1,
            name: 'Dogs',
        ),
        // Enums help you validate the input data
        status: Components\Status::Available
    );
    $response = $sdk->pet->addPetForm($request);
    if ($response->pet !== null) {
        print_r($response->pet);
    }
} catch (Throwable $e) {
    print_r($e);
}
```

In the example above, we use the `Components` namespace to create a typed security object and a typed request object. We then call the `addPetForm` operation on the `pet` object in the SDK. You'll notice that the SDK helps you validate the input data with enums and typed subobjects.

Let's run the script to see the response.

The command to run the script is nearly identical to the command the OpenAPI Generator SDK used, except for using the Speakeasy folder.

```sh
docker run --rm -v "./app/se:/app" -w "/app" composer:2.7 sh -c  "composer install && php main.php"
```

The response of `$sdk->pet->addPetForm($request)` is below.

```text Output
OpenAPI\OpenAPI\Models\Components\Pet15 Object
(
    [id] => 10
    [name] => doggie
    [category] => OpenAPI\OpenAPI\Models\Components\Category Object
        (
            [id] => 1
            [name] => Dogs
        )
    [photoUrls] => Array
        (
            [0] => https://example.com/doggie2.jpg
        )
    [tags] => Array
        (
            [0] => OpenAPI\OpenAPI\Models\Components\Tag Object
                (
                    [id] => 3
                    [name] => good-dogs
                )

            [1] => OpenAPI\OpenAPI\Models\Components\Tag Object
                (
                    [id] => 900
                    [name] => not-cats
                )
        )
    [status] => OpenAPI\OpenAPI\Models\Components\Status Enum:string
        (
            [name] => Available
            [value] => available
        )
)
```

## Package structure

Let's compare the structure of the SDKs in terms of code volume and folder structure.

You can count the lines of code in the SDKs by running `cloc` for each (ignoring documentation and test folders):

```bash
cloc ./app/og/lib
cloc ./app/se/src
```

Below are the results for each SDK.

| Project           | Files | Blank lines | Comment lines | Code lines |
| ----------------- | ----- | ----------- | ------------- | ---------- |
| OpenAPI Generator | 16    | 1198        | 4267          | 6316       |
| Speakeasy         | 84    | 1073        | 2214          | 3915       |

We see that the Speakeasy SDK has five times as many files as OpenAPI Generator, but 40% less code. The libraries Speakeasy uses, as well as shared utility functions, allow it to create more concise code than OpenAPI Generator.

The following commands output the files of each SDK.

```sh
tree ./app/og/lib
tree ./app/se/src
```

Below is the output for OpenAPI Generator.

```sh
├── Api
│   ├── PetApi.php
│   ├── StoreApi.php
│   └── UserApi.php
├── ApiException.php
├── Configuration.php
├── HeaderSelector.php
├── Model
│   ├── Address.php
│   ├── ApiResponse.php
│   ├── Category.php
│   ├── Customer.php
│   ├── ModelInterface.php
│   ├── Order.php
│   ├── Pet.php
│   ├── Tag.php
│   └── User.php
└── ObjectSerializer.php
```

The folder structure is simple and clear with nothing unexpected. Files are separated at the API level (pet, store, and user) and by model. There are a few helper files, like `ApiException.php`.

Below is the output for Speakeasy.

```sh
├── Models
│   ├── Components
│   │   ├── ApiResponse.php
│   │   ├── Category.php
│   │   ├── Order1.php
│   │   ├── Order2.php
│   │   ├── Order3.php
│   │   ├── Order4.php
│   │   ├── Order5.php
│   │   ├── Order6.php
│   │   ├── OrderStatus.php
│   │   ├── Pet1.php
│   │   ├── Pet10.php
│   │   ├── Pet11.php
│   │   ├── Pet12.php
│   │   ├── Pet13.php
│   │   ├── Pet14.php
│   │   ├── Pet15.php
│   │   ├── Pet16.php
│   │   ├── Pet17.php
│   │   ├── Pet18.php
│   │   ├── Pet19.php
│   │   ├── Pet2.php
│   │   ├── Pet20.php
│   │   ├── Pet21.php
│   │   ├── Pet22.php
│   │   ├── Pet3.php
│   │   ├── Pet4.php
│   │   ├── Pet5.php
│   │   ├── Pet6.php
│   │   ├── Pet7.php
│   │   ├── Pet8.php
│   │   ├── Security.php
│   │   ├── Status.php
│   │   ├── Tag.php
│   │   ├── User1.php
│   │   ├── User10.php
│   │   ├── User11.php
│   │   ├── User12.php
│   │   ├── User13.php
│   │   ├── User15.php
│   │   ├── User2.php
│   │   ├── User3.php
│   │   ├── User4.php
│   │   ├── User5.php
│   │   ├── User6.php
│   │   ├── User7.php
│   │   ├── User8.php
│   │   └── User9.php
│   ├── Errors
│   │   └── SDKException.php
│   └── Operations
│       ├── AddPetFormResponse.php
│       ├── AddPetJsonResponse.php
│       ├── AddPetRawResponse.php
│       ├── CreateUserFormResponse.php
│       ├── CreateUserJsonResponse.php
│       ├── CreateUserRawResponse.php
│       ├── CreateUsersWithListInputResponse.php
│       ├── DeleteOrderRequest.php
│       ├── DeleteOrderResponse.php
│       ├── DeletePetRequest.php
│       ├── DeletePetResponse.php
│       ├── DeleteUserRequest.php
│       ├── DeleteUserResponse.php
│       ├── FindPetsByStatusRequest.php
│       ├── FindPetsByStatusResponse.php
│       ├── FindPetsByTagsRequest.php
│       ├── FindPetsByTagsResponse.php
│       ├── GetInventoryResponse.php
│       ├── GetInventorySecurity.php
│       ├── GetOrderByIdRequest.php
│       ├── GetOrderByIdResponse.php
│       ├── GetPetByIdRequest.php
│       ├── GetPetByIdResponse.php
│       ├── GetPetByIdSecurity.php
│       ├── GetUserByNameRequest.php
│       ├── GetUserByNameResponse.php
│       ├── LoginUserRequest.php
│       ├── LoginUserResponse.php
│       ├── LogoutUserResponse.php
│       ├── PlaceOrderFormResponse.php
│       ├── PlaceOrderJsonResponse.php
│       ├── PlaceOrderRawResponse.php
│       ├── Status.php
│       ├── UpdatePetFormResponse.php
│       ├── UpdatePetJsonResponse.php
│       ├── UpdatePetRawResponse.php
│       ├── UpdatePetWithFormRequest.php
│       ├── UpdatePetWithFormResponse.php
│       ├── UpdateUserFormRequest.php
│       ├── UpdateUserFormResponse.php
│       ├── UpdateUserJsonRequest.php
│       ├── UpdateUserJsonResponse.php
│       ├── UpdateUserRawRequest.php
│       ├── UpdateUserRawResponse.php
│       ├── UploadFileRequest.php
│       └── UploadFileResponse.php
├── Pet.php
├── SDK.php
├── SDKBuilder.php
├── SDKConfiguration.php
├── Store.php
├── User.php
└── Utils
    ├── DateHandler.php
    ├── DateTimeHandler.php
    ├── DefaultRequest.php
    ├── DefaultResponse.php
    ├── DefaultStream.php
    ├── DefaultUri.php
    ├── EnumHandler.php
    ├── FormMetadata.php
    ├── Headers.php
    ├── JSON.php
    ├── MixedJSONHandler.php
    ├── MultipartMetadata.php
    ├── ParamsMetadata.php
    ├── PathParameters.php
    ├── PhpDocTypeParser.php
    ├── QueryParameters.php
    ├── RequestBodies.php
    ├── RequestMetadata.php
    ├── Security.php
    ├── SecurityClient.php
    ├── SecurityMetadata.php
    ├── SpeakeasyMetadata.php
    ├── UnionHandler.php
    └── Utils.php
```

The Speakeasy SDK is more complex and has more features. Files are separated at a lower level than OpenAPI Generator — at the operation level – and further split into content types of the operation, like `AddPetJsonResponse.php`. There are more helper files bundled with the SDK in the `Utils` folder.

## Code readability

We'll compare the SDKs in terms of code readability, focusing on the `Pet` model first.

### OpenAPI Generator

The `Pet` model generated by OpenAPI Generator inherits a `ModelInterface` and has a `container` property that holds the model's fields. The model's constructor can either take an associative array of field names and values or no arguments. Then, the model exposes getter and setter methods for each field.

Type mapping is presented as an associative array of field names and types as strings. The `Pet` model has the following fields:

```php app/og/lib/Model/Pet.php
//...
    protected static $openAPITypes = [
        'id' => 'int',
        'name' => 'string',
        'category' => '\OpenAPI\Client\Model\Category',
        'photo_urls' => 'string[]',
        'tags' => '\OpenAPI\Client\Model\Tag[]',
        'status' => 'string'
    ];
//...
```

Overall, the `Pet` model is extremely verbose, coming in at 623 lines of code, including comments and whitespace, but excluding dependencies.

Contrast this with the `Pet` model generated by Speakeasy.

### Speakeasy

The `Pet10` model generated by Speakeasy is more concise and readable, presented in its entirety below:

```php app/se/src/Models/Components/Pet10.php
<?php

/**
 * Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.
 */

declare(strict_types=1);

namespace OpenAPI\OpenAPI\Models\Components;

use OpenAPI\OpenAPI\Utils\SpeakeasyMetadata;
class Pet10
{
    /**
     *
     * @var ?int $id
     */
    #[SpeakeasyMetadata('form:name=id')]
    public ?int $id = null;

    /**
     *
     * @var string $name
     */
    #[SpeakeasyMetadata('form:name=name')]
    public string $name;

    /**
     *
     * @var ?Category $category
     */
    #[SpeakeasyMetadata('form:name=category,json=true')]
    public ?Category $category = null;

    /**
     * $photoUrls
     *
     * @var array<string> $photoUrls
     */
    #[SpeakeasyMetadata('form:name=photoUrls')]
    public array $photoUrls;

    /**
     * $tags
     *
     * @var ?array<Tag> $tags
     */
    #[SpeakeasyMetadata('form:name=tags,json=true')]
    public ?array $tags = null;

    /**
     * pet status in the store
     *
     * @var ?Status $status
     */
    #[SpeakeasyMetadata('form:name=status')]
    public ?Status $status = null;

    /**
     * @param  string  $name
     * @param  array<string>  $photoUrls
     * @param  ?int  $id
     * @param  ?Category  $category
     * @param  ?array<Tag>  $tags
     * @param  ?Status  $status
     */
    public function __construct(string $name, array $photoUrls, ?int $id = null, ?Category $category = null, ?array $tags = null, ?Status $status = null)
    {
        $this->name = $name;
        $this->photoUrls = $photoUrls;
        $this->id = $id;
        $this->category = $category;
        $this->tags = $tags;
        $this->status = $status;
    }
}
```

The `Pet10` model, at 76 lines of code, including comments and whitespace, is more concise and readable than the `Pet` model generated by OpenAPI Generator. Speakeasy uses modern PHP features like typed properties, attributes, and named arguments to make the model more readable.

Serialization and deserialization are handled by [JMS/Serializer](http://jmsyst.com/libs/serializer), which uses annotations in the model to convert objects to and from JSON. This allows Speakeasy to create more concise and readable code.

Instead of using a getter and setter for each field, Speakeasy uses typed properties and a constructor to set the fields. This makes implementing the model more straightforward and less verbose.

## Dependencies

The OpenAPI Generator SDK Composer file has the dependencies below.

- The ext-curl, ext-json, and ext-mbstring PHP extensions, which handle calling HTTP, serialize objects to JSON, and work with Unicode.
- [Guzzle](https://docs.guzzlephp.org/en/stable) and [Guzzle PSR-7](https://github.com/guzzle/psr7) send HTTP requests with [PSR-7](https://www.php-fig.org/psr/psr-7/) support.
- [PHPUnit](https://phpunit.de/documentation.html) runs tests.
- [Symfony PHP Coding Standards Fixer](https://cs.symfony.com/) formats code.

The Speakeasy SDK Composer file has the dependencies below.

- [Guzzle](https://docs.guzzlephp.org/en/stable) sends HTTP requests.
- [Serializer](https://jmsyst.com/libs/serializer) converts PHP objects to and from JSON and XML to be sent over HTTP.
- [Brick\DateTime](https://github.com/brick/date-time) manages dates, times, and time zones.
- [phpDocumentor TypeResolver](https://github.com/phpDocumentor/TypeResolver) generates types from DocBlocks.
- [Laravel Pint](https://laravel.com/docs/11.x/pint) formats code.
- [PHPStan](https://phpstan.org/) finds errors and handles complex types.
- [PHPUnit](https://phpunit.de/documentation.html) runs tests. However, there are no tests in the created SDK.
- [Rector](https://github.com/rectorphp/rector) checks code quality.
- [Roave Security Advisories](https://github.com/Roave/SecurityAdvisories) warns about dangerous Composer dependencies.

Both creators use similar libraries, but OpenAPI Generator relies as much as possible on core PHP extensions, while Speakeasy has more serialization and complex typing libraries: Serializer, Brick, TypeResolver, and PHPStan.

## Supported PHP versions

At the time of compiling this comparison, the Speakeasy SDK required at least PHP version 8.1. PHP 8 introduced language features to support stronger typing.

The OpenAPI Generator SDK still supports PHP version 7.4, though it is compatible with PHP 8.

We recommend you use the latest PHP version with both SDKs.

## Strong typing

Both creators use DocBlocks to provide type annotations to all parameters and variables in the SDKs, which is useful for IDEs and for programmers to understand the code.

But files in the Speakeasy SDK include the line `declare(strict_types=1);`, which causes PHP to throw a `TypeError` if a function accepts or returns an invalid type at runtime. The OpenAPI Generator SDK files do not have this line and so don't check types at runtime.

In Speakeasy, the JMS Serializer checks types when converting from JSON to PHP objects at runtime. OpenAPI Generator doesn't have this in plain Guzzle.

### Enums

OpenAPI Generator provides a workaround for enumerations using constant strings and functions. Below is the pet status enumeration for OpenAPI Generator.

```php
public const STATUS_AVAILABLE = 'available';
public const STATUS_PENDING = 'pending';
public const STATUS_SOLD = 'sold';

/**
 * Gets allowable values of the enum
 *
 * @return string[]
 */
public function getStatusAllowableValues()
{
    return [
        self::STATUS_AVAILABLE,
        self::STATUS_PENDING,
        self::STATUS_SOLD,
    ];
}
```

Below is the pet status enumeration for Speakeasy using modern PHP.

```php
enum Status: string
{
    case Available = 'available';
    case Pending = 'pending';
    case Sold = 'sold';
}
```

### Content types

Below are the content types in the schema for updating a pet, in JSON, XML, or as a form.

```yaml
requestBody:
  content:
    application/json:
      schema:
        $ref: "#/components/schemas/Pet"
    application/xml:
      schema:
        $ref: "#/components/schemas/Pet"
    application/x-www-form-urlencoded:
      schema:
        $ref: "#/components/schemas/Pet"
```

Speakeasy supports JSON and form content types, but not XML. OpenAPI Generator supports all three. Additionally, OpenAPI Generator provides asynchronous versions of each HTTP call, such as `AddPet` and `AddPetAsync`.

In Speakeasy, each content type for each operation will become its own file in the SDK. In OpenAPI Generator, all operations are combined into one API file.

### Unions

In OpenAPI, you can use `oneOf` in a schema like this:

```yaml
Pet:
  type: object
  properties:
    age:
      oneOf:
        - type: integer
        - type: string
```

The `age` property will be typed as a union in PHP in Speakeasy:

```php
class Pet10
{
    /**
     *
     * @var int|string|null $age
     */
    #[SpeakeasyMetadata('form:name=age')]
    public int|string|null $age = null;

...

    public function __construct(?string $name = null, ?array $photoUrls = null, int|string|null $age = null,
```

OpenAPI Generator can handle this schema, but creates a 380-line file called `PetAge.php` with custom code to implement unions.

## Created documentation

Both Speakeasy and OpenAPI Generator create a `docs` directory with Markdown documentation and PHP usage examples for every operation and every model.

We found the usage examples in the Speakeasy SDK worked flawlessly, while the examples in the OpenAPI Generator SDK don't always include required fields when instantiating objects. For instance, the `PetApi.md` example in the OpenAPI Generator SDK doesn't include any fields for the `Pet` object.

```php app/og/docs/PetApi.md
<?php
require_once(__DIR__ . '/vendor/autoload.php');


// Configure OAuth2 access token for authorization: petstore_auth
$config = OpenAPI\Client\Configuration::getDefaultConfiguration()->setAccessToken('YOUR_ACCESS_TOKEN');


$apiInstance = new OpenAPI\Client\Api\PetApi(
    // If you want to use a custom http client, pass your client which implements `GuzzleHttp\ClientInterface`.
    // This is optional, `GuzzleHttp\Client` will be used as default.
    new GuzzleHttp\Client(),
    $config
);
$pet = new \OpenAPI\Client\Model\Pet(); // \OpenAPI\Client\Model\Pet | Create a new pet in the store

try {
    $result = $apiInstance->addPet($pet);
    print_r($result);
} catch (Exception $e) {
    echo 'Exception when calling PetApi->addPet: ', $e->getMessage(), PHP_EOL;
}
```

Both SDKs include detailed documentation for operations and models, but the Speakeasy SDK includes more detailed usage examples that work out of the box.

Speakeasy also creates appropriate example strings based on a field's `format` in the OpenAPI schema.

For example, if we add `format: uri` to the item for a pet's photo URLs, we can compare each SDK's usage documentation for this field.

The SDK created by Speakeasy includes a helpful example of this field that lists multiple random URLs:

```php
# Speakeasy SDK Usage Example
pet = shared.Pet(
    # ...
    photo_urls=[
        'https://salty-stag.name',
        'https://moral-star.info',
        'https://present-giggle.info',
    ]
)
```

The OpenAPI Generator SDK's documentation uses a single random string in its example:

```php
# PHP SDK Usage Example
pet = Pet(
    # ...
    photo_urls=[
        "photo_urls_example"
    ]
)
```

## Automation

This comparison focuses on installing and using Speakeasy and OpenAPI Generator using the command line, but both tools can also run as part of a CI workflow. For example, you can set up a [GitHub Action](https://github.com/speakeasy-api/sdk-generation-action) to ensure your Speakeasy SDK is always up-to-date when your API schema changes.

## Unsupported features

At the time of writing, OpenAPI Generator does not support:

- [Data types null, UUID](https://openapi-generator.tech/docs/generators/php/#data-type-feature), [all, any, and union](https://openapi-generator.tech/docs/generators/php/#schema-support-feature).
- [Server URLs with parameters](https://openapi-generator.tech/docs/generators/php/#global-feature).
- [Callbacks](https://openapi-generator.tech/docs/generators/php/#global-feature) (allowing your server to call a client).
- [Link objects](https://openapi-generator.tech/docs/generators/php/#global-feature) (relating operations to each other to indicate a workflow).

Neither service supports OAuth 2 flows other than Implicit.

## Summary

Open-source tooling can be a great way to experiment, but if you're working on production code, the Speakeasy PHP SDK creator will help ensure that you create reliable and performant PHP SDKs. The Speakeasy PHP SDK creator uses strong typing to provide safe runtime performance, supports many OpenAPI features, and is rapidly adding more.


 This is the content for the doc docs/languages/python/feature-support.mdx 

 ---
title: "Python Feature Reference"
description: "An overview of Python features supported by Speakeasy for SDK generation from an OpenAPI / Swagger spec."
---

# Python Feature Reference

## Authentication

|    Name    | Support |  Docs  |   Notes |
|------------|:---:|------------------|---------|
| HTTP Basic |   ✅    |     Docs         |         |
| API Key <br /> (bearer, header, cookie, query) |   ✅    |     Docs         |         |
| OAuth <br /> implicit flow |   ✅    |     Docs         |         |
| OAuth <br /> refresh token flow |   ✅ using security callbacks    |     Docs         |         |
| OAuth <br /> client credentials flow |   ✅ using hooks   |     Docs         |         |
| mTLS |   🏗️ Partial    |     Docs         |         |

## Server Configuration

|       Name     | Support |  Docs  |   Notes |
|----------------|:-------:|--------------|--------|
| URL Templating |    ✅    | [defining `variables`](/docs/customize-sdks/servers#use-templated-urls) |  |
| Multiple server|    ✅    | [`x-speakeasy-server-id` extension](/docs/customize-sdks/servers#declare-multiple-servers) |  |
| Describe server <br /> outside your spec  | ✅    | [`serverUrl` config](/docs/customize-sdks/servers#declare-base-server-url) |  |

## Data Types

### Basic Types

| Name | Support |  Docs  |   Notes |
|------|:-------:|--------------|--------|
| Numbers |    ✅    | [data-types](https://swagger.io/docs/specification/data-models/data-types/#numbers) | `float`, `double`, `int32`, `int64` |
| Strings |    ✅    | [data-types](https://swagger.io/docs/specification/data-models/data-types/#strings) |  |
| Date Time |    ✅    | [data-types](https://swagger.io/docs/specification/data-models/data-types/#date-time) |  |
| Boolean |    ✅    | [data-types](https://swagger.io/docs/specification/data-models/data-types/#booleans) |  |
| Binary |    ✅    | [data-types](https://swagger.io/docs/specification/data-models/data-types/#binary) |  |
| Enums |    ✅    | [data-types](https://swagger.io/docs/specification/data-models/data-types/#enumerations) |  |
| Arrays |    ✅    | [data-types](https://swagger.io/docs/specification/data-models/data-types/#arrays) |  |
| Maps |    ✅    | [data-types](https://swagger.io/docs/specification/data-models/data-types/#maps) |  |
| Objects |    ✅    | [data-types](https://swagger.io/docs/specification/data-models/data-types/#objects) |  |
| Any |    ✅    | [data-types](https://swagger.io/docs/specification/data-models/data-types/#any) |  |
| Null |    ✅    | [data-types](https://swagger.io/docs/specification/data-models/data-types/#nil) |  |

### Polymorphism

| Name | Support |  Docs  |   Notes |
|------|:-------:|--------------|--------|
| Union Types |    ✅    | [Using `oneOf`](https://swagger.io/docs/specification/data-models/oneof-anyof-allof-not/#oneof) | `anyOf` is treated as `oneOf` and will create a union type object. |
| Intersection Types |   🏗️ Partial     | [Using `allOf`](https://swagger.io/docs/specification/data-models/oneof-anyof-allof-not/#allof) |  |


## Methods

|     Name    | Support |  Docs  |   Notes |
|-------------|:-------:|--------------|--------|
| Namespacing |    ✅    | [grouping operations](/docs/customize-sdks/namespaces) |  |
| Multi-level Namespacing |    ✅    | [multi-level grouping](/docs/customize-sdks/namespaces#define-multi-level-namespaces) |  |
| Custom naming|    ✅    | [`x-speakeasy-name-override` extension](/docs/customize-sdks/methods#change-method-names) |  |
| Exclude Methods |    ✅    | [`x-speakeasy-ignore` extension](/docs/customize-sdks/methods#exclude-methods-from-sdk) |  |
| Deprecation |    ✅    | the [`deprecate` flag](/docs/customize-sdks/methods#deprecate-methods) |  |

## Parameters

|     Name    | Support |  Docs  |   Notes |
|-------------|:-------:|--------------|--------|
| Pass Inline |    ✅    | [flattening parameters](/docs/customize-sdks/methods#configuring-method-signatures) |  |
| Pass via Request Object |    ✅    | [request object](/docs/customize-sdks/methods#configuring-method-signatures) |  |
| Exclude Parameters |    ✅    | [`x-speakeasy-ignore` extension](/docs/customize-sdks/methods#exclude-parameters-from-signatures) |  |
| Deprecate Parameters |    ✅    | the [`deprecate` flag](/docs/customize-sdks/deprecations#deprecate-parameters) |  |
| Define globally |    ✅    | [global parameters](/docs/customize-sdks/globals) |  |

### Path Parameters Serialization

|     Name    | Support |  Docs  |   Notes |
|-------------|:-------:|--------------|--------|
| Default <br /> `(style = simple, explode = false)` |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#path/) |  |
| Basic types |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#path/) |  |
| Simple objects |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#path/) |  |
| `label` & `matrix` |    ❌    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#path/) |  |

### Query Parameters Serialization

|     Name    | Support |  Docs  |   Notes |
|-------------|:-------:|--------------|--------|
| `json` |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#query/) |  |
| `form` |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#query/) |  |
| `spaceDelimited` |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#query/) |  |
| `pipeDelimited` |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#query/) |  |
| `deepObject` |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#query/) |  |
| Basic types |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#query/) |  |
| Simple objects |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#query/) |  |

## Requests

|     Name    | Support |  Docs  |   Notes |
|-------------|:-------:|--------------|--------|
| Request headers |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#header/) |  |
| Request retries |    ✅    | [retries](/docs/customize-sdks/retries) |  |
| `json` |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#request-body/) | Both `application/json` and `text/json`  |
| form data |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#request-body/) |  |
| binary |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#request-body/) |  |
| raw byte |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#request-body/) |  |
| plain text |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#request-body/) |  |
| `x-www-form-urlencoded` |    🏗️ Partial    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#request-body/) | Including encoding, but not non-object types |
| XML |    ❌    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#request-body/) |  |
| Other media types |    ❌    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#request-body/) |  |

## Responses

|     Name    | Support |  Docs  |   Notes |
|-------------|:-------:|--------------|--------|
| Pagination |    ✅    | [`x-speakeasy-pagination` extension](/docs/customize-sdks/pagination) |  |
| Custom Errors |    ✅    | [`x-speakeasy-errors` extension](/docs/customize-sdks/errors) |  |
| json |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#response/) |  |
| plain text |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#response/) |  |
| binary |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#response/) |  |
| raw byte |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#response/) |  |
| XML |    ❌    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#response/) |  |
| Other media types   |    ❌    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#response/) |  |

## Documentation

|     Name    | Support |  Docs  |   Notes |
|-------------|:-------:|--------------|--------|
|  `README` generation |    ✅    | [README generation](/docs/customize-sdks/sdk-docs) |  |
|  Usage Snippet generation |    ✅    | [snippet generation](/docs/customize-sdks/sdk-docs#usage-examples) |  |
|  Documentation generation |    ✅    | [documentation generation](/docs/customize-sdks/sdk-docs) |  |


 This is the content for the doc docs/languages/python/methodology-python.mdx 

 ---
title: "Generate Python SDKs from OpenAPI / Swagger"
description: "Learn how Speakeasy generates a Python client from an OpenAPI / Swagger spec."
---

import { Callout } from '~/components'

# Generate Python SDKs from OpenAPI / Swagger

<Callout title="OSS Comparison" variant="info">
For a comparison between the Speakeasy Python SDK and some popular open-source generators, see [**this page**](/post/speakeasy-oss-python-generator).
</Callout>


## SDK Overview

Speakeasy-generated Python SDKs are designed to be best in class, providing a seamless developer experience and full type safety, alongside asynchronous support.

The core Python SDK features include:
- Fully type-annotated classes and methods with full Pydantic models and associated TypedDicts.
- Async and Sync methods for all endpoints.
- Support for streaming uploads and downloads.
- Support for Server-Sent Events (SSE).
- Authentication support for OAuth flows and support for standard security mechanisms (HTTP Basic, application tokens, etc.).
- Optional pagination support for supported APIs.
- Optional support for retries in every operation.
- Complex number types including big integers and decimals.
- Date and date/time types using RFC3339 date formats.
- Custom type enums using strings and integers (including Open Enums).
- Union types and combined types.


### Python Package Structure

```yaml
├── src
|   └── {Package Name}         # Root module for the SDK where {SDK Class Name} is the provided name of the SDK
|       ├── {SDK Class Name}.py  # The main SDK class
|       ├── ...                  # Other SDK classes
|       ├── models               # Module for SDK's models
|       |   |── shared           # Submodule providing the SDK's models generated from components in the OpenAPI document
|       |   |── operations       # Submodule providing the SDK's operations models which generally house the request/response models for each API document
|       |   └── ...
|       └── utils                # Module for the SDK's utility classes
├── docs                         # Markdown files for the SDK's documentation
|   └── ...
├── setup.py                     # Package setup
└── ...
```

Python dependencies and packaging for publishing are handled using `poetry`.


##  Python Type Safety

Modern Python uses type hints to improve code readability and so do Speakeasy-generated Python SDKs! Speakeasy-generated Python SDKs expose type annotations for developers to perform type checks at runtime and increase type safety, we also employ Pydantic models to ensure that the data passed to and from the SDK is valid at runtime.

### The generated models

Speakeasy uses `pydantic` for all generated models to correctly serialize and deserialize objects; whether the objects are passed as query parameters, path parameters, or request bodies. Metadata based on the definitions provided by the OpenAPI document are appended to fields.

For example, this is the generated class for the [Drink](https://github.com/speakeasy-sdks/template-sdk/blob/main/openapi.yaml#L312) component from our [SpeakeasyBar template repository](https://github.com/speakeasy-sdks/template-sdk):
```python
class Drink(BaseModel):
    name: str
    r"""The name of the drink."""
    price: float
    r"""The price of one unit of the drink in US cents."""
    type: Optional[DrinkType] = None
    r"""The type of drink."""
    stock: Optional[int] = None
    r"""The number of units of the drink in stock, only available when authenticated."""
    product_code: Annotated[Optional[str], pydantic.Field(alias="productCode")] = None
    r"""The product code of the drink, only available when authenticated."""
```

Python also generates matching `TypedDict` classes for each model, which can be used to pass in dictionaries to the SDK methods without the need to import the model classes.

```python
class DrinkTypedDict(TypedDict):
    name: str
    r"""The name of the drink."""
    price: float
    r"""The price of one unit of the drink in US cents."""
    type: NotRequired[DrinkType]
    r"""The type of drink."""
    stock: NotRequired[int]
    r"""The number of units of the drink in stock, only available when authenticated."""
    product_code: NotRequired[str]
    r"""The product code of the drink, only available when authenticated."""
```

which allows methods to be called one of two ways:

```python
res = s.orders.create_order(drinks=[
    {
        "type": bar.OrderType.INGREDIENT,
        "product_code": "AC-A2DF3",
        "quantity": 138554,
    },
])
```

or 

```python
res = s.orders.create_order(drinks=[
    Drink(
        type=bar.OrderType.INGREDIENT,
        product_code="AC-A2DF3",
        quantity=138554,
    ),
])
```

## Async vs Sync Methods

Speakeasy-generated Python SDKs provide both synchronous and asynchronous methods for all endpoints. The SDK uses the `httpx` library for making HTTP requests, which supports both synchronous and asynchronous requests.

Synchronous:
```python
res = s.orders.create_order(drinks=[
    Drink(
        type=bar.OrderType.INGREDIENT,
        product_code="AC-A2DF3",
        quantity=138554,
    ),
])
```

Asynchronous:
```python
res = await s.orders.create_order_async(drinks=[
    Drink(
        type=bar.OrderType.INGREDIENT,
        product_code="AC-A2DF3",
        quantity=138554,
    ),
])
```

## HTTP Client

To make API calls, the Python SDK instantiates its own HTTP client using the `Client` class from the `httpx` library. This allows authentication settings to persist across requests and reduce overhead.

## Parameters

If configured, Speakeasy will generate methods with parameters for each parameter defined in the OpenAPI document, as long as the number of parameters is less than or equal to the configured `maxMethodParams` value in the `gen.yaml` file.

If the number of parameters exceeds the configured `maxMethodParams` value or is set to `0`, a request object will be generated for the method to pass in all parameters as a single object.


## Errors

The Python SDK will raise exceptions for any network or invalid request errors.

For unsuccessful responses, if a custom error response is specified in your spec file, the SDK will unmarshal the HTTP response details into the custom error response to be thrown as an exception.  When no custom response is specified in your spec, the SDK will throw an `SDKException` with details of the failed response.

```python
import sdk
from sdk.models import errors

s = sdk.SDK()
res = None
try:
    res = s.errors.status_get_x_speakeasy_errors(status_code=385913)
except errors.StatusGetXSpeakeasyErrorsResponseBody as e:
    # handle exception
except errors.SDKError as e:
    # handle exception

if res is not None:
    # handle response
    pass
```


## User Agent Strings

The Python SDK includes a [user agent](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/User-Agent) string in all requests. This can be leveraged to track SDK usage amongst broader API usage. The format is as follows: 

```stmpl
speakeasy-sdk/python {{SDKVersion}} {{GenVersion}} {{DocVersion}} {{PackageName}}
```
Where
- `SDKVersion` is the version of the SDK, defined in `gen.yaml` and released
- `GenVersion` is the version of the Speakeasy generator
- `DocVersion` is the version of the OpenAPI document
- `PackageName` is the name of the package defined in `gen.yaml`


 This is the content for the doc docs/languages/python/oss-comparison-python.mdx 

 ---
title: "Comparison guide: OpenAPI/Swagger Python client generation"
description: "Comparing the new Speakeasy Python SDK generator with popular open-source OpenAPI generators"
keywords: [api, openapi, swagger, sdk creation, python, python sdk, developer experience, devex, dx]
---

import { Callout } from '~/components'

# Comparison guide: OpenAPI/Swagger Python client generation

Many of our users have switched from [OpenAPI Generator](https://openapi-generator.tech/) to Speakeasy for their Python SDKs. Learn how to use both SDK creators in this guide, and the differences between them.

Open-source OpenAPI generators are great for experimentation but lack the reliability, performance, and intuitive developer experience required for critical applications. As an alternative, Speakeasy creates [idiomatic SDKs](/post/client-sdks-as-a-service) that meet the bar for enterprise use.

In this post, we'll focus on Python, but Speakeasy can also create SDKs in Go, TypeScript, Java, Ruby, PHP, and more.

<Callout title="View More Comparisons" variant="info">
- [Read about the differences between TypeScript SDKs generated by Speakeasy and OpenAPI Generator.](/post/speakeasy-sdk-vs-openapi-typescript-generator/) <br/>
- [Read about the differences between Go SDKs generated by Speakeasy and OpenAPI Generator.](/post/speakeasy-oss-go-generator)
</Callout>

Here's a summary of the major differences between a Python SDK created using Speakeasy, compared to an SDK created by the OpenAPI Generator. Unless support for Python 3.7 is critically important to you, we recommend using Speakeasy for your Python SDKs.

| Feature/Aspect | Speakeasy | OpenAPI Generator |
|---------------|-----------|-------------------|
| Python Version Support | ✅ Python 3.8+ | ⚠️ Python 3.7+ (outdated) |
| Type Safety | ✅ Pydantic + TypedDict + Advanced Enums | ⚠️ Basic Pydantic only |
| Advanced Data Types | ✅ Supports null, any, union | ⚠️ Limited type support |
| Async Support | ✅ (HTTPX) | ❌ Not supported |
| Documentation Quality | ✅ Rich usage examples with working code | ⚠️ Incomplete examples |
| Retries | ✅ Built-in configurable retries | ❌ No retry support |
| Pagination | ✅ Supported | ❌ Not supported |
| Security Features | ✅ Full OAuth + OpenID support | ⚠️ Basic security only |
| Multiple Servers | ✅ Supported | ❌ Not supported |
| XML Support | ❌ Not supported | ❌ Not supported |
| CI/CD Integration | ✅ Native GitHub Actions | ⚠️ Manual setup required |

For the full technical walkthrough, read on!

## What is OpenAPI Generator?

OpenAPI Generator, as opposed to an OpenAPI generator, is a specific community-run open-source SDK generator for the OpenAPI specification, [focusing on version 3](https://openapi-generator.tech/docs/fork-qna). The [Swagger Codegen](https://swagger.io/tools/swagger-codegen) tool is similar, but run by the company Smartbear. OpenAPI Generator was forked from Swagger Codegen.

## Preparing the SDK generators

For our comparison, we ran Speakeasy and OpenAPI Generator each in its own Docker container, which works on Windows, macOS, or Linux. Using Docker instead of running code directly on your physical machine is safer, as the code cannot access files outside the folder you specify.

We used the PetStore 3.1 YAML schema file from the [Swagger editor](https://editor-next.swagger.io) examples menu in **File > Load Example > OpenAPI 3.1 Petstore**. To follow along with this guide, save the file to a subfolder called `app` in your current path, such as `app/petstore31.yaml`. We changed the schema to use the server version 3.1:

```yaml
servers:
  - url: https://petstore31.swagger.io/api/v31
```

OpenAPI Generator provides a Docker image, but Speakeasy does not. To install the Speakeasy CLI, you can either install the Go binary directly on your computer following the steps in the [Speakeasy Getting Started](/docs/speakeasy-reference/cli/getting-started) guide, or run it in Docker, which we did.

To use Docker yourself, first create a Docker file called `se.dockerfile` with the content below, replacing `YourApiKey` with your key from the Speakeasy website.

```bash
FROM alpine:3.19
WORKDIR /app
RUN apk add bash go curl unzip sudo nodejs npm
RUN curl -fsSL https://go.speakeasy.com/cli-install.sh | sh;
ENV GOPATH=/root/go
ENV PATH=$PATH:$GOPATH/bin
ENV SPEAKEASY_API_KEY=YourApiKey
```

Then build the Speakeasy image with the command below.

```sh
docker build -f se.dockerfile -t seimage .
```

## Validating the schemas

Both OpenAPI Generator and the Speakeasy CLI can validate an OpenAPI schema. We'll run both and compare the output.

### Validation using OpenAPI Generator

To validate `petstore31.yaml` using OpenAPI Generator, run the following in the terminal:

```bash
docker run --rm -v "./app:/local" openapitools/openapi-generator-cli validate -i /local/petstore31.yaml
```

OpenAPI Generator returns two warnings:

```
Warnings:
	- Unused model: Address
	- Unused model: Customer

[info] Spec has 2 recommendation(s).
```

### Validation using Speakeasy

Validate the schema with Speakeasy by running the following in the terminal:

```bash
docker run --rm -v "./app:/app" seimage speakeasy validate openapi -s /app/petstore31.yaml
```

The Speakeasy validator returns 72 hints about missing examples, seven warnings about missing responses, and three warnings about unused components. Each warning includes a detailed JSON-formatted error with line numbers.

Since both validators returned only warnings and not errors, we can assume both generators will create SDKs without issues.

## Creating the SDKs

First, we'll generate an SDK with OpenAPI Generator, and then we'll create one with Speakeasy.

### Generating an SDK with OpenAPI Generator

OpenAPI Generator includes two different Python SDK generators (and four server generators):

* [python](https://openapi-generator.tech/docs/generators/python)
* [python-pydantic-v1](https://openapi-generator.tech/docs/generators/python-pydantic-v1)

The only difference between the two is that `python` is the latest version, which uses Pydantic V2. You can ignore Pydantic V1.

To generate an SDK from the schema file in OpenAPI Generator, we ran the command given in the [OpenAPI Generator readme](https://github.com/OpenAPITools/openapi-generator#16---docker) below.

```sh
docker run --rm -v "./app:/local" openapitools/openapi-generator-cli generate -i /local/petstore31.yaml -g python -o /local/og --additional-properties=packageName=petstore_sdk,projectName=petstore-sdk-python
```

This command gives one warning that looks like it could cause errors, `o.o.codegen.utils.ModelUtils - Failed to get the schema name: null`, but OpenAPI Generator successfully created three folders:

| Folder         | Content                                                                                                                                                                                                |
|----------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| `docs`         | Documentation in `.md` files for each object.                                                                                                                                                          |
| `petstore_sdk` | Python code to call the API on the server, containing a `models` folder for each object in the schema. If you don't pass parameters to the build command, this folder will be called `openapi_client`. |
| `test`         | Unit tests for all objects and operations. These tests are partially or entirely stubs and require you to manually add specific pet instances or operations and the logic to check them.                       |

The generator warned us in the terminal that `Generation using 3.1.0 specs is in development and is not officially supported yet.` The OpenAPI Generator [roadmap](https://openapi-generator.tech/docs/roadmap) hasn't been updated in almost two years.

### Creating an SDK with Speakeasy

Next, we'll create an SDK using the Speakeasy CLI with the command below.

```bash
docker run --rm -v "./app:/app" seimage speakeasy generate sdk --schema /app/petstore31.yaml --lang python --out /app/se
```

Speakeasy creates the following folders.

| Folder | Content                                                                                                |
|--------|--------------------------------------------------------------------------------------------------------|
| `docs` | Documentation in `.md` files for each component and operation.                                         |
| `src`  | Python code to call the API on the server, containing a `models` folder for each object in the schema. |

Unlike the OpenAPI Generator output, the Speakeasy output includes no tests.

## SDK code comparison: Package structure

We'll start our comparison by looking at the structure of each SDK: the OpenAPI Generator SDK and the Speakeasy SDK.

To count the lines of code in the SDKs, we'll run `cloc` for each (ignoring documentation and test folders):

```bash
cloc ./app/og/petstore_sdk
cloc ./app/se/src/openapi
```

Below are the results for each SDK.

| Project           | Files | Blank | Comment | Code | Total lines | Total non-blank lines |
|-------------------|-------|-------|---------|------|-------------|-----------------------|
| OpenAPI Generator | 19    | 1115  | 2243    | 4479 | 7837        | 6722                  |
| Speakeasy         | 69    | 1386  | 498     | 5161 | 7045        | 5659                  |

We see that the Speakeasy SDK has about the same number of lines of code and lines of comments as OpenAPI Generator, but OpenAPI Generator leaves more blank lines.

The following commands output the files of each SDK.

```sh
tree ./app/og/petstore_sdk   # exclude docs and tests
tree ./app/se/src/openapi
```

Below is the output for OpenAPI Generator.

```sh
├── api
│   ├── __init__.py
│   ├── pet_api.py
│   ├── store_api.py
│   └── user_api.py
├── api_client.py
├── api_response.py
├── configuration.py
├── exceptions.py
├── __init__.py
├── models
│   ├── address.py
│   ├── api_response.py
│   ├── category.py
│   ├── customer.py
│   ├── __init__.py
│   ├── order.py
│   ├── pet.py
│   ├── tag.py
│   └── user.py
├── py.typed
└── rest.py
```

The folder structure is simple and clear with nothing unexpected. Files are separated at the API level (pet, store, and user) and by model. There are a few helper files, like `exceptions.py`.

Below is the output for Speakeasy.

```sh
├── basesdk.py
├── _hooks
│   ├── __init__.py
│   ├── registration.py
│   ├── sdkhooks.py
│   └── types.py
├── httpclient.py
├── __init__.py
├── models
│   ├── components
│   │   ├── apiresponse.py
│   │   ├── category.py
│   │   ├── httpmetadata.py
│   │   ├── __init__.py
│   │   ├── order.py
│   │   ├── pet.py
│   │   ├── security.py
│   │   ├── tag.py
│   │   └── user.py
│   ├── errors
│   │   ├── __init__.py
│   │   └── sdkerror.py
│   ├── __init__.py
│   └── operations
│       ├── addpet_form.py
│       ├── addpet_json.py
│       ├── addpet_raw.py
│       ├── createuser_form.py
│       ├── createuser_json.py
│       ├── createuser_raw.py
│       ├── createuserswithlistinput.py
│       ├── deleteorder.py
│       ├── deletepet.py
│       ├── deleteuser.py
│       ├── findpetsbystatus.py
│       ├── findpetsbytags.py
│       ├── getinventory.py
│       ├── getorderbyid.py
│       ├── getpetbyid.py
│       ├── getuserbyname.py
│       ├── __init__.py
│       ├── loginuser.py
│       ├── logoutuser.py
│       ├── placeorder_form.py
│       ├── placeorder_json.py
│       ├── placeorder_raw.py
│       ├── updatepet_form.py
│       ├── updatepet_json.py
│       ├── updatepet_raw.py
│       ├── updatepetwithform.py
│       ├── updateuser_form.py
│       ├── updateuser_json.py
│       ├── updateuser_raw.py
│       └── uploadfile.py
├── pet.py
├── sdkconfiguration.py
├── sdk.py
├── store.py
├── types
│   ├── basemodel.py
│   └── __init__.py
├── user.py
└── utils
    ├── enums.py
    ├── eventstreaming.py
    ├── forms.py
    ├── headers.py
    ├── __init__.py
    ├── metadata.py
    ├── queryparams.py
    ├── requestbodies.py
    ├── retries.py
    ├── security.py
    ├── serializers.py
    ├── url.py
    └── values.py
```

The Speakeasy SDK is more complex and has more features. Files are separated at a lower level than OpenAPI Generator — at the operation level – and further split into media types of the operation, like `addpet_json.py`. There are more helper files bundled with the SDK in the `utils` folder. The `_hooks` folder allows you to [insert custom code](/docs/customize/code/sdk-hooks) into the SDK.

## Calling the server

Swagger provides a complete test server for the PetStore OpenAPI version 3.1 server at https://petstore31.swagger.io. (There is a version 3.0 server too, but that gives 500 errors when called.)

To check that both SDKs contain code that actually works, we called the pet operations given in the readme files against the test server.

We used a Docker Python 3.8 container, as 3.8 is supported by both OpenAPI Generator and Speakeasy.

### Calling the server with OpenAPI Generator

For OpenAPI Generator, we ran the command below, with a successful response. First, the command installs the Python dependencies in the Docker container as recommended in the SDK `README.md` file, then it runs the sample `main.py` script to call the server using the SDK.

```sh
docker run --rm -v "./app/og:/app" -w "/app" python:3.8.19-alpine3.20 sh -c  "pip install . && python setup.py install && python main.py"

# The response of PetApi->add_pet:
# Pet(id=10, name='doggie', category=None, photo_urls=['string'], tags=[], status='available')
```

The `README.md` does not give clear instructions for installing all dependencies. After running the installation commands above, `pytest` was not installed, even though it was mentioned in `README.md`.

Below is the `main.py` script to call the API.

```py
import petstore_sdk
from petstore_sdk.models.pet import Pet
from petstore_sdk.rest import ApiException
from pprint import pprint

configuration = petstore_sdk.Configuration(
    host = "https://petstore31.swagger.io/api/v31"
)
with petstore_sdk.ApiClient(configuration) as api_client:
    api_instance = petstore_sdk.PetApi(api_client)
    pet = Pet.from_json('''{
        "id": 10,
        "name": "doggie",
        "photoUrls": [
            "string"
        ],
        "status": "available"
        }''')
    try:
        api_response = api_instance.add_pet(pet)
        print("The response of PetApi->add_pet:\n")
        pprint(api_response)
    except ApiException as e:
        print("Exception when calling PetApi->add_pet: %s\n" % e)
```

The example code was partially given in `README.md`, but we needed to add the pet JSON sample from https://petstore31.swagger.io/#/pet/addPet.

### Calling the server with Speakeasy

Speakeasy also called the server successfully. The command below is almost identical to the one for OpenAPI Generator in the previous section, except that the Speakeasy SDK has more dependencies than OpenAPI Generator. Poetry needs packages that are not included with a minimal Linux installation.

```sh
docker run --rm -v "./app/se:/app" -w "/app" python:3.8.19-alpine3.20 sh -c "apk update && apk add --no-cache gcc musl-dev libffi-dev openssl-dev python3-dev py3-cffi py3-cryptography make && pip install --upgrade pip &&
pip install . && pip install poetry && poetry install && python main.py"

# Updated pet name: doggie
```

Before `poetry install` would work however, we had to comment out the invalid line in `pyproject.toml`:

```toml
[tool.poetry.group.extraDependencies.dependencies]
# dev = "[object Object]"
```

Below is the `main.py` script to call the API. The code comes straight from the `README.md` file (except the print line), including the correct JSON to create a pet.

```py
from openapi import SDK
s = SDK(petstore_auth="<YOUR_PETSTORE_AUTH_HERE>",)
res = s.pet.update_pet_json(request={
    "name": "doggie",
    "photo_urls": [
        "<value>",
    ],
    "id": 10,
    "category": {
        "id": 1,
        "name": "Dogs",
    },
})
if res.pet is not None:
    print("Updated Pet Name:", res.pet.name)
```

## Models, data containers, and typing

Both SDKs use strong typing in their models.

The OpenAPI Generator and Speakeasy SDK models inherit from the Pydantic `BaseModel` class. [Pydantic](https://docs.pydantic.dev/latest) validates data at runtime and provides clear error messages when data is invalid.

For example, creating a `Pet` object with the `name` field set to an integer value will result in a validation error:

```python
# Python Nextgen SDK
import petstore_sdk

pet = petstore_sdk.Pet(id=1, name="Archie", photoUrls=[])

pet2 = petstore_sdk.Pet(id=2, name=2, photoUrls=[])
# > pydantic.error_wrappers.ValidationError: 1 validation error for Pet
# > name
# >   str type expected (type=type_error.str)
```

Both SDKs create a `BaseModel` pet like below.

```py
class Pet(BaseModel):
    name: Annotated[str, FieldMetadata(form=True)]
    photo_urls: Annotated[List[str], pydantic.Field(alias="photoUrls"), FieldMetadata(form=True)]
    id: Annotated[Optional[int], FieldMetadata(form=True)] = None
    category: Annotated[Optional[Category], FieldMetadata(form=FormMetadata(json=True))] = None
    tags: Annotated[Optional[List[Tag]], FieldMetadata(form=FormMetadata(json=True))] = None
    status: Annotated[Annotated[Optional[Status], PlainValidator(validate_open_enum(False))], FieldMetadata(form=True)] = None
    r"""pet status in the store"""
```

In addition, Speakeasy adds `TypedDict`s to its components. An example is from `Pet.py` below.

```py
class PetTypedDict(TypedDict):
    name: str
    photo_urls: List[str]
    id: NotRequired[int]
    category: NotRequired[CategoryTypedDict]
    tags: NotRequired[List[TagTypedDict]]
    status: NotRequired[Status]
    r"""pet status in the store"""
```

These typings provide strong runtime type checking and static type safety, which your IDE can use, too.

Speakeasy also has enums in models, which OpenAPI Generator does not. Below is an example from the pet model.

```python
class Status(str, Enum):
    r"""pet status in the store"""
    AVAILABLE = 'available'
    PENDING = 'pending'
    SOLD = 'sold'
```

Contrast this enum with the string-based specification and validation created by OpenAPI Generator:

```python
class Pet(BaseModel):
    id: Optional[StrictInt] = None
    ...
    status: Optional[StrictStr] = Field(default=None, description="pet status in the store")
    ...

    @field_validator('status')
    def status_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['available', 'pending', 'sold']):
            raise ValueError("must be one of enum values ('available', 'pending', 'sold')")
        return value

    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    ... many more boilerplate methods below...
```

The OpenAPI Generator class also has to include many boilerplate methods for Pydantic, which is done for every model in the schema. Speakeasy models are more concise.

### Open enums

Speakeasy allows adding the custom attribute `x-speakeasy-unknown-values` to an OpenAPI field to allow [open enums](/post/open-enums).

```yaml
status:
    type: string
    x-speakeasy-unknown-values: allow
    description: pet status in the store
    enum:
    - available
    - pending
    - sold
```

The SDK code for an open enum doesn't change much from a standard enum. It's shown below.

```py
class Status(str, Enum, metaclass=utils.OpenEnumMeta):
    r"""pet status in the store"""
    AVAILABLE = 'available'
    PENDING = 'pending'
    SOLD = 'sold'
```

Adding `x-speakeasy-unknown-values` will result in a Python SDK that allows values for `status` that are outside the given list of `available`, `pending`, and `sold`. There will no longer be a conflict between a new version of an API sending an unknown enum value to an older version of an SDK.

The disadvantage of this open enum technique is that it allows clients to send mistaken and incorrect values to the server.

The OpenAPI Specification has no way to handle enum conflicts between schema versions currently, and so OpenAPI Generator has no similar feature to open enums. A standard solution is still being [debated on GitHub](https://github.com/OAI/OpenAPI-Specification/issues/1552).

## SDK dependencies

OpenAPI Generator and Speakeasy use almost identical Python packages.

OpenAPI Generator has the following dependencies in its `requirements.txt` file.

```text
python_dateutil >= 2.5.3
setuptools >= 21.0.0
urllib3 >= 1.25.3, < 2.1.0
pydantic >= 2
typing-extensions >= 4.7.1
```

OpenAPI Generator also has a `pyproject.toml` file, though OpenAPI Generator does not mention this file in the installation instructions.

Speakeasy has the following dependencies in its `pyproject.toml` file.

```py
httpx = "^0.27.0"
jsonpath-python = "^1.0.6"
pydantic = "^2.7.1"
python-dateutil = "^2.9.0.post0"
typing-inspect = "^0.9.0"
```

### HTTP client library

The OpenAPI Generator SDK uses `urllib3` in its HTTP clients, while the Speakeasy SDK uses the `urllib3` and the [HTTPX](https://www.python-httpx.org/) library.

HTTPX is future-proofed for HTTP/2 and asynchronous method calls. As per the Speakeasy SDK readme, you can call the server using synchronous or asynchronous calls, as shown below.

```py
import asyncio
from openapi import SDK

async def main():
    res = await s.pet.update_pet_form_async(request={
        "name": "doggie",
    ...
```

## Supported Python versions

At the time of compiling this comparison, the Speakeasy SDK required at least Python version 3.8, which is supported until October 2024. The OpenAPI Generator SDK required at least Python version 3.7, which ended support halfway through 2023.

We recommend you use the latest Python version with both SDKs.

## Retries

The SDK created by Speakeasy can automatically retry failed network requests or retry requests based on specific error responses. This provides a simpler developer experience for error handling.

To enable this feature, use the Speakeasy `x-speakeasy-retries` extension in your schema. We'll update the PetStore schema to add retries to the `addPet` operation as a test.

Edit `petstore31.yaml` and add the following to the `addPet` operation:

```yaml
      x-speakeasy-retries:
        strategy: backoff
        backoff:
          initialInterval: 500        # 500 milliseconds
          maxInterval: 60000          # 60 seconds
          maxElapsedTime: 3600000     # 5 minutes
          exponent: 1.5
```

Add this snippet to the operation:

```yaml
#...
paths:
  /pet:
    # ...
    post:
      #...
      operationId: addPet
      x-speakeasy-retries:
        strategy: backoff
        backoff:
          initialInterval: 500        # 500 milliseconds
          maxInterval: 60000          # 60 seconds
          maxElapsedTime: 3600000     # 5 minutes
          exponent: 1.5
```

Now we can rerun the Speakeasy creator to enable retries for failed network requests when creating a new pet. It is also possible to enable retries for the SDK as a whole by adding global `x-speakeasy-retries` at the root of the schema.

## Created documentation

Both Speakeasy and OpenAPI Generator create a `docs` directory with documentation and usage examples.

We found the usage examples in the Speakeasy SDK worked flawlessly, while the examples in the OpenAPI Generator SDK don't always include required fields when instantiating objects. For instance, the `Pet.md` example has the code below.

```py
# TODO update the JSON string below
json = "{}"
```

The OpenAPI Generator SDK's documentation is especially thorough regarding models and has a table of fields and their types for each model. The Speakeasy SDK's documentation is focused on usage, with a usage example for each operation for each model.

Speakeasy also creates appropriate example strings based on a field's `format` in the OpenAPI schema.

For example, if we add `format: uri` to the item for a pet's photo URLs, we can compare each SDK's usage documentation for this field.

The SDK created by Speakeasy includes a helpful example of this field that lists multiple random URLs:

```python
# Speakeasy SDK Usage Example
pet = shared.Pet(
    # ...
    photo_urls=[
        'https://salty-stag.name',
        'https://moral-star.info',
        'https://present-giggle.info',
    ]
)
```

The OpenAPI Generator SDK's documentation uses a single random string in its example:

```python
# Python SDK Usage Example
pet = Pet(
    # ...
    photo_urls=[
        "photo_urls_example"
    ]
)
```

## Automation

This comparison focuses on installing and using Speakeasy and OpenAPI Generator using the command line, but both tools can also run as part of a CI workflow. For example, you can set up a [GitHub Action](https://github.com/speakeasy-api/sdk-generation-action) to ensure your Speakeasy SDK is always up to date when your API schema changes.

## Unsupported features

At the time of writing, OpenAPI Generator does not support:

- [Data types null, any, union, and UUID](https://openapi-generator.tech/docs/generators/python/#data-type-feature).
- [OAuth and OpenID security](https://openapi-generator.tech/docs/generators/python/#security-feature).
- [Multiple servers](https://openapi-generator.tech/docs/generators/python/#global-feature) (the place where clients call your SDK) and server URLs with parameters.
- [Callbacks](https://openapi-generator.tech/docs/generators/python/#global-feature) (allowing your server to call a client).
- [Link objects](https://openapi-generator.tech/docs/generators/python/#global-feature) (relating operations to each other to indicate a workflow).

Speakeasy supports all the features above. Nullable fields in a Speakeasy SDK are marked as `Optional[]`.

Neither Speakeasy nor OpenAPI Generator supports XML requests and responses.

## Summary

Open-source tooling can be a great way to experiment, but if you're working on production code, the Speakeasy Python SDK creator will help ensure that you create reliable and performant Python SDKs.

The Speakeasy Python SDK creator uses data classes to provide good runtime performance and exceptional readability, and automatic retries for network issues make error handling straightforward. The Speakeasy-created documentation includes a working usage example for each operation. Finally, unlike other Python SDK creators, Speakeasy can publish your created SDK to PyPI and run it as part of your CI workflows.



 This is the content for the doc docs/languages/ruby/methodology-ruby.mdx 

 ---
title: "Ruby Design - Coming Soon!"
description: "Discover the Speakeasy Ruby SDK design methodology."
---

# Ruby Design - Coming Soon ! 


 This is the content for the doc docs/languages/swift/methodology-swift.mdx 

 ---
title: "Create Swift SDKs from OpenAPI / Swagger"
description: "Generate a Swift client from your Swagger / OpenAPI spec in minutes with Speakeasy."
---


# Create Swift SDKs from OpenAPI / Swagger

Speakeasy Swift SDKs are designed to be seamlessly integrated alongside your users' existing code:

- **Modern and idiomatic:** Speakeasy Swift SDKs use modern, idiomatic Swift features such as async/await for concurrency, protocols, throwing functions for error handling, and the [`Codable`](https://developer.apple.com/documentation/swift/codable) protocol for JSON serialization and deserialization.
- **Type-safe:** Where appropriate, Speakeasy Swift SDKs use structures and enumerated types to ensure your users are passing the correct data to your endpoints.
- **Backwards compatible:** iOS 13+ is supported, ensuring your users can target a wide range of devices and users.
- **Zero-dependency:** Speakeasy Swift SDKs have zero dependencies to minimize binary size and package resolution time.
- **Well-documented:** Speakeasy Swift SDKs are well-documented and can be used to generate modern and idiomatic documentation sites using the Apple [DocC documentation format](https://developer.apple.com/documentation/docc) that feel right at home for Swift developers.

## Swift SDK Design

Speakeasy Swift SDKs include a few main components:

- A `Client` class, which is the workhorse and entry point for making requests to your API.
- A Swift protocol (interface), which defines functions for the available operations that are exposed by your API. This API protocol is also namespaced by any [tags](https://swagger.io/docs/specification/grouping-operations-with-tags/) you define in your API specification and adopted by the `Client` class.
- Request and response objects (defined as Swift structures), which are used to structure data for API requests and are deserialized from API responses.

### Client Class and API Protocols

Speakeasy Swift SDKs provide a `Client` class for your users to interact with your API. This class uses the Apple [`URLSession`](https://developer.apple.com/documentation/foundation/urlsession) and [`URLRequest`](https://developer.apple.com/documentation/foundation/urlrequest) types to construct, make, and handle the responses of network requests.

The SDKs serialize request data and deserialize server responses using a rich type system, which frees users from having to manually convert data types and handle errors.

The available operations of your API are defined using a Swift protocol, providing an easy reference for the functions your users can perform against your API. This protocol is adopted by the `Client` class.

### Request and Response Models

Speakeasy Swift SDKs translate the data types required by your API operations into request objects, either Swift structs or enumerated types, depending on your API specification. For example, an operation that takes a set of optional parameters to query a set of pets could be implemented as a request:

```swift
public struct PetFilter {
  public let name: String?
  public let breed: String?
  public let minimumAge: Int?

  public init(name: String?, breed: String?, minimumAge: Int?) {
    self.name = name
    self.breed = breed
    self.minimumAge = minimumAge
  }
}
```

This approach allows your users to pass data to each API operation, which is then serialized into the appropriate format and included in the endpoint path, request body, or headers when making the actual request to your API.

### Type-Safe Security and Server Models

While the OpenAPI Specification allows for maximum flexibility in defining server configuration and authorization and authentication strategies, Speakeasy Swift SDKs take advantage of enumerated types to ensure that your users provide you with the right data for these values at the right call sites.

For example, Speakeasy Swift SDKs trivially support any security schemes defined by your API specification:

```swift
public enum Security {
  case apiKey(String)
  case authToken(String)
}
```

Our Swift SDKs also provide type-safe server configuration based on your specification, including any substituted variables comprised of primitive or custom types:

```swift
public enum GlobalServers {
  /// Corresponds to `https://example.com`
  case server1
  /// Corresponds to `https://{hostname}:{port}`
  case server2(hostname: String = "localhost", port: String = "35123")
  /// Corresponds to `http://{environment}.example.com`
  case server3(environment: Environment = .staging)
}
```

These security and server configuration parameters are also provided at the operation level, depending on your API specification.

### Enumerated Responses

The OpenAPI specification allows each of your API operations to define multiple response types, and our Swift SDKs make use of this to return enumerated values for each operation function. This allows your users to easily distinguish between and use response values returned by your API.

While these are enumerated types, Speakeasy SDKs include helper functions to access the right data when you need it:

```swift
public enum PetsResponse {
  case empty
  case pets(Shared.PetsModel)
  case error(Shared.Error)

  var isEmpty: Bool {
      if case .empty = self {
          return true
      } else {
          return false
      }
  }

  public func pets() throws -> Shared.PetsModel {
      guard case .pets(let value) = self else {
          throw PetStoreError.missingResponseData
      }
      return value
  }

  public func error() throws -> Shared.Error {
      guard case .error(let value) = self else {
          throw PetStoreError.missingResponseData
      }
      return value
  }
}
```

This allows you to easily determine whether a response is empty, or get either the pets or error model and handle any errors if the response is not of the type you expect.

### Errors

Speakeasy Swift SDKs provide a comprehensive and detailed error type that provides your customers with information in cases where anything goes wrong, from constructing a request URL, to network errors, to any problems that occur when deserializing response values.

This type conforms to the Swift `Error` protocol, as well as providing detailed reasoning and descriptive error information.

## Swift Package Management

Speakeasy Swift SDKs support distribution using the [Swift Package Manager](https://www.swift.org/package-manager/) out-of-the-box. This makes it easy to distribute your SDKs to your customers via any hosted Git repository (usually GitHub), versioned using [Git tags](https://git-scm.com/book/en/v2/Git-Basics-Tagging).

**Coming soon:** Speakeasy will soon support the distribution of your Swift SDKs through [CocoaPods](https://cocoapods.org/).

## Documentation

Speakeasy uses the Apple [DocC documentation format](https://developer.apple.com/documentation/docc) to generate documentation for your SDK automatically.

**Coming soon:** The Speakeasy [Generation Action](https://github.com/speakeasy-api/sdk-generation-action) will soon allow you to automatically maintain a documentation site hosted by GitHub Pages so that your users can easily browse the documentation for your Swift SDK.

![Generated Swift documentation](./assets/swift-docs.png)


 This is the content for the doc docs/languages/typescript/feature-support.mdx 

 ---
title: "TypeScript Feature Reference"
description: "An overview of TypeScript features supported by Speakeasy for SDK generation from an OpenAPI / Swagger spec."
---

# TypeScript Feature Reference

## Authentication

|    Name    | Support |  Docs  |   Notes |
|------------|:---:|------------------|---------|
| HTTP Basic |   ✅    |     Docs         |         |
| API Key <br /> (bearer, header, cookie, query) |   ✅    |     Docs         |         |
| OAuth <br /> implicit flow |   ✅    |     Docs         |         |
| OAuth <br /> refresh token flow |   ✅ using security callbacks    |     Docs         |         |
| OAuth <br /> client credentials flow |   ✅ using hooks    |     Docs         |         |
| mTLS |   🏗️ Partial    |     Docs         |         |

## Server Configuration

|       Name     | Support |  Docs  |   Notes |
|----------------|:-------:|--------------|--------|
| URL Templating |    ✅    | [defining `variables`](/docs/customize-sdks/servers#use-templated-urls) |  |
| Multiple server|    ✅    | [`x-speakeasy-server-id` extension](/docs/customize-sdks/servers#declare-multiple-servers) |  |
| Describe server <br /> outside your spec  | ✅    | [`serverUrl` config](/docs/customize-sdks/servers#declare-base-server-url) |  |

## Data Types

### Basic Types

| Name | Support |  Docs  |   Notes |
|------|:-------:|--------------|--------|
| Numbers |    ✅    | [data-types](https://swagger.io/docs/specification/data-models/data-types/#numbers) | `float`, `double`, `int32`, `int64` |
| Strings |    ✅    | [data-types](https://swagger.io/docs/specification/data-models/data-types/#strings) |  |
| Date Time |    ✅    | [data-types](https://swagger.io/docs/specification/data-models/data-types/#date-time) |  |
| Boolean |    ✅    | [data-types](https://swagger.io/docs/specification/data-models/data-types/#booleans) |  |
| Binary |    ✅    | [data-types](https://swagger.io/docs/specification/data-models/data-types/#binary) |  |
| Enums |    ✅    | [data-types](https://swagger.io/docs/specification/data-models/data-types/#enumerations) |  |
| Arrays |    ✅    | [data-types](https://swagger.io/docs/specification/data-models/data-types/#arrays) |  |
| Maps |    ✅    | [data-types](https://swagger.io/docs/specification/data-models/data-types/#maps) |  |
| Objects |    ✅    | [data-types](https://swagger.io/docs/specification/data-models/data-types/#objects) |  |
| Any |    ✅    | [data-types](https://swagger.io/docs/specification/data-models/data-types/#any) |  |
| Null |    ✅    | [data-types](https://swagger.io/docs/specification/data-models/data-types/#nil) |  |

### Polymorphism

| Name | Support |  Docs  |   Notes |
|------|:-------:|--------------|--------|
| Union Types |    ✅    | [Using `oneOf`](https://swagger.io/docs/specification/data-models/oneof-anyof-allof-not/#oneof) | `anyOf` is treated as `oneOf` and will create a union type object. |
| Intersection Types |   🏗️ Partial     | [Using `allOf`](https://swagger.io/docs/specification/data-models/oneof-anyof-allof-not/#allof) |  |


## Methods

|     Name    | Support |  Docs  |   Notes |
|-------------|:-------:|--------------|--------|
| Namespacing |    ✅    | [grouping operations](/docs/customize-sdks/namespaces) |  |
| Multi-level Namespacing |    ✅    | [multi-level grouping](/docs/customize-sdks/namespaces#define-multi-level-namespaces) |  |
| Custom naming|    ✅    | [`x-speakeasy-name-override` extension](/docs/customize-sdks/methods#change-method-names) |  |
| Exclude Methods |    ✅    | [`x-speakeasy-ignore` extension](/docs/customize-sdks/methods#exclude-methods-from-sdk) |  |
| Deprecation |    ✅    | the [`deprecate` flag](/docs/customize-sdks/methods#deprecate-methods) |  |

## Parameters

|     Name    | Support |  Docs  |   Notes |
|-------------|:-------:|--------------|--------|
| Pass Inline |    ✅    | [flattening parameters](/docs/customize-sdks/methods#configuring-method-signatures) |  |
| Pass via Request Object |    ✅    | [request object](/docs/customize-sdks/methods#configuring-method-signatures) |  |
| Exclude Parameters |    ✅    | [`x-speakeasy-ignore` extension](/docs/customize-sdks/methods#exclude-parameters-from-signatures) |  |
| Deprecate Parameters |    ✅    | the [`deprecate` flag](/docs/customize-sdks/deprecations#deprecate-parameters) |  |
| Define globally |    ✅    | [global parameters](/docs/customize-sdks/globals) |  |

### Path Parameters Serialization

|     Name    | Support |  Docs  |   Notes |
|-------------|:-------:|--------------|--------|
| Default <br /> `(style = simple, explode = false)` |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#path/) |  |
| Basic types |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#path/) |  |
| Simple objects |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#path/) |  |
| `label` & `matrix` |    ❌    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#path/) |  |

### Query Parameters Serialization

|     Name    | Support |  Docs  |   Notes |
|-------------|:-------:|--------------|--------|
| `json` |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#query/) |  |
| `form` |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#query/) |  |
| `spaceDelimited` |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#query/) |  |
| `pipeDelimited` |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#query/) |  |
| `deepObject` |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#query/) |  |
| Basic types |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#query/) |  |
| Simple objects |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#query/) |  |

## Requests

|     Name    | Support |  Docs  |   Notes |
|-------------|:-------:|--------------|--------|
| Request headers |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#header/) |  |
| Request retries |    ✅    | [retries](/docs/customize-sdks/retries) |  |
| `json` |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#request-body/) | Both `application/json` and `text/json`  |
| form data |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#request-body/) |  |
| binary |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#request-body/) |  |
| raw byte |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#request-body/) |  |
| plain text |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#request-body/) |  |
| `x-www-form-urlencoded` |    🏗️ Partial    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#request-body/) | Including encoding, but not non-object types |
| XML |    ❌    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#request-body/) |  |
| Other media types |    ❌    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#request-body/) |  |

## Responses

|     Name    | Support |  Docs  |   Notes |
|-------------|:-------:|--------------|--------|
| Pagination |    ✅    | [`x-speakeasy-pagination` extension](/docs/customize-sdks/pagination) |  |
| Custom Errors |    ✅    | [`x-speakeasy-errors` extension](/docs/customize-sdks/errors) |  |
| json |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#response/) |  |
| plain text |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#response/) |  |
| binary |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#response/) |  |
| raw byte |    ✅    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#response/) |  |
| XML |    ❌    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#response/) |  |
| Other media types   |    ❌    | [Swagger Docs](https://swagger.io/docs/specification/serialization/#response/) |  |

## Documentation

|     Name    | Support |  Docs  |   Notes |
|-------------|:-------:|--------------|--------|
|  `README` generation |    ✅    | [README generation](/docs/customize-sdks/sdk-docs) |  |
|  Usage Snippet generation |    ✅    | [snippet generation](/docs/customize-sdks/sdk-docs#usage-examples) |  |
|  Documentation generation |    ✅    | [documentation generation](/docs/customize-sdks/sdk-docs) |  |


 This is the content for the doc docs/languages/typescript/methodology-ts.mdx 

 ---
title: "Create TypeScript SDKs from OpenAPI / Swagger"
description: "Learn how Speakeasy generates Typescript SDKs from your OpenAPI / Swagger spec."
---

import { ScrollyCoding } from "~/components/codehike/Scrollycoding";
import { Callout } from "~/components";

# Create TypeScript SDKs from OpenAPI / Swagger

## SDK Overview

The Speakeasy TypeScript SDK creation builds idiomatic TypeScript libraries using standard web platform features.

The SDK is strongly typed, makes minimal use of third-party modules, and is straightforward to debug. Using the SDKs that Speakeasy generates will feel familiar to TypeScript developers. We make opinionated choices in some places but do so thoughtfully and deliberately.

The core features of the TypeScript SDK include:

- Compatibility with vanilla JavaScript projects since the SDK's consumption is through `.d.ts` (TypeScript type definitions) and `.js` files.
- Usable on the server and in the browser.
- Use of the `fetch`, `ReadableStream`, and async iterable APIs for compatibility with popular JavaScript runtimes:
  - Node.js
  - Deno
  - Bun
- Support for streaming requests and responses.
- Authentication support for OAuth flows and support for standard security mechanisms (HTTP Basic, application tokens, and so on).
- Optional pagination support for supported APIs.
- Optional support for retries in every operation.
- Complex number types including big integers and decimals.
- Date and date/time types using RFC3339 date formats.
- Custom type enums using strings and integers.
- Union types and combined types.

## TypeScript Package Structure

```yaml lib-structure.yaml
|-- src                # Root for all library source files
|   └-- lib            # The core internals of the SDK
|   |   └-- ...
|   |   └-- http.ts
|   |   └-- sdks.ts
|   |   └-- http.ts
|   |   └-- ...
|   |-- sdk
|   |   └-- models
|   |   |   └-- errors
|   |   |   └-- operations  # Namespace for additional helper types used during marshaling and unmarshalling
|   |   |   |   └-- ...
|   |   |   └-- shared      # Namespace for the SDK's shared models, including those from OpenAPI components
|   |   |   |   └-- ...
|   |   └-- types           # Custom types support used in the SDK
|   |   |   └-- ...
|   |   └-- index.ts
|   |   └-- sdk.ts
|   |   └-- ..
|   └-- index.ts
|-- docs               # Markdown files for the SDK's documentation
|   └- ...
└-- ...
```

## Runtime Environment Requirements

The SDK targets ES2018, ensuring compatibility with a wide range of JavaScript runtimes that support this version. Key features required by the SDK include:

- [Web Fetch API][web-fetch]
- [Web Streams API][web-streams] and in particular `ReadableStream`
- [Async iterables][async-iter] using `Symbol.asyncIterator`

[web-fetch]: https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API
[web-streams]: https://developer.mozilla.org/en-US/docs/Web/API/Streams_API
[async-iter]: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Iteration_protocols#the_async_iterator_and_async_iterable_protocols

Runtime environments that are explicitly supported are:

- Evergreen browsers: Chrome, Safari, Edge, Firefox.
- Node.js active and maintenance LTS releases (currently, v18 and v20).
- Bun v1 and above.
- Deno v1.39 - Note Deno doesn't currently have native support for streaming file uploads backed by the filesystem ([issue link][deno-file-streaming]).

[deno-file-streaming]: https://github.com/denoland/deno/issues/11018

<Callout title="Note" variant="info">
  For teams interested in working directly with the SDK&apos;s source files, our SDK
  leverages TypeScript `v5` features. To directly consume these source files,
  your environment should support TypeScript version 5 or higher. This
  requirement applies to scenarios where direct access to the source is
  necessary.
</Callout>

## TypeScript HTTP Client

TypeScript SDKs stick as close to modern and ubiquitous web standards as possible. We use the `fetch()` API as our HTTP client. The API includes all the necessary building blocks to make HTTP requests: `fetch`, `Request`, `Response`, `Headers`, `FormData`, `File`, and `Blob`.

The standard nature of this SDK ensures it works in modern JavaScript runtimes, including Node.js, Deno, Bun, and React Native. We’ve run our extensive suite to confirm that new SDKs work in Node.js, Bun, and browsers.

## Type System

### Primitive Types

Where possible the TypeScript SDK uses primitive types such as `string`, `number`, and `boolean`. In the case of arbitrary-precision decimals, a third-party library is used since there isn't a native decimal type. Using decimal types is crucial in certain applications such as code manipulating monetary amounts and in situations where overflow, underflow, or truncation caused by precision loss can lead to significant incidents.

To describe a decimal type in OpenAPI, use the `format: decimal` keyword. The SDK will take care of serializing and deserializing decimal values under the hood using the [decimal.js](https://github.com/MikeMcl/decimal.js) library.

```typescript
import { SDK } from "@speakeasy/super-sdk";
import { Decimal } from "@speakeasy/super-sdk/types";

const sdk = new SDK();
const result = await sdk.payments.create({
  amount: new Decimal(0.1).add(new Decimal(0.2))
});
```

Similar to decimal types, we’ve introduced support for native `BigInt` values for numbers too large to be represented using the JavaScript `Number` type.

In an OpenAPI schema, fields for big integers can be modeled as strings with `format: bigint`.

```typescript
import { SDK } from "@speakeasy/super-sdk";

const sdk = new SDK();
const result = await sdk.doTheThing({
  value: 67_818_454n,
  value: BigInt("340656901")
});
```

### Generated Types

The TypeScript SDK generates a type for each request, response, and shared model in your OpenAPI schema. Each model is backed by a [Zod](https://zod.dev/) schema that validates the objects at runtime.

<Callout title="Note" variant="info">
  It&apos;s important to note that data validation is run on user input when calling
  an SDK method _and on the subsequent response data from the server_. If
  servers are not returning data that matches the OpenAPI spec, then validation
  errors are thrown at runtime.
</Callout>

Below is a complete example of a shared model created by the TypeScript generator:

<ScrollyCoding>

#### !!steps Public Type

The `DrinkOrder` type represents the public type the model file exports and what SDK users will work with inside their code.

```typescript ! drinkorder.ts
// !focus(6:12)
import { Decimal as Decimal$ } from "../../types";
import { Customer, Customer$ } from "./customer";
import { DrinkType, DrinkType$ } from "./drinktype";
import { z } from "zod";

export type DrinkOrder = {
    id: string;
    type: DrinkType;
    customer: Customer;
    totalCost: Decimal$ | number;
    createdAt: Date;
};

/** @internal */
export namespace DrinkOrder$ {
  export type Inbound = {
    id: string;
    type: DrinkType;
    customer: Customer$.Inbound;
    total_cost: string;
    created_at: string;
  };

  export const inboundSchema: z.ZodType<DrinkOrder, z.ZodTypeDef, Inbound> = z
    .object({
      id: z.string(),
      type: DrinkType$,
      customer: Customer$.inboundSchema,
      total_cost: z.string().transform((v) => new Decimal$(v)),
      created_at: z
        .string()
        .datetime({ offset: true })
        .transform((v) => new Date(v)),
    })
    .transform((v) => {
      return {
        id: v.id,
        type: v.type,
        customer: v.customer,
        totalCost: v.total_cost,
        createdAt: v.created_at,
      };
    });

  export type Outbound = {
    id: string;
    type: DrinkType;
    customer: Customer$.Outbound;
    total_cost: string;
    created_at: string;
  };

  export const outboundSchema: z.ZodType<Outbound, z.ZodTypeDef, DrinkOrder> = z
    .object({
      id: z.string(),
      type: DrinkType$,
      customer: Customer$.outboundSchema,
      totalCost: z
        .union([z.instanceof(Decimal$), z.number()])
        .transform((v) => `${v}`),
      createdAt: z.date().transform((v) => v.toISOString()),
    })
    .transform((v) => {
      return {
        id: v.id,
        type: v.type,
        customer: v.customer,
        total_cost: v.totalCost,
        created_at: v.createdAt,
      };
    });
}
```

---

#### !!steps Internal Types

A special namespace accompanies every model and contains the types and schemas for the model that represent inbound and outbound data.

> The namespace, including types and values in it, isn't intended for use outside the SDK and is marked as `@internal`.

```typescript ! drinkorder.ts
// !focus(14:15)

```

---

## !!steps

The inbound representation of a model defines the shape of the data received from a server. It is validated and deserialized into the public type above.

```typescript ! drinkorder.ts
// !focus(16:43)

```

---

## !!steps

The outbound representation of a model defines the shape of the data sent to a server. A user provides a value that satisfies the public type above and the outbound schema serializes it into what the server expects.

```typescript ! drinkorder.ts
// !focus(45:71)
```

---

### !!steps Zod Validation

All generated models have this overall structure. By pinning the types with runtime validation, Speakeasy gives users a stronger guarantee that the SDK types they work with during development are valid at runtime, otherwise, Speakeasy throws exceptions that fail loudly.

```typescript ! drinkorder.ts

```

</ScrollyCoding>

<Callout title="Note" variant="info">
It&apos;s important to note that Zod is a peer dependency.

The reason for listing Zod as a peer dependency is to use the user&apos;s installation of Zod if they have it. Every popular package manager, except for Yarn, says, &quot;If the user doesn&apos;t have a peer dependency installed, I&apos;m gonna go ahead and install it and make it available&quot;.

Why does Speakeasy use peer dependencies? There are situations where the `node_modules` tree ends up with multiple Zod versions if the user has a different version of Zod installed than what the SDK requires. For example:

```text
node_modules/
  zod/  v3.21.1
  sdk/
    node_modules/
      zod/ v3.23.5
```

If the SDK throws a Zod validation error, the user might have code like this:

```typescript
import { Sdk } from "sdk";
import { ZodError } from "zod";

const sdk = new Sdk();

try {
  const result = await sdk.drinks.list({userId: "oops"});
} catch (err) {
  if (err instanceof ZodError) { // branch 1
    console.error("the server returned invalid data");
  } else {
     throw err;
  }
}
```

The code at `branch 1` will not evaluate to `true` because the runtime loaded the wrong `ZodError` version. Using peer dependencies helps prevent this Zod validation error.

Speakeasy SDKs wrap `ZodError`s with a custom error type declared in each SDK. In practice, the Zod error is hidden from users and gets them to only work with the error type exported from the SDK. In the future, we start listing Zod as a direct dependency and are unaware of other Zod installations the user might have.

</Callout>

### Union Types

Support for polymorphic types is critical to most production applications. In OpenAPI, these types are defined using the `oneOf` keyword. Speakeasy represents these types using TypeScript's union notation, for example, `Cat | Dog`.

```typescript
import { SDK } from "@speakeasy/super-sdk";

async function run() {
  const sdk = new SDK();
  const pet = await sdk.fetchMyPet();

  switch (pet.type) {
    case "cat":
      console.log(pet.litterType);
      break;
    case "dog":
      console.log(pet.favoriteToy);
      break;
    default:
      // Ensures exhaustive switch statements in TypeScript
      pet satisfies never;
      throw new Error(`Unidentified pet type: ${pet.type}`)
  }
}

run();
```

### Type Safety

TypeScript provides static type safety to give you greater confidence in the code you are shipping. However, TypeScript has limited support to protect from opaque data at the boundaries of your programs. User input and server data coming across the network can circumvent static typing if not correctly modeled. This usually means marking this data as `unknown` and exhaustively sanitizing it.

Our TypeScript SDKs solve this issue neatly by modeling all the data at the boundaries using [Zod schemas](https://zod.dev/). Using Zod schemas ensures that everything coming from users and servers will work as intended, or fail loudly with clear validation errors. This is even more impactful for the vanilla JavaScript developers using your SDK.

```typescript
import { SDK } from "@speakeasy/super-sdk";

async function run() {
  const sdk = new SDK();

  const result = await sdk.products.create({
    name: "Fancy pants",
    price: "ummm"
  });
}

run();

// 🚨 Throws
//
// ZodError: [
//   {
//     "code": "invalid_type",
//     "expected": "number",
//     "received": "string",
//     "path": [
//       "price"
//     ],
//     "message": "Expected number, received string"
//   }
// ]
```

While validating user input is considered table stakes for SDKs, it’s especially useful to validate server data given the information we have in your OpenAPI spec. This can help detect drift between schema and server and prevent certain runtime issues such as missing response fields or sending incorrect data types.

## Tree Shaking

Speakeasy-created Typescript SDKs contain few internal couplings between modules. Users who bundle them into client-side apps can take advantage of tree-shaking performance when working with "deep" SDKs. These SDKs are subdivided into namespaces like `sdk.comments.create(...)` and `sdk.posts.get(...)`. Importing the top-level SDK pulls the entire SDK into a client-side bundle even if a small subset of functionality was needed.

You can import the exact namespaces or "sub-SDKs", and tree-shake the rest of the SDK away at build time.

```typescript
import { PaymentsSDK } from "@speakeasy/super-sdk/sdk/payments";
// 👆 Only code needed by this SDK is pulled in by bundlers

async function run() {
	const payments = new PaymentsSDK({ authKey: "" });

  const result = await payments.list();

  console.log(result);
}

run();
```

Speakeasy benchmarked whether there would be benefits in allowing users to import individual SDK operations but from our testing, there was a marginal reduction in bundled code versus importing sub-SDKs. It's highly dependent on how operations are grouped and the depth and breadth of an SDK as defined in the OpenAPI spec. If you think your SDK users could greatly benefit from exporting individual operations, please reach out to us and we can re-evaluate this feature.

## Streaming Support

Support for streaming is critical for applications that need to send or receive large amounts of data between client and server without first buffering the data into memory, potentially exhausting this system resource. Uploading a huge file is one use case where streaming can be useful.

As an example, in Node.js v20, streaming a large file to a server using an SDK is only a handful of lines:

```typescript
import { openAsBlob } from "node:fs";

import { SDK } from "@speakeasy/super-sdk";

async function run() {
  const sdk = new SDK();

  const fileHandle = await openAsBlob("./src/sample.txt");

  const result = await sdk.upload({ file: fileHandle });

  console.log(result);
}
run();
```

In the browser, users would typically select files using `<input type="file">` and the SDK call is identical to the sample code above.

Other JavaScript runtimes may have similar native APIs to obtain a web standards file or blob and pass it to SDKs.

For response streaming, SDKs expose a `ReadableStream`, a part of the Streams API web standard.

```typescript
import fs from "node:fs";
import { Writable } from "node:stream";
import { SDK } from "@speakeasy/super-sdk";

async function run() {
  const sdk = new SDK();

  const result = await sdk.usageReports.download("UR123");

  const destination = Writable.toWeb(
    fs.createWriteStream("./report.csv")
  );

  await result.data.pipeTo(destination);
}

run();
```

## Server-Sent Events

TypeScript SDKs support the streaming of server-sent events by exposing async iterables. Unlike the native `EventSource` API, SDKs can create streams using GET or POST requests, and other methods that can pass custom headers and request bodies.

```typescript
import { SDK } from "@speakeasy/super-sdk";

async function run() {
  const sdk = new SDK();

  const result = await sdk.completions.chat({
    messages: [
      {
        role: 'user',
        content: "What is the fastest bird that is common in North America?",
      },
    ],
  });

  if (result.chatStream == null) {
    throw new Error("failed to create stream: received null value");
  }

  for await (const event of res.chatStream) {
    process.stdout.write(event.data.content)
  }
}

run();
```

For more information on how to model this API in your OpenAPI document, see [Enabling Event-Streaming Operations](/docs/customize-sdks/server-sent-events).

## Parameters

If configured, Speakeasy generates methods with parameters for each parameter defined in the OpenAPI document, provided the number of parameters is less than or equal to the configured `maxMethodParams` value in the `gen.yaml` file.

If the number of parameters exceeds the configured `maxMethodParams` value or is set to `0`, then a request object is generated for the method instead allowing all parameters to be passed in a single object.

## Errors

Following TypeScript best practices, all operation methods in the SDK will return a response object and an error. Callers should always check for the presence of the error. The object used for errors is configurable per request. Any error response may return a custom error object. A generic error will be provided when any sort of communication failure is detected during an operation.

Here's an example of custom error handling in a theoretical SDK:

```typescript
import { Speakeasy } from "@speakeasy/bar";
import * as errors from "@speakeasy/bar/sdk/models/errors";

async function run() {
    const sdk = new Speakeasy({
        apiKey: "<YOUR_API_KEY_HERE>",
    });

    const res = await sdk.bar.getDrink().catch((err) => {
        if (err instanceof errors.FailResponse) {
            console.error(err); // handle exception
            return null;
        } else {
            throw err;
        }
    });

    if (res?.statusCode !== 200) {
        throw new Error("Unexpected status code: " + res?.statusCode || "-");
    }

    // handle response
}

run();
```

The SDK also includes a `SDKValidationError` to make it easier to debug validation errors, particularly when the server sends unexpected data. Instead of throwing a `ZodError` back at SDK users without revealing the underlying raw data that failed validation, `SDKValidationError` provides a way to pretty-print validation errors for a more pleasant debugging experience.

## Debugging Support

Typescript SDKs support a new response format that includes the native Request and Response objects that were used in an SDK method call. Enable this by setting the `responseFormat` config in your `gen.yaml` file to `envelope-http`.

```typescript
const sdk = new SDK();
const { users, httpMeta } = await sdk.users.list();
//                👆

const { request, response } = httpMeta;
console.group("Request completed")
console.log("Endpoint:", request.method, request.url)
console.log("Status", response.status)
console.log("Content type", response.headers.get("content-type"))
console.groupEnd()
```

The `httpMeta` property will also be available on any error class that relates to HTTP requests. This includes the built-in `SDKError` class and any custom error classes that you have defined in your spec.

## User Agent Strings

The Typescript SDK includes a [`User-Agent`](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/User-Agent) string in all requests to track SDK usage amongst broader API usage. The format is as follows:

```stmpl
speakeasy-sdk/typescript {{SDKVersion}} {{GenVersion}} {{DocVersion}} {{PackageName}}
```

Where

- `SDKVersion` is the version of the SDK, defined in `gen.yaml` and released.
- `GenVersion` is the version of the Speakeasy generator.
- `DocVersion` is the version of the OpenAPI document.
- `PackageName` is the name of the package defined in `gen.yaml`.


 This is the content for the doc docs/languages/typescript/oss-comparison-ts.mdx 

 ---
title: "Comparison guide: OpenAPI/Swagger TypeScript client generation"
description: "Comparing the new Speakeasy TypeScript SDK generator with the most popular open source OpenAPI TypeScript generators"
keywords: [api, openapi, swagger, sdk generation, sdk, golang, go, python sdk, python, typescript sdk, typescript, ts, java sdk, java, developer experience, devex, dx]
date: 2024-05-08
---

# Comparison guide: OpenAPI/Swagger TypeScript client generation

At Speakeasy, we create [idiomatic SDKs](/docs/languages/philosophy) in a variety of languages. Our generators follow principles that ensure we create SDKs that offer the best developer experience so that you can focus on building your API, and your developer-users can focus on delighting their users.

In this post, we'll compare TypeScript SDKs managed by Speakeasy to those generated by open-source generators.

## The TypeScript SDK generator landscape

We'll compare the Speakeasy SDK generator to two generators from the OpenAPI Generators project and two additional popular open-source generators.

Our evaluation includes:

1.  The [TypeScript Fetch](https://openapi-generator.tech/docs/generators/typescript-fetch/) generator from OpenAPI Generators.
2.  The [TypeScript Node](https://openapi-generator.tech/docs/generators/typescript-node/) generator from OpenAPI Generators.
3.  [Oazapfts](https://github.com/oazapfts/oazapfts), an open-source generator with almost 400 stars on GitHub.
4.  [OpenAPI TypeScript Codegen](https://github.com/ferdikoomen/openapi-typescript-codegen), a popular open-source generator with 1,700 stars on GitHub.
5.  The [Speakeasy SDK generator](/docs/speakeasy-reference/cli/getting-started).

Here's the summary of how the different generators compare:

| Feature                  | Speakeasy              | TypeScript Fetch | TypeScript Node | Oazapfts             | OpenAPI TypeScript Codegen |
|--------------------------|------------------------|------------------|-----------------|----------------------|----------------------------|
| Schema validation        | ✅ Using Zod              | ✅ Basic          | ✅ Basic         | ❌                    | ❌                          |
| Documentation generation | ✅ Full docs and examples | ❌                | ❌               | ❌                    | ❌                          |
| Union types/polymorphism | ✅                        | ✅                | ❌               | ✅ With discriminator | ✅ Without discriminator    |
| Browser support          | ✅                        | ✅                | ❌               | ✅                    | ✅                          |
| Tree-shaking support     | ✅                        | ⚠️ Limited         | ⚠️ Limited        | ⚠️ Limited             | ⚠️ Limited                   |
| OAuth 2.0                | ✅                        | ❌                | ❌               | ❌                    | ❌                          |
| Retries                  | ✅                        | ❌                | ❌               | ❌                    | ❌                          |
| Pagination               | ✅                        | ❌                | ❌               | ❌                    | ❌                          |
| React Hooks generation   | ✅ With TanStack Query    | ❌                | ❌               | ❌                    | ❌                          |
| Data streaming           | ✅ With runtime docs      | ✅                | ✅               | ✅                    | ✅                          |
| Node.js support          | ✅                        | ✅                | ✅               | ✅                    | ✅                          |
| Deno support             | ✅                        | ❌                | ❌               | ❌                    | ❌                          |
| Bun support              | ✅                        | ❌                | ❌               | ❌                    | ❌                          |
| React Native support     | ✅                        | ❌                | ❌               | ❌                    | ❌                          |
| Package publishing       | ✅                        | ❌                | ❌               | ❌                    | ❌                          |
| CI/CD integration        | ✅ GitHub Actions         | ❌                | ❌               | ❌                    | ❌                          |

For a detailed comparison, read on.

## Installing SDK generators

Although generator installation does not impact the resulting SDKs, your team will install the generator on each new development environment. We believe an emphasis on usability starts at home, and your internal tools should reflect this.

Install the Speakeasy CLI by running the following in the terminal:

```bash
brew install speakeasy-api/homebrew-tap/speakeasy
```

Installing `openapi-generator` using Homebrew installs `openjdk@11` and its numerous dependencies:

```bash
brew install openapi-generator
```

To install oazapfts and openapi-typescript-codegen, add them to an npm package as dependencies:

```bash
# Install oazapfts as a dependency
npm install oazapfts --save

# Install openapi-typescript-codegen and save it as a devDependency
npm install openapi-typescript-codegen --save-dev
```

## Downloading the Swagger Petstore specification

Before we run our generators, we'll need an OpenAPI specification to generate a TypeScript SDK for. The standard specification for testing OpenAPI SDK generators and Swagger UI generators is the [Swagger Petstore](https://petstore3.swagger.io/).

We'll download the YAML specification at [https://petstore3.swagger.io/api/v3/openapi.yaml](https://petstore3.swagger.io/api/v3/openapi.yaml) to our working directory and name it `petstore.yaml`:

```bash
curl https://petstore3.swagger.io/api/v3/openapi.yaml --output petstore.yaml
```

## Validating the spec

Both the OpenAPI Generator and Speakeasy CLI can validate an OpenAPI spec. Oazapfts and OpenAPI TypeScript Codegen don't offer validation, so if we were to use them at scale, we would need a separate validation step.

To validate `petstore.yaml` using OpenAPI Generator, run the following in the terminal:

```bash
openapi-generator validate -i petstore.yaml
```

The OpenAPI Generator returns two warnings:

```
Warnings:
	- Unused model: Address
	- Unused model: Customer

[info] Spec has 2 recommendation(s).
```

### Validation using Speakeasy

We'll validate the spec with Speakeasy by running the following in the terminal:

```bash
speakeasy validate openapi -s petstore.yaml
```

The Speakeasy validator returns ten warnings, seven hints that some methods don't specify return values, and three unused components. Each warning includes a detailed, structured error with line numbers to help us fix validation errors.

Since both validators validated the spec with only warnings, we can assume that all our generators will generate SDKs without issues.

The Speakeasy validator includes an option to get hints on how to improve our schema. Use the `--output-hints` argument to activate this feature:

```bash
speakeasy validate openapi --output-hints -s petstore.yaml
```

This provides a detailed list of hints, all of which would improve our eventual SDK users' experience.

Here's how the generators' validation features compare:

|                    | Speakeasy | openapi-gen | Oazapfts | Codegen |
|--------------------|-----------|-------------|----------|---------|
| Validates schema   | ✅         | ✅           | ❌        | ❌       |
| Shows line numbers | ✅         | ❌           | ❌        | ❌       |
| Schema hints       | ✅         | ❌           | ❌        | ❌       |

## Generating SDKs

Now that we know our OpenAPI spec is valid, we can start generating and comparing SDKs. First, we'll create an SDK using Speakeasy and take a brief look at its structure. Then we'll generate SDKs using the open-source generators and compare the generated code to the Speakeasy SDK.

### Generating an SDK using Speakeasy

To create a TypeScript SDK using the Speakeasy CLI, run the following in the terminal:

```bash
# Create Petstore SDK using Speakeasy TypeScript generator
speakeasy generate sdk \
    --schema petstore.yaml \
    --lang typescript \
    --out ./petstore-sdk-speakeasy/
```

The command above creates a new directory called `petstore-sdk-speakeasy`, with the following structure:

```
./
├── README.md
├── USAGE.md
├── docs/
│   ├── models/
│   └── sdks/
├── files.gen
├── gen.yaml*
├── package-lock.json
├── package.json
├── src/
│   ├── index.ts
│   ├── lib/
│   ├── models/
│   ├── sdk/
│   └── types/
└── tsconfig.json
```

At a glance, we can see that Speakeasy creates documentation for each model in our schema and that it creates a full-featured npm package. Code is split between internal tools and the SDK code.

We'll look at the generated code in more detail in our comparisons below, starting with OpenAPI Generator.

### Generating SDKs using OpenAPI Generator

OpenAPI Generator is an open-source collection of community-maintained generators. It features generators for a wide variety of client languages, and for some languages, there are multiple generators. TypeScript tops this list of languages with multiple generators, with 11 options to choose from.

The two TypeScript SDK generators from OpenAPI Generator we tried are [typescript-fetch](https://openapi-generator.tech/docs/generators/typescript-fetch/) and [typescript-node](https://openapi-generator.tech/docs/generators/typescript-node/).

Usage is the same for both generators, but we'll specify a unique output directory, generator name, and npm project name for each.

We'll generate an SDK for each by running the following in the terminal:

```bash
# Generate Petstore SDK using typescript-fetch generator
openapi-generator generate \
  --input-spec petstore.yaml \
  --generator-name typescript-fetch \
  --output ./petstore-sdk-typescript-fetch \
  --additional-properties=npmName=petstore-sdk-typescript-fetch

# Generate Petstore SDK using typescript-node generator
openapi-generator generate \
  --input-spec petstore.yaml \
  --generator-name typescript-node \
  --output ./petstore-sdk-typescript-node \
  --additional-properties=npmName=petstore-sdk-typescript-node
```

Each command will output a list of files generated and create a unique directory. We specified an npm package name as a configuration argument, `npmName`, for each generator. This argument is required for the generators to create full packages.

### Generating an SDK with oazapfts

To run oazapfts, we'll either need to run it from the local JavaScript project bin folder or install it globally. We opted to run it from the bin folder.

Navigate to the local JavaScript project we created for `petstore-sdk-oazapfts` and run the following:

```bash
$(npm bin)/oazapfts ../petstore.yaml index.ts
```

Oazapfts runs without any output and generates a single TypeScript file, `index.ts`. Remember that we had to install `oazapfts` as a runtime dependency. Let's see what gets called from the dependency:

```typescript
import * as Oazapfts from "oazapfts/lib/runtime";
import * as QS from "oazapfts/lib/runtime/query";
```

Code generated by oazapfts excludes the HTTP client code, error handling, and serialization. We can look at the runtime dependencies from `Oazapfts` itself, to get an idea of the dependency graph:

This is an excerpt from the oazapfts `package.json` file:

```json
{
  "dependencies": {
    "@apidevtools/swagger-parser": "^10.1.0",
    "lodash": "^4.17.21",
    "minimist": "^1.2.8",
    "swagger2openapi": "^7.0.8",
    "typescript": "^5.2.2"
  }
}
```

Some of these dependencies clearly relate to the generator itself. For example, we can assume that no SDK client would need access to `swagger-parser` at runtime.

### Generating an SDK with OpenAPI TypeScript Codegen 

As with oazapfts, we'll need to run the OpenAPI TypeScript Codegen CLI from our npm binaries location, where it is aliased as `openapi`.

Navigate to the `petstore-sdk-otc` JavaScript project and run:

```bash
$(npm bin)/openapi \
  -i ../petstore.yaml
  -o src/
```

OpenAPI TypeScript Codegen uses the fetch API for requests by default, so it's aimed at SDKs used in the browser. However, it can be configured to use Axios. We tried using Axios and noted that OpenAPI TypeScript Codegen does not create an npm package with dependencies, so we had to manually install a version of Axios.

By contrast, Speakeasy manages dependencies on behalf of the developer when generating an SDK, eliminating the need to guess which version of a dependency to install.

## Polymorphism

The Petstore schema does not include examples of polymorphism in OpenAPI, so we'll add two new schemas for `Dog` and `Cat`, and use them as input and output in the `updatePet` operation.

Add the following to the component schemas in `petstore.yaml`:

```yaml
components:
  schemas:
    Dog:
      allOf:
      - $ref: '#/components/schemas/Pet'
      - type: object
        properties:
          petType:
            type: string
            example: Dog
          bark:
            type: string
      xml:
        name: dog
    Cat:
      allOf:
      - $ref: '#/components/schemas/Pet'
      - type: object
        properties:
          petType:
            type: string
            example: Cat
          hunts:
            type: boolean
          age:
            type: integer
            format: int32
      xml:
        name: cat
```

Then add [discriminated unions](https://swagger.io/docs/specification/data-models/inheritance-and-polymorphism/) to the `updatePet` operation:

```yaml
paths:
  /pet:
    put:
      requestBody:
        content:
          application/json:
            schema:
              discriminator:
                propertyName: petType
                mapping:
                  dog: '#/components/schemas/Dog'
                  cat: '#/components/schemas/Cat'
              oneOf:
              - $ref: '#/components/schemas/Cat'
              - $ref: '#/components/schemas/Dog'
      responses:
        "200":
          application/json:
              schema:
                discriminator:
                  propertyName: petType
                  mapping:
                    dog: '#/components/schemas/Dog'
                    cat: '#/components/schemas/Cat'
                oneOf:
                - $ref: '#/components/schemas/Cat'
                - $ref: '#/components/schemas/Dog'
```

After regenerating the SDKs, let's inspect each SDK's `updatePet` method.

We see that oazapfts generates a method that type casts the input and output objects based on the discriminating field `petType`:

```typescript
export function updatePet(body: ({
    petType: "dog";
} & Dog) | ({
    petType: "cat";
} & Cat), opts?: Oazapfts.RequestOpts) {
    return oazapfts.fetchJson<{
        status: 200;
        data: ({
            petType: "dog";
        } & Dog) | ({
            petType: "cat";
        } & Cat);
    } | {
        status: 400;
    } | {
        status: 404;
    } | {
        status: 405;
    }>("/pet", oazapfts.json({
        ...opts,
        method: "PUT",
        body
    }));
}
```

The SDK generated by typescript-fetch is slightly more verbose, and uses switch statements to derive the types for input and output objects:

```typescript
export type UpdatePetRequest = { petType: 'cat' } & Cat | { petType: 'dog' } & Dog;

export function UpdatePetRequestFromJSON(json: any): UpdatePetRequest {
    return UpdatePetRequestFromJSONTyped(json, false);
}

export function UpdatePetRequestFromJSONTyped(json: any, ignoreDiscriminator: boolean): UpdatePetRequest {
    if ((json === undefined) || (json === null)) {
        return json;
    }
    switch (json['petType']) {
        case 'cat':
            return {...CatFromJSONTyped(json, true), petType: 'cat'};
        case 'dog':
            return {...DogFromJSONTyped(json, true), petType: 'dog'};
        default:
            throw new Error(`No variant of UpdatePetRequest exists with 'petType=${json['petType']}'`);
    }
}

export function UpdatePetRequestToJSON(value?: UpdatePetRequest | null): any {
    if (value === undefined) {
        return undefined;
    }
    if (value === null) {
        return null;
    }
    switch (value['petType']) {
        case 'cat':
            return CatToJSON(value);
        case 'dog':
            return DogToJSON(value);
        default:
            throw new Error(`No variant of UpdatePetRequest exists with 'petType=${value['petType']}'`);
    }

}
```

OpenAPI Codegen adds a union for `Cat` and `Dog` on both input and output, but does not use the discriminator to add runtime type casting:

```typescript
export class PetService {
  public static updatePet(
      requestBody: (Cat | Dog),
  ): CancelablePromise<(Cat | Dog)> {
      return __request(OpenAPI, {
          method: 'PUT',
          url: '/pet',
          body: requestBody,
          mediaType: 'application/json',
          errors: {
              400: `Invalid ID supplied`,
              404: `Pet not found`,
              405: `Validation exception`,
          },
      });
  }
}
```

The typescript-node generator does not make use of types for unions in OpenAPI:

```typescript
export class UpdatePetRequest {
    'id'?: number;
    'name': string;
    'category'?: Category;
    'photoUrls': Array<string>;
    'tags'?: Array<Tag>;
    /**
    * pet status in the store
    */
    'status'?: UpdatePetRequest.StatusEnum;
    'petType'?: string;
    'hunts'?: boolean;
    'age'?: number;
    'bark'?: string;

    // ...
}
```

Here's a summary of how each generator handles OpenAPI polymorphism:

|                    | Speakeasy | Node | Fetch | Oazapfts | Codegen |
|--------------------|-----------|------|-------|----------|---------|
| Adds union types   | ✅         | ❌    | ✅     | ✅        | ✅       |
| Uses discriminator | ✅         | ❌    | ✅     | ✅        | ❌       |

## Retries

The SDK managed by Speakeasy can automatically retry failed network requests or retry requests based on specific error responses.

This provides a straightforward developer experience for error handling.

To enable this feature, we use the Speakeasy `x-speakeasy-retries` extension in the OpenAPI spec. We'll update the OpenAPI spec to add retries to the `addPet` operation as a test.

Edit `petstore.yaml` and add the following to the `addPet` operation:

```yaml
      x-speakeasy-retries:
        strategy: backoff
        backoff:
          initialInterval: 500        # 500 milliseconds
          maxInterval: 60000          # 60 seconds
          maxElapsedTime: 3600000     # 5 minutes
          exponent: 1.5
```

Add this snippet to the operation:

```yaml
#...
paths:
  /pet:
    # ...
    post:
      #...
      operationId: addPet
      x-speakeasy-retries:
        strategy: backoff
        backoff:
          initialInterval: 500        # 500 milliseconds
          maxInterval: 60000          # 60 seconds
          maxElapsedTime: 3600000     # 5 minutes
          exponent: 1.5
```

Now we'll rerun the Speakeasy generator to enable retries for failed network requests when creating a new pet. It is also possible to enable retries for the SDK as a whole by adding a global `x-speakeasy-retries` at the root of the OpenAPI spec.


## React Hooks 

[React Hooks](https://react.dev/reference/react/hooks) are a popular way to manage state and side effects in React applications.

Speakeasy generates built-in React Hooks using [TanStack Query](https://tanstack.com/query/latest). These hooks provide features like intelligent caching, type safety, pagination, and seamless integration with modern React patterns such as SSR and Suspense.


```typescript example/booksView.tsx
import { useQuery } from "@tanstack/react-query";

function BookShelf() { // loads books from an API
  const { data, status, error } = useQuery([
    "books" // Cache key for the query
  ], async () => {
    const response = await fetch("https://api.example.com/books");
    return response.json();
  });

  if (status === "loading") return <p>Loading books...</p>;
  if (status === "error") return <p>Error: {error?.message}</p>;

  return (
    <ul>
      {data.map((book) => (
        <li key={book.id}>{book.title}</li>
      ))}
    </ul>
  );
}
```

For example, in this basic implementation, the `useQuery` hook fetches data from an API endpoint. The cache key ensures unique identification of the query. The `status` variable provides the current state of the query: `loading`, `error`, or `success`. Depending on the query status, the component renders `loading`, `error`, or the fetched data as a list.

None of the other generators generate React Hooks for their SDKs.

|                 | Speakeasy | Node | Fetch | Oazapfts | Codegen |
|-----------------|-----------|------|-------|----------|---------|
| React Hooks     | ✅         | ❌    | ❌     | ❌        | ❌       |

For an in-depth look at how Speakeasy uses React Hooks, see our [official release article](https://www.speakeasy.com/post/release-react-hooks).


## Pagination

SDKs managed by Speakeasy include optional [pagination for OpenAPI operations](/docs/customize/runtime/pagination).

We'll update our pet store schema to add an `x-speakeasy-pagination` extension and an `offset` query parameter:

```yaml
paths:
  /store/inventory:
    get:
      x-speakeasy-pagination:
        type: offsetLimit
        inputs:
          - name: offset                # This offset refers to the value called `offset`
            in: parameters              # In this case, offset is an operation parameter (header, query, or path)
            type: offset                # The offset parameter will be used as the offset, which will be incremented by the length of the `output.results` array
        outputs:
          results: $.data.resultArray   # The length of data.resultsArray value of the response will be added to the `offset` value to determine the new offset
      parameters:
        - name: offset
          in: query
          description: The offset to start from
          required: false
          schema:
            type: integer
            default: 0
```

After regenerating the SDK with Speakeasy, the `getInventory` operation includes pagination:

```typescript
import { SDK } from "openapi";
import { GetInventorySecurity } from "openapi/models/operations";

async function run() {
  const sdk = new SDK();

  const offset = 20;
  const operationSecurity: GetInventorySecurity = "<YOUR_API_KEY_HERE>";
  
  const res = await sdk.store.getInventory(operationSecurity, offset);

  if (res?.statusCode !== 200) {
    throw new Error("Unexpected status code: " + res?.statusCode || "-");
  }
  
  let items: typeof res | null = res;
  while (items != null) {
    // handle items
  
    items = await items.next();
  }
}

run();
```

None of the other generators include pagination as a feature.

|                 | Speakeasy | Node | Fetch | Oazapfts | Codegen |
|-----------------|-----------|------|-------|----------|---------|
| Adds pagination | ✅         | ❌    | ❌     | ❌        | ❌       |


## Auto-pagination

Speakeasy's React Hooks also enable auto-pagination, which automatically fetches more data when the user scrolls to the bottom of the page. This feature is useful for infinite scrolling in social media feeds or search results.

```typescript example/booksView.tsx
import { useInView } from "react-intersection-observer";

import { useBooksInfinite } from "@speakeasy-api/books/react-query";

export function BooksView() {
  const { data, fetchNextPage, hasNextPage } = useBooksInfinite();

  const { ref } = useInView({
    rootMargin: "50px",
    onChange(inView) {
      if (inView) { fetchNextPage(); }
    },
  });

  return (
    <div>
      <ul>
        {data?.pages.flatMap((page) => {
          return page.books.map((book) => (
            <li key={book.id}>{book.title}</li>
          ));
        })}
      </ul>
      {hasNextPage ? <div ref={ref} /> : null}
    </div>
  );
}
```

None of the other generators include auto-pagination as a feature.

|                     | Speakeasy | Node | Fetch | Oazapfts | Codegen |
|---------------------|-----------|------|-------|----------|---------|
| Adds auto-pagination | ✅         | ❌    | ❌     | ❌        | ❌       |


## Data streaming

All the generators in our comparison generate SDKs that use the `Fetch` API, which enables streaming for large uploads or downloads.

|                | Speakeasy | Node | Fetch | Oazapfts | Codegen |
|----------------|-----------|------|-------|----------|---------|
| Stream uploads | ✅         | ✅    | ✅     | ✅        | ✅       |

Speakeasy creates detailed documentation as part of the SDK, detailing how to open large files on different runtimes to help your developer-users take advantage of streaming.

## Generated documentation

Of all the generators tested, Speakeasy was the only one to generate documentation and usage examples for its SDK. We see documentation generation as a crucial feature if you plan to publish your SDK to npm for others to use.

Here's how the generators add documentation:

|                     | Speakeasy | Node | Fetch | Oazapfts | Codegen |
|---------------------|-----------|------|-------|----------|---------|
| Adds documentation  | ✅         | ❌    | ❌     | ❌        | ❌       |
| Adds usage examples | ✅         | ❌    | ❌     | ❌        | ❌       |

Speakeasy generates a `README.md` at the root of the SDK, [which you can customize](/docs/sdk-docs) to add branding, support links, a code of conduct, and any other information your developer-users might find helpful.

The Speakeasy SDK also includes working usage examples for all operations, complete with imports and appropriately formatted string examples. For instance, if a type is formatted as `email` in our OpenAPI spec, Speakeasy generates usage examples with strings that look like email addresses. Types formatted as `uri` will generate examples that look like URLs. This makes example code clear and scannable.

Here's the usage example managed by Speakeasy after we update `petstore.yaml` to format the string items in `photoUrls` as `uri`:

```typescript docs/sdks/pet/README.md mark=16:18
import { SDK } from "openapi";
import { Status } from "openapi/models/components";

async function run() {
  const sdk = new SDK({
    petstoreAuth: "Bearer <YOUR_ACCESS_TOKEN_HERE>",
  });

  const res = await sdk.pet.addPetForm({
    id: 10,
    name: "doggie",
    category: {
      id: 1,
      name: "Dogs",
    },
    photoUrls: [
      "http://celebrated-surprise.org",
    ],
    tags: [
      {},
    ],
  });

  if (res?.statusCode !== 200) {
    throw new Error("Unexpected status code: " + res?.statusCode || "-");
  }
  
  // handle response
}

run();
```

## Bundling applications for the browser

Speakeasy creates SDKs that are tree-shakable and can be bundled for the browser using tools like Webpack, Rollup, or esbuild.

Because Speakeasy supports a wider range of OpenAPI features, Speakeasy-created SDKs are likely to be slightly larger than those generated by other tools. Speakeasy also limits abstraction, which can lead to larger SDKs. This does not translate to a larger bundle size, as the SDK can be tree-shaken to remove unused code.

Any SDK that supports runtime type checking or validation will have a larger bundle size, but the benefits of type checking and validation far outweigh the cost of a slightly larger bundle. If you use Zod elsewhere in your application, you can exclude it from the SDK bundle to reduce its size.

Here's an example of how to exclude Zod from the SDK bundle:

```bash Terminal mark=7
npx esbuild src/speakeasy-app.ts \
  --bundle \
  --minify \
  --target=es2020 \
  --platform=browser \
  --outfile=dist/speakeasy-app.js \
  --external:zod
```

## Automation

This comparison focuses on the installation and usage of command line generators, but the Speakeasy generator can also run as part of a CI workflow, for instance as a [GitHub Action](https://github.com/speakeasy-api/sdk-generation-action), to make sure your SDK is always up to date when your API spec changes.

## A live example: Vessel API Node SDK

[Vessel](https://www.vessel.dev/) trusts Speakeasy to generate and publish SDKs for its widely used APIs. We recently spoke to Zach Kirby about how Vessel uses Speakeasy. Zach shared that [the Vessel Node SDK](https://www.npmjs.com/package/@vesselapi/nodesdk) is downloaded from npm hundreds of times a week.

## Summary

The open-source SDK generators we tested are all good and clearly took tremendous effort and community coordination to build and maintain. Different applications have widely differing needs, and smaller projects may not need all the features offered by Speakeasy.

If you are building an API that developers rely on and would like to publish full-featured SDKs that follow best practices, we strongly recommend giving the [Speakeasy SDK generator](/docs/speakeasy-reference/cli/getting-started) a try.

[Join our Slack community](https://join.slack.com/t/speakeasy-dev/shared_invite/zt-1cwb3flxz-lS5SyZxAsF_3NOq5xc8Cjw) to let us know how we can improve our TypeScript SDK generator or to suggest features.


 This is the content for the doc docs/languages/typescript/standalone-functions.mdx 

 ---
title: "Standalone Functions"
---

import { Callout } from "~/components";

# Standalone Functions

## Feature Overview

Every method in TypeScript SDKs generated by Speakeasy is also available as a
standalone function. This alternative API is ideal for browser or serverless
environments, where bundlers can optimize applications by tree-shaking unused
functionality. This includes unused methods, Zod schemas, encoding helpers, and
response handlers. As a result, the application's final bundle size is
dramatically smaller and grows very gradually as more of the generated SDK is
used.

Using methods through the main SDK class remains a valid and generally more
ergonomic option. Standalone functions are an optimization designed for specific
types of applications.

## Usage

**Step 1: Import the Core Class and Function**

First, import the `Core` SDK class for authentication and setup, along with the
required standalone function. An SDK named `Todo`, for example, might look like
this:

```typescript index.ts
import { TodoCore } from "todo/core.js";
import { todosCreate } from "todo/funcs/todosCreate.js";
```

The `Core` SDK class is optimized for tree-shaking, and can be reused throughout
the application.

**Step 2: Instantiate the Core Class**

Create an instance of the `Core` class with the required configuration (e.g., an
API Key):

```typescript index.ts
const todoSDK = new TodoCore({
  apiKey: "TODO_API_KEY",
});
```

**Step 3: Call the Standalone Function & Handle the Result**

Invoke the standalone function, passing the core instance the first parameter.
Handle the result using a switch statement for comprehensive error handling:

```typescript index.ts
async function run() {
  const res = await todosCreate(todoSDK);

  switch (true) {
    case res.ok:
      // Successful response is processed later.
      break;
    case res.error instanceof SDKValidationError:
      // Display validation errors in a readable format.
      return console.log(res.error.pretty());
    case res.error instanceof Error:
      // Handle general errors.
      return console.log(res.error);
    default:
      // Ensure all error cases are exhaustively handled.
      res.error satisfies never;
      throw new Error("Unexpected error case: " + res.error);
  }

  const { value: todo } = res;

  // Handle the successful result.
  console.log(todo);
}

run();
```

## Result Types

Standalone functions differ from SDK methods in that they return a
`Result<Value, Error>` type to capture _known errors_ and document them through
the type system. This approach avoids throwing errors, allowing application code
to maintain clear control flow while making error handling a natural part of the
application code.

<Callout title="NOTE" variant="info">
  The term **"known errors"** is used because standalone functions and
  JavaScript code can still throw unexpected errors (e.g., `TypeError`,
  `RangeError`, and `DOMException`). While exhaustively catching all errors may
  be addressed in future SDK versions, there&apos;s significant value in capturing
  most errors and converting them into values.
</Callout>

Another reason for this programming style is that these functions are commonly
used in front-end applications where throwing exceptions is often discouraged.
React and similar frameworks promote this approach to ensure components can
render appropriate content in all states—loading, success, and error.

Thus, the general pattern when calling standalone functions looks like this:

```typescript log-something.ts
import { Core } from "<sdk-package-name>";
import { fetchSomething } from "<sdk-package-name>/funcs/fetchSomething.js";

const client = new Core();

async function run() {
  const result = await fetchSomething(client, { id: "123" });

  if (!result.ok) {
    // You can throw the error or handle it. It's your choice now.
    throw result.error;
  }

  console.log(result.value);
}

run();
```

Note that, unlike a try-catch block where errors are of type `unknown` (or `any`
depending on TypeScript settings), `result.error` in this example has a
specific, explicit type.


 This is the content for the doc docs/languages/unity/methodology-unity.mdx 

 ---
title: "Create Unity SDKs from OpenAPI / Swagger"
description: "Generate a Unity client from your Swagger / OpenAPI spec in minutes."
---

import { Callout } from '~/components'

# Create Unity SDKs from OpenAPI / Swagger

## Unity SDK Overview

The Speakeasy Unity C# SDK supports Unity 2021.3 LTS and above and is designed to be strongly typed, light on external dependencies, easy to debug, and easy to use.

Some of the core features of the SDK include:

- Interfaces for core components allow for dependency injection and mocking.
- Generated C# doc comments to enhance the SDK's IntelliSense compatibility and developer experience.
- Async/await support for all API calls, which can easily be wrapped in coroutines if needed.
- Optional pagination support for supported APIs.
- Support for complex number types:
  - `System.Numbers.BigInteger`
  - `System.Decimal`
- Support for both string- and integer-based enums.
- Streaming downloads for files.

The SDK includes minimal dependencies. The only external dependencies are:

- `newtonsoft.json` for JSON serialization and deserialization.
- The UnityEngine libraries.

## Unity Package Structure

```yaml lib-structure.yaml
├── {SDK Class Name}             # The root namespace for the SDK where {SDK Class Name} is the provided name of the SDK
|   ├── {SDK Class Name}.csproj  
|   ├── {SDK Class Name}SDK.cs   # The main SDK class
|   ├── ...                      # Other SDK classes
|   ├── Models                   # The namespace for the SDK's models
|   |   ├── Operations           # The namespace for the SDK's operations models which generally house the request/response models for each API
|   |   |   ├── ... 
|   |   └── Shared               # The namespace for the SDK's models generated from components in the OpenAPI document
|   |       ├── ...
|   └── Utils                    # The namespace for the SDK's utility classes
├── docs                         # Markdown files for the SDK's documentation
|   └── ...
├── {SDK Class Name}.sln         # The SDK's solution file
└── ...
```

## HTTP Client

The Unity C# SDK provides an interface for the HTTP client used to make API calls. A custom HTTP client can be provided to the SDK as long as it conforms to the interface.

```csharp
public interface ISpeakeasyHttpClient
{
    void AddHeader(string key, string value);
    void AddQueryParam(string key, string value);
    Task<UnityWebRequest> SendAsync(UnityWebRequest message);
}
```

By default, the SDK will instantiate its own client using `UnityWebRequest.SendWebRequest()` to send the request, but this can be overridden by providing a custom implementation of the `ISpeakeasyHttpClient` interface:

```csharp
var client = new CustomHttpClient();

var sdkInstance = new SDK(client);
```

This is useful if you're using a custom HTTP client that supports `UnityWebRequests` and a proxy or other custom configuration, or to provide a client preconfigured with standard headers.

## Data Types and Classes

The C# SDK uses as many native types from the standard library as possible, for example:

- `string`
- `System.DateTime`
- `int`
- `long`
- `System.Numberics.BigInteger`
- `float`
- `double`
- `decimal`
- `bool`


The SDK will only fall back on custom types when the native types are not suitable, for example:

- A custom `DateOnly` class for `date` types
- Custom `enum` types for `string` and `integer` based enums

Speakeasy will generate standard C# classes with public fields that use attributes to guide the serialization and deserialization processes.

The classes are also `Serializable`, with `[SerializeField]` attributes on the fields allowing them to be used in the Unity Inspector.

## Parameters

If parameters are defined in the OpenAPI document, Speakeasy will generate methods with parameters.

The number of parameters defined should not exceed the `maxMethodParams` value configured in the `gen.yaml` file. If they do or the `maxMethodParams` value is set to `0`, Speakeasy will generate a request object that allows for all parameters to be passed in a single object.

## Async Support

The Unity C# SDK is generated with async/await support for all API calls, which can easily be wrapped in coroutines if needed. For example:

```csharp
using System;
using System.Collections.Generic;
using System.Collections;
using System.IO;
using System.Threading.Tasks;

// Static methods that help using the SDK in Unity coroutines
public static class CoroutineHelper
{
    public static IEnumerator Await(Task task)
    {
        while (!task.IsCompleted)
        {
            yield return null;
        }
        if (task.IsFaulted)
        {
            throw task.Exception;
        }
    }

    public static IEnumerator Await(Func<Task> taskDelegate)
    {
        return Await(taskDelegate.Invoke());
    }
}
```

The example above can be used like so:

```csharp
yield return CoroutineHelper.Await(async () =>
{
    var sdk = new SDK();

    using (
        var res = await sdk.SomeMethod(...)
    )
    {
        // Handle response
    }
});
```

Due to the nature of the underlying `UnityWebRequest`, the response is an `IDisposable` object that should be disposed of when finished with or used within a `using` statement as shown above.

## Errors

The Unity C# SDK will throw exceptions for network or invalid request errors.

For unsuccessful responses, the SDK will return a response object containing the status code and response body, which can be checked for the status of the method call.

<Callout title="Coming Soon" variant="info">
Support for throwing unsuccessful status codes as exceptions is coming soon.
</Callout>


## User Agent Strings

The Unity SDK will include a [user agent](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/User-Agent) string in all requests that can be leveraged for tracking SDK usage amongst broader API usage. The format is as follows: 

```stmpl
speakeasy-sdk/unity {{SDKVersion}} {{GenVersion}} {{DocVersion}} {{PackageName}}
```
Where
- `SDKVersion` is the version of the SDK, defined in `gen.yaml` and released
- `GenVersion` is the version of the Speakeasy generator
- `DocVersion` is the version of the OpenAPI document
- `PackageName` is the name of the package defined in `gen.yaml`


 This is the content for the doc docs/manage/breaking-changes.mdx 

 ---
title: Handling breaking changes in SDKs
description: > 
  Learn how to handle breaking changes in your API when using
  Speakeasy-generated SDKs.
---

import { Callout } from "~/components";

# Handling breaking changes in SDKs

This guide explains how to handle breaking changes in APIs when using
Speakeasy-generated SDKs. Following these guidelines helps maintain backward
compatibility and ensures a smooth experience for SDK users.

## Safe changes

The following API changes are safe and won't break existing SDKs:

### Adding new fields

Adding new fields to API responses is safe because older SDK versions ignore
these fields. New response fields can be added without breaking existing
integrations.

### Adding new enum values

Adding new enum values is safe when enums are marked with
`x-speakeasy-unknown-values` ([see enums customization doc]). Older SDKs handle
these new values gracefully according to the behavior specified in the
extension configuration.

[see enums documentation]: /docs/customize/data-model/enums#open-enums

## Changes requiring caution

Some API changes require careful consideration to avoid breaking existing SDK
implementations. Use the [OpenAPI diff tool] to identify potential breaking
changes in your API specification:

[OpenAPI diff tool]: /docs/speakeasy-reference/cli/openapi/diff


### Deprecating required fields

When deprecating fields marked as required in the API specification:
- Older SDKs throw validation errors if the field is missing
- Make the field optional before removing it
- Plan a deprecation period for implementation updates

### Modifying oneOf schemas

Make changes to `oneOf` schemas carefully:
- Adding new variants may cause type mismatch errors in older SDKs
- Maintain backward compatibility with existing schema variants
- Test changes thoroughly with older SDK versions

## Future improvements

Speakeasy is developing additional features to help manage breaking changes:
- SDK version upgrade prompts
- Improved tooling for breaking changes
- Enhanced version management capabilities

<Callout type="info" title="Note"> 
  For more information about SDK versioning and how Speakeasy handles version
  bumps, see our [SDK versioning guide](./versioning). 
</Callout>


 This is the content for the doc docs/manage/github-setup.mdx 

 ---
title: "Set up your SDK on GitHub"
description: "Learn how to set up your GitHub repo to automatically generate and publish SDKs using the Speakeasy GitHub workflow."
position: 1
---

import { Tabs } from "@speakeasy/nextra-theme";
import { Callout } from "~/components";

# SDK Generation workflow

The SDK Generation workflow is powered by the [Speakeasy CLI](https://github.com/speakeasy-api/speakeasy) and the Speakeasy [SDK Generation GitHub Action](https://github.com/speakeasy-api/sdk-generation-action). The workflow automates the process of:

- Downloading or loading the OpenAPI document from a URL or repository.
- Validating the OpenAPI document.
- Generating SDKs for multiple languages.
- Committing the generated SDKs to the repository or opening a pull request (PR).

## Example workflow file

```yml
name: SDK Generation
permissions:
  checks: write
  contents: write
  pull-requests: write
  statuses: write

on:
  workflow_dispatch:
    inputs:
      force:
        description: Force SDK generation, even if no changes are detected.
        type: boolean
        default: false

jobs:
  generate:
    uses: speakeasy-api/sdk-generation-action/.github/workflows/workflow-executor.yaml@v15
    with:
      speakeasy_version: latest
      force: ${{ github.event.inputs.force }}
      mode: pr
    secrets:
      github_access_token: ${{ secrets.GITHUB_TOKEN }}
      speakeasy_api_key: ${{ secrets.SPEAKEASY_API_KEY }}
```

## Step-by-step guide

### 1. Initialize SDK Repository

Create a new GitHub repository to host the autogenerated SDKs. It is recommended to use a separate repository for each SDK, but a [monorepo](/guides/sdks/creating-a-monorepo) is also supported.

### 2. Generate SDK Workflow Configuration

Run the Speakeasy CLI to configure the SDK generation workflow. This command creates the necessary workflow files.

```bash
speakeasy configure github
```

After running the command, `.speakeasy/workflow.yaml` and `.github/workflows/sdk_generation.yaml` will be created. These files define the SDK generation workflow and the associated GitHub Action.

<Screenshot variant="cli">
  ![Screenshot of the terminal after successfully running Speakeasy configure
  Github.](../assets/configure-github/configure.png)
</Screenshot>

If further customization is needed, [manual configuration](/docs/workflow-reference/generation-reference) of the workflow files is available.

### 3. Set up GitHub secrets

Configure GitHub secrets for authentication:

- Navigate to **Settings > Secrets & Variables > Actions** in your GitHub repository.
- Add a new secret named `SPEAKEASY_API_KEY` which can be obtained from the Speakeasy dashboard.

### 4. Push to GitHub

Commit and push the generated workflow files to the repository. To test your GitHub Action without modifying any GitHub branches, put the action into `mode: test`.

Navigate to **Actions** in the GitHub repository to trigger the SDK generation workflow manually or wait for it to run automatically. A green checkmark indicates successful workflow completion. If the publishing step has not been configured, it will be skipped.

<Screenshot
  darkened
  url="https://github.com/speakeasy-sdks/example/actions/runs/9900330987"
>
  ![A screenshot of a successful generate
  flow.](../assets/configure-github/successful-workflow.png)
</Screenshot>

For details on package publishing, refer to the [Publishing SDKs guide](/docs/publish-sdk).

### 5. GitHub Actions workflow permissions

If the error `403 GitHub Actions is not permitted to create or approve pull requests` occurs, the repository’s GitHub Actions permissions must be updated.

Navigate to **Settings > Actions > Workflow permissions** and adjust the permissions accordingly.

<Screenshot
  darkened
  url="https://github.com/speakeasy-sdks/example/settings/actions"
>
  ![Github Actions workflow
  permissions.](../assets/configure-github/workflow-permissions.png)
</Screenshot>

## Configure remote URLs for schemas

<Callout title="Warning" variant="warning">
  Remote URLs for OpenAPI schemas must remain stable. Dynamically constructed
  URLs in workflow files are not supported.
</Callout>

If the OpenAPI schema is hosted in another repository or at a remote URL, set the `source` as the remote URL in `.speakeasy/workflow.yaml`. Use the following command to add the remote URL:

<Screenshot variant="cli">
  ![Configure Remote URL for
  schema.](../assets/configure-github/remote-url-schema.png)
</Screenshot>

To authenticate the remote URL, provide a token or key stored as an environment variable (e.g., `$OPENAPI_DOC_AUTH_TOKEN`).

**Important**: When fetching OpenAPI specs from private repositories, ensure that you prefix the token value with "Bearer " when setting the value. For example:

```bash
OPENAPI_DOC_AUTH_TOKEN="Bearer <YOUR_TOKEN_VALUE>"
```

Add a [GitHub Secret](https://docs.github.com/en/actions/security-guides/using-secrets-in-github-actions) with the same name and value as the token or key (including the "Bearer " prefix for private repositories).

## Enabling signed commits

To have signed commits from the SDK Generation workflow, add `signed_commits: true` into the workflow file. This configuration ensures that GitHub Actions creates verified commits during workflow execution.


```yml
name: SDK Generation
permissions:
  checks: write
  contents: write
  pull-requests: write
  statuses: write

on:
  workflow_dispatch:
    inputs:
      force:
        description: Force SDK generation, even if no changes are detected.
        type: boolean
        default: false

jobs:
  generate:
    uses: speakeasy-api/sdk-generation-action/.github/workflows/workflow-executor.yaml@v15
    with:
      speakeasy_version: latest
      force: ${{ github.event.inputs.force }}
      mode: pr
      signed_commits: true # !focus(1)
    secrets:
      github_access_token: ${{ secrets.GITHUB_TOKEN }}
      speakeasy_api_key: ${{ secrets.SPEAKEASY_API_KEY }}
```


 This is the content for the doc docs/manage/migrate/poetry-2-update.mdx 

 ---
title: "Poetry 2.0 and Python 3.9 Updates"
description: "Upgrading to Poetry 2.0 and Python 3.9"
---

# Poetry 2.0 and Python 3.9 Updates

This guide covers important updates to the Python SDK generation process related to Poetry 2.0 and Python 3.9 requirements.

## Steps Overview

Two significant changes are being implemented in the Python SDK generation process:

1. The minimum Python version for generated Python SDKs is changing from 3.8 to 3.9
2. Poetry packaging tool is being updated to version 2.0.0

These changes are necessary to evolve with the Python ecosystem and maintain compatibility with current tooling.

## Python 3.9 Requirement

Python 3.8 reached end-of-life (EOL) status in October 2024 and is no longer supported by the Python language maintainers for security and bug fixes. The last bug fix update was in May 2021, and the last security update was in September 2024.

Key type safety tools used by our generation process have begun removing Python 3.8 support:
- Poetry ([change](https://github.com/python-poetry/poetry/pull/9692))
- MyPy ([change](https://github.com/python/mypy/pull/17492))
- Pylint ([change](https://github.com/pylint-dev/pylint/pull/9774))

## Poetry 2.0 Update

Poetry has released a major version update (2.0.0) that includes breaking changes between 1.x and 2.x for CLI commands used in the generation process. By default, following the documented installation options, Poetry is installed at the latest version.

## Local Development Updates

API producers running generation locally will need to update Poetry to the new major version. The update process depends on your installation method:

```bash
# If installed via pipx
pipx upgrade poetry

# If installed via the official installer
poetry self update
```

If Poetry is not updated, the generator will output a dependency version error:

```
WARN	can't compile - Dependency Version Mismatch - Install Poetry by following the instructions at https://python-poetry.org/docs/#installing-with-pipx.
ERROR	dependency version not met -- poetry - version 1.8.5 is less than required version 2.0.0
FATAL	Failed to generate SDK to XXX
```

## GitHub Actions Configuration

For API producers using GitHub Actions (via `speakeasy-api/sdk-generation-action@v15`) with the latest Speakeasy version, Poetry will be automatically updated. No changes are needed for the most common usage.

If the Speakeasy version is pinned to an older version, add the `poetry_version` input to the repository's workflow configuration to pin Poetry to the older major version:

```yaml
uses: speakeasy-api/sdk-generation-action@v15
with:
  # ... other existing inputs ...
  poetry_version: "1.8.5"
```

## Version Update Considerations

The generator will suggest these Python changes as a minor version update to the generated SDK, following typical industry practice. However, API producers may want to consider releasing the SDK as a major version update if they know their API consumers are particularly prone to be running on Python 3.8, which was previously common for some data management software as a service platforms.

If you have any questions please reach out on [Slack](https://join.slack.com/t/speakeasy-dev/shared_invite/zt-1cwb3flxz-lS5SyZxAsF_3NOq5xc8Cjw).


 This is the content for the doc docs/manage/migrate/python-migration.mdx 

 ---
title: "Migrating from Python v1"
description: "Migrating from Python v1."
---

# Upgrading to Python v2 SDK with Speakeasy CLI

To upgrade your Python SDK to version 2 using the Speakeasy CLI, please follow these steps:

## 1. Update the `gen.yaml` file

- Add `templateVersion: v2` to the Python section of your `gen.yaml` file.
- If you have an `additionalDependencies` section under Python, it needs modification. If it hasn’t been changed previously, you can delete it and it will be recreated in the correct format. Otherwise, modify it from this:

     ```yaml
     additionalDependencies:
       dependencies: {}
       extraDependencies:
         dev: {}
     ```

     To this:

     ```yaml
     additionalDependencies:
       dev: {}
       main: {}
     ```

- Move any dependencies listed under the `dependencies` key to `main`.
- Move any dependencies under `extraDependencies.dev` to `dev`.
- Move any additional keys under `extraDependencies` to the top-level `additionalDependencies` next to the other keys.

## 2. Update the `author` key

- Change the old `author` key under `python` to the new `authors` key, which is an array of authors.

     ```yaml
     python:
       authors:
         - Speakeasy
       # other configurations...
     ```

## 3. Generate the Python v2 SDK

- Run `speakeasy run` to generate the Python v2 SDK.

## 4. Adjust imports for Python v2

One of the main changes in Python v2 is how imported packages are handled. In version 1, the `sdkClassName` specified the top-level module. In version 2, `packageName` is now used for imports, and matches the expected naming conventions for packages installed from PyPI. Some code imports may need to be adjusted for this change.

For example, given `sdkClassName` of `speakeasy` and `packageName` of `speakeasy-sdk`, previously the code was generated in the `src/speakeasy` directory and imported with the following code:

```python
from speakeasy import Speakeasy
```

In version 2, the code is generated in the `src/speakeasy_sdk` directory and imported as follows:

```python
from speakeasy_sdk import Speakeasy
```

- If you have custom hooks, move the custom hook files and the hook registration logic in `registration.py` from the old `sdkClassName`-based code generation directory to the new `packageName`-based code generation directory and update imports accordingly. For example:

     ```python
     # Old import
     from speakeasy.hooks import CustomHook

     # New import
     from speakeasy_sdk.hooks import CustomHook
     ```

- If you do not have custom hooks, delete the old `src/speakeasy` folder:

     ```sh
     rm -rf src/speakeasy
     ```

Feel free to reach out if you encounter any issues or need further assistance!


 This is the content for the doc docs/manage/migrate/workflow-migration.mdx 

 ---
title: "Migrate to Speakeasy Workflows"
description: "Migrate to Speakeasy Workflows."
---

# Migrate to Speakeasy Workflows

The [`workflow.yaml` file](/docs/speakeasy-reference/workflow-file) allows you to define all the relevant pieces of your SDK generation as consistent config in a single place. 
This new generation system is entirely portable. Generate your SDKs locally, from GitHub, or from any CI system with absolute consistency.

## Who Needs to Migrate?

If you have been using Speakeasy since before March 2024, follow the steps below to migrate to workflows. Customers who started with Speakeasy in March 2024 or later are likely already using Speakeasy workflows.

If a `.speakeasy` folder is present in your generated SDK, you are already using workflows. 


## Migration Steps

If you have an existing Speakeasy SDK in GitHub, we've set up an easy migration tool for you. Navigate to the root of your repo and run the following command:

```bash
speakeasy migrate
```

You should see the following changes as a result:
- `.speakeasy/workflow.yaml` [NEW]
- `.github/workflows/sdk_generation_action.yaml` [UPDATED]

Push these changes up and you are ready to go!

The produced files should look something like the following.

```yaml .github/workflows/sdk_generation_action.yaml
name: Generate
permissions:
  checks: write
  contents: write
  pull-requests: write
  statuses: write
"on":
  workflow_dispatch:
    inputs:
      force:
        description: Force generation of SDKs
        type: boolean
        default: false
  schedule:
    - cron: 0 0 * * *
jobs:
  generate:
    uses: speakeasy-api/sdk-generation-action/.github/workflows/workflow-executor.yaml@v15
    with:
      force: ${{ github.event.inputs.force }}
      mode: pr
    secrets:
      github_access_token: ${{ secrets.GITHUB_TOKEN }}
      speakeasy_api_key: ${{ secrets.SPEAKEASY_API_KEY }}
```

```yaml .speakeasy/workflow.yaml
workflowVersion: 1.0.0
speakeasyVersion: latest
sources:
    openapi:
        inputs:
            - location: https://raw.githubusercontent.com/speakeasy-sdks/template-speakeasy-bar/main/openapi.yaml
targets:
    my-target:
        target: typescript
        source: openapi
```

You can now generate your SDK locally using `speakeasy run` while GitHub Actions automated generations will continue working as previously.

If you have any custom code in your current GitHub action workflow, it should automatically be moved over by the migration script. 

If you have any issues migrating to workflows, reach out to the Speakeasy team on Slack and we will help you resolve it quickly.

## Creating a New SDK Repo

If you prefer to migrate by creating a new SDK repo, we have an easy-to-use command to set up an SDK for your preferred spec and language.

Create a new repo and run the following commands from the root directory:

```bash
speakeasy quickstart
speakeasy configure github
```

Once your repo is created, copy the `gen.yaml` from your old SDK into `.speakeasy/gen.yaml` in your new SDK repo. You're ready to generate!


 This is the content for the doc docs/manage/sdk-sandbox.mdx 

 ---
title: SDK sandboxes
description: "SDK Sandboxes offer users an intuitive, browser-based sandbox environment to explore the capabilities of your SDK."
---

import { Callout } from '~/components'

# SDK Sandboxes

Speakeasy can seamlessly generate dev container configurations for your SDK repositories to give you and your SDK consumers an intuitive, predefined sandbox environment to explore the capabilities of your SDK. Beyond setting up this environment, Speakeasy has CLI commands that allow SDK users to effortlessly generate example usage snippets for any API operation within this container setting.

<Callout title="TIP" variant="success">SDK Sandboxes are currently available in Go, TypeScript, and Python SDKs.</Callout>

## Configuring SDK Sandboxes

To set up the automatically generated dev container configurations, you'll need to make minor adjustments to your `gen.yaml` file. The `schemaPath` shown below should reference your SDK's OpenAPI spec, which can be a local path or a remote URL.

**Dev Container gen.yaml**:

```yaml
configVersion: 1.0.0
generation:
  devContainers:
    enabled: true
    schemaPath: ./openapi.yaml
```

The result of generation will be a newly created `.devcontainer` directory containing a configuration file like the one shown below.

**Generated devcontainer.json**:

```json
// For format details, see https://aka.ms/devcontainer.json. For config options, see the
// README at: https://github.com/devcontainers/templates/tree/main/src/go
{
    "name": "Go",
    "image": "mcr.microsoft.com/devcontainers/go:1-1.20-bullseye",
    // Features to add to the dev container. More info: https://containers.dev/features.
    // "features": {},
    // Use 'forwardPorts' to make a list of ports inside the container available locally.
    // "forwardPorts": [],
    // Use 'postCreateCommand' to run commands after the container is created.
    "postCreateCommand": "sudo chmod +x ./.devcontainer/setup.sh && ./.devcontainer/setup.sh",
    "customizations": {
        "vscode": {
            "extensions": [
                "golang.go",
                "github.vscode-pull-request-github" // Github interaction
            ],
            "settings": {
                "files.eol": "\n",
                "editor.formatOnSave": true,
                "go.buildTags": "",
                "go.toolsEnvVars": {
                    "CGO_ENABLED": "0"
                },
                "go.useLanguageServer": true,
                "go.testEnvVars": {
                    "CGO_ENABLED": "1"
                },
                "go.testFlags": [
                    "-v",
                    "-race"
                ],
                "go.testTimeout": "60s",
                "go.coverOnSingleTest": true,
                "go.coverOnSingleTestFile": true,
                "go.coverOnTestPackage": true,
                "go.lintTool": "golangci-lint",
                "go.lintOnSave": "package",
                "[go]": {
                    "editor.codeActionsOnSave": {
                        "source.organizeImports": true
                    }
                },
                "gopls": {
                    "usePlaceholders": false,
                    "staticcheck": true,
                    "vulncheck": "Imports"
                }
            }
        },
        "codespaces": {
            "openFiles": [
                ".devcontainer/README.md"
            ]
        }
    }
    // Uncomment to connect as root instead. More info: https://aka.ms/dev-containers-non-root.
    // "remoteUser": "root"
}
```

## Using SDK Sandboxes in the Browser

Your SDK users can instantly initialize a sandbox in [GitHub Codespaces](https://docs.github.com/en/codespaces/overview) with a single click. By default, GitHub Codespaces shifts the cost to the user. However, you have the option to [configure your organization](https://docs.github.com/en/codespaces/managing-codespaces-for-your-organization/enabling-or-disabling-github-codespaces-for-your-organization) to offer complimentary codespaces to your users if you prefer.

![Screenshot of a README featuring a Dev Container badge](../assets/dev-container.png)


 This is the content for the doc docs/manage/versioning.mdx 

 
import { Callout } from "~/components";

# SDK versioning

Speakeasy-generated SDKs are automatically versioned using Semantic Versioning ([SemVer](https://semver.org/)). With each new generation, the SDK version is bumped up.

## Versioning logic

The SDK version will be automatically incremented in the following cases. 

### Generator version changes

When Speakeasy releases a new generator version, it compares the features changed in the new generator to those used in the SDK:

- If multiple used features in the SDK change, the largest version bump (major, minor, patch) across all used features determines the version increment.
- Features unaffected by the new generator version maintain the current version.

### Configuration changes

- Changes to the `gen.yaml` file will bump the patch version.
- Changes to the checksum will also bump the patch version.

### OpenAPI document changes

- If the `info.version` section of your OpenAPI document is SemVer compliant, major or minor changes to the OpenAPI document will bump the major or minor version of SDKs correspondingly.
- *Coming Soon*: Speakeasy will detect changes to the OpenAPI document (for example, adding a breaking change to the parameters of an operation) and bump versions accordingly.

## Pre-release version bumps

Speakeasy supports any SemVer-compatible string as a valid version, including pre-release versions such as `X.X.X-alpha` or `X.X.X-alpha.X`.

- Pre-release versioning continues until manual removal.
- Automated bumps increment pre-release versions. For example, `1.0.0-alpha`, `1.0.0-alpha.1`, `1.0.0-alpha.2`.
- To exit pre-release versioning, set a new version or run `speakeasy bump graduate`.

## Major version bumps

New SDKs start at version `0.0.1`. Automatic major version bumps begin after reaching version `1.0.0`. Breaking changes trigger major version increments after `1.0.0`.

Major version changes affect the Golang SDK migration path.

### Golang major version bumps

Golang module versions above `1.0.0` require import path changes to include the major version. For example:

- Version `1.2.3`: `github.com/speakeasy/speakeasy-go`
- Version `2.0.0`: `github.com/speakeasy/speakeasy-go/v2`

Consider Golang SDK major version changes carefully due to migration path impacts. The SDK maintainer determines when to increment major versions.

## Manual version bumps

Speakeasy supports manual control of SDK versioning via the CLI and the dashboard.

### Via the CLI

To override the automatic versioning logic for the next generation, set the `version` field in the `gen.yaml` file.

- The Speakeasy generator detects manual version settings when the `releaseVersion` field in the `gen.lock` file differs from the `version` field in the `gen.yaml` file.
- Automatic versioning will resume when the version values in both files match.
- Use the Speakeasy CLI `bump` command to set the SDK version without manually editing the `gen.yaml` file.

### Via GitHub UI

Speakeasy supports label-based versioning via GitHub pull request (PR) UI:

1. Automated version detection: The system analyzes changes and suggests the appropriate semantic version bump. The generated PR displays a suggested version label: `major`, `minor`, or `patch`. A `pre-release` label is added for pre-release versions.

2. Manual override option: Override the suggestion by removing the current label and adding a `major`, `minor`, or `patch` label to the PR. Use the bump type `graduate` to move out of pre-release stage. The SDK version updates automatically on the next generation and persists across regenerations until changed.

<Screenshot darkened url="https://github.com/speakeasy-sdks/bar-python/pull/8">
![Screenshot of the publishing tab in the Speakeasy dashboard.](../assets/labels-location.png)
</Screenshot>

3. Immediate generation: Label-based versioning is active in all SDK generation workflows. To automate generation immediately after label addition, add the following action trigger to the GitHub workflow file (typically at `.github/workflows/sdk_generation.yaml`):

```yaml
# !focus(7,21:22)
name: Generate
permissions:
    checks: write
    contents: write
    pull-requests: write
    statuses: write
"on":
    workflow_dispatch:
        inputs:
            force:
                description: Force generation of SDKs
                type: boolean
                default: false
            push_code_samples_only:
                description: Force push only code samples from SDK generation
                type: boolean
                default: false
            set_version:
                description: optionally set a specific SDK version
                type: string
    pull_request:
        types: [labeled]
    schedule:
        - cron: 0 0 * * *
```

### Via the dashboard

To set a version manually in the Speakeasy dashboard:

1. Navigate to the **Publishing** tab and select **Set a New Version**.

<Screenshot darkened url="https://app.speakeasy.com/org/">
![Screenshot of the publishing tab in the Speakeasy dashboard.](../assets/versioning-1.png)
</Screenshot>

2. Enter the version following SemVer conventions. The dashboard validates and ensures no version override.

<Screenshot darkened url="https://app.speakeasy.com/org/">
![Screenshot of the version pop-up in the Speakeasy dashboard.](../assets/versioning-2.png)
</Screenshot>

3. Click **Submit Version Change** to apply.



 This is the content for the doc docs/prep-openapi/best-practices.mdx 

 ---
title: "OpenAPI overview and best practices"
description: "OpenAPI / Swagger basics and best practices for constructing an OpenAPI document."
---

import { ScrollyCoding } from "~/components/codehike/Scrollycoding";

# OpenAPI overview and best practices

OpenAPI is a standard for describing RESTful APIs. Developers use OpenAPI to define an API's core elements, like endpoints, request and response data formats, authentication methods, and so on.

Several versions of the OpenAPI Specification are in circulation: 2.0 (known as Swagger), 3.0, and 3.1.

Speakeasy supports OpenAPI versions 3.0 and 3.1 and recommends OpenAPI version 3.1 for all projects. The advantage of OpenAPI version 3.1 is that it's fully compatible with [JSON Schema](https://json-schema.org/), which gives you access to a large ecosystem of tools and libraries.

## OpenAPI best practices

OpenAPI has a lot of baked-in flexibility and can describe any HTTP API, including REST APIs and even RPC-based calls. The OpenAPI Specification provides several valid approaches to achieving the same result.

With so much flexibility, it isn't always obvious how to construct an OpenAPI document that's suitable for code generation. Speakeasy recommends a set of best practices to follow when writing OpenAPI documents. The following sections outline key points to consider as you create your OpenAPI description.

<ScrollyCoding>
## !!steps servers

Add multiple `servers` to define different environments or versions. This is especially useful for separating production and testing environments.

```yaml ! openapi.yaml
# !focus(5:9)
openapi: 3.1.0
info:
  title: The Speakeasy Bar
  version: 1.0.0
servers:
  - url: https://speakeasy.bar
    description: The production server
  - url: https://speakeasy.bar/testing
    description: The testing server
security:
  - apiKey: []
paths:
  /drinks:
    get:
      tags:
        - drinks
      operationId: listDrinks
      summary: Get a list of drinks
      responses:
        "200":
          description: A list of drinks
          content:
            application/json:
              schema:
                type: array
                items:
                  $ref: "#/components/schemas/Drink"
              examples:
                exampleResponse:
                  summary: Example response for a list of drinks
                  value:
                    drinks:
                      - name: "Coffee"
                        price: 2.5
                      - name: "Tea"
                        price: 1.8
        "400":
          description: Bad request
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/BadRequest"
components:
  schemas:
    Drink:
      type: object
      title: Drink
      properties:
        name:
          type: string
        price:
          type: number
      description: A response containing a list of drinks.
    BadRequest:
      type: object
      title: BadRequest
      properties:
        error:
          type: string
        message:
          type: string
  securitySchemes:
    apiKey:
      type: apiKey
      name: Authorization
      in: header
```

---

## !!steps tags

The `tags` property contains an optional list of values used to group or categorize a set of operations. We **_strongly recommend_** that you always define `tags` for operations but it&apos;s not required.

**In code generation**

Tags are used to namespace methods in the SDK. For example, if you have a tag called `drinks`, then all the methods for that tag will be namespaced under `drinks.listDrinks()`. You can create multi-level namespaces by using a `.` in the tag name, for example, `menu.drinks` will become `menu.drinks.listDrinks()`.

```yaml ! openapi.yaml
# !focus(15:16)
```

---

## !!steps operationId

The `operationId` value is a unique identifier for the operation. It **_must_** be unique in the document and is **_case sensitive_**. We **_strongly recommend_** that you always define an `operationId`, but it&apos;s not required.

**In code generation**

The `operationId` value is used to create the name of the method that will be generated for the operation. We recommend you follow a consistent pattern for naming your operations, for example, `listDrinks`, `createDrink`, `updateDrink`, and `deleteDrink`.

If you are generating your spec from an API framework, ensure that `operationId` values are human-readable. Some frameworks, like FastAPI, create long `operationId` identifiers that result in method names that are not idiomatic.

```yaml ! openapi.yaml
# !focus(17)
```

---

## !!steps Examples

Adding `Examples` improves the usability of your OpenAPI document by providing examples that illustrate the expected request and response structures.

```yaml ! openapi.yaml
# !focus(28:36)
```

---

## !!steps $ref

In OpenAPI, the `$ref` keyword references components defined in the Components Object. These components are commonly used for reusable elements like schemas, parameters, responses, and examples.

**In code generation**

Component schemas describe the request and response bodies of operations, serving as the basis for generating SDK types. Using components prevents issues where multiple types are defined for the same data structure.

```yaml ! openapi.yaml
# !focus(27,51:64)
```

---

**Dedicated Error Classes**

Create dedicated error classes by defining response objects with specific HTTP status codes, such as `400 Bad Request` or `404 Not Found`, accompanied by clear descriptions and structured schemas to convey detailed error information.
If the name of the error class does not clearly incidate the error type, consider using the `x-speakeasy-name-override` extension to rename it.

```yaml ! openapi.yaml
# !focus(37:42)
```

---

## !!steps title

The `title` property provides a human-readable title for each schema, improving the readability of your OpenAPI document.

```yaml ! openapi.yaml
# !focus(47)
```

---

## !!steps Description

Use the `description` field to provide clear and concise information about the purpose, behavior, and expected usage of API elements.

```yaml ! openapi.yaml
# !focus(53)
```

---

</ScrollyCoding>

## Extending OpenAPI

The OpenAPI Specification does not have an exhaustive vocabulary for describing API functionality. To overcome gaps in the specification, you can add several extension fields to an OpenAPI document that describe additional metadata and functionality.

Extensions typically follow a naming format of `x-<vendor>-<function>`, where `<vendor>` is the name of the vendor or tool that created the extension and `<function>` is the goal accomplished by the extension.

A [range of Speakeasy extensions](/docs/customize-sdks/) are available to help you prepare an OpenAPI document for code generation. Some of the most commonly used extensions are described below.

<ScrollyCoding>

## !!steps x-speakeasy-name-override

Use this extension to override the name of a class, operation, or parameter. The most common use case is to override `operationId` values in your OpenAPI document to simplify the generated SDK method names.

If your `operationId` identifiers follow a consistent pattern, you can define the name override globally using a regular expression to match the `operationId` and replace it with a new name.

In this instance, the SDK will contain a method `menu.drinks.list()` rather than the longer `menu.drinks.list_drinks_v2_get()`.

```yaml ! openapi.yaml
# !focus(10:12,19)
openapi: 3.1.0
info:
  title: The Speakeasy Bar
  version: 1.0.0
servers:
  - url: https://speakeasy.bar
    description: The production server
security:
  - apiKey: []
x-speakeasy-name-override:
  - operationId: ^list_.*
    methodNameOverride: list
paths:
  /drinks:
    get:
      tags:
        - menu
      x-speakeasy-group: menu.drinks
      operationId: list_drinks_v2_get
      x-speakeasy-usage-example: true
      summary: Get a list of drinks
      responses:
        "200":
          description: A list of drinks
          content:
            application/json:
              schema:
                type: array
                items:
                  $ref: "#/components/schemas/Drink"
components:
  schemas:
    Drink:
      type: object
      properties:
        name:
          type: string
        price:
          type: number
  securitySchemes:
    apiKey:
      type: apiKey
      name: Authorization
      in: header
      x-speakeasy-example: "<YOUR_API_KEY>"
```

---

## !!steps x-speakeasy-group

Sometimes, the `tags` in an OpenAPI document may already be used for an unrelated purpose, such as autogenerating labels in documentation. In this scenario, you may want to use something other than `tags` to organize and group your methods.

You can add the `x-speakeasy-group` field to any operation in your OpenAPI document to define custom namespaces and override any `tags` associated with the method.

In this case, the `listDrinks` operation is added to a `menu.drinks` namespace rather than a `menu` namespace.

```yaml ! openapi.yaml
# !focus(18)
```

---

## !!steps x-speakeasy-usage-example

Documentation is an important part of any SDK. This extension allows you to choose which operation is featured at the top of your `README.md`.

We recommend that you pick the API operation that your users frequently use. At a Speakeasy, that would likely be getting the list of drinks on offer.

```yaml ! openapi.yaml
# !focus(20)
```

---

## !!steps x-speakeasy-example

Another useful documentation extension is `x-speakeasy-example`, which allows you to provide an example value to be used in the `Authentication` section of your SDK `README.md`. This example signals to users that they should instantiate the SDK with their security token.

```yaml ! openapi.yaml
# !focus(45)
```

</ScrollyCoding>


 This is the content for the doc docs/prep-openapi/linting.mdx 

 ---
title: "OpenAPI document linting"
description: "Learn how to use Speakeasy to validate OpenAPI syntax, operations, schemas, and extensions."
sidebar_title: "Overview"
---

import Image from "next/image";
import { Callout } from "~/components";
import vsCodeImageUrl from "../assets/vscode.svg";

# OpenAPI document linting

<Callout title="TIP" variant="info">
  The &nbsp;<Image
    src={vsCodeImageUrl}
    width="20"
    height="20"
    style={{ display: "inline-block" }}
    alt='Visual Studio Code logo'
  />&nbsp;
  [Speakeasy VS Code
  extension](https://marketplace.visualstudio.com/items?itemName=Speakeasy.speakeasy-vscode-extension)
  provides syntax highlighting and autocompletion for editing the `lint.yaml`
  file, as well as linting for OpenAPI documents and other supported file types.
</Callout>

In addition to running validation, you can use Speakeasy to lint your OpenAPI documents to ensure they are stylistically valid. By default, the linter runs using a [recommended set of rules](/docs/linting/linting#speakeasy-recommended), which you can optionally extend with the [available ruleset](/docs/linting/linting#available-rulesets). You can also write custom rules using the Spectral format.

With the Speakeasy Linter, you can:

- Lint and validate OpenAPI 3.x documents.
- Choose from 70+ rules.
- Get started quickly with five out-the-box rulesets, including `speakeasy-recommended`, `speakeasy-generation`, `speakeasy-openapi`, `vacuum`, and `owasp`.
- Reconfigure the Speakeasy default rules and rulesets.
- Configure custom rulesets.
- Define new rules using the Spectral rule format.
- Provide custom functions written in Go and JavaScript for custom rules.

## Usage

There are three options for running linting:

1. Run manually via the Speakeasy CLI:

```bash
speakeasy lint openapi -s openapi.yaml
```

2. Integrate into your Speakeasy workflow:

```yaml
workflowVersion: "1.0.0"
speakeasyVersion: latest
sources:
  my-source:
    inputs:
      - location: ./openapi.yaml
```

Running `speakeasy run` will lint your document as part of the workflow and generate an HTML report that you can access from a link in the command output.

3. Use the <Image src={vsCodeImageUrl} width="20" height="20" style={{display: "inline-block"}} alt='Visual Studio Code logo' /> [Speakeasy VS Code extension](https://marketplace.visualstudio.com/items?itemName=Speakeasy.speakeasy-vscode-extension) in your IDE.

By default, these options use the `speakeasy-recommended` ruleset to ensure your OpenAPI document meets the Speakeasy quality bar.

## Configuration

The linting of an OpenAPI spec is fully configurable. You can create a custom ruleset by selecting from our predefined sets or writing your own rules. These custom linting rules can be used throughout your workflow.

However, immediately before SDK generation, the `speakeasy-generation` ruleset is always used to ensure compatibility with the code generator.

Configure linting in a `lint.yaml` document in the `.speakeasy` folder. The `.speakeasy` folder can be located in the same directory as the OpenAPI document, the working directory you run the `speakeasy lint` or `speakeasy run` commands from, or the home directory.

Here is an example of linting configuration in a `lint.yaml` file:

```yaml
lintVersion: 1.0.0
defaultRuleset: speakeasyBarRuleset
rulesets:
  barRuleset:
    rulesets:
      - speakeasy-generation # Use the speakeasy-generation ruleset as a base
      - ourRuleset
    rules:
      validate-enums: {
          severity: warn, # drop the severity of the `validate-enums` rule as I don't want this to block the pipeline
        }
  ourRuleset:
    rules:
      paths-kebab-case: # A custom rule following the spectral format for a rule
        description: Paths should be kebab-case.
        message: "{{property}} should be kebab-case (lower-case and separated with hyphens)"
        severity: warn
        given: $.paths[*]~
        then:
          functionOptions:
            match: "^(\\/|[a-z0-9-.]+|{[a-zA-Z0-9_]+})+$"
      contact-properties:
        description: Contact object must have "name", "url", and "email".
        given: $.info.contact
        severity: warn
        then:
          - field: name
            function: truthy
          - field: url
            function: truthy
          - field: email
            function: truthy
```

A `lint.yaml` document defines a collection of rulesets that can be chained together or used independently. You can define any built-in Speakeasy rulesets, define new rules, modify existing rules, or remix the available rules to suit your needs.

Rulesets can be used in various ways:

1. Set the `defaultRuleset` in your `lint.yaml` to the ruleset you want to use by default. The default ruleset will be used if a ruleset is not specified using the `lint` command or `workflow.yaml` file.
2. Pass a ruleset name to the `lint` command with the `-r` argument, for example, `speakeasy lint openapi -r barRuleset -s openapi.yaml`.
3. Define the ruleset to use for a particular source in your `workflow.yaml` file.

```yaml
workflowVersion: "1.0.0"
speakeasyVersion: latest
sources:
  my-source:
    inputs:
      - location: ./openapi.yaml
    ruleset: barRuleset
```

## Custom rules

The easiest way to create a custom rule is to use the [Spectral rule format](https://docs.stoplight.io/docs/spectral/d3482ff0ccae9-rules), which is an object that defines the rule and its properties.

Use this format to override built-in rules or define new rules.

For rules that are more complex than matching a pattern or checking that a field exists, you can define a custom Go or JavaScript function in your rule.

Speakeasy linting is built on top of [vacuum](https://github.com/daveshanley/vacuum) and allows you to use custom Go or JavaScript functions in rules. The vacuum documentation provides instructions for writing custom functions in [JavaScript](https://quobix.com/vacuum/api/custom-javascript-functions/) and [Go](https://quobix.com/vacuum/api/custom-functions/).

## Available rules

The rules available to the Speakeasy Linter are listed below and can be used in custom rulesets or to match and modify default rules in the `lint.yaml` file.

| Rule ID                                | Default Severity | Description                                                                                                                                                              |
| -------------------------------------- | ---------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| openapi-tags-alphabetical              | info             | Tags must be in alphabetical order.                                                                                                                                      |
| tag-description                        | warn             | Tag must have a description defined.                                                                                                                                     |
| no-$ref-siblings                       | error            | $ref values cannot be placed next to other properties (like a description).                                                                                              |
| oas3-unused-component                  | warn             | Check for unused components and bad references.                                                                                                                          |
| owasp-auth-insecure-schemes            | error            | Authentication scheme is considered outdated or insecure.                                                                                                                |
| no-http-verbs-in-path                  | warn             | Path segments must not contain an HTTP verb.                                                                                                                             |
| operation-4xx-response                 | warn             | Make sure operations return at least one `4xx` error response to help with bad requests.                                                                                 |
| duplicated-entry-in-enum               | error            | Enum values must not have duplicate entries.                                                                                                                             |
| operation-tags                         | warn             | Operation `tags` are missing or empty.                                                                                                                                   |
| owasp-define-error-responses-401       | warn             | OWASP API Security recommends defining schemas for all responses, even `401 Unauthorized`                                                                                |
| oas2-anyOf                             | error            | `anyOf` was introduced in OpenAPI 3.0, cannot be used in OpenAPI 2.0 specs                                                                                               |
| owasp-define-error-responses-429       | warn             | OWASP API Security recommends defining schemas for all responses, even `429 Too Many Requests`.                                                                          |
| owasp-no-credentials-in-url            | error            | URL parameters must not contain credentials such as API key, password, or secret.                                                                                        |
| duplicate-tag                          | error            | Tag names must be unique when converted to class, field, or file names.                                                                                                  |
| validate-parameters                    | error            | Validate parameters are unique and have a non-empty `name` property when converted to field names.                                                                       |
| oas2-operation-formData-consume-check  | warn             | Operations with `in: formData` parameter must include `application/x-www-form-urlencoded` or `multipart/form-data` in their `consumes` property.                         |
| oas2-discriminator                     | error            | Discriminators are used correctly in schemas.                                                                                                                            |
| oas2-operation-security-defined        | error            | `security` values must match a scheme defined in `securityDefinitions`.                                                                                                  |
| oas2-oneOf                             | error            | `oneOf` was introduced in OpenAPI 3.0, cannot be used in OpenAPI 2.0 specs.                                                                                              |
| operation-tag-defined                  | warn             | Operation tags must be defined in global tags.                                                                                                                           |
| oas3-example-external-check            | warn             | Examples cannot use `value` and `externalValue` together.                                                                                                                |
| oas2-api-host                          | info             | OpenAPI `host` must be present and a non-empty string.                                                                                                                   |
| owasp-protection-global-unsafe         | error            | API should be protected by a `security` rule at either global or operation level.                                                                                        |
| oas3-schema                            | error            | OpenAPI 3.0 specification is invalid.                                                                                                                                    |
| path-params                            | error            | Path parameters must be defined and valid.                                                                                                                               |
| owasp-string-limit                     | error            | String size should be limited to mitigate resource exhaustion attacks.                                                                                                   |
| owasp-no-http-basic                    | error            | Security scheme uses HTTP Basic. Use a more secure authentication method like OAuth 2.0.                                                                                 |
| oas2-host-not-example                  | warn             | Host URL should not point at example.com.                                                                                                                                |
| validate-enums                         | error            | Validate enums are valid for type generation.                                                                                                                            |
| validate-paths                         | error            | Validate paths conform to RFC 3986.                                                                                                                                      |
| duplicate-properties                   | error            | Property names must be unique and not empty within an operation when converted to field names.                                                                           |
| validate-composite-schemas             | error            | Ensure `anyOf`, `allOf`, and `oneOf` don't contain duplicate references.                                                                                                 |
| owasp-protection-global-unsafe-strict  | info             | Check if the operation is protected at operation level. Otherwise, check the global `security` property.                                                                 |
| owasp-security-hosts-https-oas3        | error            | All server interactions MUST use HTTPS, meaning server URLs should begin `https://`.                                                                                     |
| owasp-jwt-best-practices               | error            | JWTs must explicitly declare support for RFC 8725 in the description.                                                                                                    |
| owasp-define-error-responses-500       | warn             | OWASP API Security recommends defining schemas for all responses, even `500 Internal Server Error`.                                                                      |
| description-duplication                | info             | Description duplication check.                                                                                                                                           |
| no-script-tags-in-markdown             | error            | Markdown descriptions must not have `<script>` tags.                                                                                                                     |
| owasp-rate-limit-retry-after           | error            | Ensure that any `429` response contains a `Retry-After` header.                                                                                                          |
| oas3-valid-schema-example              | warn             | If an example has been used, check the schema is valid.                                                                                                                  |
| typed-enum                             | warn             | Enum values must respect the specified type.                                                                                                                             |
| operation-operationId                  | error            | Every operation must contain an `operationId`.                                                                                                                           |
| operation-parameters                   | error            | Operation parameters are unique and non-repeating.                                                                                                                       |
| validate-requests                      | error            | Validate request content types are valid MIME types.                                                                                                                     |
| validate-document                      | error            | Document must have a `paths` or `webhooks` object.                                                                                                                       |
| no-ambiguous-paths                     | error            | Paths need to resolve unambiguously from one another.                                                                                                                    |
| oas3-api-servers                       | warn             | Check for valid API servers definition.                                                                                                                                  |
| info-contact                           | warn             | Info section is missing contact details.                                                                                                                                 |
| paths-kebab-case                       | warn             | Path segments must only use kebab case (no underscores or uppercase).                                                                                                    |
| openapi-tags                           | warn             | Top-level spec `tags` must not be empty and must be an array.                                                                                                            |
| owasp-array-limit                      | error            | Array size should be limited to mitigate resource exhaustion attacks.                                                                                                    |
| oas-schema-check                       | error            | All document schemas must have a valid type defined.                                                                                                                     |
| license-url                            | info             | License should contain a URL.                                                                                                                                            |
| oas2-schema                            | error            | OpenAPI 2.0 specification is invalid.                                                                                                                                    |
| operation-success-response             | warn             | Operation must have at least one `2xx` or `3xx` response.                                                                                                                |
| owasp-no-api-keys-in-url               | error            | API key has been detected in a URL.                                                                                                                                      |
| info-description                       | error            | Info section is missing a description.                                                                                                                                   |
| oas3-missing-example                   | warn             | Ensure everything that can have an example contains one.                                                                                                                 |
| oas3-host-trailing-slash               | warn             | Server URL should not contain a trailing slash.                                                                                                                          |
| owasp-string-restricted                | error            | String must specify a `format`, RegEx `pattern`, `enum`, or `const`.                                                                                                     |
| owasp-no-additionalProperties          | warn             | By default, JSON Schema allows additional properties, which can potentially lead to mass assignment issues.                                                              |
| contact-properties                     | info             | Contact details are incomplete.                                                                                                                                          |
| validate-security                      | error            | Validate security schemes are correct.                                                                                                                                   |
| operation-operationId-unique           | error            | Every operation must have a unique `operationId`.                                                                                                                        |
| validate-types                         | error            | Ensure data types are valid for generation.                                                                                                                              |
| validate-consts-defaults               | warn             | Ensure `const` and `default` values match their type.                                                                                                                    |
| operation-singular-tag                 | warn             | Operation cannot have more than a single tag defined.                                                                                                                    |
| oas2-api-schemes                       | warn             | OpenAPI host `schemes` must be present and a non-empty array.                                                                                                            |
| validate-anyof                         | warn             | `anyOf` should only contain types that are compatible with each other.                                                                                                   |
| duplicate-schemas                      | hint             | Inline object schemas must be unique.                                                                                                                                    |
| missing-examples                       | hint             | Examples should be provided where possible.                                                                                                                              |
| no-eval-in-markdown                    | error            | Markdown descriptions must not have `eval()` statements.                                                                                                                 |
| oas2-host-trailing-slash               | warn             | Host URL should not contain a trailing slash.                                                                                                                            |
| owasp-no-numeric-ids                   | error            | Use random IDs that cannot be guessed. UUIDs are preferred.                                                                                                              |
| duplicate-schema-name                  | error            | Schema names must be unique when converted to class names.                                                                                                               |
| validate-responses                     | error            | Validate response content types are valid MIME types.                                                                                                                    |
| path-not-include-query                 | error            | Path must not include query string.                                                                                                                                      |
| path-declarations-must-exist           | error            | Path parameter declarations must not be empty, for example, `/api/{}` is invalid.                                                                                        |
| owasp-constrained-additionalProperties | warn             | By default, JSON Schema allows additional properties, which can potentially lead to mass assignment issues.                                                              |
| operation-description                  | warn             | Operation description checks.                                                                                                                                            |
| owasp-integer-format                   | error            | Integers should be limited to mitigate resource exhaustion attacks.                                                                                                      |
| owasp-integer-limit                    | error            | Integers should be limited with `min` or `max` values to mitigate resource exhaustion attacks.                                                                           |
| validate-deprecation                   | error            | Ensure correct usage of `x-speakeasy-deprecation-replacement` and `x-speakeasy-deprecation-message` extensions.                                                          |
| validate-json-schema                   | error            | Validate OpenAPI document against JSON Schema.                                                                                                                           |
| validate-content-type                  | error            | Validate content type schemas.                                                                                                                                           |
| owasp-define-error-validation          | warn             | Missing error response for `400`, `422`, or `4XX`. Ensure all errors are documented.                                                                                     |
| owasp-rate-limit                       | error            | Define proper rate limiting to avoid attackers overloading the API.                                                                                                      |
| oas3-parameter-description             | warn             | Parameter description checks.                                                                                                                                            |
| oas3-host-not-example.com              | warn             | Server URL should not point at example.com.                                                                                                                              |
| component-description                  | warn             | Component description check.                                                                                                                                             |
| oas3-operation-security-defined        | error            | `security` values must match a scheme defined in `components.securitySchemes`.                                                                                           |
| path-keys-no-trailing-slash            | warn             | Path must not end with a slash.                                                                                                                                          |
| duplicate-operation-name               | error          | Duplicate operation names can cause SDK method name collisions. An SDK method name combines two parts: `group` and `methodName`, forming `sdk.{group}.{methodName}()`. The `methodName` is derived from `operationId` but can be overridden with `x-speakeasy-name-override`; if neither is provided, it falls back to a name generated from the HTTP path and HTTP method. The optional `group` comes from `x-speakeasy-group`; if absent, `tags` may be used. |
| info-license                           | info             | Info section should contain a license.                                                                                                                                   |
| owasp-protection-global-safe           | info             | Check if the operation is protected at operation level. Otherwise, check the global `security` property.                                                                 |
| operation-operationId-valid-in-url     | error            | `operationId` must use URL-friendly characters.                                                                                                                          |
| validate-servers                       | error            | Validate servers, variables, and `x-speakeasy-server-id` extension.                                                                                                      |
| validate-extensions                    | error            | Validate `x-speakeasy-globals` extension usage.                                                                                                                          |
| oas2-unused-definition                 | warn             | Check for unused definitions and bad references.                                                                                                                         |
| oas2-parameter-description             | warn             | Parameter description checks.                                                                                                                                            |

## Available rulesets

The rulesets available to the Speakeasy Linter are listed below and can be chained in your custom rules. These rulesets will be used by default when custom linting configuration is not provided.

### speakeasy-recommended

The Speakeasy Linter uses the `speakeasy-recommended` ruleset by default when no custom ruleset is provided. This ruleset is recommended to ensure your OpenAPI document meets the Speakeasy quality bar.

| Rule ID                         |
| ------------------------------- |
| duplicate-schema-name           |
| duplicate-operation-name        |
| duplicate-properties            |
| validate-anyof                  |
| validate-document               |
| validate-enums                  |
| validate-extensions             |
| validate-json-schema            |
| validate-parameters             |
| validate-requests               |
| validate-responses              |
| validate-composite-schemas      |
| validate-security               |
| validate-servers                |
| validate-types                  |
| validate-paths                  |
| validate-deprecation            |
| duplicate-tag                   |
| validate-consts-defaults        |
| validate-content-type           |
| duplicate-schemas               |
| missing-examples                |
| path-params                     |
| path-declarations-must-exist    |
| path-not-include-query          |
| oas3-operation-security-defined |
| typed-enum                      |
| no-eval-in-markdown             |
| no-script-tags-in-markdown      |
| operation-operationId-unique    |
| operation-success-response      |
| oas3-unused-component           |
| oas3-host-not-example.com       |
| operation-operationId           |
| duplicated-entry-in-enum        |
| operation-tag-defined           |

### speakeasy-generation

The `speakeasy-generation` ruleset is used when generating an SDK from an OpenAPI document. This set of rules _must_ pass to successfully generate an SDK from an OpenAPI document. This ruleset can't be overridden or reconfigured when using the generator.

Use the `speakeasy-generation` ruleset as appropriate to configure the linter to ensure an OpenAPI document is ready for generation.

| Rule ID                         |
| ------------------------------- |
| duplicate-schema-name           |
| duplicate-operation-name          |
| duplicate-properties            |
| validate-anyof                  |
| validate-document               |
| validate-enums                  |
| validate-extensions             |
| validate-json-schema            |
| validate-parameters             |
| validate-requests               |
| validate-responses              |
| validate-composite-schemas      |
| validate-security               |
| validate-servers                |
| validate-types                  |
| validate-paths                  |
| validate-deprecation            |
| duplicate-tag                   |
| validate-consts-defaults        |
| validate-content-type           |
| path-params                     |
| path-declarations-must-exist    |
| path-not-include-query          |
| oas3-operation-security-defined |
| typed-enum                      |
| no-eval-in-markdown             |
| no-script-tags-in-markdown      |
| operation-operationId-unique    |

### speakeasy-openapi

The `speakeasy-openapi` ruleset is a minimal set of rules recommended to ensure your OpenAPI document is generally valid and ready to be used by most of the OpenAPI ecosystem.

| Rule ID                         |
| ------------------------------- |
| validate-anyof                  |
| validate-document               |
| validate-json-schema            |
| validate-parameters             |
| validate-requests               |
| validate-responses              |
| validate-composite-schemas      |
| validate-security               |
| validate-servers                |
| validate-types                  |
| validate-paths                  |
| validate-deprecation            |
| validate-consts-defaults        |
| validate-content-type           |
| duplicate-schemas               |
| missing-examples                |
| path-params                     |
| path-declarations-must-exist    |
| path-not-include-query          |
| oas3-operation-security-defined |
| typed-enum                      |
| no-eval-in-markdown             |
| no-script-tags-in-markdown      |
| operation-operationId-unique    |
| operation-success-response      |
| oas3-unused-component           |
| oas3-host-not-example.com       |
| operation-operationId           |
| duplicated-entry-in-enum        |
| operation-tag-defined           |

### vacuum

The `vacuum` ruleset is provided by the [vacuum project](https://github.com/daveshanley/vacuum), which the Speakeasy Linter is built on top of. This set of rules is recommended to ensure your OpenAPI document meets the vacuum quality bar.

| Rule ID                               |
| ------------------------------------- |
| operation-success-response            |
| operation-operationId-unique          |
| operation-operationId                 |
| operation-parameters                  |
| operation-singular-tag                |
| operation-tag-defined                 |
| path-params                           |
| contact-properties                    |
| info-contact                          |
| info-description                      |
| info-license                          |
| license-url                           |
| openapi-tags-alphabetical             |
| openapi-tags                          |
| operation-tags                        |
| operation-description                 |
| component-description                 |
| operation-operationId-valid-in-url    |
| path-declarations-must-exist          |
| path-keys-no-trailing-slash           |
| path-not-include-query                |
| tag-description                       |
| no-$ref-siblings                      |
| oas3-unused-component                 |
| oas2-unused-definition                |
| oas2-api-host                         |
| oas2-api-schemes                      |
| oas2-discriminator                    |
| oas2-host-not-example                 |
| oas3-host-not-example.com             |
| oas2-host-trailing-slash              |
| oas3-host-trailing-slash              |
| oas2-parameter-description            |
| oas3-parameter-description            |
| oas3-operation-security-defined       |
| oas2-operation-security-defined       |
| typed-enum                            |
| duplicated-entry-in-enum              |
| no-eval-in-markdown                   |
| no-script-tags-in-markdown            |
| description-duplication               |
| oas3-api-servers                      |
| oas2-operation-formData-consume-check |
| oas2-anyOf                            |
| oas2-oneOf                            |
| no-ambiguous-paths                    |
| no-http-verbs-in-path                 |
| paths-kebab-case                      |
| operation-4xx-response                |
| oas2-schema                           |
| oas3-schema                           |
| oas3-valid-schema-example             |
| oas3-missing-example                  |
| oas3-example-external-check           |
| oas-schema-check                      |

### owasp

The `owasp` ruleset is recommended to ensure your OpenAPI document meets the [Open Worldwide Application Security Project (OWASP)](https://owasp.org/www-project-api-security/) quality bar.

| Rule ID                                |
| -------------------------------------- |
| owasp-protection-global-unsafe         |
| owasp-protection-global-unsafe-strict  |
| owasp-protection-global-safe           |
| owasp-define-error-responses-401       |
| owasp-define-error-responses-500       |
| owasp-rate-limit                       |
| owasp-rate-limit-retry-after           |
| owasp-define-error-responses-429       |
| owasp-array-limit                      |
| owasp-jwt-best-practices               |
| owasp-auth-insecure-schemes            |
| owasp-no-numeric-ids                   |
| owasp-no-http-basic                    |
| owasp-define-error-validation          |
| owasp-no-api-keys-in-url               |
| owasp-no-credentials-in-url            |
| owasp-string-limit                     |
| owasp-string-restricted                |
| owasp-integer-format                   |
| owasp-integer-limit                    |
| owasp-no-additionalProperties          |
| owasp-constrained-additionalProperties |
| owasp-security-hosts-https-oas3        |


 This is the content for the doc docs/prep-openapi/maintenance.md 

 ---
description: "Learn how Speakeasy can automatically suggest improvements to an OpenAPI document."
title: "Speakeasy Suggest"
---

# Speakeasy Suggest

Maintaining an OpenAPI schema can be time-consuming, is influenced by the idiosyncrasies of the server-side frameworks
used to generate it, and directly affects downstream artifacts like documentation and SDKs. Speakeasy Suggest is an
AI-powered tool that helps you manage the nitty-gritty of creating a great OpenAPI document.

Speakeasy Suggest reduces the burden of perfecting your OpenAPI document by automatically suggesting improvements using
AI. It is the first of many AI-powered features we're developing to make spec maintenance easier.

# Auto-fix with the Speakeasy Studio UI

The easiest way to get automatic suggestions is through the Speakeasy Studio UI. The studio interacts with your local
OpenAPI document and helps you fix issues, manage overlays, regenerate SDKs, and more.

Navigate to the [Speakeasy UI](https://app.speakeasy.dev/) and log in. Go to the **Studio** tab and follow the
instructions there. Alternatively, run `speakeasy run --watch` from the root of your SDK repo to start the Studio UI.

![Speakeasy Studio](../assets/maintenance/studio-ui.png)

## Refine SDK method names

By default, your SDK will use your OpenAPI operation IDs as method names, for example, `pets.getPet()`. However,
operation IDs must be globally unique, preventing your SDK from having a truly "RESTful" interface (`pets.get()`
and `users.get()` would require both operation IDs to be `get`). Speakeasy Suggest automatically adds Speakeasy-flavored extensions to your OpenAPI document to make your SDK's method names consistent, accurate, and idiomatic.

### Use the Studio UI

Follow the instructions above to open the Speakeasy Studio UI. Once there, click the **Improve Method Names** card to
see the suggested fixes. After a few seconds of generating the fixes, you'll see something like the following:

![Studio Method Name Suggestions](../assets/maintenance/method-names-subview.png)

Review the suggested fixes, uncheck any you aren't ready to apply, and click **Apply** to apply the changes to your SDK. Under the hood, this will create
an [overlay file](https://www.speakeasy.com/docs/prep-openapi/overlays/create-overlays) and update your Speakeasy workflow to apply it. Future SDK generations will use the overlay to include the applied changes.

### Use the Speakeasy CLI

Use the [CLI](https://github.com/speakeasy-api/speakeasy) to instruct Speakeasy Suggest to improve operation IDs.

We'll run the following command to generate an example output:

```bash
speakeasy suggest operation-ids -s ~/Downloads/petstore.yaml -o ./updated-petstore.yaml --overlay=false
``` 

The command does the following:

- Provides the `~/Downloads/petstore.yaml` file path of the OpenAPI document to analyze and improve.
- Outputs the suggested fixes to the local file path `./updated-petstore.yaml`.
- Disables the `overlay` output to apply the suggestions to the entire spec in the output file.

Below is the output of the command:
![Speakeasy suggest output](../assets/maintenance/suggest-cli.png)

## Refine SDK error handling

Your SDK's error handling interface is dictated by the granularity and accuracy of the response codes defined for each
operation in your OpenAPI document.
Updating every operation's responses can be tedious and error-prone. Speakeasy Suggest automatically adds common error
codes to your OpenAPI document and groups them into common categories, allowing your users to catch the type of error they care about. For example, `401`, `403`, `407`, and `511` will be
mapped to an `Unauthorized` error type in your SDK.

### Use the Speakeasy CLI

Use the [CLI](https://github.com/speakeasy-api/speakeasy) to instruct Speakeasy Suggest to improve error types.

We'll run the following command to generate an example output:

```bash
speakeasy suggest error-types -s ~/Downloads/petstore.yaml -o ./updated-petstore.yaml --overlay=false
``` 

The command does the following:

- Provides the `~/Downloads/petstore.yaml` file path of the OpenAPI document to analyze and improve.
- Outputs the suggested fixes to the local file path `./updated-petstore.yaml`.
- Disables the `overlay` output to apply the suggestions to the entire spec in the output file.

The document has been updated to include a few new error schemas, two of which are shown below:
![Speakeasy suggest output](../assets/maintenance/error-types-schemas.png)

Meanwhile, each operation has been updated to list the appropriate response codes and their corresponding error types:
![Speakeasy suggest output](../assets/maintenance/error-types-codes.png)

Note that any codes already defined elsewhere in the document will be re-used. For example, if the `403` response code
is already defined with a `CustomUnauthorizedResponse` for one operation, it will be re-used for all operations, giving your users a consistent
experience regardless of the operation they are calling.

### Use the Studio UI

Error type suggestions are not yet available in the Studio UI.

## Disclaimer

AI-powered schema suggestions are still in beta. We strongly recommend you review suggested fixes before applying them
to your OpenAPI document.

We cannot guarantee the accuracy of fixes suggested by Speakeasy Suggest as we're still improving the AI model and
architecture. If you have any feedback, please
join [Speakeasy on Slack](https://join.slack.com/t/speakeasy-dev/shared_invite/zt-1df0lalk5-HCAlpcQiqPw8vGukQWhexw) and
let us know.


 This is the content for the doc docs/prep-openapi/overlays/apply-overlays.mdx 

 ---
slug: "/apply-overlays"
sidebar_label: Apply Overlays
description: "Overlays are patch files which implement changes to your OpenAPI / Swagger spec. With overlays you don't need to update the upstream OpenAPI spec to implement your changes. We explain how they work and show you how to use overlays."
---


# Apply an Overlay

Speakeasy provides two options for applying overlays.
- Option One: add the overlay directly to the Speakeasy workflow file, ensuring it is automatically applied with every generation.
- Option Two: output a new OpenAPI document with the overlay applied, creating an updated source of truth for the OpenAPI specification.

## Option One: Add an Overlay to a Speakeasy Workflow

The Speakeasy workflow supports using an overlay file to modify a source OpenAPI document. For more information on how sources work, see [here](/docs/core-concepts#sources).

### 1. Install the Speakeasy CLI

```bash
brew install speakeasy-api/homebrew-tap/speakeasy
```

### 2. Choose source: 


To add an overlay to the Speakeasy workflow file, run `speakeasy configure sources` and choose or create a source.

<Screenshot variant="cli" docs={true}>![Screenshot of the terminal after running speakeasy configure sources.](./assets/overlays-1.png)</Screenshot>

### 3. Add Overlay:


<Screenshot variant="cli" docs={true}>![Screenshot of the terminal prompting user to add an overlay.](./assets/overlays-2.png)</Screenshot>

### 4. Provide overlay file path:


<Screenshot variant="cli" docs={true}>![Screenshot of the terminal showing a succesful overlay application.](./assets/overlays-3.png)</Screenshot>


### 5. Provide location for the output build: 


<Screenshot variant="cli" docs={true}>![Screenshot of the terminal showing completed setup.](./assets/overlays-4.png)</Screenshot>


The overlay will now be applied to the OpenAPI document as part of the Speakeasy workflow. To execute the workflow, run `speakeasy run`.

## Option Two: Create a new OpenAPI document with an Overlay

This option is ideal for those looking to generate a new source of truth for the OpenAPI document.


### 1. Install the Speakeasy CLI

```bash
brew install speakeasy-api/homebrew-tap/speakeasy
```

### 2. Validate the Overlay

Validate the overlay before applying it to ensure it adheres to the OpenAPI Overlay specification. Use the following command:

```bash
speakeasy overlay validate -o overlays.yaml
```

This command checks the `overlays.yaml` file to confirm that it complies with the OpenAPI Overlay Specification.

### 3. Apply the Overlay

Apply the overlay to the OpenAPI document with the following command, replacing `input-openapi.yaml` with the path to the original OpenAPI spec file and `overlays.yaml` with the path to the overlay file:

```bash
speakeasy overlay apply -s input-openapi.yaml -o overlays.yaml > combined.yaml
```

This command merges the changes from the overlay file with the original OpenAPI specification and outputs the result to a new file named `combined.yaml`.

### 4. Review the Merged Results

The merged results can be viewed in the `combined.yaml` file, which contains the original OpenAPI specification updated with the modifications from the overlay. It is recommended to review this file to ensure the changes have been applied as expected.


 This is the content for the doc docs/prep-openapi/overlays/create-overlays.mdx 

 ---
slug: "/create-overlays"
sidebar_label: Create Overlays
description: "Overlays are a quick and easy way to implement changes to your OpenAPI / Swagger spec. We explain how they work and show you how to use overlays."
---

import { ScrollyCoding } from "~/components/codehike/Scrollycoding";
import { Callout } from "~/components";

# Create Overlays

## What Are Overlays?

The [Overlay Specification](https://github.com/OAI/Overlay-Specification/tree/3f398c6d38ddb5b4e514bc6a5a5ec487a3293834) defines a way to create documents to be merged with an OpenAPI description to update it with additional information.

Overlays are particularly useful in scenarios where the same API specification is used for multiple purposes across different workflows or teams. Instead of making direct changes to the primary spec or needing to manage multiple versions, overlays maintain customizations separately.

These customizations can then be applied to an OpenAPI specification in a new file, ensuring that the API specifications remain flexible and adaptive without altering the core document.

## Common Use Cases

Overlays enable a variety of customizations to API specifications. Common scenarios include:

- [Adding Speakeasy extensions](/examples/sdk-generation/overlays/overlays#adding-speakeasy-extensions): Enhance API specs with custom Speakeasy extensions for additional functionality or metadata.
- [Adding examples to API documentation](/examples/sdk-generation/overlays/overlays#adding-examples-to-api-documentation): Provide clear, concrete examples to clarify API usage.
- [Hiding internal APIs from a public SDK](/examples/sdk-generation/overlays/overlays#hiding-internal-apis-from-a-public-sdk): Exclude internal API endpoints from public-facing SDK documentation for security and clarity.

[View more examples here](/examples/sdk-generation/overlays/overlays).

## Creating an Overlay

Create an overlay by creating a new YAML document that details the specific alterations to make to the OpenAPI specification.

With Speakeasy, create overlays manually or automatically.

For a quick generation of differences between two API versions, use the `compare` command in the [Speakeasy CLI](/docs/speakeasy-reference/cli/overlay/compare).

```bash
speakeasy overlay compare --before=./openapi_original.yaml --after=./openapi.yaml > overlay.yaml
```

<Callout title="Using compare" variant="info">
  The compare feature is designed to assist in identifying differences across
  OpenAPI documents. However, users requiring precise adjustments may need to
  manually edit the generated overlay file to suit their needs. You can validate
  and evaluate your JSONPath expressions [here](https://jsonpath.com/).
</Callout>

## Anatomy of an Overlay

<ScrollyCoding>

#### !!steps `overlay`

**Required:** Specifies the Overlay Specification version used by the document, currently limited to 1.0.0.

```yaml ! overlay.yaml
# !focus(1)
overlay: 1.0.0
info:
  title: Overlay to fix the Speakeasy bar
  version: 0.0.1
actions:
  - target: "$.tags"
    description: Add a Snacks tag to the global tags list
    update:
      - name: Snacks
        description: All methods related to serving snacks
  - target: "$.paths['/dinner']"
    description: Remove all paths related to serving dinner
    remove: true
```

---

#### !!steps `info`

- `title` **Required**: Describes the overlay's purpose.
- `version` **Required**: Identifies the document's version.

```yaml ! overlay.yaml
# !focus(2:4)
```

---

#### !!steps `actions`

**Required:** An array of ordered actions for the target document, with at least one object per action.

```yaml ! overlay.yaml
# !focus(5:13)
```

---

#### !!steps `target`

**Required:** Specifies a JSONPath query expression to identify the target objects in the target document.

```yaml ! overlay.yaml
# !focus(6)
```

---

#### !!steps `description`

**Optional:** Brief explanation of the action being performed. Supports CommonMark syntax for rich text representation.

```yaml ! overlay.yaml
# !focus(7)
```

---

#### !!steps `update`

**Optional:** Defines the properties and values to be merged with the objects identified by the target. This property is disregarded if the `remove` property is set to `true`.

```yaml ! overlay.yaml
# !focus(8:10)
```

---

#### !!steps `remove`

**Optional:** A boolean value indicating whether the target object should be removed from its map or array. Defaults to `false` if not specified.

```yaml ! overlay.yaml
# !focus(13)
```

---

</ScrollyCoding>

## Helpful references:

- [Common Overlay Examples](/examples/sdk-generation/overlays/overlays)
- [Common JSON Path Examples](/examples/sdk-generation/overlays/overlays)

<Callout title="Try Overlay Speakeasy" variant="info">
  For a visual approach to creating or editing your overlays, visit <a href="https://overlay.speakeasy.com/" target="_blank" rel="noopener noreferrer">overlay.speakeasy.com</a>.
</Callout>


 This is the content for the doc docs/prep-openapi/transformations.mdx 

 ---
title: "Transformations"
description: "Transformations are predefined functions in your Speakeasy workflow that can be applied to an OpenAPI document to change its structure."
---

import { ScrollyCoding } from "~/components/codehike/Scrollycoding";

# Transformations

Transformations are predefined functions that can be applied to an OpenAPI document to change its structure.

Speakeasy currently supports the following transformations:

- **Remove unused components:** Removes components that are not referenced by any operation.
- **Filter operations:** Filters operations down to a user-defined set of operation IDs.
- **Cleanup:** Reformats the document to be more readable and compliant with various parsing tools.
- **Format:** Changes the order of keys at various levels in the document to be more human-readable.
- **Convert Swagger to OpenAPI:** Converts a Swagger 2.0 document to an OpenAPI 3.0.x document.

## Transformations vs. overlays

Transformations and overlays are similar in that they both allow you to modify an OpenAPI document. However, there are some key differences between the two:

- **Transformations** are dynamic and will account for any changes to the underlying document. In this way, they are "always up to date". For example,
if your OpenAPI document updates and a previously unused component becomes used by a newly-added operation, the `removeUnused` transformation will no longer remove it.
- **Overlays** are more flexible and can change almost any document into any other document. However, unlike transformations, overlays are static and do not evolve with the underlying document.
Taking the example of removing an unused component, an overlay will continue to remove it even if the underlying document changes and the component becomes used.


## Using transformations

Speakeasy provides two ways to apply transformations to an OpenAPI document.

1. [Using the CLI](#using-the-cli). This is the easiest and most flexible way to apply transformations to an OpenAPI document.
2. [As part of your Speakeasy workflow](#in-workflow-files). This is the most powerful way to apply transformations, but requires a bit more setup.

### Using the CLI

To apply a transformation to an OpenAPI document, use the `speakeasy openapi transform` command. The interactive CLI will walk you through the rest. Here are a few example commands:

- `speakeasy openapi transform remove-unused -s openapi.yaml`
- `speakeasy openapi transform filter-operations -s openapi.yaml --operations=getPets,createPet`
- `speakeasy openapi transform cleanup -s openapi.yaml`
- `speakeasy openapi transform format -s openapi.yaml`
- `speakeasy openapi transform convert-swagger -s swagger.yaml`

### In workflow files

The real utility of transformations comes when you use them in your `workflow.yaml` file. This allows your OpenAPI document to be always up to date with the desired transformations, but requires a bit more setup.

The `convert-swagger` transformation is an exception, as it cannot be applied as part of a workflow.

<ScrollyCoding>
### !!steps Remove unused components

Remove unused components from the OpenAPI document, preventing them from being included in the generated SDK.

```yaml ! workflow.yaml
# !focus(8)
workflowVersion: 1.0.0
speakeasyVersion: latest
sources:
  my-source:
    inputs:
      - location: ./openapi.yaml
    transformations:
      - removeUnused: true
      - filterOperations:
          operations: getPets, createPet
          include: true
      - cleanup: true
      - format: true
```

---
### !!steps Filter operations

Keep or remove the specified operations from the OpenAPI document.

```yaml ! workflow.yaml
# !focus(9:11)
workflowVersion: 1.0.0
speakeasyVersion: latest
sources:
  my-source:
    inputs:
      - location: ./openapi.yaml
    transformations:
      - removeUnused: true
      - filterOperations:
          operations: getPets, createPet
          include: true # exclude: true
      - cleanup: true
      - format: true
```

---
### !!steps Cleanup

Clean up the OpenAPI document, making it more readable and compliant with various parsing tools.

```yaml ! workflow.yaml
# !focus(12)
workflowVersion: 1.0.0
speakeasyVersion: latest
sources:
  my-source:
    inputs:
      - location: ./openapi.yaml
    transformations:
      - removeUnused: true
      - filterOperations:
          operations: getPets, createPet
          include: true
      - cleanup: true
      - format: true
```

---
### !!steps Format

Changes the order of keys at various levels in the document, formatting it to be more human-readable.

```yaml ! workflow.yaml
# !focus(13)
workflowVersion: 1.0.0
speakeasyVersion: latest
sources:
  my-source:
    inputs:
      - location: ./openapi.yaml
    transformations:
      - removeUnused: true
      - filterOperations:
          operations: getPets, createPet
          include: true
      - cleanup: true
      - format: true
```

---

</ScrollyCoding>


 This is the content for the doc docs/privacy-policy.mdx 

 ---
title: Privacy policy
description: "Your privacy is important to us. Here's our policy on how we collect, use & share information through our services."
---

# Privacy Policy

Your privacy is important to us. This Privacy Policy explains our practices regarding the collection, use and disclosure of information that we receive through our Services. This Privacy Policy does not apply to any third-party websites, services or applications, even if they are accessible through our Services.

In this Privacy Policy:

- We’ll refer to our website as the “Site”.
- We’ll refer to all the products and services we provide, individually and collectively, as the “Services”.
- We’ll refer to you, the person or entity accessing our Site or using our Services, as “you” or “your” or (if you are a purchaser of our Services), our “customer”.

## Definitions

Data Controller: For general data protection regulation purposes, the “Data Controller” means the organization who decides the purposes for which, and the way in which, any Personal Information is processed. Our customers are the Data Controllers.

Data Processor: A “Data Processor” is an organization which processes Personal Information for a Data Controller. We are the Data Processor for our customers. As a Data Processor, we are bound by the requirements of the General Data Protection Regulations (the “GDPR”).

Data Processing: Data processing is any operation or set of operations (whether automated or not) performed upon Personal Information. Examples of data processing explicitly listed in the text of the GDPR are: collection, recording, organizing, structuring, storing, adapting, altering, retrieving, consulting, using, disclosing by transmission, disseminating or making available, aligning or combining, restricting, erasure or destruction.

Personal Information: Personal information is any information which is about you, from which you can be identified. Personal Information includes information such as an individual's name, address, telephone number, or e-mail address. Personal Information also includes information about an individual's activities, such as information about his or her activity on Site or our Services, and demographic information, such as date of birth, gender, geographic area, and preferences, when any of this information is linked to personal information that identifies that individual. Personal Information does not include "aggregate" or other non-personally identifiable information. Aggregate information is information that we collect about a group or category of products, services, or users that is not personally identifiable or from which individual identities are removed.

## How do we collect Personal Information?

In our service as a Data Processor, we collect Personal Information from Data Controllers in several ways:

- Information you provide to us directly.
- Information we may receive from third parties.
- We may receive information about you, including Personal information, from other third parties, and may combine this information with other personal information we maintain about you. If we do so, this Privacy Policy governs any combined information that we maintain in personally identifiable format.

## What information do we collect?

We may collect the following types of personal information from you:

- Your first and last name, username and email address.
- Your company’s name.
- Your (and/or your company’s) physical address.
- Information you choose to provide us through our Services (including, for example, your birthdate and/or phone number).
- We may collect information you post to, or collect from, users of the Services. We use this information to operate, maintain, and provide to you the features and functionality of the Services.
- We may also collect and aggregate information about the use of our Site and our Services. That information includes browser and device data, such as IP address, device type, screen resolution, browser type, operating system name and version, language, as well as add-ons for your browser. The information may also include usage data, including the pages visited on and links clicked on our Site, the time spent on those pages, and the pages that led or referred you to our Site.
- We may also permit third-party online advertising networks to collect information (through Cookies or similar tracking technology) about your and others’ use of our Services and any of your mobile or web applications, in order to allow those third-party networks to display ads that may be relevant to your interests on our Services as well as on other websites or apps.

## What do we use your Personal Information for?

We will use your Personal Information, in compliance with this Privacy Policy, to help us deliver the Services to you. Any of the information we collect from you may be used in the following ways:

- To operate, maintain, and provide to you the features and functionality of the Services.
- To compile statistics and analysis about use of our Site and our Services.
- To personalize your experience.
- To improve our Site and our Services — we continually strive to improve our site offerings based on the information and feedback we receive from you.
- To improve customer service — your Personal Information helps us to more effectively respond to your customer service requests and support needs.
- To send periodic emails — The email address you provide may be used to send you information, notifications that you request about changes to our Services, to alert you of updates, and to send periodic emails containing information relevant to your account.
- If you purchase our Services, then to enable you to purchase, renew and appropriately use a commercial license to our Services.
- We may also use Personal Information you provide to send you email marketing about Speakeasy products and services, invite you to participate in events or surveys, or otherwise communicate with you for marketing purposes. We allow you to opt-out from receiving marketing communications from us as described in the "Your Choices" section below.

We may also use your Personal Information where necessary for us to comply with a legal obligation, including to share information with government and regulatory authorities when required by law or in response to legal process, obligation, or request.

We cooperate with government and law enforcement officials or private parties to enforce and comply with the law. We may disclose your Personal Information to government or law enforcement officials or private parties as we believe necessary or appropriate: (i) to respond to claims, legal process (including subpoenas); (ii) to protect our property, rights and safety and the property, rights and safety of a third party or the public in general; and (iii) to stop any activity that we consider illegal, unethical or legally actionable activity.

We will request your consent before we use or disclose your Personal Information for a materially different purpose than those set forth in this Policy.

## Your Choices About Your Personal Information

We may use the information we collect or receive to communicate directly with you. We may send email marketing communications about Speakeasy. If you do not want to receive such email messages, you will be given the option to opt out. We will try to comply with your request(s) as soon as reasonably practical. Additionally, even after you opt out from receiving marketing messages from us, you will continue to receive administrative messages from us regarding our Services (e.g., account verification, purchase and billing confirmations and reminders, changes/updates to features of the Service, technical and security notices).

In addition, you may opt out of allowing third-party online advertising networks to collect information from our Site by adjusting the browser settings on your computer or mobile device. Please refer to your mobile device or browser’s technical information for instructions on how to delete and disable cookies, and other tracking tools.

## Protection of Personal Information

Speakeasy cares about the security of your Personal Information, and we make reasonable efforts to ensure a level of security appropriate to the risk associated with the processing of your Personal Information. We maintain organizational, technical, and administrative procedures designed to protect your Personal Information against unauthorized access, deletion, loss, alteration, and misuse. Unfortunately, no data transmission or storage system can be guaranteed to be 100% secure. If you believe that your interaction with us is not secure, please contact us immediately.

You are responsible for maintaining the secrecy of your unique password and account information, and for controlling access to your email communications from Speakeasy. Your privacy settings may also be affected by changes to the functionality of third-party sites and services that you add to the Speakeasy Service, such as single sign on. Speakeasy is not responsible for the functionality or security measures of any third party. Upon becoming aware of a breach of your Personal Information, we will notify you as quickly as we can and will provide timely information relating to the breach as it becomes known in accordance with any applicable laws and regulations or as is reasonably requested by you.

## Cookies

We use cookies to remember information so that you don’t have to re-enter it during your visit or the next time you visit the Site, to understand and save your preferences for future visits, to compile aggregate data about site traffic and site interaction, to provide custom, personalized content, support, or information, including advertising. Unlike persistent Cookies, session Cookies are deleted when you log off from the Services and close your browser. Although most browsers automatically accept Cookies, you can change your browser options to stop automatically accepting Cookies or to prompt you before accepting Cookies. Please note, however, that if you don’t accept Cookies, you may not be able to access all portions or features of the Site or the Services. At present, there is no industry standard for recognizing Do Not Track browser signals, so we do not currently respond to them.

## Who at Speakeasy may access your Personal Information?

Designated members of our staff may access Personal Information to help our customers with any questions they have, including help using our Services, investigating security issues, or following up on bug fixes with a customer. This activity is logged in our system for compliance, and we maintain different levels of access for its employees depending on their role in our company.

## Do we disclose any information to outside parties?

Except as set out below, we do not sell, trade, or otherwise transfer to outside parties your Personal Information.

- We may share your Personal Information with other companies owned by or under common ownership as Speakeasy, which also includes our subsidiaries (i.e., any organization we own or control).
- These companies will use your Personal Information in the same way as we can under this Privacy Policy, unless otherwise specified.
- We may disclose your Personal Information to third-party service providers (for example, payment processing and data storage and processing facilities) that we use to provide the Services.
- We limit the Personal Information provided to these service providers to that which is reasonably necessary for them to perform their functions, and we require them to agree to maintain the confidentiality of such Personal Information.
- We may contract with third-party service providers to assist us in better understanding our Site visitors.
- These service providers are not permitted to use the information collected on our behalf except to help us conduct and improve our business.
- We may also release your Personal Information when we believe release is appropriate to comply with the law, enforce our site policies, or protect our or others’ rights, property, or safety.
- In particular, we may release your Personal Information to third parties as required to (i) satisfy any applicable law, regulation, subpoena/court order, legal process or other government request, (ii) enforce our Terms of Service, including the investigation of potential violations thereof, (iii) investigate and defend ourselves against any third party claims or allegations, (iv) protect against harm to the rights, property or safety of Speakeasy, its users or the public as required or permitted by law and (v) detect, prevent or otherwise address criminal (including fraud or stalking), security or technical issues.
- If you enable a public sharing of your Speakeasy applications, any information or content that you voluntarily disclose in your application becomes available to the public. If you remove information that you posted to the Services, copies may remain viewable in cached and archived pages of the Service, or if other users of the Services have copied or saved that information.
- In the event that we enter into, or intend to enter into, a transaction that alters the structure of our business, such as a merger, reorganization, joint venture, assignment, sale, or change of ownership, we may share Personal Information for the purpose of facilitating and completing the transaction.

## How do we handle global transfers and processing of your Personal Information?

Personal Information may be stored and processed in any country where we have operations, or where we engage service providers. This means that we may collect your Personal Information from, transfer it to, and store and process it in the United States and other countries outside of where you live. For example, some of our third-party providers may be located in different countries. Where this is the case, we will take steps to make sure the right security measures are taken so that your privacy rights continue to be protected as outlined in this Privacy Policy. By submitting your Personal Information, you’re agreeing to this transfer, storing or processing.

If you are located in the European Union or other regions with laws governing data collection and use that may differ from U.S. law, please note that we may transfer information, including Personal Information, to a country and jurisdiction that does not have the same data protection laws as your jurisdiction. If we transfer your Personal Information from the E.U. and process it in the United States, we do so in accordance with applicable law. In certain situations, we may be required to disclose personal information in response to lawful requests by public authorities, including to meet national security or law enforcement requirements.

## Retention of your Personal Information

We retain your Personal Information for as long as we need to fulfill our Services. In addition, we retain Personal Information after we cease providing Services to you, to the extent necessary to comply with our legal obligations. Where we retain data, we do so in accordance with any limitation periods and records retention obligations that are imposed by applicable law.

## Third-party Links

The Services may provide the ability to connect to other websites. These websites may operate independently from us and have their own privacy policies and notices, which we suggest you review. If the linked website is not owned or controlled by us, we are not responsible for its content, or the privacy practices

## Your Consent

By using our site, you consent to this Privacy Policy.

## Minors

These Services are not directed to individuals under the age of thirteen, and we kindly request they not provide any Personal Information through the Services.

## Your Rights

Other rights you have include the rights to:

- Ask for a copy of your Personal Information
- Ask us to correct your Personal Information that is inaccurate, incomplete, or outdated
- Ask us to transfer your Personal Information to other organizations.
- Ask us to erase certain categories or types of information
- If you choose to remove your Personal Information, you acknowledge that we may retain archived copies of your Personal Information in order to satisfy our legal obligations, or where we reasonably believe that we have a legitimate reason to do so.
- Ask us to restrict certain processing
- You have the right to object to processing of Personal Information. Where we have asked for your consent to process information, you have the right to withdraw this consent at any time.

## Changes to our Privacy Policy

If we decide to change our privacy policy, we will post those changes on this page. If we are going to use Personal Data collected through the Site in a manner materially different from that stated at the time of collection, then we will notify users via email and/or by posting a notice on our Site for 30 days prior to such use or by other means as required by law.

## Jurisdiction-specific Provisions

- Residents of the European Economic Area and Switzerland: The Data Protection Officer can be contacted at [info@speakeasy.com](mailto:info@speakeasy.com).

## Contacting Us

If you would like to submit a data rights request (also known as a data subject access request), or have any other questions, comments, or concerns about this privacy policy, please contact us using the following contact information: [info@speakeasy.com](mailto:info@speakeasy.com).


 This is the content for the doc docs/product-security.mdx 

 ---
title: Security and data privacy
description: "Speakeasy prioritizes security and privacy as core development principles."
---

import { Callout } from "~/components";

# Security and Data Privacy

The Speakeasy platform is built with security and privacy as core development principles. Using your company's API specifications, the Speakeasy platform creates high-quality code hosted on GitHub. 

The following sections detail our privacy and security policy for all artifacts generated and maintained through Speakeasy, such as SDKs, as well as key information regarding security features like permissions and access.

## FAQ

[Do I need to install something?](#do-i-need-to-install-something)  
[Does the Speakeasy platform access my API or customer data in any way?](#does-the-speakeasy-platform-access-my-api-or-customer-data-in-any-way)  
[What information about my company or users does Speakeasy have access to?](#what-information-about-my-company-or-users-does-speakeasy-have-access-to)  
[How does the Speakeasy service work?](#how-does-the-speakeasy-service-work)  
[Do I need to log in to the Speakeasy platform to use the service?](#do-i-need-to-log-in-to-the-speakeasy-platform-to-use-the-service)  
[Can Speakeasy be run in an air-gapped environment?](#can-speakeasy-be-run-in-an-air-gapped-environment)  
[Does Speakeasy store package manager secrets?](#does-speakeasy-store-package-manager-secrets)  
[What are Speakeasy's data storage policies?](#what-are-speakeasy-s-data-storage-policies)  

### Do I need to install something?

The [Speakeasy CLI](https://github.com/speakeasy-api/speakeasy) facilitates the creation of SDKs, Terraform providers, Postman collections, and documentation.

Written in Go and fully [open source](https://opensource.org), the CLI is compiled into binaries for easy customer use.

Typically, the CLI is used within a customer's CI/CD ("continuous integration/continuous deployment") workflow as part of the standard engineering and development flow. For most customers, this means installing the CLI as a GitHub action in GitHub. If a customer doesn't use GitHub, the CLI can be installed in whichever system, servers, or cloud environment the customer uses.

### Does the Speakeasy platform access my API or customer data in any way?

Speakeasy does not sit in the API call chain. Therefore, the Speakeasy platform **does not have access to** or store your customer data or API request data in any form.

### What information about my company or users does Speakeasy have access to?

Speakeasy has very little access to data about your employees and users.

For user authorization purposes, Speakeasy stores user login email addresses. Speakeasy also stores limited service usage data, for example, when an SDK generation is run.

### How does the Speakeasy service work?

Speakeasy is shipped as a [verified GitHub Action](https://github.com/marketplace/actions/speakeasy-sdk-workflow-runner-action) and runs in your GitHub environment (either in the cloud or on-prem). The GitHub Action accesses your company's API specification, which is a static file describing the API contract, but this specification is not sent to Speakeasy.

It's worth noting that this API specification is often made public and/or sent to third-party vendors to generate API documentation.

### Do I need to log in to the Speakeasy platform to use the service?

Yes, using the Speakeasy platform requires logging in through one of our supported authentication providers. However, this is only to request an API key (referred to in documentation as a `SPEAKEASY_API_KEY`). Once that key is obtained and stored, all features of the platform can be accessed directly through the command line interface (CLI).

### Can Speakeasy be run in an air-gapped environment?

Yes. Sending metadata on usage to Speakeasy can be disabled on request. Please reach out to info@speakeasy.com for more information.

### Does Speakeasy store package manager secrets?

No, Speakeasy does not store any package manager secrets. Speakeasy uses these secrets to publish SDKs on your behalf. Package manager secrets are stored as secrets on your GitHub repository and are only viewable to members of your GitHub organization. Publishing to package managers using
Speakeasy is optional.

### What are Speakeasy's data storage policies?

**Speakeasy stores:**
* Email addresses used to log in to the Speakeasy platform.
* Metadata on SDK generation runs, specifically, when an SDK is generated, the language it is generated in, the version of the specification used, the time it is generated, and error details if any occur.
* Point-in-time snapshots of API specifications to compare changes in the API specification over time.



**Speakeasy DOES NOT store:**
* Any customer-generated code, unless specifically configured in a Speakeasy-hosted repository.

## Customer-Hosted Repositories

<Callout title="Note" variant="info">
  The following guidance refers to artifacts hosted in the Speakeasy GitHub organization, `speakeasy-sdks`, on behalf of the
  customer.
</Callout>

A Speakeasy-created artifact (like an SDK) can be hosted on GitHub in a repository in your GitHub organization (for example, `www.github.com/yourcompany/sdk`).

The Speakeasy service is provided through a CLI that is distributed as a Go binary and accessible through various package managers like Homebrew and Chocolatey. 

Speakeasy generates code in one of two ways:

1. Locally, using the Speakeasy CLI on a developer's machine.
2. On infrastructure connected to your organization's GitHub account, using "GitHub Runners".

Artifacts created in either of these ways will require certain permissions to be granted to Speakeasy workflows on your GitHub repository. These permissions are self-documenting in GitHub workflow files, as illustrated [here](https://github.com/speakeasy-sdks/template-sdk/blob/main/.github/workflows/speakeasy_sdk_generation.yml).

The following snippet is from the GitHub workflow file that Speakeasy creates and maintains in your SDK repository:

```yaml
permissions:
  checks: write
  contents: write
  pull-requests: write
  statuses: write
```

Here, Speakeasy requests `write` permission on `checks`, `contents`, `pull-requests`, and `statuses` in your repository. Speakeasy will respect any permissions inherited from the top-level settings of the GitHub organization.

## Speakeasy-Hosted Repositories

<Callout title="Note" variant="info">
  The following guidance refers to artifacts hosted on behalf of the
  customer in the Speakeasy GitHub organization, `speakeasy-sdks`.
</Callout>

Speakeasy-hosted artifacts are created in the [`https://github.com/speakeasy-sdks` GitHub organization](https://github.com/speakeasy-sdks) owned by Speakeasy and follow the same set of security guidelines and permissions as customer-hosted artifacts. 

## Code Security and Privacy

### CLI Events

The Speakeasy CLI submits events to the Speakeasy platform to monitor errors, usage, and other telemetry data. This data is used to track and resolve issues, identify trends, and improve the Speakeasy platform.

The CLI commands that currently send telemetry data are `speakeasy run` and `speakeasy generate`. The data points these commands send are:

| Data Point | Description |
| -------- | -------- |
| `CustomerID` | A unique string identifying a specific customer account|
| `WorkspaceID` | A unique string identifying a specific customer workspace|
| `Language` | The name of the target language, for example, `go`, `python`, or `typescript`|
| `Template` | The name of the template folder to use for the target, for example, `go`, `typescriptv2`, or `javav2`|
| `RunLocation` | Whether the generation runs in a terminal (`cli`) or GitHub action (`action`)|
| `GenVersion` | The specific generator version used|
| `CLIVersion` | The specific CLI version used|
| `FeatureTracking`| A list of features the generator does or does not use|
| `ConfigTracking` | A list of configuration values the generator uses|
| `GenIgnoreUsed` | Whether or not a generation action uses a `.genignore` file, read more in the [`.genignore` docs](/docs/customize/code/monkey-patching#mark-files-with-genignore)|

### Third-Party Dependencies

- Third-party code dependencies - All Speakeasy-created SDKs use minimal to no third-party dependencies. Please see the [language-specific design pages](/docs/languages/philosophy) for more information.
- All tokens stored as GitHub secrets - Publishing tokens, such as those used for npm or PyPI, are stored as [GitHub Actions secrets](https://docs.github.com/en/rest/actions/secrets). The Speakeasy GitHub workflows use these tokens to publish SDK packages to package managers on behalf of the customer, but will never export or have plain text access to these tokens.

### Code Ownership

- All code generated by Speakeasy is owned by the customer. Speakeasy licenses code with the [open-source MIT License](https://opensource.org/license/mit/) by default. The license can be altered by the owner of the SDK at any time after generation.
- Authentication with the Speakeasy platform - When the Speakeasy code generator is invoked, it authenticates with the Speakeasy platform using a GitHub secret named `SPEAKEASY_API_KEY`. This is an opaque token that authenticates each generation run with a workspace in the platform, enabling Speakeasy to collect metadata on generations on a per-customer basis. Metadata does not include generated code or the raw API specification.

## Found a Bug or Vulnerability?

Think you may have found a security bug? We'd be happy to work with you to explore and resolve the issue -- and ensure you are fairly rewarded. Rewards will be based on severity, per CVSS ([Common Vulnerability Scoring Standard](https://docs.hackerone.com/hackers/severity.html?)). Get in touch with us at bugs@speakeasy.com to learn more.

## Questions?

Please don't hesitate to reach out to us at info@speakeasy.com for any questions you have about the information contained on this page.


 This is the content for the doc docs/publish-sdk.mdx 

 ---
title: Publish SDKs
description: "Learn how to publish your Speakeasy-generated SDK to popular package managers like npm, PyPI, and Maven."
position: 2
---

import { Callout, Screenshot } from '~/components'

# Publish SDKs

## Prerequisites

- The Speakeasy CLI
- Speakeasy generated SDKs
- Access tokens or credentials for target package managers

## Supported package managers

| Language   | Package Manager | Prerequisites                                                                                                                                                   | Notes                                                                                                          |
|------------|-----------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------|
| TypeScript | npm             | [Access tokens](https://docs.npmjs.com/creating-and-viewing-access-tokens)                                                                                        | Create an access token of type `Automation`.                                                                   |
| Python     | PyPI            | [API tokens](https://pypi.org/help/#apitoken)                                                                                                                     |                                                                                                                |
| Go         | GitHub          | [Repo visibility](https://docs.github.com/en/repositories/managing-your-repositorys-settings-and-features/managing-repository-settings/setting-repository-visibility) | For private repos, add the [Speakeasy app](https://github.com/marketplace/speakeasy-api).                      |
| Java       | Maven           | [Get started with Maven Central](https://central.sonatype.org/publish-ea/publish-ea-guide/) and [verify domain ownership](https://central.sonatype.org/faq/verify-ownership/) |                                                                                                                |
| PHP        | Packagist       | [See publishing packages](https://packagist.org/)                                                                                                                 | Monorepo setups not permitted.                                                                                 |
| C#         | NuGet           | [API key](https://learn.microsoft.com/en-us/nuget/nuget-org/publish-a-package#create-an-api-key)                                                                  |                                                                                                                |
| Terraform  | Terraform       | [GPG Key](https://developer.hashicorp.com/terraform/registry/providers/publishing#preparing-and-adding-a-signing-key)                                             |                                                                                                                |


## Naming packages

| Language   | Package Manager | Example Package          | Naming Conventions               |
|------------|-----------------|--------------------------|----------------------------------|
| TypeScript | npm             | @npm-org/package-name    | Lower case, hyphen separated     |
| Python     | PyPI            | package_name             | Lower case, underscore separated |
| Go         | GitHub          | github.com/org/repo-name | Lower case, hyphen separated     |
| Java       | Maven           | packageName              | Camel case                       |
| PHP        | Packagist       | org/package-name         | Lower case, hyphen separated     |
| C#         | NuGet           | PackageName              | Pascal case, period separated    |
| Terraform  | Terraform       | terraform-provider-name  | Lower case, hyphen separated     |

<Callout title="TIP" variant="success">
For global package managers like PyPI and Maven, ensure the package name is unique.
</Callout>

## Publishing packages

### 1. Start publishing configuration 

```bash
speakeasy configure publishing
```

Select the existing SDK targets to configure publishing. If no SDK targets are available, run `speakeasy configure targets` first.

<Screenshot variant="cli" docs={true}>![Screenshot of the terminal after running Speakeasy configure publishing.](./assets/publish-sdks/configure-publishing.png)</Screenshot>

### 2. Provide publishing credentials

Default input environment variables for publishing are provided.

<Screenshot variant="cli" docs={true}>![Screenshot of the terminal prompting the user for an NPM token.](./assets/publish-sdks/configure-token.png)</Screenshot>

### 3. Verify configuration files

Once configuration is complete, the following files will be generated or updated:

- `.speakeasy/workflow.yaml` – Speakeasy workflow configuration.
- `.github/workflows/sdk_generation.yaml`  – GitHub Action to generate SDKs.
- `.github/workflows/sdk_publish.yaml` – GitHub Action to publish SDKs.

<Screenshot variant="cli" docs={true}>![Screenshot of the terminal after succesfully running Speakeasy configure publishing.](./assets/publish-sdks/publishing-success.png)</Screenshot>

### 4. Set up repository secrets

1. Navigate to GitHub repository **Settings > Secrets & Variables > Actions**.
2. Click **New repository secret**.
3. Add `SPEAKEASY_API_KEY` (if needed) and any other required tokens (e.g., `NPM_TOKEN`).

### 5. Push changes and verify

Commit and push the updated workflow files. Once your generated SDK has been pushed to GitHub, you can manually kick off publishing for your first version.

<Screenshot variant="cli" docs={true}>![Screenshot of manually kicking off publishing in Github Actions.](./assets/publish-sdks/publishing-dispatch.png)</Screenshot>

### 6. Complete language-specific configuration

Java and C# require additional setup after running `speakeasy configure publishing`.

#### Java Maven: Sonatype Central Portal (recommended)

For legacy OSSRH publishing support, see the next section.

1. Create a [Sonatype Central Portal account](https://central.sonatype.org/register/central-portal/) (if needed).
2. Generate a [Sonatype username and password for authentication](https://central.sonatype.org/publish/generate-portal-token/). Save these for step 5.
3. Create a [Sonatype namespace](https://central.sonatype.org/register/central-portal/#choosing-a-namespace).
4. Create a GPG key to [sign the artifacts](https://central.sonatype.org/publish/requirements/gpg/). Save these for step 5.
    - Install GnuPG: `brew install gnupg`
    - Generate a key: `gpg --gen-key`. Note the key ID (e.g., `CA925CD6C9E8D064FF05B4728190C4130ABA0F98`) and short ID (e.g., `0ABA0F98`).
    - Send the key: `gpg --keyserver keys.openpgp.org --send-keys <your_keyId>`
    - Export the secret key: `gpg --export-secret-keys --armor <your_shortId> > secret_key.asc`
    - The file `secret_key.asc` will contain the GPG secret key.
5. Store the following secrets Github actions secrets: 
    - `OSSRH_USERNAME` (the Sonatype username generated in Step 2)
    - `OSSRH_PASSWORD` (the corresponding password/token generated in Step 2)
    - `GPG_SECRET_KEY` (the exported GPG key)
    - `GPG_PASSPHRASE` (the passphrase for your GPG key)
6. In the java section of `gen.yaml`,  provide the additional configuration required for publishing to Maven:
```yaml
    java:
        #ensure the `groupID` matches the OSSRH org
        groupID: com.example
        #ensure the `artificatID` matches the artifact name:
        artifactID: example-sdk
        githubURL: github.com/org/repo
        companyName: My Company
        companyURL: https://www.mycompany.com
        companyEmail: info@mycompany.com
```

#### Java Maven: Sonatype legacy OSSRH

1. Create an [OSSRH staging repository](https://central.sonatype.org/publish/publish-guide/).
2. Create a GPG key to [sign the artifacts](https://central.sonatype.org/publish/requirements/gpg/). Save these for step 3.
    - Install GnuPG: `brew install gnupg`
    - Generate a key: `gpg --gen-key`. Note the key ID (e.g., `CA925CD6C9E8D064FF05B4728190C4130ABA0F98`) and short ID (e.g., `0ABA0F98`).
    - Send the key: `gpg --keyserver keys.openpgp.org --send-keys <your_keyId>`
    - Export the secret key: `gpg --export-secret-keys --armor <your_shortId> > secret_key.asc`
    - The file `secret_key.asc` will contain the GPG secret key.
3. Store the following secrets Github actions secrets: 
    - `OSSRH_USERNAME` 
    - `OSSRH_PASSWORD`
    - `GPG_SECRET_KEY`
    - `GPG_PASSPHRASE`
4. In the [Speakeasy workflow file](/docs/workflow-file-reference), add `useSonatypeLegacy: true`:
```yaml
workflowVersion: 1.0.0
speakeasyVersion: latest
sources:
    my_source.yaml:
        inputs:
            - location: my_source.yaml
targets:
    java:
        target: java
        source: my_source.yaml
        publish:
            java:
                #add useSonatypeLegacy: true
                useSonatypeLegacy: true
                ossrhUsername: test
                ossrhPassword: $ossrh_password
                gpgSecretKey: $java_gpg_secret_key
                gpgPassPhrase: $java_gpg_passphrase
```
5. In the java section of `gen.yaml`,  provide the additional configuration required for publishing to Sonatype legacy:
```yaml
    java:
        #ensure the `groupID` matches the OSSRH org
        groupID: com.example
        #ensure the `artificatID` matches the artifact name:
        artifactID: example-sdk
        ossrhURL: https://s01.oss.sonatype.org/service/local/staging/deploy/maven2/
        githubURL: github.com/org/repo
        companyName: My Company
        companyURL: https://www.mycompany.com
        companyEmail: info@mycompany.com
```

#### C# NuGet

1. Create a [NuGet](https://www.nuget.org) account.
2. Create a NuGet API key:
   - Set the **Package Owner** field to the user or organization that will "own" the SDK artifact.
   - Ensure the API key has the relevant **Push** scope. If the package already exists, the API key may not need "Push new packages and package versions" permissions.
   - Populate the **Glob Pattern** and **Available Packages** fields in a way that allows publishing the SDK. Use the `packageName` specified in the `gen.yaml` file.
3. Store the `NUGET_API_KEY` in the GitHub Actions secrets.
4. In the C# section of `gen.yaml` add:
    ```yaml
        csharp:
            packageName: MyPackageName # Ensure this matches the desired NuGet package ID
            packageTags: sdk api client # Provide space-separated tags for searching on NuGet
            enableSourceLink: true # Enables publishing with Source Link for better debugging
            includeDebugSymbols: true # Includes .pdb files for publishing a symbol package (.snupkg)
    ```
5. In the `info` section of the OpenAPI document, describe what the package is for in the `description` property. It will be set as the [Package description](https://learn.microsoft.com/en-us/nuget/create-packages/package-authoring-best-practices#description), visible when searching for the package on NuGet.
    ```yaml
    openapi: 3.1.0
    info:
      description: This description will be visible when searching for the package on NuGet.
    ```
6. In the `externalDocs` section of the OpenAPI document, provide the website's homepage in the `url` property. It will be set as the [Project URL](https://learn.microsoft.com/en-us/nuget/create-packages/package-authoring-best-practices#project-url), visible in the package's "About" section.
    ```yaml
    openapi: 3.1.0
    externalDocs:
        url: https://homepage.com/docs
        description: Public Docs
    ```
7. In the root of the repository:
   - Add a `LICENSE[.md|.txt]` file (see [Licensing](https://learn.microsoft.com/en-us/nuget/create-packages/package-authoring-best-practices#licensing) for more details).
   - Add a 128x128 dimension image file called `icon[.jpg|.png]`to display on the NuGet package page.
   - Review the `NUGET.md` file, which is similar to the main `README.md` but excludes the `SDK Installation` and `Available Operations` sections. For more details, see [Editing Your SDK Docs](./docs/sdk-docs).

#### PHP
1. Create a [Packagist](https://packagist.org) account (if needed).
2. Generate a Safe API Token:
   - Navigate to [Packagist Profile](https://packagist.org/profile/) and log in.
   - Record the "Safe API Token" under account settings.
3. Update GitHub Action Secrets with Packagist credentials:
   - Navigate to the repository's Github Secret Settings.
   - Update the following secrets:
     - `PACKAGIST_TOKEN`: Set this to the Safe API Token from step 2.
     - `PACKAGIST_USERNAME`: Set this to Packagist username.
4. Store the following secrets in the GitHub Actions secrets:
    - `PACKAGIST_TOKEN`
    - `PACKAGIST_USERNAME`
5. Confirm that the publishing job is properly set up with the updated credentials.

## Publishing in the Speakeasy dashboard

The SDK publishing tab in the Speakeasy dashboard provides an overview of the publishing history and offers various utilities for setting up and maintaining SDK publishing.

<Screenshot darkened url="https://app.speakeasy.com/" isLinkEnabled={true} docs={true}>![Publishing Overview](./assets/publish-sdks/publishing-overview.png)</Screenshot>

If package manager secrets were not set during the initial SDK repo setup, the publishing dashboard provides an interface to attach these secrets to the repository.

<Screenshot darkened url="https://app.speakeasy.com/org" docs={true}>![Setting Publishing Secrets](./assets/publish-sdks/set-publishing-secrets.png)</Screenshot>

For GitHub actions set up with `mode:pr`, the publishing dashboard highlights open PRs in the SDK repo that are pending release. This view displays the exact SDK version that will be published upon merging the PR.

<Screenshot url="https://app.speakeasy.com/org" docs={true}>![Pending Release PRs](./assets/publish-sdks/pending-release.png)</Screenshot>



 This is the content for the doc docs/publish-terraform.mdx 

 ---
title: Terraform Registry
sidebar_label: Overview
description: "Publishing a Terraform Provider to the Hashicorp Registry."
---

# Terraform Registry

You can configure the Speakeasy Generation Action to publish a generated Terraform provider. Speakeasy Terraform provider generation does not support operating in monorepo mode, as you need to create a separate repository for the Terraform provider with the appropriate name format.
To publish the generated Terraform provider, you need to do the following:

1. The repository you make for the Terraform provider must:
    - Be given the name `terraform-provider-{NAME}`, where `NAME` is lowercase.
    - Be public.
2. Sign your Terraform provider releases with a signing key. Create and export a signing key following the instructions in the [GitHub documentation for generating a new GPG key](https://docs.github.com/en/authentication/managing-commit-signature-verification/generating-a-new-gpg-key). Generate your GPG key using either the RSA or DSA algorithm.
3. Take note of the following values:
    - The GPG private key.
    - The GPG passphrase.
    - The GPG public key.
4. Add the ASCII-armored public key to the Terraform registry.
5. Your GPG private key and GPG passphrase will be configured automatically if entered into the Speakeasy CLI. Ensure that the following secrets are available to your repository:
    - The GPG private key, `terraform_gpg_secret_key`.
    - The GPG passphrase, `terraform_gpg_passphrase`.
6. The first time you publish a Terraform provider generated using the Speakeasy Generation Action, you need to manually add it to the Terraform Registry. Subsequent updates will be published automatically. To begin this process, follow the [Terraform registry instructions](https://developer.hashicorp.com/terraform/registry/providers/publishing) and agree to any Terraform terms and conditions. Note that you will need to be an organizational admin to complete this step.
7. Add the following file to your `.github/workflows` directory to indicate create releases for your Terraform provider using GoReleaser. If all the above steps have been completed the HashiCorpy registry will automatically pick up new changes.

```yaml terraform_publish.yaml
# Terraform Provider release workflow.
name: Release

# This GitHub action creates a release when a tag that matches the pattern
# "v*" (e.g. v0.1.0) is created.
on:
  push:
    tags:
      - 'v*'
  workflow_dispatch:

# Releases need permissions to read and write the repository contents.
# GitHub considers creating releases and uploading assets as writing content.
permissions:
  contents: write

jobs:
  goreleaser:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@8f4b7f84864484a7bf31766abe9204da3cbe65b3 # v3.5.0
        with:
          # Allow goreleaser to access older tag information.
          fetch-depth: 0
      - uses: actions/setup-go@4d34df0c2316fe8122ab82dc22947d607c0c91f9 # v4.0.0
        with:
          go-version-file: 'go.mod'
          cache: true
      - name: Import GPG key
        uses: crazy-max/ghaction-import-gpg@111c56156bcc6918c056dbef52164cfa583dc549 # v5.2.0
        id: import_gpg
        with:
          gpg_private_key: ${{ secrets.terraform_gpg_secret_key }}
          passphrase: ${{ secrets.terraform_gpg_passphrase }}
      - name: Run GoReleaser
        uses: goreleaser/goreleaser-action@286f3b13b1b49da4ac219696163fb8c1c93e1200 # v6.0.0
        with:
          args: release --clean
        env:
          # GitHub sets the GITHUB_TOKEN secret automatically.
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GPG_FINGERPRINT: ${{ steps.import_gpg.outputs.fingerprint }}
```

8. Finally, create a [GoReleaser](https://goreleaser.com/) file in the root of your repository: 

```yaml .goreleaser.yml
# Visit https://goreleaser.com for documentation on how to customize this
# behavior.
version: 2

before:
  hooks:
    # this is just an example and not a requirement for provider building or publishing
    - go mod tidy
builds:
  - env:
      # goreleaser does not work with CGO, it could also complicate
      # usage by users in CI/CD systems like Terraform Cloud where
      # they are unable to install libraries.
      - CGO_ENABLED=0
    mod_timestamp: '{{ .CommitTimestamp }}'
    flags:
      - -trimpath
    ldflags:
      - '-s -w -X main.version={{.Version}} -X main.commit={{.Commit}}'
    goos:
      - freebsd
      - windows
      - linux
      - darwin
    goarch:
      - amd64
      - '386'
      - arm
      - arm64
    ignore:
      - goos: darwin
        goarch: '386'
    binary: '{{ .ProjectName }}_v{{ .Version }}'
archives:
  - format: zip
    name_template: '{{ .ProjectName }}_{{ .Version }}_{{ .Os }}_{{ .Arch }}'
checksum:
  extra_files:
    - glob: 'terraform-registry-manifest.json'
      name_template: '{{ .ProjectName }}_{{ .Version }}_manifest.json'
  name_template: '{{ .ProjectName }}_{{ .Version }}_SHA256SUMS'
  algorithm: sha256
signs:
  - artifacts: checksum
    args:
      # if you are using this in a GitHub action or some other automated pipeline, you
      # need to pass the batch flag to indicate it's not interactive.
      - "--batch"
      - "--local-user"
      - "{{ .Env.GPG_FINGERPRINT }}" # set this environment variable for your signing key
      - "--output"
      - "${signature}"
      - "--detach-sign"
      - "${artifact}"
release:
  extra_files:
    - glob: 'terraform-registry-manifest.json'
      name_template: '{{ .ProjectName }}_{{ .Version }}_manifest.json'
  # If you want to manually examine the release before it goes live, uncomment this line:
  # draft: true
changelog:
  disable: true
```

Whenever you generate and merge a new PR for your Terraform provider, it will be automatically versioned and released to the Hashicorp Registry.


 This is the content for the doc docs/sdk-docs.mdx 

 ---
title: Editing Your SDK Docs
description: "Managed SDKs: Learn how to generate developer-friendly documentation for your SDKs."
sidebar_label: "Customize Documentation"
---

import { Tabs } from "@speakeasy/nextra-theme";

# Editing Your SDK Docs

Speakeasy-managed SDKs include a `README.md` file that contains at least the following sections by default:

- `## Summary`: A brief introduction based on the `info` and `externalDocs` attributes defined in the OpenAPI document.
- `## Table of Contents`: A list of links to all available sections in the README.
- `## SDK Installation`: An installation snippet based on the package name provided in the `gen.yaml` file.
- `## SDK Example Usage`: An example usage snippet based on the first operation in the OpenAPI document.
- `## SDK Available Operations`: Links to documentation that covers all the SDK's methods.

Here's what it looks like put together:

````markdown
# github.com/client-sdk

  <!-- Start Summary [summary] -->

## Summary

<The `info.summary` provided in your OpenAPI specification>

<The `info.description` provided in your OpenAPI specification>

For more information about the API: [<externalDocs.description>](externalDocs.url)

  <!-- End Summary [summary] -->

  <!-- Start Table of Contents [toc] -->

## Table of Contents
<!-- $toc-max-depth=2 -->
* [OpenAPI SDK](#openapi-sdk)
  * [SDK Installation](#sdk-installation)
  * [SDK Example Usage](#sdk-example-usage)
  * [Available Resources and Operations](#available-resources-and-operations)
  * ...
* [Development](#development)
  * [Maturity](#maturity)
  * [Contributions](#contributions)
<!-- End Table of Contents [toc] -->

  <!-- Start SDK Installation [installation] -->

## SDK Installation

```bash
go get github.com/client-sdk
```

  <!-- End SDK Installation [installation] -->

  <!-- Start SDK Example Usage [usage] -->

## SDK Example Usage

```go
package main

import (
    "context"
    "fmt"
    "log"
    "os"

    "github.com/client-sdk"
    "github.com/client-sdk/pkg/models/shared"
    "github.com/client-sdk/pkg/models/operations"
)

func main() {
    ctx := context.Background()

    opts := []sdk.SDKOption{
        sdk.WithSecurity(shared.Security{
            APIKey: shared.SchemeAPIKey{
                APIKey: "YOUR_API_KEY",
            },
        }),
    }

    s := sdk.New(opts...)

    res, err := s.ListPets(ctx)
    if err != nil {
        log.Fatal(err)
    }

    if res.Pets != nil {
        // handle response
    }
}
```

  <!-- End SDK Example Usage [usage] -->

  <!-- Start SDK Available Operations [operations] -->

## SDK Available Operations

- `ListPets` - List all pets
  <!-- End SDK Available Operations [operations] -->
  <!-- Placeholder for Future Speakeasy SDK Sections -->
````

You can enhance your README by adding content before or after any of the three main sections (**SDK Installation**, **SDK Example Usage**, and **SDK Available Options**). The generator will not overwrite any content you have added to the `README.md` file. The generator will automatically keep the content within the walled-off sections between the `<!-- Start ... [tag] -->` and `<!-- End ... [tag] -->` comments, but the rest is up to you to maintain.

If you would like to take over the management of automatically generated sections, you can do the following:

1. Remove the `<!-- Start ... [tag] -->` section comment.
2. Find the matching `<!-- End ... [tag] -->` comment and change it to `<!-- No ... [tag] -->`, which marks that section as managed by you. (This step is important. If you only remove the "Start" comment, the section may be re-inserted as described below.)
3. Edit the content between those comments as you see fit.

If you change your mind at any time and want to go back to having Speakeasy manage a section, you can either delete the `<!-- No ... [tag] -->` comment from the file, or replace it with `<!-- Start ... [tag] --><!-- End ... [tag] -->`, and the next generation will re-insert the Speakeasy-managed content into your file.

Speakeasy may provide additional sections as new features are released or as you alter your SDK configuration by changing your OpenAPI specification and `gen.yaml` configuration. These new sections will be inserted above the comment named `<!-- Placeholder for Future Speakeasy SDK Sections -->`. (The placeholder heading will always be present in the file, and if you remove it, it will be added again just below the last README section.) Any missing sections will be inserted here during generation, so if you do not want a section inserted, be sure to follow the steps above to convert it to a `<!-- No ... [tag] -->` section rather than removing it entirely.

## Usage Examples

### Main Usage section

By default, `USAGE.md` and the **SDK Example Usage** section in the main `README.md` file will showcase a usage example from a random operation in the OpenAPI document. You can specify one or more operations to be used as the main usage example(s) by setting the `x-speakeasy-usage-example: true` extension to any operation in the OpenAPI document.

The `x-speakeasy-usage-example` extension can be further configured to associate each usage snippet with a custom header, description, and relative positioning.

| Key           | Description                                                                                                                                                                           |
| ------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `title`       | The title text to be used for the usage example (an empty string indicates no title).                                                                                                 |
| `description` | The description for the usage example (an empty string indicates no description).                                                                                                     |
| `position`    | Usage examples are sorted from lowest to highest based on the `position` value. Usage examples that share a `position` value will be sorted in the order they appear in the document. |

This may be particularly useful for guiding users through a specific set of instructions or a "getting started" section. For example:

```yaml
paths:
  /pets:
    get:
      x-speakeasy-usage-example:
        title: List the pets
        description: Now you can get all of the pets that have been added.
        position: 2
      summary: List all pets
      operationId: ListPets
      tags:
        - pets
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/Pets"
    put:
      x-speakeasy-usage-example:
        title: Add your pet
        description: First, add your own pet.
        position: 1
      summary: Add pet
      operationId: AddPet
      tags:
        - pets
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/Pet"
      responses:
        "200":
          description: OK
```

This YAML will result in the following being added to the `README.md` and `USAGE.md` files:

````markdown
### Add your pet

First, add your own pet.

```csharp
using PetStore;
using PetStore.Models.Pets;

var sdk = new PetstoreSDK();

var req = new Pet();

var res =  await sdk.Pets.AddPetAsync(req);
```

### List the pets

Now you can get all of the pets that have been added.

```csharp
using PetStore;
using PetStore.Models.Pets;

var sdk = new PetstoreSDK();
var res =  await sdk.Pets.ListPetsAsync();
```
````

### Table of Contents

To generate a more detailed Table of Contents, you can edit the value of the `$toc-max-depth` parameter in your `README.md` and subheadings will get updated upon regeneration:
```markdown
<!-- $toc-max-depth=3 -->
* [openapi](#openapi)
  * [SDK Installation](#sdk-installation)
  * [SDK Example Usage](#sdk-example-usage)
    * [Example 1](#example-1)
    * [Example 2](#example-2)
    * [Example 3](#example-3)
  * [Custom Header](#custom-header)
* ...
```

To ensure custom headings are properly referenced when manually adding sections to your `README.md` file, the basic markdown syntax should be respected:
```markdown
## Section Heading (level 2)
### Subsection Heading (level 3)
...
```

### Feature sections

Specific usage snippets can also be selected for other sections in the main `README.md`, provided they meet the requirements to showcase the feature at play. To do so, use the `x-speakeay-usage-example` extension and specify a list of section `tags` (referring to `<-- Start Section [tag] -->` placeholders).

For example, if you wish to select an operation for both the **Override Server URL Per-Operation** and the **Retries** sections, you can use the following:

```yaml
/webhooks/subscribe:
  post:
    operationId: subscribeToWebhooks
    servers:
      - url: https://speakeasy.bar
    x-speakeasy-usage-example:
      tags:
        - server
        - retries
    x-speakeasy-retries:
      strategy: backoff
      backoff:
        initialInterval: 10
        maxInterval: 200
        maxElapsedTime: 1000
        exponent: 1.15
```

The supported `tags` and their associated conditions are listed in this table:

| README section    | Sub-section   | tag               | Conditions for selection to be effective                           |
| :---------------- | ------------- | :---------------- | :----------------------------------------------------------------- |
| Global Parameters |               | global-parameters | One of the `parameters` must originate from `x-speakeasy-globals`. |
| Event Streaming   |               | eventstream       | One of the response must use the `text/event-stream` content type. |
| Pagination        |               | pagination        | `x-speaskeasy-pagination` must be set for the operation.           |
| Retries           |               | retries           | `x-speakeasy-retries` must be set for the operation.               |
| Error Handling    |               | errors            | One of the responses must be an error with custom content data.    |
| Server Selection  | Per-Client    | server            | `servers` must **not** be set at the operation level.              |
| Server Selection  | Per-Operation | server            | Operation must define its own `servers` array.                     |
| Authentication    | Per-Client    | security          | `security` must **not** be set for the operation.                  |
| Authentication    | Per-Operation | security          | Operation must define its own `security` array.                    |
| SDK Example Usage |               | usage             | None (same effect as `x-speakeasy-usage-example: true`).           |

If you wish to select an operation for the main usage section as well as other sections, you can use the `usage` tag:

```yaml
/drinks/{page}:
  get:
    operationId: listDrinks
    x-speakeasy-pagination:
      type: offsetLimit
      inputs:
        - name: page
          in: parameters
          type: page
    x-speakeasy-usage-example:
      title: "Browse available drinks"
      position: 2
      tags:
        - usage
        - pagination
```

Note: The `title`, `description`, and `position` attributes only affect the main **SDK Example Usage** section.

### Values

When generating usage examples, Speakeasy defaults to using any `example` values provided for schemas within your OpenAPI document. If no examples are present, Speakeasy will try to determine the most relevant example to generate from either the `format` field of a schema or the property name of a schema in an object.

For example, if the schema has `format: email` or is within a property called `email`, Speakeasy will generate a random email address as an example value.

### Security Schemes

For security schemes, the OpenAPI Specification does not allow you to specify examples of the values needed to populate the security details when initializing the SDKs. To provide custom examples for these values, add the `x-speakeasy-example` extension to the `securitySchemes` in your OpenAPI document.

For example:

```yaml
components:
  securitySchemes:
    apiKey:
      type: apiKey
      name: api_key
      in: header
      x-speakeasy-example: YOUR_API_KEY
```

The `x-speakeasy-example` value must be a string value and will be used as the example value for the Security Scheme. If the Security Scheme is a basic auth scheme, the example value will be a key-value pair that consists of a username and password split by a `;` character, such as `YOUR_USERNAME;YOUR_PASSWORD`.

## Comments

### Code Comments

As part of the SDK generation, the Speakeasy CLI will generate comments for operations and models in generated SDKs. These comments are generated from the OpenAPI specification, based on the summary or description of the operation or schema. Comments are generated in the target language docstring format.

For example, in Python, the comments will be generated as [PEP 257](https://www.python.org/dev/peps/pep-0257/)-compliant docstrings.

By default, comments are generated for all operations and models. To disable comment generation for your SDK, modify your `gen.yaml` file to disable them, like so:

```yaml
# ...
generation:
  comments:
    disabled: true
```

### Operation Comments

Comments for each method in the generated SDK will be generated from the summary or description of the Operation. For example, if you have an Operation like the following:

```yaml
paths:
  /pets:
    get:
      operationId: listPets
      summary: List all pets
      description: Get a list of all pets in the system
      responses:
        "200":
          description: A list of pets
          content:
            application/json:
              schema:
                type: array
                items:
                  $ref: "#/components/schemas/Pet"
```

The generated SDK will have a method commented like so:

<Tabs items={['Go', 'Python', 'TS', 'Java', 'C#']}>
<Tabs.Tab>

```go
// ListPets - List all pets
// Get a list of all pets in the system
func (s *SDK) ListPets(ctx context.Context) (*operations.ListPetsResponse, error) {
// ...
}
```

</Tabs.Tab>
<Tabs.Tab>

```python
def list_pets(self) -> operations.ListPetsResponse:
    r"""List all pets
    Get a list of all pets in the system
    """
    # ...
```

</Tabs.Tab>
<Tabs.Tab>

```typescript
  /**
   * ListPets - List all pets
   *
   * Get a list of all pets in the system
  **/
  ListPets(
    config?: AxiosRequestConfig
  ): Promise<operations.ListPetsResponse> {
    // ...
  }
```

</Tabs.Tab>
<Tabs.Tab>

```java
  /**
   * ListPets - List all pets
   *
   * Get a list of all pets in the system
  **/
  public ListPetsResponse listPets() {
    // ...
  }
```

</Tabs.Tab>
<Tabs.Tab>
```csharp
  /// <summary>
  /// List all pets
  ///
  /// <remarks>
  /// Get a list of all pets in the system
  /// </remarks>
  /// </summary>
  Task<ListPetsResponse> ListPetsAsync();
```

**Note:** In C#, the operation comment will appear on the function definition on the interface, not the class itself.

</Tabs.Tab>
</Tabs>

If both the summary and description are present, the summary will be used as the first line of the comment and the description will be used as the second line of the comment. If just the description is present, it will be used as the first line of the comment. If both are present, but you would like to omit the description as it might be too verbose, you can use the `omitdescriptionifsummarypresent` option in your `gen.yaml` file, as follows:

```yaml
# ...
generation:
  comments:
    omitDescriptionIfSummaryPresent: true
```

### Model Comments

For each model in the generated SDK, comments are generated from the description of the schema. For example, if you have the following schema:

```yaml
components:
  schemas:
    Pet:
      type: object
      description: A pet sold in the pet store
      properties:
        id:
          type: integer
          format: int64
        name:
          type: string
```

The generated SDK will have a model commented like so:

<Tabs items={['Go', 'Python', 'TS', 'Java', 'C#']}>
  <Tabs.Tab>

```go
// Pet
// A pet sold in the pet store
type Pet struct {
    // ...
```

  </Tabs.Tab>
  <Tabs.Tab>

```python
@dataclass_json
@dataclass
class Pet:
    r"""Pet
    A pet sold in the pet store
    """
    # ...
```

  </Tabs.Tab>
  <Tabs.Tab>

```typescript
// Pet
/**
 * A pet sold in the pet store
**/
export class Pet extends SpeakeasyBase {
    // ...
```

  </Tabs.Tab>
  <Tabs.Tab>

```java
/**
 * Pet
 *
 * A pet sold in the pet store
**/
public class Pet {
    // ...
}
```

  </Tabs.Tab>
  <Tabs.Tab>

```csharp
/// <summary>
/// A pet sold in the pet store
/// </summary>
public class Pet {
    // ...
}
```

  </Tabs.Tab>
</Tabs>

### Per-SDK Comments

You can configure comments that only display in the SDK for a single language. For example, if you need the comment for the TypeScript or the Golang SDK to say something different from the others, or you want to control the documentation separately for each language, you can use the Speakeasy `x-speakeasy-docs` extension. Anywhere you can set the `summary` or `description`, you can also add `x-speakeasy-docs` with per-language text for the docs.

Consider the following parameter description:

```yaml
parameters:
  - name: type
    in: query
    description: This query parameter names the type of drink to filter the results by. If not provided, all drinks will be returned.
    required: false
    schema:
      $ref: "#/components/schemas/DrinkType"
    x-speakeasy-docs:
      go:
        description: The type field names the type of drink to filter the results by. If set to nil, all drinks will be returned.
      python:
        description: The ``type`` field names the type of drink to filter the results by. If set to ``None``, all drinks will be returned.
      typescript:
        description: This field is the type of drink to filter the results by. If set to null, all drinks will be returned.
```

The documentation generated for each SDK will contain different comments specific to the respective programming languages.

## Class Names

By default, Speakeasy SDKs will be generated with the class name, `SDK`. However, you can configure a custom class name by modifying your `gen.yaml` file to include:

```yaml
generation:
  sdkClassName: "myClassName"
```

This will yield a package like this:

```go
package petshop

import (
	"net/http"

	"openapi/pkg/utils"
)

var ServerList = []string{
	"http://petstore.speakeasy.io/v1",
}

type HTTPClient interface {
	Do(req *http.Request) (*http.Response, error)
}

type PetShop struct {
	Pets *Pets

	_defaultClient  HTTPClient
	_securityClient HTTPClient

	_serverURL  string
	_language   string
	_sdkVersion string
	_genVersion string
}
```


 This is the content for the doc docs/speakeasy-reference/cli/README.md 

 ---
sidebar_position: 2
---

# speakeasy  
`speakeasy`  


The Speakeasy CLI tool provides access to the Speakeasy.com platform  

## Details

# Speakeasy 

A CLI tool for interacting with the [Speakeasy platform](https://www.speakeasy.com/) and its APIs.

Use this CLI to:
- Lint and validate OpenAPI specs
- Create, manage, and run Speakeasy workflows
- Configure GitHub Actions for Speakeasy workflows
- Suggest improvements to OpenAPI specs

Generate from OpenAPI Specs:
- Client and Server SDKs in GO, Python, TypeScript, Java, PHP, C#, Swift, Ruby
- Postman collections
- Terraform providers

[Quickstart guide](https://www.speakeasy.com/docs/create-client-sdks)

Visit [Speakeasy](https://www.speakeasy.com/) for more information


## Usage

```
speakeasy [flags]
```

### Options

```
  -h, --help              help for speakeasy
      --logLevel string   the log level (available options: [info, warn, error]) (default "info")
```

### Sub Commands

* [speakeasy ask](/docs/speakeasy-reference/cli/ask)	 - Starts a conversation with Speakeasy trained AI
* [speakeasy auth](/docs/speakeasy-reference/cli/auth)	 - Authenticate the CLI
* [speakeasy billing](/docs/speakeasy-reference/cli/billing)	 - Manage billing related operations
* [speakeasy bump](/docs/speakeasy-reference/cli/bump)	 - Bumps the version of a Speakeasy Generation Target
* [speakeasy clean](/docs/speakeasy-reference/cli/clean)	 - Speakeasy clean can be used to clean up cache, stale temp folders, and old CLI binaries.
* [speakeasy configure](/docs/speakeasy-reference/cli/configure)	 - Configure your Speakeasy SDK Setup.
* [speakeasy lint](/docs/speakeasy-reference/cli/lint)	 - Lint/Validate OpenAPI documents and Speakeasy configuration files
* [speakeasy merge](/docs/speakeasy-reference/cli/merge)	 - Merge multiple OpenAPI documents into a single document
* [speakeasy openapi](/docs/speakeasy-reference/cli/openapi)	 - Utilities for working with OpenAPI documents
* [speakeasy overlay](/docs/speakeasy-reference/cli/overlay)	 - Work with OpenAPI Overlays
* [speakeasy quickstart](/docs/speakeasy-reference/cli/quickstart)	 - Guided setup to help you create a new SDK in minutes.
* [speakeasy run](/docs/speakeasy-reference/cli/run)	 - Run all the workflows defined in your workflow.yaml file. This can include multiple SDK generations from different OpenAPI sources
* [speakeasy status](/docs/speakeasy-reference/cli/status)	 - Review status of current workspace
* [speakeasy suggest](/docs/speakeasy-reference/cli/suggest)	 - Automatically improve your OpenAPI document with an LLM
* [speakeasy tag](/docs/speakeasy-reference/cli/tag)	 - Add tags to a given revision of your API. Specific to a registry namespace
* [speakeasy test](/docs/speakeasy-reference/cli/test)	 - For each workflow target, starts the mock API server and runs testing.
* [speakeasy update](/docs/speakeasy-reference/cli/update)	 - Update the Speakeasy CLI to the latest version


 This is the content for the doc docs/speakeasy-reference/cli/ask.md 

 # ask  
`speakeasy ask`  


Starts a conversation with Speakeasy trained AI  

## Details

Starts a conversation with Speakeasy trained AI. Ask about OpenAPI, Speakeasy, configuring SDKs, or anything else you need help with.

## Usage

```
speakeasy ask [flags]
```

### Options

```
  -h, --help             help for ask
  -m, --message string   Your question for AI.
```

### Options inherited from parent commands

```
      --logLevel string   the log level (available options: [info, warn, error]) (default "info")
```

### Parent Command

* [speakeasy](/docs/speakeasy-reference/cli/getting-started)	 - The Speakeasy CLI tool provides access to the Speakeasy.com platform


 This is the content for the doc docs/speakeasy-reference/cli/auth/README.md 

 # auth  
`speakeasy auth`  


Authenticate the CLI  

## Details

The "authenticate" command allows control over the authentication of the CLI.

## Usage

```
speakeasy auth [flags]
```

### Options

```
  -h, --help   help for auth
```

### Options inherited from parent commands

```
      --logLevel string   the log level (available options: [info, warn, error]) (default "info")
```

### Parent Command

* [speakeasy](/docs/speakeasy-reference/cli/getting-started)	 - The Speakeasy CLI tool provides access to the Speakeasy.com platform
### Sub Commands

* [speakeasy auth login](/docs/speakeasy-reference/cli/auth/login)	 - Authenticate the CLI
* [speakeasy auth logout](/docs/speakeasy-reference/cli/auth/logout)	 - Logout of the CLI
* [speakeasy auth switch](/docs/speakeasy-reference/cli/auth/switch)	 - Switch between authenticated workspaces


 This is the content for the doc docs/speakeasy-reference/cli/auth/login.md 

 # login  
`speakeasy auth login`  


Authenticate the CLI  

## Details

The "login" command authenticates the CLI for use with the Speakeasy Platform.

## Usage

```
speakeasy auth login [flags]
```

### Options

```
  -h, --help   help for login
```

### Options inherited from parent commands

```
      --logLevel string   the log level (available options: [info, warn, error]) (default "info")
```

### Parent Command

* [speakeasy auth](/docs/speakeasy-reference/cli/auth)	 - Authenticate the CLI


 This is the content for the doc docs/speakeasy-reference/cli/auth/logout.md 

 # logout  
`speakeasy auth logout`  


Logout of the CLI  

## Details

The "logout" command removes authentication from the CLI.

## Usage

```
speakeasy auth logout [flags]
```

### Options

```
  -h, --help   help for logout
```

### Options inherited from parent commands

```
      --logLevel string   the log level (available options: [info, warn, error]) (default "info")
```

### Parent Command

* [speakeasy auth](/docs/speakeasy-reference/cli/auth)	 - Authenticate the CLI


 This is the content for the doc docs/speakeasy-reference/cli/auth/switch.md 

 # switch  
`speakeasy auth switch`  


Switch between authenticated workspaces  

## Details

Change the default workspace to a different authenticated workspace

## Usage

```
speakeasy auth switch [flags]
```

### Options

```
  -h, --help   help for switch
```

### Options inherited from parent commands

```
      --logLevel string   the log level (available options: [info, warn, error]) (default "info")
```

### Parent Command

* [speakeasy auth](/docs/speakeasy-reference/cli/auth)	 - Authenticate the CLI


 This is the content for the doc docs/speakeasy-reference/cli/billing/README.md 

 # billing  
`speakeasy billing`  


Manage billing related operations  

## Details

Commands for managing billing related operations in Speakeasy.

## Usage

```
speakeasy billing [flags]
```

### Options

```
  -h, --help   help for billing
```

### Options inherited from parent commands

```
      --logLevel string   the log level (available options: [info, warn, error]) (default "info")
```

### Parent Command

* [speakeasy](/docs/speakeasy-reference/cli/getting-started)	 - The Speakeasy CLI tool provides access to the Speakeasy.com platform
### Sub Commands

* [speakeasy billing activate](/docs/speakeasy-reference/cli/billing/activate)	 - Activate a paid feature


 This is the content for the doc docs/speakeasy-reference/cli/billing/activate.md 

 # activate  
`speakeasy billing activate`  


Activate a paid feature  

## Details

Activate a paid feature in your Speakeasy workspace.

## Usage

```
speakeasy billing activate [flags]
```

### Options

```
  -f, --feature string   feature to activate (e.g. webhooks)
  -h, --help             help for activate
```

### Options inherited from parent commands

```
      --logLevel string   the log level (available options: [info, warn, error]) (default "info")
```

### Parent Command

* [speakeasy billing](/docs/speakeasy-reference/cli/billing)	 - Manage billing related operations


 This is the content for the doc docs/speakeasy-reference/cli/bump.md 

 # bump  
`speakeasy bump`  


Bumps the version of a Speakeasy Generation Target  

## Details

# Bump

Bumps the version of a Speakeasy Generation Target, run within the target's directory. Allows the bumping of patch, minor, and major versions or setting to a specific version.

Examples:

- speakeasy bump patch - Bumps the target's version by one patch version
- speakeasy bump -v 1.2.3 - Sets the target's version to 1.2.3
- speakeasy bump major -t typescript - Bumps the typescript target's version by one major version
- speakeasy bump graduate - Current version 1.2.3-alpha.1 sets the target's version to 1.2.3


## Usage

```
speakeasy bump [patch|minor|major|graduate] [flags]
```

### Examples

```


const version = require("@speakeasy/sdk-typescript").version;
console.log(version);

```

### Options

```
  -h, --help             help for bump
  -t, --target string    The target to bump the version of, if more than one target is found in the gen.yaml
  -v, --version string   The version to bump to, if you want to specify a specific version.
```

### Options inherited from parent commands

```
      --logLevel string   the log level (available options: [info, warn, error]) (default "info")
```

### Parent Command

* [speakeasy](/docs/speakeasy-reference/cli/getting-started)	 - The Speakeasy CLI tool provides access to the Speakeasy.com platform


 This is the content for the doc docs/speakeasy-reference/cli/clean.md 

 # clean  
`speakeasy clean`  


Speakeasy clean can be used to clean up cache, stale temp folders, and old CLI binaries.  

## Details

Using speakeasy clean outside of an SDK directory or with the --global will clean cache, CLI binaries, and more out of the root .speakeasy folder.
Within an SDK directory, it will clean out stale entries within the local .speakeasy folder.

## Usage

```
speakeasy clean [flags]
```

### Options

```
      --global   clean out the root .speakeasy directory
  -h, --help     help for clean
```

### Options inherited from parent commands

```
      --logLevel string   the log level (available options: [info, warn, error]) (default "info")
```

### Parent Command

* [speakeasy](/docs/speakeasy-reference/cli/getting-started)	 - The Speakeasy CLI tool provides access to the Speakeasy.com platform


 This is the content for the doc docs/speakeasy-reference/cli/configure/README.md 

 # configure  
`speakeasy configure`  


Configure your Speakeasy SDK Setup.  

## Details

# Configure

Configure your Speakeasy workflow file.

[Workflows](https://www.speakeasy.com/docs/workflow-file-reference)

[GitHub Setup](https://www.speakeasy.com/docs/publish-sdks/github-setup)

[Publishing](https://www.speakeasy.com/docs/publish-sdks/publish-sdks)

[Testing](https://www.speakeasy.com/docs/customize-testing/bootstrapping-test-generation)



## Usage

```
speakeasy configure [flags]
```

### Options

```
  -h, --help   help for configure
```

### Options inherited from parent commands

```
      --logLevel string   the log level (available options: [info, warn, error]) (default "info")
```

### Parent Command

* [speakeasy](/docs/speakeasy-reference/cli/getting-started)	 - The Speakeasy CLI tool provides access to the Speakeasy.com platform
### Sub Commands

* [speakeasy configure github](/docs/speakeasy-reference/cli/configure/github)	 - Configure Speakeasy for github.
* [speakeasy configure publishing](/docs/speakeasy-reference/cli/configure/publishing)	 - Configure Speakeasy for publishing.
* [speakeasy configure sources](/docs/speakeasy-reference/cli/configure/sources)	 - Configure new or existing sources.
* [speakeasy configure targets](/docs/speakeasy-reference/cli/configure/targets)	 - Configure new target.
* [speakeasy configure tests](/docs/speakeasy-reference/cli/configure/tests)	 - Configure Speakeasy SDK tests.


 This is the content for the doc docs/speakeasy-reference/cli/configure/github.md 

 # github  
`speakeasy configure github`  


Configure Speakeasy for github.  

## Details

Configure your Speakeasy workflow to generate and publish from your github repo.

## Usage

```
speakeasy configure github [flags]
```

### Options

```
  -h, --help                        help for github
  -d, --workflow-directory string   directory of speakeasy workflow file
```

### Options inherited from parent commands

```
      --logLevel string   the log level (available options: [info, warn, error]) (default "info")
```

### Parent Command

* [speakeasy configure](/docs/speakeasy-reference/cli/configure)	 - Configure your Speakeasy SDK Setup.


 This is the content for the doc docs/speakeasy-reference/cli/configure/publishing.md 

 # publishing  
`speakeasy configure publishing`  


Configure Speakeasy for publishing.  

## Details

Configure your Speakeasy workflow to publish to package managers from your github repo.

## Usage

```
speakeasy configure publishing [flags]
```

### Options

```
  -h, --help                        help for publishing
  -d, --workflow-directory string   directory of speakeasy workflow file
```

### Options inherited from parent commands

```
      --logLevel string   the log level (available options: [info, warn, error]) (default "info")
```

### Parent Command

* [speakeasy configure](/docs/speakeasy-reference/cli/configure)	 - Configure your Speakeasy SDK Setup.


 This is the content for the doc docs/speakeasy-reference/cli/configure/sources.md 

 # sources  
`speakeasy configure sources`  


Configure new or existing sources.  

## Details

Guided prompts to configure a new or existing source in your speakeasy workflow.

## Usage

```
speakeasy configure sources [flags]
```

### Options

```
  -h, --help        help for sources
  -i, --id string   the name of an existing source to configure
  -n, --new         configure a new source
```

### Options inherited from parent commands

```
      --logLevel string   the log level (available options: [info, warn, error]) (default "info")
```

### Parent Command

* [speakeasy configure](/docs/speakeasy-reference/cli/configure)	 - Configure your Speakeasy SDK Setup.


 This is the content for the doc docs/speakeasy-reference/cli/configure/targets.md 

 # targets  
`speakeasy configure targets`  


Configure new target.  

## Details

Guided prompts to configure a new target in your speakeasy workflow.

## Usage

```
speakeasy configure targets [flags]
```

### Options

```
  -h, --help        help for targets
  -i, --id string   the name of an existing target to configure
  -n, --new         configure a new target
```

### Options inherited from parent commands

```
      --logLevel string   the log level (available options: [info, warn, error]) (default "info")
```

### Parent Command

* [speakeasy configure](/docs/speakeasy-reference/cli/configure)	 - Configure your Speakeasy SDK Setup.


 This is the content for the doc docs/speakeasy-reference/cli/configure/tests.md 

 # tests  
`speakeasy configure tests`  


Configure Speakeasy SDK tests.  

## Details

Configure your Speakeasy workflow to generate and run SDK tests..

## Usage

```
speakeasy configure tests [flags]
```

### Options

```
  -h, --help                        help for tests
  -d, --workflow-directory string   directory of speakeasy workflow file
```

### Options inherited from parent commands

```
      --logLevel string   the log level (available options: [info, warn, error]) (default "info")
```

### Parent Command

* [speakeasy configure](/docs/speakeasy-reference/cli/configure)	 - Configure your Speakeasy SDK Setup.


 This is the content for the doc docs/speakeasy-reference/cli/getting-started.mdx 

 ---
description: "Generate client SDKs in popular languages from your OpenAPI spec with Speakeasy. Install the CLI and run a single command to generate an SDK."
slug: /speakeasy-cli/
---

# Getting Started

The Speakeasy CLI provides access to features of the Speakeasy Platform. This CLI supports an interactive mode. Simply type `speakeasy` in your terminal for a guided set-up and usage experience.

## Install

In your terminal, run:

### Homebrew (macOS)

```bash
brew install speakeasy-api/homebrew-tap/speakeasy
```

### Script (macOS and Linux)

```bash
curl -fsSL https://go.speakeasy.com/cli-install.sh | sh
```

### winget (Windows)

```cmd
winget install speakeasy
```

### Chocolatey (Windows)

```cmd
choco install speakeasy
```

### Manual Installation

Download the latest Speakeasy CLI release for your platform from the [releases page](https://github.com/speakeasy-api/speakeasy/releases), extract, and add the binary to your path.

## Authenticate

Authenticate with the Speakeasy Platform to use the Speakeasy CLI:

```bash
speakeasy auth login
```

A browser window will open. Log in to the Speakeasy Platform and create a workspace (or select a workspace if you have previously used the platform) by following the prompts.

When you are redirected to your workspace, Speakeasy will generate an API key for you. Return to the terminal, and you should see a message that you are authenticated.

## Run

Get started with the installed Speakeasy CLI with a single interactive command.

```bash
speakeasy quickstart
```

Getting started is that easy.

For the full set of CLI commands, type `speakeasy -h`.

## Using the Speakeasy CLI in CI/CD

To use the Speakeasy CLI in a CI/CD pipeline, authenticate it by creating an API key in the [Speakeasy Platform](https://app.speakeasy.com) and then set the `SPEAKEASY_API_KEY` environment variable to the value of an API key from the API keys page.


 This is the content for the doc docs/speakeasy-reference/cli/lint/README.md 

 # lint  
`speakeasy lint`  


Lint/Validate OpenAPI documents and Speakeasy configuration files  

## Details

# Lint 
 The `lint` command provides a set of commands for linting OpenAPI docs and more.

## Usage

```
speakeasy lint [flags]
```

### Options

```
  -h, --help   help for lint
```

### Options inherited from parent commands

```
      --logLevel string   the log level (available options: [info, warn, error]) (default "info")
```

### Parent Command

* [speakeasy](/docs/speakeasy-reference/cli/getting-started)	 - The Speakeasy CLI tool provides access to the Speakeasy.com platform
### Sub Commands

* [speakeasy lint arazzo](/docs/speakeasy-reference/cli/lint/arazzo)	 - Validate an Arazzo document
* [speakeasy lint config](/docs/speakeasy-reference/cli/lint/config)	 - Lint a Speakeasy configuration file
* [speakeasy lint openapi](/docs/speakeasy-reference/cli/lint/openapi)	 - Lint an OpenAPI document


 This is the content for the doc docs/speakeasy-reference/cli/lint/arazzo.md 

 # arazzo  
`speakeasy lint arazzo`  


Validate an Arazzo document  

## Details

Validates an Arazzo document adheres to the Arazzo specification. Supports either yaml or json based Arazzo documents.

## Usage

```
speakeasy lint arazzo [flags]
```

### Options

```
  -f, --file string   path to the Arazzo document (default "arazzo.yaml")
  -h, --help          help for arazzo
```

### Options inherited from parent commands

```
      --logLevel string   the log level (available options: [info, warn, error]) (default "info")
```

### Parent Command

* [speakeasy lint](/docs/speakeasy-reference/cli/lint)	 - Lint/Validate OpenAPI documents and Speakeasy configuration files


 This is the content for the doc docs/speakeasy-reference/cli/lint/config.md 

 # config  
`speakeasy lint config`  


Lint a Speakeasy configuration file  

## Details

Validates a Speakeasy configuration file for SDK generation.

## Usage

```
speakeasy lint config [flags]
```

### Options

```
  -d, --dir string   path to the directory containing the Speakeasy configuration file (default ".")
  -h, --help         help for config
```

### Options inherited from parent commands

```
      --logLevel string   the log level (available options: [info, warn, error]) (default "info")
```

### Parent Command

* [speakeasy lint](/docs/speakeasy-reference/cli/lint)	 - Lint/Validate OpenAPI documents and Speakeasy configuration files


 This is the content for the doc docs/speakeasy-reference/cli/lint/openapi.md 

 # openapi  
`speakeasy lint openapi`  


Lint an OpenAPI document  

## Details

# Lint 
## OpenAPI

Validates an OpenAPI document is valid and conforms to the Speakeasy OpenAPI specification.

## Usage

```
speakeasy lint openapi [flags]
```

### Options

```
  -H, --header string                 header key to use if authentication is required for downloading schema from remote URL
  -h, --help                          help for openapi
      --max-validation-errors int     limit the number of errors to output (default 1000, 0 = no limit) (default 1000)
      --max-validation-warnings int   limit the number of warnings to output (default 1000, 0 = no limit) (default 1000)
  -r, --ruleset string                ruleset to use for linting (default "speakeasy-recommended")
  -s, --schema string                 local filepath or URL for the OpenAPI schema
      --token string                  token value to use if authentication is required for downloading schema from remote URL
```

### Options inherited from parent commands

```
      --logLevel string   the log level (available options: [info, warn, error]) (default "info")
```

### Parent Command

* [speakeasy lint](/docs/speakeasy-reference/cli/lint)	 - Lint/Validate OpenAPI documents and Speakeasy configuration files


 This is the content for the doc docs/speakeasy-reference/cli/merge.md 

 ---
sidebar_position: 7
---

# merge  
`speakeasy merge`  


Merge multiple OpenAPI documents into a single document  

## Details

Merge multiple OpenAPI documents into a single document, useful for merging multiple OpenAPI documents into a single document for generating a client SDK.
Note: That any duplicate operations, components, etc. will be overwritten by the next document in the list.

## Usage

```
speakeasy merge [flags]
```

### Options

```
  -h, --help                           help for merge
  -o, --out string                     path to the output file
  -s, --schemas path/to/schema1.json   a list of paths to OpenAPI documents to merge, specify -s path/to/schema1.json -s `path/to/schema2.json` etc
```

### Options inherited from parent commands

```
      --logLevel string   the log level (available options: [info, warn, error]) (default "info")
```

### Parent Command

* [speakeasy](/docs/speakeasy-reference/cli/getting-started)	 - The Speakeasy CLI tool provides access to the Speakeasy.com platform


 This is the content for the doc docs/speakeasy-reference/cli/openapi/README.md 

 # openapi  
`speakeasy openapi`  


Utilities for working with OpenAPI documents  

## Details

# OpenAPI 
 The `openapi` command provides a set of commands for visualizing, linting and transforming OpenAPI documents.

## Usage

```
speakeasy openapi [flags]
```

### Options

```
  -h, --help   help for openapi
```

### Options inherited from parent commands

```
      --logLevel string   the log level (available options: [info, warn, error]) (default "info")
```

### Parent Command

* [speakeasy](/docs/speakeasy-reference/cli/getting-started)	 - The Speakeasy CLI tool provides access to the Speakeasy.com platform
### Sub Commands

* [speakeasy openapi diff](/docs/speakeasy-reference/cli/openapi/diff)	 - Visualize the changes between two OpenAPI documents
* [speakeasy openapi lint](/docs/speakeasy-reference/cli/openapi/lint)	 - Lint an OpenAPI document
* [speakeasy openapi transform](/docs/speakeasy-reference/cli/openapi/transform)	 - Transform an OpenAPI spec using a well-defined function


 This is the content for the doc docs/speakeasy-reference/cli/openapi/diff.md 

 # diff  
`speakeasy openapi diff`  


Visualize the changes between two OpenAPI documents  

## Details

Visualize the changes between two OpenAPI documents

## Usage

```
speakeasy openapi diff [flags]
```

### Options

```
  -f, --format string   output format (default "summary")
  -h, --help            help for diff
      --new string      local filepath or URL for the updated OpenAPI schema
      --old string      local filepath or URL for the base OpenAPI schema to compare against
  -o, --output string   output file (default "-")
```

### Options inherited from parent commands

```
      --logLevel string   the log level (available options: [info, warn, error]) (default "info")
```

### Parent Command

* [speakeasy openapi](/docs/speakeasy-reference/cli/openapi)	 - Utilities for working with OpenAPI documents


 This is the content for the doc docs/speakeasy-reference/cli/openapi/lint.md 

 # lint  
`speakeasy openapi lint`  


Lint an OpenAPI document  

## Details

# Lint 
## OpenAPI

Validates an OpenAPI document is valid and conforms to the Speakeasy OpenAPI specification.

## Usage

```
speakeasy openapi lint [flags]
```

### Options

```
  -H, --header string                 header key to use if authentication is required for downloading schema from remote URL
  -h, --help                          help for lint
      --max-validation-errors int     limit the number of errors to output (default 1000, 0 = no limit) (default 1000)
      --max-validation-warnings int   limit the number of warnings to output (default 1000, 0 = no limit) (default 1000)
  -r, --ruleset string                ruleset to use for linting (default "speakeasy-recommended")
  -s, --schema string                 local filepath or URL for the OpenAPI schema
      --token string                  token value to use if authentication is required for downloading schema from remote URL
```

### Options inherited from parent commands

```
      --logLevel string   the log level (available options: [info, warn, error]) (default "info")
```

### Parent Command

* [speakeasy openapi](/docs/speakeasy-reference/cli/openapi)	 - Utilities for working with OpenAPI documents


 This is the content for the doc docs/speakeasy-reference/cli/openapi/transform/README.md 

 # transform  
`speakeasy openapi transform`  


Transform an OpenAPI spec using a well-defined function  

## Usage

```
speakeasy openapi transform [flags]
```

### Options

```
  -h, --help   help for transform
```

### Options inherited from parent commands

```
      --logLevel string   the log level (available options: [info, warn, error]) (default "info")
```

### Parent Command

* [speakeasy openapi](/docs/speakeasy-reference/cli/openapi)	 - Utilities for working with OpenAPI documents
### Sub Commands

* [speakeasy openapi transform cleanup](/docs/speakeasy-reference/cli/openapi/transform/cleanup)	 - Cleanup the formatting of a given OpenAPI document
* [speakeasy openapi transform convert-swagger](/docs/speakeasy-reference/cli/openapi/transform/convert-swagger)	 - Given a Swagger 2.0 file, convert it to an OpenAPI 3.x file
* [speakeasy openapi transform filter-operations](/docs/speakeasy-reference/cli/openapi/transform/filter-operations)	 - Given an OpenAPI file, filter down to just the given set of operations
* [speakeasy openapi transform format](/docs/speakeasy-reference/cli/openapi/transform/format)	 - Format an OpenAPI document to be more human-readable
* [speakeasy openapi transform normalize](/docs/speakeasy-reference/cli/openapi/transform/normalize)	 - Normalize an OpenAPI document to be more human-readable
* [speakeasy openapi transform remove-unused](/docs/speakeasy-reference/cli/openapi/transform/remove-unused)	 - Given an OpenAPI file, remove all unused options


 This is the content for the doc docs/speakeasy-reference/cli/openapi/transform/cleanup.md 

 # cleanup  
`speakeasy openapi transform cleanup`  


Cleanup the formatting of a given OpenAPI document  

## Usage

```
speakeasy openapi transform cleanup [flags]
```

### Options

```
  -h, --help            help for cleanup
  -o, --out string      write directly to a file instead of stdout
  -s, --schema string   the schema to transform
```

### Options inherited from parent commands

```
      --logLevel string   the log level (available options: [info, warn, error]) (default "info")
```

### Parent Command

* [speakeasy openapi transform](/docs/speakeasy-reference/cli/openapi/transform)	 - Transform an OpenAPI spec using a well-defined function


 This is the content for the doc docs/speakeasy-reference/cli/openapi/transform/convert-swagger.md 

 # convert-swagger  
`speakeasy openapi transform convert-swagger`  


Given a Swagger 2.0 file, convert it to an OpenAPI 3.x file  

## Usage

```
speakeasy openapi transform convert-swagger [flags]
```

### Options

```
  -h, --help            help for convert-swagger
  -o, --out string      write directly to a file instead of stdout
  -s, --schema string   the schema to transform
```

### Options inherited from parent commands

```
      --logLevel string   the log level (available options: [info, warn, error]) (default "info")
```

### Parent Command

* [speakeasy openapi transform](/docs/speakeasy-reference/cli/openapi/transform)	 - Transform an OpenAPI spec using a well-defined function


 This is the content for the doc docs/speakeasy-reference/cli/openapi/transform/filter-operations.md 

 # filter-operations  
`speakeasy openapi transform filter-operations`  


Given an OpenAPI file, filter down to just the given set of operations  

## Usage

```
speakeasy openapi transform filter-operations [flags]
```

### Options

```
  -x, --exclude              exclude the given operationIDs, rather than including them
  -h, --help                 help for filter-operations
      --operations strings   list of operation IDs to include (or exclude) (comma-separated list)
  -o, --out string           write directly to a file instead of stdout
  -s, --schema string        the schema to transform
```

### Options inherited from parent commands

```
      --logLevel string   the log level (available options: [info, warn, error]) (default "info")
```

### Parent Command

* [speakeasy openapi transform](/docs/speakeasy-reference/cli/openapi/transform)	 - Transform an OpenAPI spec using a well-defined function


 This is the content for the doc docs/speakeasy-reference/cli/openapi/transform/format.md 

 # format  
`speakeasy openapi transform format`  


Format an OpenAPI document to be more human-readable  

## Details

Format an OpenAPI document to be more human-readable by sorting the keys in a specific order best suited for each level in the OpenAPI specification

## Usage

```
speakeasy openapi transform format [flags]
```

### Options

```
  -h, --help            help for format
  -o, --out string      write directly to a file instead of stdout
  -s, --schema string   the schema to transform
```

### Options inherited from parent commands

```
      --logLevel string   the log level (available options: [info, warn, error]) (default "info")
```

### Parent Command

* [speakeasy openapi transform](/docs/speakeasy-reference/cli/openapi/transform)	 - Transform an OpenAPI spec using a well-defined function


 This is the content for the doc docs/speakeasy-reference/cli/openapi/transform/normalize.md 

 # normalize  
`speakeasy openapi transform normalize`  


Normalize an OpenAPI document to be more human-readable  

## Usage

```
speakeasy openapi transform normalize [flags]
```

### Options

```
  -h, --help            help for normalize
  -o, --out string      write directly to a file instead of stdout
      --prefixItems     Normalize prefixItems to be a simple string
  -s, --schema string   the schema to transform
```

### Options inherited from parent commands

```
      --logLevel string   the log level (available options: [info, warn, error]) (default "info")
```

### Parent Command

* [speakeasy openapi transform](/docs/speakeasy-reference/cli/openapi/transform)	 - Transform an OpenAPI spec using a well-defined function


 This is the content for the doc docs/speakeasy-reference/cli/openapi/transform/remove-unused.md 

 # remove-unused  
`speakeasy openapi transform remove-unused`  


Given an OpenAPI file, remove all unused options  

## Usage

```
speakeasy openapi transform remove-unused [flags]
```

### Options

```
  -h, --help            help for remove-unused
  -o, --out string      write directly to a file instead of stdout
  -s, --schema string   the schema to transform
```

### Options inherited from parent commands

```
      --logLevel string   the log level (available options: [info, warn, error]) (default "info")
```

### Parent Command

* [speakeasy openapi transform](/docs/speakeasy-reference/cli/openapi/transform)	 - Transform an OpenAPI spec using a well-defined function


 This is the content for the doc docs/speakeasy-reference/cli/overlay/README.md 

 # overlay  
`speakeasy overlay`  


Work with OpenAPI Overlays  

## Details

# Overlay

Command group for working with OpenAPI Overlays.


## Usage

```
speakeasy overlay [flags]
```

### Options

```
  -h, --help   help for overlay
```

### Options inherited from parent commands

```
      --logLevel string   the log level (available options: [info, warn, error]) (default "info")
```

### Parent Command

* [speakeasy](/docs/speakeasy-reference/cli/getting-started)	 - The Speakeasy CLI tool provides access to the Speakeasy.com platform
### Sub Commands

* [speakeasy overlay apply](/docs/speakeasy-reference/cli/overlay/apply)	 - Given an overlay, construct a new specification by extending a specification and applying the overlay, and output it to stdout.
* [speakeasy overlay compare](/docs/speakeasy-reference/cli/overlay/compare)	 - Given two specs (before and after), output an overlay that describes the differences between them
* [speakeasy overlay validate](/docs/speakeasy-reference/cli/overlay/validate)	 - Given an overlay, validate it according to the OpenAPI Overlay specification


 This is the content for the doc docs/speakeasy-reference/cli/overlay/apply.md 

 # apply  
`speakeasy overlay apply`  


Given an overlay, construct a new specification by extending a specification and applying the overlay, and output it to stdout.  

## Usage

```
speakeasy overlay apply [flags]
```

### Options

```
  -h, --help             help for apply
      --out string       write directly to a file instead of stdout
  -o, --overlay string   the overlay file to use
  -s, --schema string    the schema to extend
      --strict           fail if the overlay has any action target expressions which match no nodes, and produce warnings if any overlay actions do nothing
```

### Options inherited from parent commands

```
      --logLevel string   the log level (available options: [info, warn, error]) (default "info")
```

### Parent Command

* [speakeasy overlay](/docs/speakeasy-reference/cli/overlay)	 - Work with OpenAPI Overlays


 This is the content for the doc docs/speakeasy-reference/cli/overlay/compare.md 

 # compare  
`speakeasy overlay compare`  


Given two specs (before and after), output an overlay that describes the differences between them  

## Usage

```
speakeasy overlay compare [flags]
```

### Options

```
  -a, --after string    the after schema to compare
  -b, --before string   the before schema to compare
  -h, --help            help for compare
      --out string      write directly to a file instead of stdout
```

### Options inherited from parent commands

```
      --logLevel string   the log level (available options: [info, warn, error]) (default "info")
```

### Parent Command

* [speakeasy overlay](/docs/speakeasy-reference/cli/overlay)	 - Work with OpenAPI Overlays


 This is the content for the doc docs/speakeasy-reference/cli/overlay/validate.md 

 # validate  
`speakeasy overlay validate`  


Given an overlay, validate it according to the OpenAPI Overlay specification  

## Usage

```
speakeasy overlay validate [flags]
```

### Options

```
  -h, --help             help for validate
  -o, --overlay string   the overlay file to use
```

### Options inherited from parent commands

```
      --logLevel string   the log level (available options: [info, warn, error]) (default "info")
```

### Parent Command

* [speakeasy overlay](/docs/speakeasy-reference/cli/overlay)	 - Work with OpenAPI Overlays


 This is the content for the doc docs/speakeasy-reference/cli/quickstart.md 

 # quickstart  
`speakeasy quickstart`  


Guided setup to help you create a new SDK in minutes.  

## Details

Guided setup to help you create a new SDK in minutes.

## Usage

```
speakeasy quickstart [flags]
```

### Options

```
  -h, --help             help for quickstart
  -o, --out-dir string   output directory for the quickstart command
  -s, --schema string    local filepath or URL for the OpenAPI schema
      --skip-compile     skip compilation during generation after setup
  -t, --target string    language to generate sdk for (available options: [typescript, python, go, java, terraform, csharp, unity, php, postman, ruby, swift])
```

### Options inherited from parent commands

```
      --logLevel string   the log level (available options: [info, warn, error]) (default "info")
```

### Parent Command

* [speakeasy](/docs/speakeasy-reference/cli/getting-started)	 - The Speakeasy CLI tool provides access to the Speakeasy.com platform


 This is the content for the doc docs/speakeasy-reference/cli/run.md 

 # run  
`speakeasy run`  


Run all the workflows defined in your workflow.yaml file. This can include multiple SDK generations from different OpenAPI sources  

## Details

# Run 
 Execute the workflow(s) defined in your `.speakeasy/workflow.yaml` file.

A workflow can consist of multiple targets that define a source OpenAPI document that can be downloaded from a URL, exist as a local file, or be created via merging multiple OpenAPI documents together and/or overlaying them with an OpenAPI overlay document.

A full workflow is capable of running the following:
  - Downloading source OpenAPI documents from a URL
  - Merging multiple OpenAPI documents together
  - Overlaying OpenAPI documents with an OpenAPI overlay document
  - Generating one or many SDKs from the resulting OpenAPI document
  - Compiling the generated SDKs

If `speakeasy run` is run without any arguments it will run either the first target in the workflow or the first source in the workflow if there are no other targets or sources, otherwise it will prompt you to select a target or source to run.

## Usage

```
speakeasy run [flags]
```

### Options

```
  -d, --debug                     enable writing debug files with broken code
      --github                    kick off a generation run in GitHub
  -h, --help                      help for run
  -i, --installationURL string    the language specific installation URL for installation instructions if the SDK is not published to a package manager
      --installationURLs string   a map from target ID to installation URL for installation instructions if the SDK is not published to a package manager (default "null")
      --minimal                   only run the steps that are strictly necessary to generate the SDK
  -o, --output string             What to output while running (default "summary")
      --registry-tags strings     tags to apply to the speakeasy registry bundle (comma-separated list)
  -r, --repo string               the repository URL for the SDK, if the published (-p) flag isn't used this will be used to generate installation instructions
  -b, --repo-subdir string        the subdirectory of the repository where the SDK is located in the repo, helps with documentation generation
      --repo-subdirs string       a map from target ID to the subdirectory of the repository where the SDK is located in the repo, helps with documentation generation (default "null")
      --set-version string        the manual version to apply to the generated SDK
      --skip-compile              skip compilation when generating the SDK
      --skip-testing              skip testing after generating the SDK, if testing is configured in the workflow
      --skip-versioning           skip automatic SDK version increments
  -s, --source string             source to run. specify 'all' to run all sources
  -t, --target string             target to run. specify 'all' to run all targets
      --verbose                   Verbose logging
  -w, --watch                     launch the web studio for improving the quality of the generated SDK
```

### Options inherited from parent commands

```
      --logLevel string   the log level (available options: [info, warn, error]) (default "info")
```

### Parent Command

* [speakeasy](/docs/speakeasy-reference/cli/getting-started)	 - The Speakeasy CLI tool provides access to the Speakeasy.com platform


 This is the content for the doc docs/speakeasy-reference/cli/status.md 

 # status  
`speakeasy status`  


Review status of current workspace  

## Usage

```
speakeasy status [flags]
```

### Options

```
  -h, --help   help for status
```

### Options inherited from parent commands

```
      --logLevel string   the log level (available options: [info, warn, error]) (default "info")
```

### Parent Command

* [speakeasy](/docs/speakeasy-reference/cli/getting-started)	 - The Speakeasy CLI tool provides access to the Speakeasy.com platform


 This is the content for the doc docs/speakeasy-reference/cli/suggest/README.md 

 # suggest  
`speakeasy suggest`  


Automatically improve your OpenAPI document with an LLM  

## Details


# Suggest 

Automatically optimise your OpenAPI document for SDK generation with an LLM powered suggestions


## Usage

```
speakeasy suggest [flags]
```

### Options

```
  -h, --help   help for suggest
```

### Options inherited from parent commands

```
      --logLevel string   the log level (available options: [info, warn, error]) (default "info")
```

### Parent Command

* [speakeasy](/docs/speakeasy-reference/cli/getting-started)	 - The Speakeasy CLI tool provides access to the Speakeasy.com platform
### Sub Commands

* [speakeasy suggest error-types](/docs/speakeasy-reference/cli/suggest/error-types)	 - Automatically improve your SDK's error handling ergonomics
* [speakeasy suggest operation-ids](/docs/speakeasy-reference/cli/suggest/operation-ids)	 - Automatically improve your SDK's method names


 This is the content for the doc docs/speakeasy-reference/cli/suggest/error-types.md 

 # error-types  
`speakeasy suggest error-types`  


Automatically improve your SDK's error handling ergonomics  

## Usage

```
speakeasy suggest error-types [flags]
```

### Options

```
  -h, --help            help for error-types
  -o, --out string      write the suggestion to the specified path
      --overlay         write the suggestion as an overlay to --out, instead of the full document (default: true) (default true)
  -s, --schema string   the schema to transform
```

### Options inherited from parent commands

```
      --logLevel string   the log level (available options: [info, warn, error]) (default "info")
```

### Parent Command

* [speakeasy suggest](/docs/speakeasy-reference/cli/suggest)	 - Automatically improve your OpenAPI document with an LLM


 This is the content for the doc docs/speakeasy-reference/cli/suggest/operation-ids.md 

 # operation-ids  
`speakeasy suggest operation-ids`  


Automatically improve your SDK's method names  

## Usage

```
speakeasy suggest operation-ids [flags]
```

### Options

```
  -h, --help            help for operation-ids
  -o, --out string      write the suggestion to the specified path
      --overlay         write the suggestion as an overlay to --out, instead of the full document (default: true) (default true)
  -s, --schema string   the schema to transform
```

### Options inherited from parent commands

```
      --logLevel string   the log level (available options: [info, warn, error]) (default "info")
```

### Parent Command

* [speakeasy suggest](/docs/speakeasy-reference/cli/suggest)	 - Automatically improve your OpenAPI document with an LLM


 This is the content for the doc docs/speakeasy-reference/cli/tag/README.md 

 # tag  
`speakeasy tag`  


Add tags to a given revision of your API. Specific to a registry namespace  

## Usage

```
speakeasy tag [flags]
```

### Options

```
  -h, --help   help for tag
```

### Options inherited from parent commands

```
      --logLevel string   the log level (available options: [info, warn, error]) (default "info")
```

### Parent Command

* [speakeasy](/docs/speakeasy-reference/cli/getting-started)	 - The Speakeasy CLI tool provides access to the Speakeasy.com platform
### Sub Commands

* [speakeasy tag apply](/docs/speakeasy-reference/cli/tag/apply)	 - Add tags to a given revision of your API. Specific to a registry namespace
* [speakeasy tag promote](/docs/speakeasy-reference/cli/tag/promote)	 - Add tags to a revision in the Registry, based on the most recent workflow run


 This is the content for the doc docs/speakeasy-reference/cli/tag/apply.md 

 # apply  
`speakeasy tag apply`  


Add tags to a given revision of your API. Specific to a registry namespace  

## Usage

```
speakeasy tag apply [flags]
```

### Options

```
  -h, --help                     help for apply
  -n, --namespace-name string    the revision to tag
  -r, --revision-digest string   the revision ID to tag
  -t, --tags strings             A list of tags to apply (comma-separated list)
```

### Options inherited from parent commands

```
      --logLevel string   the log level (available options: [info, warn, error]) (default "info")
```

### Parent Command

* [speakeasy tag](/docs/speakeasy-reference/cli/tag)	 - Add tags to a given revision of your API. Specific to a registry namespace


 This is the content for the doc docs/speakeasy-reference/cli/tag/promote.md 

 # promote  
`speakeasy tag promote`  


Add tags to a revision in the Registry, based on the most recent workflow run  

## Usage

```
speakeasy tag promote [flags]
```

### Options

```
  -c, --code-samples strings   a list of targets whose code samples should be tagged (comma-separated list)
  -h, --help                   help for promote
  -s, --sources strings        a list of sources whose schema revisions should be tagged (comma-separated list)
  -t, --tags strings           A list of tags to apply (comma-separated list)
```

### Options inherited from parent commands

```
      --logLevel string   the log level (available options: [info, warn, error]) (default "info")
```

### Parent Command

* [speakeasy tag](/docs/speakeasy-reference/cli/tag)	 - Add tags to a given revision of your API. Specific to a registry namespace


 This is the content for the doc docs/speakeasy-reference/cli/test.md 

 # test  
`speakeasy test`  


For each workflow target, starts the mock API server and runs testing.  

## Usage

```
speakeasy test [flags]
```

### Options

```
      --disable-mockserver   Skips starting the target testing mock API server before running tests.
  -h, --help                 help for test
  -t, --target string        Specify a single workflow target to run testing. Defaults to all targets. Use 'all' to explicitly run all targets.
      --verbose              Verbose output.
```

### Options inherited from parent commands

```
      --logLevel string   the log level (available options: [info, warn, error]) (default "info")
```

### Parent Command

* [speakeasy](/docs/speakeasy-reference/cli/getting-started)	 - The Speakeasy CLI tool provides access to the Speakeasy.com platform


 This is the content for the doc docs/speakeasy-reference/cli/update.md 

 ---
sidebar_position: 10
---

# update  
`speakeasy update`  


Update the Speakeasy CLI to the latest version  

## Details

Updates the Speakeasy CLI in-place to the latest version available by downloading from Github and replacing the current binary

## Usage

```
speakeasy update [flags]
```

### Options

```
  -h, --help          help for update
  -t, --timeout int   timeout in seconds for the update to complete (default 60)
```

### Options inherited from parent commands

```
      --logLevel string   the log level (available options: [info, warn, error]) (default "info")
```

### Parent Command

* [speakeasy](/docs/speakeasy-reference/cli/getting-started)	 - The Speakeasy CLI tool provides access to the Speakeasy.com platform


 This is the content for the doc docs/speakeasy-reference/extensions.mdx 

 ---
title: "Speakeasy extensions"
description: "List of all Speakeasy extensions"
slug: "/speakeasy-extensions"
---

# List of Speakeasy extensions

| Extension                                 | Description                                                                                                                                                                                                                                        | Docs                                                                         |
| ----------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------- |
| `x-speakeasy-name-override`               | Use it globally to change method names or inline to change the name of a method, parameter, or class.                                                                                                                                             | [Full docs](/docs/methods/#change-method-names)               |
| `x-speakeasy-group`                       | Allows you to define custom namespaces when adding this property to any operation in your OpenAPI spec. If added, the tags for that method will be ignored and the value of `x-speakeasy-group` will define the namespace for that method instead. | [Full docs](/docs/structure/namespaces/#define-namespaces-without-tags) |
| `x-speakeasy-ignore`                      | Exclude certain methods from your SDK with this extension.                                                                                                                                                                                         | [Full docs](/docs/methods/#exclude-methods-from-sdk)          |
| `x-speakeasy-enums`                       | Use this extension to control generated enum members by providing alternative names for each value in the enum field.                                                                                                                              | [Full docs](/docs/data-model/enums/#enum-member-names)                   |
| `x-speakeasy-enum-format`                 | Customize how the enum type is generated for the schema, either `enum` for a native enum type or `union` for a union of values.                                                                                                                    | [Full docs](/docs/data-model/enums/#mixing-enum-formats)                 |
| `x-speakeasy-retries`                     | Enable retries globally or on a per-request basis. A backoff strategy is applied to specified status codes.                                                                                                                                        | [Full docs](/docs/runtime/retries/#global-retries)                    |
| `x-speakeasy-pagination`                  | Use to customize offset- or cursor-based pagination rules for each API operation.                                                                                                                                                                  | [Full docs](/docs/runtime/pagination/)                                |
| `x-speakeasy-usage-example`               | Feature a method in your SDK's `README.md` by adding this property to the method.                                                                                                                                                                  | [Full docs](/docs/sdk-docs/#values)                           |
| `x-speakeasy-example`                     | The OpenAPI specification doesn't allow example values for `securityscheme` property. Using this extension overcomes this limitation.                                                                                                              | [Full docs](/docs/sdk-docs/#securityschemes)                  |
| `x-speakeasy-docs`                        | Configure comments that only show up in the SDK for a single language.                                                                                                                                                                             | [Full docs](/docs/sdk-docs/#per-sdk-comments)                 |
| `x-speakeasy-globals`                     | Define parameters that can be configured globally on the main SDK instance and populated automatically for any operations that use them.                                                                                                           | [Full docs](/docs/globals/)                                   |
| `x-speakeasy-globals-hidden`              | Define parameters that can be configured globally on the main SDK instance but are not shown in the matching method's signature.                                                                                                                   | [Full docs](/docs/globals/)                                   |
| `x-speakeasy-errors`                      | Apply this extension at the level of `paths`, `path` `item`, or `operation` in the document to override the default error-handling behavior of the SDKs.                                                                                               | [Full docs](/docs/responses/errors/)                                    |
| `x-speakeasy-error-message`               | Used to mark a field in an error response as containing the error message to use.                                                                                                                                                                       | [Full docs](/docs/responses/errors/)                                    |
| `x-speakeasy-server-id`                   | Enable users to pick a server when instantiating the SDK. Use this extension to define an ID for each server in the `servers` array in the OpenAPI spec.                                                                                           | [Full docs](/docs/servers/#declare-multiple-servers)          |
| `x-speakeasy-deprecation-message`         | Allows you to add a message to deprecated operations, parameters, and schemas.                                                                                                                                                                     | [Full docs](/docs/deprecations/)                              |
| `x-speakeasy-deprecation-replacement`     | Allows you to specify an alternate operation to use in place of a deprecated operation.                                                                                                                                                            | [Full docs](/docs/deprecations/)                              |
| `x-speakeasy-type-override`               | Use this to override a schema's type, forcing it to be handled as `any` to accept arbitrary data.                                                                                                                                                  | [Full docs](/docs/data-model/oneof-schemas)                                      |
| `x-speakeasy-max-method-params`           | Allows you to set the maximum number of parameters that can be passed to a method. If the number of parameters exceeds this value, a request object will be used instead.                                                                          | [Full docs](/docs/methods#configuring-method-signatures)      |
| `x-speakeasy-param-encoding-override`     | When set with a value of `allowReserved`, path parameters will appear in a request URL with reserved characters `:/?#[]@!$&'()*+,;=` unencoded. Currently in Java only.                                                                                               | [Full docs](/docs/languages/java/param-encoding)      |

You can use `x-speakeasy-extension-rewrite` to map any extension from the wider OpenAPI ecosystem or another vendor to the equivalent Speakeasy extension. This allows you to use your existing OpenAPI spec without needing to make changes to it, if necessary.

```yaml
openapi: 3.1.0
info:
  title: My API
  version: 1.0.0
x-speakeasy-extension-rewrite:
  x-speakeasy-enums: x-enum-varnames # Maps x-enum-varnames used by the OSS generator to x-speakeasy-enums which has the same functionality
```

## Terraform-specific extensions

| Terraform extension                | Description                                                                                                                                                                                                                                | Docs                                                                    |
| ----------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------- |
| `x-speakeasy-entity`                      |   Map API entities to Terraform resources by annotating objects in your OpenAPI spec as entities in the Terraform provider.                                                                                                          | [Full docs](/docs/terraform/entity-mapping)   |
| `x-speakeasy-entity-operation`            |   Specify CRUD operations for API endpoints to map to Terraform resources, such as create, read, update, or delete operations.                                                                                                       | [Full docs](/docs/terraform/entity-mapping#specify-crud-operations-for-api-endpoints)         |
| `x-speakeasy-name-override`               |   Remap API properties to Terraform attribute names while keeping API data handling intact.                                                                                                                                          | [Full docs](/docs/terraform/property-customization#remap-api-property-to-terraform) |
| `x-speakeasy-param-sensitive`             |   Hide sensitive properties from Terraform console output for security purposes.                                                                                                                                                     | [Full docs](/docs/terraform/property-customization#hide-sensitive-properties)       |
| `x-speakeasy-terraform-ignore`            |   Use this extension to exclude properties from Terraform state management.                                                                                                                                                          | [Full docs](/docs/terraform/property-customization#exclude-property-from-terraform-state) |
| `x-speakeasy-type-override`               |   Allows the conversion of an attribute to a JSON string, accommodating dynamic structures in Terraform configurations.                                                                                                               | [Full docs](/docs/terraform/property-customization#allow-json-string-attributes)    |
| `x-speakeasy-plan-validators`             |   Add custom validation logic to Terraform plan operations to ensure configurations meet predefined criteria before execution.                                                                                                       | [Full docs](/docs/terraform/validation-dependencies#add-custom-validation-logic)     |
| `x-speakeasy-plan-modifiers`              |   Add custom plan modification logic to Terraform plan operations for advanced default values or resource replacement logic.                                                                                                          | [Full docs](/docs/terraform/plan-modification#add-custom-plan-modification)    |
| `x-speakeasy-entity-version`              |   Specify the version of a Terraform resource to support state migrations for breaking changes.                                                                                                                                      | [Full docs](/docs/terraform/plan-modification#specify-resource-version)        |
| `x-speakeasy-conflicts-with`              |   Indicate conflicting properties to prevent incompatible combinations in Terraform configurations.                                                                                                                                 | [Full docs](/docs/terraform/validation-dependencies#prevent-conflicting-attributes)  |
| `x-speakeasy-param-readonly`              |   Mark properties as read-only in Terraform, preventing modifications by the user.                                                                                                                                                  | [Full docs](/docs/terraform/advanced-features#force-mark-property-as-read-only)|
| `x-speakeasy-param-optional`              |   Force a property to be optional, overriding the required attribute in JSON Schema specifications.                                                                                                                                  | [Full docs](/docs/terraform/advanced-features#force-designate-a-property-as-optional) |
| `x-speakeasy-param-force-new`             |   Force resource recreation in Terraform when certain property values change.                                                                                                                                                        | [Full docs](/docs/terraform/advanced-features#force-resource-recreation)       |
| `x-speakeasy-terraform-plan-only`         |   Ensure that only values from the Terraform plan are used during updates, overriding prior state or default values.                                                                                                                 | [Full docs](/docs/terraform/advanced-features#update-behavior-for-plan-only-attributes)   |


 This is the content for the doc docs/speakeasy-reference/generation/ci-cd-pipeline.mdx 

 ---
slug: "/ci-cd-pipeline"
sidebar_label: CI/CD Workflow for SDK Management
description: "Manage CI/CD (the automatic generation and publishing of Client SDKs) in a repo containing the generated SDKs."
---

import { Callout } from '~/components';

# Workflow matrix


<Callout title="TIP" variant="success"> To quickly set up the workflow, run `speakeasy configure github` in the root of the SDK repository. This automates the setup and commits the necessary files. For more complex or custom configurations, the following is supported. </Callout>

## Workflow inputs

```yml
"on":
  workflow_dispatch:
    inputs:
      force:
        description: Force generation of SDKs
        type: boolean
        default: false
      set_version:
        description: optionally set a specific SDK version
        type: string
```

The inputs to the workflow determine how the SDKs will be generated.

| **Input Name**  | **Description**                                                                    | **Type** | **Default** |
|-----------------|------------------------------------------------------------------------------------|----------|-------------|
| `force`         | Forces SDK generation even if no changes are detected in the OpenAPI document.      | boolean  | `false`     |
| `set_version`   | Optionally set a specific version for the SDKs.                                     | string   | N/A         |

## Workflow jobs

The generate job utilizes the Speakeasy SDK generation action. It references the `workflow-executor.yaml` from the `sdk-generation-action` repo, which handles the core operations like pulling the OpenAPI document, validating it, and generating the SDKs.

### With

```yml
jobs:
  generate:
    uses: speakeasy-api/sdk-generation-action/.github/workflows/workflow-executor.yaml@v15
    with:
      force: ${{ github.event.inputs.force }}
      mode: pr
      set_version: ${{ github.event.inputs.set_version }}
      speakeasy_version: latest
```

| **Input Name**      | **Description**                                                                                                                                                           | **Type** | **Default** |
|---------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------|-------------|
| `speakeasy_version` | Version of the Speakeasy CLI to use. Use "latest" to always use the latest version.                                                                                        | string   | `latest`    |
| `mode`              | Workflow mode: `direct` commits changes directly to the branch, `pr` creates a pull request, or `test` fully runs through generation without modifying any GitHub state.    | string   | `direct`    |
| `force`             | Forces SDK generation, even if no changes are detected.                                                                                                                    | boolean  | `false`     |
| `set_version`       | Manually set a specific version for the SDK being generated.                                                                                                               | string   | None        |

### Secrets

```yml
secrets:
  github_access_token: ${{ secrets.GITHUB_TOKEN }}
  npm_token: ${{ secrets.NPM_TOKEN }}
  speakeasy_api_key: ${{ secrets.SPEAKEASY_API_KEY }}
```

| **Secret Name**           | **Description**                                                                                 |
|---------------------------|-------------------------------------------------------------------------------------------------|
| `github_access_token`      | GitHub access token with write access to the repository. Used to push changes and create PRs.   |
| `speakeasy_api_key`        | API key for authenticating with the Speakeasy CLI.                                              |
| `npm_token`                | Token to authenticate publishing to npm registry.                                               |
| `pypi_token`               | Token to authenticate publishing to PyPi for Python packages.                                   |
| `packagist_token`          | Token to authenticate publishing to Packagist for PHP packages.                                 |
| `ossrh_username`           | Username for publishing the Java package to the OSSRH repository.                               |
| `ossrh_password`           | Password for publishing the Java package to the OSSRH repository.                               |
| `java_gpg_secret_key`      | GPG secret key used for signing the Java package.                                               |
| `java_gpg_passphrase`      | Passphrase for the GPG secret key.                                                              |
| `rubygems_auth_token`      | Auth token (API key) for publishing to RubyGems.                                                |
| `nuget_api_key`            | API key for publishing to the Nuget registry.                                                   |
| `slack_webhook_url`        | Optional: Slack Webhook URL for posting workflow failure notifications.                         |
| `terraform_gpg_secret_key` | GPG secret key used for signing the Terraform provider.                                         |
| `terraform_gpg_passphrase` | Passphrase for the Terraform GPG secret key.                                                    |


## Workflow outputs

The workflow provides outputs that indicate which SDKs were regenerated and can trigger further actions in the pipeline, such as validating, testing, and publishing the SDKs.

| **Output Name**             | **Description**                                             |
|-----------------------------|-------------------------------------------------------------|
| `python_regenerated`         | Indicates if the Python SDK was regenerated.               |
| `python_directory`           | Directory where the Python SDK was generated.              |
| `typescript_regenerated`     | Indicates if the TypeScript SDK was regenerated.           |
| `typescript_directory`       | Directory where the TypeScript SDK was generated.          |
| `java_regenerated`           | Indicates if the Java SDK was regenerated.                 |
| `java_directory`             | Directory where the Java SDK was generated.                |
| `go_regenerated`             | Indicates if the Go SDK was regenerated.                   |
| `go_directory`               | Directory where the Go SDK was generated.                  |
| `php_regenerated`            | Indicates if the PHP SDK was regenerated.                  |
| `php_directory`              | Directory where the PHP SDK was generated.                 |
| `ruby_regenerated`           | Indicates if the Ruby SDK was regenerated.                 |
| `ruby_directory`             | Directory where the Ruby SDK was generated.                |
| `swift_regenerated`          | Indicates if the Swift SDK was regenerated.                |
| `swift_directory`            | Directory where the Swift SDK was generated.               |
| `terraform_regenerated`      | Indicates if the Terraform SDK was regenerated.            |
| `terraform_directory`        | Directory where the Terraform SDK was generated.           |
| `docs_regenerated`           | Indicates if the SDK documentation was regenerated.        |
| `branch_name`                | The branch name used for generating the SDK or the PR.     |
| `commit_hash`                | The commit hash generated for the SDK (in direct mode).    |


 This is the content for the doc docs/speakeasy-reference/generation/csharp-config.mdx 

 
import { Callout } from "~/components";

# C# configuration options

 This section details the available configuration options for the C# SDK. All configuration is managed in the `gen.yaml` file under the `csharp` section.

## Version and general configuration

```yml
csharp:
  version: 1.2.3
  author: "Your Name"
  packageName: "custom-sdk"
  dotnetVersion: "net8.0"
```

| Name                   | Required | Default Value | Description                                                                                   |
|------------------------|----------|---------------|-----------------------------------------------------------------------------------------------|
| `version`              | true     | `0.0.1`       | The current version of the SDK.                                                               |
| `packageName`           | true     | `openapi`     | The [NuGet package ID]( https://learn.microsoft.com/en-us/dotnet/standard/design-guidelines/names-of-namespaces), also used as the root namespace. |
| `author`               | true     | `Speakeasy`   | The name of the [author](https://learn.microsoft.com/en-us/nuget/create-packages/package-authoring-best-practices#authors) of the published package. |
| `dotnetVersion`               | false    | `dotnetVersion`   | The [version](https://learn.microsoft.com/en-us/dotnet/standard/frameworks) of .NET to target. net8.0 (default), net6.0 and net5.0 supported. |

## Publishing configuration
```yml
csharp:
  packageTags: "openapi sdk rest"
  includeDebugSymbols: true
  enableSourceLink: true
```

| Name                | Required | Default Value | Description                                                                                               |
|---------------------|----------|---------------|-----------------------------------------------------------------------------------------------------------|
| `packageTags`        | false    | `""`          | Space-delimited list of tags and keywords used when searching for packages on NuGet.                       |
| `includeDebugSymbols`| false    | `false`       | Whether to generate `.pdb` files and publish a `.snupkg` symbol package to NuGet.                          |
| `enableSourceLink`   | false    | `false`       | Whether to produce and publish the package with Source Link. See [Source Link](https://github.com/dotnet/sourcelink). |

## Additional dependencies

```yml
csharp:
  additionalDependencies:
    - "Newtonsoft.Json"
    - "RestSharp"
```
| Name                        | Required | Default Value                | Description                                                                                   |
|-----------------------------|----------|------------------------------|-----------------------------------------------------------------------------------------------|
| `additionalDependencies`               | false    | `[]`                         | Add additional dependencies to include in the generated `.csproj` file.                           |


## Method and parameter management
```yml
csharp:
  maxMethodParams: 4
```

| Name                       | Required | Default Value               | Description                                                                                   |
|----------------------------|----------|-----------------------------|-----------------------------------------------------------------------------------------------|
| `maxMethodParams`           | false    | `4`                         | Maximum number of parameters before an input object is created. `0` means input objects are always used. |

## Security configuration

```yml
csharp:
  flattenGlobalSecurity: true
```
| Property                        | Description                                                                                              | Type     | Default   |
|---------------------------------|----------------------------------------------------------------------------------------------------------|----------|-----------|
| `flattenGlobalSecurity`         | Enables inline security credentials during SDK instantiation. **Recommended: `true`**                    | boolean  | `true`    |

## Module management

```yml
csharp:
  sourceDirectory: "src"
  disableNamespacePascalCasingApr2024: false
```
| Name                    | Required | Default Value     | Description                                                                                   |
|-------------------------|----------|-------------------|-----------------------------------------------------------------------------------------------|
| `sourceDirectory`        | false    | `src`            | The name of the source directory.                                     |
| `disableNamespacePascalCasingApr2024`    | false    | `false`        | Whether to disable Pascal Casing sanitization on the `packageName` when setting the root namespace and NuGet package ID.      |

## Import management

```yml
csharp:
  imports:
    option: "openapi"
    paths:
      callbacks: models/callbacks
      errors: models/errors
      operations: models/operations
      shared: models/components
      webhooks: models/webhooks
```
| Field   | Required | Default Value | Description                                                                                   |
|---------|----------|---------------|-----------------------------------------------------------------------------------------------|
| `option`| false    | `"openapi"`   | Defines the type of import strategy. Typically set to `"openapi"`, indicating that the structure is based on the OpenAPI document. |
| `paths` | false    | `{}`          | Customizes where different parts of the SDK (e.g., callbacks, errors, and operations) will be imported from. |

### Import paths

| Component      | Default Value              | Description                                                                                                   |
|----------------|----------------------------|---------------------------------------------------------------------------------------------------------------|
| `callbacks`    | `models/callbacks`          | The directory where callback models will be imported from.                                                     |
| `errors`       | `models/errors`             | The directory where error models will be imported from.                                                        |
| `operations`   | `models/operations`         | The directory where operation models (i.e., API endpoints) will be imported from.                              |
| `shared`       | `models/components`         | The directory for shared components, such as reusable schemas, and data models, imported from the OpenAPI spec. |
| `webhooks`     | `models/webhooks`           | The directory for webhook models, if your SDK includes support for webhooks.                                   |

## Error and response handling
```yml
csharp:
  clientServerStatusCodesAsErrors: true
  responseFormat: "envelope-http"
```
| Name                            | Required | Default Value   | Description                                                                                               |
|---------------------------------|----------|-----------------|-----------------------------------------------------------------------------------------------------------|
| `responseFormat`                | false    | `envelope-http` | Defines how responses are structured. Options: `envelope`, `envelope-http`, or `flat`.                     |
| `clientServerStatusCodesAsErrors`| false    | `true`          | Treats `4XX` and `5XX` status codes as errors. Set to `false` to treat them as normal responses.           |


 This is the content for the doc docs/speakeasy-reference/generation/gen-yaml.mdx 

 import Image from "next/image";
import { Tabs } from "@speakeasy/nextra-theme";
import { ScrollyCoding } from "~/components/codehike/Scrollycoding";
import { Callout } from "~/components";
import vsCodeImageUrl from "../../assets/vscode.svg";

# The gen.yaml file reference

<Callout title="TIP" variant="info">

For most use cases, the `speakeasy configure` command is the recommended means of interacting with the Speakeasy `gen.yaml` file. The `speakeasy configure` command has subcommands for configuring sources, targets, GitHub workflow setups, and package publications. All new targets created using `speakeasy quickstart` automatically generate workflow files in the `.speakeasy/` folder in the root of the target directory.

The <Image src={vsCodeImageUrl} alt="VS Code" width="20" height="20" style={{display: "inline-block"}} /> [Speakeasy VS Code extension](https://marketplace.visualstudio.com/items?itemName=Speakeasy.speakeasy-vscode-extension) provides several useful features for manually editing the `gen.yaml` file, including syntax highlighting, autocompletion, and linting for OpenAPI documents and other supported file types.

</Callout>

The `gen.yaml` file has several sections:

- The `generation` section is essential for SDK configuration
- The `management` and `features` sections are maintained by Speakeasy and should not be edited
- The final section is for language-specific configuration (for more information, see the language-specific configuration docs)

## Generation

<ScrollyCoding>

#### !!steps `configVersion`

The currently supported version of the Speakeasy `gen.yaml` configuration file is `2.0.0`. Older versions will be automatically upgraded when encountered.

```yaml ! gen.yaml
# !focus(1)
configVersion: 2.0.0
generation:
  sdkClassName: speakeasybar
  maintainOpenAPIOrder: true
  usageSnippets:
    optionalPropertyRendering: withExample
  devContainers:
    enabled: true
    schemaPath: "path/to/schema"
  useClassNamesForArrayFields: true
  fixes:
    nameResolutionDec2023: true
    parameterOrderingFeb2024: true
    requestResponseComponentNamesFeb2024: true
  auth:
    OAuth2ClientCredentialsEnabled: true
  baseServerUrl: "speakeasy.bar/public/api/"
  mockServer:
    disabled: true
# Add language-specific configs here
```

---

#### !!steps `generation`

The `generation` section of the `gen.yaml` file supports configuration that is relevant to all SDK targets. If a value isn't configured here, and it has a default value, then that value will be added automatically on the next generation. For more information about SDK generation and targets, see our [core concepts documentation](/docs/core-concepts#sdk-generation).

```yaml ! gen.yaml
# !focus(2:17)
```

---

#### !!steps `sdkClassName`

Defines the class name of the main imported class in the generated SDK.

```yaml ! gen.yaml
# !focus(3)
```

---

#### !!steps `maintainOpenAPIOrder`

Determines whether the parameters, properties, operations, etc., are maintained in the same order they appear in the OpenAPI document. If set to `false`, these elements are sorted alphabetically.

```yaml ! gen.yaml
# !focus(4)
```

---

#### !!steps `usageSnippets`

The options for `optionalPropertyRendering` include `always`, `never`, and `withExample`, which renders optional properties only when an example is present in the OpenAPI document.

```yaml ! gen.yaml
# !focus(5:6)
```

---

#### !!steps `devContainers`

Enables or disables the use of development containers, and specifies the schema path. For more information about development containers and SDK sandboxes, see our [SDK sandbox documentation](/docs/manage/sdk-sandbox).

```yaml ! gen.yaml
# !focus(7:9)
```

---

#### !!steps `useClassNamesForArrayFields`

When set to true, array fields use class names instead of child schema types.

```yaml ! gen.yaml
# !focus(10)
```

---

#### !!steps `fixes`

Includes specific fixes or features to be applied during SDK generation to avoid breaking changes.

- `nameResolutionDec2023`: **Disabling not recommended**. Enables changes introduced in December 2023 for improved name resolution, defaults to `true` for new SDKs. For older SDKs, setting `true` is recommended, but will be a breaking change.  
- `parameterOrderingFeb2024`: **Disabling not recommended**. Enables changes introduced in February 2024 to respect the order of parameters in the OpenAPI document where possible, defaults to `true` for new SDKs. For older SDKs, setting `true` is recommended, but will be a breaking change.  
- `requestResponseComponentNamesFeb2024`: **Disabling not recommended**. Enables changes introduced in February 2024 to use the name of parent request/response components where possible, defaults to `true` for new SDKs. For older SDKs, setting `true` is recommended, but will be a breaking change.

```yaml ! gen.yaml
# !focus(11:14)
```

---

#### !!steps `auth`

- `OAuth2ClientCredentialsEnabled`: Enables the generation of code for handling OAuth 2.0 client credentials for authentication, where possible. **Enterprise license only**.

For detailed information about authentication configuration, see our [guide to customizing security and authentication](/docs/customize/authentication/configuration).

```yaml ! gen.yaml
# !focus(15:16)
```

---

#### !!steps `baseServerUrl`

Used to declare your base server URL. It overrides the `servers` field in your OpenAPI document if present, or provides a server URL if the `servers` field is absent.

```yaml ! gen.yaml
# !focus(17)
```

---

#### !!steps `mockServer`

Disables the generation and use of a mock HTTP server with generated tests.

```yaml ! gen.yaml
# !focus(18)
```

---

</ScrollyCoding>


 This is the content for the doc docs/speakeasy-reference/generation/go-config.mdx 

 

# Go configuration options

 This section details the available configuration options for the Go SDK. All configuration is managed in the `gen.yaml` file under the `go` section.

## Version and general configuration

```yml
go:
  version: 1.2.3
  packageName: "custom-sdk"
```

| Name          | Required | Default Value | Description                                                                                                      |
|---------------|----------|---------------|------------------------------------------------------------------------------------------------------------------|
| `version`     | true     | `0.0.1`       | The current version of the SDK. |
| `packageName` | true     | `openapi`     | The Go module package name. See [Go Module Path Documentation](https://go.dev/ref/mod#module-path). |

## Additional dependencies

```yml
go:
  additionalDependencies:
    dependencies:
      axios: "^0.21.0"
```
| Name                        | Required | Default Value  | Description                                                                                                                                |
|-----------------------------|----------|----------------|--------------------------------------------------------------------------------------------------------------------------------------------|
| `additionalDependencies`     | false    | `{}`           | Add additional dependencies to include in the generated `go.mod`.                                                                      |

## Method and parameter management
```yml
go
  maxMethodParams: 4
  methodArguments: "require-security-and-request"
```

| Name                            | Required | Default Value  | Description                                                                                                                                   |
|---------------------------------|----------|----------------|-----------------------------------------------------------------------------------------------------------------------------------------------|
| `maxMethodParams`               | false    | `4`            | The maximum number of parameters a method can have before the resulting SDK endpoint is no longer "flattened" and an input object is created. `0` will use input objects always. Must match the regex pattern `/^\d+$/`." |
| `methodArguments`               | false    | `require-security-and-request` | Determines how arguments for SDK methods are generated. Options: `"infer-optional-args"` or `"require-security-and-request"`. |

## Security configuration

```yml
go
  envVarPrefix: SPEAKEASY
  flattenGlobalSecurity: true
```


| Name                            | Required | Default Value  | Description                                                                                                                                |
|---------------------------------|----------|----------------|--------------------------------------------------------------------------------------------------------------------------------------------|
| `clientServerStatusCodesAsErrors`| false    | `true`         | Whether to treat `4xx` and `5xx` status codes as errors. |
| `flattenGlobalSecurity`         | false    | `newSDK`       | Flatten the global security configuration if there is only a single option in the spec.                                                     |
                                                                                  |


## Import management

```yml
go
  imports:
    paths:
      callbacks: models/callbacks
      errors: models/errors
      operations: models/operations
      shared: models/components
      webhooks: models/webhooks
```

| Path        | Default Value         | Description                                                                                                |
|-------------|-----------------------|------------------------------------------------------------------------------------------------------------|
| `shared`    | `models/components`   | The directory for shared components, such as reusable schemas, and data models.                                                                  |
| `operations`| `models/operations`   | The directory where operation models (i.e., API endpoints) will be imported from.                                                                 |
| `errors`    | `models/sdkerrors`    | The directory where error models will be imported from.                                                                                           |
| `callbacks` | `models/callbacks`    | The directory where callback models will be imported from.                                                                                         |
| `webhooks`  | `models/webhooks`     | The directory where webhook models will be imported from.                                                                                          |

## Error and response handling
```yml
go:
  responseFormat: "envelope-http"
```
| Name                            | Required | Default Value  | Description                                                                                                                                |
|---------------------------------|----------|----------------|--------------------------------------------------------------------------------------------------------------------------------------------|
| `responseFormat`                | false    | `envelope-http` | Determines the shape of the response envelope that is returned from SDK methods. Must be `envelope-http`, `envelope`, or `flat` only.' |


 This is the content for the doc docs/speakeasy-reference/generation/java-config.mdx 

 

# Java Configuration Options

 This section details the available configuration options for the Java SDK. All configuration is managed in the `gen.yaml` file under the `java` section.

## Version and general configuration

```yml
java:
  version: 1.2.3
  projectName: "openapi"
```

| Name            | Required | Default Value | Description                                                                                     |
|-----------------|----------|---------------|-------------------------------------------------------------------------------------------------|
| `version`       | true     | `0.0.1`       | The current version of the SDK.                                                                 |
| `projectName`   | true     | `openapi`     | Assigns Gradle `rootProject.name`, which names the Gradle build. See [Gradle Naming](https://docs.gradle.org/current/userguide/multi_project_builds.html#naming_recommendations). |

## Publishing

```yml
java:
  groupID: "com.mycompany"
  artifactID: "my-sdk"
  ossrhURL: "https://s01.oss.sonatype.org/service/local/staging/deploy/maven2/"
  githubURL: "https://github.com/mycompany/my-sdk"
  companyName: "My Company"
  companyURL: "https://www.mycompany.com"
  companyEmail: "support@mycompany.com"
```
| Name            | Required | Default Value       | Description                                                                                     |
|-----------------|----------|---------------------|-------------------------------------------------------------------------------------------------|
| `groupID`       | true     | `org.openapis`      | The group ID used for namespacing the package. Typically the reversed domain of your organization. |
| `artifactID`    | true     | `openapi`           | The artifact ID used for namespacing the package, usually the name of the project.               |
| `ossrhURL`      | false    | N/A                 | The URL of the staging repository to publish the SDK artifact to.                                |
| `githubURL`     | for publishing | `github.com/owner/repo` | The GitHub URL where the artifact is hosted. Sets metadata required by Maven.                    |
| `companyName`   | for publishing | `My Company`        | The name of your company. Sets metadata required by Maven.                                       |
| `companyURL`    | for publishing | `www.mycompany.com`  | Your company's homepage URL. Sets metadata required by Maven.                                    |
| `companyEmail`  | for publishing | `info@mycompany.com` | A support email address for your company. Sets metadata required by Maven.                       |

## Additional Dependencies

```yml
java:
  additionalDependencies:
    - "implementation:com.fasterxml.jackson.core:jackson-databind:2.12.3"
    - "testImplementation:junit:junit:4.13.2"
```

| Name                   | Required | Default Value                | Description                                                                                               |
|------------------------|----------|------------------------------|-----------------------------------------------------------------------------------------------------------|
| `additionalDependencies`| false    | `[]`                         | Adds additional dependencies to include in `build.gradle`. Format: `scope:groupId:artifactId:version`.  |
| `additionalPlugins`     | false    | `[]`                         | Adds additional plugins to include in `build.gradle`. Format: `id("plugin.id") version "x.x.x"`.        |

## License

```yml
java:
  license:
    name: "The MIT License (MIT)"
    url: "https://mit-license.org/"
    shortName: "MIT"
```

| Name    | Required | Default Value                                  | Description                                                                                               |
|---------|----------|------------------------------------------------|-----------------------------------------------------------------------------------------------------------|
| `license`| false   | MIT License | License information. Defaults to the MIT license if not provided.                                |


## Method and parameter management
```yml
java:
  maxMethodParams: 4
```

| Name               | Required | Default Value               | Description                                                                                               |
|--------------------|----------|-----------------------------|-----------------------------------------------------------------------------------------------------------|
| `maxMethodParams`   | false    | `4`                         | Maximum number of parameters before an input object is created. `0` means input objects are always used.   |


## Security configuration

```yml
java:
  flattenGlobalSecurity: true
```
| Property                        | Description                                                                                              | Type     | Default   |
|---------------------------------|----------------------------------------------------------------------------------------------------------|----------|-----------|
| `flattenGlobalSecurity`         | Enables inline security credentials during SDK instantiation. **Recommended: `true`**                    | boolean  | `true`    |

## Module management

```yml
java:
  moduleFormat: "dual"
  useIndexModules: true
```
| Name                    | Required | Default Value     | Description                                                                                   |
|-------------------------|----------|-------------------|-----------------------------------------------------------------------------------------------|
| `useIndexModules`        | false    | `true`            | Determines if index modules (`index.ts`) are generated.                                        |
| `moduleFormat`           | false    | `commonjs`        | Sets the module format to use when compiling the SDK (`commonjs`, `esm`, or `dual`).      |

## Import management

```yml
java:
  imports:
    paths:
      callbacks: models/callbacks
      errors: models/errors
      operations: models/operations
      shared: models/components
      webhooks: models/webhooks
```
| Field   | Required | Default Value | Description                                                                                   |
|---------|----------|---------------|-----------------------------------------------------------------------------------------------|
| `paths` | false    | `{}`          | Customizes where different parts of the SDK (e.g., callbacks, errors, and operations) will be imported from. |

### Import paths

| Component      | Default Value              | Description                                                                                                   |
|----------------|----------------------------|---------------------------------------------------------------------------------------------------------------|
| `callbacks`    | `models/callbacks`          | The directory where callback models will be imported from.                                                     |
| `errors`       | `models/errors`             | The directory where error models will be imported from.                                                        |
| `operations`   | `models/operations`         | The directory where operation models (i.e., API endpoints) will be imported from.                              |
| `shared`       | `models/components`         | The directory for shared components, such as reusable schemas and data models, imported from the OpenAPI spec. |
| `webhooks`     | `models/webhooks`           | The directory for webhook models, if your SDK includes support for webhooks.                                   |

## Error and response handling
```yml
java:
  clientServerStatusCodesAsErrors: false
```
| Name                            | Required | Default Value   | Description                                                                                               |
|---------------------------------|----------|-----------------|-----------------------------------------------------------------------------------------------------------|
| `clientServerStatusCodesAsErrors`| false   | `true`          | Whether to treat 4xx and 5xx status codes as errors. Options: `true` or `false`.                           |


 This is the content for the doc docs/speakeasy-reference/generation/php-config.mdx 

 
import { Callout } from "~/components";

# PHP Configuration Options

 This section details the available configuration options for the PHP SDK. All configuration is managed in the `gen.yaml` file under the `php` section.

## Version and general configuration

```yml
php:
  version: 1.2.3
  packageName: "openapi/openapi"
  namespace: "OpenAPI\\OpenAPI"
```

| Name          | Required | Default Value      | Description                                                                                                                        |
|---------------|----------|--------------------|------------------------------------------------------------------------------------------------------------------------------------|
| `version`     | true     | `0.0.1`            | The current version of the SDK.                                                                                                    |
| `packageName` | true     | `openapi/openapi`  | The name of the composer package. See [Composer Package Naming](https://getcomposer.org/doc/04-schema.md#name).                    |
| `namespace`   | true     | `OpenAPI\\OpenAPI` | The namespace for the package. See [PHP Namespace Documentation](https://www.php.net/manual/en/language.namespaces.rationale.php). |


## Method and parameter management
```yml
php:
  maxMethodParams: 4
```

| Name              | Required | Default Value | Description                                                                                              |
|-------------------|----------|---------------|----------------------------------------------------------------------------------------------------------|
| `maxMethodParams` | false    | `4`           | Sets the maximum number of parameters before an input object is created. `0` means input objects are always used. |


## Security configuration

```yml
php:
  flattenGlobalSecurity: true
```
| Property                | Description                                                                           | Type    | Default |
|-------------------------|---------------------------------------------------------------------------------------|---------|---------|
| `flattenGlobalSecurity` | Enables inline security credentials during SDK instantiation. **Recommended: `true`** | boolean | `true`  |


## Import management

```yml
php:
  imports:
    option: "openapi"
    paths:
      callbacks: models/Callbacks
      errors: models/Errors
      operations: models/Operations
      shared: models/Components
      webhooks: models/Webhooks
```

| Field    | Required | Default Value | Description                                                                                                                        |
|----------|----------|---------------|------------------------------------------------------------------------------------------------------------------------------------|
| `option` | false    | `"openapi"`   | Defines the type of import strategy. Typically set to `"openapi"`, indicating that the structure is based on the OpenAPI document. |
| `paths`  | false    | `{}`          | Customizes where different parts of the SDK (e.g., callbacks, errors, operations) will be imported from.                           |

### Import paths

| Component    | Default Value       | Description                                                                                                    |
|--------------|---------------------|----------------------------------------------------------------------------------------------------------------|
| `callbacks`  | `models/callbacks`  | The directory where callback models will be imported from.                                                      |
| `errors`     | `models/errors`     | The directory where error models will be imported from.                                                         |
| `operations` | `models/operations` | The directory where operation models (i.e., API endpoints) will be imported from.                               |
| `shared`     | `models/components` | The directory for shared components, such as reusable schemas, and data models imported from the OpenAPI spec.  |
| `webhooks`   | `models/webhooks`   | The directory for webhook models, if your SDK includes support for webhooks.                                    |

## Error and Response Handling

```yml
php:
  clientServerStatusCodesAsErrors: true
  responseFormat: "flat"
  enumFormat: "enum"
```
| Name                              | Required | Default Value | Description                                                                            |
|-----------------------------------|----------|---------------|----------------------------------------------------------------------------------------|
| `clientServerStatusCodesAsErrors` | false    | `true`        | Whether to treat 4XX and 5XX status codes as errors.                                  |
| `responseFormat`                  | false    | `flat`        | Defines how responses are structured. Options: `envelope`, `envelope-http`, or `flat`.  |

## Laravel service provider

If your PHP SDK is being used within a Laravel application, Speakeasy is able to generate the needed [Service Provider](https://laravel.com/docs/master/providers)
code to support seamless integration.

> ...all of Laravel's core services, are bootstrapped via service providers.
>
> But, what do we mean by "bootstrapped"? In general, we mean registering things, including registering service container bindings, event listeners, middleware, and even routes. Service providers are the central place to configure your application.


To enable the Laravel Service Provider generation, update the `gen.yaml` configuration setting `enabled` to `true`, and set `svcName` appropriately.

```yml
php:
  laravelServiceProvider:
    enabled: true
    svcName: "openapi"
```

| Field                    | Required | Default Value | Description                                       |
|--------------------------|----------|---------------|---------------------------------------------------|
| `laravelServiceProvider` | false    | `{}`          | Configure the generation of the Service Provider. |

### Laravel service provider configuration

| Field     | Required | Default Value | Description                                        |
|-----------|----------|---------------|----------------------------------------------------|
| `enabled` | false    | false         | Set to true to enable Service Provider generation. |
| `svcName` | false    | `"openapi"`   | The name to be used for the service provider.     |

## Additional dependencies

```yml
php:
 additionalDependencies: {
    "autoload": {
      "OpenAPI\\OpenAPI\\Lib\\": "lib/"
    },
    "autoload-dev": {
      "OpenAPI\\OpenAPI\\Test\\": "Tests/"
      },
    "require": {
      "firebase/php-jwt": "^6.10",
      "phpseclib/phpseclib": "^3.0"
    },
    "require-dev": {
      "monolog/monolog": "^3.0"
    }
  }
```

| Field                    | Required | Default Value | Description                                                                                             |
|--------------------------|----------|---------------|---------------------------------------------------------------------------------------------------------|
| `additionalDependencies` | false    | `{}`          | Adds additional dependencies and autoload mappings to the generated `composer.json` file. |

### Additional dependencies configuration

| Name           | Required | Default Value | Description                                                                                        |
|----------------|----------|---------------|----------------------------------------------------------------------------------------------------|
| `autoload`     | false    | `{}`          | Defines autoload mappings for the `autoload.psr4` section.                                   |
| `autoload-dev` | false    | `{}`          | Defines autoload mappings for the `autoload-dev.psr4` section (for development and testing). |
| `require`      | false    | `{}`          | Adds additional dependencies to the `require` section.                                   |
| `require-dev`  | false    | `{}`          | Adds additional dependencies to the `require-dev` section (for development and testing). |


 This is the content for the doc docs/speakeasy-reference/generation/python-config.mdx 

 
import { Callout } from "~/components";

# Python Configuration Options

 This section details the available configuration options for the Python SDK. All configuration is managed in the `gen.yaml` file under the `python` section.

## Version and general configuration

```yml
python:
  version: 1.2.3
  authors: ["Your Name"]
  packageName: "openapi"
```

| Name              | Required | Default Value | Description                                                                                     |
|-------------------|----------|---------------|-------------------------------------------------------------------------------------------------|
| `version`         | true     | `0.0.1`       | The current version of the SDK.                                                                 |
| `packageName`     | true     | `openapi`     | The distribution name of the PyPI package. See [Python Package Metadata](https://docs.python.org/3.11/distutils/setupscript.html#additional-meta-data). |
| `authors`         | true     | `["Speakeasy"]`| Authors of the published package. See [Poetry Authors Field](https://python-poetry.org/docs/pyproject/#authors). |

## Description and URLs
```yml
python:
  description: "Python Client SDK Generated by Speakeasy."
  homepage: "https://example.com"
  documentationUrl: "https://example.com/docs"
```
| Name               | Required | Default Value                                      | Description                                                                                           |
|--------------------|----------|---------------------------------------------------|-------------------------------------------------------------------------------------------------------|
| `description`      | false    | `"Python Client SDK Generated by Speakeasy."`      | A short description of the project. See [Poetry Description Field](https://python-poetry.org/docs/pyproject/#description). |
| `homepage`         | false    | `null`                                             | The URL for the homepage of the project.                                                              |
| `documentationUrl` | false    | `null`                                             | The URL for the project documentation.                                                                |

## Additional dependencies

```yml
python:
  additionalDependencies:
    main:
      requests: "^2.25.1"
    dev:
      pytest: "^6.2.1"
```
| Name                        | Required | Default Value                | Description                                                                                               |
|-----------------------------|----------|------------------------------|-----------------------------------------------------------------------------------------------------------|
| `additionalDependencies`     | false    | `{}`                         | Add additional dependencies to include in the generated `pyproject.toml` file.                         |


## Method and parameter management
```yml
python:
  maxMethodParams: 4
  flatteningOrder: "parameters-first"
  methodArguments: "infer-optional-args"
```

| Name                       | Required | Default Value               | Description                                                                                   |
|----------------------------|----------|-----------------------------|-----------------------------------------------------------------------------------------------|
| `flattenRequests`          | false    | `true`                         | Turn request parameters and body fields into a flat list of method arguments. This takes precedence over maxMethodParams. If there is no request body then maxMethodParams will be respected. |
| `maxMethodParams`          | false    | `9999`                         | Maximum number of parameters before an input object is generated. `0` means input objects are always used. |
| `flatteningOrder`          | false    | `parameters-first` | Determines the ordering of method arguments when flattening parameters and body fields.  `parameters-first` or `body-first`       |
| `methodArguments`          | false    | `require-security-and-request` | Determines how arguments for SDK methods are generated.                                        |


## Security configuration

```yml
python:
  envVarPrefix: "SPEAKEASY"
  flattenGlobalSecurity: true
```
| Name                    | Required | Default Value | Description                                                                                               |
|-------------------------|----------|---------------|-----------------------------------------------------------------------------------------------------------|
| `flattenGlobalSecurity`  | false    | `true`        | Enables inline security credentials during SDK instantiation.                                              |
| `envVarPrefix`           | false    | `""`          | Sets a prefix for environment variables that allows users to configure global parameters and security.      |

## Import management

```yml
python:
  imports:
    option: "openapi"
    paths:
      callbacks: "models/callbacks"
      errors: "models/errors"
      operations: "models/operations"
      shared: "models/shared"
      webhooks: "models/webhooks"
```
| Field   | Required | Default Value | Description                                                                                   |
|---------|----------|---------------|-----------------------------------------------------------------------------------------------|
| `option`| false    | `"openapi"`   | Defines the type of import strategy. Typically set to `"openapi"`, indicating that the structure is based on the OpenAPI document. |
| `paths` | false    | `{}`          | Customizes where different parts of the SDK (e.g., callbacks, errors, and operations) will be imported from. |

### Import paths

| Component      | Default Value              | Description                                                                                                   |
|----------------|----------------------------|---------------------------------------------------------------------------------------------------------------|
| `callbacks`    | `models/callbacks`          | The directory where callback models will be imported from.                                                      |
| `errors`       | `models/errors`             | The directory where error models will be imported from.                                                         |
| `operations`   | `models/operations`         | The directory where operation models (i.e., API endpoints) will be imported from.                               |
| `shared`       | `models/components`         | The directory for shared components, such as reusable schemas, and data models imported from the OpenAPI spec.  |
| `webhooks`     | `models/webhooks`           | The directory for webhook models, if your SDK includes support for webhooks.                                    |

## Error and response handling
```yml
python:
  clientServerStatusCodesAsErrors: true
  responseFormat: "flat"
  enumFormat: "enum"
```
| Name                           | Required | Default Value   | Description                                                                                               |
|--------------------------------|----------|-----------------|-----------------------------------------------------------------------------------------------------------|
| `clientServerStatusCodesAsErrors`| false   | `true`           | Whether to treat 4XX and 5XX status codes as errors.                                                       |
| `responseFormat`               | false    | `flat`          | Defines how responses are structured. Options: `envelope`, `envelope-http`, or `flat`.                      |
| `enumFormat`                   | false    | `enum`          | Determines how enums are generated. Options: `enum` (Python enums) or `union` (union types).               |


 This is the content for the doc docs/speakeasy-reference/generation/ruby-config.mdx 

 
import { Callout } from "~/components";

# Ruby Configuration Options

 This section details the available configuration options for the Ruby SDK. All configuration is managed in the `gen.yaml` file under the `ruby` section.

## Version and general configuration

```yml
ruby:
  version: 1.2.3
  author: "Your Name"
  packageName: "custom-sdk"
```

| Name                   | Required | Default Value | Description                                                                                   |
|------------------------|----------|---------------|-----------------------------------------------------------------------------------------------|
| `version`              | true     | `0.0.1`       | The current version of the SDK.                                                               |
| `packageName`           | true     | `openapi`     | The name of the package.  |
| `author`               | true     | `Speakeasy`   | The name of the author of the published package. |


## Method and parameter management
```yml
ruby:
  maxMethodParams: 4
```

| Name                       | Required | Default Value               | Description                                                                                   |
|----------------------------|----------|-----------------------------|-----------------------------------------------------------------------------------------------|
| `maxMethodParams`           | false    | `4`                         | Sets the maximum number of parameters before an input object is created. `0` means input objects are always used. |


## Module management

```yml
ruby:
  module: "OpenApiSdk"
```
| Name                    | Required | Default Value     | Description                                                                                   |
|-------------------------|----------|-------------------|-----------------------------------------------------------------------------------------------|
| `module`        | true   | `OpenAPISdk`            | [See Docs](https://ruby-doc.org/core-2.5.3/Module.html).                                  |

## Import management

```yml
ruby:
  imports:
    option: "openapi"
    paths:
      callbacks: models/callbacks
      errors: models/errors
      operations: models/operations
      shared: models/components
      webhooks: models/webhooks
```
| Field   | Required | Default Value | Description                                                                                   |
|---------|----------|---------------|-----------------------------------------------------------------------------------------------|
| `option`| false    | `"openapi"`   | Defines the type of import strategy. Typically set to `"openapi"`, indicating that the structure is based on the OpenAPI document. |
| `paths` | false    | `{}`          | Customizes where different parts of the SDK (e.g., callbacks, errors, and operations) will be imported from. |

### Import paths

| Component      | Default Value              | Description                                                                                                   |
|----------------|----------------------------|---------------------------------------------------------------------------------------------------------------|
| `callbacks`    | `models/callbacks`          | The directory where callback models will be imported from.                                                      |
| `errors`       | `models/errors`             | The directory where error models will be imported from.                                                         |
| `operations`   | `models/operations`         | The directory where operation models (i.e., API endpoints) will be imported from.                               |
| `shared`       | `models/components`         | The directory for shared components, such as reusable schemas, and data models imported from the OpenAPI spec.  |
| `webhooks`     | `models/webhooks`           | The directory for webhook models, if your SDK includes support for webhooks.                                    |



 This is the content for the doc docs/speakeasy-reference/generation/swift-config.mdx 

 # Swift configuration options

 This section details the available configuration options for the Swift SDK. All configuration is managed in the `gen.yaml` file under the `swift` section.

## General configuration

```yml
swift:
  version: 1.2.3
  author: "Speakeasy"
  packageName: "openapi"
  description: "Swift Client SDK Generated by Speakeasy"
```

| Name                   | Required | Default Value                  | Description                                                                                               |
|------------------------|----------|--------------------------------|-----------------------------------------------------------------------------------------------------------|
| `version`              | true     | `0.0.1`                        | The current version of the SDK.                                                                            |
| `packageName`          | true     | `OpenAPI`                      | The name of the Swift Package Manager (SPM) package.                                                       |
| `author`               | true     | `Speakeasy`                    | The name of the author of the published package.                                                           |
| `description`          | true     | `Swift Client SDK Generated by Speakeasy` | A short description of the SDK.                                                                            |
| `documentationBaseURL` | false    | `""`                           | The base URL to the hosted documentation site.                                                             |

## Import management

```yml
swift:
  imports:
    option: "openapi"
    paths:
      callbacks: models/callbacks
      errors: models/errors
      operations: models/operations
      shared: models/components
      webhooks: models/webhooks
```
| Field   | Required | Default Value | Description                                                                                   |
|---------|----------|---------------|-----------------------------------------------------------------------------------------------|
| `option`| false    | `"openapi"`   | Defines the type of import strategy. Typically set to `"openapi"`, indicating that the structure is based on the OpenAPI document. |
| `paths` | false    | `{}`          | Customizes where different parts of the SDK (e.g., callbacks, errors, and operations) will be imported from. |

### Import paths

| Component      | Default Value              | Description                                                                                                   |
|----------------|----------------------------|---------------------------------------------------------------------------------------------------------------|
| `callbacks`    | `models/callbacks`          | The directory where callback models will be imported from.                                                     |
| `errors`       | `models/errors`             | The directory where error models will be imported from.                                                        |
| `operations`   | `models/operations`         | The directory where operation models (i.e., API endpoints) will be imported from.                              |
| `shared`       | `models/components`         | The directory for shared components, such as reusable schemas, and data models imported from the OpenAPI spec. |
| `webhooks`     | `models/webhooks`           | The directory for webhook models, if your SDK includes support for webhooks.                                   |



 This is the content for the doc docs/speakeasy-reference/generation/terraform-config.mdx 

 
import { Callout } from "~/components";

# Terraform configuration options

 This section details the available configuration options for the Terraform SDK. All configuration is managed in the `gen.yaml` file under the `terraform` section.

## Version and general configuration

```yml
terraform:
  version: 1.2.3
  author: "Your Name"
  packageName: "custom-sdk"
```

| Name                   | Required | Default Value | Description                                                                                   |
|------------------------|----------|---------------|-----------------------------------------------------------------------------------------------|
| `version`              | true     | `0.0.1`       | The current version of the SDK.                                                               |
| `packageName`                     | true     | `terraform`        | The Terraform provider name.                                                                                |
| `author`                          | true     | `speakeasy`        | The name of the author of the published package.                                                            |

## Additions

```yml
terraform:
  additionalDependencies: {}
  additionalResources: []
  additionalDataSources: []
```

| Name                   | Required | Default Value | Description                                                                                   |
|------------------------|----------|---------------|-----------------------------------------------------------------------------------------------|
| `additionalDependencies`          | false    | `{}`               | Add additional dependencies to include in the generated `go.mod`.                                      |
| `additionalResources`             | false    | `[]`               | A list of `{ importLocation?: string, importAlias?: string, resource: string }` objects to insert into the provider resource list.    |
| `additionalDataSources`           | false    | `[]`               | A list of `{ importLocation?: string, importAlias?: string, datasource: string }` objects to insert into the provider data source list.  |

## Method and parameter management
```yml
terraform:
  allowUnknownFieldsInWeakUnions: false
```

| Name                       | Required | Default Value               | Description                                                                                   |
|----------------------------|----------|-----------------------------|-----------------------------------------------------------------------------------------------|
|  `allowUnknownFieldsInWeakUnions`  | false    | `false`            | Allow unknown fields in weak (undiscriminated) unions.                                                     |

## Environment variables

```yml
terraform:
  environmentVariables: []
```

| Name                       | Required | Default Value               | Description                                                                                   |
|----------------------------|----------|-----------------------------|-----------------------------------------------------------------------------------------------|
| `environmentVariables`            | false    | `[]`               | A list of objects with `[env: string, providerAttribute: string]` keys/values to associate environment variables with a provider variable. |




 This is the content for the doc docs/speakeasy-reference/generation/ts-config.mdx 

 
import { Callout } from "~/components";

# Typescript Configuration Options

 This section details the available configuration options for the TypeScript SDK. All configuration is managed in the `gen.yaml` file under the `typescript` section.

## Version and general configuration

```yml
typescript:
  version: 1.2.3
  author: "Your Name"
  packageName: "custom-sdk"
```

| Name                   | Required | Default Value | Description                                                                                   |
|------------------------|----------|---------------|-----------------------------------------------------------------------------------------------|
| `version`              | true     | `0.0.1`       | The current version of the SDK.                                                               |
| `packageName`           | true     | `openapi`     | The name of the npm package. See [npm package guidelines](https://docs.npmjs.com/package-name-guidelines). |
| `author`               | true     | `Speakeasy`   | The name of the author of the published package. See [npm author field](https://docs.npmjs.com/cli/v9/configuring-npm/package-json#people-fields-author-contributors). |

## Additional JSON package

```yml
typescript:
  additionalPackageJSON:
    license: "MIT"
```

| Name                   | Required | Default Value | Description                                                                                   |
|------------------------|----------|---------------|-----------------------------------------------------------------------------------------------|
| `additionalPackageJSON` | false    | `{}`          | Additional key/value pairs for the `package.json` file. Example: license, keywords, etc.       |

## Additional dependencies

```yml
typescript:
  additionalDependencies:
    dependencies:
      axios: "^0.21.0"
    devDependencies:
      typescript: "^4.0.0"
    peerDependencies:
      react: "^16.0.0"
```
| Name                        | Required | Default Value                | Description                                                                                   |
|-----------------------------|----------|------------------------------|-----------------------------------------------------------------------------------------------|
| `dependencies`               | false    | `{}`                         | Additional production dependencies to include in the `package.json`.                           |
| `devDependencies`            | false    | `{}`                         | Additional development dependencies to include in the `package.json`.                          |
| `peerDependencies`           | false    | `{}`                         | Peer dependencies for compatibility.                                                          |


## Method and parameter management
```yml
typescript:
  maxMethodParams: 3
  methodArguments: "require-security-and-request"
```

| Name                       | Required | Default Value               | Description                                                                                   |
|----------------------------|----------|-----------------------------|-----------------------------------------------------------------------------------------------|
| `maxMethodParams`           | false    | `0`                         | Maximum number of parameters before an input object is created. `0` means input objects are always used. |
| `flatteningOrder`           | false    | `parameters-first` or `body-first` | Determines the ordering of method arguments when flattening parameters and body fields.        |
| `methodArguments`           | false    | `require-security-and-request` | Determines how arguments for SDK methods are generated.                                        |


## Security configuration

```yml
typescript:
  envVarPrefix: SPEAKEASY
  flattenGlobalSecurity: true
```
| Property                        | Description                                                                                              | Type     | Default   |
|---------------------------------|----------------------------------------------------------------------------------------------------------|----------|-----------|
| `flattenGlobalSecurity`         | Enables inline security credentials during SDK instantiation. **Recommended: `true`**                    | boolean  | `true`    |
| `envVarPrefix`                  | Sets a prefix for environment variables that allows users to configure global parameters and security.     | string   | N/A    |

## Module management

```yml
typescript:
  moduleFormat: "dual"
  useIndexModules: true
```
| Name                    | Required | Default Value     | Description                                                                                   |
|-------------------------|----------|-------------------|-----------------------------------------------------------------------------------------------|
| `useIndexModules`        | false    | `true`            | Controls generation of index modules (`index.ts`). Setting to `false` improves tree-shaking and build performance by avoiding barrel files. |
| `moduleFormat`           | false    | `commonjs`        | Sets the module format to use when compiling the SDK (`commonjs`, `esm`, or `dual`). Using `dual` provides optimal compatibility while enabling modern bundler optimizations. |

<Callout title="Performance optimization" variant="info">
For optimal bundle size and tree-shaking performance in modern applications, we recommend using `moduleFormat: "dual"` together with `useIndexModules: false`. This combination ensures maximum compatibility while enabling the best possible bundler optimizations.

See the [module format configuration guide](/docs/customize/typescript/configuring-module-format) and [barrel files documentation](/docs/customize/typescript/disabling-barrel-files) for detailed information about these optimizations.
</Callout>

## Import management

```yml
typescript:
  imports:
    option: "openapi"
    paths:
      callbacks: models/callbacks
      errors: models/errors
      operations: models/operations
      shared: models/components
      webhooks: models/webhooks
```
| Field   | Required | Default Value | Description                                                                                   |
|---------|----------|---------------|-----------------------------------------------------------------------------------------------|
| `option`| false    | `"openapi"`   | Defines the type of import strategy. Typically set to `"openapi"`, indicating that the structure is based on the OpenAPI document. |
| `paths` | false    | `{}`          | Customizes where different parts of the SDK (e.g., callbacks, errors, and operations) will be imported from. |

### Import paths

| Component      | Default Value              | Description                                                                                                   |
|----------------|----------------------------|---------------------------------------------------------------------------------------------------------------|
| `callbacks`    | `models/callbacks`          | The directory where callback models will be imported from.                                                      |
| `errors`       | `models/errors`             | The directory where error models will be imported from.                                                         |
| `operations`   | `models/operations`         | The directory where operation models (i.e., API endpoints) will be imported from.                               |
| `shared`       | `models/components`         | The directory for shared components, such as reusable schemas, and data models imported from the OpenAPI spec.  |
| `webhooks`     | `models/webhooks`           | The directory for webhook models, if your SDK includes support for webhooks.                                    |

## Error and response handling
```yml
typescript:
  clientServerStatusCodesAsErrors: false
  responseFormat: "envelope-http"
  enumFormat: "union"
```
| Property          | Description                                                                                       | Type    | Default           |
|-------------------|---------------------------------------------------------------------------------------------------|---------|-------------------|
| `responseFormat`   | Defines how responses are structured. Options: `envelope`, `envelope-http`, or `flat`.             | string  | `envelope-http`    |
| `enumFormat`       | Determines how enums are generated. Options: `enum` (TypeScript enums) or `union` (union types).   | string  | `union`            |
| `clientServerStatusCodesAsErrors`| Treats `4XX` and `5XX` status codes as errors. Set to `false` to treat them as normal responses.         | boolean  | `true`    |


 This is the content for the doc docs/speakeasy-reference/workflow-file.mdx 

 ---
description: "Syntax reference for the Speakeasy workflow file"
slug: /workflow-file-reference/
sidbar_label: Workflow File Reference
---

import Image from "next/image";
import { ScrollyCoding } from "~/components/codehike/Scrollycoding";
import { Callout } from "~/components";
import vsCodeImageUrl from "../assets/vscode.svg";

# Speakeasy Workflow File

<Callout title="TIP" variant="info">
For most use cases we recommend interacting with the Speakeasy workflow file (`workflow.yaml`) through the `speakeasy configure` command.
This command has subcommands to configure your sources, targets, github setup and package publishing. All new targets created through `speakeasy quickstart` will automatically have a workflow
file created in the `.speakeasy/` folder in the root of their target directory.

For editing the workflow file manually, <Image src={vsCodeImageUrl} alt="VS Code" width="20" height="20" style={{display: "inline-block"}} /> [Speakeasy's VSCode extension](https://marketplace.visualstudio.com/items?itemName=Speakeasy.speakeasy-vscode-extension) provides syntax highlighting and autocompletion for the workflow file,
in addition to linting for OpenAPI documents, and our other supported file types.

</Callout>

The workflow file is a file that dictates how the Speakeasy CLI will interact with sources and targets. The interaction is modelled as a workflow between sources and targets.
A Source is one or more OpenAPI documents and Overlays merged together to create a single OpenAPI documents.
A Target is a SDK, Terraform or other generated artifact from sources.

# File Structure

## Speakeasy Version

The version of the Speakeasy CLI to use to run the workflow. The version can be a specific version or `latest` to use the latest version.
Pinning to a specific version can be useful to ensure that the workflow runs consistently across different environments.

```yaml
workflowVersion: 1.0.0
speakeasyVersion: v1.250.0
```

## Sources

Sources can be added to a workflow programmatically `speakeasy configure sources` or manually by editing the workflow file.

<ScrollyCoding>

### !!steps `sources`

Sources are the inputs to the workflow. A single Source is one or more OpenAPI documents and Overlays that are merged together to create a single OpenAPI document.

```yaml ! gen.yaml
# !focus(3:13)
workflowVersion: 1.0.0
speakeasyVersion: latest
sources:
  my-source:
    inputs:
      - location: ./openapi.yaml
      - location: ./another-openapi.yaml
      # .... more openapi documents can be added here
    overlays:
      - location: ./overlay.yaml
      - location: ./another-overlay.yaml
      # .... more openapi overlays can be added here
  # more inputs can be added here through `speakeasy configure sources` command
  # ....
  # ....
targets:
  python-sdk:
    target: python
    source: my-source
  # more inputs can be added here through `speakeasy configure targets` command
  # ....
  # ....
```

---

### !!steps `my-source`

Each Source is given a name. In this example the name is `my-source`. This name is used to reference the source in the workflow file.

```yaml ! gen.yaml
# !focus(4)
workflowVersion: 1.0.0
speakeasyVersion: latest
sources:
  my-source:
    inputs:
      - location: ./openapi.yaml
      - location: ./another-openapi.yaml
      # .... more openapi documents can be added here
    overlays:
      - location: ./overlay.yaml
      - location: ./another-overlay.yaml
      # .... more openapi overlays can be added here
  # more inputs can be added here through `speakeasy configure sources` command
  # ....
  # ....
targets:
  python-sdk:
    target: python
    source: my-source
  # more inputs can be added here through `speakeasy configure targets` command
  # ....
  # ....
```

---

### !!steps `inputs`

Each Source has a list of inputs. Each input is an OpenAPI document or Overlay. The OpenAPI documents and Overlays are merged together to create a single OpenAPI document.

```yaml ! gen.yaml
# !focus(5:8)
workflowVersion: 1.0.0
speakeasyVersion: latest
sources:
  my-source:
    inputs:
      - location: ./openapi.yaml
      - location: ./another-openapi.yaml
      # .... more openapi documents can be added here
    overlays:
      - location: ./overlay.yaml
      - location: ./another-overlay.yaml
      # .... more openapi overlays can be added here
  # more inputs can be added here through `speakeasy configure sources` command
  # ....
  # ....
targets:
  python-sdk:
    target: python
    source: my-source
  # more inputs can be added here through `speakeasy configure targets` command
  # ....
  # ....
```

---

### !!steps `location`

Each input has a location. The location is the path to the OpenAPI document or Overlay. The path can be a local reference or a remote URL. If a URL is a used
authentication may need to be provided.

```yaml ! gen.yaml
# !focus(6:8)
workflowVersion: 1.0.0
speakeasyVersion: latest
sources:
  my-source:
    inputs:
      - location: ./openapi.yaml
      - location: ./another-openapi.yaml
      # .... more openapi documents can be added here
    overlays:
      - location: ./overlay.yaml
      - location: ./another-overlay.yaml
      # .... more openapi overlays can be added here
  # more inputs can be added here through `speakeasy configure sources` command
  # ....
  # ....
targets:
  python-sdk:
    target: python
    source: my-source
  # more inputs can be added here through `speakeasy configure targets` command
  # ....
  # ....
```

---

### !!steps `transformations`

Sources can include transformations that modify the OpenAPI document before it's used to generate SDKs. Transformations are applied in order after merging inputs and applying overlays.

```yaml ! gen.yaml
# !focus(7:15)
workflowVersion: 1.0.0
speakeasyVersion: latest
sources:
  my-source:
    inputs:
      - location: ./openapi.yaml
    transformations:
      # Remove unused components from the OpenAPI document
      - removeUnused: true
      # Filter to include only specific operations
      - filterOperations:
          operations: getPets, createPet
          include: true
      # General cleanup of the OpenAPI document (formatting and style)
      - cleanup: true
```
---

### !!steps `output`

Each source can specify an output location where the merged OpenAPI document will be written.

```yaml ! gen.yaml
# !focus(7)
workflowVersion: 1.0.0
speakeasyVersion: latest
sources:
  my-source:
    inputs:
      - location: ./openapi.yaml
    output: ./merged-openapi.yaml
```

---

### !!steps `registry`

Sources can be configured to publish to the API Registry found in your Speakeasy workspace.

```yaml ! gen.yaml
# !focus(7:8)
workflowVersion: 1.0.0
speakeasyVersion: latest
sources:
  my-source:
    inputs:
      - location: ./openapi.yaml
    registry:
      location: registry.speakeasyapi.dev/my-org/my-api
```

---

</ScrollyCoding>

## Targets

Targets can be added to a workflow programmatically `speakeasy configure targets` or manually by editing the workflow file.

<ScrollyCoding>

### !!steps `targets`

Targets are the outputs of the workflow. A single Target is a SDK, Terraform or other generated artifact from sources.

```yaml ! gen.yaml
# !focus(16:20)
workflowVersion: 1.0.0
speakeasyVersion: latest
sources:
  my-source:
    inputs:
      - location: ./openapi.yaml
      - location: ./another-openapi.yaml
      # .... more openapi documents can be added here
    overlays:
      - location: ./overlay.yaml
      - location: ./another-overlay.yaml
      # .... more openapi overlays can be added here
  # more inputs can be added here through `speakeasy configure sources` command
  # ....
  # ....
targets:
  my-target:
    target: python
    source: my-source
  # more inputs can be added here through `speakeasy configure targets` command
  # ....
  # ....
```

---

### !!steps `my-target`

Each Target is given a name. In this example the name is `my-target`. This name is used to reference the target in the workflow file.

```yaml ! gen.yaml
# !focus(17)
workflowVersion: 1.0.0
speakeasyVersion: latest
sources:
  my-source:
    inputs:
      - location: ./openapi.yaml
      - location: ./another-openapi.yaml
      # .... more openapi documents can be added here
    overlays:
      - location: ./overlay.yaml
      - location: ./another-overlay.yaml
      # .... more openapi overlays can be added here
  # more inputs can be added here through `speakeasy configure sources` command
  # ....
  # ....
targets:
  my-target:
    target: python
    source: my-source
  # more inputs can be added here through `speakeasy configure targets` command
  # ....
  # ....
```

---

### !!steps `target`

Each Target has a type. The target is the type of artifact that will be generated from the sources. The target can be one of the supported languages [here](/docs/create-client-sdks)

```yaml ! gen.yaml
# !focus(18)
workflowVersion: 1.0.0
speakeasyVersion: latest
sources:
  my-source:
    inputs:
      - location: ./openapi.yaml
      - location: ./another-openapi.yaml
      # .... more openapi documents can be added here
    overlays:
      - location: ./overlay.yaml
      - location: ./another-overlay.yaml
      # .... more openapi overlays can be added here
  # more inputs can be added here through `speakeasy configure sources` command
  # ....
  # ....
targets:
  my-target:
    target: python
    source: my-source
  # more inputs can be added here through `speakeasy configure targets` command
  # ....
  # ....
```

---

### !!steps `source`

Each Target has a source. The source is the name of the source that the target will be generated from.

```yaml ! gen.yaml
# !focus(19)
workflowVersion: 1.0.0
speakeasyVersion: latest
sources:
  my-source:
    inputs:
      - location: ./openapi.yaml
      - location: ./another-openapi.yaml
      # .... more openapi documents can be added here
    overlays:
      - location: ./overlay.yaml
      - location: ./another-overlay.yaml
      # .... more openapi overlays can be added here
  # more inputs can be added here through `speakeasy configure sources` command
  # ....
  # ....
targets:
  my-target:
    target: python
    source: my-source
  # more inputs can be added here through `speakeasy configure targets` command
  # ....
  # ....
```

---

### !!steps `testing`

Each Target supports enabling testing as part of the workflow, if test generation is licensed. This will run target-specific testing, such as `go test` or `pytest`, after code generation. Use this with CLI-only `speakeasy run` development workflows (instead of separately calling `speakeasy test`) or GitHub Actions `mode: direct` or `mode: test` development workflows to ensure tests are successful with any potential code updates.

```yaml ! gen.yaml
# !focus(20:21)
workflowVersion: 1.0.0
speakeasyVersion: latest
sources:
  my-source:
    inputs:
      - location: ./openapi.yaml
      - location: ./another-openapi.yaml
      # .... more openapi documents can be added here
    overlays:
      - location: ./overlay.yaml
      - location: ./another-overlay.yaml
      # .... more openapi overlays can be added here
  # more inputs can be added here through `speakeasy configure sources` command
  # ....
  # ....
targets:
  my-target:
    target: python
    source: my-source
    testing:
      enabled: true
  # more inputs can be added here through `speakeasy configure targets` command
  # ....
  # ....
```

---

### !!steps `mockServer`

Target testing, when licensed and enabled, starts a mock API server automatically as part of the workflow. This disables the mock API server, if the testing should always pointed at a test environment server URL instead.

```yaml ! gen.yaml
# !focus(22:23)
workflowVersion: 1.0.0
speakeasyVersion: latest
sources:
  my-source:
    inputs:
      - location: ./openapi.yaml
      - location: ./another-openapi.yaml
      # .... more openapi documents can be added here
    overlays:
      - location: ./overlay.yaml
      - location: ./another-overlay.yaml
      # .... more openapi overlays can be added here
  # more inputs can be added here through `speakeasy configure sources` command
  # ....
  # ....
targets:
  my-target:
    target: python
    source: my-source
    testing:
      enabled: true
      mockServer:
        enabled: false
  # more inputs can be added here through `speakeasy configure targets` command
  # ....
  # ....
```

---

### !!steps `codeSamples`

Each target can be configured to generate code samples and publish them to Speakeasy's registry.

```yaml ! gen.yaml
# !focus(11:14)
workflowVersion: 1.0.0
speakeasyVersion: latest
sources:
  my-source:
    inputs:
      - location: ./openapi.yaml
targets:
  my-target:
    target: python
    source: my-source
    codeSamples:
      output: codeSamples.yaml
      registry:
        location: registry.speakeasyapi.dev/my-org/my-api/code-samples
```

</ScrollyCoding>  


 This is the content for the doc docs/supported/openapi.mdx 

 ---
title: "OpenAPI Support Matrix"
description: "An overview of OpenAPI features supported by Speakeasy for SDK generation."
---

# OpenAPI Support Matrix

The tables below give an overview of what we support from OpenAPI.

## ✅ Server Configuration

| Name | Notes | Swagger Link |Support |
|------|-------|--------------|--------|
| ServerURL config | Global and per-method (include base URL and templating) | [api-host-and-base-path](https://swagger.io/docs/specification/api-host-and-base-path/) |✅ |
| Authentication and security | Global and per-method | [authentication](https://swagger.io/docs/specification/authentication/) |✅ |
| Method generation |  |   |✅ |
| Model generation |  Request and response |   |✅ |

## ⚠️ Path Parameters Serialization ([path-parameters](https://swagger.io/docs/specification/describing-parameters/#path-parameters))

| Name | Notes | Swagger Link | Support |
|------|-------|--------------|---------|
| Default | `(style = simple, explode = false)` | [serialization/#path](https://swagger.io/docs/specification/serialization/#path/) | ✅ |
| Basic types | | | ✅ |
| Simple objects | | | ✅ |
| `label` | | | ❌ |
| `matrix` | | | ❌ |

## ⚠️ Query Parameters Serialization ([query-parameters](https://swagger.io/docs/specification/describing-parameters/#query-parameters) & [query](https://swagger.io/docs/specification/describing-parameters/#query))

| Name | Notes | Swagger Link | Support |
|------|-------|--------------|---------|
| `json` | | | ✅ |
| `form` | | | ✅ |
| `spaceDelimited` | | | ✅ |
| `pipeDelimited` | | | ✅ |
| `deepObject` | | | ✅ |
| Basic types | | | ✅ |
| Simple objects | | | ✅ |

## ✅  Request Headers ([header](https://swagger.io/docs/specification/serialization/#header))

| Name | Notes | Swagger Link | Support |
|------|-------|--------------|---------|
| Simple (explode = true)| | | ✅ |
| Simple (explode = false)| | | ✅ |

## ⚠️  Request Body Serialization

| Name | Notes | Swagger Link | Support |
|------|-------|--------------|---------|
| Multipart encoding | | [multi-part requests](https://swagger.io/docs/specification/describing-request-body/multipart-requests/)| ✅ |
| Binary| | | ✅ |
| Form data | | | ✅ |
| JSON | Both `application/json` and `text/json`| | ✅ |
| `x-www-form-urlencoded` |  Including encoding, but not non-object types | [describing-request-body](https://swagger.io/docs/specification/describing-request-body)| ⚠️ |
| Plain text | | | ✅ |
| Raw byte | | | ✅ |
| Handling `required` body | | | ✅ |
| XML | | | ❌ |
| Other media types| | | ❌ |

## ⚠️  Response Body Deserialization

| Name | Notes | Swagger Link | Support |
|------|-------|--------------|---------|
| Return StatusCode and Content-Type | | | ✅ |
| JSON | | | ✅ |
| Plain text | | | ✅ |
| Raw byte | | | ✅ |
| JSON | | | ✅ |
| Other media types| | | ❌ |

## ✅ Media-Type Patterns ([media-types](https://swagger.io/docs/specification/media-types))

## ✅ Datatypes

| Name | Notes | Swagger Link | Support |
|------|-------|--------------|---------|
| Basic types | | [data-models/data-types](https://swagger.io/docs/specification/data-models/data-types/)| ✅ |
| Enums | | | ✅ |
| Number formats | float, double, int32, int64 | | ✅ |
| Date-time | | | ✅ |
| Binary | | | ✅ |
| Arrays | | | ✅ |
| Objects | | | ✅ |
| Optional | | | ✅ |
| Maps | | | ✅ |
| Any type | | | ✅ |
| OneOf/AnyOf/AllOf |  |[oneof-anyof-allof-not](https://swagger.io/docs/specification/data-models/oneof-anyof-allof-not/)| ⚠️ See `union type` support below |

### ✅ Union Types

| Name | Notes | Language Support |
|------|-------|---------|
| `oneOf` | For languages we haven't yet developed native Union type support for. `oneOf` will be treated as an `any` type. | ✅ TS, Python, Go, C#, Java, Php  |
| `allOf` | To avoid construction of illogical types, Speakeasy currently constructs an object using the superset of fields from the listed schemas. In cases where the base schemas have a field name collision, Speakeasy will default to using the field from the object deepest in the list. | ✅ All languages  |
| `anyOf` | `anyOf` is treated as `oneOf` to avoid the bloat of combinatorial data type creation. | ✅ TS, Python, Go  |

## ✅  Miscellaneous

| Name | Notes | Swagger Link | Support |
|------|-------|--------------|---------|
| Auxiliary files* | | | ✅ |
| `x-speakeasy-server-id` generation | | | ✅ |
| Snippet generation | | | ✅ |
| README generation | | | ✅ |
| Documentation generation | | | ✅ |

\* Utility classes and functions to help with serialization and deserialization.

\* Files needed for creating a fully compilable package that can be published to the relevant package manager without further changes.


 This is the content for the doc docs/supported/terraform.mdx 

 ---
slug: /terraform-support/
sidebar_label: Terraform Support Matrix
description: "Support matrix for Speakeasy Terraform."
---

# Speakeasy Terraform provider support matrix

## Provider components

| Provider components | Speakeasy extension                             | Speakeasy generation                                                                                                                                                                                                             | Full docs                                                                                                                      |
| ------------------- | ----------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------ |
| Resource schemas    | `x-speakeasy-entity-operation: MyEntity#create` | Hoists and merges JSON Schemas associated with all create, read, update, and delete operations appropriately.                                                                                                                    | [Docs link](/docs/terraform/entity-mapping#specify-crud-operations-for-api-endpoints) |
| Data source schemas | `x-speakeasy-entity-operation: MyEntity#read`   | Hoists and merges JSON Schemas associated with all read operations into a single data source.                                                                                                                                    | [Docs link](/docs/terraform/entity-mapping#specify-crud-operations-for-api-endpoints) |
| Create methods      | `x-speakeasy-entity-operation: MyEntity#create` | Speakeasy generates platform connector logic to invoke all API requests and save responses to the Terraform state.                                                                                                               | [Docs link](/docs/terraform/entity-mapping#specify-crud-operations-for-api-endpoints) |
| Read methods        | `x-speakeasy-entity-operation: MyEntity#read`   | Speakeasy generates platform connector logic to invoke all API requests and save responses to the Terraform state. Also invoked in `CREATE` and `UPDATE` methods for additional data calls, enabling drift detection and import. | [Docs link](/docs/terraform/entity-mapping#specify-crud-operations-for-api-endpoints) |
| Update methods      | `x-speakeasy-entity-operation: MyEntity#update` | Speakeasy generates platform connector logic to invoke all API requests and save responses to the Terraform state. Plan modifiers force resource recreation when needed.                                                         | [Docs link](/docs/terraform/entity-mapping#specify-crud-operations-for-api-endpoints) |
| Delete methods      | `x-speakeasy-entity-operation: MyEntity#delete` | Speakeasy generates platform connector logic to invoke all API requests and save responses to the Terraform state.                                                                                                               | [Docs link](/docs/terraform/entity-mapping#specify-crud-operations-for-api-endpoints) |
| Plan validators     | `x-speakeasy-plan-validators`                   | Generated when using restricted OpenAPI data types (for example, JSON fields, date fields). Also generated for specific Speakeasy extensions.                                                                                     | [Docs link](/docs/terraform/validation-dependencies#add-custom-validation-logic)               |
| Plan modifiers      | `x-speakeasy-plan-modifiers`                    | Ensures API and `terraform state` and `terraform plan` commands have appropriate semantics, such as [diff-detection](/docs/terraform/plan-modification#suppress-unnecessary-plan-changes).                 | [Docs link](/docs/terraform/plan-modification#add-custom-plan-modification)        |
| Resource imports    | n/a                                             | Each `resource` will be inserted into the provider resource list.                                                                                                                                                                | [Docs link](/docs/terraform/configuration#custom-resources-or-data-sources)          |

## Supported OpenAPI semantics

| **OpenAPI semantics**                              | **Speakeasy support** | **Comments & limitations**                                                                                                                                                                                                                                      |
| -------------------------------------------------- | --------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Resource schemas (const)                           | ✅ Full support       | When an attribute in an OpenAPI document is specified as `const`, it is removed from a Terraform schema and automatically included in requests or assumed in responses.                                                                                         |
| Resource schemas (default)                         | ✅ Full support       | When an attribute specifies a default value, this value will be used whenever that attribute is not explicitly set, ensuring consistency and reliability.                                                                                                       |
| Server configuration                               | ✅ Full support       | The provider includes a `server_url` variable, allowing it to be used with any API server. By default, this variable is set to the first entry in the `servers` field of your OpenAPI document.                                                                      |
| Global authentication                              | ✅ Full support       | All authentication mechanisms that rely on static authorization are supported, with their values automatically configurable in the provider settings. For OAuth, you need to write a custom hook that implements your authentication flow logic. |
| Query parameter serialization                      | ✅ Full support       | All query parameter attributes will be available as resource or data source attributes in a Terraform-native format. Might require remapping through `x-speakeasy-match`.                                                                                         |
| Request headers                                    | ✅ Full support       | All request attributes will be available as resource or data source attributes in a Terraform-native format.                                                                                                                                                      |
| Multiple API requests in one CRUD step             | ✅ Full support       | For example, `create` requires two API calls.                                                                                                                                                                                                                   |
| JSON Schema `type: string`                         | ✅ Full support       |                                                                                                                                                                                                                                                                 |
| JSON Schema `type: number`                         | ✅ Full support       |                                                                                                                                                                                                                                                                 |
| JSON Schema `type: integer`                        | ✅ Full support       |                                                                                                                                                                                                                                                                 |
| JSON Schema `type: boolean`                        | ✅ Full support       |                                                                                                                                                                                                                                                                 |
| JSON Schema `type: object`                         | ✅ Full support       |                                                                                                                                                                                                                                                                 |
| JSON Schema `type: null`                           | ✅ Full support       |                                                                                                                                                                                                                                                                 |
| JSON Schema `required: [requiredPropertyA, ...]`   | ✅ Full support       | Combined into `Required` or `Optional` Terraform attribute modifiers.                                                                                                                                                                                           |
| JSON Schema `enum: [...values...]`                 | ✅ Full support       | A plan validator is added to assert that only one of the predefined values is set.                                                                                                                                                                              |
| JSON Schema `type: array`                          | ✅ Full support       |                                                                                                                                                                                                                                                                 |
| JSON Schema `type: array, minItems: N`             | ✅ Full support       | A plan validator is added to ensure the Terraform `ListAttribute` has `N` items set.                                                                                                                                                                            |
| JSON Schema `type: array, maxItems: J`             | ✅ Full support       | A plan validator is added to ensure the Terraform `ListAttribute` has `J` items set.                                                                                                                                                                            |
| JSON Schema `type: array, uniqueItems: true`       | ✅ Full support       | A plan validator is added to ensure the Terraform `ListAttribute` has all items as unique values.                                                                                                                                                               |
| JSON Schema `type: number, format: float`          | ✅ Full support       |                                                                                                                                                                                                                                                                 |
| JSON Schema `type: number, format: double`         | ✅ Full support       |                                                                                                                                                                                                                                                                 |
| JSON Schema `type: integer, format: int32`         | ✅ Full support       |                                                                                                                                                                                                                                                                 |
| JSON Schema `type: integer, format: int64`         | ✅ Full support       |                                                                                                                                                                                                                                                                 |
| JSON Schema `type: string, format: date`           | ✅ Full support       | A plan validator is added to ensure that this string value is set to a date in the YYYY-MM-DD format.                                                                                                                                                         |
| JSON Schema `type: string, format: date-time`      | ✅ Full support       | A plan validator is added to ensure that this string value is RFC 3339-compatible.                                                                                                                                                                              |
| JSON Schema `format: binary`                       | ✅ Full support       | Accessible as a string attribute.                                                                                                                                                                                                                               |
| JSON Schema `nullable: true`                       | ✅ Full support       | Combined into `Required` or `Optional` Terraform attribute modifiers.                                                                                                                                                                                           |
| JSON Schema `additionalProperties: true`           | ✅ Full support       | A free-form object without `additionalProperties: true` is treated as an empty object.                                                                                                                                                                          |
| JSON Schema `additionalProperties: ${JSON Schema}` | ✅ Full support       | Full support for defining schemas for additional properties.                                                                                                                                                                                                    |
| JSON Schema `oneOf: [${JSON Schema}, ...]`         | ✅ Full support       | Represented as a nested object with one child attribute for each `oneOf` subschema. A plan validator is added that asserts only one child attribute can be set.                                                                                                 |
| JSON Schema `anyOf: [${JSON Schema}, ...]`         | ✅ Full support       | Considered the same as `oneOf`.                                                                                                                                                                                                                                 |
| JSON Schema `allOf: [${JSON Schema}, ...]`         | ✅ Full support       | Constructs an "uber-type" by merging the superset of all subschemas.                                                                                                                                                                                            |
| JSON Schema "Any" Type                             | ✅ Full support       | Requires the `x-speakeasy-type-override: any` annotation. Used as an escape hatch.                                                                                                                                                                              |
| OpenAPI `readOnly: true`                           | ✅ Full support       |                                                                                                                                                                                                                                                                 |
| OpenAPI `writeOnly: true`                          | ✅ Full support       |                                                                                                                                                                                                                                                                 |
| Example generation                                 | ✅ Full support       | Propagates `example` and `examples` into generated Terraform resource examples. Uses a type-appropriate value for other cases.                                                                                                                                  |
| Operation-specific authentication                  | ⚠️ Partial support    | Speakeasy doesn't support overriding global authentication on specific operations without advanced techniques like monkey patching.                                                                                                                             |
| `label` or `matrix` path param serialization        | ⚠️ No support         | Remapping may be required through `x-speakeasy-match`.                                                                                                                                                                                                          |
| XML request body serialization                     | ⚠️ Partial support    | Full support for JSON data types but no support for XML.                                                                                                                                                                                                        |
| XML response body deserialization                  | ⚠️ Partial support    | Full support for JSON data types but no support for XML response bodies.                                                                                                                                                                                        |
| Circular references                                | ⚠️ Partial support    | `x-speakeasy-type-override: any` enables setting attributes with `jsonencode(...arbitrary data...)`.                                                                                                                                                            |
| Lists of lists of primitives                       | ⚠️ Partial support    | `x-speakeasy-type-override: any` enables setting lists of lists, but Terraform's `ListAttribute` only supports primitive types.                                                                                                                                 |

### Terraform framework types from JSON Schema types

| JSON Schema type | JSON Schema additions         | Terraform framework type                               | Notes                                                                          |
| ---------------- | ----------------------------- | ------------------------------------------------------ | ------------------------------------------------------------------------------ |
| `type: string`   | -                             | `schema.StringAttribute`                               |                                                                                |
| `type: number`   | -                             | `schema.NumberAttribute`                               |                                                                                |
| `type: integer`  | -                             | `schema.Int64Attribute`                                |                                                                                |
| `type: boolean`  | -                             | `schema.BoolAttribute`                                 |                                                                                |
| `type: array`    | -                             | `schema.ListAttribute` or `schema.ListNestedAttribute` | A `ListAttribute` is used when `items` has the primitive `type`.               |
| `type: array`    | `format: set`                 | `schema.SetAttribute` or `schema.SetNestedAttribute`   | A `SetAttribute` is used when `items` has the primitive `type`.                |
| `type: object`   | `properties: {...}`           | `schema.SingleNestedAttribute`                         |                                                                                |
| `type: object`   | `additionalProperties: {...}` | `schema.MapAttribute` or `schema.MapNestedAttribute`   | A `MapAttribute` is used when `additionalProperties` has the primitive `type`. |
| `type: null`     | N/A                           |                                                        | Element ignored                                                                |

### JSON Schema subschema handling

| JSON Schema subschema type | Handling                                                                                                                                    | Full docs                                                                                          |
| -------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------ |
| `oneOf`                    | A `schema.SingleNestedAttribute` is created with one key for each `oneOf` child. Plan validator ensures that only one subattribute is used. | [Docs link](/docs/terraform/extensions#the-oneof-keyword) |
| `anyOf`                    | Considered the same as `oneOf`. Speakeasy does not strictly enforce this subschema type in production environments.                         | [Docs link](/docs/terraform/extensions#the-anyof-keyword) |
| `allOf`                    | Merges all subschemas. When the subschemas are objects, it creates a composite object with properties from all child schemas.               | [Docs link](/docs/terraform/extensions#the-allof-keyword) |


 This is the content for the doc docs/terms-of-service.mdx 

 ---
title: Terms of Service
description: "Speakeasy Terms of Service"
---

# Terms of Service

**Speakeasy Development, Inc.**

Welcome to Speakeasy Development, Inc. ("Speakeasy"), herein referred to as "Company," "we," "us," or "our". By accessing and using our services ("Services"), which include but are not limited to our website at [https://www.speakeasy.com](https://www.speakeasy.com), Command Line Interface (CLI) tool, GitHub Action, Web User Interface (Web UI), and any related software, applications, tools, or utilities provided by the Company, you, the user, agree to be bound by the following terms of service ("Terms"). These Terms form a legally binding contract between you and the Company.

Acceptance of Terms: By using any part of our Services, clicking on the "I Agree" or similar button, installing our software, or otherwise engaging with our Services, you acknowledge that you have read, understood, and agree to these Terms. If you are accepting these Terms on behalf of an employer or another legal entity, you represent and warrant that you have the authority to bind that entity to these Terms. If you do not agree with any part of these Terms, you must not use the Services.

Separate Agreements: If a separate written Services Agreement exists between you (or your entity) and the Company regarding the Services, the terms of that agreement shall take precedence over these Terms.

Use of Services: Your use of the Services signifies your agreement to be bound by these Terms and any modifications made to them. The Company reserves the right to modify these Terms at any time, with changes becoming effective upon posting to our website or direct communication to you. Your continued use of the Services following such changes constitutes your acceptance of the new Terms.

Eligibility: By using our Services, you confirm that you are legally capable of entering into binding contracts and that your use of the Services is not prohibited by any applicable laws or agreements.

## 1. SERVICES AND SUPPORT

1.1. Subject to the terms of this Agreement, Company will use commercially reasonable efforts to provide Customer the Services.

1.2  Subject to the terms hereof, Company will provide Customer with reasonable technical support services in accordance with the Company’s standard practice

## 2. RESTRICTIONS AND RESPONSIBILITIES

2.1 Customer will not, directly or indirectly: reverse engineer, decompile, disassemble or otherwise attempt to discover the source code, object code or underlying structure, ideas, know-how or algorithms relevant to the Services or any software, documentation or data related to the Services (“Software”); modify, translate, or create derivative works based on the Services or any Software (except to the extent expressly permitted by Company or authorized within the Services); use the Services or any Software for timesharing or service bureau purposes or otherwise for the benefit of a third; or remove any proprietary notices or labels. With respect to any Services provided on a cloud-hosted basis, where Company (or its third-party service provider) hosts the Services, Company grants to Customer a non-exclusive, non-transferable, non-sublicensable right to access and use the Services on a software-as-a-service basis for Customer’s internal business purposes. With respect to any Software that is distributed or provided to Customer for use on Customer premises or devices, Company hereby grants Customer a non-exclusive, non-transferable, non-sublicensable license to use such Software during the Term only in connection with the Services. Note that any client SDKs produced during the Term may continue to be used even after the Term expires. With respect to any Services that are self-hosted by the Customer, Company grants Customer a non-exclusive, non-transferable, non-sublicensable right to (i) download, install and use any executable Software provided by Company for the purpose of integrating the Services into the Customer Environment (as defined below), and (ii) access and use the Services solely to enable Customer to connect and integrate the Service with Customer’s servers and/or cloud-hosting environments (which may include, without limitation, any of the foregoing that are made available to Customer by a third-party service provider) (collectively, “Customer Environment”). Customer will be solely responsible for integrating and implementing the Services with the Customer Environment. Customer will only permit the Services to be accessed by Customer’s employees or contractors that are authorized by Customer to access the Services, provided that Customer shall remain liable for all acts or omissions of such users.

2.2 Further, Customer may not remove or export from the United States or allow the export or re-export of the Services, Software or anything related thereto, or any direct product thereof in violation of any restrictions, laws or regulations of the United States Department of Commerce, the United States Department of Treasury Office of Foreign Assets Control, or any other United States or foreign agency or authority.  As defined in FAR section 2.101, the Software and documentation are “commercial items” and according to DFAR section 252.227 7014(a)(1) and (5) are deemed to be “commercial computer software” and “commercial computer software documentation.”  Consistent with DFAR section 227.7202 and FAR section 12.212, any use modification, reproduction, release, performance, display, or disclosure of such commercial software or commercial software documentation by the U.S. Government will be governed solely by the terms of this Agreement and will be prohibited except to the extent expressly permitted by the terms of this Agreement.

2.3 Customer represents, covenants, and warrants that Customer will use the Services only in compliance with the terms of this Agreement and all applicable laws and regulations. Customer hereby agrees to indemnify and hold harmless Company against any damages, losses, liabilities, settlements and expenses (including without limitation costs and attorneys’ fees) in connection with any claim or action that arises from an alleged violation of the foregoing or otherwise from Customer’s use of Services. Although Company has no obligation to monitor Customer’s use of the Services, Company may do so and may prohibit any use of the Services it believes may be (or alleged to be) in violation of the foregoing.

2.4 Customer shall be responsible for obtaining and maintaining any equipment and ancillary services needed to connect to, access or otherwise use the Services, including, without limitation, modems, hardware, servers, software, operating systems, networking, web servers and the like (collectively, “Equipment”). Customer shall also be responsible for maintaining the security of the Equipment, Customer account, passwords (including but not limited to administrative and user passwords) and files, and for all uses of Customer account or the Equipment with or without Customer’s knowledge or consent.

## 3. CONFIDENTIALITY; PROPRIETARY RIGHTS

3.1 Each party (the “Receiving Party”) understands that the other party (the “Disclosing Party”) has disclosed or may disclose business, technical or financial information relating to the Disclosing Party’s business (hereinafter referred to as “Proprietary Information” of the Disclosing Party). Proprietary Information of Company includes non-public information regarding features, functionality and performance of the Service. Proprietary Information of Customer includes non-public data provided by Customer to Company to enable the provision of the Services (“Customer Data”). The Receiving Party agrees: (i) to take reasonable precautions to protect such Proprietary Information, and (ii) not to use (except in performance of the Services or as otherwise permitted herein) or divulge to any third person any such Proprietary Information. The Disclosing Party agrees that the foregoing shall not apply with respect to any information after five (5) years following the disclosure thereof or any information that the Receiving Party can document (a) is or becomes generally available to the public, or (b) was in its possession or known by it prior to receipt from the Disclosing Party, or (c) was rightfully disclosed to it without restriction by a third party, or (d) was independently developed without use of any Proprietary Information of the Disclosing Party or (e) is required to be disclosed by law.

3.2 Customer shall own all right, title and interest in and to the Customer Data and any SDKs, Terraform providers, and documentation generated for Customer using Company’s Services. Company shall own and retain all right, title and interest in and to (a) the Services and Software (including Company’s SDK, Terraform provider, and documentation generators), and all improvements, enhancements or modifications thereto, (b) any software, applications, inventions or other technology developed in connection with Services or support (if applicable), and (c) all intellectual property rights related to any of the foregoing.

3.3 Notwithstanding anything to the contrary, Company shall have the right to collect and analyze data and other information relating to the provision, use and performance of various aspects of the Services and related systems and technologies (including, without limitation, information concerning Customer Data and data derived therefrom), and Company will be free (during and after the term hereof) to (i) use such information and data to improve and enhance the Services and for other development, diagnostic and corrective purposes in connection with the Services and other Company offerings, and (ii) disclose such data solely in aggregate or other de-identified form in connection with its business. No rights or licenses are granted except as expressly set forth herein.

## 4 PAYMENT OF FEES

Speakeasy offers a variety of service plans, from complimentary access to extended features available through paid subscriptions. Detailed information on what each plan includes can be found on our pricing page. Access to paid plans is facilitated securely through our hosted payment link, and by selecting any of these plans, you agree to the payment terms outlined herein, managed via our chosen third-party payment processor ("PSP").

4.1 Subscription and Billing Cycle: Payment for your chosen service plan is required in advance and will be billed by the PSP on or shortly after the subscription initiation date and subsequently at the beginning of each billing cycle (monthly, annually, or as otherwise specified). The fees charged are non-refundable, except as explicitly stated in these Terms.

4.2 Adjustments to Service Plans: Users may upgrade or downgrade their service plans. Upgrades take effect immediately, and additional charges will be applied on a pro-rata basis. Downgrades, including transitions from paid to freemium plans, take effect at the start of the next billing cycle.

4.3 Changes to Fees: Speakeasy reserves the right to change fees or billing methods for service plans at any time. Users will be notified of any fee changes in advance. Disagreement with the changes requires cancellation of your subscription. Continued use after the change takes effect implies acceptance of the new fees.

4.4 Responsibility for Taxes and Charges: Users are responsible for any taxes, duties, or charges incurred in connection with the services, except for those based on Speakeasy's income. All listed prices do not include such taxes or charges.

4.5 Payment Information: You agree to provide accurate and up-to-date payment information to the PSP and to promptly update your information with any changes. Failure to process a payment will result in suspension of the Services until payment can be collected. You authorize us to continue billing the provided payment method for all charges due and to update information from your payment provider to continue billing if necessary.

## 5. TERM AND TERMINATION

5.1 Term: This Agreement becomes effective upon your first use of the Services and remains in effect until terminated by either party according to the terms provided herein. The term of this Agreement consists of the following:

- Initial Term: For all users, the "initial term" begins upon the first use of the Services. For users who choose a paid subscription, this term extends through the end of the first billing cycle specified at the time of purchase (e.g., one month, one year).

- Renewal Term: After the initial term, the Agreement will automatically renew for additional periods matching the length of the initial paid subscription cycle (e.g., monthly, annually). For users on freemium or trial plans who have not transitioned to a paid subscription, the Agreement will continue indefinitely on the same terms until either party opts for termination.

- Termination: Either party may terminate this Agreement with at least thirty (30) days' notice prior to the end of the current term, whether it be the initial term or any renewal term.

5.2 Termination for Cause: Either party may terminate this Agreement with thirty (30) days’ written notice if the other party materially breaches any terms or conditions and fails to cure such breach within the thirty (30) day notice period. Immediate termination is allowed in cases of nonpayment.

5.3 Effects of Termination: Upon termination, you must cease all use of the Services, and we will disable your access. We will provide you with access to retrieve your data for thirty (30) days post-termination. After this period, we may delete your data, although we are not obligated to do so.

5.4 Survival: Provisions regarding payment, data ownership, confidentiality, liability limitations, and any other terms which by their nature should survive, will remain in effect after this Agreement ends.

## 6.  WARRANTY AND DISCLAIMER

Company shall use reasonable efforts consistent with prevailing industry standards to maintain the Services in a manner which minimizes errors and interruptions in the Services and shall perform the Implementation Services (if applicable) in a professional and workmanlike manner. Services may be temporarily unavailable for scheduled maintenance or for unscheduled emergency maintenance, either by Company or by third-party providers, or because of other causes beyond Company’s reasonable control, but Company shall use reasonable efforts to provide advance notice in writing or by e-mail of any scheduled service disruption. HOWEVER, COMPANY DOES NOT WARRANT THAT THE SERVICES WILL BE UNINTERRUPTED OR ERROR FREE; NOR DOES IT MAKE ANY WARRANTY AS TO THE RESULTS THAT MAY BE OBTAINED FROM USE OF THE SERVICES. EXCEPT AS EXPRESSLY SET FORTH IN THIS SECTION, THE SERVICES AND IMPLEMENTATION SERVICES ARE PROVIDED “AS IS” AND COMPANY DISCLAIMS ALL WARRANTIES, EXPRESS OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT.

## 7. LIMITATION OF LIABILITY

NOTWITHSTANDING ANYTHING TO THE CONTRARY, EXCEPT FOR BODILY INJURY OF A PERSON, COMPANY AND ITS SUPPLIERS (INCLUDING BUT NOT LIMITED TO ALL EQUIPMENT AND TECHNOLOGY SUPPLIERS), OFFICERS, AFFILIATES, REPRESENTATIVES, CONTRACTORS AND EMPLOYEES SHALL NOT BE RESPONSIBLE OR LIABLE WITH RESPECT TO ANY SUBJECT MATTER OF THIS AGREEMENT OR TERMS AND CONDITIONS RELATED THERETO UNDER ANY CONTRACT, NEGLIGENCE, STRICT LIABILITY OR OTHER THEORY: (A) FOR ERROR OR INTERRUPTION OF USE OR FOR LOSS OR INACCURACY OR CORRUPTION OF DATA OR COST OF PROCUREMENT OF SUBSTITUTE GOODS, SERVICES OR TECHNOLOGY OR LOSS OF BUSINESS; (B) FOR ANY INDIRECT, EXEMPLARY, INCIDENTAL, SPECIAL OR CONSEQUENTIAL DAMAGES; (C) FOR ANY MATTER BEYOND COMPANY’S REASONABLE CONTROL; OR (D) FOR ANY AMOUNTS THAT, TOGETHER WITH AMOUNTS ASSOCIATED WITH ALL OTHER CLAIMS, EXCEED THE FEES PAID BY CUSTOMER TO COMPANY FOR THE SERVICES UNDER THIS AGREEMENT IN THE 12 MONTHS PRIOR TO THE ACT THAT GAVE RISE TO THE LIABILITY, IN EACH CASE, WHETHER OR NOT COMPANY HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES.

## 8. MISCELLANEOUS

If any provision of this Agreement is found to be unenforceable or invalid, that provision will be limited or eliminated to the minimum extent necessary so that this Agreement will otherwise remain in full force and effect and enforceable. This Agreement is not assignable, transferable or sublicensable by Customer except with Company’s prior written consent. Company may transfer and assign any of its rights and obligations under this Agreement without consent. Company may use Customer’s name and logo on Company’s website and in marketing materials to identify Customer as a client of Company. This Agreement is the complete and exclusive statement of the mutual understanding of the parties and supersedes and cancels all previous written and oral agreements, communications and other understandings relating to the subject matter of this Agreement, and that all waivers and modifications must be in a writing signed by both parties, except as otherwise provided herein. No agency, partnership, joint venture, or employment is created as a result of this Agreement and Customer does not have any authority of any kind to bind Company in any respect whatsoever. In any action or proceeding to enforce rights under this Agreement, the prevailing party will be entitled to recover costs and attorneys’ fees. All notices under this Agreement will be in writing and will be deemed to have been duly given when received, if personally delivered; when receipt is electronically confirmed, if transmitted by facsimile or e-mail; the day after it is sent, if sent for next day delivery by recognized overnight delivery service; and upon receipt, if sent by certified or registered mail, return receipt requested. This Agreement shall be governed by the laws of the State of California without regard to its conflict of laws provisions. Customer agrees to reasonably cooperate with Company to serve as a reference account upon request.

## 9. Contact Information

If you have any questions about these Terms or the Services please contact Speakeasy at [info@speakeasy.com](mailto:info@speakeasy.com).


 This is the content for the doc docs/terraform/advanced-features.mdx 

 ---
title: "Advanced Features"
description: "Learn about advanced customization options for your Terraform provider."
---

import { Callout } from '~/components'

# Advanced Features

## Speciality Annotations

The annotations in this section are not commonly used within Speakeasy. We recommend contacting our team to help determine if they are correct for you.

### Force Mark Property as Read-Only

The `x-speakeasy-param-readonly` extension marks a property as read-only. Any user attempt to modify it in Terraform will result in a runtime error. This prevents unintended changes to critical properties in Terraform configurations.

```yaml
components:
  schemas:
    Pet:
      type: object
      properties:
        name:
          type: string
        id:
          type: integer
          x-speakeasy-param-readonly: true
```

### Force Designate a Property as Optional

Apply `x-speakeasy-param-optional` to any property to designate it as optional. This extension takes precedence over the required attribute in the JSON Schema specification, providing flexibility in Terraform configurations by allowing optional settings for certain properties.

```yaml
components:
  schemas:
    Pet:
      type: object
      properties:
        name:
          type: string
        id:
          type: integer
          x-speakeasy-param-optional: true
```

### Force Resource Recreation on Property Change

Properties marked with `x-speakeasy-param-force-new` will cause the associated Terraform resource to be destroyed and recreated whenever the property value changes. This ensures that any alteration to the property triggers a complete recreation of the object.

```yaml
components:
  schemas:
    Pet:
      type: object
      properties:
        name:
          type: string
        id:
          type: integer
          x-speakeasy-param-force-new: true
```

### Update Behavior for Plan-Only Attributes

The `x-speakeasy-terraform-plan-only` extension ensures that only the values from the Terraform plan are used during updates, overriding any prior state or default values provided by the API. By preventing prior state values from being merged into the update request, the annotation ensures that omitted or null values in the plan are correctly reflected in API calls.

```yaml
components:
  schemas:
    Pet:
      type: object
      properties:
        properties:
        name:
          type: string
        id:
          type: integer
          nullable: true
          x-speakeasy-terraform-plan-only: true
```


 This is the content for the doc docs/terraform/configuration.mdx 

 ---
title: "Configuration"
description: "Learn how to configure environment values and manage custom resources in your Terraform provider."
---

import { Callout } from '~/components'

# Configuration

## Configuring Environment Values

Use the `environmentVariables` configuration in your `gen.yaml` to set up default values for provider variables to be pulled in from a user environment variable. This is useful for mapping known environment values that will hold an API key into the provider.

``` yaml
terraform:
  environmentVariables:
    - env: EXAMPLE_SERVER_URL_FROM_ENV_VAR
      providerAttribute: server_url
    - env: EXAMPLE_ACCESS_TOKEN
      providerAttribute: access_token
```

The `environmentVariables` configuration is expected to be a list of objects with `{env: string, providerAttribute: string}` keys and values. These will create associations from environment variables (referenced as `env`) with provider attributes (referenced as `providerAttribute`).

## Additional Provider Configurations

Enable Terraform configurations to specify additional provider-wide customizations in the generation configuration (`gen.yaml`) file with the `additionalProviderAttributes` configuration, for example:

```yaml
terraform:
  additionalProviderAttributes:
    # ... configuration ...
```

### Custom HTTP Headers

Set the `httpHeaders` configuration with the desired attribute name to enable Terraform configurations to specify a mapping of additional HTTP headers for all HTTP requests.

In this example, HTTP header customization is enabled using the `http_headers` provider attribute name:

```yaml
terraform:
  additionalProviderAttributes:
    httpHeaders: http_headers
```

This configuration enables provider configuration such as:

```hcl
provider "examplecloud" {
  http_headers = {
    "X-Example-Header" = "example-value"
  }
}
```

## Custom Resources or Data Sources

If you would like to include an existing resource that is outside of the Speakeasy-generated provider, reference it in `gen.yaml` like so:

```yaml
terraform:
  additionalResources:
    - importAlias: custom
      importLocation: github.com/custom/terraform-provider-example/src/custom_resource
      resource: custom.NewCustomResource
  additionalDataSources:
    - importAlias: custom
      importLocation: github.com/custom/terraform-provider-example/src/custom_datasource
      datasource: custom.NewCustomDataSource
```

The `additionalResources` key is expected to contain a list of `{ importLocation?: string, importAlias?: string, resource: string }` objects. Each `resource` will be inserted into the provider resource list. If `importLocation` or `importAlias` is defined, Speakeasy will add that to the import list at the top of the provider file. The value of `resource` is arbitrary text, and could contain a function invocation if desired.

The `additionalDataSources` key follows the same syntax, but with `datasource` as the text string to be inserted into the list instead of `resource`.

To learn more about how to write a Terraform resource, please consult the [official Terraform documentation](https://developer.hashicorp.com/terraform/plugin/framework).

## Modifying Resource and Data Source Descriptions

The `x-speakeasy-entity-description` extension allows you to modify the description of a Terraform resource or data source. This is useful when augmenting the documentation in your OpenAPI specification with documentation for your specific resources. This documentation is expected to be in Markdown format. Use this extension alongside your `x-speakeasy-entity` extension.

Alternatively, a template folder can be written to customize any or all aspects of generated documentation in alignment with [terraform-plugin-docs](https://github.com/hashicorp/terraform-plugin-docs).

```yaml
components:
  schemas:
    Order:
      description: An order helps you make coffee
      x-speakeasy-entity: Order
      x-speakeasy-entity-description: |
        The order resource allows you to declaratively construct an order for coffee.

        resource "speakeasy_order" "example" {
          name = "Filter Blend"
          price = 11.5
        }
```

## Deduplicate Terraform Types

The `terraform` types folder includes a representation of your data models that is appropriate for the `terraform-plugin-framework` type system. However, if you have multiple types with the same *signature* (e.g. the same set of child property *types*), there might be a lot of these types that are effectively duplicated. To minimize the git repository / binary size, it might make sense to deduplicate these by re-using types with the same *signature* across different resources. If you would like to enable this, set the following configuration option:

This option is `false` by default.

```yaml
terraform:
  enableTypeDeduplication: true
```


 This is the content for the doc docs/terraform/entity-mapping.mdx 

 ---
title: "Map API Entities to Terraform Resources"
description: "Learn how to map your API entities to Terraform resources and specify CRUD operations."
---

import { Callout } from '~/components'

#  Map API Entities to Terraform Resources

Add the `x-speakeasy-entity` annotation to objects in your OpenAPI spec to include them as entities in the Terraform provider.

As a component:

```yaml
components:
  schemas:
    Order:
      description: An order helps you make coffee
      x-speakeasy-entity: Order
      properties:
        id:
          type: integer
          description: Numeric identifier of the order.
        name:
          type: string
          description: Product name of the coffee.
        price:
          type: number
          description: Suggested cost of the coffee.
      required:
        - name
        - price
      type: object
```

Or inline in a path:

```yaml
paths:
  /order:
    post:
      tags:
        - Order
      summary: Create a coffee order
      x-speakeasy-entity-operation: Order#create
      requestBody:
        content:
          application/json:
            schema:
              x-speakeasy-entity: Order
              properties:
                id:
                  type: integer
                  description: Numeric identifier of the order.
                name:
                  type: string
                  description: Product name of the coffee.
                price:
                  type: number
                  description: Suggested cost of the coffee.
              required:
                - name
                - price
              type: object
```

```tf
resource "yourprovider_order" "example" {
  name = "Filter Blend"
  price = 11.5
}
```

Where you place the `x-speakeasy-entity` annotation affects the Terraform provider structure.
- **At the top level:** Properties are nested objects.
- **At a lower level:** Properties above the annotation are flattened.


**Top Level** 
```yaml 
Pet:
  x-speakeasy-entity: Pet
  ...
```


```tf
resource "yourprovider_pet" "example" {
  data = { name = "Filter Blend" }
}
```

**Lower Level**
```yaml 
Pet:
  properties:
    data:
      x-speakeasy-entity: Pet
      ...
```


```tf
resource "yourprovider_pet" "example" {
  name = "Filter Blend"
}
```

<Callout title="Warning" variant="warning">
Properties above the `x-speakeasy-entity` annotation are flattened, which could cause conflicts. Apply the annotation carefully to align the structure of the Terraform provider with your API&apos;s intended user interaction.
</Callout>

## Specify CRUD Operations for API Endpoints

The `x-speakeasy-entity-operation` annotation specifies CRUD (create, read, update, and delete) operations associated with each endpoint in your OpenAPI spec for a Terraform entity. The value determines the behavior of operations such as create, read, update, and delete and is structured as `Entity#operation,operation,...#order`:
  - `Entity` represents the name of the entity.
  - `operation` can be one or more of `create`, `read`, `update`, and `delete`, concatenated with commas.
  - `order` is optional and can be used to define additional API calls that should be invoked for a given CRUD invocation.

### Behavior of Operations

- `Entity:create` makes the entity a Terraform resource.
- `Entity:read` ensures consistency with Terraform state, updates attributes, and generates a data source.
- `Entity:update` provides update support for the resource. Without it, any attribute change requires resource replacement (`ForceNew`).
- `Entity:delete` enables deletion of the resource. Without it, no action is taken on deletion.
- `Entity:create,update` **(idempotent operations)** indicates the API is idempotent. Combine these operations to allow the same API call to create new objects and update existing ones, depending on attribute changes.

```yaml
paths:
  /pet:
    post:
      tags:
        - pet
      summary: Add a new pet to the store
      x-speakeasy-entity-operation: Pet#create
  /pet/{petId}:
    get:
      tags:
        - pet
      summary: Info for a specific pet
      x-speakeasy-entity-operation: Pet#read
    update:
      tags:
        - pet
      summary: Update the pet
      x-speakeasy-entity-operation: Pet#update
    delete:
      tags:
        - pet
      summary: Delete the pet 
      x-speakeasy-entity-operation: Pet#delete
```

### Multiple API Operations for One Resource

When multiple API operations are necessary for a single resource, use the additional entity-ordering capabilities of the `x-speakeasy-entity-operation` annotation.

```yaml
paths:
  /pet/{petId}:
    get:
      x-speakeasy-entity-operation: Pet#read#1
  /animal:
    get:
      x-speakeasy-entity-operation: Pet#read#2
```

Multiple API operations for one resource can be combined with multiple entity operations of [one API operation for multiple resources](#one-api-operation-for-multiple-resources) as necessary.

### One API Operation for Multiple Resources

When a single API operation is necessary for multiple resources, use multiple entity operation entries with the `x-speakeasy-entity-operation` annotation.

```yaml
parameters:
  - in: query
    name: id
    required: false
    schema:
      type: string
operationId: GetAnimal
x-speakeasy-entity-operation:
  - Cat#read
  - Dog#read
```

One API operation for multiple resources can be combined with the entity operation ordering of [multiple API operations for one resource](#multiple-api-operations-for-one-resource) as necessary.

### Manual association between Operations and Resource / Data Sources

The default behavior within Speakeasy is to automatically infer a data source from all operations that have an `x-speakeasy-entity-operation: Entity#read` association defined.

For some APIs, you might want the data source to use a "search" endpoint (e.g., search for an entity by name, where name is non-unique), while using a "get" operation for the resource (e.g., to find an entity by ID for state reconciliation).

In this case, you can use an object syntax for the `x-speakeasy-entity-operation` annotation to explicitly control whether an operation generates a resource, a data source, or both:

```yaml
paths:
  "/example":
    get:
      operationId: getThing
      x-speakeasy-entity-operation:
        terraform-datasource: null
        terraform-resource: Thing#read
```

This syntax allows you to:
- Prevent automatic generation of a data source by setting `terraform-datasource` to `null`
- Prevent invocation of the operation during the resource's Read method ("invoked as part of terraform state refresh") by setting `terraform-resource` to `null`

For example, the configuration above declares that `getThing` is associated with just a resource, and a data source should not be automatically generated.

### Resources with Soft Delete

By default, a generated managed resource uses the HTTP 404 Not Found status code on read to automatically remove the resource from the Terraform state which causes the next Terraform plan to propose recreating the resource. For resource APIs that support soft delete (grace time period before the resource is fully deleted), the `x-speakeasy-soft-delete-property` annotation adds a check against a read response property to also propose resource recreation.

For managed resources, any `x-speakeasy-soft-delete-property` attribute is omitted from the schema and state. For data resources, the attribute remains to preserve client-side filtering capabilities.

In this example, the resource will be proposed for recreation if the `deleted_at` property has a value:

```yaml
paths:
  "/example":
    get:
      x-speakeasy-entity-operation: Example#read
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schema/ExampleGetResponse"
components:
  schemas:
    ExampleGetResponse:
      type: object
      properties:
        # ...
        deleted_at:
          type: string
          format: date-time
          x-speakeasy-soft-delete-property: true
```


 This is the content for the doc docs/terraform/extensions.mdx 

 ---
title: "Customize Terraform"
description: "Learn how to customize your Terraform provider using Speakeasy extensions and configurations."
redirect: "/docs/terraform"
---
# Note
The Terraform documentation has been reorganized for better navigation. Please visit the [new documentation structure](/docs/terraform) to find all Terraform-related content.


 This is the content for the doc docs/terraform/index.mdx 

 ---
title: "Customize Terraform Provider"
description: "Learn how to customize your Terraform provider using Speakeasy extensions and configurations."
---

import { Callout } from '~/components'

# Customize Your Terraform Provider

Speakeasy provides various extensions and configurations to customize your Terraform provider. These customizations allow you to:

- Map API entities to Terraform resources
- Specify CRUD operations
- Customize validation and plan modification
- Configure environment values
- And more

Select a topic from the navigation to learn more about specific customization options.

## Available Customization Options

### [Entity Mapping](/docs/terraform/entity-mapping)
Learn how to map your API entities to Terraform resources and specify CRUD operations.

### [Property Customization](/docs/terraform/property-customization)
Customize how API properties are mapped to Terraform attributes and manage property behavior.

### [Validation and Dependencies](/docs/terraform/validation-dependencies)
Add custom validation logic and manage attribute dependencies.

### [Plan Modification](/docs/terraform/plan-modification)
Customize Terraform plan behavior and resource versioning.

### [Configuration](/docs/terraform/configuration)
Configure environment values and manage custom resources.

### [Advanced Features](/docs/terraform/advanced-features)
Access advanced customization options for fine-grained control.

### [Schema Keywords](/docs/terraform/schema-keywords)
Learn about supported OpenAPI schema keywords and their behavior.


 This is the content for the doc docs/terraform/plan-modification.mdx 

 ---
title: "Plan Modification"
description: "Learn how to customize Terraform plan behavior and resource versioning."
---

import { Callout } from '~/components'

# Plan Modification

## Add Custom Plan Modification Logic

Use the `x-speakeasy-plan-modifiers` extension to add custom plan modification logic to Terraform plan operations. Plan modifiers enable advanced default value, resource replacement, and difference suppression logic.

```yaml
components:
  schemas:
    Pet:
      type: object
      x-speakeasy-entity: Pet
      properties:
        name:
          type: string
        age:
          type: integer
          x-speakeasy-plan-modifiers: AgeModifier
```

In this scenario, when Speakeasy next generates the Terraform provider, it will bootstrap a custom plan modifier file located at `internal/planmodifiers/int64planmodifier/age_modifier.go`, and import the schema configuration wherever `x-speakeasy-plan-modifiers: AgeModifier` is referenced. You can edit the plan modifier file to contain your logic.

### Implementation Notes

1. A plan modifier is a type conformant to the `terraform-plugin-framework` expected interface. A unique plan modifier will be bootstrapped in the appropriate subfolder for the Terraform type it is applied to: `boolplanmodifiers`, `float64planmodifiers`, `int64planmodifiers`, `listplanmodifiers`, `mapplanmodifiers`, `numberplanmodifiers`, `objectplanmodifiers`, `setplanmodifiers`, or `stringplanmodifiers`. Speakeasy will always create and use a file as `snake_case.go` for a given `x-speakeasy-plan-modifiers` value.

2. A plan modifier operates on the raw (untyped) Terraform value types. However, you can convert a Terraform type to a value type Speakeasy manages (`type_mytype.go`) by using the included reflection utility. This is useful for applying modifiers to complex types like `list`, `map`, `object`, and `set`.

3. While working with a plan modifier, you have the ability to perform various tasks, including initiating network requests. However, it's important to ensure that plan modifiers do not result in any unintended side effects. Please refer to [the HashiCorp guidance on plan modifier development](https://developer.hashicorp.com/terraform/plugin/framework/resources/plan-modification) or reach out in our Slack if you have questions.

4. It is possible to have an array of plan modifiers, for example, `x-speakeasy-plan-modifiers: [FirstModifier, SecondModifier]`.

5. A modifier can only be applied to a resource attribute. The annotation will be ignored for data sources. Modifiers cannot be applied at the same level as the `x-speakeasy-entity` annotation because that becomes the "root" of the Terraform resource.

6. Speakeasy regenerations do not delete user-written code. If the modifier is no longer in use, it will be ignored (no longer referenced) but the source file will remain. You might want to delete such an orphaned modifier file for repository hygiene.

##  Specify Resource Version

The `x-speakeasy-entity-version` extension specifies the version of a given resource and should *only* be used if you need to write a state migrator, for instance, if you are changing the type of a field.

Terraform resource versions are zero-indexed and default to `0`. For your first breaking change requiring a state migrator, set `x-speakeasy-entity-version: 1`. Each state migrator function must migrate from the previous version of the state.

If this is set, a boilerplate state upgrader will be written and hooked into `internal/stateupgraders/your_resource_v1.go`. Please refer to the [Terraform documentation](https://developer.hashicorp.com/terraform/plugin/framework/resources/state-upgrade) for guidance on writing a state migrator.


 This is the content for the doc docs/terraform/property-customization.mdx 

 ---
title: "Customize Terraform Properties"
description: "Learn how to customize property behavior and mapping in your Terraform provider."
---

import { Callout } from '~/components'

# Customize Terraform Properties

## Remap API Property to Terraform Attribute Name

The `x-speakeasy-name-override` annotation adjusts the Terraform attribute name within a resource while remapping all the API data handling internally. This is useful, for example, to standardize differing API property names across operations to a single attribute name.

```yaml
unique_id:
  type: string
  x-speakeasy-name-override: id
```

The annotation also has other [SDK customization capabilities](/docs/customize-sdks/methods), however, those are generally unnecessary for Terraform providers as the generated Go SDK is internal to the provider code.

## Align API Parameter With Terraform Property

The `x-speakeasy-match` annotation adjusts the API parameter name to align with a Terraform state property. If mismatches occur, a generation error will highlight appropriate root-level properties for accurate mapping.


```yaml
paths:
  /pet/{petId}:
    delete:
      parameters:
        - name: petId
          x-speakeasy-match: id
      x-speakeasy-entity-operation: Pet#delete
```

##  Hide Sensitive Properties

Properties marked as `x-speakeasy-param-sensitive` will be concealed from the console output of Terraform. This helps to ensure the confidentiality of sensitive data within Terraform operations.

```yaml
components:
  schemas:
    Pet:
      type: object
      properties:
        name:
          type: string
        secret:
          type: string
          x-speakeasy-param-sensitive: true
```

## Exclude Property From Terraform State

When `x-speakeasy-terraform-ignore: true`, this extension ensures the specified property and any interactions involving it are omitted from Terraform's state management.

<Callout title="Info" variant="info">
This extension completely suppresses the property from the Terraform state. If you want to suppress a specific operation, use `x-speakeasy-ignore: true` to omit the operation from the annotated CRUD method. For example, if a field is present in both the `CREATE` and `READ` response bodies, omitting it from the `READ` response body will turn off drift detection for that field. The field will remain in the `CREATE` response body and the Terraform state.
</Callout>

```yaml
components:
  schemas:
    Pet:
      x-speakeasy-entity: Pet
      type: object
      properties:
        optionalMetadata:
          x-speakeasy-terraform-ignore: true
          type: string
        name:
          type: string
      required:
        - name
```

```tf
resource "petstore_pet" "mypet" {
  name = "myPet"
  # Attempting to set an ignored parameter results in an error  
  # optionalMetadata = true
}
```

##  Allow JSON String Attributes

Set the `x-speakeasy-type-override` extension to `any` to convert the associated attribute to a JSON string. This allows for inline the specification of the attribute's value, accommodating attributes with variable or dynamic structures.

```yaml
components:
  schemas:
    Pet:
      x-speakeasy-entity: Pet
      type: object
      properties:
        deep:
          x-speakeasy-type-override: any
          type: object
          properties:
            object: 
              type: object
              additionalProperties: true
              properties: 
                in:
                  type: object
                  properties:
                    here:
                      type: string
        name:
          type: string
      required:
        - name
```

```tf
resource "petstore_pet" "mypet" {
  name = "myPet"
  deep = jsonencode({
    object = {
      with = "anything"
      defined = true
    }
  })
}
```

## Suppress Unnecessary Plan Changes

Setting the `x-speakeasy-param-suppress-computed-diff` to true suppresses unnecessary Terraform plan changes for computed attributes that are not definitively known until after application. This is useful in scenarios where computed attributes frequently cause spurious plan changes.


```yaml
components:
  schemas:
    Pet:
      x-speakeasy-entity: Pet
      type: object
      properties:
        name:
          type: string
        status:
          x-speakeasy-param-suppress-computed-diff: true
          type: string
```


<Callout title="Warning" variant="warning">
Applying this modifier when `x-speakeasy-entity-operation: my_resource#read` is not defined may result in drift between the Terraform plan and remote state should updates to attributes happen outside of Terraform changes. Please only apply this when necessary.
</Callout>


 This is the content for the doc docs/terraform/schema-keywords.mdx 

 ---
title: "Schema Keywords"
description: "Learn about supported OpenAPI schema keywords and their behavior in Terraform providers."
---

import { Callout } from '~/components'

# Schema Keywords

<Callout title="Tip" variant="success">
This section is not an exhaustive list of available keyword options. If you&apos;re unsure whether a keyword is supported, please reach out to our team at support@speakeasy.com.
</Callout>

### The `anyOf` Keyword

Terraform has limited support for the `anyOf` keyword due to its less flexible type system than JSON Schema. For instance, managing `anyOf` with multiple subtypes requires a large set of combined types, leading to practical and implementation challenges.

Consider replacing `anyOf` in your schema with `oneOf` or `allOf`. This adjustment aligns with Terraform's capabilities: `oneOf` for union types and `allOf` for intersection types.

For more guidance or to discuss schema adaptations, contact our support team at support@speakeasy.com.

### The `oneOf` Keyword

In Terraform, `oneOf` is defined as a `SingleNestedAttribute` where each potential child is represented by a unique key. To ensure compliance with `oneOf` semantics, `conflicts-with` plan validators are added to confirm that only one of these keys is active at any given time.

If a `oneOf` is declared at the root level of an entity, the Speakeasy generator will extract common property attributes and duplicate them into the root level. This is important if, for instance, a common `id` property is required for making read, update, or delete requests.

### The `allOf` Keyword

For `allOf`, Speakeasy merges all sub-schemas into a single combined attribute, creating a unified schema component that encapsulates all specified properties.


 This is the content for the doc docs/terraform/validation-dependencies.mdx 

 ---
title: "Validation and Dependencies"
description: "Learn how to add custom validation logic and manage attribute dependencies in your Terraform provider."
---

import { Callout } from '~/components'

# Validation and Dependencies

##  Prevent Conflicting Attributes

The `x-speakeasy-conflicts-with` extension indicates that a property conflicts with another, ensuring that certain combinations of properties are not set together. This is ideal for situations where certain attributes are mutually exclusive or setting one attribute invalidates another.

```yaml
components:
  schemas:
    Pet:
      x-speakeasy-entity: Pet
      type: object
      properties:
        name:
          type: string
        name_prefix:
          type: string
          x-speakeasy-conflicts-with: name
        id:
          type: string
        generated_name_options:
          type: object
          properties:
            prefix:
              type: string
              x-speakeasy-conflicts-with:
                - ../name_prefix
                - ../name
                - ../id
```

```tf
resource "example_pet" "happy_pet" {
  name = "Mrs Poppy"
  name_prefix = "Mrs"
}
```

```txt
$ terraform plan
│ Error: Invalid Attribute Combination
│ 
│   with example_pet.happy_pet,
│   on provider.tf line 39, in resource "example_pet" "happy_pet":
│   3:   name_prefix = "test"
│ 
│ Attribute "name" cannot be specified when "name_prefix" is specified
```

## Enforce Mutually Exclusive Attributes (x-speakeasy-xor-with)

The `x-speakeasy-xor-with` extension ensures that exactly one of the listed attributes must be configured at the same time. If multiple attributes are set simultaneously or if no attribute is set, Terraform plan validation fails. This differs from `x-speakeasy-conflicts-with` in that it requires exactly one attribute to be set, while `conflicts-with` allows zero or one attribute to be set.

```yaml
components:
  schemas:
    Pet:
      x-speakeasy-entity: Pet
      type: object
      properties:
        this:
          type: string
        that:
          type: string
        another:
          type: string
          # user MUST configure exactly one of: this, that, or another
          x-speakeasy-xor-with:
            - ../this
            - ../that
```

```tf
resource "example_pet" "happy_pet" {
  this = "value1"
  that = "value2"  # Error: exactly one field must be set
}
```

```txt
$ terraform plan
│ Error: Invalid Attribute Combination
│ 
│   with example_pet.happy_pet,
│   on provider.tf line 2:
│   2:   that = "value2"
│ 
│ Exactly one of attributes [this, that, another] must be specified
```

## Enforce Required Attribute Dependencies (x-speakeasy-required-with)

The `x-speakeasy-required-with` extension ensures that when the annotated field is configured, all the specified dependent fields must also be configured. This is useful for enforcing that certain fields are always configured together.

```yaml
components:
  schemas:
    Pet:
      x-speakeasy-entity: Pet
      type: object
      properties:
        name:
          type: string
        age:
          type: integer
        breed:
          type: string
          # when breed is set, name and age must also be set
          x-speakeasy-required-with:
            - ../name
            - ../age
```

```tf
resource "example_pet" "happy_pet" {
  breed = "Labrador"  # Error: name and age must also be set when breed is set
}
```

```txt
$ terraform plan
│ Error: Missing Required Attributes
│ 
│   with example_pet.happy_pet,
│   on provider.tf line 2:
│   2:   breed = "Labrador"
│ 
│ The following attributes must be configured when 'breed' is specified: [name, age]
```

## OpenAPI Plan Validators

Speakeasy automatically generates certain Terraform configuration value validation handlers based on your OpenAPI specification. When configuration validation is defined, Terraform raises invalid value errors before users can apply their configuration for a better user experience.

By default, these OpenAPI specification properties are automatically handled:

- For `string` types: `enum`, `maxLength`, `minLength`, and `pattern`
- For `integer` types: `enum`, `minimum`, and `maximum`
- For `array` types: `maxItems`, `minItems`, and `uniqueItems`

For use cases not automatically handled, add custom validation logic or reach out to the team.

### Add Custom Validation Logic

Use the `x-speakeasy-plan-validators` extension to add custom validation logic to Terraform plan operations and ensure configurations meet predefined criteria before execution. This extension is essential for scenarios requiring advanced validation logic that JSON Schema cannot accommodate.

```yaml
components:
  schemas:
    Pet:
      type: object
      x-speakeasy-entity: Pet
      properties:
        name:
          type: string
        age:
          type: integer
          x-speakeasy-plan-validators: AgeValidator
```

In this scenario, when Speakeasy next generates the Terraform provider, it will bootstrap a custom validator file located at `internal/validators/int64validators/age_validator.go`, and import the schema configuration wherever `x-speakeasy-plan-validators: AgeValidator` is referenced. You can modify the validator file to contain your logic.

#### Implementation Notes

1. A plan validator is a type conformant to the `terraform-plugin-framework` expected interface. A unique plan validator will be bootstrapped in the appropriate subfolder for the Terraform type it is applied to: `boolvalidators`, `float64validators`, `int64validators`, `listvalidators`, `mapvalidators`, `numbervalidators`, `objectvalidators`, `setvalidators`, or `stringvalidators`. Speakeasy will always create and use a file as `snake_case.go` for a given `x-speakeasy-plan-validators` value.

2. A plan validator operates on the raw (untyped) Terraform value types. However, you can convert a Terraform type to a value type Speakeasy manages (`type_mytype.go`) by using the included reflection utility. This is useful for applying validators to complex types like `list`, `map`, `object`, and `set`.

3. While working with a plan validator, you have the ability to perform various tasks, including initiating network requests. However, it's important to ensure that plan validations do not result in any unintended side effects. Please refer to [the HashiCorp guidance on plan validator development](https://developer.hashicorp.com/terraform/plugin/framework/validation) or reach out in our Slack if you have questions. 

4. It is possible to have an array of plan validators, for example, `x-speakeasy-plan-validators: [MinAgeValidator, MaxAgeValidator]`.

5. A validator can only be applied to a resource attribute. Validators cannot be applied at the same level as the `x-speakeasy-entity` annotation because that becomes the "root" of the Terraform resource. However, validators can access or refer to any data in the entire resource (for an example, see the `x-speakeasy-conflicts-with` validator). The annotation will be ignored for data sources.

6. Speakeasy regenerations do not delete user-written code. If the validator is no longer in use, it will be ignored (no longer referenced) but the source file will remain. You might want to delete such an orphaned validation file for repository hygiene.


 This is the content for the doc docs/testing.mdx 

 ---
title: Contract testing
description: "Learn how to generate and run automated testing for your API and SDKs."
---

import { Callout } from '~/components';
import { LanguageTestingGrid } from "~/features/shared/recipes";

# Testing with Speakeasy

<Callout title="INFO" variant="info">

  Testing features are in early access. Breaking changes may occur.

</Callout>

Speakeasy enables you to verify SDK and API functionality by generating and running SDK tests and API tests. Our solution scales from per-operation SDK tests to end-to-end API tests for validating any multi-step API user journey.

## Design Philosophy

Similar to our [SDK design philosophy](/docs/languages/philosophy), we strive to have best-in-class development experience for Contract testing as well:

- **Human readable** - Generated tests are easy for developers to read and debug. We avoid convoluted abstractions.
- **Batteries-included** - Generated tests for all SDK operations and a real API testing environment is optional. A generated mock API server works out of the box to avoid complex test environment setup, such as data seeding.
- **Rich coverage** - Automatically generated contract tests verify all possible data fields to ensure full coverage. If data examples are not available, realistic example values for the field are used based on naming, type, and format information.
- **Customizable** - Custom tests are supported beside generated tests.
- **Minimal dependencies** - We start with native language libraries and layer on third-party libraries only when the customer benefits far outweigh the cost of the extra dependency. We avoid adding unnecessary dependencies.
- **Easy integration** - Integrating our testing should fit into your existing API development and testing workflows.
- **Open standards** - No vendor lock-in necessary.

## Features

Speakeasy's test generation uses the [Arazzo Specification](/openapi/arazzo) to generate tests for your API. Arazzo is a simple, human-readable, and extensible specification for defining API workflows.
With Arazzo powering test generation, Speakeasy provides the following features:

- Automatically generate contract tests for every operation in your OpenAPI specification.
  - A `.speakeasy/tests.arazzo.yaml` file is generated or modified to include tests for your operations.
  - Use examples available in your OpenAPI document or autogenerates examples based on the field name, type, and format of your schemas.
  - Generates a mock server capable of responding to the API requests, making the tests functional.
- Define custom tests & workflows for any use case and define rich tests capable of:
  - Testing multiple operations.
  - Testing different inputs.
  - Validating the correct response is returned.
  - Run against a real API or mock server.
  - Configure setup and teardown routines for complex E2E tests.

## Prerequisites

The following are requirements for enabling testing features:

- Existing, successfully generating SDK.
- [Speakeasy CLI](/docs/speakeasy-reference/cli/getting-started) or GitHub repository with Actions enabled.
- [Docker](https://www.docker.com/) or equivalent container runtime, if using the mock server for local testing.
- [Enterprise or Business tier account](/pricing).
- The SDK Tests Add-On is enabled.

<LanguageTestingGrid />

## Next Steps

- [Bootstrapping SDK Tests](/docs/customize-testing/bootstrapping-test-generation)
- [Customize your SDK tests](/docs/customize-testing/customizing-sdk-tests)
- [Setup testing in GitHub Actions](/docs/customize-testing/github-actions)
- [Configure Custom API Contract Tests](/docs/api-contract-tests)


 This is the content for the doc events/api-days-paris-2023/index.mdx 

 ---
id: api-days-paris-2024
title: "[Talk] Get Your OpenAPI Spec Ready For Code Generation"
keywords: [openapi, api, codegen, devex, dx]
image: "/media/events/api-days-paris-2023.png"
date: 2023-12-06
location: "CNIT, Paris"
route: "https://www.apidays.global/paris/"
description: "A lot of companies' API specs are good, but if you want to use a spec for code generation (which most companies do), then you need your spec to be great.  We'll walkthrough the most important improvements you can make that will get your spec ready for code generation."
tags:
  - Events
is_featured: false
featured_image: "/media/events/api-days-paris-2023.png"
similar_events: [  ]
---


A lot of companies API specs are good, but if you want to use your spec for code generation (which most companies do), then you need your spec to be great.

We'll walkthrough the most important improvements you can make that will get your spec ready for code generation.


 This is the content for the doc events/categories/[category].mdx 

 ---
title: "Events"
description: "Speakeasy events"
---

import { Category, getStaticPaths as getCategoryStaticPaths, getStaticProps as getCategoryStaticProps } from '~/features/events/category';

<Category />

export const getStaticPaths = getCategoryStaticPaths;
export const getStaticProps = getCategoryStaticProps;


 This is the content for the doc events/fintech-meetup-2024/index.mdx 

 ---
id: fintech--meetup-2024
title: "Meet Speakeasy at Fintech Meetup 2024"
keywords: [openapi, api, fintech]
image: "/media/events/fintech-meetup-1.png"
date: 2024-03-03
location: "Venetian, Las Vegas"
route: "https://fintechmeetup.com/"
description: "Join the companies at the forefront of the Fintech industry! Stop by our booth 606; let's chat all things API and how Speakeasy SDKs can help you take your API to the next level!"
tags:
  - Events
is_featured: true
featured_image: "/media/events/fintech-meetup-1.png"
similar_events: [  ]
---


Join the companies at the forefront of the Fintech industry! Stop by our booth 606; let's chat all things API and how Speakeasy SDKs can help you take your API to the next level!


 This is the content for the doc events/gdc-2024/index.mdx 

 ---
id: gdc-2024
title: "Meet Speakeasy at GDC 2024"
keywords: [openapi, api, middleware, game developers]
image: "/media/events/gdc.png"
date: 2024-03-18
location: "San Francisco, CA"
route: "https://gdconf.com/"
description: "Come see us at the largest gathering of gaming professionals - the Game Developers Conference in San Francisco! If you are looking to supercharge your game or middleware API, stop by our booth S1852!"
tags:
  - Events
is_featured: false
featured_image: "/media/events/gdc.png"
similar_events: [  ]
---


Come see us at the largest gathering of gaming professionals - the Game Developers Conference in San Francisco! If you are looking to supercharge your game or middleware API, stop by our booth S1852!


 This is the content for the doc events/index.mdx 

 ---
title: "Events"
description: "Speakeasy events"
---

import { Events } from '~/features/events/home';

# Events

<Events />


 This is the content for the doc examples/[category].mdx 

 ---
title: "Examples"
description: "How to use Speakeasy's solutions"
breadcrumb: false
---



Categories Examples

 This is the content for the doc examples/hooks/env-auth-hook.mdx 

 ---
title: "Authentication hook for local environment variables"
description: "How to use a SDK hook for authenticating with your API using local environment variables."
image: "/media/examples/generic.png"
date: 2024-04-24
authors:
  - name: Sagar Batchu
  - image_url: '/media/author-headshots/sagar.jpeg'
tags:
  - Hooks
is_featured: true
featured_image: "/media/examples/generic.png"
---

# Authenticating with local environment variables

When authenticating with an API using a SDK, its a common pattern for the value of an `API_KEY` or `token` to default to 
the value of an environment variable. This allows you to easily switch between different environments without changing the code.

In this example, we'll show you how to use a [SDK Hook](/docs/customize/code/sdk-hooks) enable your users to authenticate 
with your API using local environment variables. A SDK Hook is a function that will be executed by the SDK at a specific point in the 
request lifecycle. For this use case we'll leverage a `BeforeRequest` hook.

Inside of our Speakeasy generated SDK hooks are written in the `src/hooks/` directory. We'll make a new hook called in a file called `auth.ts`. 

```typescript src/hooks/auth.ts

import { BeforeRequestHook } from "./types";

export const injectAPIKey: BeforeRequestHook = {
    beforeRequest: async (_, request) => {
        const authz = request.headers.get("Authorization");
        if (authz) {
            return request;
        }

        let token = "";
        if (typeof process !== "undefined") {
            token = process.env["API_KEY"] ?? "";
        }

        if (!token) {
            throw new Error("The API_KEY environment variable is missing or empty; either provide it");
        }

        request.headers.set("Authorization", `Bearer ${token}`);

        return request;
    },
};
```
This hook will check for the presence of an environment variable named `API_KEY` and if it exists, it will add it to the `Authorization` 
header of the request.

Finally to ensure the SDK uses this hook, we need to add it to make sure it is registered with the SDK. This is done in the
`src/hooks/registration.ts` file.

```typescript src/hooks/registration.ts
import { injectAPIKey } from "./auth";
import { Hooks } from "./types";

/*
 * This file is only ever generated once on the first generation and then is free to be modified.
 * Any hooks you wish to add should be registered in the initHooks function. Feel free to define them
 * in this file or in separate files in the hooks folder.
 */

export function initHooks(hooks: Hooks) {
    // Add hooks by calling hooks.register{ClientInit/BeforeRequest/AfterSuccess/AfterError}Hook
    // with an instance of a hook that implements that specific Hook interface
    // Hooks are registered per SDK instance, and are valid for the lifetime of the SDK instance

    hooks.registerBeforeRequestHook(injectAPIKey);
}
```

Finally make sure to update the usage snippet in your readme to reference the environment variable.

 This is the content for the doc examples/hooks/posthog-telemetry-hook.mdx 

 ---
title: "Add telemetry to your SDK with SDK hooks and Posthog"
description: "Use SDK hooks with Posthog to track events."
image: "/media/examples/posthog-hook-example.png"
date: 2024-06-13
authors:
  - name: Luke Hagar
  - image_url: "/media/author-headshots/luke.jpeg"
tags:
  - Hooks
is_featured: true
featured_image: "/media/examples/posthog-hook-example.png"
---

# Add telemetry to your SDK with SDK hooks and Posthog

## Prerequisites
- You will need a Posthog account (If you don't have one, you can sign up [here](https://posthog.com/signup))

## Overview

This guide will walk you through adding telemetry to a TypeScript SDK using SDK hooks and the Posthog Node SDK.

SDK hooks are a way to inject custom actions at various points in the SDK's execution.

You can inject custom actions at the following points in the SDK's execution:

- `On SDK Initialization`
- `Before a request is executed`
- `After a successful response`
- `After an error response`

## Adding the Posthog SDK to your project

To add the Posthog SDK to your project, you will need to add the dependancy to your Speakeasy SDK's `gen.yaml` file under the dependancies section:

```yaml
configVersion: 2.0.0
generation:
  sdkClassName: Petstore
  ...
typescript:
  version: 0.7.11
  additionalDependencies:
    dependencies:
      posthog-node: ^4.0.1 <- This is the line you need to add, ensure the version you add adheres to NPM package standards.
```

After adding the dependency, the Posthog SDK will be included in your projects package.json file everytime you generate your SDK.

## Adding your first SDK hook

Now that you have the Posthog SDK included in your project, you can start adding SDK hooks to your SDK.

First, create a new file in the `src/hooks` directory, and name it `telemetry_hooks.ts`.

In this file you will need to import the hook types for each hook you want to use, as well as the PostHog SDK and initialize the PostHog SDK with your API Key. 
I will be using all four of the hooks in this guide, but you can choose which hooks you want to use. 

```typescript
import {
  AfterErrorContext,
  AfterErrorHook,
  AfterSuccessContext,
  AfterSuccessHook,
  BeforeRequestContext,
  BeforeRequestHook,
  SDKInitHook,
  SDKInitOptions,
} from "./types";

import { PostHog } from "posthog-node";

const PostHogClient = new PostHog("phc_xxxxxxxxxxxxxxxxxx", {
  host: "https://us.i.posthog.com",
});
```

Next you can create a class that will hold your hooks. 
Our class will be `TelemetryHooks` and our first hook will be an `On SDK Initialization` hook.

Below is the start of our `TelemetryHooks` class. This class will hold all of our telemetry hooks. 

```typescript
export class TelemetryHooks
  implements SDKInitHook {
  sdkInit(opts: SDKInitOptions): SDKInitOptions {
    const { baseURL, client } = opts;
    return { baseURL, client };
  }
}
```

This hook allows us to inject custom actions and capture an `SDK Init` event to Posthog at the time the SDK is initialized.

Here are the key points to the capture method outlined below:
- **distinctId**: A `distinctId` can be provided, serving as a unique identifier for either a user or a session. This is particularly useful for tracking recurring events across different sessions, which can aid in identifying and troubleshooting issues.
- **event**: The name of the event is specified to facilitate easier sorting and analysis within Posthog.
- **properties**: An arbitrary set of properties; extra information relevant to the event. Here the contents of the `opts` parameter are added to the event as properties. This allows for detailed tracking of the initialization parameters.

Lastly Posthog's SDKs are asynchronous, so we need to shutdown the SDK after we are done, ensuring events are flushed out before the process ends.

```typescript
export class TelemetryHooks
  implements SDKInitHook {
  sdkInit(opts: SDKInitOptions): SDKInitOptions {
    const { baseURL, client } = opts;

    PostHogClient.capture({
      distinctId: "distinct_id_of_the_user",
      event: "SDK Init",
      properties: {
        baseURL,
        client,
      },
    });

    PostHogClient.shutdown();
    return { baseURL, client };
  }
}
```

Now that we have our `TelemetryHooks` class, we can add the remainder of the hooks.

```typescript
export class TelemetryHooks
  implements SDKInitHook, BeforeRequestHook, AfterSuccessHook, AfterErrorHook {// <- add in the remainder of the hooks you will be implementing
  ...
  }
```

The structure of the remaining hooks is the same, We just supply a `distinctId`, an `event`, and `properties` for each hook.

```typescript
async beforeRequest(
    hookCtx: BeforeRequestContext,
    request: Request
  ): Promise<Request> {
    PostHogClient.capture({
      distinctId: "distinct_id_of_the_user",
      event: "Before Request",
      properties: {
        hookCtx: hookCtx,
      },
    });

    await PostHogClient.shutdown();
    return request;
  }

  async afterSuccess(
    hookCtx: AfterSuccessContext,
    response: Response
  ): Promise<Response> {
    PostHogClient.capture({
      distinctId: "distinct_id_of_the_user",
      event: "After Success",
      properties: {
        hookCtx: hookCtx,
        response: response,
      },
    });

    await PostHogClient.shutdown();
    return response;
  }

  async afterError(
    hookCtx: AfterErrorContext,
    response: Response | null,
    error: unknown
  ): Promise<{ response: Response | null; error: unknown }> {
    PostHogClient.capture({
      distinctId: "distinct_id_of_the_user",
      event: "After Error",
      properties: {
        hookCtx: hookCtx,
        response: response,
        error: error,
      },
    });

    await PostHogClient.shutdown();
    return { response, error };
  }
```

Once all the hooks are implemented, you can now use the `TelemetryHooks` class in your SDK.

in the `src/hooks/registration.ts`, you simply need to import the class from the file you created the hooks in, and register them following the directions in the comment.

```typescript
import { Hooks } from "./types";

import { TelemetryHooks } from "./telemetry_hooks";

/*
 * This file is only ever generated once on the first generation and then is free to be modified.
 * Any hooks you wish to add should be registered in the initHooks function. Feel free to define them
 * in this file or in separate files in the hooks folder.
 */

export function initHooks(hooks: Hooks) {
    // Add hooks by calling hooks.register{ClientInit/BeforeCreateRequest/BeforeRequest/AfterSuccess/AfterError}Hook
    // with an instance of a hook that implements that specific Hook interface
    // Hooks are registered per SDK instance, and are valid for the lifetime of the SDK instance
    hooks.registerBeforeRequestHook(new TelemetryHooks());
    hooks.registerAfterSuccessHook(new TelemetryHooks());
    hooks.registerAfterErrorHook(new TelemetryHooks());
    hooks.registerSDKInitHook(new TelemetryHooks());
}

```

You can now regenerate your SDK and use the new hooks. 

Running API calls using this SDK will surface events up to Posthog.

And you can review all the details in Posthog.

![Screenshot of event data in Posthog.](./assets/posthog-event-data.png)

You can review all the code outlined in this guide in the [SDK Hooks](https://github.com/speakeasy-api/sdk-hooks/blob/main/Posthog/TypeScript.ts) repository.


 This is the content for the doc examples/hooks/sentry-error-hook.mdx 

 ---
title: "Capture errors with SDK hooks and Sentry"
description: "Use SDK hooks with Sentry to track errors."
image: "/media/examples/sentry-hook-example.png"
date: 2024-07-10
authors:
  - name: Luke Hagar
  - image_url: '/media/author-headshots/luke.jpeg'
tags:
  - Hooks
is_featured: true
featured_image: "/media/examples/sentry-hook-example.png"
---

# Capture errors with SDK hooks and Sentry

## Prerequisites
You will need:
- A Sentry account [(If you don't have one, you can sign up [here](https://sentry.io/signup))]
- A Sentry project

## Overview

This guide will show you how to use SDK hooks to integrate error collection into a TypeScript SDK with the Sentry Node SDK, allowing you to insert custom actions at various stages of the SDK's execution:

- `On SDK Initialization`
- `Before a request is executed`
- `After a successful response`
- `After an error response`

## Adding the Sentry SDK to your project

To add the Sentry SDK to your project, you will need to add the dependancy to your Speakeasy SDK's `gen.yaml` file under the dependancies section:

```yaml
configVersion: 2.0.0
generation:
  sdkClassName: Petstore
  ...
typescript:
  version: 0.8.4
  additionalDependencies:
    dependencies:
        '@sentry/node': ^8.9.2 # <- This is the line you need to add, ensure the version you add adheres to NPM package standards.
```

After adding the dependency, the Sentry SDK will be included in your projects package.json file everytime you generate your SDK.

## Adding your first SDK hook

With the Sentry SDK included in your project, you can start adding SDK hooks.

1. Create a new file: In the `src/hooks` directory, create a file named `error_hooks.ts`.
2. Import hook types and Sentry SDK: In this file, import the necessary hook types and initialize the Sentry SDK with your project's DSN.

```typescript
import {
    AfterErrorContext,
    AfterErrorHook,
} from "./types";

import * as Sentry from "@sentry/node";

Sentry.init({
    dsn: process.env.SENTRY_DSN, // <- This is your Sentry DSN, you can find this in your Sentry project settings.
});
```

Next create an `ErrorHooks` class to hold your hooks.

```typescript
export class ErrorHooks
    implements AfterErrorHook {
    afterError(
        hookCtx: AfterErrorContext,
        response: Response | null,
        error: unknown
    ): { response: Response | null; error: unknown } {
        return { response, error };
    }
}
```

This hook allows us to inject custom code that runs on error responses and capture an `SDK Error` event to Sentry at the time the error occurs.

Here are the key points to the class outlined below:

- Use the `AfterErrorHook` interface to define the type of the hook.
- Capture the `hookCtx`, `response`, and `error` in the `afterError` method.
- Return the `response` and `error` so that the SDK can continue to process the error.

Specific notes for using Sentry here:

- Add a breadcrumb to Sentry to capture additional details regarding the error.
- capturing the error in Sentry using `Sentry.captureException(error)`.


```typescript
export class ErrorHooks
    implements AfterErrorHook {
    afterError(
        hookCtx: AfterErrorContext,
        response: Response | null,
        error: unknown
    ): { response: Response | null; error: unknown } {
        Sentry.addBreadcrumb({
            category: "sdk error",
            message: "An error occurred in the SDK",
            level: "error",
            data:{
                hookCtx,
                response,
                error
            }
          });
        Sentry.captureException(error);
        return { response, error };
    }
}
```

Once this hook is implemented, you can now use the `ErrorHooks` class in your SDK.

In the `src/hooks/registration.ts` file import and register the class from the file you created the hooks in:

```typescript
import { Hooks } from "./types";

import { ErrorHooks } from "./error_hooks";

/*
 * This file is only ever generated once on the first generation and then is free to be modified.
 * Any hooks you wish to add should be registered in the initHooks function. Feel free to define them
 * in this file or in separate files in the hooks folder.
 */

export function initHooks(hooks: Hooks) {
    // Add hooks by calling hooks.register{ClientInit/BeforeCreateRequest/BeforeRequest/AfterSuccess/AfterError}Hook
    // with an instance of a hook that implements that specific Hook interface
    // Hooks are registered per SDK instance, and are valid for the lifetime of the SDK instance
    hooks.registerAfterErrorHook(new ErrorHooks());
}

```

You can now regenerate your SDK and use the new hooks. 

Running API calls with this SDK will send error events to your Sentry project, where you can review all the details for each error.

![Screenshot of error data in Sentry.](./assets/sentry-error-data.png)

Review all the code outlined in this guide by visiting the [SDK Hooks](https://github.com/speakeasy-api/sdk-hooks/blob/main/Sentry/TypeScript.ts) repository.


 This is the content for the doc examples/hooks/user-agent-hook.mdx 

 ---
title: "Setting user agents in browser environments"
description: "How to use SDK hooks to set user agents in a browser-compatible way"
image: "/media/examples/generic.png"
date: 2024-02-11
authors:
  - name: Sagar
  - image_url: '/media/author-headshots/sagar.jpeg'
tags:
  - Hooks
is_featured: true
featured_image: "/media/examples/generic.png"
---

# Setting user agents in browser environments

## Overview

When using Speakeasy SDKs in browser environments, setting the user agent header directly is restricted by browser security policies. This guide demonstrates how to use SDK hooks to set user agent information in a browser-compatible way.

## Understanding the challenge

Browsers prevent direct modification of the `User-Agent` header for security reasons. When attempting to set this header in browser environments:
- The header modification may silently fail
- No error will be thrown
- The original browser user agent will be used instead

## Solution using SDK hooks

We can use a `BeforeRequestHook` to implement a fallback mechanism that ensures our SDK version information is properly transmitted, even in browser environments.

```typescript
import { BeforeRequestContext, BeforeRequestHook, Awaitable } from "./types";
import { SDK_METADATA } from "../lib/config";

export class CustomUserAgentHook implements BeforeRequestHook {
    beforeRequest(_: BeforeRequestContext, request: Request): Awaitable<Request> {
        const version = SDK_METADATA.sdkVersion;
        const ua = `speakeasy-sdk/${version}`;

        // Try to set the standard user-agent header first
        request.headers.set("user-agent", ua);

        // Check if the header was actually set (it may silently fail in browsers)
        if (!request.headers.get("user-agent")) {
            // Fall back to a custom header if the user-agent couldn't be set
            request.headers.set("x-sdk-user-agent", ua);
        }

        return request;
    }
}
```

## How the hook works

1. The hook attempts to set the standard `user-agent` header first
2. It then checks if the header was successfully set
3. If the header wasn't set (which happens in browsers), it falls back to using a custom header `x-sdk-user-agent`
4. This ensures your SDK version information is always transmitted, regardless of browser restrictions

## Adding the hook to your SDK

Register the hook in your SDK's hook registration file:

```typescript
import { CustomUserAgentHook } from "./user_agent";
import { Hooks } from "./types";

export function initHooks(hooks: Hooks) {
    hooks.registerBeforeRequestHook(new CustomUserAgentHook());
}
```

## Using hooks with generated SDKs

When working with SDKs generated by Speakeasy, you'll want to follow these best practices:

- Always implement the fallback mechanism to handle browser environments
- Use a consistent format for your user agent string (e.g., `sdk-name/version`)
- Consider including additional relevant information in the user agent string
- Test the implementation in both browser and non-browser environments

This approach ensures your Speakeasy SDK can properly identify itself to your API while remaining compatible with browser security restrictions.


 This is the content for the doc examples/index.mdx 

 ---
title: "Examples"
description: "Speakeasy examples"
---

EXAMPLES


 This is the content for the doc examples/openapi/path-fragments.mdx 

 ---
title: "Solving Equivalent Path Signatures"
description: "Using path fragments to solve equivalent path signatures"
image: "/media/examples/generic.png"
date: 2024-12-10
authors:
  - name: Logan Gingerich
  - image_url: '/media/author-headshots/logan.jpg'
tags:
  - OpenAPI
is_featured: true
featured_image: "/media/examples/generic.png"
---

# Using Path Fragments to Solve Equivalent Path Signatures

Equivalent path signatures in an OpenAPI specification can cause validation errors and/or unexpected behaviors. Adding unique path fragments is an effective method for resolving these conflicts. Path fragments appended with an anchor (e.g., `#id`, `#name`) make paths unique without altering the API’s functionality since the anchor section is not sent in API requests.

## When to Use Path Fragments
Path fragments should be used when the OpenAPI specification contains multiple paths with equivalent signatures but distinct parameter names. For example:

```yaml
paths:
  /v13/deployments/{idOrUrl}:
    get:
      summary: "Get deployment by ID or URL"
      parameters:
        - name: idOrUrl
          in: path
          required: true
          schema:
            type: string
  /v13/deployments/{id}:
    get:
      summary: "Get deployment by ID"
      parameters:
        - name: id
          in: path
          required: true
          schema:
            type: string
```
These paths conflict because their structures are identical, even though their parameter names differ.

## Add Path Fragments

Modify the conflicting paths by appending a unique anchor fragment to each. For example:

   ```yaml
   paths:
     /v13/deployments/{idOrUrl}#idOrUrl:
       get:
         summary: "Get deployment by ID or URL"
         parameters:
           - name: idOrUrl
             in: path
             required: true
             schema:
               type: string
     /v13/deployments/{id}#id:
       get:
         summary: "Get deployment by ID"
         parameters:
           - name: id
             in: path
             required: true
             schema:
               type: string
   ```

Corresponding SDK method signatures:

   ```typescript
   // For /v13/deployments/{idOrUrl}#idOrUrl
   function getDeploymentByIdOrUrl(idOrUrl: string): Deployment {
       // Implementation
   }

   // For /v13/deployments/{id}#id
   function getDeploymentById(id: string): Deployment {
       // Implementation
   }
   ```

## Considerations
- **Impact on Tooling**: Most tools will handle path fragments correctly, but confirm that all downstream tooling supports the updated specification.
- **Path Fragments in Overlays**: Path fragments cannot be added using overlays. They must be introduced directly in the upstream OpenAPI specification.


 This is the content for the doc examples/sdk-generation/overlays/internal-external-versions.mdx 

 ---
title: "Creating Internal and External SDKs"
description: "Create two different versions of an SDK, one for internal use and one for external use, using JSONPath expressions in OpenAPI Overlays."
image: "/media/examples/generic.png"
date: 2024-09-16
authors:
  - name: Logan Gingerich
  - image_url: '/media/author-headshots/logan.jpg'
tags:
  - SDK Generation
is_featured: false
featured_image: "/media/examples/generic.png"
---

# Creating Internal and External SDKs

To create two different versions of an SDK, one for internal use and one for external use, use JSONPath expressions in [OpenAPI Overlays](/openapi/overlays) (a standard extension for modifying existing OpenAPI documents without changing the original). This approach dynamically targets and hides internal operations and parameters from the public SDK. The [`workflow.yaml` file](/docs/workflow-file-reference) can be configured to include Overlays as part of the source definition.

### Using the `x-internal` Extension

First, add an`x-internal: true`extension to all the operations, parameters, and other elements in the OpenAPI spec that should only be available in the internal SDK.

```yaml api.yaml
info:
  title: Sample API
  version: 1.0.0
  description: A sample API with internal paths and parameters.

paths:
  /public-resource:
    get:
      summary: Retrieve public data
      responses:
        '200':
          description: Public data response
          content:
            application/json:
              schema:
                type: object
                properties:
                  id:
                    type: string
                  name:
                    type: string

  /internal-resource:
    x-internal: true   # This path is internal and should not be exposed externally
    get:
      summary: Retrieve internal data
      responses:
        '200':
          description: Internal data response
          content:
            application/json:
              schema:
                type: object
                properties:
                  id:
                    type: string
                  internalInfo:
                    type: string
                    description: Internal information
                    x-internal: true  # This field is internal
        description: "This endpoint is restricted for internal staff management and not visible in public SDKs."
```

### Using JSONPath Expressions in an Overlay

Next, use a JSONPath expression to remove all the internal paths and parameters from the SDK. This removal occurs specifically when generating the internal SDK.

```yaml internal-overlay.yaml
info:
  title: Sample API Overlay
  version: 1.0.0
actions:
  - target: $.paths.*.*[?(@["x-internal"] == true)]
    remove: true
  - target: $.paths.*.*[?(@.properties[?(@["x-internal"] == true)])]
    remove: true
```

Define a workflow that generates both the internal and external SDKs.

```yaml workflow.yaml
workflowVersion: 1.0.0
speakeasyVersion: latest
sources:
  external-api:
    inputs:
      - location: ./api.yaml
    overlays:
      - location: ./external-overlay.yaml
  internal-api:
    inputs:
      - location: ./api.yaml
    overlays:
      - location: ./internal-overlay.yaml
targets:
  internal-sdk:
    target: python
    source: internal-api

  external-sdk:
    target: python
    source: external-api
```      

 This is the content for the doc examples/sdk-generation/overlays/json-path-expressions.mdx 

 ---
title: "Common JSON Path expressions"
description: " use JSONPath expressions in API documentation overlays to dynamically target and modify specific parts of an OpenAPI specification"
image: "/media/examples/generic.png"
date: 2024-05-14
authors:
  - name: Ash Godfrey
  - image_url: '/media/author-headshots/ash.jpg'
tags:
  - SDK Generation
is_featured: true
featured_image: "/media/examples/generic.png"
---

# What are JSONPath Expressions?

JSONPath expressions provide a powerful tool for querying and manipulating JSON data in your OpenAPI specifications. By using JSONPath, you can selectively target specific nodes in your API spec and apply modifications without altering the base structure

## Example JSONPath Expressions

* [All Post or Get Operations](#all-post-or-get-operations)
* [Operations with a Request Body](#operations-with-a-request-body)
* [Operations with a Specific Visibility Notation](#operations-with-a-specific-visibility-notation)
* [Inject Annotations as Siblings](#inject-annotations-as-siblings)

### All Post or Get Operations 

This expression selects all paths that contain either POST or GET operations. It's useful when you want to apply changes or add annotations specifically to these HTTP methods.


**JSONPath Target**

```
$.paths.*[?("post","get")]
```

**Overlay Action**

```yaml
actions:
  - target: $.paths.*[?("post","get")]
    update:
      x-apiture-logging: true
      description: "Logging enabled for all POST and GET operations."
```


### Operations with a Request Body

This targets all operations that include a request body. It's ideal for adding descriptions, examples, or additional schema validations to request bodies.

**JSONPath Target**

```
$.paths.*[?(@.requestBody)]
```

**Overlay Action**

```yaml
actions:
  - target: $.paths.*[?(@.requestBody)]
    update:
      x-custom-validation: "custom-validation-schema"
      description: "Custom validations applied to request bodies."

```

### Operations with a Specific Visibility Notation

This expression is used to find all operations marked with 'admin' visibility. It can be used to apply additional security measures or modify documentation for admin-only endpoints.


**JSONPath Target**

```
$.paths.*[?(@["x-visibility"] == "admin")]
```

**Overlay Action**

```yaml
actions:
  - target: $.paths.*[?(@["x-visibility"] == "admin")]
    update:
      x-custom-security: "enhanced"
      description: "Enhanced security for admin endpoints."
```

### Inject Annotations as Siblings

This expression targets all operations within an OpenAPI specification that have an `operationId` property.

**JSONPath Target**

```
$.paths.*.*[?(@.operationId)]
```

**Overlay Action**

```yaml
actions:
  - target: $.paths.*.*[?(@.operationId)]
    update:
      x-detailed-logging: "enabled"
      log_level: "verbose"
      description: "Verbose logging enabled for this operation to track detailed performance metrics."
```


 This is the content for the doc examples/sdk-generation/overlays/overlays.mdx 

 ---
title: "Common Overlays for SDKs"
description: "Overlays are a quick and easy way to implement changes to your OpenAPI / Swagger spec. We explain how they work and show you how to use overlays."
image: "/media/examples/generic.png"
date: 2023-01-26
authors:
  - name: Ash Godfrey
  - image_url: '/media/author-headshots/ash.jpg'
tags:
  - SDK Generation
is_featured: true
featured_image: "/media/examples/generic.png"
---

# Example Overlays

[Overlays](/docs/prep-openapi/overlays/create-overlays) act as a layer on top of your existing OpenAPI specification, allowing you to apply modifications and extensions seamlessly. They are perfect for adding new features, customizing responses, and adapting specifications to specific needs without disrupting the underlying structure.

To demonstrate the power of overlays, we'll use a sample OpenAPI Specification for "The Speakeasy Bar." This initial spec sets the stage for our overlay examples:

```yaml openapi.yaml
openapi: 3.1.0
info:
  title: The Speakeasy Bar
  version: 1.0.0
  summary: A bar that serves drinks.
servers:
  - url: https://speakeasy.bar
    description: The production server.
security:
  - apiKey: []
tags:
  - name: drinks
    description: The drinks endpoints.
  - name: orders
    description: The orders endpoints.
paths:
  /dinner/:
    post:
      ...
    get:
      ...
  /drinks/:
    post:
      ...
```

Let's explore how overlays can enhance and adapt this specification to do the following: 


* [Adding Speakeasy Extensions](#adding-speakeasy-extensions)
* [Adding SDK Specific Documentation](#adding-sdk-specific-documentation)
* [Modifying Auto-Generated Schemas](#modifying-auto-generated-schemas)
* [Adding Examples to API Documentation](#adding-examples-to-api-documentation)
* [Hiding Internal APIs from a Public SDK](#hiding-internal-apis-from-a-public-sdk)
* [Removing specific PUT operation](#removing-specific-put-operation)
* [Standardize Configurations](#standardize-configurations)


### Adding Speakeasy Extensions

**Objective:** Integrate [Terraform](/docs/terraform/extensions) functionality into the API specification for order management.

**Overlay Action**: 

```yaml overlay.yaml
overlay: 1.0.0
info:
  title: Add Terraform Functionality to Order Schema
  version: 1.1.0
actions:
  - target: "$.components.schemas.Order"
    update:
      - x-speakeasy-entity: Order
        description: "Enables Terraform provider support for the Order schema."

```

### Adding SDK Specific Documentation

**Objective:** Provide tailored instructions for Java and JavaScript SDKs for the `/orders` endpoint.

**Overlay Action**:
```yaml overlay.yaml
overlay: 1.0.0
info:
  title: Distinguish Order Endpoint Docs for Java and JavaScript SDKs
  version: 1.1.1
actions:
  - target: "$.paths['/orders'].post.description"
    update:
      - value: "For Java SDK: use `OrderService.placeOrder()`. For JavaScript SDK: use `orderService.placeOrder()`."
```

### Modifying Auto-Generated Schemas

**Objective:**  Enhance the precision of the Drink schema, making it more descriptive and informative for API consumers. 

```yaml overlay.yaml
overlay: 1.0.0
info:
  title: Refine Drink Schema for Better Clarity
  version: 1.1.2
actions:
  - target: "$.components.schemas.Drink"
    update:
      - properties:
          type:
            type: string
            description: "Type of drink, e.g., 'cocktail', 'beer'."
          alcoholContent:
            type: number
            description: "Percentage of alcohol by volume."
```


### Adding Examples to API Documentation

**Objective:**  Illustrate the drink ordering process with a practical example for user clarity.

```yaml overlay.yaml
overlay: 1.0.0
info:
  title: Add Drink Order Example for User Clarity
  version: 1.1.3
actions:
  - target: "$.paths['/drinks/order'].post"
    update:
      - examples:
          standardOrder:
            summary: "Standard order example"
            value: 
              drink: "Old Fashioned"
              quantity: 1
```

### Hiding Internal APIs from a Public SDK

**Objective:** Restrict the visibility of internal staff management endpoints.

```yaml overlay.yaml
overlay: 1.0.0
info:
  title: Secure Internal Staff Management Endpoint
  version: 1.1.4
actions:
  - target: "$.paths['/internal/staff']"
    update:
      - x-internal: true
        description: "This endpoint is restricted for internal staff management and not visible in public SDKs."
```

### Removing Specific Put Operation

**Objective:** Exclude PUT operations without the `x-speakeasy-entity-operation.`

**Overlay Action**: 

```yaml overlay.yaml
overlay: 1.0.0
info:
  title: Remove Non-Essential PUT Operations
  version: 1.1.0
actions:
  - target: $.paths.*.put[?(! @.x-speakeasy-entity-operation)]
    remove: true

```

### Standardize Configurations

**Objective:** Remove the server and security configurations from each operation within the paths.

**Overlay Action**: 

```yaml overlay.yaml
overlay: 1.0.0
info:
  title: Standardize Server and Security Configurations
  version: 1.1.0
actions:
  - target: $.paths.*.*.servers
    remove: true
  - target: $.paths.*.*.security
    remove: true

```


 This is the content for the doc examples/sdk-generation/override-compile.mdx 

 ---
title: "Overriding Compile Commands for SDK Generation"
description: "Use the `compileCommand` feature to streamline SDK generation and avoid manual maintenance of the `package.json` file during SDK generation."
image: "/media/examples/generic.png"
date: 2025-01-03
authors:
  - name: Logan Gingerich
  - image_url: '/media/author-headshots/logan.jpg'
tags:
  - SDK Generation
is_featured: false
featured_image: "/media/examples/generic.png"
---

## Overriding Compile Commands for SDK Generation

### 1. Remove `package.json` from `.genignore`

The `.genignore` file is used to signal which files are manually managed rather than handled by the SDK generator. It functions similarly to `.gitignore` but for SDK generation purposes. 
Update your `.genignore` file to remove `package.json`. It no longer needs to be ignored as the generation process will manage it automatically.

### 2. Create a Compile Script

Create a file named `openapi/scripts/compile.sh` and add the following script:

```bash
#!/usr/bin/env bash

set -e

npm install
npm run build
```

Ensure the script is executable by running the following command:

```bash
chmod +x openapi/scripts/compile.sh
```

### 3. Update `gen.yaml`

Modify your `.speakeasy/gen.yaml` file to include the `compileCommand` under the TypeScript section. Add the following configuration:

```yaml
typescript:
  compileCommand:
    - bash
    - -c
    - ./openapi/scripts/compile.sh
```

### 4. Verify the Configuration

Run the following command to test that the setup is working as expected:

```bash
speakeasy run --force
```

 This is the content for the doc examples/sdk-generation/pnpm-default.mdx 

 ---
title: "Switching default package manager to pnpm"
description: "Configure pnpm as the default package manager in the SDK generation workflow."
image: "/media/examples/generic.png"
date: 2024-12-05
authors:
  - name: Logan Gingerich
  - image_url: '/media/author-headshots/logan.jpg'
tags:
  - SDK Generation
is_featured: false
featured_image: "/media/examples/generic.png"
---

# Switching default package manager to `pnpm`

## Prerequisite

- A GitHub repository with the Speakeasy [SDK Generation GitHub Action](https://github.com/speakeasy-api/sdk-generation-action) integrated and enabled.

## Adding `pnpm` Support

1. Open the GitHub Actions workflow file (e.g., `.github/workflows/sdk-generation.yaml`).
2. Modify the `generate` job to include the `pnpm_version` input. This ensures pnpm is installed during the action.

### Example Workflow File

```yaml
name: Generate
permissions:
  checks: write
  contents: write
  pull-requests: write
  statuses: write
'on':
  workflow_dispatch:
    inputs:
      force:
        description: Force generation of SDKs
        type: boolean
        default: false
      set_version:
        description: Optionally set a specific SDK version
        type: string
jobs:
  generate:
    uses: speakeasy-api/sdk-generation-action/.github/workflows/workflow-executor.yaml@v15
    with:
      force: ${{ github.event.inputs.force }}
      mode: pr
      set_version: ${{ github.event.inputs.set_version }}
      speakeasy_version: latest
      working_directory: packages/sdk
      pnpm_version: "9.19.4"  # Specify the required pnpm version
    secrets:
      github_access_token: ${{ secrets.GITHUB_TOKEN }}
      npm_token: ${{ secrets.NPM_TOKEN_ELEVATED }}
      speakeasy_api_key: ${{ secrets.SPEAKEASY_API_KEY }}
```
## (Optional) Verifying `pnpm` Installation

Ensure pnpm is used in the workflow by adding a step to verify its presence:

```yaml
steps:
  - name: Verify pnpm installation
    run: pnpm --version
```

This outputs the installed `pnpm` version for confirmation during workflow execution.

## Additional Notes

- Use the same `pnpm_version` as used in local development for consistency.
- Ensure any `package.json` files are compatible with pnpm. Run `pnpm install` locally to verify.

 This is the content for the doc examples/terraform/crud.mdx 

 ---
title: "CRUD Example"
description: "Learn how to annotate an operation as creating, reading, updating or deleting a remote entity."
image: "/media/examples/generic.png"
date: 2023-01-26
authors:
  - name: Ash Godfrey
  - image_url: "/media/author-headshots/ash.jpg"
tags:
  - Terraform
is_featured: true
featured_image: "/media/examples/generic.png"
---

 

# What is a Terraform Provider

A Terraform provider is a plugin that extends Terraform, allowing it to manage external resources such as cloud services. It serves as a mediator between Terraform and external APIs, using the [Terraform Plugin Protocol](https://developer.hashicorp.com/terraform/plugin/terraform-plugin-protocol) for communication.

Terraform providers, built with the [terraform-plugin-framework](https://github.com/hashicorp/terraform-plugin-framework), include:

1. **Resources** and **Data Sources**: described using a Terraform Type Schema, which is a `map[string]Attribute`, where an Attribute could be _Primitive_, _Composite_, or _List_.
2. **Create**, **Read**, **Update** and **Delete** methods: the interface through which the provider interacts with an external resource (usually an API) to reconcile a desired terraform specification with the actual state of the resource.
3. **Plan Validators**: defined to enable the validation of a desired specification at Plan-time, without making API calls to the external resource.
4. **Plan Modifiers**: defined to enable custom semantics around the Terraform Type Schema, and how it is reconciled with the external state to make a Plan.
5. **Resource imports**: defined to enable Terraform Specifications to be generated from existing resources.

## A simple CRUD example

Let's explore how to define a resource and map API operations to Terraform methods using annotations for CRUD actions.


<div className="ScrollyCoding">

### !!steps Defining a Resource

Use `x-speakeasy-entity` to define a resource that you want to use terraform to manage.

```yaml ! openapi.yaml
# !focus(53)
  /drinks:
    post:
      x-speakeasy-entity-operation: Drink#create
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/Drink"
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/Drink"
  /drinks/{id}:
    parameters:
      - name: id
        in: path
        required: true
        schema:
          type: string
    get:
      x-speakeasy-entity-operation: Drink#read
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/Drink"
    post:
      x-speakeasy-entity-operation: Drink#update
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/Drink"
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/Drink"
    delete:
      x-speakeasy-entity-operation: Drink#delete
      responses:
        "202":
          description: OK
components:
  schemas:
    Drink:
      x-speakeasy-entity: Drink
      type: object
      properties:
        name:
          description: The name of the drink.
          type: string
          examples:
            - Old Fashioned
            - Manhattan
            - Negroni
        type:
          $ref: "#/components/schemas/DrinkType"
        price:
          description: The price of one unit of the drink in US cents.
          type: number
          examples:
            - 1000 # $10.00
            - 1200 # $12.00
            - 1500 # $15.00
      required:
        - name
        - price
```

---

### !!steps Mapping API Operations to Resources Methods

An OpenAPI specification tracks a large list of [`Operation` objects](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.1.0.md#operationObject).

For a Terraform Provider generated by Speakeasy, the key element is the [the `x-speakeasy-entity-operation` annotation](/docs/terraform/extensions#the-x-speakeasy-entity-operation-annotation). This annotation clarifies the purpose of each operation in terms of how it affects the associated remote entity.

```yaml ! openapi.yaml
# !focus(3)
# !focus(24)
# !focus(32)
# !focus(46)
  /drinks:
    post:
      x-speakeasy-entity-operation: Drink#create
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/Drink"
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/Drink"
  /drinks/{id}:
    parameters:
      - name: id
        in: path
        required: true
        schema:
          type: string
    get:
      x-speakeasy-entity-operation: Drink#read
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/Drink"
    post:
      x-speakeasy-entity-operation: Drink#update
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/Drink"
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/Drink"
    delete:
      x-speakeasy-entity-operation: Drink#delete
      responses:
        "202":
          description: OK
components:
  schemas:
    Drink:
      x-speakeasy-entity: Drink
      type: object
      properties:
        name:
          description: The name of the drink.
          type: string
          examples:
            - Old Fashioned
            - Manhattan
            - Negroni
        id:
          description: The ID of the drink
          readOnly: true
          type: string
        type:
          $ref: "#/components/schemas/DrinkType"
        price:
          description: The price of one unit of the drink in US cents.
          type: number
          examples:
            - 1000 # $10.00
            - 1200 # $12.00
            - 1500 # $15.00
      required:
        - name
        - price
```

</div>

## Managing Complex API Semantics with Speakeasy

APIs can have unique semantics not fully described by OpenAPI specs. To address this we have:

1. **Inference Rules**: Automatically derive most API semantics from the OpenAPI spec, with the exception of the `x-speakeasy-entity-operation` annotation.
2. **OpenAPI Extensions**: For more complex cases, use extensions to provide detailed configurations. These extensions are documented in the [Terraform Extensions](/docs/terraform/extensions/) section of this documentation.
3. **Support**: Our engineering team continually updates inference rules and extensions to accommodate new API patterns.

Read more in our [documentation here](/docs/create-terraform), or [view more examples here](/examples/categories/terraform).


 This is the content for the doc examples/terraform/hoisting.mdx 

 ---
title: "Hoisting"
description: "Hoisting enables flattening of an API request or API response body to make it more tightly align with the resource semantics."
image: "/media/examples/generic.png"
date: 2023-01-26
authors:
  - name: Ash Godfrey
  - image_url: "/media/author-headshots/ash.jpg"
tags:
  - Terraform
is_featured: true
featured_image: "/media/examples/generic.png"
---

 

# What is hoisting?

Hoisting is a technique used in API design to reorganize the structure of data in API requests and responses. Its main goal is to simplify the way data is presented by moving nested or deeply structured data to a higher level in the API's response or request body. This process makes the data easier to work with for developers by reducing complexity and aligning the structure more closely with how resources are conceptually understood.

In essence, hoisting "flattens" data structures. For APIs, this means transforming responses or requests so that important information is more accessible and not buried within nested objects. This is particularly beneficial when dealing with APIs that serve complex data models, as it can make the data easier to parse and use without extensive traversal of nested objects.

## When should you use hoisting?

Hoisting is usually applied in specific scenarios to improve the design and usability of APIs:

- **Complex Nested Structures**: Employ hoisting when your API deals with complex, deeply nested data. It streamlines access to important information, reducing the need for deep navigation.
- **Frequent Data Access**: Use hoisting for elements that are often accessed or critical to operations, making them more directly accessible.
- **Data Model Alignment**: Apply hoisting to better align the API's data structure with the conceptual model of the resources.

<div className="ScrollyCoding">

## !!steps Initial Structure: Without Hoisting

Initially, our data structure represents a hierarchical model with nested entities, depicted as a tree.

`x-speakeasy-entity: 1` at the top, with entities 2 and 3 as direct descendants. Entity 2 further nests entities 4, which branches into 5 and 6.

{/* prettier-ignore */}
```bash !
 (1)
 / \
2   3
 \
  4
 / \
5   6
```

---

## !!steps Step 1: Selecting an entity for hoisting

Entity (2) is marked with `x-speakeasy-entity` for hoisting.

{/* prettier-ignore */}
```bash !
    1
   / \
 (2)  3
   \
    4
   / \
  5   6
```

---

## !!steps Step 2

After applying hoisting, the structure is reorganized to prioritize `x-speakeasy-entity: 2`, making its leaf nodes directly accessible and flattening the remaining structure.

`x-speakeasy-entity: 2`

{/* prettier-ignore */}
```bash !
x-speakeasy-entity: 2

 (2)
 / \
3   4
   / \
  5   6
```

</div>

## Real-World Application: Flattening a "data" property

The JSON Schemas for `Drink`, `Drink`, and `{ drinkType: $DrinkType }` will be each considered the root of a Terraform Type Schema, and will be merged together to form the final Terraform Type Schema using Attribute Inference.

However, this is not always desired. Consider this alternative response:

<div className="ScrollyCoding" data-fullheight>

## !!steps Original

In the original API design, the request and response body are structured equivalently, without nested elements. This approach is straightforward but might not always suit complex data relationships or requirements.

```yaml ! openapi.yaml
# !focus(18:23)
/drinks:
  post:
    x-speakeasy-entity-operation: Drink#create
    parameters:
      - name: type
        in: query
        description: The type of drink
        required: false
        deprecated: true
        schema:
          $ref: "#/components/schemas/DrinkType"
    requestBody:
      required: true
      content:
        application/json:
          schema:
            $ref: "#/components/schemas/Drink"
    responses:
      "200":
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/Drink"
      "5XX":
        $ref: "#/components/responses/APIError"
      default:
        $ref: "#/components/responses/UnknownError"
```

---

## !!steps Alternate

The alternate approach introduces a nested `data` property in the API response, which can encapsulate the drink information more distinctly, albeit adding a layer of complexity in data access.

```yaml ! openapi.yaml
# !focus(18:26)
/drinks:
  post:
    x-speakeasy-entity-operation: Drink#create
    parameters:
      - name: type
        in: query
        description: The type of drink
        required: false
        deprecated: true
        schema:
          $ref: "#/components/schemas/DrinkType"
    requestBody:
      required: true
      content:
        application/json:
          schema:
            $ref: "#/components/schemas/Drink"
  responses:
    "200":
      content:
        application/json:
          schema:
            type: object
            properties:
              data:
                $ref: "#/components/schemas/Drink"
      "5XX":
        $ref: "#/components/responses/APIError"
      default:
        $ref: "#/components/responses/UnknownError"
```

---

## !!steps Original Code

Using the same request/response bodies, speakeasy would generate the following type schema

```go ! drink_resource.go
func (r *DrinkResource) Schema(ctx context.Context, req resource.SchemaRequest, resp *resource.SchemaResponse) {
  resp.Schema = schema.Schema{
    MarkdownDescription: "Drink Resource",

    Attributes: map[string]schema.Attribute{
      "drink_type": schema.StringAttribute{
        Optional:    true,
        Computed:    true
        Description: `The type of drink.`,
        stringvalidator.OneOf(
          "cocktail",
          "non-alcoholic",
          "beer",
          "wine",
          "spirit",
          "other",
        ),
      },
      "name": schema.Int64Attribute{
        Required:    true,
        Description: `The name of the drink.`,
      },
      "price": schema.StringAttribute{
        Required:    true,
        Description: `The price of one unit of the drink in US cents.`,
      },
    },
  }
}
```

---

## !!steps Alternative Code

When generated, the provider schema would look like this: not understanding that `data` was a nested object, and instead treating it as a root of the schema.

```go ! drink_resource.go
// !focus(25:40)
func (r *DrinkResource) Schema(ctx context.Context, req resource.SchemaRequest, resp *resource.SchemaResponse) {
  resp.Schema = schema.Schema{
    MarkdownDescription: "Drink Resource",

    Attributes: map[string]schema.Attribute{
      "drink_type": schema.StringAttribute{
        Optional:    true,
        Description: `The type of drink.`,
        stringvalidator.OneOf(
          "cocktail",
          "non-alcoholic",
          "beer",
          "wine",
          "spirit",
          "other",
        ),
      },
      "name": schema.Int64Attribute{
        Required:    true,
        Description: `The name of the drink.`,
      },
      "price": schema.StringAttribute{
        Required:    true,
        Description: `The price of one unit of the drink in US cents.`,
      },
      "data": schema.SingleNestedAttribute{
        Computed: true,
        Attributes: map[string]schema.Attribute{
          "drink_type": schema.StringAttribute{
            Computed:    true
            Description: `The type of drink.`,
          },
          "name": schema.Int64Attribute{
            Computed:    true
            Description: `The name of the drink.`,
          },
          "price": schema.StringAttribute{
            Computed:    true,
            Description: `The price of one unit of the drink in US cents.`,
          },
        },
      },
    },
  }
}
```

---

## !!steps The Fix: Implementing Hoisting

By applying the [`x-speakeasy-entity` annotation](/docs/terraform/extensions#the-x-speakeasy-entity-annotation), we direct the schema generation process to consider the `Drink` schema as the root of the type schema, effectively flattening the response structure for easier access.

```yaml ! openapi.yaml
# !focus(34)
  /drinks:
    post:
      x-speakeasy-entity-operation: Drink#create
      parameters:
        - name: type
          in: query
          description: The type of drink
          required: false
          deprecated: true
          schema:
            $ref: "#/components/schemas/DrinkType"
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/Drink"
    responses:
      "200":
        content:
          application/json:
            schema:
              type: object
              properties:
                data:
                  $ref: "#/components/schemas/Drink"
        "5XX":
          $ref: "#/components/responses/APIError"
        default:
          $ref: "#/components/responses/UnknownError"
components:
  schemas:
    Drink:
      x-speakeasy-entity: Drink
      type: object
      properties:
        name:
          description: The name of the drink.
          type: string
          examples:
            - Old Fashioned
            - Manhattan
            - Negroni
        type:
          $ref: "#/components/schemas/DrinkType"
        price:
          description: The price of one unit of the drink in US cents.
          type: number
          examples:
            - 1000 # $10.00
            - 1200 # $12.00
            - 1500 # $15.00
      required:
        - name
        - price
```

---

## !!steps Finalized Schema: Simplified Access

The final provider schema reflects a flattened structure, similar to the original API design but with the flexibility to include nested data when necessary.

```go ! drink_resource.go
func (r *DrinkResource) Schema(ctx context.Context, req resource.SchemaRequest, resp *resource.SchemaResponse) {
  resp.Schema = schema.Schema{
    MarkdownDescription: "Drink Resource",

    Attributes: map[string]schema.Attribute{
      "drink_type": schema.StringAttribute{
        Optional:    true,
        Computed:    true
        Description: `The type of drink.`,
        stringvalidator.OneOf(
          "cocktail",
          "non-alcoholic",
          "beer",
          "wine",
          "spirit",
          "other",
        ),
      },
      "name": schema.Int64Attribute{
        Required:    true,
        Description: `The name of the drink.`,
      },
      "price": schema.StringAttribute{
        Required:    true,
        Description: `The price of one unit of the drink in US cents.`,
      },
    },
  }
}
```

</div>


 This is the content for the doc examples/terraform/merged-entity.mdx 

 ---
title: "Creating a Merged Terraform entity"
description: "Specify how to orchestrate disparate API calls to create, update or delete a single merged entity that is resolved across multiple JSON Schemas in your OpenAPI spec."
image: "/media/examples/generic.png"
date: 2023-01-26
authors:
  - name: Ash Godfrey
  - image_url: "/media/author-headshots/ash.jpg"
tags:
  - Terraform
is_featured: true
featured_image: "/media/examples/generic.png"
---

 

# Creating a Merged Terraform Entity

Creating a merged Terraform entity involves combining data from separate API endpoints into a single Terraform resource. This process allows Terraform to manage complex entities that span multiple API calls for their lifecycle operations—create, read, update, and delete.

## Example Scenario: Merging Resource Entities

Consider a scenario where managing a `drink` resource requires setting a `visibility` attribute post-creation using separate API endpoints:

1. **Create the drink**: Invoke `POST /drink` to create the drink entity.
2. **Set visibility**: Follow with `POST /drink/{id}/visibility` to configure visibility.


<div className="ScrollyCoding">

## !!steps Step 1: Define API Endpoints

Identify the API endpoints involved in the operation. For instance, creating a `drink` and setting its visibility involves two distinct endpoints:

```yaml ! openapi.yaml
# !focus(1:2)
# !focus(27:28)
/drinks:
  post:
    requestBody:
      required: true
      content:
        application/json:
          schema:
            type: object
            properties:
              name:
                type: string
            required: [name]
    responses:
      "200":
        content:
          application/json:
            schema:
              type: object
              properties:
                data:
                  type: object
                  properties:
                    id:
                      type: string
                  required: [id]
              required: [data]
/drink/{id}/visibility:
  post:
    requestBody:
      required: true
      content:
        application/json:
          schema:
            type: object
            properties:
              visibility:
                type: string
                enum:
                  - public
                  - private
    responses:
      "202":
        description: OK
```

---

## !!steps Step 2: Annotate for Execution Order

Mark both operations with annotations. For the operation requiring the `id` parameter, assign an `order` property value greater than the first operation to reflect its dependency on the `id` attribute.

```yaml ! openapi.yaml
# !focus(3)
# !focus(30)
/drinks:
  post:
    x-speakeasy-entity-operation: Drink#create
    requestBody:
      required: true
      content:
        application/json:
          schema:
            type: object
            properties:
              name:
                type: string
            required: [name]
    responses:
      "200":
        content:
          application/json:
            schema:
              type: object
              properties:
                data:
                  type: object
                  properties:
                    id:
                      type: string
                  required: [id]
              required: [data]
/drink/{id}/visibility:
  post:
    x-speakeasy-entity-operation: Drink#create#2
    requestBody:
      required: true
      content:
        application/json:
          schema:
            type: object
            properties:
              visibility:
                type: string
                enum:
                  - public
                  - private
    responses:
      "202":
        description: OK
```

---

## !!steps Step 3: Configure Hoisting for Response Unwrapping

Use `x-speakeasy-entity` annotations to simplify response handling by hoisting, avoiding nested data wrapping.

```yaml ! openapi.yaml
# !focus(9)
# !focus(24)
# !focus(39)
/drinks:
  post:
    x-speakeasy-entity-operation: Drink#create
    requestBody:
      required: true
      content:
        application/json:
          schema:
            x-speakeasy-entity: Drink
            type: object
            properties:
              name:
                type: string
            required: [name]
    responses:
      "200":
        content:
          application/json:
            schema:
              type: object
              properties:
                data:
                  type: object
                  x-speakeasy-entity: Drink
                  properties:
                    id:
                      type: string
                  required: [id]
              required: [data]
/drink/{id}/visibility:
  post:
    x-speakeasy-entity-operation: Drink#create#2
    requestBody:
      required: true
      content:
        application/json:
          schema:
            type: object
            x-speakeasy-entity: Drink
            properties:
              visibility:
                type: string
                enum:
                  - public
                  - private
    responses:
      "202":
        description: OK
```

</div>

## Advanced Example Step-by-Step

When an [x-speakeasy-entity-operation](/docs/terraform/extensions#the-x-speakeasy-entity-operation-annotation) is defined, the request body, parameters, and response bodies of `CREATE` and `READ` operations are considered the root of the Terraform Type Schema.

<div className="ScrollyCoding">

## !!steps Step 1:

Adding a `x-speakeasy-entity-operation: Drink#create` annotation marks the `POST /drinks` operation as CREATING a `drink` resource.

```yaml ! openapi.yaml
# !focus(3)
  /drinks:
    post:
      x-speakeasy-entity-operation: Drink#create
      parameters:
        - name: type
          in: query
          description: The type of drink
          required: false
          deprecated: true
          schema:
            $ref: "#/components/schemas/DrinkType"
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/Drink"
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/Drink"
        "5XX":
          $ref: "#/components/responses/APIError"
        default:
          $ref: "#/components/responses/UnknownError"
components:
  schemas:
    Drink:
      type: object
      properties:
        name:
          description: The name of the drink.
          type: string
          examples:
            - Old Fashioned
            - Manhattan
            - Negroni
        type:
          $ref: "#/components/schemas/DrinkType"
        price:
          description: The price of one unit of the drink in US cents.
          type: number
          examples:
            - 1000 # $10.00
            - 1200 # $12.00
            - 1500 # $15.00
      required:
        - name
        - price
    DrinkType:
      description: The type of drink.
      type: string
      enum:
        - cocktail
        - non-alcoholic
        - beer
        - wine
        - spirit
        - other
```

---

## !!steps Step 2:

Parameters, Request Bodies, and Response Bodies (associated with a 2XX status code) are each considered roots of the Terraform Type Schema

```yaml ! openapi.yaml
# !focus(4)
# !focus(11)
# !focus(15:17)
# !focus(21:23)
  /drinks:
    post:
      x-speakeasy-entity-operation: Drink#create
      parameters:
        - name: type
          in: query
          description: The type of drink
          required: false
          deprecated: true
          schema:
            $ref: "#/components/schemas/DrinkType"
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/Drink"
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/Drink"
        "5XX":
          $ref: "#/components/responses/APIError"
        default:
          $ref: "#/components/responses/UnknownError"
components:
  schemas:
    Drink:
      type: object
      properties:
        name:
          description: The name of the drink.
          type: string
          examples:
            - Old Fashioned
            - Manhattan
            - Negroni
        type:
          $ref: "#/components/schemas/DrinkType"
        price:
          description: The price of one unit of the drink in US cents.
          type: number
          examples:
            - 1000 # $10.00
            - 1200 # $12.00
            - 1500 # $15.00
      required:
        - name
        - price
    DrinkType:
      description: The type of drink.
      type: string
      enum:
        - cocktail
        - non-alcoholic
        - beer
        - wine
        - spirit
        - other
```

---

## !!steps Step 3

The Terraform Type Schema merges all 3 of these together, and inferring links between the Operation and the Attributes. Note that similarly named attributes are merged together, and that the `DrinkType` attribute is inferred to be a `DrinkType` enum, rather than a `string`.

```yaml ! derived.yaml
 - create.parameters:
     type:
       from: "paths["/drinks"].post.parameters[0]"
       type: enum
       enumValues:
          type: string
          values:
            - cocktail
            - non-alcoholic
            - beer
            - wine
            - spirit
            - other
  - create.requestBody:
      name:
        from: "components.schemas.Drink.properties.name"
        description: The name of the drink.
        type: string
        examples:
          - Old Fashioned
          - Manhattan
          - Negroni
      drinkType:
        from: "components.schemas.Drink.properties.type"
        type: string
        enum:
        - cocktail
        - non-alcoholic
        - beer
        - wine
        - spirit
        - other
      price:
        from: "components.schemas.Drink.properties.price]"
        type: number
  - create.successResponseBody:
      name:
        from: "components.schemas.Drink.properties.name"
        description: The name of the drink.
        type: string
        examples:
          - Old Fashioned
          - Manhattan
          - Negroni
      drinkType:
        from: "components.schemas.Drink.properties.type"
        type: string
        enum:
        - cocktail
        - non-alcoholic
        - beer
        - wine
        - spirit
        - other
      price:
        from: "components.schemas.Drink.properties.price]"
        type: number
```

---

## !!steps Step 4

These attributes are then merged together. If any properties conflict in type, an error is raised.

```yaml ! derived.yaml
 - create.requestShard:
     type:
       from: "paths["/drinks"].post.parameters[0]"
       type: enum
       enumValues:
          type: string
          values:
            - cocktail
            - non-alcoholic
            - beer
            - wine
            - spirit
            - other
    name:
      from: "components.schemas.Drink.properties.name"
      description: The name of the drink.
      type: string
      examples:
        - Old Fashioned
        - Manhattan
        - Negroni
    drinkType:
      from: "components.schemas.Drink.properties.type"
      type: string
      enum:
      - cocktail
      - non-alcoholic
      - beer
      - wine
      - spirit
      - other
    price:
      from: "components.schemas.Drink.properties.price]"
      type: number
  - create.responseShard:
      name:
        from: "components.schemas.Drink.properties.name"
        description: The name of the drink.
        type: string
        examples:
          - Old Fashioned
          - Manhattan
          - Negroni
      drinkType:
        from: "components.schemas.Drink.properties.type"
        type: string
        enum:
        - cocktail
        - non-alcoholic
        - beer
        - wine
        - spirit
        - other
      price:
        from: "components.schemas.Drink.properties.price]"
        type: number
```

---

## !!steps Step 5

First, the `type` is taken from the OpenAPI `type`. It is `Optional: true` because it is not `required: true` or `nullable: true`.
The description is taken from the OpenAPI `description`. The `examples` will be used to generate an example for the documentation

```go ! drink_resource.go
// !focus(6:9)
func (r *DrinkResource) Schema(ctx context.Context, req resource.SchemaRequest, resp *resource.SchemaResponse) {
  resp.Schema = schema.Schema{
    MarkdownDescription: "Drink Resource",

    Attributes: map[string]schema.Attribute{
      "type": schema.StringAttribute{
        Optional:    true,
        Description: `The type of drink.`,
      },
    },
  }
}
```

---

## !!steps Step 6

Second, the `drinkType` is taken from the request and response bodies. It's converted to snake case as `drink_type` to follow terraform best-practices.

It is `Optional: true` because it was not a member of the OpenAPI `requiredProperties`. It is `Computed: true` because even if not defined, the API is defined to (optionally) return a value for it.

A plan validator is added with each of the enum values. This will be used to validate the plan at plan-time.

```go ! drink_resource.go
// !focus(10:21)
func (r *DrinkResource) Schema(ctx context.Context, req resource.SchemaRequest, resp *resource.SchemaResponse) {
  resp.Schema = schema.Schema{
    MarkdownDescription: "Drink Resource",

    Attributes: map[string]schema.Attribute{
      "type": schema.StringAttribute{
        Optional:    true,
        Description: `The type of drink.`,
      },
      "drink_type": schema.StringAttribute{
        Optional:    true,
        Computed:    true
        Description: `The type of drink.`,
        stringvalidator.OneOf(
          "cocktail",
          "non-alcoholic",
          "beer",
          "wine",
          "spirit",
          "other",
        ),
      },
    },
  }
}
```

---

## !!steps Step 7

The other parameters are also pulled in from the request body. Both of them are required, with their type being derived from the equivalent Terraform primitive to their OpenAPI type.

```go ! drink_resource.go
// !focus(22:30)
func (r *DrinkResource) Schema(ctx context.Context, req resource.SchemaRequest, resp *resource.SchemaResponse) {
  resp.Schema = schema.Schema{
    MarkdownDescription: "Drink Resource",

    Attributes: map[string]schema.Attribute{
      "type": schema.StringAttribute{
        Optional:    true,
        Description: `The type of drink.`,
      },
      "drink_type": schema.StringAttribute{
        Optional:    true,
        Computed:    true
        Description: `The type of drink.`,
        stringvalidator.OneOf(
          "cocktail",
          "non-alcoholic",
          "beer",
          "wine",
          "spirit",
          "other",
        ),
      },
      "name": schema.Int64Attribute{
        Required:    true,
        Description: `The name of the drink.`,
      },
      "price": schema.StringAttribute{
        Required:    true,
        Description: `The price of one unit of the drink in US cents.`,
      },
    },
  }
}
```

---

## !!steps Step 8: Cleanup

In this API `drinkType` and `type` appear to refer to the same thing. `type` comes from a query parameter, whereas `drinkType` comes from the response body.

This kind of pattern can be found in more legacy APIs, where parameters have been moved around and renamed, but older versions of those attributes are left around for backwards capability reasons.

To clean up, we have many options we can apply to the API to describe what we want to happen:

1. `x-speakeasy-ignore: true` could be applied to the query parameter. After this point, it won't be configurable, and will never be sent.
2. `x-speakeasy-match: drinkType` could be applied to the query parameter. This will cause it to always be sent in the request, the same as the `drink_type` property.
3. `x-speakeasy-name-override: type` could be applied to the `drinkType` property. This will rename it as `type`, and ensure both `drinkType` request body key and `type` query parameter are both always sent.

```go ! drink_resource.go
func (r *DrinkResource) Schema(ctx context.Context, req resource.SchemaRequest, resp *resource.SchemaResponse) {
  resp.Schema = schema.Schema{
    MarkdownDescription: "Drink Resource",

    Attributes: map[string]schema.Attribute{
      "drink_type": schema.StringAttribute{
        Optional:    true,
        Computed:    true
        Description: `The type of drink.`,
        stringvalidator.OneOf(
          "cocktail",
          "non-alcoholic",
          "beer",
          "wine",
          "spirit",
          "other",
        ),
      },
      "name": schema.Int64Attribute{
        Required:    true,
        Description: `The name of the drink.`,
      },
      "price": schema.StringAttribute{
        Required:    true,
        Description: `The price of one unit of the drink in US cents.`,
      },
    },
  }
}
```

</div>


 This is the content for the doc examples/terraform/remove-nontf-endpoints.mdx 

 ---
title: "Removing non-Terraform endpoints from your OpenAPI document"
description: "Use an overlay to remove endpoints not used in Terraform generation."
image: "/media/examples/generic.png"
date: 2024-04-02
authors:
  - name: Sagar Batchu
  - image_url: '/media/author-headshots/sagar.jpeg'
tags:
  - Terraform
is_featured: true
featured_image: "/media/examples/generic.png"
---

# Overlay to remove non-Terraform endpoints

Often generating a Terraform provider from your OpenAPI spec means using a subset of endpoints to generate the provider. Endpoints or `paths` in your spec not used for terraform
generation will still be used to generate a Go client inside your provider. This can lead to a bloated provider with unused endpoints. If you want to remove these consider using 
the following overlay. 

```yaml
overlay: 1.0.0
info:
  title: Overlay openapi.yaml
  version: 0.1.0
actions: 
  - target: $.paths.*.*[?(!@.x-speakeasy-entity-operation && @.operationId)] # Find all paths that do not have x-speakeasy-entity-operation and operationId
    remove: true
```
When applied to an OpenAPI specification this overlay will remove any paths from the specification that are not tagged with `x-speakeasy-entity-operation`. The operation needed to 
map an OpenAPI `operationId` to a terraform resource.

To apply this overlay run `speakeasy overlay apply -s {your-spec.yaml} -o {overlay.yaml}`. This will generate a new OpenAPI specification with the paths removed.

Finally add this to your terraform generation workflow by using `speakeasy configure sources` to add an overlay to any source with an existing openapi specificaiton configured.

 This is the content for the doc guides/index.mdx 

 ---
title: "Guides"
description: "Speakeasy guides"
---

 
 
# Speakeasy guides

Here, you'll find a comprehensive collection of step-by-step guides, best practices, and tutorials to help you get the most out of Speakeasy. Whether you're just getting started or looking to delve deeper into advanced features, our guides are tailored to support you at every step of your journey.

If you haven't used OpenAPI before, start with our [guide to creating an OpenAPI schema from your existing code](openapi/frameworks.mdx).

<div className="IconGrid">FrameworkGuidesData</div>

## OpenAPI guides

- [Complete OpenAPI reference guide](/openapi)
- [Using `additionalProperties` with Speakeasy](/guides/openapi/additionalproperties)
- [Using `x-codeSamples` to sync SDK usage snippets and your documentation site](guides/openapi/x-codesamples)

## SDKs

- [Create a monorepo with Speakeasy and GitHub](/guides/sdks/creating-a-monorepo)
- [Utilizing user agent strings for telemetry](/guides/sdks/utilizing-user-agent-strings)


 This is the content for the doc guides/openapi/additionalproperties.mdx 

 ---
description: "Using additional properties with Speakeasy."
---

{/*import { Tabs } from "@speakeasy/nextra-theme";*/}

# Understanding `additionalProperties`

In a standard JSON schema, the [`additionalProperties`](https://json-schema.org/understanding-json-schema/reference/object#additional-properties) keyword controls whether objects can include properties beyond those explicitly defined. By default, if `additionalProperties` is not specified, it's considered to be `true`, allowing objects to carry arbitrary additional data.

## The Speakeasy approach

At Speakeasy, we diverge from the standard approach by setting `additionalProperties` to `false` unless explicitly defined otherwise. This approach encourages defining fully-typed objects, promoting clear and comprehensive documentation of their structure. This method aligns with the common developer expectation of creating APIs with precise and predictable data models.

API developers generally prefer closed objects as the default, rather than open ones, and setting `additionalProperties: false` in the spec would be tedious. Most backend frameworks that generate OpenAPI schemas rarely add `additionalProperties: false`, even when that behavior is intended.

## Using `additionalProperties: true`

Setting `additionalProperties` to `true` is beneficial for schemas that need flexibility to dynamically accommodate unknown fields. This setting is ideal for scenarios where the data model may extend beyond the initially defined properties, allowing for future growth without requiring schema revisions.

Imagine a scenario where an API endpoint accepts user-generated content with a set of core properties but also needs to be open to future extensions. By setting `additionalProperties` to `true`, the API can accept and store these extensions without needing schema updates for each new property.

```yaml openapi.yaml
components:
  schemas:
    FlexibleObject:
      type: object
      properties:
        title:
          type: string
        description:
          type: string
      additionalProperties: true
```

This schema allows for the inclusion of any additional user-provided properties alongside the defined `title` and `description`.

<div className="Tabs" data-items="['TypeScript', `Python`, `Golang`, `Java`]">
<div className="TabsTab">
```typescript Typescript
export type FlexibleObject = {
    title: string;
    description: string;
    additionalProperties: Record<string, any>;  // 👈 
}

````
</div>
<div className="TabsTab">
```python Python
@dataclass
class FlexibleObject:
    title: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('title') }})
    description:  str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('description') }})
    additional_properties: Optional[Dict[str, Any]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'exclude': lambda f: f is None }}) // 👈 

````

</div>
<div className="TabsTab">
```go Go 
type FlexibleObject struct {
	Title                 string                 `json:"title"`
	Description           string                `json:"description"`
	AdditionalProperties map[string]interface{} `additionalProperties:"true" json:"-"`// 👈 
}
```
</div>
<div className="TabsTab">
```java Java
public class FlexibleObject {
  public FlexibleObject(String title, String description) {...}
  public String title() {...}
  public String description() {...}
  public Map<String, Object> additionalProperties() {...}
  ...
}
```
</div>
</div>

## Using typed `additionalProperties`

For use cases that need to accommodate arbitrary additional data within a constrained type, Speakeasy allows `additionalProperties` to be defined with a specific type or schema, enabling the creation of flexible yet type-safe objects.

```yaml openapi.yaml
components:
  schemas:
    StringOnlyObject:
      type: object
      properties:
        title:
          type: string
        description:
          type: string
      additionalProperties:
        type: string
```

In this schema, alongside the explicitly defined `name`, any additional properties must be strings, ensuring a consistent data type across all properties.

<div className="Tabs" data-items="['TypeScript', `Python`, `Golang`, `Java`]">

<div className="TabsTab">
```typescript Typescript
export type StringOnlyObject = {
    title: string;
    description: string;
    additionalProperties: Record<string, string>;
};

````
</div>
<div className="TabsTab">
```python Python
@dataclass
class StringOnlyObject:
    title: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('title') }})
    description:  str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('description') }})
    additional_properties: Optional[Dict[str, str]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'exclude': lambda f: f is None }})

````

</div>
<div className="TabsTab">
```go Go 
type StringOnlyObject struct {
	Title                 string                 `json:"title"`
	Description           string                `json:"description"`
	AdditionalProperties map[string]string `additionalProperties: type: string json:"-"`
}
```
</div>
<div className="TabsTab">
```java Java
public class FlexibleObject {
  public FlexibleObject(String title, String description) {...}
  public String title() {...}
  public String description() {...}
  public Map<String, String> additionalProperties() {...}
  ...
}
```
</div>
</div>


 This is the content for the doc guides/openapi/x-codesamples.mdx 

 ---
description: "Using the code samples extension to sync SDK usage snippets with your documentation site."
sidebar_label: "Code Samples"
slug: "/guides/x-codesamples/"
---

{/*import { Tabs } from "@speakeasy/nextra-theme";*/}

# What is the code samples extension?

Many API documentation providers provide code snippets in multiple languages to help developers understand how to use the API. However, these snippets
may not correspond to a usage snippet from an existing SDK provided by the API, which reduces the value of the API documentation and can lead to inconsistent integrations, depending on whether a user discovers the API docs or the SDK first.

The `x-codeSamples` (previously called `x-code-samples`) extension is a widely accepted spec extension that enables the addition of custom code samples in one or more languages to operation IDs in your OpenAPI specification.
When custom code samples are added using the code samples extension, documentation providers will render the usage snippet in the right-hand panel of the documentation page:

![Screenshot of Inkeep's API docs showing featured SDK usage.](./docs-example.png)

## Anatomy of the extension

| Field Name | Type     | Description                                                                                                                                      | Required |
| ---------- | -------- | ------------------------------------------------------------------------------------------------------------------------------------------------ | -------- |
| `lang`     | `string` | The language of the code snippet. Can be one from this [list](https://github.com/github-linguist/linguist/blob/master/lib/linguist/popular.yml). | Yes      |
| `label`    | `string` | Code sample label, for example, `Node` or `Python3`. The `lang` value is used by default.                                                        | No       |
| `source`   | `string` | The code sample source code. In this case, the SDK usage snippet.                                                                                | Yes      |

Documentation providers that support `x-codeSamples` include but are not limited to:

- Mintlify
- Readme
- Redocly
- Stoplight

## Example usage

Here is a basic example of using the `x-codeSamples` extension with a `curl` snippet.

```yaml
openapi: "3.0.3"
info: ...
tags: [...]
paths:
  /example:
    get:
      summary: Example summary
      description: Example description
      operationId: examplePath
      responses: [...]
      parameters: [...]
      x-codeSamples:
        - lang: "cURL"
          label: "CLI"
          source: |
            curl --request POST \
            --url 'https://data.apiexample.com/api/example/batch_query/json?format=json' \
            --header 'content-type: application/octet-stream: ' \
            --data '{}'
```

Now let's extend this to a more complex example: a TypeScript SDK for an LLM chat API.

```yaml
openapi: "3.0.3"
info: ...
tags: [...]
paths:
  /chat_sessions/chat_results:
    post:
      summary: Create Chat Session
      operationId: create
      tags: [chat_session]
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateChatSession"
        required: true
      x-codeSamples:
        - lang: "typescript"
          label: "create_chat_session"
          source: |
            import { ChatSDK } from "@llm/chat-sdk";

            async function run() {
              const sdk = new ChatSDK({
                apiKey: "<API_KEY>",
              });

              const res = await sdk.chatSession.create({
                integrationId: "<interagtion_id>",
                chatSession: {
                  messages: [
                    {
                      role: "user",
                      content: "How do I get started?",
                    },
                  ],
                },
                stream: true,
              });

              /* Example of handling a streamed response */
              if (res.chatResultStream == null) {
                throw new Error("failed to create stream: received null value");
              }

              let chatSessionId: string | undefined | null = undefined;

              for await (const event of res.chatResultStream) {
                if (event.event == "message_chunk") {
                  console.log("Partial message: " + event.data.contentChunk);
                  chatSessionId = event.data.chatSessionId;
                }
                if (event.event == "records_cited") {
                  console.log("Citations: ", JSON.stringify(event.data.citations, null, 2));
                }
              }
            }

            run();
```

Multiple code samples can be added to a single `operationId` to support examples in any number of languages by adding multiple keys under the `x-codeSamples` extension.

```yaml
openapi: "3.0.3"
info: ...
tags: [...]
paths:
  /chat:
    get:
      summary: Example summary
      description: Example description
      operationId: examplePath
      responses: [...]
      parameters: [...]
      x-codeSamples:
        - lang: "typescript"
          label: "chat_ts"
          source: |
            .....
            .....
        - lang: "python"
          label: "chat_python"
          source: |
            .....
            .....
```

## Generating code samples

To generate SDK code samples for your OpenAPI document, run the following command:

```bash
speakeasy generate codeSamples -s {{your-spec.yaml}} --langs {{lang1}},{{lang2}} --out code-samples-overlay.yaml
```

This command creates an [overlay](/docs/prep-openapi/overlays/create-overlays) with code samples for every `operationId` in your OpenAPI document.

To apply the overlay to your specification, run:

```bash
speakeasy overlay apply -o code-samples-overlay.yaml -s {{your-spec.yaml}} -o {{output-spec.yaml}}
```

The final output spec will include `codeSamples` inline.

## Adding code sample generation to your workflow

To include `codeSamples` overlay generation in your Speakeasy workflow, add the following to your `.speakeasy/workflow.yaml` for any `target` you have configured:

```yaml .speakeasy/workflow.yaml
# !focus(5:6)
targets:
  my-target:
    target: typescript
    source: my-source
    codeSamples:
      output: codeSamples.yaml
```

If you want the overlay to be automatically applied on the source, create another workflow entry using `speakeasy configure` as follows:

![Configure Sources 1](../../docs/assets/spec-workflow/1.png)

Then add the overlay created by Speakeasy to inject code snippets into your spec:

![Configure Sources 2](../../docs/assets/spec-workflow/2.png)

Finally, provide the name and path for your output OpenAPI spec. This will be the final spec used by Mintlify.

![Configure Sources 3](../../docs/assets/spec-workflow/3.png)


 This is the content for the doc guides/sdks/creating-a-monorepo.mdx 

 ---
title: "Create a monorepo"
description: "Create a monorepo with Speakeasy and Github."
---

{/*import { Callout } from '~/components'*/}


<div className="Callout" data-title="Warning" data-variant="warning">
This section outlines an advanced setup process that may not be suitable for all users. For most use cases, we recommend adopting the simpler approach of a single SDK per GitHub repository. To setup a single SDK per Github see our [SDK quickstart](/docs/create-client-sdks).
</div>

# What is a Monorepo?

A monorepo is a unified repository containing multiple SDKs, each corresponding to a unique OpenAPI specification. This approach offers a centralized location for discovering available SDKs while allowing for the independent download and management of each SDK as needed. Each SDK resides in its own subfolder, and can be made complete with individual GitHub workflows for regeneration and release processes.


## Repository Structure

The monorepo's structure is designed for scalability and easy navigation. In our example, we will discuss two SDKs: ServiceA and ServiceB, each found in their respective subfolders. The typical structure of such a monorepo is as follows:

```yaml
.github/workflows/
 - serviceA_generate.yaml # Github Workflow for generating the ServiceA SDK, generated by speakeasy cli
 - serviceA_release.yaml # Github Workflow for releasing and publishing the ServiceA SDK, generated by speakeasy cli
 - serviceB_generate.yaml # Github Workflow for generating the ServiceB SDK, generated by speakeasy cli
 - serviceB_release.yaml # Github Workflow for releasing and publishing the ServiceB SDK, generated by speakeasy cli
.speakeasy/workflow.yaml # Speakeasy workflow file that dictates mapping of sources (eg: openapi docs) and targets (eg: language sdks) to generate
serviceA/
 - gen.yaml # Generation config for the ServiceA SDK
serviceB/
 - gen.yaml # Generation config for the ServiceB SDK
 ```
 This structure can be expanded to accommodate any number of SDKs.

## Creating Your SDK Monorepo

You have two options for creating your SDK monorepo with Speakeasy and GitHub: starting from a template or building from scratch. For the purpose of this guide, we will use an example with two APIs, one for `lending` and one for `accounting`.

### Option 1: Use a Template
Start by cloning the [`template-sdk-monorepo` repository](https://github.com/speakeasy-sdks/template-sdk-monorepo?tab=readme-ov-file) using the "Use template" button on GitHub, and name it as you see fit.

### Option 2: Build from Scratch
1. Create a new repository on GitHub and clone it down locally with `git clone <repo-url>`.
2. Mimic the directory structure shown above. This can be achieved easily by following the interactive CLI commands below

a. Install Speakeasy CLI

b. Use quickstart to boostrap the repository. 
  
  This will create the necessary directories and files for you to start generating SDKs.

  ```bash
  speakeasy quickstart
  ```

  When prompted make sure to choose a sub directory rather than the root of your directory for generating the first target. We will add more targets in the following steps.

c. Configure your sources
  
  ```bash
  speakeasy configure sources
  ```
  For each source reference a local or remote OpenAPI document. Optionally add in an overlay if needed. Each source you configure here will be used 
  to point towards a generation target in the following step. 

 ![Screenshot of configuring sources for monorepo.](../assets/monorepo-step-2c.png)

d. Configure your targets 

  For each target referenced a local or remote OpenAPI document. Optionally add in an overlay if needed. For ever target make sure to choose a 
  a language, a source and a subdirectory to generate the target in. In the provided example `accounting` and `lending` are two sub directories in which we'll generate two different targets for two different sources.

  ```bash
  speakeasy configure targets
  ```

 ![Screenshot of configuring targets for monorepo.](../assets/monorepo-step-2d.png)

#### Final Speakeasy Workflow

The final speakeasy workflow file will look like the following

```yaml
workflowVersion: 1.0.0
speakeasyVersion: latest
sources:
    accounting:
        inputs:
            - location: /path/to/accounting/openapi.yaml
    lending:
        inputs:
            - location: /path/to/lending/openapi.yaml
targets:
    accounting-ts:
        target: typescript
        source: accounting
        output: ./accounting
    lending-ts:
        target: typescript
        source: lending
        output: ./lending
```


#### Setup Github Release and Publishing Workflows

Finally if you want your SDKs to be regenerated and published in their Github repos setup the workflow files needed for remote generation and publishing. The CLI can help you set up these files with: 

```bash
speakesy configure publishing
```

Follow the prompts to setup your secrets in Github Action Secrets. Push up the repo to your remote location and watch everything spin!

### Configure Generation

Edit the `gen.yaml` file in the root of each SDK's subfolder. This file dictates the generator settings, including package name, class names, parameter inlining, and other preferences. For complete documentation on all the available publishing configurations, see [here](../../docs/gen-reference.mdx).

## Generate SDKs

### Locally

Simply run `speakeasy run` and select the SDKs you wish to regenerate. Use `speakaesy run --force` if there are no OpenAPI document changes.

 ![Screenshot of running all targets for monorepo.](../assets/monorepo-step-run.png)

### Github

To manually trigger SDK generation:
1. Navigate to the Actions tab in your GitHub repository.
2. Select the generation workflow for the SDK you wish to generate.
3. Click "Run workflow" to start the generation process. Check mark the "Force" input option if there are no OpenAPI document changes.

## Verify your SDK

After generation, review the SDK to ensure it aligns with your requirements.


 This is the content for the doc guides/sdks/generate-in-a-subdirectory.mdx 

 ---
title: "Generate SDK in a subdirectory"
description: "Setup your SDK in a subdirectory."
---


# Generate SDK in a Subdirectory

Similar to setting up a monorepo, you can also configure Speakeasy to generate your SDK into a subdirectory. This setup maybe useful in maintaining seperation between handwritten and generated code or for consuming the SDK in a monolithic codebase.

## Step 1: 

In the root of your existing directory run `speakeasy quickstart`: 

<div className="Screenshot" variant="cli">
  ![A screenshot of the speakeasy quickstart command in the CLI.](../assets/subdirectory/1.png)
</div>

## Step 2: 

Select your generation language.

<div className="Screenshot" variant="cli">
  ![A screenshot of the CLI prompting the user to select their generation language.](../assets/subdirectory/2.png)
</div>

## Step 3: 

Name your package.


<div className="Screenshot" variant="cli">
  ![A screenshot of the package name in the Speakeasy CLI.](../assets/subdirectory/3.png)
</div>

## Step 4: 

If you're setting your SDK up in a folder with existing subfolders, you will be prompted to select an output directory. 

<div className="Screenshot" variant="cli">
  ![A screenshot of the user being prompted to provide an output directory in the CLI.](../assets/subdirectory/4.png)
</div>

## Step 5: 

Complete generating your SDK.

<div className="Screenshot" variant="cli">
  ![A screenshot of a succesful CLI generation.](../assets/subdirectory/5.png)
</div>

Going forward to generate your SDK navigate to your SDK folder and run `speakeasy run`.

 This is the content for the doc guides/sdks/utilizing-user-agent-strings.mdx 

 ---
title: "Utilizing user agent strings for telemetry"
description: "Use user agent strings to gather insightful telemetry on SDK interactions."
---

# Utilizing User Agent Strings for Telemetry

## Overview

Each Speakeasy SDK incorporates a unique user agent string in all HTTP requests made to the API. This string helps identify the source SDK and provides details like the SDK version, the generator version, the document version, and the package name.

## Format

The format of the user agent string across all Speakeasy SDKs is as follows:

```
speakeasy-sdk/<<Language>> {{SDKVersion}} {{GenVersion}} {{DocVersion}} {{PackageName}}
```

Components:

* `Language`: The language of the SDK (e.g., C#, Java, Python).
* `SDKVersion`: The version of the SDK, specified in `gen.yaml`.
* `GenVersion`: The version of the Speakeasy generator used.
* `DocVersion`: The version of the OpenAPI document that generated the SDK.
* `PackageName`: The name of the package as defined in `gen.yaml`.

For a Java SDK, the user agent string might look like this:

```speakeasy-sdk/java 2.3.1 1.5.0 2022.01 1.0.0 speakeasyJavaClient```

## Parsing User Agent Strings

To accurately parse user agent strings, you can use regular expressions, string manipulation techniques, or dedicated parsing libraries.

Below is a Python example using regex and Flask:


```python
from flask import request
import re

@app.route('/some-path')
def some_function():
    user_agent = request.headers.get('User-Agent')

    # Regex pattern to match the user agent string
    pattern = r"speakeasy-sdk/(?P<Language>\w+) (?P<SDKVersion>[\d\.]+) (?P<GenVersion>[\d\.]+) (?P<DocVersion>[\d\.]+) (?P<PackageName>[\w\.-]+)"

    # Match the user agent string against the regex pattern
    match = re.match(pattern, user_agent)
    if match:
        details = match.groupdict()
        print(details)
```

## Utilizing Parsed Data for Telemetry

Parsed user agent strings can enhance telemetry in several ways:

**Data Enrichment**: With parsed user agent strings, you can enhance telemetry records by appending key metadata such as the SDK version, programming language, and package details. This enriched data supports more detailed segmentation and sophisticated analysis, improving the granularity and usability of your telemetry insights. This approach allows you to track feature adoption across different segments and tailor your development focus accordingly.

**Monitoring SDK Usage**: Utilize the detailed data from user agent strings to monitor the adoption rates of different SDK versions and the prevalence of programming languages among your users. This intelligence is crucial for informed decision-making regarding SDK updates and deprecation schedules. By understanding which versions are most popular and how quickly users adopt new releases, you can better manage support resources and communication strategies.

**Performance Analysis**: Correlate specific SDK versions or configurations with performance metrics like response times and error rates. This analysis helps pinpoint whether recent updates have improved performance or introduced new issues, allowing your development team to target fixes and optimizations more effectively. Regularly reviewing these correlations helps maintain high performance standards and ensures a positive user experience.

**Anomaly Detection**: Implement advanced anomaly detection techniques in your telemetry to automatically flag unusual activity, such as a sudden decrease in the usage of a normally popular SDK version or an unexpected increase in error rates following a new release. Early detection of these anomalies can prompt swift action, potentially averting more significant issues and enhancing customer satisfaction. This proactive monitoring is essential in maintaining the reliability and credibility of your SDKs.


 This is the content for the doc openapi/arazzo.mdx 

 import { ScrollyCoding } from "~/components/codehike/Scrollycoding";
import { Callout } from "~/components";

# Arazzo: OpenAPI Workflows

The Arazzo Specification is a new addition to the OpenAPI Specification that allows you to define sequences of operations for your API.

An Arazzo description is a separate document that references your OpenAPI document and describes how to combine operations from your OpenAPI document into step-by-step sequences.

Arazzo descriptions are useful for:

- Defining complex sequences of operations that involve multiple API calls.
- Documenting the expected behavior of your API in a more structured way than a narrative description.
- Generating code to execute the sequences of operations.
- Generating tests to verify that the sequences of operations behave as expected.
- Generating documentation that explains how to use the sequences of operations.

## Arazzo Description Structure

An Arazzo description is a JSON or YAML document that follows the structure defined by the Arazzo Specification.

<ScrollyCoding fullHeight>

#### !!steps `arazzo`

| Field Name | Type     | Required |
| ---------- | -------- | -------- |
| `arazzo`   | `string` | ✅       |

The version of the Arazzo Specification that the document uses. The value must be a supported [version number](#arazzo-specification-versions).

```yaml ! arazzo.yaml focus=1
!from ./assets/arazzo.yaml.txt
```

---

#### !!steps `info`

| Field Name | Type                        | Required |
| ---------- | --------------------------- | -------- |
| `info`     | [Info Object](#info-object) | ✅       |

Provides metadata about the Arazzo description.

```yaml ! arazzo.yaml
# !focus(2:8)
```

---

#### !!steps `sourceDescriptions`

| Field Name           | Type                                                      | Required |
| -------------------- | --------------------------------------------------------- | -------- |
| `sourceDescriptions` | [[Source Description Object](#source-description-object)] | ✅       |

An array of [source description objects](#source-description-object) defining the OpenAPI or other documents containing the operations referenced by the workflows. The array must contain at least one source.

```yaml ! arazzo.yaml
# !focus(9:15)
```

---

#### !!steps `workflows`

| Field Name  | Type                                  | Required |
| ----------- | ------------------------------------- | -------- |
| `workflows` | [[Workflow Object](#workflow-object)] | ✅       |

An array of [workflow objects](#workflow-object) defining the workflows. The array must contain at least one workflow.

```yaml ! arazzo.yaml
# !focus(16:156)
```

</ScrollyCoding>

This table shows all fields at the root of the Arazzo Specification:

| Field Name           | Type                                                      | Required | Description                                                                                                                                                                                                     |
| -------------------- | --------------------------------------------------------- | -------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `arazzo`             | `string`                                                  | ✅       | The version of the Arazzo Specification that the document uses. The value must be a supported [version number](#arazzo-specification-versions).                                                                 |
| `info`               | [Info Object](#info-object)                               | ✅       | Provides metadata about the Arazzo description.                                                                                                                                                                 |
| `sourceDescriptions` | [[Source Description Object](#source-description-object)] | ✅       | An array of [source description objects](#source-description-object) defining the OpenAPI or other documents containing the operations referenced by the workflows. The array must contain at least one source. |
| `workflows`          | [[Workflow Object](#workflow-object)]                     | ✅       | An array of [workflow objects](#workflow-object) defining the workflows. The array must contain at least one workflow.                                                                                          |
| `components`         | [Components Object](#components-object)                   |          | An element to hold reusable schemas for the workflow, for example, inputs and parameters.                                                                                                                       |
| `x-*`                | [Extensions](#arazzo-specification-extensions)            |          | Any number of extension fields can be added to the Arazzo description that can be used by tooling and vendors. When provided at this level, the extensions generally apply to the entire document.              |

## Arazzo Specification Versions

The `arazzo` field contains the version number of the Arazzo Specification that the document conforms to. Tooling should use this value to interpret the document correctly.

The current version of the Arazzo Specification is 1.0.0-prerelease, but keep in mind that the specification is still under development.

## Info Object

Provides metadata about the Arazzo description.

| Field Name    | Type                                           | Required | Description                                                                                                                                 |
| ------------- | ---------------------------------------------- | -------- | ------------------------------------------------------------------------------------------------------------------------------------------- |
| `title`       | `string`                                       | ✅       | A human-readable title for the set of workflows.                                                                                            |
| `summary`     | `string`                                       |          | A short summary of the Arazzo description.                                                                                                  |
| `description` | `string`                                       |          | A longer description of the Arazzo description. [CommonMark syntax](https://spec.commonmark.org/) may be used for rich text representation. |
| `version`     | `string`                                       | ✅       | A version string indicating the version of the Arazzo document.                                                                             |
| `x-*`         | [Extensions](#arazzo-specification-extensions) |          | Any number of extension fields can be added that can be used by tooling and vendors.                                                        |

Below is an example of an `info` object in an Arazzo document:

```yaml arazzo.yaml focus=2:8
!from ./assets/arazzo.yaml.txt
```

## Source Description Object

A source description points to an OpenAPI document containing the operations referenced by the workflows in this document. It may also reference other Arazzo documents.

| Field Name | Type                                           | Required | Description                                                                                                                                                                                                                                                        |
| ---------- | ---------------------------------------------- | -------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| `name`     | `string`                                       | ✅       | A name for the source document, used to reference it from other parts of the Arazzo description. The name must be unique within the `sourceDescriptions` array and may only contain alphanumeric characters, underscores, and dashes.                              |
| `url`      | `string`                                       | ✅       | The URL of the source document. This identifier must conform to [RFC 3986 section 4.1](https://datatracker.ietf.org/doc/html/rfc3986#section-4.1) for absolute URLs or [section 4.2](https://datatracker.ietf.org/doc/html/rfc3986#section-4.2) for relative URIs. |
| `type`     | `string`                                       |          | The type of the source document. Supported values are `openapi`, indicating an OpenAPI document, or `arazzo` indicating another Arazzo description. Additional values may be supported in future versions of the specification.                                    |
| `x-*`      | [Extensions](#arazzo-specification-extensions) |          | Any number of extension fields can be added to the source description object that can be used by tooling and vendors.                                                                                                                                              |

Below is an example of two source description objects in an Arazzo description document:

```yaml arazzo.yaml focus=9:15
!from ./assets/arazzo.yaml.txt
```

## Workflow Object

A workflow object defines a sequence of operations.

| Field Name       | Type                                                                                     | Required | Description                                                                                                                                                                                                                                                                                                                                                                                               |
| ---------------- | ---------------------------------------------------------------------------------------- | -------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `workflowId`     | `string`                                                                                 | ✅       | A unique identifier for the workflow. This is used to reference the workflow from other parts of the Arazzo description. May contain only alphanumeric characters, underscores, and dashes.                                                                                                                                                                                                               |
| `summary`        | `string`                                                                                 |          | A short summary of what the workflow does.                                                                                                                                                                                                                                                                                                                                                                |
| `description`    | `string`                                                                                 |          | A longer description of the workflow. [CommonMark syntax](https://spec.commonmark.org/) may be used for rich text representation.                                                                                                                                                                                                                                                                         |
| `inputs`         | [JSON Schema](https://json-schema.org/)                                                  |          | A schema defining the input parameters for the workflow.                                                                                                                                                                                                                                                                                                                                                  |
| `dependsOn`      | [`string`]                                                                               |          | An array of workflow IDs that this workflow depends on. The workflows in the array must be executed before this workflow.                                                                                                                                                                                                                                                                                 |
| `steps`          | [[Step Object](#step-object)]                                                            | ✅       | An ordered array of [step objects](#step-object) defining the steps of the workflow. The array must contain at least one step.                                                                                                                                                                                                                                                                            |
| `successActions` | [[Success Action Object](#success-action-object) \| [Reusable Object](#reusable-object)] |          | An array of [success action objects](#success-action-object) and [reusable objects](#reusable-object) specifying actions to take for each step of this workflow that completes successfully. Individual steps may override the workflow object's success actions. Reusable objects must reference success actions defined in the [components/successActions](#components-object) of this Arazzo document. |
| `failureActions` | [[Failure Action Object](#failure-action-object) \| [Reusable Object](#reusable-object)] |          | An array of [failure action objects](#failure-action-object) and [reusable objects](#reusable-object) specifying actions to take for each step of this workflow that fails. Individual steps may override the workflow object's failure actions. Reusable objects must reference success actions defined in the [components/failureActions](#components-object) of this Arazzo document.                  |
| `outputs`        | Map[`string`, \{[Runtime Expression](#runtime-expressions)}]                             |          | A map of output values produced by the workflow. The keys are the names of the outputs, and the values are [runtime expressions](#runtime-expressions) that extract the output values from the results of the workflow steps.                                                                                                                                                                             |
| `parameters`     | [[Parameter Object](#parameter-object) \| [Reusable Object](#reusable-object)]           |          | An array of parameters applicable to all steps in this workflow. Individual steps may override the workflow object's parameters. A reusable object must reference an object in this document's [components/parameters](#components-object) of this Arazzo document.                                                                                                                                       |
| `x-*`            | [Extensions](#arazzo-specification-extensions)                                           |          | Any number of extension fields can be added to the workflow object that can be used by tooling and vendors.                                                                                                                                                                                                                                                                                               |

Below is an example of a workflow object:

```yaml arazzo.yaml focus=17:55
!from ./assets/arazzo.yaml.txt
```

## Step Object

A step object defines a single operation to perform as part of a workflow.

| Field Name        | Type                                                                                     | Required | Description                                                                                                                                                                                                         |
| ----------------- | ---------------------------------------------------------------------------------------- | -------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `stepId`          | `string`                                                                                 | ✅       | A unique identifier for the step within the workflow. Used to reference the step's outputs from other parts of the workflow. May contain only alphanumeric characters, underscores, and dashes.                     |
| `description`     | `string`                                                                                 |          | A description of what the step does. [CommonMark syntax](https://spec.commonmark.org/) may be used for rich text representation.                                                                                    |
| `operationId`     | `string`                                                                                 |          | The `operationId` of the operation to execute for this step. Must match an `operationId` in one of the `sourceDescriptions`. This field is mutually exclusive with `operationPath` and `workflowId`.                |
| `operationPath`   | `string`                                                                                 |          | A JSON Pointer to the operation to execute for this step, relative to one of the `sourceDescriptions`. This field is mutually exclusive with `operationId` and `workflowId`.                                        |
| `workflowId`      | `string`                                                                                 |          | The ID of a workflow in this document to execute as a sub-workflow. This field is mutually exclusive with `operationId` and `operationPath`.                                                                        |
| `parameters`      | [[Parameter Object](#parameter-object) \| [Reusable Object](#reusable-object)]           |          | An array of parameters to pass to the operation for this step. Overrides any parameters defined at the workflow level.                                                                                              |
| `requestBody`     | [Request Body Object](#request-body-object)                                              |          | The request body to send for the operation.                                                                                                                                                                         |
| `successCriteria` | [[Criterion Object](#criterion-object)]                                                  |          | An array of criteria for determining if the step succeeded. All criteria must be met for the step to be considered successful. Individual criteria are defined using [criterion objects](#criterion-object).        |
| `onSuccess`       | [[Success Action Object](#success-action-object) \| [Reusable Object](#reusable-object)] |          | An array of actions to take if the step succeeds. Overrides any success actions defined at the workflow level. Individual actions are defined using [success action objects](#success-action-object).               |
| `onFailure`       | [[Failure Action Object](#failure-action-object) \| [Reusable Object](#reusable-object)] |          | An array of actions to take if the step fails. Overrides any failure actions defined at the workflow level. Individual actions are defined using [failure action objects](#failure-action-object).                  |
| `outputs`         | Map[`string`, \{[Runtime Expression](#runtime-expressions)}]                             |          | A map of output values produced by the step. The keys are the names of the outputs, and the values are [runtime expressions](#runtime-expressions) that extract the output values from the result of the operation. |
| `x-*`             | [Extensions](#arazzo-specification-extensions)                                           |          | Any number of extension fields can be added to the step object that can be used by tooling and vendors.                                                                                                             |

Below is an example of step objects in an Arazzo description document:

```yaml arazzo.yaml focus=34:55
!from ./assets/arazzo.yaml.txt
```

## Parameter Object

A parameter object defines a single parameter to pass to an operation in a workflow step.

| Field Name | Type                                                 | Required | Description                                                                                                                                                                                                                                                                                                         |
| ---------- | ---------------------------------------------------- | -------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `name`     | `string`                                             | ✅       | The name of the parameter.                                                                                                                                                                                                                                                                                          |
| `in`       | `string`                                             | ✅       | The location of the parameter. Possible values are `path`, `query`, `header`, `cookie`. Required for parameters passed to an operation. Must be omitted for parameters passed to a workflow, where the parameter is always passed in the workflow's `inputs` object. See [Parameter Location](#parameter-location). |
| `value`    | Any \| \{[Runtime Expression](#runtime-expressions)} |          | The value of the parameter. Can be a literal value, or a [runtime expression](#runtime-expressions) that will be evaluated and passed to the operation or workflow.                                                                                                                                                 |
| `x-*`      | [Extensions](#arazzo-specification-extensions)       |          | Any number of extension fields can be added to the parameter object that can be used by tooling and vendors.                                                                                                                                                                                                        |

### Parameter Location

For parameters passed to an operation, the `in` field specifies the location of the parameter. The possible values are:

- `path` - The parameter is part of the operation's URL path.
- `query` - The parameter is appended to the operation's URL as a query parameter.
- `header` - The parameter is sent in the request headers.
- `cookie` - The parameter is sent in a cookie.

For parameters passed to a workflow, the `in` field must be omitted. Workflow parameters are always passed in the workflow's `inputs` object.

### Arazzo Parameter Object Examples

```yaml arazzo.yaml focus=42:55
!from ./assets/arazzo.yaml.txt
```

## Success Action Object

A success action object defines an action to take when a workflow step succeeds.

| Field Name   | Type                                           | Required | Description                                                                                                                                                                                 |
| ------------ | ---------------------------------------------- | -------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `name`       | `string`                                       | ✅       | The name of the action. Names are case-sensitive and must be unique within the `successActions` array of a step or workflow.                                                                |
| `type`       | `string`                                       | ✅       | The type of action to take. Possible values are:<br/>`end` - End the workflow.<br/>`goto` - Move to another step in the workflow. Requires either `stepId` or `workflowId` to be specified. |
| `stepId`     | `string`                                       |          | The `stepId` of the step to execute next if `type` is `goto`. Mutually exclusive with `workflowId`.                                                                                         |
| `workflowId` | `string`                                       |          | The `workflowId` of the workflow to execute if `type` is `goto`. Mutually exclusive with `stepId`.                                                                                          |
| `criteria`   | [[Criterion Object](#criterion-object)]        |          | An array of criteria that determine whether the action should be executed. All criteria must be met for the action to execute. If not provided, the action will always execute.             |
| `x-*`        | [Extensions](#arazzo-specification-extensions) |          | Any number of extension fields can be added to the success action object that can be used by tooling and vendors.                                                                           |

Below is an example of a success action object:

```yaml arazzo.yaml focus=93:99
!from ./assets/arazzo.yaml.txt
```

## Failure Action Object

A failure action object defines an action to take when a workflow step fails.

| Field Name   | Type                                           | Required | Description                                                                                                                                                                                                                                                                                                                                        |
| ------------ | ---------------------------------------------- | -------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `name`       | `string`                                       | ✅       | The name of the action. Names are case-sensitive and must be unique within the `failureActions` array of a step or workflow.                                                                                                                                                                                                                       |
| `type`       | `string`                                       | ✅       | The type of action to take. Possible values are:<br/>`end` - End the workflow, returning the specified `outputs` if provided.<br/>`goto` - Move to another step in the workflow. Requires either `stepId` or `workflowId` to be specified.<br/>`retry` - Retry the failed step. Requires `retryAfter` and optionally `retryLimit` to be specified. |
| `stepId`     | `string`                                       |          | The `stepId` of the step to execute next if `type` is `goto`. Mutually exclusive with `workflowId`.                                                                                                                                                                                                                                                |
| `workflowId` | `string`                                       |          | The `workflowId` of the workflow to execute if `type` is `goto`. Mutually exclusive with `stepId`.                                                                                                                                                                                                                                                 |
| `retryAfter` | Number                                         |          | The number of seconds to wait before retrying the failed step if `type` is `retry`. Must be a non-negative integer. The specification is ambiguous about whether this field also applies when `type` is `goto`.                                                                                                                                    |
| `retryLimit` | Integer                                        |          | The maximum number of times to retry the failed step if `type` is `retry`. Must be a non-negative integer. If not provided, the step will be retried indefinitely until it succeeds or the workflow is canceled.                                                                                                                                   |
| `criteria`   | [[Criterion Object](#criterion-object)]        |          | An array of criteria that determine whether the action should be executed. All criteria must be met for the action to execute.                                                                                                                                                                                                                     |
| `x-*`        | [Extensions](#arazzo-specification-extensions) |          | Any number of extension fields can be added to the failure action object that can be used by tooling and vendors.                                                                                                                                                                                                                                  |

Below is an example of a failure action object:

```yaml arazzo.yaml focus=100:106
!from ./assets/arazzo.yaml.txt
```

## Components Object

The `components` object holds reusable objects that can be referenced from other parts of the Arazzo description.

| Field Name       | Type                                                           | Description                                                                                                           |
| ---------------- | -------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------- |
| `inputs`         | Map[`string`, `JSON Schema`]                                   | An object containing reusable [JSON Schemas](https://json-schema.org/) that can be referenced from workflow `inputs`. |
| `parameters`     | Map[`string`, [Parameter Object](#parameter-object)]           | An object containing reusable [parameter objects](#parameter-object).                                                 |
| `successActions` | Map[`string`, [Success Action Object](#success-action-object)] | An object containing reusable [success action objects](#success-action-object).                                       |
| `failureActions` | Map[`string`, [Failure Action Object](#failure-action-object)] | An object containing reusable [failure action objects](#failure-action-object).                                       |
| `x-*`            | [Extensions](#arazzo-specification-extensions)                 | Any number of extension fields can be added to the components object that can be used by tooling and vendors.         |

The keys in the `components` object may only contain alphanumeric characters, underscores, and dashes.

### Arazzo Components Object Example

```yaml arazzo.yaml focus=157:178
!from ./assets/arazzo.yaml.txt
```

The components defined in an Arazzo description are scoped to that document. Components defined in one Arazzo description cannot be referenced from another Arazzo description.

## Reusable Object

A reusable object allows you to reference objects like success actions and failure actions defined in the `components` object from locations within steps or workflows.

| Field Name  | Type                                          | Required | Description                                                                                                     |
| ----------- | --------------------------------------------- | -------- | --------------------------------------------------------------------------------------------------------------- |
| `reference` | \{[Runtime Expression](#runtime-expressions)} | ✅       | A [runtime expression](#runtime-expressions) used to reference the desired object from the `components` object. |
| `value`     | string                                        |          | The value of the referenced parameter. Only used for parameters.                                                |

### Arazzo Reusable Object Example

```yaml arazzo.yaml focus=138:140
!from ./assets/arazzo.yaml.txt
```

## Criterion Object

A criterion object is used to specify assertions in the `successCriteria` field of a [step object](#step-object), or the `criteria` field of a [success action object](#success-action-object) or [failure action object](#failure-action-object).

Criterion objects support three types of assertions:

- `simple` - Basic comparisons using literals, operators, and [runtime expressions](#runtime-expressions). This is the default if no `type` is specified.
- `regex` - Applies a regular expression pattern to a context defined by a [runtime expression](#runtime-expressions).
- `JSONPath` - Applies a [JSONPath](https://goessner.net/articles/JsonPath/) expression to a context defined by a [runtime expression](#runtime-expressions). The root node of the JSONPath is the context.

### Literals

Literals are constant values that can be used in `simple` conditions. The following data types are supported:

| Type      | Literal Value                                                                                                               |
| --------- | --------------------------------------------------------------------------------------------------------------------------- |
| `boolean` | `true` or `false`                                                                                                           |
| `null`    | `null`                                                                                                                      |
| `number`  | A number of type `int32`, `int64`, `float`, or `double`.                                                                    |
| `string`  | Strings must be enclosed in single quotes ('). To include a literal single quote, escape it with another single quote (''). |

### Operators

Simple conditions support the following operators:

| Operator | Description           |
| -------- | --------------------- |
| `<`      | Less than             |
| `<=`     | Less than or equal    |
| `>`      | Greater than          |
| `>=`     | Greater than or equal |
| `==`     | Equal                 |
| `!=`     | Not equal             |
| `!`      | Not                   |
| `&&`     | And                   |
| `\|\|`   | Or                    |
| `()`     | Grouping              |
| `[]`     | Array index (0-based) |
| `.`      | Property dereference  |

String comparisons are case-insensitive.

A criterion object consists of the following fields:

| Field Name  | Type                                           | Required | Description                                                                                                                                                                                                  |
| ----------- | ---------------------------------------------- | -------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| `context`   | \{[Runtime Expression](#runtime-expressions)}  |          | A [runtime expression](#runtime-expressions) that defines the context for `regex` and `JSONPath` conditions. Must be provided if `type` is specified.                                                        |
| `condition` | `string`                                       | ✅       | The assertion to evaluate. For `simple` conditions, combines literals, operators, and runtime expressions. For `regex` and `JSONPath` conditions, provides the expression to evaluate against the `context`. |
| `type`      | `string`                                       |          | The type of assertion. Allowed values are `simple`, `regex`, or `JSONPath`. Defaults to `simple` if not provided.                                                                                            |
| `x-*`       | [Extensions](#arazzo-specification-extensions) |          | Any number of extension fields can be added to the criterion object that can be used by tooling and vendors.                                                                                                 |

### Arazzo Criterion Object Examples

**Simple Condition - Check if a drink was successfully created**

```yaml arazzo.yaml
- condition: $statusCode == 201
```

**Simple Condition - Check if the bar is open**

```yaml
- condition: $response.body.isOpen == true
```

**Regex Condition - Check if the drink name matches a pattern**

```yaml arazzo.yaml
- context: $response.body.drinkName
  condition: "^Sazerac"
  type: regex
```

**JSONPath Condition - Check if the ingredient list contains "whiskey"**

```yaml arazzo.yaml
- context: $response.body
  condition: $..ingredients[?(@.name == 'whiskey')]
  type: JSONPath
```

**Simple Condition - Check if the customer is over 21**

```yaml arazzo.yaml
- condition: $response.body.customer.age >= 21
```

**JSONPath Condition - Check if there are any available tables**

```yaml arazzo.yaml
- context: $response.body
  condition: $[?length(@.tables[?(@.available == true)]) > 0]
  type: JSONPath
```

## Request Body Object

The request body object describes the payload and `Content-Type` to send with the request when executing an operation in a workflow step.

| Field Name     | Type                                                        | Required | Description                                                                                                                                                        |
| -------------- | ----------------------------------------------------------- | -------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| `contentType`  | `string`                                                    |          | The `Content-Type` header for the request payload. If omitted, defaults to the `Content-Type` of the referenced operation.                                         |
| `payload`      | Any                                                         |          | The literal payload value to send in the request body. Can contain [runtime expressions](#runtime-expressions) which will be evaluated before sending the request. |
| `replacements` | [[Payload Replacement Object](#payload-replacement-object)] |          | An array of [payload replacement objects](#payload-replacement-object) specifying values to insert into specific locations in the payload.                         |
| `x-*`          | [Extensions](#arazzo-specification-extensions)              |          | Any number of extension fields can be added to the request body object that can be used by tooling and vendors.                                                    |

### Request Body Object Examples

**JSON Payload (Template)**

```yaml arazzo.yaml
contentType: application/json
payload: |
  {
    "order": {
      "drinkId": "{$inputs.drink_id}",
      "customerId": "{$inputs.customer_id}",
      "quantity": {$inputs.quantity}
    }
  }
```

**JSON Payload (Object)**

```yaml arazzo.yaml
contentType: application/json
payload:
  order:
    drinkId: $inputs.drink_id
    customerId: $inputs.customer_id
    quantity: $inputs.quantity
```

**JSON Payload (Runtime Expression)**

```yaml arazzo.yaml
contentType: application/json
payload: $inputs.orderPayload
```

**XML Payload (Template)**

```yaml arazzo.yaml
contentType: application/xml
payload: |
  <order>
    <drinkId>{$inputs.drink_id}</drinkId>
    <customerId>{$inputs.customer_id}</customerId>
    <quantity>{$inputs.quantity}</quantity>
  </order>
```

**Form Data Payload (Object)**

```yaml arazzo.yaml
contentType: application/x-www-form-urlencoded
payload:
  drinkId: $inputs.drink_id
  customerId: $inputs.customer_id
  quantity: $inputs.quantity
```

**Form Data Payload (String)**

```yaml arazzo.yaml
contentType: application/x-www-form-urlencoded
payload: "drinkId={$inputs.drink_id}&customerId={$inputs.customer_id}&quantity={$inputs.quantity}"
```

## Payload Replacement Object

A payload replacement object specifies a location within the request payload and the value to insert at that location.

| Field Name | Type                                           | Required | Description                                                                                                                                                                                                                                                      |
| ---------- | ---------------------------------------------- | -------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `target`   | `string`                                       | ✅       | A [JSON Pointer](https://tools.ietf.org/html/rfc6901) or [XPath](https://www.w3.org/TR/xpath-31/#id-expressions) expression that identifies the location in the payload to insert the `value`. For JSON payloads, use JSON Pointer. For XML payloads, use XPath. |
| `value`    | Any                                            | ✅       | The value to insert at the specified `target` location. Can be a literal or a [runtime expression](#runtime-expressions) that will be evaluated before sending the request.                                                                                      |
| `x-*`      | [Extensions](#arazzo-specification-extensions) |          | Any number of extension fields can be added to the payload replacement object that can be used by tooling and vendors.                                                                                                                                           |

### Payload Replacement Object Examples

**Runtime Expression Value**

```yaml
target: /drinkId
value: $inputs.drink_id
```

**Literal Value**

```yaml
target: /quantity
value: 2
```

## Runtime Expressions

Runtime expressions allow you to reference values that will be available when a workflow is executed, such as values from the HTTP request or response, the event that triggered the workflow, or outputs from previous workflow steps.

The syntax for runtime expressions is `{expression}`, where `expression` is one of the following:

| Expression                         | Description                                                         |
| ---------------------------------- | ------------------------------------------------------------------- |
| `$url`                             | The full URL of the request                                         |
| `$method`                          | The HTTP method of the request                                      |
| `$statusCode`                      | The HTTP status code of the response                                |
| `$request.header.{name}`           | The value of the specified request header                           |
| `$request.query.{name}`            | The value of the specified query parameter from the request URL     |
| `$request.path.{name}`             | The value of the specified path parameter from the request URL      |
| `$request.body`                    | The entire request body                                             |
| `$request.body#/path/to/property`  | The value of the specified JSON pointer path from the request body  |
| `$response.header.{name}`          | The value of the specified response header                          |
| `$response.body`                   | The entire response body                                            |
| `$response.body#/path/to/property` | The value of the specified JSON pointer path from the response body |
| `$inputs.{name}`                   | The value of the specified workflow input                           |
| `$outputs.{name}`                  | The value of the specified workflow output                          |
| `$steps.{stepId}.{outputName}`     | The value of the specified output from the step with ID `{stepId}`  |
| `$workflows.{id}.{inputName}`      | The value of the specified input from the workflow with ID `{id}`   |
| `$workflows.{id}.{outputName}`     | The value of the specified output from the workflow with ID `{id}`  |

### Runtime Expression Examples

| Expression                           | Example Value      |
| ------------------------------------ | ------------------ |
| `$request.header.Authorization`      | `Bearer abc123`    |
| `$request.query.drinkId`             | `12345`            |
| `$response.body#/drinks/0/name`      | `"Negroni"`        |
| `$inputs.orderType`                  | `"pickup"`         |
| `$steps.submitOrder.outputs.orderId` | `"a8b9c6d4e5f001"` |

## Arazzo Specification Extensions

The Arazzo Specification allows custom properties to be added at certain points using specification extensions.

Extension properties are always prefixed by `"x-"` and can have any valid JSON value.

For example:

```yaml
x-internal-id: abc123
x-vendor-parameter:
  vendorId: 123
  channelId: abc
```

The extensions defined by the Arazzo Specification are:

| Context                                                   | Description                                       |
| --------------------------------------------------------- | ------------------------------------------------- |
| [Arazzo Description](#arazzo-description-structure)       | Applies to the entire Arazzo description document |
| [Info Object](#info-object)                               | Applies to the `info` object                      |
| [Source Description Object](#source-description-object)   | Applies to all the source description objects     |
| [Workflow Object](#workflow-object)                       | Applies to all workflow objects                   |
| [Step Object](#step-object)                               | Applies to all step objects                       |
| [Parameter Object](#parameter-object)                     | Applies to all parameter objects                  |
| [Success Action Object](#success-action-object)           | Applies to all success action objects             |
| [Failure Action Object](#failure-action-object)           | Applies to all failure action objects             |
| [Criterion Object](#criterion-object)                     | Applies to all criterion objects                  |
| [Request Body Object](#request-body-object)               | Applies to all request body objects               |
| [Payload Replacement Object](#payload-replacement-object) | Applies to all payload replacement objects        |
| [Reusable Object](#reusable-object)                       | Applies to all reusable objects                   |
| [Components Object](#components-object)                   | Applies to the components object                  |

The specification extension key formats `^x-oai-` and `^x-oas-` are reserved for extensions defined by the [OpenAPI Initiative](https://www.openapis.org/).

Extension properties can be used to add additional features, metadata, or configuration options to the Arazzo description that are not directly supported by the current version of the specification. However, additional tooling may be required to process custom extensions.


 This is the content for the doc openapi/components.md 

 # Components Object in OpenAPI

The Components Object is a container for reusable objects that can be referenced across the API. These objects can be referenced using [References](/openapi/references), and generally are only valid if referenced by other parts of the API.

| Field             |                                                           Type                                                            | Required | Description                                                                                                                                                                                                                                                                                         |
| ----------------- | :-----------------------------------------------------------------------------------------------------------------------: | :------: | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `schemas`         |                                      Map[string, [Schema Object](/openapi/schemas)]\*                                       |          | A map of [Schema Objects](/openapi/schemas) that can be referenced by other parts of the API.<br/><br/>**Note: OpenAPI 3.0.x does support [OpenAPI Reference Objects](/openapi/references#openapi-reference-object) as the value here, but `3.1.x` uses the [JSON Schema Referencing](/openapi/schemas#json-schema--openapi) format.** |
| `securitySchemes` | Map[string, [Security Scheme Object](/openapi/security/security-schemes) \| [OpenAPI Reference Object](/openapi/references#openapi-reference-object)]\* |          | A map of [Security Scheme Objects](/openapi/security/security-schemes) that can be referenced by other parts of the API.                                                                                                                                                                                       |
| `pathItems`       |       Map[string, [Path Item Object](/openapi/paths#path-item-object) \| [OpenAPI Reference Object](/openapi/references#openapi-reference-object)]\*       |          | A map of [Path Item Objects](/openapi/paths#path-item-object) that can be referenced by other parts of the API.                                                                                                                                                                                                   |
| `parameters`      |       Map[string, [Parameter Object](/openapi/paths/parameters#parameter-object) \| [OpenAPI Reference Object](/openapi/references#openapi-reference-object)]\*       |          | A map of [Parameter Objects](/openapi/paths/parameters#parameter-object) that can be referenced by other parts of the API.                                                                                                                                                                                                   |
| `requestBodies`   |    Map[string, [Request Body Object](/openapi/paths/operations/requests) \| [OpenAPI Reference Object](/openapi/references#openapi-reference-object)]\*    |          | A map of [Request Body Objects](/openapi/paths/operations/requests) that can be referenced by other parts of the API.                                                                                                                                                                                             |
| `responses`       |        Map[string, [Response Object](/openapi/paths/operations/responses#response-object) \| [OpenAPI Reference Object](/openapi/references#openapi-reference-object)]\*        |          | A map of [Response Objects](/openapi/paths/operations/responses#response-object) that can be referenced by other parts of the API.                                                                                                                                                                                                     |
| `headers`         |          Map[string, [Header Object](/openapi/paths/operations/responses/headers) \| [OpenAPI Reference Object](/openapi/references#openapi-reference-object)]\*          |          | A map of [Header Objects](/openapi/paths/operations/responses/headers) that can be referenced by other parts of the API.                                                                                                                                                                                                         |
| `examples`        |         Map[string, [Example Object](/openapi/examples) \| [OpenAPI Reference Object](/openapi/references#openapi-reference-object)]\*         |          | A map of [Example Objects](/openapi/examples) that can be referenced by other parts of the API.                                                                                                                                                                                                       |
| `callbacks`       |        Map[string, [Callback Object](/openapi/paths/operations/callbacks#callback-object) \| [OpenAPI Reference Object](/openapi/references#openapi-reference-object)]\*        |          | A map of [Callback Objects](/openapi/paths/operations/callbacks#callback-object) that can be referenced by other parts of the API.                                                                                                                                                                                                     |
| `links`           |            Map[string, [Link Object](/openapi/paths/operations/responses/links#link-object) \| [OpenAPI Reference Object](/openapi/references#openapi-reference-object)]\*            |          | A map of [Link Objects](/openapi/paths/operations/responses/links#link-object) that can be referenced by other parts of the API.                                                                                                                                                                                                             |
| `x-*`             |                                                 [Extensions](/openapi/extensions)                                                 |          | Any number of extension fields can be added to the Components Object that can be used by tooling and vendors.                                                                                                                                                                                       |


 This is the content for the doc openapi/errors.mdx 

 import { Callout } from "~/components";

# Errors in OpenAPI

In OpenAPI, errors are typically represented as [responses](/openapi/paths/operations/responses#response-object-in-openapi), with a clear body response structure and a status code in the range of **400-599** describing the error.

A well-designed error response should provide a clear and actionable message that helps the developer describe the error to a user.

## Key elements of an error response

The status code and response body are the key elements of an error response. 

### Status code

HTTP response status codes play a vital role in describing the nature of errors. You should use appropriate codes to indicate the error type:

| Status code | Meaning                | Example use case                      |
|-------------|------------------------|---------------------------------------|
| `400`       | Bad Request            | Input validation failed               |
| `401`       | Unauthorized           | Missing or invalid authentication     |
| `403`       | Forbidden              | Insufficient permissions              |
| `404`       | Not Found              | Resource does not exist               |
| `413`       | Payload Too Large      | File or request body exceeds limit    |
| `415`       | Unsupported Media Type | Invalid content type (for example, text or XML) |
| `500`       | Internal Server Error  | Unexpected server-side issue          |


<Callout title="HTTP response status codes" variant="info">
  You can find a comprehensive list of HTTP response status codes for client errors (400-499) [here](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status#client_error_responses) and server errors (500-599) [here](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status#server_error_responses).
</Callout>


### Response body

The response body provides the client with additional information about the error that can be displayed to the user. It is recommended to use a structured schema that describes the error in a clear and actionable way. Here is an example:

```yaml
{
  "error": "ValidationError",
  "message": "The provided file type is not supported.",
  "details": {
    "field": "fileType",
    "allowedValues": ["image/jpeg", "application/pdf"]
  }
}
```

An error response can have these common properties: 

- `error`: A machine-readable error code, such as `ValidationError` or `AuthenticationFailed`.

- `message`: A human-readable description of the error.

- `details`: Additional contextual information about the error, such as invalid fields or allowed values.

You can provide additional properties in the response body, such as the `timestamp` or `trace ID`, to help with debugging and tracking the error.

## Defining error responses in an OpenAPI document

For standard API endpoints, error responses should be defined in the `responses` section of the OpenAPI document. You can use reusable components to standardize error schemas:


```yaml openapi.yaml
paths:
  /resource:
    get:
      summary: Retrieve a resource
      responses:
        '200':
          description: Successful operation
        '400':
          $ref: '#/components/responses/BadRequestError'
        '500':
          $ref: '#/components/responses/InternalServerError'

components:
  responses:
    BadRequestError:
      description: Invalid input provided
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/ErrorResponse'
    InternalServerError:
      description: Unexpected server error
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/ErrorResponse'
  schemas:
    ErrorResponse:
      type: object
      properties:
        error:
          type: string
          description: Machine-readable error code
        message:
          type: string
          description: Human-readable error message
        details:
          type: object
          additionalProperties: true
          description: Additional error context
        timestamp:
          type: string
          format: date-time
        traceId:
          type: string
          description: Unique identifier for error tracing
```


## RFC 9457 Problem Details for Errors

## Standardizing error messages: RFC 9457 Problem Details

[RFC 9457](https://tools.ietf.org/html/rfc9457) is a standard for representing errors in REST APIs. Published in July 2023, it introduces a standardized, machine-readable, and actionable format for describing errors. While RFC 9457 is widely regarded as a best practice, it is important to note that it is not included in the OpenAPI Specification (OAS).

The Problem Details format for describing errors is JSON-based and specifies key properties that are either required, optional, or extensible. When serialized as JSON, the format uses the media type `application/problem+json`. 

The core properties of the Problem Details format are:

- `type`: A URI reference that identifies the problem type, providing documentation or additional context for the error.

- `title`: A short, human-readable summary of the problem type. The title should be consistent across instances of the same problem.

- `status`: The HTTP status code for the error.

- `detail`: A human-readable explanation of the error.

- `instance`: A URI reference that identifies the specific occurrence of the problem, providing a link for debugging or accessing more information.

Here is how you can apply RFC 9457 to your OpenAPI documentation:


```yaml openapi.yaml
paths:
  /user:
    post:
      summary: Create a new user
      responses:
        '400':
          description: Validation Error
          content:
            application/problem+json:
              schema:
                $ref: '#/components/schemas/ProblemDetails'

components:
  schemas:
    ProblemDetails:
      type: object
      properties:
        type:
          type: string
          format: uri-reference
          description: URI reference identifying the problem type.
        title:
          type: string
          description: A short, human-readable summary of the problem type.
        status:
          type: integer
          description: HTTP status code for this error occurrence.
        detail:
          type: string
          description: Explanation specific to this occurrence of the problem.
        instance:
          type: string
          format: uri-reference
          description: URI reference identifying the specific occurrence of the problem.
```


 This is the content for the doc openapi/examples.md 

 # Examples in OpenAPI

## Why add examples to your OpenAPI spec?

Adding examples to your OpenAPI spec significantly improves the readability of generated artifacts, like documentation and SDKs, by providing concrete, real-world illustrations of how your API behaves. This reduces the learning curve and potential for user errors.

## Where to add examples to your OpenAPI spec

You can add examples to **objects, parameters, or properties** using either the `example` or `examples` keyword.

In the examples below, we consider an API endpoint (e.g., `/ingredients/{id}`) that returns the following example response. This response will be defined in the OpenAPI spec using an `Ingredient` object:

```json
{
  "id": 123,
  "name": "Sugar Syrup",
  "type": "long-life",
  "stock": 10,
  "photo": "https://speakeasy.bar/ingredients/sugar_syrup.jpg",
  "status": "available"
}
```

## 1. Single Example (`example` Keyword)

### Defining a Single Example within `components.schemas`

Use the `example` keyword to define a single example directly within the `schemas` section.

This provides immediate context without requiring users to reference other parts of the spec. However, since it splits the example across multiple properties, it can make understanding the entire object more difficult and may lead to duplication (and maintenance issues) if the same example is needed in multiple schemas.

```yaml
components:
  schemas:
    Ingredient:
      type: object
      properties:
        id:
          type: integer
          example: 123
        name:
          type: string
          example: "Sugar Syrup"
        type:
          type: string
          example: "long-life"
        stock:
          type: integer
          example: 10
        photo:
          type: string
          format: uri
          example: "https://speakeasy.bar/ingredients/sugar_syrup.jpg"
        status:
          type: string
          enum:
            - available
            - out-of-stock
          example: "available"
```

### Defining a Single Example within `components.examples`
Alternatively, you can define the example as a reusable Example Object in the `components.examples` section. This approach helps avoid redundancy and improves maintainability, as the example can be referenced across multiple schemas, requests, or responses.

This is the format of the Example Object:

| Field           | Type                      | Required | Description                                                                                                                                |
| --------------- | ------------------------- | -------- | ------------------------------------------------------------------------------------------------------------------------------------------ |
| `summary`       | String                    |          | A brief summary of the example.                                                                                                            |
| `description`   | String                    |          | A detailed description of the example. This may contain [CommonMark syntax](https://spec.commonmark.org/) to provide a rich description.   |
| `value`         | Any (typically object)                       |          | The example value. This field can contain any valid JSON data, including simple values or complex objects with multiple properties, as shown in the example below. Mutually exclusive with the `externalValue` field.                                                                      |
| `externalValue` | String                    |          | A URL that points to the example. This is useful if the example is too large to include inline. Mutually exclusive with the `value` field. |
| `x-*`           | [Extensions](/openapi/extensions) |          | Any number of extension fields can be added to the Example Object that can be used by tooling and vendors.             

```yaml
components:
  examples:
    SugarSyrup:
      summary: An example of a sugar syrup ingredient.
      value:
        id: 123
        name: "Sugar Syrup"
        type: "long-life"
        stock: 10
        photo: "https://speakeasy.bar/ingredients/sugar_syrup.jpg"
        status: "available"
```

**Referencing the Reusable Example in `components.schemas`**
Once defined in `components.examples`, you can reference this reusable example in your schema like this:

```yaml
components:
  schemas:
    Ingredient:
      type: object
      properties:
        id:
          type: integer
        name:
          type: string
        type:
          type: string
        stock:
          type: integer
        photo:
          type: string
          format: uri
        status:
          type: string
          enum:
            - available
            - out-of-stock
      examples:
        $ref: '#/components/examples/SugarSyrup'
```

## 2. Multiple Examples (`examples` Keyword)

To provide multiple examples for a property, or for the entire object, you can use the `examples` keyword. This is useful for showing different scenarios or variations, such as different statuses or conditions for an ingredient.

#### Defining Multiple Examples within `components.schemas`

As before, the `examples` can be specified within `components.schemas`. 

Here’s how you can use the examples keyword at both the property level and the object level.

**Using examples at the Property Level**

```yaml
components:
  schemas:
    Ingredient:
      type: object
      properties:
        id:
          type: integer
          examples:
            - 123
            - 125
        name:
          type: string
          examples:
            - "Sugar Syrup"
            - "Maple Syrup"
        type:
          type: string
          examples:
            - "long-life"
            - "organic"
        stock:
          type: integer
          examples:
            - 10
            - 0
        photo:
          type: string
          format: uri
          examples:
            - "https://speakeasy.bar/ingredients/sugar_syrup.jpg"
            - "https://speakeasy.bar/ingredients/maple_syrup.jpg"
        status:
          type: string
          enum:
            - available
            - discontinued
          examples:
            - "available"
            - "discontinued"
```

The above uses a concise array underneath each `examples`. The drawback of this approach is that it doesn't allow for additional metadata such as `summary` or `description`. An alternative approach that does allow for such metadata is e.g.:

```yaml
...
        photo:
          type: string
          format: uri
          examples:
            sugarSyrup:
              summary: A photo of Sugar Syrup.
              value: "https://speakeasy.bar/ingredients/sugar_syrup.jpg"
            mapleSyrup:
              summary: A photo of Maple Syrup.
              value: "https://speakeasy.bar/ingredients/maple_syrup.jpg"
        status:
          type: string
          enum:
            - available
            - discontinued
          examples:
            available:
              summary: Status for available ingredient.
              value: "available"
            discontinued:
              summary: Status for discontinued ingredient.
              value: "discontinued"
```

**Using examples at the Object Level**

An alternative approach to defining examples at the property level is to define them at the object level.

This shows entire scenarios for the object (`Ingredient` in this case). Each example (`available` and `discontinued`) is a complete instance of the object with all its properties.

```yaml
components:
  schemas:
    Ingredient:
      type: object
      properties:
        id:
          type: integer
        name:
          type: string
        type:
          type: string
        stock:
          type: integer
        photo:
          type: string
          format: uri
        status:
          type: string
          enum:
            - available
            - discontinued
      examples:
        available:
          value:
            id: 123
            name: "Sugar Syrup"
            type: "long-life"
            stock: 10
            photo: "https://speakeasy.bar/ingredients/sugar_syrup.jpg"
            status: "available"
        discontinued:
          value:
            id: 125
            name: "Maple Syrup"
            type: "organic"
            stock: 0
            photo: "https://speakeasy.bar/ingredients/maple_syrup.jpg"
            status: "discontinued"
```

Note that the specific names used here (`available` and `discontinued`) are not referenced elsewhere. In other words, you could use names like `example1` or `example2` without affecting the validity of the OpenAPI spec. However, descriptive names like `available` and `discontinued` are important for readability.


### Defining Multiple Examples as Reusable Objects in `components.examples`
Multiple examples can also be defined as a reusable object in the `components.examples` section. This approach keeps examples grouped together, making them easier to maintain and reuse across different parts of the API specification:

```yaml
components:
  examples:
    AvailableIngredient:
      summary: An example of an ingredient that is available.
      value:
        id: 123
        name: "Sugar Syrup"
        type: "long-life"
        stock: 10
        photo: "https://speakeasy.bar/ingredients/sugar_syrup.jpg"
        status: "available"

    DiscontinuedIngredient:
      summary: An example of an ingredient that has been discontinued.
      value:
        id: 125
        name: "Maple Syrup"
        type: "organic"
        stock: 0
        photo: "https://speakeasy.bar/ingredients/maple_syrup.jpg"
        status: "discontinued"
```


**Referencing Multiple Reusable Examples in `components.schemas`**
Once defined, you can reference the examples in your schemas like this:

```yaml
components:
  schemas:
    Ingredient:
      type: object
      properties:
        id:
          type: integer
        name:
          type: string
        type:
          type: string
        stock:
          type: integer
        photo:
          type: string
          format: uri
        status:
          type: string
          enum:
            - available
            - discontinued
      examples:
        available:
          $ref: '#/components/examples/AvailableIngredient'
        discontinued:
          $ref: '#/components/examples/DiscontinuedIngredient'
```

Here of course, the names `AvailableIngredient` and `DiscontinuedIngredient` are important since they are referenced elsewhere.

 This is the content for the doc openapi/extensions.md 

 # Extensions in OpenAPI

Extensions allow us to add extra keywords not included in the OpenAPI Specification. This enables tooling such as SDK generators to access vendor-specific functionality directly in an OpenAPI document.

Extension fields always start with `x-`.

Although optional, it is conventional for vendors to further prefix their extensions with the name of the vendor. For example, Speakeasy uses extensions that start with `x-speakeasy-`. This makes it easier to track vendor extensions over time and remove unused vendor extensions in the future.

The value of an extension field can be an object, array, `null`, or any primitive value. Vendors determine the values they expect for the extensions they use.

| Field | Type | Description                                                                                                            |
| ----- | ---- | ---------------------------------------------------------------------------------------------------------------------- |
| `^x-` | Any  | An extension's value can be an object, array, primitive, or `null`. Expected values are determined by tooling vendors. |

Here's an example of a Speakeasy extension that adds retries to requests made by Speakeasy-managed SDKs:

```yaml
x-speakeasy-retries:
  strategy: backoff
  backoff:
    initialInterval: 500 # 500 milliseconds
    maxInterval: 60000 # 60 seconds
    maxElapsedTime: 3600000 # 5 minutes
    exponent: 1.5
  statusCodes:
    - 5XX
  retryConnectionErrors: true
```


 This is the content for the doc openapi/external-documentation.md 

 # The OpenAPI External Documentation Object

Allows for providing information about external documentation available for the API, Operation, Tag, or Schema.

| Field | Type | Required | Description |
| ----- | ----- | ----- | ----- |
| `url` | String | ✅ | A URL to the external documentation. |
| `description` | String | | A description of the external documentation. [CommonMark syntax](https://spec.commonmark.org/) can be used to provide a rich description. |
| `x-*` | [Extensions](/openapi/extensions) | | Any number of extension fields can be added to the external documentation object that can be used by tooling and vendors. |


 This is the content for the doc openapi/file-uploads.mdx 

 import { Tabs } from "@speakeasy/nextra-theme";

# File uploads in OpenAPI

File uploads are a critical part of powerful REST APIs, allowing files to be transmitted from clients to servers for storage, analysis, or processing.

File uploads in a REST API can be handled in various ways, depending on file format, size, and complexity. OpenAPI provides a standardized way to define and describe file uploads, accommodating diverse use cases.

OpenAPI facilitates file uploads through various media types, including `multipart/form-data`, `application/octet-stream` (binary), and JSON-embedded payloads. Each approach has advantages and challenges that should be evaluated based on the API's requirements.

## Why file uploads can be tricky

File uploads present several technical and operational challenges, such as:

- **Content type complexity:** Servers need to process different content types differently.
- **Validation and error handling:** Validating and handling file uploads can be complex, especially when dealing with large files or multiple file uploads.
- **Security and privacy:** File uploads are susceptible to security and privacy risks, such as data exfiltration, resource abuse, file injection, and data breaches.
- **Scalability and performance:** Handling large file uploads is resource-intensive and can impact server performance, so a good strategy for streaming and buffering is needed.

These challenges can be mitigated with the right approach and tools, but also the correct specification, so the client and server can communicate effectively.

These challenges can be mitigated by following best practices for efficient file handling and ensuring the specification allows the client and server to communicate effectively.

## Defining file uploads in an OpenAPI document

File uploads can be described in an OpenAPI document using `multipart/form-data`, `application/octet-stream` (binary), or JSON.

### `multipart/form-data`

Widely recognized as the standard for file uploads, `multipart/form-data` allows files and associated metadata to be transmitted in the same request. 

In an OpenAPI document, specifying `multipart/form-data` for the `/file/upload` endpoint might look like this:

```yaml openapi.yaml
paths:
  /file/upload:
    post:
    summary: Upload a file
      description: >
        Allows uploading a file along with additional metadata. 
      operationId: uploadFile
      tags:
        - FileUpload      
      requestBody:
        required: true
        content:
          multipart/form-data:
            schema:
              type: object
              properties:
                file:
                  type: string
                  format: binary
                caption:
                  type: string
      responses:
        '200':
          description: File uploaded successfully
```

The client can call the endpoint to upload a PDF file with a metadata description like this:

<Tabs items={['curl', 'Python']}>
<Tabs.Tab>
```bash curl
curl -X POST "https://api.example.com/file/upload" \
     -H "Content-Type: multipart/form-data" \
     -F "file=@content.pdf" \
     -F "caption=Sample PDF file"
```
</Tabs.Tab>
<Tabs.Tab>
```python Python
import requests

url = "https://api.example.com/file/upload"
file_path = "content.pdf"
caption = "Sample PDF file"

with open(file_path, 'rb') as file:
    files = {
        'file': (file_path, file, 'application/pdf'),
        'caption': (None, caption)
    }
    response = requests.post(url, files=files)

if response.status_code == 200:
    print("File uploaded successfully")
else:
    print(f"Failed to upload file: {response.status_code}"
```
</Tabs.Tab>
</Tabs>

### `application/octet-stream` (binary)

The `application/octet-stream` media type is used to transmit binary data, such as images, audio, or video files. It is commonly used for file uploads, but it can also be used for other types of binary data.

In an OpenAPI document, specifying `application/octet-stream` for the `/file/upload` endpoint might look like this:

```yaml openapi.yaml
paths:
  /file/upload:
    post:
      summary: Upload a file
      requestBody:
        required: true
        content:
          application/octet-stream:
            schema:
              type: string
              format: binary
      responses:
        '200':
          description: File uploaded successfully
```

The client can call the endpoint to upload an image file as follows:

<Tabs items={['curl', 'Python']}>
<Tabs.Tab>
```bash curl
curl -X POST "https://api.example.com/file/upload" \
     -H "Content-Type: application/octet-stream" \
     --data-binary "@image.jpg"
```
</Tabs.Tab>

<Tabs.Tab>
```python Python
import requests

url = "https://api.example.com/file/upload"
file_path = "image.jpg"

with open(file_path, 'rb') as file:
    files = {
        'file': (file_path, file, 'image/jpeg')
    }
    response = requests.post(url, files=files)

if response.status_code == 200:
    print("File uploaded successfully")
else:
    print(f"Failed to upload file: {response.status_code}")
```
</Tabs.Tab>
</Tabs>

In curl, the `--data-binary` option sends raw file data in the HTTP request body, specified with `@` followed by the file path. Similarly, in Python, a file opened in binary mode (`rb`) is read and sent as a binary string.

### JSON

For specific use cases, the JSON format can be used to transmit a file to a server, such as when the file is small and requires little or no processing.
The JSON format is not suitable for large files or files with complex structures, as it can lead to issues such as data loss or corruption.

In an OpenAPI document, the specification for transmitting a JSON file on the `/file/upload` endpoint might look like this:

```yaml openapi.yaml
paths:
  /file/upload:
    post:
      summary: Upload a file
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              properties:
                file:
                  type: string
                  format: byte
                caption:
                  type: string
      responses:
        '200':
          description: File uploaded successfully
```

The client can call the endpoint using curl or Python as follows:

<Tabs items={['curl', 'Python']}>
<Tabs.Tab>
```bash curl
curl -X POST "https://api.example.com/file/upload" \
     -H "Content-Type: application/json" \
     -d '{"file": $(base64 image.jpg), "caption": "Sample JSON file"}'
```
</Tabs.Tab>

<Tabs.Tab>
```python Python
import requests
import base64

url = "https://api.example.com/file/upload"
file_path = "image.jpg"

with open(file_path, "rb") as file:
    base64_file = base64.b64encode(file.read()).decode("utf-8")

payload = {
    "file": base64_file,
    "filename": "image.jpg"
}

response = requests.post(url, json=payload)

if response.status_code == 200:
    print("File uploaded successfully")
else:
    print(f"Failed to upload file: {response.status_code}")
```
</Tabs.Tab>
</Tabs>

In this example, the file data is encoded in Base64 format and included in the JSON payload. The Python code reads the file data from a string variable and sends it as a JSON object in the request body.

## Best practices for file uploads

Here are some best practices for handling file uploads in an OpenAPI document.

### Prioritize `multipart/form-data`

The `multipart/form-data` format is preferred for most file uploads, as it allows additional metadata to be sent with the file. However, other formats like binary or JSON can be used for specific use cases, such as streaming large files (binary) or embedding files within JSON payloads for system integration.

### Handling large files

Uploading large files can significantly impact the performance of your API. To avoid server overload, consider using a streaming approach instead of sending or processing the whole file at once on the server. The `application/octet-stream` media type is ideal for this use case, as it allows the file to be divided into smaller binary chunks to be sent one by one. 

Chunked file uploads require some extra coding work as there is no formal specification for upload streams. However, this process can be implemented using a **session-based streaming** approach, which involves the following steps:

1. **Initiate the session:** The client requests an upload session, and the server responds with a session ID to track the upload.

2. **Upload chunks:** The client slices the file into smaller binary chunks and uploads them sequentially, using the session ID to associate them.

3. **Finalize the upload:** The client signals the server to finalize the upload, and the server assembles the chunks into the complete file.

In an OpenAPI document, the specification for this approach might look like this:

```yaml openapi.yaml
openapi: 3.1.0
info:
  title: File Upload API
  version: 1.0.0

paths:
  /init:
    post:
      summary: Initiate an upload session
      operationId: initiateSession
      responses:
        200:
          description: Upload session initiated
          content:
            application/json:
              schema:
                type: object
                properties:
                  session_id:
                    type: string
                    description: The unique ID for the upload session
        400:
          description: Bad request

  /upload:
    post:
      summary: Upload a file chunk
      operationId: uploadChunk
      parameters:
        - name: x-session-id
          in: header
          required: true
          schema:
            type: string
          description: The unique session ID for associating the chunk
      requestBody:
        required: true
        content:
          application/octet-stream:
            schema:
              type: string
              format: binary
      responses:
        200:
          description: Chunk uploaded successfully
        400:
          description: Invalid or missing session ID

  /finalize:
    post:
      summary: Finalize the upload session
      operationId: finalizeUpload
      parameters:
        - name: x-session-id
          in: header
          required: true
          schema:
            type: string
          description: The unique session ID for finalizing the upload
      responses:
        200:
          description: Upload finalized successfully
        400:
          description: Invalid or missing session ID
```

The client begins by sending a POST `/init` request to the server to initiate an upload session, receiving a `session_id` in the response. 

The file is then divided into smaller binary chunks, and each chunk is sent using a POST `/upload` request with the `X-Session-ID` header set to the `session_id`. The chunk is included in the request body as `application/octet-stream`. 

When all chunks are uploaded, the client sends a POST `/finalize` request including the `X-Session-ID` header to instruct the server to validate and assemble the chunks into the complete file, ensuring a reliable and efficient upload process.

### Provide clear and informative feedback

If an error occurs during the upload process, the client should receive clear and informative feedback from the server.

For example, if the server data within the request body is invalid, the client should receive a `400 Bad Request` response with a clear error message. If the file is too large, the client should receive a `413 Request Entity Too Large` response.

Here's how you can define these responses in your OpenAPI document:

```yaml openapi.yaml
responses:
  400:
    description: Bad Request - Validation error
    content:
      application/json:
        schema:
          type: object
          properties:
            error:
              type: string
              example: "Invalid file format. Only JPEG and PNG are allowed."
  413:
    description: Payload Too Large - File size exceeds limit
    content:
      application/json:
        schema:
          type: object
          properties:
            error:
              type: string
              example: "File size exceeds the maximum allowed limit of 10MB."
```


 This is the content for the doc openapi/frameworks.mdx 

 ---
description: "How to generate an OpenAPI schema from your code"
---


import { IconGrid } from "~/features/shared/recipes/IconGrid/IconGrid";
import { TypescriptFrameworkGuidesData } from "~/data/shared/frameworkGuides";
import { PythonFrameworkGuidesData } from "~/data/shared/frameworkGuides";
import { GoFrameworkGuidesData } from "~/data/shared/frameworkGuides";
import { JavaFrameworkGuidesData } from "~/data/shared/frameworkGuides";
import { PHPFrameworkGuidesData } from "~/data/shared/frameworkGuides";
import { getFilteredFrameworkData } from "~/data/shared/frameworkGuides";

# Server Framework Guides

Here, you'll find a comprehensive collection of step-by-step guides for generating OpenAPI specs for popular server frameworks in various languages. Or read our guide below for advice on how to generate an OpenAPI schema from your existing code base.

<IconGrid {...TypescriptFrameworkGuidesData} />

<IconGrid {...PythonFrameworkGuidesData} />

<IconGrid {...GoFrameworkGuidesData} />

<IconGrid {...JavaFrameworkGuidesData} />

<IconGrid {...PHPFrameworkGuidesData} />

# How to generate an OpenAPI schema from your code

An [OpenAPI schema](https://www.openapis.org/) (also called an OpenAPI specification) is a text description of your web service in detail. Your customers and automated tools can use this document to interact with your service with the confidence that they know exactly what each operation does and how to use it.

Some companies start designing their software service in an OpenAPI schema and use that schema to generate their server code. This is called the schema-first approach.

But it's more likely you started building software to service a market, then realized the benefits of providing OpenAPI tools to your clients, and now want to know how to create and maintain an OpenAPI schema from your existing server code. This is the code-first approach. This guide will explain how to generate a schema from code, and link to all the necessary tools in the programming language you use.

But first, let's summarize the benefits of using OpenAPI and the variations of the code-first approach that you can choose from.

## The benefits of OpenAPI

If you don't have an OpenAPI schema, you still need to write documentation, with examples, explaining to your clients how they can call your API. You also need to update this documentation whenever the code changes on your server.

Writing this documentation in the standard OpenAPI format provides the following benefits:

- Enables your clients to browse the schema in their tool of choice, such as [Swagger UI](https://swagger.io/tools/swagger-ui), with good usability.
- Allows the schema to be used for automatic SDK generation, enabling your clients to call your server directly from code without needing to handle REST web calls or use curl. Even if you don't generate an SDK, using an OpenAPI schema to validate the code that clients use to call your service can reduce confusion and errors.
- Supports the generation of server code stubs with statically typed request parameters and responses that you can use to validate that your server code matches the schema.

## Different workflows to support OpenAPI

If you take a code-first approach, you can either annotate your existing code with special comments that an automated tool uses to generate an OpenAPI schema, or start coding in a meta-framework that generates both the server code and the OpenAPI schema. (We call it a meta-framework because it sits above both your code and your schema, controlling both.)

There are two types of annotation:

- Text comments, which are not part of the programming language in which your server is written.
- Attributes, which are valid code in the programming language.

Attributes are superior, as the compiler and your IDE can check that your annotations are syntactically valid code as you work. Attributes can also be refactored, unlike comments.

The danger of using annotations is human error. Programmers need to update annotations correctly whenever they change an operation, but they may forget to or make mistakes. Even when attribute annotations are syntactically correct, they may still describe the operation incorrectly. This will cause your code and schema to drift apart, potentially causing errors when clients try to call your API.

Using a meta-framework, on the other hand, automatically synchronizes your code and schema but requires writing code in the new framework, adding a compilation step, and learning a new tool.

A third option that falls between annotations and meta-frameworks is to use an OpenAPI-aware web framework. These frameworks are designed with native support for OpenAPI features and can automatically generate an OpenAPI schema from the code you write, usually with more detail than that provided in annotations. OpenAPI-aware frameworks, however, tend to be very new, and the most popular (and older) frameworks, like Django and Laravel, are not OpenAPI-aware.

Note that the workflow options we discuss here depend on the availability of tools to support them in your programming language. Popular web languages will have tools for a range of options, but obscure languages may not. You will also find it easier to use a statically typed language, like Go, than a dynamic one, like PHP.

The following process will probably work best for most companies wanting to support OpenAPI:

- Generate an OpenAPI schema for your code, as we describe in the rest of this article.
- Use the new schema as your principal source from now on and generate server code from the schema rather than the other way around. (There is a section explaining schema-first workflows at the end of this guide.)
- Generate SDKs from the schema to make it simple for your clients to call your API.

If you want to keep your code as the principal source, you may want to include an automated reminder in your version-control process to tell programmers to update annotations whenever they commit code.

## Four techniques to extract an OpenAPI schema

The next four sections will show you different ways to generate an OpenAPI schema document from your existing code by:

- Recording network traffic
- Adding comment annotations
- Adding attribute annotations and changing your code to use an OpenAPI-aware framework
- Rewriting your code using a meta-framework

Each technique varies depending on the programming language. This guide provides examples in Go, as it's a popular, statically typed language specifically designed for web services.

The first thing to check is whether your web server framework already natively supports OpenAPI. If it does, you can stop reading this article and follow the framework documentation on how to access the schema the framework automatically creates. If not, read on to discover your options.

If you don't have an API yet but want to learn about OpenAPI for future projects, choose a server framework and language with native OpenAPI support. Alternatively, start by documenting your proposed API as a schema using a Swagger tool, then use a framework that supports code generation from the schema.

## Use HAR and APIGit to generate a schema

The first way to create a schema is to use a tool that listens to your network calls and extracts the schema automatically from the HTTP calls it sees. Generating a schema from network traffic does not depend on programming language. The process is the same for all languages.

The benefit of this approach is that you don't have to manually read your code and document (potentially with mistakes) what the calling contract should be. Instead, the network tool will tell you what actual data is sent, allowing you to spot any unintended parameters when reading through the schema after creation.

The disadvantage is that you have to manually call every operation in your API with all possible parameters to ensure the generator records all variations and creates an accurate schema.

For smaller APIs, you might prefer manually adding annotations or writing code to generate a schema. But for any other project, we recommend using this network listener approach, even in conjunction with other approaches, as it provides an automated review of your existing API.

### HAR example

Let's use the standard Pet Store OpenAPI example to demonstrate how to use a network listener.

- Browse to https://petstore31.swagger.io/#/pet/addPet in a Chromium-based browser.
- Open the developer tools (F12) and select the **Network** tab.
- Select only **Fetch/XHR**.
- Click **Execute** in the web page to start a network call to the API to add a pet.
- In the developer tools, click the `pet` line that appears to see the details of the request and response.
  ![XHR](./assets/guide/xhr.png)
- Also execute a pet update (PUT). (In reality, you want to call every endpoint in your API, but we don't need to do that now.)
- In the network tab, click the download arrow icon in the top row.
- Save an HAR file (HTTP archive) to your desktop.

[Several tools](https://openapi.tools) will convert HAR to an OpenAPI schema. We'll use APIGit.

- Browse to https://app.apigit.com.
- Create an account.
- Create a repository named `pet` (any name will do).
- In the sidebar, browse to **API Documents**, then click the plus sign to add a document.
- Upload the HAR file you saved previously.
- Set the path name to `pet.yaml`.
- Click **Create**.
- Download the YAML file. This is your OpenAPI schema.

![APIGit](./assets/guide/apigit.png)

You can view the schema in a text editor or in a more visually descriptive way in an OpenAPI editor.

- Browse to https://editor-next.swagger.io.
- Import your YAML file.

![Swagger editor](./assets/guide/editornext.png)

The editor will show errors and duplicated objects that could be moved into the components section and shared.

[Other network capture tools](https://tools.openapis.org/categories/all.html) are available. The all-in-one OpenAPI DevTools plugin from Chrome Web Store offers network recording and OpenAPI schema generation.

## Comment annotation

Once you know what all the operations and parameters for your API should be in OpenAPI terms – either by using the generator as discussed in the previous section or by reading the list of OpenAPI data types – you can annotate your existing code with comments. A generator will then use the comments to output an OpenAPI schema.

As mentioned in the introduction, we recommend using attribute annotations instead of comment annotations whenever possible. If your server framework doesn't support attribute annotations, this approach is an alternative option.

You should consider whether to continue using your existing framework or switch to one with native support for OpenAPI. In the long term, adding and maintaining annotations might be more or less work than rewriting and maintaining OpenAPI-aware code.

Comment annotation, like attribute annotation and using an OpenAPI meta-framework, depends on the programming language you use.

### Example comment annotation in Go

The tool used here is [go-swagger3](https://github.com/parvez3019/go-swagger3).

- In any folder on your computer, create a folder called `src`.
- Create a file in `src` called `main.go` and add the content below to it.
  ```go
  package main

  import (
	  "encoding/json"
	  "fmt"
	  "log"
	  "net/http"
  )

  type RequestBody struct {
	  Name string `json:"name"`
  }

  func main() {
	  mux := http.NewServeMux()
	  mux.HandleFunc("/hello", helloHandler)

	  log.Println("Server started on port 8080")
	  log.Fatal(http.ListenAndServe(":8080", mux))
  }

  func helloHandler(w http.ResponseWriter, r *http.Request) {
	  if r.Method != http.MethodPost {
		  http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
		  return
	  }

	  var requestBody RequestBody
	  err := json.NewDecoder(r.Body).Decode(&requestBody)
	  if err != nil {
		  http.Error(w, "Bad request", http.StatusBadRequest)
		  return
	  }

	  response := fmt.Sprintf("Hello %s", requestBody.Name)
	  w.Header().Set("Content-Type", "text/plain")
	  w.Write([]byte(response))
  }
  ```
	This minimal web service has a single POST endpoint, `/hello` that says hello to the name sent as a string parameter called `name`.
- Build and run the service with the commands below to see that it works. You don't need to install Go on your machine, but you do need Docker. Docker will run Go in a container in a security sandbox so it has no access to the rest of your files. You then call the service in the terminal with curl.
  ```sh
  docker run --rm  -v $(pwd)/src:/app -w /app golang:1.23-alpine3.19 /bin/sh -c   "go mod init helloworld && go mod vendor && go build"

  docker run --rm -p 65000:8080 -v $(pwd)/src:/app -w /app golang:1.23-alpine3.19     ./helloworld

  # In a new terminal
  curl -X POST -H "Content-Type: application/json" -d '{"name":"John"}' http://localhost:65000/hello

  # Output
  # Hello John
  ```

Now let's update the web service with some OpenAPI comments.

- Update `main.go`, adding the following at the top of the file:
  ```go
  // @Version 1.0.0
  // @Title Hello API
  // @Description Testing Go OpenAPI frameworks
  package main
  ...
  ```
- Add comments above the operation:
  ```go
  // @Title Hello
  // @Description Say hi to the name given
  // @Param  name  body  RequestBody   true  "Any name"
  // @Success  200 {string} string "Responds with 'Hello {name}'"
  // @Route /helloHandler [post]
  func helloHandler(w http.ResponseWriter, r *http.Request) {
  ...
  ```

To generate a schema from this file, you can either install go-swagger3 in the standard Go container you just used or use the dedicated go-swagger3 Docker image. The first option requires redownloading the Go modules each time, as they are not stored in your project `vendor` folder.

Run one of the two commands below.

  ```sh
  docker run --rm -v $(pwd)/src:/app -w /app golang:1.23-alpine3.19 /bin/sh -c "go install github.com/parvez3019/go-swagger3@latest && /go/bin/go-swagger3 --main-file-path /app/main.go --module-path . --output oas.json --schema-without-pkg --generate-yaml true"

  # OR use dedicated docker image
  docker run -t --rm -v $(pwd)/src:/app -w /app parvez3019/go-swagger3:latest --main-file-path /app/main.go --module-path . --output oas.json --schema-without-pkg --generate-yaml true
  ```

In your `src` folder, you'll now have a schema called `oas.yml`:

```yml
components:
  schemas:
	RequestBody:
	  properties:
		name:
		  type: string
	  type: object
info:
  description: Say hi to the name given
  title: Hello
  version: 1.0.0
openapi: 3.0.0
paths:
  /helloHandler:
	post:
	  description: ' Say hi to the name given'
	  requestBody:
		content:
		  application/json:
			schema:
			  $ref: '#/components/schemas/RequestBody'
		required: true
	  responses:
		"200":
		  content:
			application/json:
			  schema:
				type: string
		  description: Responds with 'Hello {name}'
	  summary: Hello
servers:
- description: Default Server URL
  url: /
```

## Attribute annotation

All the considerations raised about comment annotations in the previous section also apply to attribute annotations, except that attribute annotations are safer than comment annotations as they can be parsed by a compiler.

### Example attribute annotation with an OpenAPI-aware framework in Go

To demonstrate attribute annotation, we'll use a framework called [Huma](https://huma.rocks/), which [supports many Go routers](https://huma.rocks/features/bring-your-own-router). Unlike a simple annotation plugin that sits above your existing code, Huma requires you to alter your operations to use the Huma context object. While Huma doesn't support the standard Go `net/http` router, it does support the more complex `mux` handler.

If you'd like to follow along, use the existing `main.go` file from the previous section.

First, install Huma:

  ```sh
  docker run --rm -v $(pwd)/src:/app -w /app golang:1.23-alpine3.19    go get github.com/danielgtaylor/huma/v2 github.com/danielgtaylor/huma/v2/adapters/humago
  ```

Update `main.go` to use Huma with the changes below.

  ```go
  package main

  import (
	  // "encoding/json"
	  "fmt"
	  "log"
	  "net/http"

	  "context"
	  "github.com/danielgtaylor/huma/v2" // NEW
	  "github.com/danielgtaylor/huma/v2/adapters/humago"
  )

  type RequestBody struct {
	  // Name string `json:"name"`
	  Body struct {
		Name string `json:"name" maxLength:"30" example:"world" doc:"Name to greet"`
	}
  }

  //NEW
  type ResponseBody struct {
	Body struct {
		Message string `json:"message"`
	}
  }

  func main() {
	  mux := http.NewServeMux()
	  api := humago.New(mux, huma.DefaultConfig("Hello API", "1.0.0")) // NEW
	huma.Post(api, "/hello", helloHandler) // NEW

	  log.Println("Server started on port 8080")
	  log.Fatal(http.ListenAndServe(":8080", mux))
  }

   // NEW
  func helloHandler(ctx context.Context, input *RequestBody) (*ResponseBody, error) {
	response := &ResponseBody {
		Body: struct { Message string `json:"message"`}{
			Message: fmt.Sprintf("Hello %s", input.Body.Name),
		},
	}
	  return response, nil
  }
  ```

Note that the code above has changed the request and response types to have a `Body` section. Huma returns a schema object in the response at the same level as `Body`. The `main` function no longer uses the router in the same way, but now uses Huma to declare routes.

Now run the server.

  ```sh
  docker run --rm  -p 65000:8080 -v $(pwd)/src:/app -w /app golang:1.23-alpine3.19 /bin/sh -c   "go build && ./helloworld"

  # In a new terminal:
  curl -X POST -H "Content-Type: application/json" -d '{"name":"John"}' http://localhost:65000/hello

  # Output
  # {"$schema":"http://localhost:65000/schemas/ResponseBodyBody.json","message":"Hello John"}
  ```

Browse to http://localhost:65000/docs#/operations/post-hello to see the generated schema in a Swagger-like viewer.

  ![Huma OpenAPI documentation](./assets/guide/huma.png)

## Using an OpenAPI meta-framework

The final option is to manually rewrite your server router in a meta-framework, and use that framework to generate a schema and new server code. For Go, this framework is called Goa. Speakeasy has an article demonstrating the process [here](/openapi/frameworks/goa).

In brief, the code you'll write is Go, but it is neither normal server code nor OpenAPI in YAML. It looks like the Go description of a schema below.

```go
var _ = Service("order", func() {
	Description("A waiter that brings drinks.")
	Method("tea", func() {
		Description("Order a cup of tea.")
		Payload(func() {
			Field(1, "isGreen", Boolean, "Whether to have green tea instead of normal.")
			Field(2, "numberSugars", Int, "Number of spoons of sugar.")
			Field(3, "includeMilk", Boolean, "Whether to have milk.")
		})
		Result(String)
		HTTP(func() {
			Meta("openapi:tag:Drink operations")
			POST("/tea")
		})
		GRPC(func() {
		})
	})
	Files("/openapi.json", "./gen/http/openapi.json")
})
```

Using an OpenAPI meta-framework to generate a schema is highly dependent on the programming language you use, as most languages don't have tools like Goa available (see the list of tools in the next section). A meta-framework is a great tool for maintaining server code separately from your schema (unlike using annotations), with the added advantage that it allows business analysts to understand and edit API contracts without needing to know a programming language in detail. It also makes the code to be maintained isolated and small, compared to annotating your entire server codebase.

The disadvantage of this approach is that you will be heavily dependent on the framework you choose, and that it's regularly maintained to fix bugs in generation and stay current with changes to OpenAPI. You will also be choosing a tool that's built on top of another tool. It might be easier for your team to stick with a popular web framework and simple OpenAPI annotations. Evaluate the framework you are considering and the quality of its outputs in a short test to decide if you like this approach.

## Tools available in each language

Now that you have seen the options you can choose from to generate an OpenAPI schema, you need to see if the tools you need are available for your language. In this final section, we list all the best tools we have found, ignoring repositories that haven't been updated in a year.

### C#, F#, and .NET

The .NET framework has two libraries you can use to generate OpenAPI schemas: [OpenAPI.NET](https://github.com/microsoft/openapi.net) and [NSwag](https://github.com/ricosuter/nswag).

Microsoft has official tutorials on both:

- [Generate OpenAPI documents with the `Microsoft.AspNetCore.OpenApi` package](https://learn.microsoft.com/en-us/aspnet/core/fundamentals/openapi/aspnetcore-openapi?view=aspnetcore-8.0&tabs=visual-studio%2Cminimal-apis)
- [Get started with NSwag and ASP.NET Core](https://learn.microsoft.com/en-us/aspnet/core/tutorials/getting-started-with-nswag?view=aspnetcore-8.0&tabs=visual-studio)

The `AspNetCore.OpenApi` package allows you to add attributes to your code. NSwag can generate client and server code, too.

### Go

[go-swagger3](https://github.com/parvez3019/go-swagger3) creates OpenAPI schemas for Go code based on text comments.

[Huma](https://huma.rocks) is a combination of annotations and an OpenAPI-aware framework that allows you to add attributes to your API to generate a schema and serve documentation for it.

[Fuego](https://go-fuego.github.io/fuego/docs/guides/openapi) is an OpenAPI-aware web framework. The [`swaggest/rest`](https://github.com/swaggest/rest) package, based on the Chi web framework, and [GoAPI](https://github.com/hvuhsg/goapi) offer similar functionality.

[Goa](https://goa.design/learn/getting-started) is a meta-framework that allows you to write an API design in Go code, which it then compiles into web server code and an OpenAPI schema.

[ogen](https://ogen.dev/docs/intro) generates data types and server and client code from an OpenAPI schema, but not an OpenAPI schema.

### JavaScript

JavaScript does not have static typing, but you can add type hints in text comments using [JSDoc](https://jsdoc.app/about-getting-started).

[swagger-jsdoc](https://github.com/Surnet/swagger-jsdoc) will convert your JSDoc annotations to an OpenAPI schema.

[hapi-swagger](https://github.com/hapi-swagger/hapi-swagger) adds OpenAPI features to the hapi web framework by using JSON descriptions of routes.

### TypeScript

[Tsoa](https://tsoa-community.github.io/docs/getting-started.html#configuring-tsoa-and-typescript) is similar to Goa — a meta-framework in TypeScript that will output server code and an OpenAPI schema.

[swagger-docs](https://github.com/AmishFaldu/swagger-docs/wiki/Getting-Started) creates an OpenAPI schema for you from TypeScript attributes.

### PHP

[OpenAPI PHP Attributes Generator](https://github.com/uderline/openapi-php-attributes) is a code-first tool that generates an OpenAPI schema from annotations.

[Swagger-PHP](https://zircote.github.io/swagger-php/) generates an OpenAPI schema from code attributes or comment annotations.

If you're using Laravel, you can use [Scramble](https://scramble.dedoc.co) to generate an OpenAPI schema without needing to add annotations. [Scribe](https://scribe.knuckles.wtf) is similar.

[API Platform](https://api-platform.com/), which works with Laravel and Symfony, provides OpenAPI features using your existing code, extended by attributes.

[PSX](https://phpsx.org/docs/intro) is an OpenAPI-aware web framework.

### Python

[drf-spectacular](https://drf-spectacular.readthedocs.io/en/latest/readme.html) automatically generates an OpenAPI schema from your Django code. You can add more information to your code with the `@extend_schema` attribute.

[FastAPI](https://fastapi.tiangolo.com) is an OpenAPI-aware web framework.

### Rust

[Poem](https://docs.rs/poem-openapi/latest/poem_openapi/) is the only Rust web framework that is OpenAPI-aware. Poem automatically generates an OpenAPI schema for you and serves it through the Swagger UI at your site `/docs`.

The three most popular web frameworks, axum, Actix Web, and Rocket, don't support OpenAPI yet, though they are working on it. For these, you should add OpenAPI attribute annotations with [utoipa](https://github.com/juhaku/utoipa). The Axum team has been working to elegantly integrate with utoipa. Take a look at an example [here](https://github.com/juhaku/utoipa/blob/master/examples/axum-utoipa-bindings/src/main.rs).

### Java

For frameworks that support the Jakarta RESTful Web Services specification (JAX-RS), formerly Java API for RESTful Web Services, you can use [Swagger Core](https://github.com/swagger-api/swagger-core/wiki/Swagger-2.X---Getting-started) to automatically generate an OpenAPI schema from code annotations.

[Swagger Parser](https://github.com/swagger-api/swagger-parser) will generate Java objects when given an OpenAPI schema. [guardrail](https://github.com/guardrail-dev/guardrail) will generate server code for you from your OpenAPI schema and supports Spring and Dropwizard. [openapi-processor](https://openapiprocessor.io/oap/home.html) will generate Java objects and server code interfaces in Spring or Micronaut, given an OpenAPI schema.

### Scala

If you're working in Scala, you can use the tools described in the Java section or the Scala-specific tools described below.

[endpoints4s](https://endpoints4s.github.io/quick-start.html) is a meta-framework that describes your API in code. You reference this code as a shared project in your client and server code, then implement the functions the API description specifies. endpoints4s will also generate an OpenAPI schema for you. Note that endpoints4s will not generate any code for you.

[SBT OpenApi Schema Codegen](https://github.com/eikek/sbt-openapi-schema) will generate the `/components/schema` types from your OpenAPI schema in Scala.

[Guardrail](https://github.com/guardrail-dev/guardrail) is a schema-first tool that will generate server code for you from your OpenAPI schema. It supports Akka, Dropwizard, and http4s.

### Kotlin

[Fabrikt](https://github.com/cjbooms/fabrikt) is a schema-first tool that generates data classes and interfaces for server and client code.


## The schema-first workflow

The alternative to a code-first approach is schema-first. If you treat your OpenAPI schema as your principal source after writing it or generating it from your code, and generate server code from it thereafter, then your code and schema will always be synchronized. While this approach is similar to the meta-framework approach, it provides a schema that's easier to read for non-programmers, though it may not be able to generate the framework's more specific features. A schema-first approach also allows you to add detailed text descriptions to help clients understand what your service endpoint does, which you may not be able to do in code.

Generating server code doesn't mean that you have to overwrite your existing code. You can use the generated code merely as an interface, or contract, to call your underlying code and check that all its requests and responses are of the expected types.

## Further reading

While there are a few tools listed above that do more than generate a schema from code, there are hundreds of OpenAPI tools and services available. Tools that validate code against schemas, create contracts, generate server code from a schema, and create and run tests. To see what's available, visit:

- https://tools.openapis.org/categories/all.html
- https://openapi.tools



 This is the content for the doc openapi/frameworks/django.mdx 

 ---
title: How to generate an OpenAPI/Swagger document with Django
description: "Generating an OpenAPI document with Django and using it to create SDKs with Speakeasy."
---

import { ScrollyCoding } from "~/components/codehike/Scrollycoding";
import { Callout } from "~/components";

# How to generate an OpenAPI document with Django and Django REST framework

OpenAPI is a tool for defining and sharing REST APIs, and Django can be paired with Django REST framework to build such APIs.

This guide walks you through generating an OpenAPI document from a Django project and using it to create SDKs with Speakeasy, covering the following steps:

1. Setting up a simple Django REST API with `djangorestframework`
2. Integrating `drf-spectacular`
3. Creating the OpenAPI document to describe the API
4. Customizing the OpenAPI schema
5. Using the Speakeasy CLI to create an SDK based on the schema
6. Integrating SDK creation into CI/CD workflows

## Requirements

This guide assumes you have a basic understanding of Django project structure and how REST APIs work.

You will also need the following installed on your machine:

- Python version 3.8 or higher
- Django

  You can install Django using the following command:

  ```bash Terminal
  pip install django
  ```

- Django REST Framework

  You can install Django REST Framework using the following command:

  ```bash Terminal
  pip install djangorestframework
  ```

## Example Django REST API repository

<Callout title="Example repository" variant="info">
The source code for the completed example is available in the [**Speakeasy Django example repository**](https://github.com/speakeasy-api/django-openapi-example).
</Callout>

The example repository contains all the code covered in this guide. You can clone it and follow along with the tutorial or use it as a reference to add to your own Django project.

---

## Creating the OpenAPI document to describe an API

To better understand the process of generating an OpenAPI document with Django, let's start by inspecting some simple CRUD endpoints for an online library, along with a `Book` class and a serializer for the data.

### Models, serializers, and views

<ScrollyCoding fullHeight>

## !!steps

Find the `books/models.py` file in the root of the repository. Open the file to see a `Book` model containing a few fields with validation:

```python ! models.py focus=1:8
!from ./assets/django/models.py.txt
```


---

## !!steps

In the `books/serializers.py` file, there is a `BookSerializer` class that you can use to serialize and deserialize your Book data:

```python !! serializers.py focus=1:10
!from ./assets/django/serializers.py.txt
```


---

## !!steps

The `books/views.py` file contains a `BookViewSet` class that uses Django REST Framework's `ModelViewSet` to handle all of the CRUD operations for the `Book` model:

```python ! views.py focus=1:94
!from ./assets/django/views.py.txt
```

This code defines a simple Django REST API with CRUD operations for a `Book` model. The `BookViewSet` class provides a way to interact with the `Book` model through the API.
It also contains a custom action called `author_books` that retrieves all books by the same author.


---

## !!steps

The `books/urls.py` file contains a router that maps the `BookViewSet` to the `/books` endpoint:

```python !! urls.py
!from ./assets/django/urls.py.txt
```


---

## !!steps

In the `books_project/urls.py` file, the router is included in the main Django URL configuration:

```python ! project_urls.py
!from ./assets/django/project_urls.py.txt
```


</ScrollyCoding>



## Integrate `drf-spectacular`

Django no longer supports the built-in OpenAPI document generation, so we'll use the `drf-spectacular` package to generate the OpenAPI document.

Run the following to install `drf-spectacular`:

```bash Terminal
pip install drf-spectacular
```

<ScrollyCoding fullHeight>

## !!steps

Open the `books_project/settings.py` file. You should see `'drf_spectacular'` in the `INSTALLED_APPS` list:

```python !! settings.py focus=11:21 mark=20
!from ./assets/django/settings.py.txt
```

Adding this package to the `INSTALLED_APPS` list enables OpenAPI document generation for your Django project.


---

## !!steps

The `books_project/settings.py` file also contains the `REST_FRAMEWORK` configuration object, which sets the schema class used to create the OpenAPI document:

```python !! settings.py focus=87:89
!from ./assets/django/settings.py.txt
```


---

## !!steps

Notice `SPECTACULAR_SETTINGS`, which contains additional settings for OpenAPI document generation. You can customize these settings to fit your project:

```python !! settings.py focus=91:117
!from ./assets/django/settings.py.txt
```


---

## !!steps

In the `books_project/urls.py` file, the new OpenAPI schema and Swagger UI endpoints are added alongside the `api/` endpoint:

```python ! project_urls.py mark=7:9
!from ./assets/django/project_urls.py.txt
```


</ScrollyCoding>


### Apply migrations and run the server

To inspect and interact with the OpenAPI document, you need to apply database migrations and run the development server.

Apply database migrations:

```bash Terminal
python manage.py makemigrations
python manage.py migrate
```

Run the development server:

```bash Terminal
python manage.py runserver
```

You can now access the API and documentation:

* Visit `http://127.0.0.1:8000/api/books/` to interact with the book API.
* Visit `http://127.0.0.1:8000/swagger/` for Swagger documentation.

### OpenAPI document generation

Now that we understand our Django REST API, we can generate the OpenAPI document using `drf-spectacular` with the following command:

```bash Terminal
python manage.py spectacular --file openapi.yaml
```

<ScrollyCoding fullHeight>

## !!steps

This command will generate an OpenAPI document in the `openapi.yaml` file.

```yaml ! openapi.yaml focus=1:170
!from ./assets/django/openapi.yaml.txt
```


---

## !!steps

Return to the `books_project/settings.py` file to see how the values in `SPECTACULAR_SETTINGS` influence the OpenAPI document generation:

```python !! settings.py focus=91:103
!from ./assets/django/settings.py.txt
```


---

## !!steps

Notice that the title, description, and versions are reflected in the generated OpenAPI document:

```yaml ! openapi.yaml focus=1:15
!from ./assets/django/openapi.yaml.txt
```


---

## !!steps

The server URL is also included in the OpenAPI document:

```yaml ! openapi.yaml focus=280:282
!from ./assets/django/openapi.yaml.txt
```


---

## !!steps

Open the `books/models.py` file to see the `Book` parameters:

```python !! models.py focus=4:6
!from ./assets/django/models.py.txt
```


---

## !!steps

These same `Book` parameters are reflected in the OpenAPI document:

```yaml ! openapi.yaml focus=236:256
!from ./assets/django/openapi.yaml.txt
```

</ScrollyCoding>


## OpenAPI document customization

The OpenAPI document generated by `drf-spectacular` may not be detailed enough for all use cases. Fortunately, it can be customized to better serve information about your API endpoints. You can add descriptions, tags, examples, and more to make the documentation more informative and user-friendly.

In the [customized](https://github.com/speakeasy-api/django-openapi-example/tree/customized) branch of the example repository, you can find a customized OpenAPI document that demonstrates the available options for modifying your generated document.

The `drf-spectacular` package provides decorators to directly modify the schema for your views and viewsets.

- `@extend_schema_view`: Allows customization of all methods in a viewset.
- `@extend_schema`: Allows customization of individual methods or actions.

<ScrollyCoding fullHeight>

## !!steps

As an example of how you can customize the schema of the `BookViewSet`, open the `books/views.py` file and update it with the following code:

```python ! views.py
!from ./assets/django/custom_views.py.txt
```


---

## !!steps

You can extend or override the document generation for specific views or viewsets using the `@extend_schema_view` decorator:

```python ! views.py focus=9:26
!from ./assets/django/custom_views.py.txt
```

---

## !!steps

This results in the following additions, for example, to the `/api/books/` `get` operation in the document:

```yaml !! openapi.yaml focus=17:36
!from ./assets/django/openapi.yaml.txt
```


---

## !!steps

Then, you can use the `@extend_schema` decorator to customize individual actions:

```python ! views.py focus=36:70
!from ./assets/django/custom_views.py.txt
```


---

## !!steps

This results in the following additions to the `get` operation for `author_books` in the document:

```yaml !! openapi.yaml focus=178:234
!from ./assets/django/openapi.yaml.txt
```


---

## !!steps

You can make the OpenAPI documentation more readable and organized by specifying tags and descriptions for your viewset methods:

```python ! views.py focus=36:53 mark=38,53
!from ./assets/django/custom_views.py.txt
```


---

## !!steps

This adds a list of tags to the viewset methods in the OpenAPI document:

```yaml !! openapi.yaml focus=201:203
!from ./assets/django/openapi.yaml.txt
```


---

## !!steps

You can customize query parameters for your API endpoint. For example, you can add filtering or sorting options:

```python ! views.py focus=54:57
!from ./assets/django/custom_views.py.txt
```


---

## !!steps

These options then reflect as follows:

```yaml !! openapi.yaml focus=184:200 mark=186,197
!from ./assets/django/openapi.yaml.txt
```


---

## !!steps

You can add examples, such as an example of a book object, to assist anyone using your API:

```python ! views.py focus=58:69
!from ./assets/django/custom_views.py.txt
```


---

## !!steps

The document is then updated with the examples:

```yaml !! openapi.yaml focus=216:223
!from ./assets/django/openapi.yaml.txt
```


---

## !!steps

You can add global retries to the OpenAPI document by modifying `SPECTACULAR_SETTINGS` in the `books_project/settings.py` file:

```python ! settings.py focus=104:116
!from ./assets/django/settings.py.txt
```


---

## !!steps

It is also possible to apply the retries setting to specific views or viewsets using the `@extend_schema` decorator:

```python !! views.py focus=40:52
!from ./assets/django/custom_views.py.txt
```


</ScrollyCoding>

In summary, the `drf-spectacular` package provides a variety of ways to customize the OpenAPI document for your Django REST API. You can use decorators, tags, descriptions, parameters, fields, examples, and global settings to modify the document according to your requirements.

- **Decorators (@extend_schema and @extend_schema_view):** Customize individual methods or entire views.
- **Tags and descriptions:** Organize endpoints for better readability.
- **Parameters:** Define custom parameters using `OpenApiParameter`.
- **OpenAPI components:** Use `OpenApiExample` to provide reusable components or examples.
- **Global settings (`SPECTACULAR_SETTINGS`):** Modify the global behavior of `drf-spectacular`.

For more information about customizing the OpenAPI schema with `drf-spectacular`, refer to the official [`drf-spectacular` documentation](https://drf-spectacular.readthedocs.io/en/latest/).



## Creating SDKs for a Django REST API

To create a Python SDK for the Django REST API, run the following command:

```bash Terminal
speakeasy quickstart
```

Follow the onscreen prompts to provide the configuration details for your new SDK, such as the name, schema location, and output path. When prompted, enter `openapi.yaml` for the OpenAPI document location, select a language, and generate.

## Add SDK generation to your GitHub Actions

The Speakeasy [`sdk-generation-action`](https://github.com/speakeasy-api/sdk-generation-action) repository provides workflows for integrating the Speakeasy CLI into your CI/CD pipeline, so that your SDKs are recreated whenever your OpenAPI document changes.

You can set up Speakeasy to automatically push a new branch to your SDK repositories for your engineers to review before merging the SDK changes.

For an overview of how to set up automation for your SDKs, see the Speakeasy [SDK Generation Action and Workflows](/docs/speakeasy-reference/workflow-file) documentation.

## SDK customization

Explore the effects of your newly generated OpenAPI document on the SDK created by Speakeasy.

After creating your SDK with Speakeasy, you will find a new directory containing the generated SDK code. Let's explore this code a bit further.

These examples assume a Python SDK named `books-python` was generated from the example Django project above. Edit any paths to reflect your environment if you want to follow in your own project.

<ScrollyCoding fullHeight>

## !!steps

Navigate into the `books-python/src/books` directory and open the `book.py` file created by Speakeasy. Note how the OpenAPI document was used to create the `Book` class:

```python ! book.py
!from ./assets/django/book.py.txt
```


---

## !!steps

Open the `api.py` file to see the methods that call the web API from an application using the SDK:

```python !! api.py mark=12
!from ./assets/django/api.py.txt
```


---

## !!steps

Notice the `server_url` parameter in the `api.py` file, which was configured in the `SERVERS` key under `SPECTACULAR_SETTINGS` in the `settings.py` file:

```python !! api.py focus=12:21 mark=19
!from ./assets/django/api.py.txt
```


---

## !!steps

And the `retries` parameter:

```python !! api.py focus=12:21 mark=18
!from ./assets/django/api.py.txt
```


---

## !!steps

This is all used to build the request to the API endpoint:

```python !! api.py focus=35:50
!from ./assets/django/api.py.txt
```


---

## !!steps

Finally, you should get the result of the global retries strategy set up in `SPECTACULAR_SETTINGS` in the `settings.py` file:

```python ! retries.py focus=11:27
!from ./assets/django/retries.py.txt
```


---

## !!steps

You can also find a method implementing the retries strategy:

```python ! retries.py focus=66:112
!from ./assets/django/retries.py.txt
```


</ScrollyCoding>


## Summary

In this guide, we showed you how to generate an OpenAPI document for a Django API and use Speakeasy to create an SDK based on the OpenAPI document. The step-by-step instructions included adding relevant tools to the Django project, generating an OpenAPI document, enhancing it for improved creation, using Speakeasy OpenAPI extensions, and interpreting the basics of the generated SDK.

We also explored automating SDK generation through CI/CD workflows and improving API operations.


 This is the content for the doc openapi/frameworks/elysia.mdx 

 ---
title: How to generate an OpenAPI document with ElysiaJS
description: "Learn how to generate an OpenAPI document for your ElysiaJS API and use it to automatically generate and customize SDKs."
---

import { Callout } from "~/components";

# How to generate an OpenAPI document with ElysiaJS

This guide walks you through generating an OpenAPI document for an [ElysiaJS](https://elysiajs.com/) API and using Speakeasy to create an SDK based on the generated document.

Here's what we'll do:

1. Add a Swagger endpoint, which uses Scalar UI, to an Elysia Bun app using the Elysia Swagger plugin.
3. Improve the OpenAPI document to prepare it for code generation.
4. Convert the JSON OpenAPI document to YAML.
5. Use the Speakeasy CLI to generate an SDK based on the OpenAPI document.
6. Add a Speakeasy OpenAPI extension to improve the generated SDK.

We'll also take a look at how you can use the generated SDK.

Your Elysia project might not be as simple as our example app, but the steps below should translate well to any Elysia project.

## The OpenAPI generation pipeline

The Elysia [Swagger plugin](https://github.com/elysiajs/elysia-swagger) generates a Swagger API documentation endpoint. By default, Elysia uses the OpenAPI Specification and [Scalar UI](https://scalar.com/), an open-source interactive document UI for OpenAPI.

We'll first add the Swagger plugin to an existing Elysia app.

Then, we'll improve the plugin-generated OpenAPI document according to Speakeasy [best practices](https://www.speakeasy.com/docs/best-practices). The quality of an OpenAPI document determines the quality of the SDKs and documentation it's used to create.

Next, we'll use Speakeasy to generate an SDK based on the OpenAPI document. 

Finally, we'll use a simplified example to demonstrate how to use the generated SDK and how to add SDK creation to a CI/CD pipeline so that Speakeasy automatically generates fresh SDKs whenever your Elysia API changes in the future.

## Requirements

This guide assumes that you have an existing Elysia app and basic familiarity with Elysia.

<Callout title="Example repository" variant="info">
If you don't have an Elysia app or if you want to follow the guide step by step, you can clone the [Speakeasy ElysiaJS example repo](https://github.com/speakeasy-api/elysia-openapi-example) to access the example code used in this tutorial. The `initial-app` branch contains the initial state of the app that we'll use to start this tutorial.
</Callout>

The following should be installed on your machine:

- [Bun](https://bun.sh/): The Node.js alternative that Elysia is built on.
- [Speakeasy CLI](https://www.speakeasy.com/docs/speakeasy-cli/getting-started): The tool you'll use to generate an SDK from the OpenAPI document.

## Adding the Swagger plugin to an Elysia project

The Elysia Swagger plugin automatically generates an API documentation page for your server.

First, install the Swagger plugin:

```bash Terminal
bun add @elysiajs/swagger
```

Import the plugin, then register it by passing in an instance of `swagger` to the `use()` method and chaining the `use()` method to the `Elysia` instance:

```typescript index.ts
import { Elysia } from 'elysia'
import { users } from './controllers/users';
// !mark
import { swagger } from '@elysiajs/swagger'

const app = new Elysia()
  .onError(({ error, code }) => {
    console.log({code})
    if (code === 'NOT_FOUND') return 'Not Found :('
    if (code === 'VALIDATION') return 'Invalid user'
    console.error(error);
  })
  .use(users)
  // !mark
  .use(swagger())
  .listen(3000)
```

In Elysia, a [plugin](https://elysiajs.com/essential/plugin) is a reusable component. In fact, everything in Elysia is a component, including Elysia instances, plugins, routers, stores, and more. Components split apps into small pieces, making it easier to add, remove, or modify app features. It's important that we use [method chaining](https://elysiajs.com/key-concept.html#method-chaining) for type inference in our Elysia code. In the above code block, we use the `onError` lifecycle method to catch any error that's thrown on the server. 

Run the Bun development server with `bun run dev` and open `http://localhost:3000/swagger` to see the Scalar UI with five API endpoints:

![Scalar UI](./assets/elysia/scalar.png)

The API routes are listed in the navigation pane on the left. Click  **`/users/` GET** to navigate to the section for the `/users/` GET request API endpoint:

![GET request API endpoint](./assets/elysia/scalar-get.png)

Each section shows information about an API endpoint, such as its path parameters, body, and responses.

The code block on the right shows an example curl request. Click the **Shell cURL** dropdown menu to change the language or library used in the example request:

![Change example request dropdown menu](./assets/elysia/scalar-change-example-request.png)

Click the **Test Request** button to open an API client that lets you test your API endpoints. Then, click **Send** to test the request:

![Scalar API client](./assets/elysia/scalar-api-client.png)

In the response, you should get an array containing one user. 

The user data in the Elysia server is stored temporarily in a singleton `Users` class :

```typescript users.ts
class Users {
  constructor(
    public data: UserInfo[] = [
      {
        id: "1",
        name: "Alice",
        age: 20
      }
    ]
) {}
```

This class is added to the `Elysia` instance using the 
[`decorate`](https://elysiajs.com/essential/handler.html#decorate) method:

```typescript users.ts mark=2
export const users = new Elysia({ prefix: '/users' })
  .decorate('users', new Users())
```

This adds the `Users` class to the [context](https://elysiajs.com/essential/handler.html#context) that contains information for each request. You can access the context in route handlers.

## Viewing the OpenAPI document and modifying its root object

Open `http://localhost:3000/swagger/json` to view the OpenAPI document in JSON format:

```json
{
  "openapi": "3.0.3",
  "info": {
    "title": "Elysia Documentation",
    "description": "Development documentation",
    "version": "0.0.0"
  },
  "paths": {
    "/users/": {
      "get": {
        "operationId": "getUsers",
        "responses": {
          "200": {
            
          }
        }
      },
      "post": {
     // ...
```

Add the following TypeScript configuration option to your `tsconfig.json` file to enable JSON file imports:

```json tsconfig.json
 "resolveJsonModule": true,
```

Add the following configuration object to the `swagger` plugin:

```typescript index.ts
import { Elysia } from 'elysia';
import { users } from './controllers/users';
import { swagger } from '@elysiajs/swagger';
// !mark
import packageJson from '../package.json';

const app = new Elysia()
  .onError(({ error, code }) => {
    if (code === 'NOT_FOUND') return 'Not Found :(';
    if (code === 'VALIDATION') return 'Invalid user';
    console.error(error);
  })
  .use(users)
  .use(
    // !mark(2:12)
    swagger({
      documentation: {
        info: {
          title: 'Users app documentation',
          version: packageJson.version,
        },
        externalDocs: {
          description: 'Find out more about the Users API',
          url: 'www.example.com',
        },
      }
    })
  )
  .listen(3000)
```

This configures the [root document object](https://swagger.io/specification/v3/#openapi-object) of the OpenAPI document.

The `info` object is a required property used to add metadata about the API. The `externalDocs` object lets you extend your documentation by referencing an external resource.

Note that the API operation for each path has an `operationId` value that's named by combining the HTTP request type and the name of the path. The value can be modified using the [`detail`](https://elysiajs.com/recipe/openapi.html#operationid) field in a route; however, we won't modify it in this guide, as Elysia produces consistently named, human-readable `operationId` values.

The `operationId` is the identifier for an operation. It is case sensitive and must be unique within the document. The Speakeasy SDK, which we'll use later in this guide, uses it during code generation to name the method it generates for the operation.

## OpenAPI Specification versions supported by Elysia and Speakeasy

Speakeasy currently supports the OpenAPI Specification versions 3.0.x and 3.1.x and recommends you use version 3.1, as it's fully compatible with [JSON Schema](https://json-schema.org/), which gives you access to a large ecosystem of tools and libraries.

However, we use OpenAPI Specification version 3.0.3 in this guide, as it is the version Elysia supports.

To check which version you are using, open `http://localhost:3000/swagger/json` and see the OpenAPI Specification version in the root document object.

## Adding example data to a data model and the POST request body

The API routes in the Scalar UI don't have example values for the path parameters, requests, or responses. The `user` model doesn't have example values either. It's important to add examples to make your API more user-friendly.

Let's start by adding example values to the `userInfo` model:

```typescript users.ts
const userInfo = t.Object({
  id: t.String({
    example: '1'
  }),
  name: t.String({
    example: 'Alice'
  }),
  age: t.Number({
    example: 20
  })
}, {
  title: 'User',
  description: 'User object',
  example: 
    {
      id: "1",
      name: "Alice",
      age: 20
    }
});
```

The Elysia schema builder, `t`, gives compile-time and runtime type safety. It also registers the model as a reusable OpenAPI [Components Object](https://swagger.io/specification/v3/#components-object) schema, which you can see at the bottom of your OpenAPI document:

```json
"components": {
  "schemas": {
    "user": {
      "example": {
        "id": "1",
        "name": "Alice",
        "age": 20
      },
      "type": "object",
      "properties": {
        "id": {
          "example": "1",
          "type": "string"
        },
        "name": {
          "example": "Alice",
          "type": "string"
        },
        "age": {
          "example": 20,
          "type": "number"
        }
      },
      "required": [
        "id",
        "name",
        "age"
      ]
    }
  }
}
```

You'll also see the example values in the **`user`** model in the Scalar UI:

![Example values in user model](./assets/elysia/scalar-user-model-examples.png)

The `userInfo` schema is used in the `post()` and `patch()` routes. Elysia HTTP request methods accept three arguments: the path, the function used to respond to the client, and the hook used to define extra metadata. Add an example to the `body` in the hook object of the `post()` route:

```typescript users.ts mark=4:9
body: 
  t.Omit(
    userInfo, ['id'], 
    {
      example: {
        name: "Alice",
        age: 20
      }
    }
  ),
```

If you look at your OpenAPI document now, you'll see that the `content` of the POST request body has three possible types: `application/json`, `multipart/form-data`, or `text/plain`. To limit it to `application/json`, set the `type` in the hook object of the `post()` route:

```typescript users.ts mark=14
.post('/',({ users, body: user }) =>
  users.add(user),
  {
    body: 
      t.Omit(
        userInfo, ['id'], 
        {
          example: {
            name: "Alice",
            age: 20
          }
        }
      ),
    type: 'json',
```

## Adding extra information to a route using the detail field

The [`detail`](https://elysiajs.com/recipe/openapi.html#detail) field is used to define a route for the OpenAPI document. It extends the [OpenAPI Operation Object](https://swagger.io/specification#operation-object), which describes an API operation within a path.

Add the following `detail` field to the hook object of the `post()` route:

```typescript users.ts  mark=2:5
type: 'json',
detail: { 
  summary: 'Create user', 
  description: 'Add user to the database',
},
```

Add the following `responses` property to the `detail` object:

```typescript users.ts
responses: {
  200: {
    description: 'The created users assigned id',
    content: {
      'application/json': {
        schema: {
          $ref: '#/components/schemas/id',
        },     
        examples: {
          "Created user": {
            value: {
              id: "1",
              name:  "Alice",
              age: 20
            }
          }
        }
      }
    },
  },
},
```

The [Responses Object](https://swagger.io/specification/#responses-object) is used to list the possible responses returned from the POST request. There is one possible response listed - a successful response. This response has a [`schema`](https://swagger.io/specification/#schema-object) that defines the content of the response. The `id` schema is referenced using [`$ref`](https://swagger.io/specification/#reference-object), the reference identifier that specifies the URI location of the value being referenced. Let's define this `id` model.

Add the following `idObject` model to the `users.ts` file, below the `userInfo` model:

```typescript users.ts
const idObject = t.Object({
  id: t.String({
    example: '1'
  })
}, {
  title: 'ID object',
  description: 'ID object',
  example: 
    {
      id: "1"
    }
});
```

Create a [reference model](https://elysiajs.com/tutorial.html#reference-model) for the model:

```typescript users.ts mark=5
export const users = new Elysia({ prefix: '/users' })
  .decorate('users', new Users())
  .model({
    user: userInfo,
    id: idObject,
  })
```

A reference model lets us reuse a model by referencing its name.

It's also good practice to add possible error responses. Add the following `500` response to the `responses` property:

```typescript users.ts
500: {
  description: 'Server error',
  content: {
    'application/json': {
      schema: {
        $ref: '#/components/schemas/errorResponse'
      },
      examples: {
        "Server error": {
          value: {
            message: 'There was an error',
            status: 500
          }
        }
      }
    }
  }
}
```

Add the definition for the `errorResponse` model below the `idObject` model:

```typescript users.ts
const errorResponse = t.Object({
  status: t.Number({
    example: 404
  }),
  message: t.String({
    example: 'User not found :('
  })
}, {
  title: 'Error response',
  description: 'Error response object',
  example: 
    {
      status: 404,
      message: 'User not found :('
    }
});
```

Create a reference model for the `errorResponse` model:

```typescript users.ts mark=6
export const users = new Elysia({ prefix: '/users' })
  .decorate('users', new Users())
  .model({
    user: userInfo,
    id: idObject,
    errorResponse: errorResponse,
  })
```

You'll now see example responses for the **Create user** POST route in Scalar:

![Example POST request responses](./assets/elysia/scalar-example-responses.png)

## Adding OpenAPI tags to routes

We recommend adding tags to all your Elysia routes. This allows you to group the routes according to tag in the generated SDK code and documentation.

### Adding OpenAPI tags to routes in Elysia

To add OpenAPI tags to a route, use the `tags` property to pass in an array of tags in the hook object of the `post()` route:

```typescript users.ts
tags: ['Users']
```
 
### Adding tags to the root OpenAPI document object and adding metadata to tags

Add the following `tags` array to the configuration object of the `swagger` plugin:

```typescript index.ts mark=13:20
  .use(
    swagger(
      {
      documentation: {
        info: {
          title: 'Users app documentation',
          version: packageJson.version,
        },
        externalDocs: {
          description: 'Find out more about the Users API',
          url: 'www.example.com',
        },
        tags: [{
          name: 'Users',
          description: 'Users operations',
          externalDocs: {
            description: 'Find more info here',
            url: 'https://example.com',
          },
        }],
      }
    })
  )
```

This adds a `tags` array to the root OpenAPI document object. In the above code, we add metadata to the tag by passing in a [Tag Object](https://swagger.io/specification/#tag-object) (instead of a string) to the tag array item.

After adding tags to your routes, you'll see that they are organized by tags in Scalar:

![Routes grouped by tag](./assets/elysia/scalar-grouping-by-tag.png)

## Adding example data, extra information, and tags to the other API routes

Let's improve the other API route operations like we improved the **Create user** route.

Replace the **Get all users** route with the following lines of code:

```typescript users.ts mark=2:58
.get('/', ({ users }) => users.data, 
  {
    detail: { 
      summary: 'Get all users', 
      description: 'Get all users from the database',
      responses: {
        200: {
          description: 'The array of users',
          content: {
            'application/json': {
              schema: {
                type: 'array',
                items: {
                  $ref: '#/components/schemas/user'
                },
              },    
              examples: {
                basic: {
                  value: [
                    {
                      id: "1",
                      name: "Alice",
                      age: 20
                    },
                    {
                      id: "2",
                      name: "Bob",
                      age: 25
                    }
                  ]
                }
              }    
            }
          },
        },
        500: {
          description: 'Server error',
          content: {
            'application/json': {
              schema: {
                $ref: '#/components/schemas/errorResponse'
              },
              examples: {
                "Server error": {
                  value: {
                    message: 'There was an error',
                    status: 500
                  }
                }
              }
            }
          }
        }
      },
      tags: ['Users'] 
    },
  }
)
```

Replace the **Get user** route with the following lines of code:

```typescript users.ts mark=5:53
.get('/:id',({ users, params: { id }, error }) => {
    return users.data.find(user => user.id === id) ?? error(404, 'User not found :(')
  },
  {
    params: 'id',
    detail: { 
      summary: 'Get user', 
      description: 'Get user by id from the database',
      responses: {
        200: {
          description: 'The user object',
          content: {
            'application/json': {
              schema: {
                $ref: '#/components/schemas/user',
              },     
              examples: {
                basic: {
                  value: 
                    {
                      id: "1",
                      name: "Alice",
                      age: 20
                    }
                }
              }   
            }
          },
        },
        404: {
          description: 'User not found',
          content: {
            'application/json': {
              schema: {
                $ref: '#/components/schemas/errorResponse'
              },
              examples: {
                "User not found": {
                  value: {
                    message: 'User not found :(',
                    status: 404
                  }
                }
              }
            }
          }
        }
      },
      tags: ['Users'] 
    },
  },
)
```

Replace the **Delete user** route with the following lines of code:

```typescript users.ts mark=5:49
.delete('/:id', ({ users, params: { id }, error }) => {
    return users.remove(id) ?? error(422, 'Invalid user')
  },
  {
    params: 'id',
    detail: { 
      summary: 'Delete user', 
      description: 'Delete user by id from the database',
      responses: {
        200: {
          description: 'Deleting user was successful',
          content: {
            'application/json': {
              schema: {
                $ref: '#/components/schemas/successResponse'
              },       
              examples: {
                success: {
                  value: {
                    success: true
                  }
                }
              }    
            }
          },
        },
        422: {
          description: 'Invalid user',
          content: {
            'application/json': {
              schema: {
                $ref: '#/components/schemas/errorResponse'
              },
              examples: {
                "Invalid user": {
                  value: {
                    message: 'Invalid user',
                    status: 422
                  }
                }
              }
            }
          }
        }
      },
      tags: ['Users'] 
    },
  }   
) 
```

Add the definition for the `successResponse` model below the `errorResponse` model:

```typescript users.ts
const successResponse = t.Object({
  success: t.Boolean({
    example: true
  })
}, {
  title: 'Success response',
  description: 'Success response object',
  example: 
    {
      success: true
    }
});
```

Create a reference model for the `successResponse` model:

```typescript users.ts mark=7
export const users = new Elysia({ prefix: '/users' })
  .decorate('users', new Users())
  .model({
    user: userInfo,
    id: idObject,
    errorResponse: errorResponse,
    successResponse: successResponse
  })
```

Replace the **Update user** route with the following lines of code:

```typescript users.ts mark=7:63
.patch(
  '/:id',({ users, params: { id }, body: user, error }) => {
    return users.update(id, user) ?? error(422, 'Invalid user')
  },
  {
    params: 'id',
    body: 
      t.Partial(
        t.Omit(
          userInfo, ['id'], 
          {
            example: {
              age: 21
            }
          }
        ),
      ),
    type: 'json',
    detail: { 
      summary: 'Update user', 
      description: 'Update user by id from the database',
      responses: {
        200: {
          description: 'Update was successful',
          content: {
            'application/json': {
              schema: {
                $ref: '#/components/schemas/successResponse'
              },       
              examples: {
                Success: {
                  value: {
                    success: true
                  }
                }
              }  
            }
          },
        },
        422: {
          description: 'Invalid user',
          content: {
            'application/json': {
              schema: {
                $ref: '#/components/schemas/errorResponse'
              },
              examples: {
                "Invalid user": {
                  value: {
                    message: 'Invalid user',
                    status: 422
                  }
                }
              }
            }
          }
        }
      },
      tags: ['Users'] 
    },
  }
)
```

## Adding a list of servers to the Elysia OpenAPI document

When validating an OpenAPI document, [Speakeasy expects a list of servers](https://www.speakeasy.com/docs/best-practices#openapi-best-practices) at the root of the document.

Add a server by adding a `servers` property to the configuration object of the `swagger` plugin:

```typescript index.ts mark=13:18
.use(
  swagger(
    {
    documentation: {
      info: {
        title: 'Users app documentation',
        version: packageJson.version,
      },
      externalDocs: {
        description: 'Find out more about the Users API',
        url: 'www.example.com',
      },
      servers: [
        {
          url: 'http://localhost:3000/',
          description: 'Development server',
        },
      ],
```

You can add multiple `servers` to define different environments or versions. This is useful for separating production and testing environments.

## Adding retries to your SDK with `x-speakeasy-retries`

[OpenAPI document extensions](https://www.speakeasy.com/openapi/extensions) allow us to add vendor-specific functionality to an OpenAPI document.

- Extension fields must be prefixed with `x-`.
- Speakeasy uses extensions that start with `x-speakeasy-`.

Speakeasy gives you fine-tuned control over the Speakeasy SDK via its [range of Speakeasy extensions](https://www.speakeasy.com/docs/speakeasy-extensions), which you can use to modify retries, pagination, error handling, and other advanced SDK features.

Let's add a Speakeasy extension that adds retries to requests from Speakeasy SDKs by adding a top-level `x-speakeasy-retries` schema to the OpenAPI document. We can also override the retry strategy per operation.

### Adding global retries

Apply the Speakeasy retries extension globally by adding the following `'x-speakeasy-retries'` property to the configuration object of the `swagger` plugin:

```typescript users.ts mark=7:17
servers: [
  {
    url: 'http://localhost:3000/',
    description: 'Development server',
  },
],
'x-speakeasy-retries': {
  strategy: 'backoff',
  backoff: {
    initialInterval: 500,
    maxInterval: 60000,
    maxElapsedTime: 3600000,
    exponent: 1.5,
  },
  statusCodes: ['5XX'],
  retryConnectionErrors: true,
},
```

### Adding retries per method

You can create a unique retry strategy for a single route by adding a `'x-speakeasy-retries'` property to the route's hook object:

```typescript users.ts mark=1:11
      'x-speakeasy-retries': {
        strategy: 'backoff',
        backoff: {
          initialInterval: 300,
          maxInterval: 40000,
          maxElapsedTime: 3000000,
          exponent: 1.2,
        },
        statusCodes: ['5XX'],
        retryConnectionErrors: true,
      },
      tags: ['Users']
    },
  }
)
.delete('/:id', ({ users, params: { id }, error }) => {
```

## Creating an SDK based on your OpenAPI document

Before creating an SDK, we need to save the Elysia Swagger plugin-generated OpenAPI document to a file. OpenAPI files are written as JSON or YAML; we'll save it as a YAML file, as it's easier to read.

### Saving the OpenAPI document to a YAML file using a Bun script

Let's create a script that uses the [JS-YAML](https://github.com/nodeca/js-yaml) library to convert the JSON OpenAPI document to a YAML string.

Install the library and its types:

```bash Terminal
bun add js-yaml @types/js-yaml
```

Create a script called `generateOpenAPIYamlFile.ts` in the `src` folder and add the following lines of code to it:

```typescript generateOpenAPIYamlFile.ts
import * as yaml from 'js-yaml';

async function generateOpenAPIYaml() {
  try {
    const response = await fetch('http://localhost:3000/swagger/json');
    const openAPIObject = await response.json();

    // Convert to YAML
    const yamlString = yaml.dump(openAPIObject);

    // Save the YAML string to a file
    await Bun.write('openapi.yaml', yamlString);
    
    console.log('OpenAPI document saved to openapi.yaml');
  } catch (error) {
    console.error('Error generating OpenAPI document:', error);
  }
}

generateOpenAPIYaml();
```

This script fetches the JSON OpenAPI document from the Scalar OpenAPI document endpoint, converts it to a YAML string, and then saves it as a file.

Add the following script to your `package.json` file:

```bash Terminal
"generate:openapi": "bun run src/generateOpenAPIYamlFile.ts"
```

Run the development server and then run the `generate:openapi` script using the following command:

```bash Terminal
bun run generate:openapi
```

This generates an `openapi.yaml` file in your root folder.

### Linting the OpenAPI document with Speakeasy

The Speakeasy CLI has an OpenAPI [linting](https://www.speakeasy.com/docs/linting) command that checks the OpenAPI document for errors and style issues.

Run the linting command:

```bash Terminal
speakeasy lint openapi --schema ./openapi.yaml
```

A lint report will be displayed in the terminal, showing errors, warnings, and hints:

![Speakeasy lint report](./assets/elysia/speakeasy-lint-report.png)

The Speakeasy linter uses the [`speakeasy-recommended`](https://www.speakeasy.com/docs/linting/linting#speakeasy-recommended) ruleset by default, but you can [configure](https://www.speakeasy.com/docs/linting#configuration) a custom ruleset.

Speakeasy also has a [VS Code extension](https://marketplace.visualstudio.com/items?itemName=Speakeasy.speakeasy-vscode-extension), which you can use to help you validate your OpenAPI documents for the creation of production-grade SDKs.

### Creating an SDK from the Speakeasy CLI

We'll use the [`quickstart`](https://www.speakeasy.com/docs/speakeasy-cli/quickstart) command for a guided SDK setup.

Run the command using the Speakeasy CLI:

```bash Terminal
speakeasy quickstart
```

Following the prompts, provide the OpenAPI document location, name the SDK `SDK`, and select `TypeScript` as the SDK language.

In the terminal, you'll see the steps taken by Speakeasy to generate the SDK.

```bash Terminal
│ Workflow - success
│ └─Target: sdk - success
│   └─Source: SDK -OAS - success
│     └─Validating Document - success
│     └─Diagnosing OpenAPI - success
│     └─Tracking OpenAPI Changes - success
│       └─Snapshotting OpenAPI Revision - success
│       └─Storing OpenAPI Revision - success
│   └─Validating gen.yaml - success
│   └─Generating Typescript SDK - success
│     └─Setup Environment - success
│     └─Load and Validate Document - success
│     └─Generate SDK - success
│     └─Compile SDK - success
```

Speakeasy [validates](https://www.speakeasy.com/docs/concepts#validation) the OpenAPI document to check that it's ready for code generation. Validation issues will be printed in the terminal. The generated SDK is saved as a folder in your project.

If you get ESLint styling errors, run the `speakeasy quickstart` command from outside your project.

## Adding SDK generation to your GitHub Actions

The Speakeasy [`sdk-generation-action`](https://github.com/speakeasy-api/sdk-generation-action) repository provides workflows that integrate the Speakeasy CLI into CI/CD pipelines and automatically regenerate client SDKs when the reference OpenAPI document changes.

You can configure Speakeasy to push a new branch to your SDK repositories automatically when the OpenAPI document changes, allowing your engineers to review and merge the SDK changes.

The Speakeasy [workflow matrix](https://www.speakeasy.com/docs/workflow-reference/generation-reference) provides an overview of how to set up automatic SDK generation.

## Using your SDK

Once you've generated your SDK, you can [publish](https://www.speakeasy.com/docs/publish-sdks) it for use. TypeScript SDKs are published as npm packages.

A quick, non-production-ready way to see your SDK in action is to copy your SDK folder to a frontend TypeScript project and use it there.

For example, you can create a Vite project that uses TypeScript:

```bash Terminal
npm create vite@latest
```

Then, copy the SDK folder from your Elysia app to the `src` directory of your TypeScript Vite project and delete the SDK folder in your Elysia project.

In the SDK `README.md` file, you'll find the documentation for your Speakeasy SDK.

Note that the SDK is not ready for production use. To get it production-ready, follow the steps outlined in your Speakeasy workspace.

The SDK has Zod as a peer dependency, as can be seen in the `sdk-typescript/package.json` file.

Install the required Zod version:

```bash Terminal
npm i zod
```

Replace the code in the `src/main.ts` file with the following example code taken from the `sdk-typescript/docs/sdk/users/README.md` file:

```typescript main.ts
import { SDK } from './sdk-typescript/src/'; // Adjust the path as necessary e.g. if your generated SDK has a different name

const sdk = new SDK();

async function run() {
  const result = await sdk.users.getUsers();

  // Handle the result
  console.log({ result });
}

run();
```

Make sure the Elysia server is running, then run the Vite dev server:

```bash Terminal
npm run dev
```

Now, you need to enable CORS in your Elysia dev server.

First, install the CORS plugin:

```bash Terminal
bun add @elysiajs/cors
```

Import the CORS plugin, then register it by passing the plugin into the `use()` method and chaining the `use()` method to the `Elysia` instance:

```typescript index.ts
// !mark(1,8:12)
import { cors } from '@elysiajs/cors';

const app = new Elysia()
  .onError(({ error, code }) => {
    if (code === 'NOT_FOUND') return 'Not Found :('
      console.error(error);
    })
    .use(
      cors({
        origin: 'http://localhost:5173'
      })
    )
```

Open `http://localhost:5173` in your browser, then open your browser dev tools. You should see the following logged in the dev tools console:

```
{
  "result": [
    {
      "id": "1",
      "name": "Alice",
      "age": 20
    }
  ]
}
```

The SDK functions are type safe and include TypeScript autocompletion for arguments and outputs.

Consider the following example scenario:

```typescript main.ts
const userOne = result[0].email;
```

When you try to access a property that doesn't exist, as in the code block above, you get a TypeScript error:

```
Property 'email' does not exist on type 'User'.
```

## Further reading

This guide covered the basics of generating an OpenAPI document using Elysia. Here are some resources to help you learn more about OpenAPI, the Elysia Swagger plugin, and Speakeasy:

- [Elysia Swagger plugin](https://elysiajs.com/recipe/openapi.html): Learn more about using Elysia to generate OpenAPI documents. Elysia has first-class support for OpenAPI and follows the OpenAPI Specification by default.
- [Speakeasy documentation](https://www.speakeasy.com/docs): Speakeasy has extensive documentation covering how to generate SDKs from OpenAPI documents, customize SDKs, and more.
- [Speakeasy OpenAPI reference](https://www.speakeasy.com/openapi): Review a detailed reference on the OpenAPI Specification.


 This is the content for the doc openapi/frameworks/fastapi.mdx 

 ---
title: How to generate an OpenAPI document with FastAPI
description: "Creating an OpenAPI document with FastAPI and using it to generate SDKs with Speakeasy."
---

import YouTube from "react-youtube";
import { ScrollyCoding } from "~/components/codehike/Scrollycoding";
import { Callout } from "~/components";

# How to generate an OpenAPI document with FastAPI

<div className="mt-10 flex items-center justify-center">
  <YouTube videoId="86hiib_OA4c" />
</div>

Many developers start their API development with FastAPI, and with good reason. FastAPI has rapidly gained traction in the Python community for its excellent performance, intuitive design, and flexibility. It enables developers to craft API solutions that not only run fast but also meet their users' unique needs.

FastAPI is great for building your core API, but you'll want to layer on SDKs and docs to provide your users with easy integration. For that, you'll want an OpenAPI file.

The good news is that FastAPI provides you with an OpenAPI file out of the box. The less good news is that you'll need some tweaking to get the OpenAPI document to a level where it becomes usable with other tooling.

This article will show you how to improve the default OpenAPI document generation to make the most of the generated schema.

## Generating an OpenAPI document with FastAPI

Understanding how FastAPI generates OpenAPI schemas can help you make more informed decisions when you customize your FastAPI setup.

The process is fairly straightforward: FastAPI builds the OpenAPI schema based on the routes and models you've defined in your application. For every route in your FastAPI application, FastAPI adds an operation to the OpenAPI schema. For every model used in these routes, FastAPI adds a schema definition. The request and response bodies, parameters, and headers all draw from these schema definitions.

While this process works well out of the box, FastAPI also offers several customization options that can change the generated OpenAPI schema. We'll cover some of these options in the following sections.

## Our FastAPI example app: APItizing Burgers

Let's get this out of the way: The name came in a daydream shortly before lunchtime.

To guide us through this journey, we'll use a simple example FastAPI application: the "APItizing Burgers" burger shop API. This API includes two models, `Burger` and `Order`, and provides basic CRUD operations for managing burgers and orders at our hypothetical burger shop. Additionally, we have a webhook defined for order status events.

We'll look at how we optimized this FastAPI application and refined our models and routes so that the generated OpenAPI document is intuitive and easy to use. We will also explore how we can use this schema to generate SDKs using Speakeasy. The source code for our example API is available in the [apitizing-burgers](https://github.com/speakeasy-api/apitizing-burgers) repository.

The repository consists of two directories: `app` and `sdk`.

The `app` directory contains only our FastAPI server definition: `app/main.py`. This is where we'll look at what we customized.

The `sdk` directory and the two OpenAPI documents, `openapi.yaml` and `openapi.json`, are generated by running `gen.sh` in the root of the project.

Join us as we dive into FastAPI customization and discover how these tweaks can streamline your SDK generation process.

<Callout title="WARN" variant="warning">
  When using Pydantic to define models, a known issue is that the serialization
  of `datetime` objects is not timezone-aware. This will cause a mismatch with
  the OpenAPI format `date-time`, which requires RFC 3339 date-time strings with
  timezones included. Consider using
  [`AwareDatetime`](https://docs.pydantic.dev/2.5/api/types/#pydantic.types.AwareDatetime)
  fields in Pydantic models to enable the appropriate
  [validation](https://docs.pydantic.dev/latest/errors/validation_errors/#timezone_aware)
  and ensure your SDK behavior matches the response definition from your server.
</Callout>{" "}

## Basic FastAPI setup

Let's get started with the basics – some things you probably do already.

These straightforward examples are trivial but will help you better understand the three steps in the automation pipeline: How FastAPI setup influences OpenAPI documents, which, in turn, influences SDK code.

<ScrollyCoding className="ch-scrollycoding-full-height">

## !!steps Add a list of servers to your FastAPI app

This may seem obvious, but while first working with FastAPI in development, the generated docs, development server, and API operations all work out of the box without the need to manually specify your server address.

However, when generating SDKs, your OpenAPI document needs to list servers.

In our `app/main.py`, we added our local server as shown.

```python ! main.py
from fastapi import FastAPI

app = FastAPI(
    servers=[
        {"url": "http://127.0.0.1:8000", "description": "Local server"},
    ],
)
```

---

## !!steps

This leads to the following generated output in `openapi.yaml`.

```yaml !! openapi.yaml
servers:
  - description: Local server
    url: http://127.0.0.1:8000/
```

---

## !!steps Add a title, summary, description, and version to your FastAPI app

In our `app/main.py`, if we have the following.

```python ! main.py
from fastapi import FastAPI

app = FastAPI(
    summary="A simple API to manage burgers and orders",
    description="This API is used to manage burgers and orders in a restaurant",
    version="0.1.0",
    title="APItizing Burger API",
)
```

---

## !!steps

FastAPI generates the following YAML in our `openapi.yaml` file.

```yaml !! openapi.yaml
info:
  description: This API is used to manage burgers and orders in a restaurant
  summary: A simple API to manage burgers and orders
  title: APItizing Burger API
  version: 0.1.0
```

---

## !!steps Route-level customizations: Enhancing usability

With the basics out of the way, let's look at a few more substantial recommendations.

```yaml !


```

---

## !!steps Add typed additional responses to FastAPI routes

When developers use your generated SDK, they may wish to see what all the possible responses for an API call could be.

With FastAPI, you can add additional responses to each route by specifying a response type.

In our `app/main.py`, we added this abbreviated code.

```python !! main.py
from fastapi import FastAPI
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field

class ResponseMessage(BaseModel):
    """A response message"""

    message: str = Field(description="The response message")

OPENAPI_RESPONSE_BURGER_NOT_FOUND = {
    "model": ResponseMessage,
    "description": "Burger not found",
}

def response_burger_not_found(burger_id: int):
    """Response for burger not found"""

    return JSONResponse(
        status_code=404,
        content=f"Burger with id {burger_id} does not exist",
    )

class Burger(BaseModel):
    id: int
    name: str
    description: str = None

app = FastAPI()

@app.get(
    "/burger/{burger_id}",
    response_model=BurgerOutput,
    responses={404: OPENAPI_RESPONSE_BURGER_NOT_FOUND},
    tags=["burger"],
)
def read_burger(burger_id: Annotated[int, Path(title="Burger ID")]):
    """Read a burger"""

    for burger in burgers_db:
        if burger.id == burger_id:
            return burger
    return response_burger_not_found(burger_id)
```

---

## !!steps 

FastAPI adds a schema for our specific error message to `openapi.yaml`.

```yaml ! openapi.yaml
components:
  schemas:
    ResponseMessage:
      description: A response message
      properties:
        message:
          description: The response message
          title: Message
          type: string
      required:
        - message
      title: ResponseMessage
      type: object
```

---

## !!steps Group FastAPI operations with OpenAPI tags and tag metadata

As your API develops and grows bigger, you're likely to split it into separate files. FastAPI [provides conveniences](https://fastapi.tiangolo.com/tutorial/bigger-applications/) to help reduce boilerplate and repetition when splitting an API into multiple modules.

While this separation may reduce cognitive overhead while you're working in particular sections of the API code, it doesn't mean similar groups are automatically created in your documentation and SDK code.

We recommend you add tags to all operations in FastAPI, whether you're building a big application or only have a handful of operations, so that operations can be grouped by tag in generated SDK code and documentation.

```python !


```

---

## !!steps Add tags to operations

The most straightforward way to add tags is to edit each operation and add a list of tags. This example highlights the tags list.

```python !! main.py mark=7
from fastapi import FastAPI

app = FastAPI()

@app.get(
    "/burger/{burger_id}",
    tags=["burger"],
)
def read_burger(burger_id: int):
    return {
        "burger_id": burger_id,
    }
```

---

## !!steps Add metadata to tags

You can add metadata to your tags to further improve the developer experience.

FastAPI accepts a parameter called `openapi_tags`, which we can use to add metadata, such as a description and a list of external documentation links.

Here's how to add metadata to tags.

```python !! main.py
from fastapi import FastAPI

tags_metadata = [
    {
        "name": "burger",
        "description": "Operations related to burgers",
        "externalDocs": {
            "description": "Burger external docs",
            "url": "https://en.wikipedia.org/wiki/Hamburger",
        },
    },
    {
        "name": "order",
        "description": "Operations related to orders",
    },
]

app = FastAPI(
    openapi_tags=tags_metadata,
)

@app.get(
    "/burger/{burger_id}",
    tags=["burger"],
)
def read_burger(burger_id: int):
    return {
        "burger_id": burger_id,
    }
```

---

## !!steps How tags are added to the OpenAPI document

When we add metadata to tags, FastAPI adds a top-level `tags` section to our OpenAPI document.

```yaml ! openapi.yaml
tags:
  - description: Operations related to burgers
    externalDocs:
      description: Burger external docs
      url: https://en.wikipedia.org/wiki/Hamburger
    name: burger
  - description: Operations related to orders
    name: order
```

---

## !!steps

Each tagged path in our OpenAPI document also gets a list of tags.

```yaml !! openapi.yaml
paths:
  /burger/{burger_id}:
    get:
      description: Read a burger
      operationId: readBurger
      summary: Read Burger
      tags:
        - burger
      # ...
```

---

## !!steps Customize the OpenAPI `operationId` generated by FastAPI

When FastAPI outputs an OpenAPI document, it generates a unique OpenAPI `operationId` for each path. By default, this unique ID is generated by the FastAPI `generate_unique_id` function.

```python ! main.py
def generate_unique_id(route: "APIRoute") -> str:
    operation_id = route.name + route.path_format
    operation_id = re.sub(r"\W", "_", operation_id)
    assert route.methods
    operation_id = operation_id + "_" + list(route.methods)[0].lower()
    return operation_id
```

---

## !!steps

This can often lead to cumbersome and unintuitive names. To improve usability, we have two methods of customizing these generated strings.

```python !


```

---

## !!steps Option 1: Customize the FastAPI `generate_unique_id_function` function

The preferred method is to use a custom function when you generate unique IDs for paths.

The example below is an illustrative function that doesn't generate guaranteed-unique IDs and doesn't handle method names without an underscore. However, it demonstrates how you can add a function that generates IDs based on an operation's method name.

```python !! main.py
from fastapi import FastAPI

def convert_snake_case_to_camel_case(string: str) -> str:
    """Convert snake case to camel case"""

    words = string.split("_")
    return words[0] + "".join(word.title() for word in words[1:])


def custom_generate_unique_id_function(route: APIRoute) -> str:
    """Custom function to generate unique id for each endpoint"""

    return convert_snake_case_to_camel_case(route.name)


app = FastAPI(
    generate_unique_id_function=custom_generate_unique_id_function,
)
```

---

## !!steps Option 2: Add an operation ID per operation

With FastAPI, you can specify the `operationId` per operation. For our example, we'll add a new parameter called `operation_id` to the operation decorator.

```python !! main.py mark=7
from fastapi import FastAPI

app = FastAPI()

@app.get(
    "/burger/{burger_id}",
    operation_id="readBurger",
)
def read_burger(burger_id: int):
    pass
```

---

## !!steps Add webhooks for real-time notifications

Starting with OpenAPI version 3.1.0, it is possible to specify webhooks for your application in OpenAPI.

Here's how to add a webhook to FastAPI:

```python !! main.py
from fastapi import FastAPI

app = FastAPI()


class Order(BaseModel):
    id: int
    note: str


@app.webhooks.post(
    "order-status-changed",
    operation_id="webhookOrderStatusChanged",
)
def webhook_order_status_changed(body: Order):
    """
    When an order status is changed, this webhook will be triggered.

    The server will send a `POST` request with the order details to the webhook URL.
    """
    pass
```

---

## !!steps

FastAPI generates the following top-level `webhooks` section in `openapi.yaml`.

```yaml ! openapi.yaml
webhooks:
  order-status-changed:
    post:
      description:
        "When an order status is changed, this webhook will be triggered.


        The server will send a `POST` request with the order details to the webhook
        URL."
      operationId: webhookOrderStatusChanged
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/Order"
        required: true
      responses:
        "200":
          content:
            application/json:
              schema: {}
          description: Successful Response
        "422":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/HTTPValidationError"
          description: Validation Error
      summary: Webhook Order Status Changed
```

---

## !!steps Integrating Speakeasy

Now that we have a customized OpenAPI document, we can use Speakeasy to generate SDKs based on it. Let's take a look at how the information we detailed in the OpenAPI document affects how Speakeasy generates SDKs.

```yaml !


```

---

## !!steps Server information

After we added our local server information, this is how it generates in the `openapi.yaml` file.

```yaml !! openapi.yaml
servers:
  - description: Local server
    url: http://127.0.0.1:8000/
```

---

## !!steps

After Speakeasy generates the SDK, this leads to the following abbreviated code in `sdk/src/openapi/sdkconfiguration.py`.

```python ! sdkconfiguration.py
from dataclasses import dataclass

SERVERS = [
    'http://127.0.0.1:8000/',
    # Local server
]
"""Contains the list of servers available to the SDK"""

@dataclass
class SDKConfiguration:
    ...
    server_url: Optional[str] = ""
    server_idx: Optional[int] = 0
    ...

    def __post_init__(self):
        self._hooks = SDKHooks()

    def get_server_details(self) -> Tuple[str, Dict[str, str]]:
        if self.server_url is not None and self.server_url:
            return remove_suffix(self.server_url, "/"), {}
        if self.server_idx is None:
            self.server_idx = 0

        return SERVERS[self.server_idx], {}
```

---

## !!steps

You'll find calls to `SDKConfiguration.get_server_details()` when the SDK builds API URLs.

```python !! sdkconfiguration.py
# !focus(18:24)
from dataclasses import dataclass

SERVERS = [
    'http://127.0.0.1:8000/',
    # Local server
]
"""Contains the list of servers available to the SDK"""

@dataclass
class SDKConfiguration:
    ...
    server_url: Optional[str] = ""
    server_idx: Optional[int] = 0
    ...

    def __post_init__(self):
        self._hooks = SDKHooks()

    def get_server_details(self) -> Tuple[str, Dict[str, str]]:
        if self.server_url is not None and self.server_url:
            return remove_suffix(self.server_url, "/"), {}
        if self.server_idx is None:
            self.server_idx = 0

        return SERVERS[self.server_idx], {}
```

---

## !!steps Title, summary, and description

Speakeasy uses the title, summary, and descriptions we provided earlier to add helpful text to the generated SDK documentation, including comments in the SDK code. For example, in `sdk/src/sdk/sdk.py`.

```python ! sdk.py
class SDK(BaseSDK):
    r"""APItizing Burgers API: A simple API to manage burgers and orders

    This API is used to manage burgers and orders in a restaurant
    """
```

---

## !!steps

Speakeasy adds the version to the `SDKConfiguration` in `sdk/src/openapi/sdkconfiguration.py`. It also uses this version to construct the user agent (`user_agent`), which contains the version of the SDK, the version of the Speakeasy generator build, and the version of the OpenAPI documentation.

```python !! sdkconfiguration.py
from dataclasses import dataclass

@dataclass
class SDKConfiguration:
    ...
    openapi_doc_version: str = '0.1.0'
    user_agent: str = "speakeasy-sdk/python 0.1.0 2.484.0 0.1.0 openapi"
    ...
```

---

## !!steps

When users call your API using the generated SDK, the `user_agent` from `SDKConfiguration` is automatically added to the `user-agent` header. The `_build_request_with_client` method in `BaseSDK` constructs the HTTP request and sets the header using `headers[user_agent_header] = self.sdk_configuration.user_agent`.

```python ! burger.py
# !focus(9)
def _build_request_with_client(
    self,
    ...
    user_agent_header,
    ...
) -> httpx.Request:
    ...
    headers["Accept"] = accept_header_value
    headers[user_agent_header] = self.sdk_configuration.user_agent
    ...
```

---

## !!steps Customizing the FastAPI `operation_id`

The unique `operation_id` generated by FastAPI does not translate well into an SDK. We need to customize the unique `operation_id` that FastAPI generates for better readability.

For instance, in the operation that returns a burger by `burger_id`, the default unique ID would be `read_burger_burger__burger_id__get`. This makes its way into SDK code, leading to class names such as `ReadBurgerBurgerBurgerIDGetRequest` or function names like `read_burger_burger_burger_id_get`.

Here's a usage example after generating an SDK without customizing the `operationId`.

```python !! main.py
import sdk
from sdk.models import operations

s = sdk.SDK()

req = operations.ReadBurgerBurgerBurgerIDGetRequest(
    burger_id=847252,
)

res = s.burger.read_burger_burger_burger_id_get(req)
```

---

## !!steps

However, after using the custom function `generate_unique_id` we defined previously, the `read_burger` operation gets a much friendlier operation ID: `readBurger`. And the usage example becomes much easier to read.

```python !! main.py
import sdk
from sdk.models import operations

s = sdk.SDK()

req = operations.ReadBurgerRequest(
    burger_id=847252,
)

res = s.burger.read_burger(req)
```

---

## !!steps

In addition to the two methods described earlier for customizing the `operation_id`, there is a third way. We can add the top-level `x-speakeasy-name-override` extension to our OpenAPI document, allowing Speakeasy to override these generated names when it generates SDK code.

To add this extension, follow the Speakeasy guide on [changing method names](/docs/customize-sdks/methods).

```yaml !


```

---

## !!steps Add retries to your SDK with `x-speakeasy-retries`

Speakeasy can generate SDKs that follow custom rules for retrying failed requests. For instance, if your server fails to return a response within a specified time, you may want your users to retry their request without clobbering your server.

To add retries to SDKs generated by Speakeasy, add a top-level `x-speakeasy-retries` schema to your OpenAPI document. You can also override the retry strategy per operation by adding `x-speakeasy-retries` to each operation.

```yaml !


```

---

## !!steps Add global retries

To add global retries, we need to customize the schema generated by the FastAPI `get_openapi` function.

```python !! main.py
from fastapi import FastAPI
from fastapi.openapi.utils import get_openapi

app = FastAPI(
    summary="A simple API to manage burgers and orders",
    description="This API is used to manage burgers and orders in a restaurant",
    version="0.1.0",
    title="APItizing Burger API",
)

@app.get("/")
def root():
    return {"message": "Root"}

def custom_openapi():
    if app.openapi_schema:
        return app.openapi_schema

    openapi_schema = get_openapi(
        title=app.title,
        version=app.version,
        summary=app.summary,
        description=app.description,
        routes=app.routes,
    )

    # Add retries
    openapi_schema["x-speakeasy-retries"] = {
        "strategy": "backoff",
        "backoff": {
            "initialInterval": 500,
            "maxInterval": 60000,
            "maxElapsedTime": 3600000,
            "exponent": 1.5,
        },
        "statusCodes": [
            "5XX",
        ],
        "retryConnectionErrors": True,
    }

    app.openapi_schema = openapi_schema
    return app.openapi_schema


app.openapi = custom_openapi
```

Keep in mind, you'll need to add this customization _after_ declaring your operation routes.

---

## !!steps 

This change adds the following top-level section to `openapi.yaml`.

```yaml ! openapi.yaml
x-speakeasy-retries:
  backoff:
    exponent: 1.5
    initialInterval: 500
    maxElapsedTime: 3600000
    maxInterval: 60000
  retryConnectionErrors: true
  statusCodes:
    - 5XX
  strategy: backoff
```

---

## !!steps Adding retries per request

To add `x-speakeasy-retries` to a single operation, update the operation and add the `openapi_extra` parameter as follows.

```python !! main.py
from fastapi import FastAPI

app = FastAPI()

@app.get(
    "/burger/",
    openapi_extra={
        "x-speakeasy-retries": {
            "strategy": "backoff",
            "backoff": {
                "initialInterval": 500,
                "maxInterval": 60000,
                "maxElapsedTime": 3600000,
                "exponent": 1.5,
            },
            "statusCodes": [
                "5XX",
            ],
            "retryConnectionErrors": True,
        }
    },
)
def list_burgers():
    return []
```

---

## !!steps Configuring authentication and security

FastAPI supports several authentication mechanisms that can be easily integrated into your API. 

The example below demonstrates adding an API key authentication scheme to the `/burger/` endpoint of our API. We use the `APIKeyHeader` dependency to validate the API key passed in the `Authorization` header.

```python !! main.py
from fastapi.security import APIKeyHeader

API_KEY = "your-apitizing-api-key"

header_scheme = APIKeyHeader(
    name=API_KEY,
    auto_error=True,
    description="API Key for the Burger listing API. API Key should be sent as a header, with the value 'your-apitizing-api-key'",
    scheme_name="api_key",
)
```

---

## !!steps Using API key authentication

We can pass a `key` parameter to the `list_burgers` function, retrieve the API key from the header, and perform validation.

```python !! main.py
@app.get(
    "/burger/",
    response_model=List[BurgerOutput],
    tags=["burger"],
    ...
)
def list_burgers(key: str = Depends(header_scheme)):
    """List all burgers"""

    if key != API_KEY:
        raise HTTPException(status_code=401, detail="Invalid API Key")

    return [BurgerOutput(**burger_data.dict()) for burger_data in burgers_db]
```

Now when generating the OpenAPI document, the API key authentication scheme will be included and only required for the listing on the `/burger/` endpoint.

</ScrollyCoding>

## Summary

In this post, we've explored how you can set up a FastAPI-based SDK generation pipeline without hand-editing or updating OpenAPI documents. By using existing FastAPI methods for extending and customizing OpenAPI documents, you can improve the usability of your generated client SDKs.


 This is the content for the doc openapi/frameworks/fastapi/fastapi-forms.mdx 

 ---
title: "Addressing form data type compatibility in FastAPI"
description: "Handle form data discrepancy with FastAPI and Speakeasy."
---


# Addressing form data type compatibility in FastAPI

## Understanding the challenges 

When integrating FastAPI with a Speakeasy Python SDK, one of the main challenges arises from differences in how form data is structured. Speakeasy employs a bracket notation (`key[]`) to represent arrays in form data, whereas FastAPI does not natively support this format. By default, FastAPI constructs lists from form data containing duplicate keys, which can lead to mismatches in processing.

FastAPI:

```python 
FormData([('key', 'value1'), ('key', 'value2')])
```

Speakeasy SDKs:

```python
FormData([('key[]', 'value1'), ('key[]', 'value2')])
```

## Limitations 

**Middleware Execution Order**

In FastAPI, middleware executes after FastAPI has already read and interpreted the request body. By this point, FastAPI has parsed the form data, making it challenging for middleware to modify the format of the form data. This sequential execution order restricts the ability of middleware to alter the form data format effectively.

**Streaming Data Handling**

FastAPI processes incoming request data as a continuous stream, allowing it to handle large payloads efficiently. However, this streaming approach complicates the process of making alterations to the data mid-stream within middleware. Attempting to modify the data stream after it has been parsed introduces a heightened risk of errors. Additionally, such modifications can lead to reduced efficiency in data handling, as they may require rewinding or manipulating the stream, resulting in additional processing overhead.

## Solution

Addressing these challenges involves a direct modification of FastAPI's request processing mechanism. This allows for the conversion of Speakeasy-formatted form data into a structure recognizable by FastAPI. 

```python
# Reference to FastAPI's original form retrieval method.
get_form = Request._get_form

async def patched_get_form(self, **kwargs) -> FormData:
    
    # Fetch original form data.
    form_params = await get_form(self)

    # Adjust parameters: remove '[]' from keys indicating arrays.
    fixed_params = []
    for key, value in form_params.multi_items():
        if key.endswith("[]"):  # Normalize array keys.
            key = key[:-2]
        fixed_params.append((key, value))  # Collect adjusted pairs.

    # Return modified FormData with compatible keys.
    return FormData(fixed_params)
```



## Conclusion


Integrating FastAPI with Speakeasy SDKs can pose challenges due to differences in form data handling. However, by understanding the limitations of middleware and applying a custom patch to FastAPI's request form handling, we can overcome these obstacles. 



 This is the content for the doc openapi/frameworks/fastify.mdx 

 ---
title: How To Generate an OpenAPI Spec With Fastify
description: "Learn how to create an OpenAPI spec for your Fastify API and use it to automatically generate and customize client SDKs across different languages."
---

import { Callout } from "~/components";

# How to generate an OpenAPI/Swagger spec with Fastify

In this tutorial, we'll show you how to generate an OpenAPI specification using [Fastify](https://fastify.dev/). We will also show how you can use Speakeasy to generate client SDKs for your API based on the specification.

<Callout title="Example code" variant="info">
  If you want to follow along with the example code in this tutorial, you can
  clone the [Speakeasy Fastify example
  repo](https://github.com/speakeasy-api/guide-fastify-example).
</Callout>

Here's what we'll cover:

1.  How to add `@fastify/swagger` to a Fastify project.
2.  Generate an OpenAPI specification using the Fastify CLI.
3.  Improve the generated OpenAPI specification for better downstream SDK generation.
4.  Use the Speakeasy CLI to generate a client SDK based on our generated OpenAPI specification.
5.  Use the Speakeasy OpenAPI extensions to improve generated SDKs.
6.  How to automate this process as part of a CI/CD pipeline.

Your Fastify project might not be as simple as our example app, but the steps below should translate well to any Fastify project. We'll also look at how to gradually add routes to OpenAPI so that you have the option to ship an SDK that improves API coverage over time.

## The SDK Generation Pipeline

Fastify ships with the [`@fastify/swagger`](https://github.com/fastify/fastify-swagger) plugin, which provides convenient shortcuts for generating good OpenAPI specifications. We'll start this tutorial by registering `@fastify/swagger` in a Fastify project to generate a spec.

The quality of your OpenAPI specification will ultimately determine the quality of generated SDKs and documentation, so we'll dive into ways you can improve the generated specification.

With our new and improved OpenAPI specification in hand, we'll take a look at how to generate SDKs using Speakeasy.

Finally, we'll add this process to a CI/CD pipeline so that Speakeasy automatically generates fresh SDKs whenever your Fastify API changes in the future.

## Requirements

This guide assumes that you have an existing Fastify app or you'll clone our example application, and that you have a basic familiarity with Fastify.

You'll need [Node.js installed](https://nodejs.org/en/download) (we used Node v20.5.1), and you'll need to install the [Fastify CLI](https://github.com/fastify/fastify-cli/).

Once you have Node.js, you can install the Fastify CLI by running the following in the terminal:

```bash
npm install fastify-cli --global
```

Make sure `fastify` is in your `$PATH`:

```bash
fastify version
```

If you can't run `fastify` using the steps above, you can use `npx` to run `fastify-cli` by replacing `fastify` with `fastify-cli` in our code samples.

For example:

```bash
# fastify version
npx fastify-cli version
```

Install the [Speakeasy CLI](/docs/speakeasy-cli/getting-started) to generate the SDK once you have generated your OpenAPI spec.

## How To Add "@fastify/swagger" to a Fastify Project

In your Fastify project folder, run the following in the terminal to install `@fastify/swagger`:

```bash
npm install --save @fastify/swagger
```

To register `@fastify/swagger` in our Fastify app, we added a new plugin. Here's the simplified plugin we added as `plugins/openapi.js`:

```javascript plugins/openapi.js
import swagger from "@fastify/swagger";
import fp from "fastify-plugin";

export default fp(async (fastify) => {
  fastify.register(swagger);
});
```

Without any further configuration, you can generate an OpenAPI specification by running the Fastify CLI:

```bash
fastify generate-swagger app.js
```

This should print a basic OpenAPI spec in JSON format.

<Callout title="TIP" variant="success">
If you find YAML more readable than JSON, you can add `--yaml=true` to your `fastify` commands:

```bash
fastify generate-swagger --yaml=true app.js
```

The option to output YAML is [brand new](https://github.com/fastify/fastify-cli/pull/662) and, while merged, hasn't made it to a release when we wrote this tutorial.

</Callout>

## Supported OpenAPI Versions in Fastify and Speakeasy

Fastify can generate OpenAPI specifications in [OpenAPI version 2.0](https://swagger.io/specification/v2/) (formerly known as _Swagger_) or [OpenAPI version 3.0.3](https://swagger.io/specification/v3/).

Speakeasy supports OpenAPI 3.x.

We need to configure Fastify to ensure we output an OpenAPI spec that conforms to OpenAPI 3.0.3.

### How To Generate a Specification in OpenAPI Version 3.0.3 Using Fastify

In Fastify, the version of the generated OpenAPI specification is determined by the Fastify options object. To use OpenAPI 3.0.3, the options object should contain an object with the key `openapi` at its root.

Continuing our example above, we'll add an options object when we register `@fastify/swagger` in `plugins/openapi.js`:

```javascript plugins/openapi.js mark=5:7
import swagger from "@fastify/swagger";
import fp from "fastify-plugin";

export default fp(async (fastify) => {
  fastify.register(swagger, {
    openapi: {},
  });
});
```

To verify that we now have an OpenAPI 3.0.3 spec, run:

```bash
fastify generate-swagger app.js
```

The output should start with the following JSON:

```json mark=2
{
  "openapi": "3.0.3"
  //...
}
```

## How To Add OpenAPI "info" in Fastify

Without customization, `@fastify/swagger` generates the following `info` object for our API:

```json
{
  //...
  "info": {
    "version": "8.10.1",
    "title": "@fastify/swagger"
  }
}
```

We can customize this object by updating our options object in `plugins/openapi.js`:

```javascript plugins/openapi.js mark=7:21
import swagger from "@fastify/swagger";
import fp from "fastify-plugin";

export default fp(async (fastify) => {
  fastify.register(swagger, {
    openapi: {
      info: {
        title: "Speakeasy Bar API",
        description: "This is a sample API for Speakeasy Bar.",
        termsOfService: "http://example.com/terms/",
        contact: {
          name: "Speakeasy Bar Support",
          url: "http://www.example.com/support",
          email: "support@example.com",
        },
        license: {
          name: "Apache 2.0",
          url: "https://www.apache.org/licenses/LICENSE-2.0.html",
        },
        version: "1.0.1",
      },
    },
  });
});
```

Fastify copies this `info` object verbatim, which results in the following `info` object in our JSON:

```json
{
  "info": {
    "title": "Speakeasy Bar API",
    "description": "This is a sample API for Speakeasy Bar.",
    "termsOfService": "http://example.com/terms/",
    "contact": {
      "name": "Speakeasy Bar Support",
      "url": "http://www.example.com/support",
      "email": "support@example.com"
    },
    "license": {
      "name": "Apache 2.0",
      "url": "https://www.apache.org/licenses/LICENSE-2.0.html"
    },
    "version": "1.0.1"
  }
  //...
}
```

Another common pattern we've seen, included here for completeness, is to reuse information from the project's `package.json` when generating OpenAPI specs. This pattern takes [DRY](https://en.wikipedia.org/wiki/Don%27t_repeat_yourself) quite literally, and someone editing the package might not realize the downstream consequences.

To pull information from `package.json` in `plugins/openapi.js`:

```javascript plugins/openapi.js mark=9:11
import swagger from "@fastify/swagger";
import fp from "fastify-plugin";
import packageJson from "../package.json";

export default fp(async (fastify) => {
  fastify.register(swagger, {
    openapi: {
      info: {
        title: packageJson.name,
        description: packageJson.description,
        version: packageJson.version,
        //...
      },
    },
  });
});
```

## Update Fastify to Generate OpenAPI Component Schemas

Fastify handles validation and serialization for Fastify apps based on schemas defined as JSON Schema but does not enforce separating schemas into reusable components.

Let's start with a hypothetical example in a route definition, `routes/drink/index.js`:

```javascript routes/drink/index.js mark=11:16
export default async function (fastify, opts) {
  const schema = {
    params: {
      type: "object",
      properties: {
        drinkId: { type: "string" },
      },
    },
    response: {
      200: {
        type: "object",
        properties: {
          id: { type: "string" },
          name: { type: "string" },
          description: { type: "string" },
        },
      },
    },
  };

  fastify.get("/:drinkId/", { schema }, async function (request, reply) {
    const { drinkId } = request.params;
    return {
      id: drinkId,
      name: "Example Drink Name",
      description: "Example description",
    };
  });
}
```

The example above would generate the following OpenAPI schema for this route:

```json
// !focus(20:33)
{
  "paths": {
    "/drink/{drinkId}/": {
      "get": {
        "parameters": [
          {
            "schema": {
              "type": "string"
            },
            "in": "path",
            "name": "drinkId",
            "required": true
          }
        ],
        "responses": {
          "200": {
            "description": "Default Response",
            "content": {
              "application/json": {
                "schema": {
                  "type": "object",
                  "properties": {
                    "id": {
                      "type": "string"
                    },
                    "name": {
                      "type": "string"
                    },
                    "description": {
                      "type": "string"
                    }
                  }
                }
              }
            }
          }
        }
      }
    }
  }
}
```

Note how the response schema is presented inline. If we defined the schema for another route that returns a drink object similarly, our OpenAPI spec, resulting SDK, and documentation would not present a drink as a reusable component schema.

Fastify provides methods to add and reuse schemas in an application.

As a start, let's separate the response schema and use the Fastify `addSchema` method:

```javascript routes/drink/index.js mark=2:9,30
export default async function (fastify, opts) {
  fastify.addSchema({
    $id: "Drink",
    type: "object",
    properties: {
      name: { type: "string" },
      description: { type: "string" },
    },
  });

  const schema = {
    params: {
      type: "object",
      properties: {
        drinkId: { type: "string" },
      },
    },
    response: {
      200: {
        $ref: "Drink",
      },
    },
  };

  fastify.get("/:drinkId/", { schema }, async function (request, reply) {
    const { drinkId } = request.params;
    return {
      id: drinkId,
      name: "Example Drink Name",
      description: "Example description",
    };
  });
}
```

We added a field called `$id` to our drink schema, then called `fastify.addSchema()` to add this shared schema to the Fastify app. To use this shared schema, we reference it using the JSON Schema `$ref` keyword, referencing the shared schema `$id` field.

This generates the following OpenAPI schema:

```json
// !focus(4:15)
// !focus(37)
{
  "components": {
    "schemas": {
      "def-0": {
        "type": "object",
        "properties": {
          "name": {
            "type": "string"
          },
          "description": {
            "type": "string"
          }
        },
        "title": "Drink"
      }
    }
  },
  "paths": {
    "/drink/{drinkId}/": {
      "get": {
        "parameters": [
          {
            "schema": {
              "type": "string"
            },
            "in": "path",
            "name": "drinkId",
            "required": true
          }
        ],
        "responses": {
          "200": {
            "description": "Default Response",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/def-0"
                }
              }
            }
          }
        }
      }
    }
  }
}
```

Note how, instead of defining the response schema inline with the path schema, we now have a component schema `def-0`, which our path's response schema references as `#/components/schemas/def-0`.

This is already more useful. But if we were to generate an SDK or documentation based on this schema, the autogenerated name `def-0` would lead to documentation and methods for a schema component named `def-0`.

Our next task is to customize this name.

## Creating Useful OpenAPI "$ref" references in Fastify

By default, Fastify keeps track of all schemas added with `fastify.addSchema()` and numbers them. The default internal [function that builds these references](https://github.com/fastify/fastify-swagger/blob/ff0260811c0c319f4973665fd15517937e287040/lib/mode/dynamic.js#L17) looks like this:

```javascript fastify-swagger/lib/mode/dynamic.js
function buildLocalReference(json, baseUri, fragment, i) {
  if (!json.title && json.$id) {
    json.title = json.$id;
  }
  return `def-${i}`;
}
```

This function makes it clear where the `def-0` reference in our generated OpenAPI specification came from.

Fastify allows us to override the `buildLocalReference` function as part of our OpenAPI options object in `plugins/openapi.js`:

```javascript plugins/openapi.js mark=13:17
import swagger from "@fastify/swagger";
import fp from "fastify-plugin";

export default fp(async (fastify) => {
  fastify.register(swagger, {
    openapi: {
      info: {
        title: "Speakeasy Bar API",
        description: "This is a sample API for Speakeasy Bar.",
        version: "1.0.1",
      },
    },
    refResolver: {
      buildLocalReference(json, baseUri, fragment, i) {
        return json.$id || `id-${i}`;
      },
    },
  });
});
```

By overriding `buildLocalReference` in the snippet above, we help Fastify to use the `$id` field as the component schema's reference. If we were to regenerate the OpenAPI spec now, we would see that `def-0` is replaced by `Drink`.

## Customizing OpenAPI "operationId" Using Fastify

Each path's `operationId` field in the OpenAPI specification is used to generate method names and documentation in SDKs.

To add `operationId` to a route, add the field to the route's schema. For example:

```javascript routes/drink/index.js mark=3
fastify.get(
  "/:drinkId/",
  { schema: { operationId: "getDrink" } },
  async function ({ params: { drinkId } }) {
    return {
      id: drinkId,
    };
  },
);
```

This would generate the following OpenAPI schema:

```json
// !focus(4)
{
  "/drink/{drinkId}/": {
    "get": {
      "operationId": "getDrink",
      "responses": {
        "200": {
          "description": "Default Response"
        }
      }
    }
  }
}
```

## Add OpenAPI Tags to Fastify Routes

At Speakeasy, whether you're building a big application or only have a handful of operations, we recommend adding tags to all your Fastify routes so you can group them by tag in generated SDK code and documentation.

### Add OpenAPI Tags to Routes in Fastify

To add OpenAPI tags to a route in Fastify, add the `tags` keyword with a list of tags to the route's schema. Here's a simplified example from `routes/drink/index.js`:

```javascript routes/drink/index.js mark=3
fastify.get(
  "/:drinkId/",
  { schema: { tags: ["drinks"] } },
  async function ({ params: { drinkId } }) {
    return {
      id: drinkId,
    };
  },
);
```

### Add Metadata to Tags

We can add a description and external documentation link to each tag by adding a list of tag objects to the Swagger options object in `plugins/openapi.js`:

```javascript plugins/openapi.js mark=8:17
import swagger from "@fastify/swagger";
import fp from "fastify-plugin";

export default fp(async (fastify) => {
  fastify.register(swagger, {
    openapi: {
      info: {
        tags: [
          {
            name: "drinks",
            description: "Drink-related endpoints",
            externalDocs: {
              description: "Find out more",
              url: "http://swagger.io",
            },
          },
        ],
      },
    },
  });
});
```

As with the other keys in the `info` options, Fastify copies the list of tags to the generated OpenAPI spec verbatim.

## Add a List of Servers to the Fastify OpenAPI Spec

When validating an OpenAPI spec, Speakeasy expects a list of servers at the root of the spec. We'll add this to our options object in `plugins/openapi.js`:

```javascript plugins/openapi.js mark=7:12
import swagger from "@fastify/swagger";
import fp from "fastify-plugin";

export default fp(async (fastify) => {
  fastify.register(swagger, {
    openapi: {
      servers: [
        {
          url: "http://localhost",
          description: "Development server",
        },
      ],
    },
  });
});
```

## Add Retries to Your SDK With "x-speakeasy-retries"

If you are using Speakeasy to generate your SDK, we can customize it to follow custom rules for retrying failed requests. For instance, if your server fails to return a response within a specified time, you may want your users to retry their request without clobbering your server.

Add retries to SDKs generated by Speakeasy by adding a top-level `x-speakeasy-retries` schema to your OpenAPI spec. You can also override the retry strategy per operation by adding `x-speakeasy-retries`.

### Adding Global Retries

```javascript plugins/openapi.js mark=7:17
import swagger from "@fastify/swagger";
import fp from "fastify-plugin";

export default fp(async (fastify) => {
  fastify.register(swagger, {
    openapi: {
      "x-speakeasy-retries": {
        strategy: "backoff",
        backoff: {
          initialInterval: 500,
          maxInterval: 60000,
          maxElapsedTime: 3600000,
          exponent: 1.5,
        },
        statusCodes: ["5XX"],
        retryConnectionErrors: true,
      },
    },
  });
});
```

Fastify respects OpenAPI extensions that start with `x-` and copies these to the root of the generated OpenAPI specification.

### Adding Retries per Method

If we want to add a unique retry strategy to a single route, we can add `x-speakeasy-retries` to the route's schema:

```javascript routes/drink/index.js mark=5:15
fastify.get(
  "/:drinkId/",
  {
    schema: {
      "x-speakeasy-retries": {
        strategy: "backoff",
        backoff: {
          initialInterval: 500,
          maxInterval: 60000,
          maxElapsedTime: 3600000,
          exponent: 1.5,
        },
        statusCodes: ["5XX"],
        retryConnectionErrors: true,
      },
    },
  },
  async function (request, reply) {
    const { drinkId } = request.params;
    return {
      id: drinkId,
      name: "Example Drink Name",
      description: "Example description",
    };
  },
);
```

Once again, when generating an OpenAPI spec, Fastify will copy route-specific OpenAPI extensions without any changes.

## How To Generate an SDK Based on Your OpenAPI Spec

Before generating an SDK, we need to save the Fastify-generated OpenAPI spec to a file. We'll add the following script to our `package.json` to generate `openapi.json` in the root of our project:

```json package.json
{
  "scripts": {
    "openapi": "fastify generate-swagger app.js > openapi.json"
  }
  //...
}
```

Then we run the following in the terminal:

```bash
npm run openapi
```

After following the steps above, we have an OpenAPI spec that is ready to use as the basis for a new SDK. Now we'll use Speakeasy to generate an SDK.

In the root directory of your project, run the following:

```bash
speakeasy quickstart
```

Follow the onscreen prompts to provide the necessary configuration details for your new SDK such as the name, schema location and output path. Enter `openapi.json` when prompted for the OpenAPI document location and select TypeScript when prompted for which language you would like to generate.

## Add SDK Generation to Your GitHub Actions

The Speakeasy [`sdk-generation-action`](https://github.com/speakeasy-api/sdk-generation-action) repository provides workflows that can integrate the Speakeasy CLI in your CI/CD pipeline, so your SDKs are regenerated when your OpenAPI spec changes.

You can set up Speakeasy to automatically push a new branch to your SDK repositories so that your engineers can review and merge the SDK changes.

For an overview of how to set up automation for your SDKs, see the Speakeasy documentation about [SDK Generation Action and Workflows](/docs/speakeasy-reference/workflow-file).

## Summary

In this tutorial, we've learned how to generate an OpenAPI specification for your Fastify API. We also learn how to integrate Fastify with Speakeasy to generate SDKs. The tutorial guides you through step-by-step instructions on how to do this, from adding `@fastify/swagger` to a Fastify project and generating an OpenAPI specification to improving the generated OpenAPI specification for better SDK generation.

It also covers how to use the Speakeasy OpenAPI extensions to improve generated SDKs and how to automate SDK generation as part of a CI/CD pipeline.

Following these steps, you can successfully generate OpenAPI specifications for your Fastify app and improve your API operations.


 This is the content for the doc openapi/frameworks/flask.mdx 

 ---
title: Generate an OpenAPI/Swagger document with Flask
description: "Generating an OpenAPI document with Flask and using it to create SDKs with Speakeasy."
---

import { ScrollyCoding } from "~/components/codehike/Scrollycoding";
import { Callout } from "~/components";

# How to generate an OpenAPI document with Flask

OpenAPI is a tool for defining and sharing REST APIs, and Flask can be paired with `flask-smorest` to build such APIs.

This guide walks you through generating an OpenAPI document from a Flask project and using it to create SDKs with Speakeasy, covering the following steps:

1. Setting up a simple REST API with Flask
2. Integrating `flask-smorest`
3. Creating the OpenAPI document to describe the API
4. Customizing the OpenAPI schema
5. Using the Speakeasy CLI to create an SDK based on the schema
6. Integrating SDK creation into CI/CD workflows

## Requirements

To follow along, you will need:

- Python version 3.8 or higher
- An existing Flask project or a copy of the provided [example repository](https://github.com/speakeasy-api/flask-openapi-example)
- A basic understanding of Flask project structure and how REST APIs work

## Example Flask REST API repository

<Callout title="Example repository" variant="info">
The source code for the completed example is available in the [**Speakeasy Flask example repository**](https://github.com/speakeasy-api/openapi-flask-example).
</Callout>

The repository already contains all the code covered throughout the guide. You can clone it and follow along with the tutorial, or use it as a reference to add to your own Flask project.

To better understand the process of generating an OpenAPI document with Flask, let's start by inspecting some simple CRUD endpoints for an online library, along with a `Book` class and a serializer for our data.

### Models and routes

<ScrollyCoding fullHeight>

## !!steps

Open the `app.py` file, which serves as the main entry point of the program, and inspect the main function:

```python ! app.py focus=1:55
!from ./assets/flask/app.py.txt
```


---

## !!steps

Here, you will see a method call to create a SQLite database and a function to run the Flask app:

```python ! app.py focus=52:55 mark=54,55
!from ./assets/flask/app.py.txt
```


---

## !!steps

From the root of the repository, open the `models.py` file to see a `Book` model containing a few fields with validation:

```python !! models.py focus=1:8
!from ./assets/flask/models.py.txt
```


---

## !!steps

In the `schemas.py` file, the `BookSchema` class can be used to serialize and deserialize book data with the `marshmallow` package:

```python ! schemas.py focus=1:10
!from ./assets/flask/schemas.py.txt
```


---

## !!steps

The `resources.py` file contains API endpoints set up to handle all the CRUD operations for the books:

```python !! resources.py focus=1:94
!from ./assets/flask/resources.py.txt
```

</ScrollyCoding>


This code defines a simple Flask REST API with CRUD operations for a `Book` model. The `BookList` class provides a way to retrieve all book data and create new books. The `BookDetail` class handles the retrieval of specific books, updating book data, and deleting books.

## Generate the OpenAPI document using `flask-smorest`

Flask does not support OpenAPI document generation out-of-the-box, so we'll use the `flask-smorest` package to generate the OpenAPI document.

If you are following along with the example repository, you can create and activate a virtual environment to install the project dependencies:

```bash Terminal
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

If you have not already, install `flask-smorest` with the following command:

```bash Terminal
pip install flask-smorest
```


<ScrollyCoding fullHeight>

## !!steps

The most basic configuration for generating an OpenAPI document with `flask-smorest` is added in the `app.py` file:

```python !! app.py focus=9:12
!from ./assets/flask/app.py.txt
```


---

## !!steps

The new Swagger UI endpoint is also added in the `app.py` file:

```python !! app.py focus=14 mark=14
!from ./assets/flask/app.py.txt
```


---

## !!steps

The `app.py` file contains additional configuration settings for the OpenAPI document. These add a development server:

```python !! app.py focus=36:41
!from ./assets/flask/app.py.txt
```


---

## !!steps

These additional configuration settings add a route to serve the OpenAPI document:

```python !! app.py focus=44:50
!from ./assets/flask/app.py.txt
```


</ScrollyCoding>


### Run server

To inspect and interact with the OpenAPI document, you need to run the development server, which will create a database file if one does not already exist, and serve the API.

Run the development server:

```bash Terminal
python app.py
```

You can now access the API and documentation:

- Visit `http://127.0.0.1:5000/swagger-ui` to view the Swagger documentation and interact with the API.
- Visit `http://127.0.0.1:5000/openapi.yaml` to download the OpenAPI document.

### OpenAPI document generation

Now that we understand our Flask REST API, we can run the following command to generate the OpenAPI document using `flask-smorest`:

```bash Terminal
flask openapi write --format=yaml openapi.yaml
```

This generates a new file, `openapi.yaml`, in the root of the project.



<ScrollyCoding fullHeight>

## !!steps

Here, you can see an example of the generated OpenAPI document:

```yaml ! openapi.yaml focus=1:170
!from ./assets/flask/openapi.yaml.txt
```


---

## !!steps

Return to the `app.py` file to see how the app configuration influences the OpenAPI document generation:

```python !! app.py focus=9:15
!from ./assets/flask/app.py.txt
```


---

## !!steps

Open the `openapi.yaml` file to see the titles and versions reflected in the generated OpenAPI document:

```yaml ! openapi.yaml focus=64:67
!from ./assets/flask/openapi.yaml.txt
```


---

## !!steps

The server URL is also included in the OpenAPI document:

```yaml ! openapi.yaml focus=155:157
!from ./assets/flask/openapi.yaml.txt
```


---

## !!steps

Open the `models.py` file to see the `Book` parameters:

```python !! models.py focus=3:8
!from ./assets/flask/models.py.txt
```


---

## !!steps

Open the `openapi.yaml`file to check the same `Book` parameters are reflected in the OpenAPI document:

```yaml ! openapi.yaml focus=15:30
!from ./assets/flask/openapi.yaml.txt
```


</ScrollyCoding>



## OpenAPI document customization

The OpenAPI document generated by `flask-smorest` may not fit all use cases. The document can be customized further to better serve information about your API endpoints. You can add descriptions, tags, examples, and more to make the documentation more informative and user-friendly.

In the [customized](https://github.com/speakeasy-api/openapi-flask-example/tree/customized) branch of the example repository, you can find a customized OpenAPI document that demonstrates the options available for modifying your generated document.



<ScrollyCoding fullHeight>

## !!steps

Open the `resources.py` file and inspect the configured endpoints:

```python ! resources.py focus=1:94
!from ./assets/flask/resources.py.txt
```


---

## !!steps

You can indicate the expected response codes and models using `@blp.response()`:

```python ! resources.py focus=12
!from ./assets/flask/resources.py.txt
```


---

## !!steps

This results in the following additions, for example, to the `/books/` `get` operation in the OpenAPI document:

```yaml !! openapi.yaml focus=69:82
!from ./assets/flask/openapi.yaml.txt
```


---

## !!steps

Use the `@blp.arguments()` decorator to enforce a schema for arguments:

```python ! resources.py focus=25
!from ./assets/flask/resources.py.txt
```


---

## !!steps

An enforced arguments schema results in the following additions to the `post` operation:

```yaml !! openapi.yaml focus=96:97
!from ./assets/flask/openapi.yaml.txt
```


---

## !!steps

Allow pagination with the `@blp.paginate()` decorator:

```python ! resources.py focus=13
!from ./assets/flask/resources.py.txt
```


---

## !!steps

Allowing paginations gives you access to the `page` and `page_size` properties, which you can use in your database query:

```python ! resources.py focus=14:23
!from ./assets/flask/resources.py.txt
```


---

## !!steps

You can add inline documentation using docstrings:

```python ! resources.py focus=38:41
!from ./assets/flask/resources.py.txt
```


---

## !!steps

Docstrings are reflected in the OpenAPI document as follows:

```yaml !! openapi.yaml focus=124
!from ./assets/flask/openapi.yaml.txt
```


---

## !!steps

Notice the internal comment that is omitted from the OpenAPI document:

```python ! resources.py focus=40
!from ./assets/flask/resources.py.txt
```


---

## !!steps

You can add global retries to the OpenAPI document by modifying the app config in the `app.py` file:

```python !! app.py focus=17:28
!from ./assets/flask/app.py.txt
```


---

## !!steps

This enables retries when using the document to create an SDK with Speakeasy:

```yaml ! openapi.yaml focus=161:170
!from ./assets/flask/openapi.yaml.txt
```

</ScrollyCoding>



## Creating SDKs for a Flask REST API

To create a Python SDK for the Flask REST API, run the following command:

```bash Terminal
speakeasy quickstart
```

Follow the onscreen prompts to provide the configuration details for your new SDK, such as the name, schema location, and output path. When prompted, enter `openapi.yaml` for the OpenAPI document location, select a language, and generate.

## Add SDK generation to your GitHub Actions

The Speakeasy [`sdk-generation-action`](https://github.com/speakeasy-api/sdk-generation-action) repository provides workflows for integrating the Speakeasy CLI into your CI/CD pipeline, so that your SDKs are recreated whenever your OpenAPI document changes.

You can set up Speakeasy to automatically push a new branch to your SDK repositories for your engineers to review before merging the SDK changes.

For an overview of how to set up automation for your SDKs, see the Speakeasy [SDK Generation Action and Workflows](/docs/speakeasy-reference/workflow-file) documentation.

## SDK customization

After creating your SDK with Speakeasy, you will find a new directory containing the generated SDK code, which we will now explore further.

These examples assume a Python SDK named `books-python` was generated from the example Flask project above. Edit any paths to reflect your environment if you want to follow in your own project.


<ScrollyCoding fullHeight>

## !!steps

Navigate into the `books-python/src/books/models` directory and find the `book.py` file created by Speakeasy. Note how the OpenAPI document was used to create the `Book` class:

```python ! book.py
!from ./assets/flask/book.py.txt
```


---

## !!steps

Open the `src/books/books_sdk.py` file to see the methods that call the web API from an application using the SDK:

```python !! books_sdk.py focus=13:104 mark=13
!from ./assets/flask/books_sdk.py.txt
```


---

## !!steps

Here, you can see how the request to the API endpoint is built:

```python !! books_sdk.py focus=136:148
!from ./assets/flask/books_sdk.py.txt
```


---

## !!steps

Finally, note the result of the global retries strategy that we set up in the `app.py` file:

```python !! books_sdk.py focus=154:156
!from ./assets/flask/books_sdk.py.txt
```


</ScrollyCoding>


## Summary

In this guide, we showed you how to generate an OpenAPI document for a Flask API and use Speakeasy to create an SDK based on the OpenAPI document. The step-by-step instructions included adding relevant tools to the Flask project, generating an OpenAPI document, enhancing it for improved creation, using Speakeasy CLI to create the SDKs, and interpreting the basics of the generated SDK.

We also explored automating SDK generation through CI/CD workflows and improving API operations.


 This is the content for the doc openapi/frameworks/gnostic.mdx 

 ---
title: How To Generate an OpenAPI Spec With Gnostic
description: "Take an OpenAPI document and end with a fully functional gRPC server. Create a RESTful gateway to the gRPC server and generate SDKs in multiple languages."
---

import { ScrollyCoding } from "~/components/codehike/Scrollycoding";

# How to generate an OpenAPI/Swagger spec with Gnostic

In this tutorial, we'll start with an OpenAPI document and end with a fully functional gRPC server. We'll also create a RESTful gateway to the gRPC server, and create SDKs in multiple languages.

You might rightfully ask why we would want to do all of this, and there's no better way to illustrate a need than by starting with a real example that is entirely plausible and definitely not made up.

Picture this: You're tasked with setting up an underground bar in the far reaches of the galaxy. Interstellar travelers from far and wide look forward to drinks they've never even dreamt of.

Because this is the far future and, obviously, everyone is still using gRPC, we better set up a gRPC server that can handle billions of requests from light years away. gRPC helps us keep throughput high and latency low—both essential elements of an interstellar API. However, even civilizations that have mastered the Dyson Sphere know better than to use gRPC in the browser and other clients. So we'll need to create an HTTP server to complement our gRPC server. Our users will need SDKs to query our endpoints.

There's no AI in the Laniakea Supercluster of galaxies who'd be willing to code all of this token by token, so let's help them generate as much of this as possible.

We're working with enough acronyms to make our heads spin faster than the neutron star and the space jokes aren't helping.

Let's break this down step by step and park the science fiction for the moment. Here's what we'll do:

1. Create an OpenAPI document describing our API.
2. Set up a development environment using Docker and dev containers.
3. Install a handful of dependencies.
4. Use Gnostic to generate a binary protocol buffer description of our API.
5. Use the Gnostic gRPC plugin to generate an annotated protocol buffer description of our API.
6. Transcode that description to create a gRPC API.
7. Create our server logic as a Go package.
8. Generate a gRPC gateway to handle HTTP requests and pass these to our server.
9. Use Speakeasy to create SDKs in Python and TypeScript.
10. And finally, test all of this by requesting some spectacular drinks.

## Example gRPC and REST API Server Repository

The source code for our complete example is available in the [**Speakeasy gRPC and REST example repository**](https://github.com/speakeasy-api/grpc-rest-service).

This repository already contains all the generated code we'll cover in this tutorial. You can clone it and follow along with the tutorial, or use it as a reference to build your own gRPC and REST API server.

## Creating an OpenAPI Document to Describe an API

As a start, and for the sake of shipping our server, we'll create an API with only two endpoints.

The first endpoint is `createDrink`: Create a new drink based on the provided ingredients and return the drink's name, description, recipe, and possibly a photo.

Our second endpoint is `getDrink`: Create a new drink based only on the drink's name. Return a list of ingredients with quantities, a recipe, and a photo.

<ScrollyCoding className="ch-scrollyCoding-full-height ch-scrollyCoding-force-focus-scroll" fullHeight>

## !!steps

Let's take a detailed tour of our API by exploring `bar.yaml`:

```yaml ! bar.yaml
!from ./assets/gnostic/bar.yaml
```

---

## !!steps

We'll start by creating an OpenAPI 3.0.0 document. Gnostic, unfortunately, only supports OpenAPI 3.0.0, so we'll have to make sure our document is compliant.

```yaml ! bar.yaml
# !mark(1)
```

---

## !!steps

Next, we'll create an info object that describes our API. This object contains the title, version, and description of our API.

```yaml ! bar.yaml
# !focus(3:6)
```

---

## !!steps

Now let's define the servers where our API will be hosted. In this case, we'll have a single server running locally on `http://localhost:8080`.

```yaml ! bar.yaml
# !focus(8:10)
```

---

## !!steps

Next, we'll define the `/create-drink` endpoint. This endpoint will accept a POST request with a JSON body containing the ingredients of the drink.

```yaml ! bar.yaml
# !focus(13:27)
```

---

## !!steps

Our `/create-drink` endpoint will return a JSON object with the drink's name, description, recipe, and possibly a photo.

```yaml ! bar.yaml
# !focus(28:39)
```

---

## !!steps

Next, we'll define the `/get-drink` endpoint. This endpoint will accept a POST request with a JSON body containing the name of the drink.

```yaml ! bar.yaml
# !focus(47:58)
```

---

## !!steps

Our `/get-drink` endpoint will return a JSON object with the ingredients, recipe, and possibly a photo of the drink.

```yaml ! bar.yaml
# !focus(60:79)
```

---

## !!steps

Our first component, `IngredientsRequest`, is a JSON object that contains the ingredients of a drink as an array of strings.

```yaml ! bar.yaml
# !focus(89:104)
```

---

## !!steps

Next up, `DrinkResponse`, is a JSON object that contains the name, description, recipe, and a photo of a drink.

```yaml ! bar.yaml
# !focus(106:126)
```

---

The third component, `DrinkNameRequest`, is a JSON object that contains the name of a drink.

```yaml ! bar.yaml
# !focus(128:137)
```

---

## !!steps

Our fourth component, `DrinkRecipeResponse`, is a JSON object that contains the ingredients, recipe, and a photo of a drink.

```yaml ! bar.yaml
# !focus(139:156)
```

---

## !!steps

Our fifth component, `IngredientQuantity`, is a JSON object that contains the name and quantity of an ingredient.

```yaml ! bar.yaml
# !focus(158:169)
```

---

## !!steps

Finally, `error` is a JSON object that contains an error code and message.

```yaml ! bar.yaml
# !focus(171:181)
```

## !!steps Setting Up a Development Environment

Here, we'll take an opinionated approach to setting up a development environment. We'll use Docker and dev containers in VS Code to ensure that everyone has the same environment and avoid any issues with dependencies.

We'll start by creating a `Dockerfile` in the `.devcontainer` directory. The `Dockerfile` will install all the dependencies we need to generate our gRPC server.

Our development container is based on `mcr.microsoft.com/devcontainers/go` from the Microsoft Dev Container Images repository. The image we'll use has Go version 1.22 and is based on Debian Bookworm.

```docker ! .devcontainer/Dockerfile
!from ./assets/gnostic/Dockerfile.txt
```

---

## !!steps

We'll install Speakeasy using the `install.sh` script from the Speakeasy repository.

```docker ! .devcontainer/Dockerfile focus=3
!from ./assets/gnostic/Dockerfile.txt
```

---

## !!steps

Next, we'll install Gnostic, the Gnostic gRPC plugin, the Go protocol buffer compiler, Buf, the gRPC Go plugin, gRPCurl, and the gRPC gateway plugin.

```docker ! .devcontainer/Dockerfile focus=5:11
!from ./assets/gnostic/Dockerfile.txt
```

---

## !!steps

We'll copy our project files into the container and set the working directory to `/app`.

```docker ! .devcontainer/Dockerfile focus=13:14
!from ./assets/gnostic/Dockerfile.txt
```

---

## !!steps

We'll run `go mod tidy` to ensure all dependencies are up to date.

```docker ! .devcontainer/Dockerfile focus=16
!from ./assets/gnostic/Dockerfile.txt
```

---

## !!steps

Finally, we'll expose port 50051 and run our server.

```docker ! .devcontainer/Dockerfile focus=18:21
!from ./assets/gnostic/Dockerfile.txt
```

</ScrollyCoding>

### Dev Container Configuration

Next, we'll create a `devcontainer.json` file in our `.devcontainer` directory to configure our development container:

```json .devcontainer/devcontainer.json
!from ./assets/gnostic/devcontainer.json
```

For help with the `devcontainer.json` file, check out the [official documentation](https://containers.dev/implementors/json_reference/).

### Docker Compose

We'll also create a `docker-compose.yaml` file in our `.devcontainer` directory to define our development container:

```yaml .devcontainer/docker-compose.yaml
!from ./assets/gnostic/docker-compose.yaml
```

This Docker Compose file defines a service called `app` that uses the `Dockerfile` in the `.devcontainer` directory. It also mounts the current directory into the container at `/app` and overrides the default command to start the server.

We use `/bin/sh -c "while sleep 1000; do :; done"` as the default command to keep the container running while we work on our server. This means we can start the server manually when we're ready.

### Starting the Development Container

For this step, you'll need to have [Docker](https://www.docker.com/get-started) and the [Dev Containers extension](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers) for VS Code installed.

Start the Docker engine and open the project in VS Code. Press F1 to open the command palette, then select `Dev Containers: Reopen in Container`. This will build the development container and open a new VS Code window inside it.

This step might take a while the first time you run it, as it needs to download the base image and install all the dependencies.

### Interacting With the Development Container

Once the development container is running, you can interact with it using the terminal in VS Code. You can run commands as you would in a regular terminal, such as `go run main.go` to start the server later on.

When we refer to running commands in the development container, we mean running them in the dev container terminal in VS Code.

If you think something isn't working as expected, try restarting the development container by running `Dev Containers: Rebuild Container` from the command palette. You may also restart Docker to ensure everything is working as expected.

## Dependencies for Generating a gRPC Server Using Gnostic

To generate a gRPC server using Gnostic, we added the following dependencies to our development container:

- [Gnostic](https://github.com/google/gnostic): A compiler for APIs described by the OpenAPI 3.0.0 specification.
- [Gnostic gRPC plugin](https://github.com/google/gnostic-grpc): A plugin for Gnostic that generates gRPC service definitions.
- [Go protocol buffer compiler](https://pkg.go.dev/github.com/golang/protobuf/protoc-gen-go): A plugin for the protocol buffer compiler that generates Go code.
- [Buf](https://buf.build/): A tool for managing protocol buffer files.
- [gRPC Go plugin](https://pkg.go.dev/google.golang.org/grpc/cmd/protoc-gen-go-grpc): A plugin for the protocol buffer compiler that generates Go gRPC code.
- [gRPCurl](https://github.com/fullstorydev/grpcurl): A command-line tool for interacting with gRPC servers. We'll use this to test our gRPC server.
- [gRPC gateway plugin](https://github.com/grpc-ecosystem/grpc-gateway): A plugin for the protocol buffer compiler that generates a reverse proxy server to translate RESTful HTTP and JSON requests to gRPC.

## Generating a gRPC Server Using Gnostic

To generate a gRPC server using Gnostic, we need to follow these steps:

1. Compile the API definition to a binary protocol buffer file using Gnostic.
2. Create an API definition in a `.proto` file.
3. Generate a gRPC service definition using the Gnostic gRPC plugin.
4. Generate Go code using the Go protocol buffer compiler and the gRPC Go plugin.

We've already completed step 1 by creating the `bar.yaml` file. Now we'll compile the API definition to a binary protocol buffer file using Gnostic.

### Compiling the API Definition to a Binary Protocol Buffer File

This step is necessary because we've found that the Go protocol buffer compiler and the gRPC Go plugin require a binary protocol buffer file as input. To compile the API definition to a binary protocol buffer file, we'll use the following command:

```bash vscode@devcontainer
gnostic --pb-out=. bar.yaml
```

This command compiles the API definition in `bar.yaml` to a binary protocol buffer file named `bar.pb`.

### Creating an API Definition in a `.proto` File

Next, we'll create an API definition in a `.proto` file. We'll use the `bar.pb` file generated in the previous step as input. To accomplish this, we'll use the following command:

```bash vscode@devcontainer
gnostic-grpc -input bar.pb -output .
```

This command generates a `.proto` file named `bar.proto` that contains the gRPC service definition:

```cpp bar.proto
!from ./assets/gnostic/bar.proto
```

### Generating Go Code Using Buf and the gRPC Go Plugin

To set up Buf, we need to run the following command:

```bash vscode@devcontainer
buf mod init
```

This command initializes a new Buf module in the current directory.

Update the `buf.yaml` file created in the project root with the following content:

```yaml buf.yaml
!from ./assets/gnostic/buf.yaml
```

We depend on `googleapis` because the gRPC Go plugin requires it.

<ScrollyCoding className="ch-scrollyCoding-full-height" fullHeight>

## !!steps

Next, create a `buf.gen.yaml` file in the project root with the following content:

```yaml ! buf.gen.yaml
!from ./assets/gnostic/buf.gen.yaml
```

---

## !!steps

We enable managed mode and set the `go_package_prefix` to `github.com/speakeasy-api/grpc-rest-service/bar`.

```yaml ! buf.gen.yaml
!from ./assets/gnostic/buf.gen.yaml
```

---

## !!steps

We also specify the plugins we want to use and where to output the generated code.

```yaml ! buf.gen.yaml
# !focus(9:21)
```

</ScrollyCoding>

Update Buf's dependencies using the following command:

```bash vscode@devcontainer
buf mod update
```

Now we can generate Go code using the following command:

```bash vscode@devcontainer
buf generate
```

This command generates Go code in the `bar` directory. The generated code includes the gRPC service definition and the gRPC gateway definition.

## Implementing the gRPC Server

To implement the gRPC server, we created one big `main.go` with our endpoint implementations and business logic all in one. This will make a lot of people very angry and is widely regarded as a bad move. ([🫡 Douglas Adams](https://www.goodreads.com/quotes/1-the-story-so-far-in-the-beginning-the-universe-was))

To make things slightly more confusing, we're including OpenAI API calls alongside our focus on OpenAPI. The similarities in the names are purely coincidental.

The `main.go` file is too large to include here, but you can find it in the root of the example project.

## Optional: Adding Your OpenAI API Key

If you want to use the OpenAI API to generate drink recipes, you'll need to add your OpenAI API key to the project. Without this key, the server will return placeholder data for the drink recipes.

Copy the `.env.template` file to a new file named `.env`:

```bash vscode@devcontainer
cp .env.template .env
```

Open the `.env` file and add your OpenAI API key:

```bash
OPENAI_API_KEY=your-openai-api-key
```

This file is included in the `.gitignore` file, so it won't be checked into version control.

## Rebuilding the Docker Image

We've installed a bunch of new dependencies and generated a lot of new code. To make sure everything is working as expected, we need to rebuild our Docker image.

This also runs `go mod tidy` to ensure all dependencies are up to date, which can take a while.

In VS Code, press F1 to open the command palette, then select `Dev Containers: Rebuild Container`. This will rebuild the development container and install all the dependencies.

## Running the gRPC Server

To run the gRPC server, we need to start the development container and run the following command:

```bash vscode@devcontainer
go run main.go
```

This command starts the gRPC server on port `50051` and the gRPC gateway on port `8080`.

## Testing the gRPC Server

To test the gRPC server, we'll use the `grpcurl` command-line tool.

First, open a new terminal in VS Code by pressing ⌃⇧`.

This next step will use OpenAI credits, so make sure you have credits available before running the command.

Now run the following command to send a request to the gRPC server:

```bash vscode@devcontainer
grpcurl -plaintext -d '{"drink_name_request": {"name": "Pan Galactic Gargle Blaster"}}' localhost:50051 bar.Bar/GetDrink
```

This command sends a request to the `GetDrink` endpoint with the `name` field set to `Pan Galactic Gargle Blaster`.

The response should look something like this:

```json
{
  "ingredients": [
    {
      "name": "Ol' Janx Spirit",
      "quantity": "1 oz"
    },
    {
      "name": "Water from the seas of Santraginus V",
      "quantity": "0.5 oz"
    },
    {
      "name": "Arcturan Mega-gin",
      "quantity": "1 oz"
    },
    {
      "name": "Fallian marsh gas",
      "quantity": "A gentle bubble"
    },
    {
      "name": "Quantum hyper-mint extract",
      "quantity": "1 teaspoon"
    },
    {
      "name": "Zap powder",
      "quantity": "A pinch"
    },
    {
      "name": "Algolian Suntiger tooth extract",
      "quantity": "1 drop"
    },
    {
      "name": "Galaxy-wide famous Olives",
      "quantity": "1 olive"
    }
  ],
  "recipe": "In a cosmic shaker, mix Ol' Janx Spirit, Arcturan Mega-gin, and water from Santraginus V. Gently add fallian marsh gas to create a mystery bubble. Stir in quantum hyper-mint extract and a pinch of zap powder with a molecular stirrer (mind the speed, or you'll end up in another dimension). Carefully add a single drop of Algolian Suntiger tooth extract, ensuring not to evaporate your mixing vessel. Serve in a glass forged from comets' ice, garnished with a galaxy-wide famous Olive. Be sure to have your propulsion system set to the nearest recovery planet because after one sip, you'll need it.",
  "photo": "https://example.com/photo.jpg"
}
```

The photo URL returned by OpenAI is only valid for an hour, so be sure to open it in a browser to view it.

You may find that the terminal output escapes the JSON response, breaking the photo URL. You can use the following command to unescape the JSON response:

```bash vscode@devcontainer
grpcurl -plaintext -d '{"drink_name_request": {"name": "Pan Galactic Gargle Blaster"}}' localhost:50051 bar.Bar/GetDrink | sed 's/%3A/:/g; s/%2F/\//g; s/%3D/=/g; s/%3F/?/g; s/%26/\&/g' | jq
```

This command uses `sed` to unescape the JSON response and `jq` to format the JSON response.

## Generating SDKs for the gRPC Gateway

To generate a TypeScript SDK for the gRPC gateway, we run the following command:

```bash vscode@devcontainer
speakeasy quickstart
```

Follow the onscreen prompts to provide the necessary configuration details for your new SDK such as the name, schema location and output path. Enter `bar.yaml` when prompted for the OpenAPI document location and select TypeScript when prompted for which language you would like to generate.

To generate a Python SDK for the gRPC gateway, we run the following command:

```bash vscode@devcontainer
speakeasy quickstart
```

Follow the onscreen prompts to provide the necessary configuration details for your new SDK such as the name, schema location and output path. Enter `bar.yaml` when prompted for the OpenAPI document location and select Python when prompted for which language you would like to generate.

Now we have generated SDKs for the gRPC gateway in both TypeScript and Python.


 This is the content for the doc openapi/frameworks/goa.mdx 

 ---
title: "How To Generate an OpenAPI Spec With Goa"
description: "A step-by-step guide to generating an OpenAPI / Swagger spec with Goa and using it to generate an SDK with Speakeasy."
---

import { Callout } from '~/components';

# How to generate an OpenAPI/Swagger spec with Goa

This tutorial explains how to define an application programming interface (API) service written in Go with Goa, convert it to an OpenAPI schema with Goa, and convert that to software development kits (SDKs) in multiple languages with Speakeasy. (OpenAPI used to be known as Swagger, which is now a set of tools that can be used with OpenAPI schemas.)

Below is a graphical summary of the creation process.

```mermaid
    flowchart LR
    design.go --> Goa
    Goa --> api[OpenAPI schema]
    Goa --> cli[Client API CLI]
    Goa --> client[Client Go code]
    Goa --> server[Server Go code]
    api --> Speakeasy
    Speakeasy --> ts[TypeScript SDK]
    Speakeasy --> c[C# SDK]
    Speakeasy --> p[Go SDK]
    Speakeasy --> etc[Other SDKs...]
```

We will talk you through creating a complete code example. By the end of the tutorial, you will have a working API service running in Go that you call through TypeScript code in an SDK.

## Is This Tutorial Right for You?

If you're new to OpenAPI, Go, Goa, or Speakeasy, this is the perfect tutorial to see if they are the appropriate technologies for your service. If you're familiar with Goa, but not with Speakeasy, this is also the right place to start.

But if you want to use your OpenAPI schema as a starting point, and not Go code that is transpiled into a schema, Goa is not the right choice for you. Rather, choose one of the other [Go frameworks](#other-go-openapi-frameworks) below.

You also might want to design your schema without choosing any programming language. In this case, you could start with the [Swagger schema editor](https://swagger.io/tools/swagger-editor/). However, using the elegant Goa design language is a lot simpler than trying to design your schema manually. It also creates all the HTTP and gRPC transport code for you.

## Prerequisites

For this tutorial, you only need Docker version 20 or newer. You can complete this tutorial on Linux, macOS, or Windows since Docker commands are not dependent on your operating system or any installed frameworks.

If you are running on Windows, please replace backslashes with forward slashes in the few places where you specify a folder path on your host machine.

## Introduction to Goa

The [OpenAPI specification](https://spec.openapis.org/oas/latest.html) is a standard that explains how to create a human- and machine-readable schema (`.json` or `.yaml` document) for any API service. (This tutorial refers to the standard as "the OpenAPI Specification", and the definition you create for your service as "your OpenAPI schema", or just "your schema".)

[Goa](https://goa.design/learn/getting-started/) is a package written in the Go language that allows you to define an API in Go syntax using functions from the Goa design language. Goa uses your definition in its `design.go` file to create:

- An OpenAPI schema that can be used by programmers or tools like Speakeasy to understand your API.
- Go code for a client application to call your API.
- A command line interface (CLI) to call your API.
- The transport-agnostic code to provide the API on a server over protocols like HTTP and gRPC.
- Go code stubs for the service itself, which you can complete with business logic.

### Other Go OpenAPI Frameworks

Most other Go frameworks generate code from an existing OpenAPI schema and don't allow you to write Go as a starting point. These include:

- [Deepmap OpenAPI code generator](https://github.com/deepmap/oapi-codegen)
- [Ogen](https://github.com/ogen-go/ogen)
- [Swaggest OpenAPI structures for Go](https://github.com/swaggest/openapi-go)

[Swaggest Rest](https://github.com/swaggest/rest) can generate OpenAPI definitions from Go code, but it's not as comprehensive as Goa and does not support gRPC.

### Is This Related to Tsoa?

[Tsoa](https://github.com/lukeautry/tsoa) is a popular TypeScript framework similar to Goa that you may encounter in the OpenAPI ecosystem. Speakeasy has a [tutorial](/docs/api-frameworks/tsoa) for tsoa, too.

Goa was created in 2015 and tsoa in 2016. While tsoa uses decorators and can work with normal Express code, Goa starts with an abstract design document in its domain-specific language (DSL) and uses that to generate code and schemas.

## Create the API Schema in Goa

Now that you understand how Goa and Speakeasy are used, let's write some code.

### Download the Example Repository

First, clone the [example repository](https://github.com/speakeasy-api/speakeasy-goa-example.git) using the code below. If you don't have Git, you can download the code and unzip it.

```bash
git clone https://github.com/speakeasy-api/speakeasy-goa-example.git;
cd speakeasy-goa-example;
```

While you will create a demonstration application in the `app` folder in this tutorial, there is a folder called `completed_app` in the example repository that has all the final generated code and executable files.

### Google Protocol Buffers

Goa generates [gRPC](https://grpc.io/) code for you. gRPC is an efficient alternative to plain HTTP, over which you can provide your API. It requires the use of protocol buffers, made by Google. Our repository already provides the `protoc` app for you, in `completed_app/lib`.

To use more recent versions of `protoc` in future applications, you can download them from [the Protobuf repository](https://github.com/protocolbuffers/protobuf/releases).

### Set Up Go

First, set up your environment. You'll run a Go Docker container and later you'll install Node.js in it. In a terminal in the `speakeasy-goa-example` folder, run the commands below. Comments in the commands explain what they do.

```bash
mkdir app;
cd app;
cp -r ../completed_app/lib .; # copy protoc into your new app
cp -r ../completed_app/design .; # copy in a simple Goa design file

docker run --name gobox --volume .:/go/src/app -it golang:1.21.2 bash; # start Go in a container and share your app folder with it
```

You now have an `app` folder ready to code in, and you're in a terminal in a Go container called `gobox` in Docker.

<Callout title="Restarting Docker" variant="info">
If you leave this tutorial and return later, you can start the container and attach to the terminal instead of rebuilding everything:

```bash
docker start gobox;
docker exec -it gobox bash;
export PATH=$PATH:/go/src/app/lib;
cd /go/src/app;
```

If you need to delete the container and start over, run:

```bash
docker stop gobox;
docker rm gobox;
```
</Callout>

Run the following commands in the `gobox` terminal.

```bash
cd /go/src/app;
go mod init app; # create a new Go package in this folder called app
go install goa.design/goa/v3/cmd/goa@v3; # install Goa
go install google.golang.org/protobuf/cmd/protoc-gen-go@latest; # install gRPC
go install google.golang.org/grpc/cmd/protoc-gen-go-grpc@latest;
export PATH=$PATH:/go/src/app/lib; # add protoc to your path
```

### Review the Goa Design File

You now have Goa installed and ready to run against a Goa design file. Let's pause to review the API schema in `app/design/design.go`. Open the file now.

After importing Goa, the design starts by defining the top-level API:

```go design.go
    var _ = API("club", func() {
        Title("The Speakeasy Club")
        Version("1.0.0")
        Description("A club that serves drinks and plays jazz. A Goa and Speakeasy example.")
        Contact(func() {
            Name("Speakeasy Support")
            URL("https://speakeasy-dev.slack.com/join/shared_invite/zt-1cwb3flxz-lS5SyZxAsF_3NOq5xc8Cjw")
        })
        Docs(func() {
            Description("The Speakeasy Club documentation")
            URL("https://www.speakeasyapi.dev/docs")
        })
        License(func() {
            Name("Apache 2.0")
            URL("https://www.apache.org/licenses/LICENSE-2.0.html")
        })
        TermsOfService("https://www.speakeasyapi.dev/docs/terms-of-service")
        Server("club", func() {
            Description("club server hosts the band and order services.")
            Services("band", "order")
            Host("dev", func() {
                Description("The development host. Safe to use for testing.")
                URI("http://{machine}:51000") // use the machine variable below
                URI("grpc://{machine}:52000")
                Variable("machine", String, "Machine IP Address", func() {
                    Default("localhost")
                })
            })
        })
        Meta("openapi:extension:x-speakeasy-retries", `{
            "strategy":"backoff",
            "statusCodes": "408,504"
        }`)
    })
```

Note that everything in the Goa DSL is a function. The `API` function takes a function that runs other functions to specify parts of the overall definition of the API, such as `Description`, `Version`, and server endpoints (URLs). To learn all the possible functions Goa provides, read the [DSL documentation](https://pkg.go.dev/goa.design/goa/dsl). To create a simpler, minimal definition, use the [Goa getting started guide](https://goa.design/learn/getting-started/).

The example you create here provides a virtual jazz club, allowing you to order a digital drink and change the genre of music played. These features are defined in two separate services, `order` and `band`. While the `club` API title corresponds to the server URL and is not visible, the service names are visible in the URLs `http://localhost:51000/order` and `http://localhost:51000/band`.

The definitions of the two services are below the API. Let's look at the drinks service.

```go design.go
var _ = Service("order", func() {
	Description("A waiter that brings drinks.")
	Method("tea", func() {
		Description("Order a cup of tea.")
		Payload(func() {
			Field(1, "isGreen", Boolean, "Whether to have green tea instead of normal.")
			Field(2, "numberSugars", Int, "Number of spoons of sugar.")
			Field(3, "includeMilk", Boolean, "Whether to have milk.")
		})
		Result(String)
		HTTP(func() {
			Meta("openapi:tag:Drink operations")
			POST("/tea")
		})
		GRPC(func() {
		})
	})
	Files("/openapi.json", "./gen/http/openapi.json")
})
```

Here you can see we've defined a single POST method called `tea` in the `order` service. The `tea` method takes a few parameters about how you like your milk and sugar and returns a string representing a cup of tea.

Note that an HTTP GET method won't accept a complex method body, so you have to use POST for any calls other than simple URL IDs.

#### Encapsulate With References

Goa automatically moves complex types out of the service definition section and into their own section in the schema. For example, in the generated OpenAPI specification file, the line `$ref: '#/components/schemas/TeaRequestBody'` refers the order specification for tea to the `components` section later in the document using the JSON [references](https://swagger.io/docs/specification/using-ref) feature.

#### Rename With Custom operationIds

If you can't find a function in the Goa documentation that corresponds to an OpenAPI field you are expecting, you can probably add it with the [`Meta`](https://pkg.go.dev/goa.design/goa/dsl#Meta) function. The `Meta` function will add a field and value to any object.

For example, here's how you can change the default `operationId` value for a method, which is normally `serviceName#methodPath`:

```go
Method("play", func() {
  Meta("openapi:operationId", "band#play2")
```

An `operationId` is a unique name to clearly identify an operation (method). They are useful to name and discuss operations in documentation and SDKs.

#### Group Operations With Tags

Speakeasy recommends adding [tags](https://swagger.io/docs/specification/grouping-operations-with-tags/) to all operations so that you can group operations by tag in generated SDK code and documentation. A tag is just a label, like a comment, that you can add to a method.

The [`Tag`](https://pkg.go.dev/goa.design/goa/dsl#Tag) function in Goa has a different meaning than it does in OpenAPI, so you need to use the `Meta` function again in the `HTTP` section of a method.

```go
var _ = Service("band", func() {
	Method("play", func() {
		HTTP(func() {
			Meta("openapi:tag:Music operations")
```

### Generate the API Code With Goa

Generate the client and server code and your OpenAPI schema from your design file by running the commands below in the `gobox` container.

```bash
goa gen app/design;
goa example app/design;
```

The files created in the container will belong to the root user, and you will not be able to edit them on your host. In a terminal on your host machine, go to the `app` folder and give yourself permissions to edit the created files:

```bash
sudo chown -R $(id -u):$(id -g) .
```

Rerun this whenever you create a file in the container.

#### Explore the Generated Files

Goa has written a lot of code for us. Below is everything created under `app` and what it does. To avoid duplication, there is only an explanation for the band files and not for the order files, because they are services with identical structures.

The following files and folders are created by `goa gen`, and you may regenerate them when your `design.go` file changes. You may not edit them manually.

- `/gen` — Contains all definition and communication code for HTTP, gRPC, and schemas. Think of the `gen` folder as your `definitions` folder.
- `/gen/band` — Contains transport independent service code.
- `/gen/band/client.go` — Can be imported by client code to make calls to the server.
- `/gen/band/endpoints.go` — Exposes the service code to the transport layers.
- `/gen/grpc` — Contains the server and client code that connects the `protoc`-generated gRPC server and client code, along with the logic to encode and decode requests and responses.
- `/gen/grpc/band/pb` — Contains the protocol buffer files that describe the band gRPC service.
- `/gen/grpc/band/pb/goagen_app_band_grpc.pb.go` — The output of the `protoc` tool.
- `/gen/grpc/cli` — Contains the CLI code to build gRPC requests from a terminal.
- `/gen/http` — All HTTP-related transport code, for server and client.
- `/gen/http/openapi3.yaml` — The OpenAPI version 3 schema (next to `.json` and version 1 schemas).

The following files and folders are created by `goa example` and you can use them as a starting point to write business logic implementation and tests for your server. You **should not** regenerate these files when your `design.go` file changes, rather update them manually. If you haven't started work on your implementation yet and do wish to regenerate the files, delete the existing files first to be certain that Goa recreates them.

- `/cmd` — Contains working placeholder server and CLI code. Think of the `cmd` folder as your `implementation` folder.
- `/cmd/club` — A Go package containing your API that you can compile and run to have a working server.
- `/cmd/club/main.go` — The server implementation that you can change to your liking. Add your favorite logger and database manager here.
- `/cmd/club-cli` — A Go package containing a CLI tool that you can compile and call from the terminal to make requests to the server above.
- `band.go` — A placeholder implementation of your service. You can write your business logic here. You might think this file belongs in the `/cmd/club` folder with the API implementation instead of in the root of the project, but Goa puts the API implementation in the `cmd` folder and all service implementations in the root.

Take a little time to review `/gen/http/openapi3.yaml` and see how your `design.go` functions map to the generated YAML.

### Run the Server and CLI

Goa has given us a simple working client and server implementation. Let's compile and test them before starting with Speakeasy.

Run the code below in the container.

```bash
go get app/cmd/club; # download dependencies
go build ./cmd/club && go build ./cmd/club-cli; # build the server
./club; # start the server
```

You now have two executable files called `club` and `club-cli` in the `app` folder. The Club server is running inside Docker. The output should look like this:

```bash
[club] 16:20:55 HTTP "Play" mounted on POST /play
[club] 16:20:55 HTTP "./gen/http/openapi.json" mounted on GET /openapi.json
[club] 16:20:55 HTTP "Tea" mounted on POST /tea
[club] 16:20:55 HTTP "./gen/http/openapi.json" mounted on GET /openapi.json
[club] 16:20:55 serving gRPC method band.Band/Play
[club] 16:20:55 serving gRPC method order.Order/Tea
[club] 16:20:55 HTTP server listening on "localhost:51000"
[club] 16:20:55 gRPC server listening on "localhost:52000"
```

Open another terminal on your host machine and log in to a new Docker terminal:

```bash
docker exec -it gobox bash;
cd /go/src/app;
./club-cli --help; # see if you can call the server from a CLI client
./club-cli order tea --body '{"includeMilk": false, "isGreen": false, "numberSugars": 1 }';
./club-cli band play --body '{"style": "Bebop" }';
```

While the CLI won't receive a response from the server because the implementation is just a placeholder, you can see in the server terminal that it has been successfully called.

## Customize With Speakeasy Extensions

OpenAPI supports fields that are not in the specification. These [extensions](https://swagger.io/docs/specification/openapi-extensions/) allow you to add custom data to your schema that might have special meaning to applications like Speakeasy. They start with `x-`.

Speakeasy provides a set of [OpenAPI extensions](/docs/customize-sdks). For example, you may want to give an SDK method a name different from the `operationId`:

```go
Method("tea", func() {
  Meta("openapi:extension:x-speakeasy-name-override", "chai")
```

### Retry Calling the Server

Speakeasy provides a schema extension called [retries](https://www.speakeasyapi.dev/docs/customize-sdks/retries) that will create an SDK that automatically retries calling the server if a call fails.

In `design.go`, retries for timeout errors are enabled for the entire API rather than for an individual service or method. For example, this code:

```go
Meta("openapi:extension:x-speakeasy-retries", `{
	"strategy":"backoff",
	"statusCodes": "504,408"
}`)
```

Will produce this OpenAPI YAML:

```yaml
x-speakeasy-retries:
	statusCodes: 408,504
	strategy: backoff
```

Note that the `Meta` function had to use JSON syntax in the value to output an extension object with sub-properties.

## Create SDKs With Speakeasy

Before continuing with this tutorial, please register at https://app.speakeasy.com. Once you've registered, create a workspace named `club`. Browse to API keys. Click "New Api Key". Name it `club`. Copy and save the key content to use later.

### Set Up the Speakeasy CLI

The CLI is the simplest way to use Speakeasy. This tutorial uses Docker, but if you want to install Speakeasy directly on your computer in the future, follow the instructions in the [readme](https://github.com/speakeasy-api/speakeasy#installation).

Run the commands below in the second terminal to `gobox` that you used to log in to a new Docker terminal. Use the API key you saved earlier in the last line.

```bash
apt update;
apt install -y curl unzip sudo nodejs npm; # install dependencies
curl -fsSL https://go.speakeasy.com/cli-install.sh | sh; # install Speakeasy
export SPEAKEASY_API_KEY=your_api_key_here; # <-- overwrite this with your key
```

Now Speakeasy is installed in the container. Test it by running:

```bash
speakeasy help;
```

### Build an SDK

You now have `app/gen/http/openapi3.yaml` and Speakeasy, so you can build the SDK. In the container terminal, run:

```bash
speakeasy generate sdk --schema /go/src/app/gen/http/openapi3.yaml --lang typescript --out /go/src/app/sdk
```

The output should be:

```bash
Authenticated with workspace successfully - https://app.speakeasy.com/workspaces/
Generating SDK for typescript...
INFO	operation valid	{"operation":"band#/openapi.json","type":"paths"}
INFO	operation valid	{"operation":"band#play","type":"paths"}
INFO	operation valid	{"operation":"order#tea","type":"paths"}
Generating SDK for typescript... done ✓.
For more docs on customizing the SDK check out: https://www.speakeasyapi.dev/docs/customize-sdks
```

Remember to give yourself permissions to the files on your host machine in another terminal:

```bash
sudo chown -R $(id -u):$(id -g) .
```

<Callout title="SDK Languages" variant="info">
While you're using only TypeScript in this tutorial, Speakeasy supports [C#, Go, Java, PHP, Python, Ruby, Swift, and TypeScript](/docs/create-client-sdks#language-support).
</Callout>

#### Explore the Generated Files

The root of the Speakeasy-generated `sdk` folder contains various npm files. Importantly, the `package.json` file lists the dependencies you need to install before you can run the SDK. The `docs` folder contains your SDK documentation in Markdown files. The `src` folder contains the SDK code.

### Call Your Service With the SDK

We'll implement the documentation example in `sdk/docs/sdks/drinkoperations/README.md`.

Make a file called `test.js` in the `app/sdk` folder. Insert the code below.

```js
const SDK = require("./dist/index");

(async() => {
  const sdk = new SDK.SDK();

  const res = await sdk.drinkOperations.orderNumberTea({
    includeMilk: true,
    isGreen: false,
    numberSugars: 1584355970564842800,
  });

  if (res.statusCode == 200) {
    console.log('A nice cup of tea');
  }
})();
```

In the container terminal, install the npm dependencies and run the test file.

```bash
cd /go/src/app/sdk;
npm install;
npx tsc --build;
node test.js;
```

In the first terminal where your `club` server is still running, you should see that the server has received a request. In the second terminal, you should see it receive `A nice cup of tea`.

## Next Steps

You now know how to make an OpenAPI-compliant web service from a Goa design specification, and how to generate SDKs for it using Speakeasy. 

### Get Help With Advanced Goa

If you want to build a more complex API and need help understanding Goa, read the full [design language specification](https://pkg.go.dev/goa.design/goa/dsl).

You can also use the Go Slack group to ask for help:

- Register for the group at https://invite.slack.golangbridge.org.
- Log in at https://gophers.slack.com.
- Join the Goa channel to ask questions about the framework.

Perhaps the easiest way to find out how to do something (especially when using `Meta`) is to search the test cases when you have cloned the [source code](https://github.com/goadesign/goa).

### Use Speakeasy Customizations

Review the [Speakeasy customizations](https://www.speakeasyapi.dev/docs/customize-sdks) to see if adding any would make your service more understandable or usable.


 This is the content for the doc openapi/frameworks/grpc-gateway.mdx 

 ---
title: How To Generate an OpenAPI Spec With gRPC Gateway
description: "How to create OpenAPI schemas and great SDKs for your gRPC server"
---

import { CodeWithTabs } from "~/components/codehike/CodeTabs";
import { ScrollyCoding } from "~/components/codehike/Scrollycoding";
import { Callout } from "~/components";

# How to generate an OpenAPI/Swagger spec with gRPC Gateway

You may want to provide a RESTful API in addition to your gRPC service without the need to duplicate your code.

[gRPC Gateway](https://grpc-ecosystem.github.io/grpc-gateway/) is a popular tool for generating RESTful APIs from gRPC service definitions.

In this tutorial, we'll take a detailed look at how to use gRPC Gateway to generate an OpenAPI schema based on a Protocol Buffers (protobuf) gRPC service definition. Afterward, we can use Speakeasy to read our generated OpenAPI schema and create a production-ready SDK.

<Callout title="TIP" variant="success">
  If you want to follow along, you can use the [**gRPC Speakeasy Bar example
  repository**](https://github.com/speakeasy-api/speakeasy-grpc-gateway-example).
</Callout>

## An Overview of gRPC Gateway

[gRPC Gateway](https://grpc-ecosystem.github.io/grpc-gateway/) is a [protoc](https://github.com/protocolbuffers/protobuf) plugin that reads gRPC service definitions and generates a reverse proxy server that translates a RESTful JSON API into gRPC.

This way, you can expose an HTTP endpoint that can be called by clients that don't support gRPC. The generated server code will forward incoming JSON requests to your gRPC server and translate the responses to JSON.

gRPC Gateway also generates an OpenAPI schema that describes your API. You can use this schema to create SDKs for your API.

## OpenAPI Versions

gRPC Gateway outputs OpenAPI 2.0, and Speakeasy supports OpenAPI 3.0 and 3.1. To generate an OpenAPI 3.0 or 3.1 schema, you'll need to convert the OpenAPI 2.0 schema to at least OpenAPI 3.0.

## The Protobuf to REST SDK Pipeline

To generate a REST API with a developer-friendly SDK, we'll follow these three core steps:

1. **gRPC to OpenAPI:** First, we will use gRPC Gateway to produce an OpenAPI schema based on our protobuf service definition. This generated schema is in OpenAPI 2.0 format.

2. **OpenAPI 2.0 to OpenAPI 3.x:** Next, as gRPC Gateway's output schema is in OpenAPI 2.0 and we need at least OpenAPI 3.0 for our SDK, we will convert the generated schema from OpenAPI 2.0 to OpenAPI 3.0.

3. **OpenAPI 3.x to SDK:** Finally, once we have the OpenAPI 3.0 schema, we will leverage Speakeasy to create our SDK based on the OpenAPI 3.0 schema derived from the previous steps.

By following these steps, we can ensure we have a robust, production-ready SDK that adheres to our API's specifications.

## Step-by-Step Tutorial: From Protobuf to OpenAPI to an SDK

Now let's walk through generating an OpenAPI schema and SDK for our Speakeasy Bar gRPC service.

### Check Out the Example Repository

If you would like to follow along, start by cloning the example repository:

```bash Terminal
git clone git@github.com:speakeasy-api/speakeasy-grpc-gateway-example.git
cd speakeasy-grpc-gateway-example
```

### Install Go

To generate an OpenAPI schema from a protobuf file, we'll need to install Go and protoc.

This tutorial was written using Go 1.21.4.

On macOS, install Go by running:

```bash Terminal
brew install go
```

Alternatively, follow the [Go installation instructions](https://go.dev/doc/install) for your platform.

### Install Buf

We'll use the [Buf CLI](https://buf.build/) as an alternative to protoc so that we can save our generation configuration as YAML. Buf is compatible with protoc plugins.

On macOS, install Buf by running:

```bash Terminal
brew install bufbuild/buf/buf
```

Alternatively, follow the [Buf CLI installation instructions](https://buf.build/docs/installation) for your platform.

### Install Buf Modules

We'll use Buf modules to manage our dependencies.

```bash Terminal
cd proto
buf mod update
cd ..
```

### Install protoc-gen-go

Buf requires the `protoc-gen-go` plugin to generate Go code from protobuf files.

Install `protoc-gen-go` by running:

```bash Terminal
go install google.golang.org/protobuf/cmd/protoc-gen-go@latest
```

Make sure that the `protoc-gen-go` binary is in your `$PATH`. On macOS, you can achieve that by running the following command if the `go/bin` directory is not already in your path.

```bash Terminal
export PATH=${PATH}:`go env GOPATH`/bin
```

### Install Go Requirements

```bash Terminal
go mod tidy
go install \
    github.com/grpc-ecosystem/grpc-gateway/v2/protoc-gen-grpc-gateway \
    github.com/grpc-ecosystem/grpc-gateway/v2/protoc-gen-openapiv2 \
    google.golang.org/protobuf/cmd/protoc-gen-go \
    google.golang.org/grpc/cmd/protoc-gen-go-grpc
```

### Generate the Go Code

We'll use Buf to generate the Go code from the protobuf file.

Run the following in the terminal:

```bash Terminal
buf generate
```

Buf reads the configuration in `buf.gen.yaml`, then generates the Go code in the `proto` directory.

This will generate the `proto/speakeasy/v1/speakeasy.pb.go`, `proto/speakeasy/v1/speakeasy_grpc.pb.go`, and `proto/speakeasy/v1/speakeasy.pb.gw.go` files.

### Generate the OpenAPI Schema

Because we have the `openapiv2` protoc plugin configured in our `buf.gen.yaml` file, Buf will generate an OpenAPI schema and save it as `openapi/speakeasy/v1/speakeasy.swagger.json`.

This is the OpenAPI 2.0 schema that gRPC Gateway generates by default.

### Convert the OpenAPI Schema to OpenAPI 3.0

We'll use the excellent [kin-openapi](https://github.com/getkin/kin-openapi) Go library to convert the OpenAPI 2.0 schema to OpenAPI 3.0.

In `convert/convert.go`, we use `kin-openapi` to unmarshal `openapi/speakeasy/v1/speakeasy.swagger.json`, then convert it to OpenAPI 3.0, then marshal it back to JSON, and finally write it to `openapi/speakeasy/v1/speakeasy.openapi.json`.

To do the conversion, run the following in the terminal:

```bash Terminal
go run convert/convert.go
```

## How To Customize the API Schema

By modifying the protobuf service definition, we can customize the generated OpenAPI schema.

We'll start with a basic example and add options to enhance the schema.

<ScrollyCoding fullHeight>

## !!steps Meet the Speakeasy Bar Protobuf Service

We'll start by taking a look at the Speakeasy Bar protobuf service definition in `proto/speakeasy/v1/speakeasy.proto`.

```cpp ! proto/speakeasy/v1/speakeasy.proto
!from ./assets/grpc/speakeasy-raw.proto
```

---

## !!steps

The service defines one object type, called `Drink`.

```cpp ! proto/speakeasy/v1/speakeasy.proto
// !focus(9:32)
```

---

## !!steps

A service called `SpeakeasyService` has two methods, `GetDrink` and `ListDrinks`.

```cpp ! proto/speakeasy/v1/speakeasy.proto
// !focus(42:59)
```

---

## !!steps Add API Information to the Service

We'll add information about the API to the service definition using `options.openapiv2_swagger` from `grpc.gateway.protoc_gen_openapiv2`.

```cpp ! proto/speakeasy/v1/speakeasy.proto
// !focus(10:26)
```

---

## !!steps

We'll add a title, description, and version to the API.


```cpp ! proto/speakeasy/v1/speakeasy.proto
// !focus(11:15)
```

---

## !!steps

This appears in the `info` object in the generated OpenAPI schema.

```json !! openapi/speakeasy/v1/speakeasy.openapi.json(generated)
!from ./assets/grpc/speakeasy.openapi.json
```

---

## !!steps

We'll add a server to the API using the `host` key.

Our conversion script will add the `servers` object to the generated OpenAPI schema.

```cpp ! proto/speakeasy/v1/speakeasy.proto focus=16
!from ./assets/grpc/speakeasy.proto
```

---

## !!steps

Our conversion script will add the `servers` object to the generated OpenAPI schema.

```json !! openapi/speakeasy/v1/speakeasy.openapi.json(generated) focus=222:226
!from ./assets/grpc/speakeasy.openapi.json
```

---

## !!steps Add Descriptions and Examples to Components

To create an SDK that offers a great developer experience, we recommend adding descriptions and examples to all fields in OpenAPI components.

We'll start with the `Drink` object type.

```cpp ! proto/speakeasy/v1/speakeasy.proto focus=29:35
!from ./assets/grpc/speakeasy.proto
```

---

## !!steps

We added a `title`, `description`, and `example` to the `Drink` object type.

Note that the `example` is a stringified JSON object.

```cpp ! proto/speakeasy/v1/speakeasy.proto focus=29:35 mark=34
!from ./assets/grpc/speakeasy.proto
```

---

## !!steps

We use `openapiv2_field` to add options to the fields in the `Drink` object type.

For example, we added a `description`, `pattern`, format, and `example` to the `productCode` field.

```cpp !! proto/speakeasy/v1/speakeasy.proto focus=74:79
!from ./assets/grpc/speakeasy.proto
```

---

```json !! openapi/speakeasy/v1/speakeasy.openapi.json(generated) focus=66:72
!from ./assets/grpc/speakeasy.openapi.json
```

---

## !!steps

If you use Speakeasy to create an SDK, this description and example will appear in the generated documentation and usage examples.

This usage example is from the TypeScript SDK's documentation.

Note how the `productCode` field is represented by our UUID example instead of a random string.

```typescript ! sdk/docs/sdks/drinks/README.md(generated)
// !mark(7)
import { SDK } from "openapi";

(async() => {
  const sdk = new SDK();

  const res = await sdk.drinks.getDrink({
    productCode: "602a7da9-b8bb-46e6-b288-457b561029b8",
  });

  if (res.statusCode == 200) {
    // handle response
  }
})();
```

---

## !!steps Customize the OperationId

By default, the `operationId` is the method name in the protobuf service definition.

We can customize the `operationId` for each method using `options.openapiv2_operation`.

```cpp ! proto/speakeasy/v1/speakeasy.proto focus=105
!from ./assets/grpc/speakeasy.proto
```

---

```json ! openapi/speakeasy/v1/speakeasy.openapi.json(generated) focus=122
!from ./assets/grpc/speakeasy.openapi.json
```

---

## !!steps Add Descriptions and Tags to Methods

We can add descriptions and tags to methods using `options.openapiv2_operation`.

```cpp !! proto/speakeasy/v1/speakeasy.proto focus=106
!from ./assets/grpc/speakeasy.proto
```

---

```json !! openapi/speakeasy/v1/speakeasy.openapi.json(generated) focus=219:226
!from ./assets/grpc/speakeasy.openapi.json
```

---

## !!steps Add Tag Descriptions

We can add descriptions to tags in the protobuf definition by using `options.openapiv2_swagger`.

In the code example, we added a description to the `drinks` tag.

```cpp ! proto/speakeasy/v1/speakeasy.proto focus=22:25
!from ./assets/grpc/speakeasy.proto
```

---

```json ! openapi/speakeasy/v1/speakeasy.openapi.json(generated) focus=221
!from ./assets/grpc/speakeasy.openapi.json
```

---

## !!steps Add OpenAPI Extensions

gRPC Gateway allows us to add OpenAPI extensions to the OpenAPI schema using the `extensions` key in our protobuf service definition.

For example, we can add the [Speakeasy retries extension](/docs/customize-sdks/retries) `x-speakeasy-retries`, which will cause the SDK to retry failed requests.

In the code example, we added the `x-speakeasy-retries` extension to the `GetDrink` method.

```cpp ! proto/speakeasy/v1/speakeasy.proto focus=120:179
!from ./assets/grpc/speakeasy.proto
```

---

```json ! openapi/speakeasy/v1/speakeasy.openapi.json(generated) focus=200:209
!from ./assets/grpc/speakeasy.openapi.json
```

</ScrollyCoding>

## Create an SDK With Speakeasy

Now that we have an OpenAPI 3.0 schema, we can create an SDK with Speakeasy. Speakeasy will create documentation and usage examples based on the descriptions and examples we added.

We'll use the `speakeasy quickstart` command to create an SDK for the Speakeasy Bar gRPC service.

Run the following in the terminal:

```bash Terminal
speakeasy quickstart
```

Follow the onscreen prompts to provide the necessary configuration details for your new SDK such as the name, schema location and output path. Enter `openapi/speakeasy/v1/speakeasy.openapi.json` when prompted for the OpenAPI document location and select TypeScript when prompted for which language you would like to generate.

## Example Protobuf Definition and SDK Generator

The source code for our complete example is available in the [**gRPC Speakeasy Bar example repository**](https://github.com/speakeasy-api/speakeasy-grpc-gateway-example).

The repository contains a TypeScript SDK and instructions on how to create more SDKs.

You can clone this repository to test how changes to the protobuf definition result in changes to the SDK.

After modifying your protobuf definition, you can run the following in the terminal to create a new SDK:

```bash Terminal
buf generate && go run convert/convert.go && speakeasy quickstart
```

Happy generating!


 This is the content for the doc openapi/frameworks/hono.mdx 

 ---
title: How to generate an OpenAPI document with Hono
description: "Learn how to create an OpenAPI document for your Hono API and use it to automatically generate and customize SDKs."
---

import { Callout } from "~/components";

# How to generate an OpenAPI document with Hono

This guide walks you through generating an OpenAPI document for a [Hono](https://hono.dev/) API and using Speakeasy to create an SDK based on the generated document.

Here's what we'll do:

1. Add Zod OpenAPI and Scalar UI to a Node.js Hono project.
2. Generate an OpenAPI document using the Zod OpenAPI Hono middleware.
3. Improve the generated OpenAPI document to prepare it for code generation.
4. Use the Speakeasy CLI to generate an SDK based on the OpenAPI document.
5. Add Speakeasy OpenAPI extensions to improve the generated SDK.

We'll also take a look at how you can use the generated SDK.

Your Hono project might not be as simple as our example app, but the steps below should translate well to any Hono project.

## The OpenAPI creation pipeline

[Zod OpenAPI](https://hono.dev/examples/zod-openapi#zod-openapi) is Hono middleware that allows you to validate values and types using [Zod](https://zod.dev/) and generate an OpenAPI document. We'll begin by defining data schemas with Zod, then set up the Hono app to generate an OpenAPI document.

The quality of your OpenAPI document determines the quality of generated SDKs and documentation, so we'll look into ways you can improve the generated document based on the Speakeasy [OpenAPI best practices](/docs/best-practices).

We'll then use the improved OpenAPI document to generate an SDK using Speakeasy.

Finally, we'll use a simplified example to demonstrate how to use the generated SDK and how to add SDK creation to a CI/CD pipeline so that Speakeasy automatically generates fresh SDKs whenever your Hono API changes in the future.

## Requirements

This guide assumes that you have an existing Hono app and basic familiarity with Hono.

<Callout title="Example repository" variant="info">
If you don't have a Hono app, or you want to follow along step-by-step, you can clone the [Speakeasy Hono example repo](https://github.com/speakeasy-api/hono-openapi-example.git) to access the example code used in this tutorial. The `initial-app` branch has the initial state of the app that we'll use to start this tutorial.
</Callout>

The following should be installed on your machine:

- [Node.js version 18 or above](https://nodejs.org/en/download) (we used Node v20.18.0), which the Hono Node.js Adapter requires.
- The [JS-YAML](https://www.npmjs.com/package/js-yaml) package, which we'll use to convert the OpenAPI document to a YAML file.
- The [Speakeasy CLI](/docs/speakeasy-cli/getting-started), which we'll use to generate an SDK from the OpenAPI document.

If you're using the [example application](https://github.com/speakeasy-api/hono-openapi-example.git), add a `.env` file containing the following environment variables to the root of your project:

```env
NODE_ENV=development
PORT=3000
```

## Adding the Zod OpenAPI middleware to a Hono project

We'll use the [Zod OpenAPI Hono](https://hono.dev/examples/zod-openapi) middleware to generate an OpenAPI document. We'll create Zod schemas to validate values and types and to generate part of the OpenAPI document.

### Creating Zod schemas

First, install the middleware and Zod:

```bash Terminal
npm i zod @hono/zod-openapi
```

Next, create a `schemas.ts` file in the `src` folder and create Zod schemas for your data:

```typescript schema.ts
import { z } from '@hono/zod-openapi';

export const UserInsertSchema = z
  .object({
    name: z.string(),
    age: z.number(),
  });

export const UserSelectSchema = z
  .object({
    id: z.string(),
    name: z.string(),
    age: z.number()
    ,
  });

export const patchUserSchema = UserInsertSchema.partial();
```

The `z` object should be imported from `@hono/zod-openapi`.

Create schemas for your request-query parameters, messages, and error responses:

```typescript schema.ts
export const idParamsSchema = z.object({
  id: z
    .string()
    .min(3),
});

export function createMessageObjectSchema(exampleMessage: string = 'Hello World') {
  return z.object({
    message: z.string(),
  });
}

export function createErrorSchema<
  T extends ZodSchema,
>(schema: T) {
  const { error } = schema.safeParse(
    schema._def.typeName
    === z.ZodFirstPartyTypeKind.ZodArray
      ? []
      : {},
  );
  return z.object({
    success: z.boolean(),
    error: z
      .object({
        issues: z.array(
          z.object({
            code: z.string(),
            path: z.array(
              z.union([z.string(), z.number()]),
            ),
            message: z.string().optional(),
          }),
        ),
        name: z.string(),
      }),
  });
}
```

Create a `types.ts` file in the `src/lib` folder and add the `ZodSchema` type to it:

```typescript types.ts
import type { z } from '@hono/zod-openapi';

// eslint-disable-next-line ts/ban-ts-comment
// @ts-expect-error
export type ZodSchema = z.ZodUnion | z.AnyZodObject | z.ZodArray<z.AnyZodObject>;
```

Import this type in the `src/schemas.ts` file.

```typescript schemas.ts
import type { ZodSchema } from './lib/types';
```

### Replacing the `Hono` instances with `OpenAPIHono`

Set up your app to use the `OpenAPIHono` instance of the Zod OpenAPI middleware instead of the `Hono` instance. Import the `OpenAPIHono` class in the `src/lib/createApp.ts` file:

```typescript createApp.ts
import { OpenAPIHono } from '@hono/zod-openapi';
```

Remove the `Hono` import and replace the `Hono` instances with `OpenAPIHono`:

```diff createApp.ts
- return new Hono({ strict: false });
+ return new OpenAPIHono({ strict: false });
```

```diff createApp.ts
- const app = new Hono({ strict: false });
+ const app = new OpenAPIHono({ strict: false });
```

The `OpenAPIHono` class is an extension of the `Hono` class that gives `OpenAPIHono` its OpenAPI document-generation functionality.

### Defining routes

Let's split the routes and handlers into separate files for better code organization.

Create a `users.routes.ts` file in the `src/routes/users` folder and use the Zod OpenAPI `createRoute` method to define your routes:

```typescript users.routes.ts
import { createRoute, z } from '@hono/zod-openapi';

import { createErrorSchema, createMessageObjectSchema, idParamsSchema, patchUserSchema, UserInsertSchema, UserSelectSchema } from '@/schemas';

export const list = createRoute({
  path: '/users',
  method: 'get',
  responses: {
    200: {
      content: {
        'application/json': {
          schema: z.array(UserSelectSchema),
        },
      },
      description: 'The list of users',
    },
  },
});

export const create = createRoute({
  path: '/users',
  method: 'post',
  request: {
    body: {
      content: {
        'application/json': {
          schema: UserInsertSchema,
        },
      },
      description: 'The user to create',
      required: true,
    },
  },
  responses: {
    200: {
      content: {
        'application/json': {
          schema: UserSelectSchema,
        },
      },
      description: 'The created user',
    },
    404: {
      content: {
        'application/json': {
          schema: createMessageObjectSchema('Not Found'),
        },
      },
      description: 'User not found',
    },
    422: {
      content: {
        'application/json': {
          schema: createErrorSchema(patchUserSchema),
        },
      },
      description: 'The validation error(s)',
    },
  },
});

export const getOne = createRoute({
  path: '/users/{id}',
  method: 'get',
  request: {
    params: idParamsSchema,
  },
  responses: {
    200: {
      content: {
        'application/json': {
          schema: UserSelectSchema,
        },
      },
      description: 'The requested user',
    },
    404: {
      content: {
        'application/json': {
          schema: createMessageObjectSchema('Not Found'),
        },
      },
      description: 'User not found',
    },
    422: {
      content: {
        'application/json': {
          schema: createErrorSchema(patchUserSchema),
        },
      },
      description: 'Invalid id error',
    },
  },
});

export type ListRoute = typeof list;
export type CreateRoute = typeof create;
export type GetOneRoute = typeof getOne;
```

The `createRoute` function takes in an object that describes the route's request and possible responses. The Zod schema defines the request and response content. The route types are then exported for use in the route handlers.

### Defining route handlers

Create a `users.handlers.ts` file in the `src/routes/users` folder and add the following route handlers to it:

```typescript users.handlers.ts
import type { AppRouteHandler } from '@/lib/types';
import type { CreateRoute, GetOneRoute, ListRoute } from '@/routes/users/users.routes';

export const list: AppRouteHandler<ListRoute> = async (c) => {
  // Add db query to get all users
  return c.json([{
    age: 42,
    id: '123',
    name: 'John Doe',
  }, {
    age: 32,
    id: '124',
    name: 'Sarah Jones',
  }], 200);
};

export const create: AppRouteHandler<CreateRoute> = async (c) => {
  const user = c.req.valid('json');
  console.log({ user });
  // Add db query create a user
  return c.json({
    age: 42,
    id: '2342',
    name: 'John Doe',
  }, 200);
};

export const getOne: AppRouteHandler<GetOneRoute> = async (c) => {
  const { id } = c.req.valid('param');
  // Add db query to get a user by id
  const foundUser = {
    age: 50,
    id,
    name: 'Lisa Smith',
  };

  if (!foundUser) {
    return c.json(
      {
        message: 'Not found',
      },
      404,
    );
  }
  return c.json(foundUser, 200);
};
```

Add the following `AppRouteHandler` type to the `src/lib/types.ts` file:

```typescript types.ts
import type { RouteConfig, RouteHandler } from '@hono/zod-openapi';

export type AppRouteHandler<R extends RouteConfig> = RouteHandler<R>;
```

The handlers are made type safe by the route types. The request and response data in the Hono [context object](https://hono.dev/docs/api/context) is type checked using the schema defined in the routes. If you use an incorrect type, for example setting `age:` to `42`, you'll get a type error.

### Configuring the middleware for each endpoint

Replace the code in the `src/routes/users/users.index.ts` file with the following lines of code:

```typescript users.index.ts
import { createRouter } from '@/lib/createApp';

import * as handlers from './users.handlers';
import * as routes from './users.routes';

const router = createRouter()
  .openapi(routes.list, handlers.list)
  .openapi(routes.create, handlers.create)
  .openapi(routes.getOne, handlers.getOne);

export default router;
```

The `openapi` method takes the route and the handler as its arguments and configures the Zod OpenAPI middleware for each endpoint on the `OpenAPIHono` instance

## Configuring and generating the OpenAPI document

Create a file called `configureOpenAPI.ts` in the `src/lib` folder and add the following lines of code to it:

```typescript configureOpenAPI.ts
import type { OpenAPIHono } from '@hono/zod-openapi';
import packageJson from '../../package.json';

export const openAPIObjectConfig = {
  openapi: '3.1.0',
  externalDocs: {
    description: 'Find out more about Users API',
    url: 'www.example.com',
  },
  info: {
    version: packageJson.version,
    title: 'Users API',
  },
};

export default function configureOpenAPI(app: OpenAPIHono) {
  app.doc31('/doc', openAPIObjectConfig);
}
```

The `configureOpenAPI` function takes in an `OpenAPIHono` instance and uses the `doc31` method to generate an OpenAPI document based on the OpenAPI Specification version 3.1. This document can be viewed at the `'/doc'` endpoint. We then pass in the OpenAPI configuration object to the function to add fields to the root object of the OpenAPI document.

Now, pass in the `OpenAPIHono` app instance to the `configureOpenAPI` function in the `src/app.ts` file:

```typescript app.ts
import configureOpenAPI from './lib/configureOpenAPI';

configureOpenAPI(app);
```

## Supported OpenAPI Specification versions in Hono and Speakeasy

Speakeasy currently supports the OpenAPI Specification versions 3.0.x and 3.1.x. We recommend using OpenAPI Specification version 3.1 if possible, as it's fully compatible with [JSON Schema](https://json-schema.org/), which gives you access to a large ecosystem of tools and libraries.

Zod OpenAPI Hono can generate an OpenAPI document using version 3.0 or version 3.1 of the OpenAPI Specification. This guide uses version 3.1.

Run the development server and open [`http://localhost:3000/doc`](http://localhost:3000/doc) to see the OpenAPI document in JSON format:

```json
{
  "openapi": "3.1.0",
  "externalDocs": {
    "description": "Find out more about Users API",
    "url": "www.example.com"
  },
  "info": {
    "version": "1.0.0",
    "title": "Users API"
  },
  "components": {
    "schemas": {

    },
    "parameters": {

    }
  },
  "paths": {
    "/users": {
      "get": {
        "responses": {
          "200": {
            "description": "The list of users",
            "content": {
              "application/json": {
                "schema": {
                  "type": "array",
                  "items": {
                    "type": "object",
                    ...

```

## Adding Scalar UI middleware

Let's use the [Scalar UI middleware](https://www.npmjs.com/package/@scalar/hono-api-reference) to add an interactive documentation UI for the API.

Install the middleware:

```bash Terminal
npm install @scalar/hono-api-reference
```

Import the `apiReference` middleware in the `src/lib/configureOpenAPI.ts` file:

```typescript configureOpenAPI.ts
import { apiReference } from '@scalar/hono-api-reference'
```

Add `apiReference` as a handler for GET requests to the `/ui` route:

```typescript configureOpenAPI.ts mark=3
export default function configureOpenAPI(app: OpenAPIHono) {
  app.doc31('/doc', openAPIObjectConfig);
  app.get(
    '/ui',
    apiReference({
      spec: {
        url: '/doc',
      },
      pageTitle: 'Users Management API',
    }),
  );
}
```

Open your browser and navigate to [`http://localhost:3000/ui`](http://localhost:3000/ui). You should see the Scalar UI with three API endpoints in the sidebar:

![Scalar UI endpoints](./assets/hono/scalar-ui.png)

You can see the parameters required for API endpoints and try out the different API endpoints. In the `http://localhost:3000/doc` route, you can also view the OpenAPI document in JSON format.

## Registering the Zod schemas as reusable OpenAPI component schemas

The request and response content schemas of the OpenAPI document are inline:

```json focus= 13:20
"components": {
    "schemas": {},
    "parameters": {}
  },
"paths": {
  "/users": {
    "get": {
      "responses": {
        "200": {
          "description": "The list of users",
          "content": {
            "application/json": {
              "schema": {
                "type": "array",
                "items": {
                  "type": "object",
                  "properties": {
                    "id": {
                      "type": "string"
                    },
```

Let's make these schemas reusable by adding them to the OpenAPI [Components Object](https://swagger.io/specification/#components-object).

Use the [`.openapi()` method on the Zod object](https://github.com/asteasolutions/zod-to-openapi#the-openapi-method) to register your Zod schemas as referenced components in the `src/schemas.ts` file:

```typescript schemas.ts mark=7
export const UserSelectSchema = z
  .object({
    id: z.string(),
    name: z.string(),
    age: z.number(),
  })
  .openapi('UserSelect');
```

This adds your schemas to the OpenAPI components object:

```json
  "components": {
    "schemas": {
      "UserSelect": {
        "type": "object",
        "properties": {
          "id": {
            "type": "string"
          },
          "name": {
            "type": "string"
          },
          "age": {
            "type": "number"
          }
        },
        "required": [
          "id",
          "name",
          "age"
        ]
      },
```

The schemas are referenced using a [Reference Object](https://swagger.io/specification/#reference-object) (`$ref`), which is a reference identifier that specifies the location (as a URI) of the value being referenced.

```json focus=7
  "responses": {
    "200": {
      "description": "The created user",
      "content": {
        "application/json": {
          "schema": {
            "$ref": "#/components/schemas/UserSelect"
          }
        }
      }
    },
```

## Adding OpenAPI metadata to the Zod schemas

Let's add additional OpenAPI metadata to our schemas.

In the `src/schemas.ts` file, add example values by passing in an object with an `example` property to the `openapi` method:

```typescript schemas.ts mark=4:6,8:10
export const UserInsertSchema = z
  .object({
    name: z.string()
      .openapi({
        example: 'John Doe',
      }),
    age: z.number()
      .openapi({
        example: 42,
      }),
  })
  .openapi('UserInsert');

export const UserSelectSchema = z
  .object({
    id: z.string()
      .openapi({
        example: '123',
      }),
    name: z.string()
      .openapi({
        example: 'John Doe',
      }),
    age: z.number()
      .openapi({
        example: 42,
      }),
  })
  .openapi('UserSelect');
```

Define the route parameters for parameter schema:

```typescript schemas.ts mark=6:9
export const idParamsSchema = z.object({
  id: z
    .string()
    .min(3)
    .openapi({
      param: {
        name: 'id',
        in: 'path',
      },
      example: '423',
    })
    .openapi('idParams'),
});
```

After adding the OpenAPI metadata to your schemas, you'll see that your OpenAPI document and Scalar UI will show example values for the schemas used in requests and responses:

![Scalar UI POST request example values](./assets/hono/scalar-ui-example-post.png)

You can also view the details of the example data schemas:

![Scalar UI example data schema](./assets/hono/scalar-ui-data-schema.png)

## Adding the OpenAPI `operationId` using Hono Zod OpenAPI

In the OpenAPI document, each HTTP request has an `operationId` that identifies the operation. The `operationId` is also used to generate method names and documentation in SDKs.

To add an `operationId`, use the `operationId` property of the `createRoute` method in the `src/routes/users/users.routes.ts` file:

```typescript users.routes.ts
export const list = createRoute({
  operationId: 'getUsers',
```

## Adding OpenAPI tags to Zod OpenAPI Hono routes

Whether you're building a big application or only have a handful of operations, we recommend adding tags to all your Hono routes so you can group them by tag in generated SDK code and documentation.

### Adding OpenAPI tags to routes in Hono

To add an OpenAPI tag to a Zod OpenAPI Hono route, use the `tags` property to pass in an array of tags as the argument object of the `createRoute` method call:

```typescript users.routes.ts
  tags: ['Users'],
```

### Adding metadata to tags

We can add metadata to the tag by passing in a [Tag Object](https://swagger.io/specification/#tag-object), instead of a string, to a tag array item.

Add a tag to the root OpenAPI object `openAPIObjectConfig` in the `src/lib/configureOpenAPI.ts` file:

```typescript configureOpenAPI.ts mark=7:14
export const openAPIObjectConfig = {
  openapi: '3.1.0',
  externalDocs: {
    description: 'Find out more about Users API',
    url: 'https://www.example.com',
  },
  tags: [{
    name: 'Users',
    description: 'Users operations',
    externalDocs: {
      description: 'Find more info here',
      url: 'https://example.com',
    },
  }],
```

## Adding a list of servers to the Hono OpenAPI document

When validating an OpenAPI document, Speakeasy expects a list of servers at the root of the document.

Add a server by adding a `servers` property to the `openAPIObjectConfig` object:

```typescript configureOpenAPI.ts mark=7:12
export const openAPIObjectConfig = {
  openapi: '3.1.0',
  externalDocs: {
    description: 'Find out more about Users API',
    url: 'https://www.example.com',
  },
  servers: [
    {
      url: 'http://localhost:3000/',
      description: 'Development server',
    },
  ],
```

## Adding retries to your SDK with `x-speakeasy-retries`

[OpenAPI document extensions](/openapi/extensions) allow us to add vendor-specific functionality to the document.

- Extension fields must be prefixed with `x-`.
- Speakeasy uses extensions that start with `x-speakeasy-`.

Let's add a Speakeasy extension that adds retries to requests from Speakeasy SDKs by adding a top-level `x-speakeasy-retries` schema to the OpenAPI document. We can also override the retry strategy per operation.

### Adding global retries

Apply the Speakeasy retries extension globally by adding the following `'x-speakeasy-retries'` property to the `openAPIObjectConfig` object:

```typescript configureOpenAPI.ts mark=13:23
export const openAPIObjectConfig = {
  openapi: '3.1.0',
  externalDocs: {
    description: 'Find out more about Users API',
    url: 'https://www.example.com',
  },
  servers: [
    {
      url: 'http://localhost:3000/',
      description: 'Development server',
    },
  ],
  'x-speakeasy-retries': {
    strategy: 'backoff',
    backoff: {
      initialInterval: 500,
      maxInterval: 60000,
      maxElapsedTime: 3600000,
      exponent: 1.5,
    },
    statusCodes: ['5XX'],
    retryConnectionErrors: true,
  },
```

### Adding retries per method

To create a unique retry strategy for a single route, add an `'x-speakeasy-retries'` property to the `createRoute` method call's argument object:

```typescript users.routes.ts mark=6:16
export const list = createRoute({
  'operationId': 'getUsers',
  'path': '/users',
  'method': 'get',
  'tags': ['Users'],
  'x-speakeasy-retries': {
    strategy: 'backoff',
    backoff: {
      initialInterval: 300,
      maxInterval: 40000,
      maxElapsedTime: 3000000,
      exponent: 1.2,
    },
    statusCodes: ['5XX'],
    retryConnectionErrors: true,
  },
```

## Generating an SDK based on your OpenAPI document

Before generating an SDK, we need to save the Hono Zod OpenAPI-generated OpenAPI document to a file. OpenAPI files are written as JSON or YAML; we'll save it as a YAML file, as it's easier to read.

### Saving the OpenAPI document to a YAML file using a Node.js script

Let's create a script to convert the OpenAPI object to a YAML file. We'll use the JS-YAML library to convert the OpenAPI object to a YAML string.

Create a script called `generateOpenAPIYamlFile.ts` in the `src` folder and add the following lines of code to it:

```typescript generateOpenAPIYamlFile.ts
import * as yaml from 'js-yaml';
import { writeFileSync } from 'node:fs';

import users from '@/routes/users/users.index';

import configureOpenAPI, { openAPIObjectConfig } from './lib/configureOpenAPI';
import createApp from './lib/createApp';

const app = createApp();

const routes = [
  users,
] as const;

configureOpenAPI(app);
routes.forEach((route) => {
  app.route('/', route);
});

// Convert the OpenAPIObject to a YAML string
const yamlString = yaml.dump(app.getOpenAPI31Document(openAPIObjectConfig));

// Save the YAML string to a file
writeFileSync('openapi.yaml', yamlString);
```

This initializes the app and routes, uses the `getOpenAPI31Document` method to generate an OpenAPI Specification version 3.1 schema object, converts the schema object to a YAML string, and saves it as a file.

Add the following script to your `package.json` file:

```json package.json
"create:openapi": "npx tsx ./src/generateOpenAPIYamlFile.ts"
```

Run the script using the following command:

```bash Terminal
npm run create:openapi
```

An `openapi.yaml` file will be created in your root folder.

### Linting the OpenAPI document with Speakeasy

The Speakeasy CLI has an OpenAPI [linting](/docs/linting) command that checks the OpenAPI document for errors and style issues.

Run the linting command:

```bash Terminal
speakeasy lint openapi --schema ./openapi.yaml
```

A lint report will be displayed in the terminal, showing errors, warnings, and hints:

![Speakeasy lint report](./assets/hono/speakeasy-lint-report.png)

The Speakeasy Linter uses a [recommended set of rules](/docs/linting/linting#speakeasy-recommended) that you can [configure](/docs/linting#configuration).

Speakeasy also has a [VS Code extension](https://marketplace.visualstudio.com/items?itemName=Speakeasy.speakeasy-vscode-extension) to help you validate your OpenAPI documents for the creation of production-grade SDKs.

### Creating an SDK from the Speakeasy CLI

We'll use the [`quickstart`](/docs/speakeasy-cli/quickstart) command for a guided SDK setup.

Run the command using the Speakeasy CLI:

```bash Terminal
speakeasy quickstart
```

Following the prompts, provide the OpenAPI document location, name the SDK `SDK`, and select `TypeScript` as the SDK language.

In the terminal, you'll see the steps taken by Speakeasy to create the SDK.

```
│ Workflow - success
│ └─Target: sdk - success
│   └─Source: SDK -OAS - success
│     └─Validating Document - success
│     └─Diagnosing OpenAPI - success
│     └─Tracking OpenAPI Changes - success
│       └─Snapshotting OpenAPI Revision - success
│       └─Storing OpenAPI Revision - success
│   └─Validating gen.yaml - success
│   └─Generating Typescript SDK - success
│     └─Setup Environment - success
│     └─Load and Validate Document - success
│     └─Generate SDK - success
│     └─Compile SDK - success
```

Speakeasy [validates](/docs/concepts#validation) the OpenAPI document to check that it's ready for code generation. Validation issues will be printed in the terminal. The generated SDK will be saved as a folder in your project.

If you get ESLint styling errors, run the `speakeasy quickstart` command from outside your project.

## Adding SDK generation to your GitHub Actions

The Speakeasy [`sdk-generation-action`](https://github.com/speakeasy-api/sdk-generation-action) repository provides workflows for integrating the Speakeasy CLI into CI/CD pipelines to automatically regenerate SDKs when the OpenAPI document changes.

You can set up Speakeasy to automatically push a new branch to your SDK repositories so that your engineers can review and merge the SDK changes.

For an overview of how to set up automation for your SDKs, see the Speakeasy [SDK Workflow Matrix](/docs/workflow-reference/generation-reference).

## Using your SDK

Once you've generated your SDK, you can [publish](/docs/publish-sdk) it for use. For TypeScript, you can publish it as an npm package.

A quick, non-production-ready way to see your SDK in action is to copy your SDK folder to a frontend TypeScript project and use it there.

For example, you can create a Vite project that uses TypeScript:

```bash Terminal
npm create vite@latest
```

Copy the SDK folder from your Hono app to the `src` directory of your TypeScript Vite project and delete the SDK folder in your Hono project.

In the SDK `README.md` file, you'll find documentation about your Speakeasy SDK.

Note that the SDK is not ready for production use. To get it production-ready, follow the steps outlined in your Speakeasy workspace.

The SDK has Zod as a peer dependency, as can be seen in the `sdk-typescript/package.json` file.

Install the required Zod version:

```bash Terminal
npm i zod
```

Replace the code in the `src/main.ts` file with the following example code taken from the `sdk-typescript/docs/sdk/users/README.md` file:

```typescript main.ts
import { SDK } from './sdk-typescript/src/'; // Adjust the path as necessary eg if your generated SDK has a different name

const sdk = new SDK();

async function run() {
  const result = await sdk.users.getUsers();

  // Handle the result
  console.log({ result });
}

run();
```

Run the Vite dev server:

```bash Terminal
npm run dev
```

Enable CORS in your Hono dev server by importing the built-in CORS middleware:

```typescript app.ts
import { cors } from 'hono/cors';
```

Add the middleware and set the `origin` to the Vite dev server URL:

```typescript app.ts
app.use(
  '/users',
  cors({
    origin: 'http://localhost:5173',
  }),
);
```

Run the Hono dev server as well:

```bash Terminal
npm run dev
```

You'll see the following logged in your browser dev tools console:

```
{
    "result": [
        {
            "id": "123",
            "name": "John Doe",
            "age": 42
        },
        {
            "id": "124",
            "name": "Sarah Jones",
            "age": 32
        }
    ]
}
```

The SDK functions are type safe and include TypeScript autocompletion for arguments and outputs.

If you try to access a property that doesn't exist:

```typescript main.ts
const userOne = result[0].surname;
```

You'll get a TypeScript error:

```
Property 'surname' does not exist on type 'UserSelect'
```

## Further reading

This guide covered the basics of generating an OpenAPI document using Hono. Here are some resources to help you learn more about OpenAPI, the Hono Zod OpenAPI middleware, and Speakeasy:

- [Hono Zod OpenAPI middleware documentation](https://github.com/honojs/middleware/tree/main/packages/zod-openapi): Learn more about generating an OpenAPI document and validating values and types using Zod. The topics covered include setup, handling validation errors, configuration, RPC mode, and authorization setup.
- [Speakeasy documentation](/docs): Speakeasy has extensive documentation covering how to generate SDKs from OpenAPI documents, customize SDKs, and more.
- [Speakeasy OpenAPI reference](/openapi): View a detailed reference for the OpenAPI Specification.


 This is the content for the doc openapi/frameworks/laravel.mdx 

 ---
title: How To Generate a OpenAPI/Swagger Spec for Laravel APIs
description: "Learn how to create a Swagger/OpenAPI spec for your Laravel API."
---

import YouTube from "react-youtube";
import { ScrollyCoding } from "~/components/codehike/Scrollycoding";
import { Callout } from "~/components";

# How To Generate a OpenAPI/Swagger Spec for your Laravel API

<div className="mt-10 flex items-center justify-center">
  <YouTube videoId="dn5U_pidRw0" />
</div>

You’re investing in your API, and that means finally creating an OpenAPI spec that accurately describes your API. Of course you could write the document by hand, or use a GUI tool to make it easier. Or with just a bit of upfront work, you can generate a complete OpenAPI specification directly from your Laravel application.

Back in the time of Swagger documents, BeyondCode had a well known package for performing spec generation. However, with the advent of OpenAPI, a new package, [Scribe](https://scribe.knuckles.wtf/laravel), has become the go to for generating an OpenAPI Spec from a Laravel API.

## An Overview of Scribe

Scribe is a robust documentation solution for PHP APIs. It helps you generate comprehensive human-readable documentation from your Laravel/Lumen/Dingo codebase. That includes HTML documentation, code samples, Postman Collections, and most importantly in our case, OpenAPI specifications.

So let’s start by installing the package using composer, and explore the options available.

```bash
composer require --dev knuckleswtf/scribe
```

Once installed, we want to publish the package configuration so that we can make any changes in how we want this to work.

```bash
php artisan vendor:publish --tag=scribe-config
```

Let’s take a quick look at the specific configuration options that will help us optimize this package to work with our Laravel API:

- `routes` - this option allows us to configure how we want to detect the API routes, and prefix we may use and any routes we want to exclude by default.
- `type` - we can choose between `static` (a static HTMI page) and `laravel` (a Blade view). We will get into more details on the differences later.
- `openapi` \***\*- \*\***this section allows you to toggle OpenAPI generation on or off. We’ll toggle it on.
- `auth` - specify the API’s authentication mechanism. This will be used to describe the `security` section of the OpenAPI document
- `strategies` - this is where we configure how Scribe will interact with our application to get the data needed to create the specification and documentation.

## Scribe’s Default OpenAPI Output

As mentioned above, the `type` config allows us to specify the type of output we get, and also where we want it to be outputted. The `static` option will generate HTMI documentation pages within our `public` directory. `laravel` we will generate this within the `storage` directory.

Note, anything in the `storage` directory typically won’t be committed to version control - so you would need to update the `.gitignore` file if you want to version this. For this article, we will keep the defaults as we want to focus on the OpenAPI Specification not the documentation.

### Testing Generation

When we first install and set up this package, we should run a test to make sure that everything is configured correctly and we aren’t going to run into issues further on.

```bash
php artisan scribe:generate
```

You should see a console output similar to the following:

```bash
❯ php artisan scribe:generate
ⓘ Processing route: [GET] api/user
✔ Processed route: [GET] api/user
ⓘ Extracting intro and auth Markdown files to: .scribe
✔ Extracted intro and auth Markdown files to: .scribe
ⓘ Writing HTML docs...
✔ Wrote HTML docs and assets to: public/docs/
ⓘ Generating Postman collection
✔ Wrote Postman collection to: public/docs/collection.json
ⓘ Generating OpenAPI specification
✔ Wrote OpenAPI specification to: public/docs/openapi.yaml
Checking for any pending upgrades to your config file...

✔ Visit your docs at http://localhost/docs
```

So, we can confirm that our package is working correctly with our application, let’s take a look at the OpenAPI Specification that was generated and see what changes are required.

```yaml
openapi: 3.0.3
info:
  title: Laravel
  description: ""
  version: 1.0.0
servers:
  - url: "http://localhost"
paths:
  /api/user:
    get:
      summary: ""
      operationId: getApiUser
      description: ""
      parameters: []
      responses:
        401:
          description: ""
          content:
            application/json:
              schema:
                type: object
                example:
                  message: Unauthenticated.
                properties:
                  message:
                    type: string
                    example: Unauthenticated.
      tags:
        - Endpoints
      security: []
tags:
  - name: Endpoints
    description: ""
```

This is our default set up in Laravel - we are using a project I have yet to add an API to. Let’s add some endpoints so we can see something a little more fleshed out.

## Our Example App: The Standup API

We’ll be working on an asynchronous stand-up application, it allows you to do your daily check-ins on one system, enables your manager to have a high level overview of team blockers and mood etc. You can follow along with the GitHub repository [here](https://github.com/speakeasy-api/guide-laravel-openapi).

## Non-Optimized Example Output

Now we got that out of the way, let’s regenerate our OpenAPI Specification now that I have added BREAD (Browse, Read, Edit, Add, Delete) endpoints.

```yaml
openapi: 3.0.3
info:
  title: Laravel
  description: ""
  version: 1.0.0
servers:
  - url: "http://localhost"
paths:
  /api/standups:
    get:
      summary: ""
      operationId: getApiStandups
      description: ""
      parameters: []
      responses:
        401:
          description: ""
          content:
            application/json:
              schema:
                type: object
                example:
                  message: Unauthenticated.
                properties:
                  message:
                    type: string
                    example: Unauthenticated.
      tags:
        - Endpoints
      security: []
    post:
      summary: ""
      operationId: postApiStandups
      description: ""
      parameters: []
      responses: {}
      tags:
        - Endpoints
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              properties:
                mood:
                  type: string
                  description: ""
                  example: excited
                  enum:
                    - happy
                    - sad
                    - excited
                    - frustrated
                    - tired
                    - neutral
                    - angry
                    - anxious
                    - optimistic
                    - pensive
                    - surprised
                    - sick
                    - confident
                    - disappointed
                    - amused
                    - relieved
                    - indifferent
                    - grateful
                    - inspired
                    - confused
                tasks:
                  type: string
                  description: "Must be at least 2 characters."
                  example: bhwfcupupgcgexmeiuzxvftnsxzwcvllulcenigndwkejgeqjalhsmrsseu
                blockers:
                  type: string
                  description: "Must be at least 2 characters."
                  example: cwtdgfoqgixwkwhlrwzapudsxtrtoiuldf
                questions:
                  type: string
                  description: "Must be at least 2 characters."
                  example: nqfytjwyyyxv
                comments:
                  type: string
                  description: "Must be at least 2 characters."
                  example: ynztxjgszeqzhdqamrfvtnsajozigaivnxbjsrvdujrchjnq
                department:
                  type: string
                  description: ""
                  example: quo
              required:
                - mood
                - tasks
                - department
      security: []
  "/api/standups/{uuid}":
    get:
      summary: ""
      operationId: getApiStandupsUuid
      description: ""
      parameters: []
      responses:
        401:
          description: ""
          content:
            application/json:
              schema:
                type: object
                example:
                  message: Unauthenticated.
                properties:
                  message:
                    type: string
                    example: Unauthenticated.
      tags:
        - Endpoints
      security: []
    parameters:
      - in: path
        name: uuid
        description: ""
        example: eb68e6e5-999a-3a67-a465-afa4b064af3d
        required: true
        schema:
          type: string
  "/api/standups/{standUp_id}":
    put:
      summary: ""
      operationId: putApiStandupsStandUp_id
      description: ""
      parameters: []
      responses: {}
      tags:
        - Endpoints
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              properties:
                mood:
                  type: string
                  description: ""
                  example: pensive
                  enum:
                    - happy
                    - sad
                    - excited
                    - frustrated
                    - tired
                    - neutral
                    - angry
                    - anxious
                    - optimistic
                    - pensive
                    - surprised
                    - sick
                    - confident
                    - disappointed
                    - amused
                    - relieved
                    - indifferent
                    - grateful
                    - inspired
                    - confused
                tasks:
                  type: string
                  description: "Must be at least 2 characters."
                  example: zeovcuepgdsmjpzdjtycdvcbhkeoxvifmj
                blockers:
                  type: string
                  description: "Must be at least 2 characters."
                  example: eqursmzxxjivpjqphrlxhritykekqhgsunqbtgvwvypyumuyekvxgzvcviyqa
                questions:
                  type: string
                  description: "Must be at least 2 characters."
                  example: nwqwclebngkisgxklxnaqrncxpkpzicwplklzpstkrnltjiivjbgmvybbgctihycvwtveebvytrk
                comments:
                  type: string
                  description: "Must be at least 2 characters."
                  example: vjkatsczlriwefgtiovegcovtzxcngsbiirsyegkfsegwjaandugmbx
                department:
                  type: string
                  description: ""
                  example: optio
              required:
                - mood
                - tasks
                - department
      security: []
    delete:
      summary: ""
      operationId: deleteApiStandupsStandUp_id
      description: ""
      parameters: []
      responses: {}
      tags:
        - Endpoints
      security: []
    parameters:
      - in: path
        name: standUp_id
        description: "The ID of the standUp."
        example: a
        required: true
        schema:
          type: string
tags:
  - name: Endpoints
    description: ""
```

That was a lot to look through, so let’s do a run through of each path - so we can understand what all this YAML actually means.

## Documenting all Response Codes

Let’s focus on the browse endpoint, accessed through `/api/standups` , which returns a collection of stand-ups that are part of the department you belong to.

```yaml
/api/standups:
  get:
    summary: ""
    operationId: getApiStandups
    description: ""
    parameters: []
    responses:
      401:
        description: ""
        content:
          application/json:
            schema:
              type: object
              example:
                message: Unauthenticated.
              properties:
                message:
                  type: string
                  example: Unauthenticated.
    tags:
      - Endpoints
    security: []
```

You may have noticed that by default Scribe is only documenting the error responses of the API; it's missing how the API would respond successfully.

### How Scribe Works

This is a good opportunity to explain about how Scribe works under the hood. Scribe scans your application routes to identify which endpoints should be documented based on your configuration. It then extracts metadata from your routes, such as route names, URI patterns, HTTP methods, and any specific annotations or comments in the controller that might be relevant for documentation.

Scribe then uses the extracted metadata to perform request simulation on your API. It captures the responses that come back, including: status codes, headers, and body content. All this then get packaged into an internal representation of your API, which is how the OpenAPI spec is created.

In the example above, only the `401` is being documented because Scribe hasn’t been configured with the proper authentication information, which makes it unable to access the proper response.

## Getting to 200

Let’s modify our Laravel code to get some useful information about our `200` responses.

To achieve this we will use PHP 8.0 Attributes to add additional information to our controllers, this will use the built in Laravel ecosystem to make a request, inspect the information, and write the specification for you. Let’s have a look at our controller:

<ScrollyCoding>

### !!steps Adding tags

In OpenAPI, `tags` are used to group related operations together. Typically, a good way to use tags is to have one tag per "resource" and then associate all the relevant operations that access and modify that resourc together. We'll add a group annotation to the top of the controller.

```php !
// !focus(1)
#[Group(name: 'Stand Ups', description: 'A series of endpoints that allow programatic access to managing stand-ups.', authenticated: true)]
final readonly class IndexController
{
    public function __construct(
        private AuthManager $auth,
        private StandUpRepository $repository,
    ) {
    }

    #[Authenticated]
    #[ResponseFromApiResource(StandUpResource::class, StandUp::class, collection: true)]
    #[Endpoint(title: 'Browse Stand Ups', description: 'Browse through the stand-ups that belong to your team, no matter what department you are in.')]
    public function __invoke(Request $request): CollectionResponse
    {
        $standups = $this->repository->forTeam(
            team: $this->auth->user()->current_team_id,
        );

        return new CollectionResponse(
            data: StandUpResource::collection(
                resource: $standups->paginate(),
            ),
        );
    }
}
```

---

### !!steps Authenicate Scribe

Let’s next focus on the `invoke` method that is what will be used to generate the path information. We use `#[Authenticated]` to let Scribe know that this endpoint needs to be authenticated

```php !
// !focus(10)
```

---

### !!steps Add Descriptions

Use `#[Endpoint]` to add additional information about this endpoint; describing what it’s function is.

```php !
// !focus(11)
```

---

### !!steps Adding Responses

Finally, we want to add `#[ResponseFromApiResource]` to let Scribe know how this API should respond, passing through the resource class and the model itself so Scribe can make a request in the background and inspect the types on the response payload. Also, we pass the boolean flag for whether or not this response should return a collection or not.

```php !
// !focus(12)
```

</ScrollyCoding>

Now let’s see the OpenAPI spec:

```yaml
/api/standups:
  get:
    summary: "Browse Stand Ups"
    operationId: browseStandUps
    description: "Browse through the stand-ups that belong to your team, no matter what department you are in."
    parameters: []
    responses:
      200:
        description: ""
        content:
          application/json:
            schema:
              type: object
              example:
                data:
                  - id: ""
                    type: standUps
                    attributes:
                      mood: angry
                      tasks: 'WOULD always get into that lovely garden. First, however, she went slowly after it: ''I never saw one, or heard of "Uglification,"'' Alice ventured to ask. ''Suppose we change the subject. ''Go on with.'
                      blockers: "I wonder what was the matter on, What would become of you? I gave her answer. 'They're done with a little girl or a worm. The question is, Who in the pool as it was all ridges and furrows; the balls."
                      questions: "I to get dry again: they had to stop and untwist it. After a minute or two, they began moving about again, and put it into his cup of tea, and looked at it, and kept doubling itself up very sulkily."
                      comments: "Alice, in a large canvas bag, which tied up at this moment the door with his knuckles. It was as much as she ran. 'How surprised he'll be when he sneezes; For he can EVEN finish, if he doesn't."
                      created:
                        human: null
                        timestamp: null
                        string: null
                        local: null
                  - id: ""
                    type: standUps
                    attributes:
                      mood: pensive
                      tasks: "She was looking at the Lizard as she picked her way into a graceful zigzag, and was looking down at her for a good many little girls eat eggs quite as much as she couldn't answer either question, it."
                      blockers: "Alice, 'it's very rude.' The Hatter opened his eyes were nearly out of sight, they were all ornamented with hearts. Next came the guests, mostly Kings and Queens, and among them Alice recognised the."
                      questions: "After a while she was near enough to look over their slates; 'but it doesn't matter much,' thought Alice, 'shall I NEVER get any older than I am in the last few minutes that she had felt quite."
                      comments: "An obstacle that came between Him, and ourselves, and it. Don't let him know she liked them best, For this must ever be A secret, kept from all the other was sitting on a little hot tea upon its."
                      created:
                        human: null
                        timestamp: null
                        string: null
                        local: null
              properties:
                data:
                  type: array
                  example:
                    - id: ""
                      type: standUps
                      attributes:
                        mood: angry
                        tasks: 'WOULD always get into that lovely garden. First, however, she went slowly after it: ''I never saw one, or heard of "Uglification,"'' Alice ventured to ask. ''Suppose we change the subject. ''Go on with.'
                        blockers: "I wonder what was the matter on, What would become of you? I gave her answer. 'They're done with a little girl or a worm. The question is, Who in the pool as it was all ridges and furrows; the balls."
                        questions: "I to get dry again: they had to stop and untwist it. After a minute or two, they began moving about again, and put it into his cup of tea, and looked at it, and kept doubling itself up very sulkily."
                        comments: "Alice, in a large canvas bag, which tied up at this moment the door with his knuckles. It was as much as she ran. 'How surprised he'll be when he sneezes; For he can EVEN finish, if he doesn't."
                        created:
                          human: null
                          timestamp: null
                          string: null
                          local: null
                    - id: ""
                      type: standUps
                      attributes:
                        mood: pensive
                        tasks: "She was looking at the Lizard as she picked her way into a graceful zigzag, and was looking down at her for a good many little girls eat eggs quite as much as she couldn't answer either question, it."
                        blockers: "Alice, 'it's very rude.' The Hatter opened his eyes were nearly out of sight, they were all ornamented with hearts. Next came the guests, mostly Kings and Queens, and among them Alice recognised the."
                        questions: "After a while she was near enough to look over their slates; 'but it doesn't matter much,' thought Alice, 'shall I NEVER get any older than I am in the last few minutes that she had felt quite."
                        comments: "An obstacle that came between Him, and ourselves, and it. Don't let him know she liked them best, For this must ever be A secret, kept from all the other was sitting on a little hot tea upon its."
                        created:
                          human: null
                          timestamp: null
                          string: null
                          local: null
                  items:
                    type: object
                    properties:
                      id:
                        type: string
                        example: ""
                      type:
                        type: string
                        example: standUps
                      attributes:
                        type: object
                        properties:
                          mood:
                            type: string
                            example: angry
                          tasks:
                            type: string
                            example: 'WOULD always get into that lovely garden. First, however, she went slowly after it: ''I never saw one, or heard of "Uglification,"'' Alice ventured to ask. ''Suppose we change the subject. ''Go on with.'
                          blockers:
                            type: string
                            example: "I wonder what was the matter on, What would become of you? I gave her answer. 'They're done with a little girl or a worm. The question is, Who in the pool as it was all ridges and furrows; the balls."
                          questions:
                            type: string
                            example: "I to get dry again: they had to stop and untwist it. After a minute or two, they began moving about again, and put it into his cup of tea, and looked at it, and kept doubling itself up very sulkily."
                          comments:
                            type: string
                            example: "Alice, in a large canvas bag, which tied up at this moment the door with his knuckles. It was as much as she ran. 'How surprised he'll be when he sneezes; For he can EVEN finish, if he doesn't."
                          created:
                            type: object
                            properties:
                              human:
                                type: string
                                example: null
                              timestamp:
                                type: string
                                example: null
                              string:
                                type: string
                                example: null
                              local:
                                type: string
                                example: null
    tags:
      - "Stand Ups"
```

## Documenting Parameters

So far so good! However, this API example is limited. What if we add query parameters like filtering and sorting which we would likely want on a real API.

In terms of Laravel implementation, we recommend use the `spatie/laravel-query-builder` package to enable JSON:API style filtering on my API, as it ties directly into Eloquent ORM from the request parameters. Let’s start adding some filters.

Our controller code used our `StandUpRepository` which just leverages Eloquent to query our database through a shared abstraction. However, we want to lean on the package by Spatie, which has a slightly different approach. Let’s rewrite this code to make it more flexible.

```php
// !focus(6:16)
#[Authenticated]
#[Endpoint(title: 'Browse Stand Ups', description: 'Browse through the stand-ups that belong to your team, no matter what department you are in.')]
#[ResponseFromApiResource(StandUpResource::class, StandUp::class, collection: true)]
public function __invoke(Request $request): CollectionResponse
{
    $standups = QueryBuilder::for(
			subject: $this->repository->forTeam(
				team: $this->auth->user()->current_team_id,
			),
		)->allowedFilters(
			filters: $this->repository->filters(),
		)->allowedIncludes(
			includes: $this->repository->includes(),
		)->allowedSorts(
			sorts: $this->repository->sort(),
		)->getEloquentBuilder();

    return new CollectionResponse(
        data: StandUpResource::collection(
            resource: $standups->paginate(),
        ),
    );
}
```

We use the `QueryBuilder` class from the package, to pass in the result of our repository call. The repository is just passing a pre-built query back, which we can use to paginate or extend as required. I prefer this approach as the sometimes you want to tie multiple methods together. You will see that I have 4 new methods that weren’t there before:

- `allowedFilters`
- `allowedIncludes`
- `allowedSorts`
- `getEloquentBuilder`

The first three allow you to programmatically control what parts of the query parameters to use and which to ignore. The final one is to get back the eloquent query builder, that we want to use as we know the API for it. The package returns a custom query builder, which does not have all of the methods we may want. Let’s flesh out the filter, include, and sort method calls next.

Going back we add attributes that will be parsed - so that our OpenAPI spec is generated with all available options:

```php
// !focus(9:18)
final readonly class IndexController
{
    public function __construct(
        private AuthManager $auth,
        private StandUpRepository $repository,
    ) {
    }

    #[
      Authenticated,
      QueryParam(name: 'filter[mood]', type: 'string', description: 'Filter the results by mood', required: false, example: 'filter[mood]=neutral', enum: Mood::class),
      QueryParam(name: 'filter[name]', type: 'string', description: 'Filter the results by the users name', required: false, example: 'filter[mood]=Rumpelstiltskin'),
      QueryParam(name: 'filter[department]', type: 'string', description: 'Filter the results by the department name', required: false, example: 'Engineering'),
      QueryParam(name: 'include', type: 'string', description: 'A comma separated list of relationships to side-load', required: false, example: 'include=user,department.team'),
      QueryParam(name: 'sort', type: 'string', description: 'Sort the results based on either the mood, or the created_at', required: false, example: 'sort=-mood'),
      ResponseFromApiResource(StandUpResource::class, StandUp::class, collection: true),
      Endpoint(title: 'Browse Stand Ups', description: 'Browse through the stand-ups that belong to your team, no matter what department you are in.')
    ]
    public function __invoke(Request $request): CollectionResponse
    {
        $standups = $this->repository->forTeam(
            team: $this->auth->user()->current_team_id,
        );

        return new CollectionResponse(
            data: StandUpResource::collection(
                resource: $standups->paginate(),
            ),
        );
    }
}
```

<Callout title="NOTE" variant="info">
  You may have noticed that the syntax has collapsed all the metadata into one
  attribute. It’s just a code style choice, there’s no change in functionality.
</Callout>

The result of the above will be the following inside your OpenAPI specification:

```yaml
parameters:
  - in: query
    name: "filter[mood]"
    description: "Filter the results by mood"
    example: "filter[mood]=neutral"
    required: false
    schema:
      type: string
      description: "Filter the results by mood"
      example: "filter[mood]=neutral"
      enum:
        - happy
        - sad
        - excited
        - frustrated
        - tired
        - neutral
        - angry
        - anxious
        - optimistic
        - pensive
        - surprised
        - sick
        - confident
        - disappointed
        - amused
        - relieved
        - indifferent
        - grateful
        - inspired
        - confused
  - in: query
    name: "filter[name]"
    description: "Filter the results by the users name"
    example: "filter[mood]=Rumpelstiltskin"
    required: false
    schema:
      type: string
      description: "Filter the results by the users name"
      example: "filter[mood]=Rumpelstiltskin"
  - in: query
    name: "filter[department]"
    description: "Filter the results by the department name"
    example: Engineering
    required: false
    schema:
      type: string
      description: "Filter the results by the department name"
      example: Engineering
  - in: query
    name: include
    description: "A comma separated list of relationships to side-load"
    example: "include=user,department.team"
    required: false
    schema:
      type: string
      description: "A comma separated list of relationships to side-load"
      example: "include=user,department.team"
  - in: query
    name: sort
    description: "Sort the results based on either the mood, or the created_at"
    example: sort=-mood
    required: false
    schema:
      type: string
      description: "Sort the results based on either the mood, or the created_at"
      example: sort=-mood
```

Quite convenient I am sure you can agree!

## A More Complex Endpoint

Let’s now move onto documenting our `store` endpoint which is what is used to create a new stand-up.

```yaml
/api/standups:
  post:
    summary: ""
    operationId: postApiStandups
    description: ""
    parameters: []
    responses: {}
    tags:
      - Endpoints
    requestBody:
      required: true
      content:
        application/json:
          schema:
            type: object
            properties:
              mood:
                type: string
                description: ""
                example: excited
                enum:
                  - happy
                  - sad
                  - excited
                  - frustrated
                  - tired
                  - neutral
                  - angry
                  - anxious
                  - optimistic
                  - pensive
                  - surprised
                  - sick
                  - confident
                  - disappointed
                  - amused
                  - relieved
                  - indifferent
                  - grateful
                  - inspired
                  - confused
              tasks:
                type: string
                description: "Must be at least 2 characters."
                example: fsukiymcjmglqdyuuecbuhdlplot
              blockers:
                type: string
                description: "Must be at least 2 characters."
                example: xxqzeornblypfisimgvgucodtqracytnncacoqxqaeuzytrvmezydvztnqtmrmbgdebrfdmgkmjczytt
              questions:
                type: string
                description: "Must be at least 2 characters."
                example: ckmhwsbrdoryyfdxhidyrbugkaftcyiozxzsdtahbnsdivqferixcflplmadjarlyosbn
              comments:
                type: string
                description: "Must be at least 2 characters."
                example: kbczrybawedlzxhpzyhcorgzjmsgcdvdbgryjaqhwsbccxwyfkprfhnpogyqjuyyramuqrkzzsypaajoegiu
              department:
                type: string
                description: ""
                example: pariatur
            required:
              - mood
              - tasks
              - department
    security: []
```

For the most part, this has been documented quite well by leaning on the Laravel framework and understanding what the validation rules on the request means. Let’s enhance this by adding some information.

```php
#[
	Group(name: 'Stand Ups', description: 'A series of endpoints that allow programmatic access to managing stand-ups.', authenticated: true),
	Authenticated,
	Endpoint(title: 'Create a new Stand Up', description: 'Create a new Stand Up for a specified department, will be assigned to whichever user is authenticated at the time.'),
]
```

This is similar to what we did on the `IndexController` but this time we are jumping straight into grouping the attributes all together at the top of the class. We do not need to add these above the `invoke` method, as this class only performs the one action anyway. I would consider moving these if I were to leverage additional Attributes for different purposes on the method, however for now I am not. Let’s now regenerate the OpenAPI Specification to see what the difference is, but this time I am going to omit the request validation information.

```yaml
post:
  summary: "Create a new Stand Up"
  operationId: createANewStandUp
  description: "Create a new Stand Up for a specified department, will be assigned to whichever user is authenticated at the time."
  parameters: []
  responses: {}
  tags:
    - "Stand Ups"
  requestBody:
    required: true
    content:
```

As you can see, the information is starting to build up based on the information we pass through to the PHP Attributes. Let’s start expanding on the request body and response information and build a better specification.

```php
#[
	Authenticated,
  Group(name: 'Stand Ups', description: 'A series of endpoints that allow programmatic access to managing stand-ups.', authenticated: true),
  Endpoint(title: 'Create a new Stand Up', description: 'Create a new Stand Up for a specified department, will be assigned to whichever user is authenticated at the time.'),

  BodyParam(name: 'mood', type: 'string', description: 'The mood of the user to be submitted to the stand-up.', required: true, example: 'neutral', enum: Mood::class),
  BodyParam(name: 'tasks', type: 'string', description: 'The list of tasks the user is planning on working on today. Markdown is supported.', required: false, example: 'Today I will be working on the OpenAPI Specification.'),
  BodyParam(name: 'blockers', type: 'string', description: 'A list of things that are blocking the user from progressing. Markdown is supported.', required: false, example: 'I am currently being blocked by front-end playing with crayons.'),
  BodyParam(name: 'questions', type: 'string', description: 'A list of questions that the user wants information on, these could be anything. Markdown is supported.', required: false, example: 'How much wood, could a woodchuck chuck, if a woodchuck, could chuck wood.'),
  BodyParam(name: 'comments', type: 'string', description: 'Any comments that the user wants to add to their stand-up that may be useful.', required: false, example: 'Going to the Dentist at 2pm, will make up hours later.'),
  BodyParam(name: 'department', type: 'string', description: 'The Unique Identifier for the department that the user is adding their stand up to.', required: true, example: '1234-1234-1234-1234'),

  ResponseFromApiResource(StandUpResource::class, StandUp::class, collection: false)
]
```

Now we have the body parameters for this request, as well as how the API is expected to respond. We are currently only documenting the happy path - as we have yet to decide how we want to handle errors. This will create the following in your OpenAPI Specification:

```yaml
post:
  summary: "Create a new Stand Up"
  operationId: createANewStandUp
  description: "Create a new Stand Up for a specified department, will be assigned to whichever user is authenticated at the time."
  parameters: []
  responses:
    200:
      description: ""
      content:
        application/json:
          schema:
            type: object
            example:
              data:
                id: 9bce14db-cdd1-4a8a-86cb-e05f9f918d20
                type: standUps
                attributes:
                  mood: sick
                  tasks: "Tortoise, if he were trying which word sounded best. Some of the deepest contempt. 'I've seen hatters before,' she said to Alice; and Alice looked all round the court and got behind him, and said."
                  blockers: "Hatter with a soldier on each side, and opened their eyes and mouths so VERY remarkable in that; nor did Alice think it so quickly that the cause of this elegant thimble'; and, when it had made. 'He."
                  questions: "Alice. 'Come on, then!' roared the Queen, 'and he shall tell you my adventures--beginning from this morning,' said Alice desperately: 'he's perfectly idiotic!' And she began again: 'Ou est ma."
                  comments: 'Alice felt a little ledge of rock, and, as there was nothing else to say "HOW DOTH THE LITTLE BUSY BEE," but it was written to nobody, which isn''t usual, you know.'' Alice had never been so much.'
                  created:
                    human: "0 seconds ago"
                    timestamp: 1713094155
                    string: "2024-04-14 11:29:15"
                    local: "2024-04-14T11:29:15"
            properties:
              data:
                type: object
                properties:
                  id:
                    type: string
                    example: 9bce14db-cdd1-4a8a-86cb-e05f9f918d20
                  type:
                    type: string
                    example: standUps
                  attributes:
                    type: object
                    properties:
                      mood:
                        type: string
                        example: sick
                      tasks:
                        type: string
                        example: "Tortoise, if he were trying which word sounded best. Some of the deepest contempt. 'I've seen hatters before,' she said to Alice; and Alice looked all round the court and got behind him, and said."
                      blockers:
                        type: string
                        example: "Hatter with a soldier on each side, and opened their eyes and mouths so VERY remarkable in that; nor did Alice think it so quickly that the cause of this elegant thimble'; and, when it had made. 'He."
                      questions:
                        type: string
                        example: "Alice. 'Come on, then!' roared the Queen, 'and he shall tell you my adventures--beginning from this morning,' said Alice desperately: 'he's perfectly idiotic!' And she began again: 'Ou est ma."
                      comments:
                        type: string
                        example: 'Alice felt a little ledge of rock, and, as there was nothing else to say "HOW DOTH THE LITTLE BUSY BEE," but it was written to nobody, which isn''t usual, you know.'' Alice had never been so much.'
                      created:
                        type: object
                        properties:
                          human:
                            type: string
                            example: "0 seconds ago"
                          timestamp:
                            type: integer
                            example: 1713094155
                          string:
                            type: string
                            example: "2024-04-14 11:29:15"
                          local:
                            type: string
                            example: "2024-04-14T11:29:15"
  tags:
    - "Stand Ups"
  requestBody:
    required: true
    content:
      application/json:
        schema:
          type: object
          properties:
            mood:
              type: string
              description: "The mood of the user to be submitted to the stand-up."
              example: neutral
              enum:
                - happy
                - sad
                - excited
                - frustrated
                - tired
                - neutral
                - angry
                - anxious
                - optimistic
                - pensive
                - surprised
                - sick
                - confident
                - disappointed
                - amused
                - relieved
                - indifferent
                - grateful
                - inspired
                - confused
            tasks:
              type: string
              description: "The list of tasks the user is planning on working on today. Markdown is supported."
              example: "Today I will be working on the OpenAPI Specification."
            blockers:
              type: string
              description: "A list of things that are blocking the user from progressing. Markdown is supported."
              example: "I am currently being blocked by front-end playing with crayons."
            questions:
              type: string
              description: "A list of questions that the user wants information on, these could be anything. Markdown is supported."
              example: "How much wood, could a woodchuck chuck, if a woodchuck, could chuck wood."
            comments:
              type: string
              description: "Any comments that the user wants to add to their stand-up that may be useful."
              example: "Going to the Dentist at 2pm, will make up hours later."
            department:
              type: string
              description: "The Unique Identifier for the department that the user is adding their stand up to."
              example: 1234-1234-1234-1234
          required:
            - mood
            - department
```

As you can see, a lot more information is provided which will help anyone who wants to interact with this API.

## Summary

If we follow this approach throughout our API, we can generate a well documented OpenAPI Specification for our Laravel based API - utilizing modern PHP to add information to our code base. This not only aids in the OpenAPI generation, but it also adds a level of in-code documentation that will help onboard any new developer who needs to know what the purpose of an endpoint may be.


 This is the content for the doc openapi/frameworks/nestjs.mdx 

 ---
title: How to generate an OpenAPI document with NestJS
description: "Learn how to generate an OpenAPI document for your NestJS API and use it to automatically generate and customize client SDKs across different languages."
---

import { Callout } from "~/components";

# How to generate an OpenAPI document with NestJS

This guide walks you through generating an OpenAPI document for a [NestJS](https://nestjs.com/) API and using Speakeasy to create an SDK based on the generated document.

<Callout title="Example code" variant="info">
Clone the [Speakeasy NestJS example repo](https://github.com/speakeasy-api/nestjs-openapi-example.git) to follow along with the example code in this tutorial. The `initial-app` branch has the initial state of the app that we'll use to start this tutorial.
</Callout>

Here's what we'll do:

1. Add the NestJS OpenAPI module to a NestJS project.
2. Generate an OpenAPI document using the NestJS OpenAPI module.
3. Improve the OpenAPI document for better downstream SDK generation.
4. Use the Speakeasy CLI to generate an SDK based on the OpenAPI document.
5. Use a Speakeasy OpenAPI extension to improve the generated SDK.

We'll also take a look at how you can use the generated SDK.

Your NestJS project might not be as simple as our example app, but the steps below should translate well to any NestJS project.

## The SDK generation pipeline

NestJS has an [OpenAPI (Swagger) module](https://github.com/nestjs/swagger) for generating OpenAPI documents. We'll begin by installing, configuring, and initializing the NestJS [OpenAPI (Swagger) module](https://github.com/nestjs/swagger). We will also use the [Scalar UI](https://www.npmjs.com/package/@scalar/nestjs-api-reference) to add an interactive documentation UI for the API.

The quality of your OpenAPI document determines the quality of generated SDKs and documentation, so we'll look into ways you can improve the generated document based on the Speakeasy [OpenAPI best practices](/docs/best-practices).

We'll then use the improved OpenAPI document to generate an SDK using Speakeasy.

Finally, we'll use a simplified example to demonstrate how to use the SDK we generated and how to add SDK generation to a CI/CD pipeline so that Speakeasy automatically generates fresh SDKs whenever your NestJS API changes in the future.

## Requirements

This guide assumes that you have an existing NestJS app (or a clone of our [example application](https://github.com/speakeasy-api/nestjs-openapi-example.git)) and basic familiarity with NestJS.

The following should be installed on your machine:

- [Node.js version 16 or above](https://nodejs.org/en/download) (we used Node v20.17.0).
- The [NestJS CLI](https://docs.nestjs.com/cli/overview), which can be installed with the following command once you have Node.js:

  ```bash Terminal
  npm install -g @nestjs/cli
  ```

- The [JS-YAML](https://www.npmjs.com/package/js-yaml) package, which we'll use to convert the OpenAPI document to a YAML file.
- The [Speakeasy CLI](/docs/speakeasy-cli/getting-started), which we'll use to generate an SDK from the OpenAPI document.

## Adding `@nestjs/swagger` to a NestJS project

Install the NestJS OpenAPI (Swagger) and Scalar API Reference modules:

```bash Terminal
 npm install --save @nestjs/swagger @scalar/nestjs-api-reference
```

In the `bootstrap` function of your application entry file, initialize Swagger using the `SwaggerModule` class:

```typescript main.ts
const config = new DocumentBuilder()
  .setTitle('Pet API')
  .setDescription('Create a cat or dog record and view pets by id')
  .setVersion('1.0')
  .addTag('library')
  .build();

const document = SwaggerModule.createDocument(app, config); // serializable object - conform to OpenAPI
SwaggerModule.setup('api', app, document, {
  swaggerUiEnabled: false,
});

app.use(
  '/api',
  apiReference({
    spec: {
      content: document,
    },
  }),
);
```

Add the required imports:

```typescript main.ts
import { SwaggerModule, DocumentBuilder } from '@nestjs/swagger';
import { apiReference } from '@scalar/nestjs-api-reference';
```

In the above code:

- The `SwaggerModule.createDocument` method returns a serializable [OpenAPI document](https://swagger.io/specification/#openapi-document) object that we'll convert to an OpenAPI YAML document file using JS-YAML.
- We use `DocumentBuilder` to create the base structure of the OpenAPI document. The [`DocumentBuilder` methods](https://github.com/nestjs/swagger/blob/master/lib/document-builder.ts) set the properties that identify the purpose and owner of the document, such as the title and description properties.
- We use the `createDocument()` method to define the API routes by passing in two arguments: the `app` instance and the document `config`. We can also provide a third argument, [`SwaggerDocumentOptions`](https://docs.nestjs.com/openapi/introduction#document-options).
- We use `SwaggerModule.setup()` to expose the OpenAPI document at `/api-yaml` for the YAML format and `/api-json` for the JSON format.
- The `app.use('/api', ...)` method mounts the Scalar API Reference component to the `/api` route. The `apiReference` function takes the `document` object as a parameter, which represents the OpenAPI document.

Run the NestJS HTTP development server:

```bash Terminal
npm run start:dev
```

Open your browser and navigate to [`http://localhost:3000/api`](http://localhost:3000/api). You should see the Scalar UI with three API endpoints in the sidebar.

![Scalar UI](./assets/nestjs/scalar-ui.png)

For each API endpoint, you can see which parameters are required and try out the different API endpoints.

Open `http://localhost:3000/api-yaml` to see the following basic OpenAPI document in YAML format:

```yaml
openapi: 3.0.0
paths:
  /pets:
    post:
      operationId: PetsController_create
      parameters: []
      responses:
        "201":
          description: ""
  /pets/cats/{id}:
    get:
      operationId: PetsController_findOneCat
      parameters:
        - name: id
          required: true
          in: path
          schema:
            type: string
      responses:
        "200":
          description: ""
  /pets/dogs/{id}:
    get:
      operationId: PetsController_findOneDog
      parameters:
        - name: id
          required: true
          in: path
          schema:
            type: string
      responses:
        "200":
          description: ""
info:
  title: Pet API
  description: Create a cat or dog record and view pets by id
  version: "1.0"
  contact: {}
tags:
  - name: library
    description: ""
servers: []
components:
  schemas: {}
```

Note that the document uses OpenAPI Specification version 3.0.0.

## Supported OpenAPI Specification versions in NestJS and Speakeasy

Speakeasy currently supports the OpenAPI Specification versions 3.0.x and 3.1.x. We recommend using OpenAPI Specification version 3.1 if possible, as it's fully compatible with [JSON Schema](https://json-schema.org/), which gives you access to a large ecosystem of tools and libraries. NestJS supports OpenAPI Specification version 3.0.x.

## Adding OpenAPI `info` in NestJS

Let's improve the OpenAPI document by better describing it. We'll add more fields to the [info object](https://swagger.io/specification/#info-object), which contains metadata about the API.

Add the following `DocumentBuilder` methods to the `config` section of the document (`main.ts`) to supply more data about the API:

```typescript main.ts
.setContact(
  'Speakeasy support',
  'http://www.example.com/support',
  'support@example.com',
)
.setTermsOfService('http://example.com/terms/')
.setLicense(
  'Apache 2.0',
  'https://www.apache.org/licenses/LICENSE-2.0.html',
)
```

## Updating NestJS to generate OpenAPI components schemas

In the example app, [NestJS core decorators](https://docs.nestjs.com/custom-decorators) define the structure and functionality of the Pets Controller and its API routes.

We can add [OpenAPI decorators](https://docs.nestjs.com/openapi/decorators) to better describe our API. The OpenAPI document lacks details about the POST request body, data schema, and API response.

Add the following OpenAPI decorators, with the `Api` prefix to distinguish them from the core decorators, to the `@Get('cats/:id')` route handler:

```typescript pets.controller.ts
@ApiOperation({ summary: 'Get cat' })
@ApiResponse({
  description: 'The found record',
  type: Cat,
})
@ApiBadRequestResponse({ description: 'Bad Request' })
```

Import these decorators from `'@nestjs/swagger'`:

```typescript pets.controller.ts
import {
  ApiBadRequestResponse,
  ApiBody,
  ApiExtension,
  ApiForbiddenResponse,
  ApiOkResponse,
  ApiOperation,
  ApiResponse,
  ApiTags,
  getSchemaPath,
} from '@nestjs/swagger';
```

Add the following OpenAPI decorators to the `@Get('dogs/:id')` route handler:

```typescript pets.controller.ts
@ApiOperation({ summary: 'Get dog' })
@ApiResponse({
  description: 'The found record',
  type: Dog,
})
@ApiBadRequestResponse({ description: 'Bad Request' })
```

Add the following OpenAPI decorators to the `@Post()` route handler:

```typescript pets.controller.ts
@ApiOperation({ summary: 'Create a pet' })
@ApiBody({
  schema: {
    oneOf: [{ $ref: getSchemaPath(Cat) }, { $ref: getSchemaPath(Dog) }],
    discriminator: {
      propertyName: 'type',
      mapping: {
        cat: getSchemaPath(Cat),
        dog: getSchemaPath(Dog),
      },
    },
  },
  description: 'Create a pet cat or dog',
})
@ApiOkResponse({
  schema: {
    oneOf: [{ $ref: getSchemaPath(Cat) }, { $ref: getSchemaPath(Dog) }],
    discriminator: {
      propertyName: 'type',
      mapping: {
        cat: getSchemaPath(Cat),
        dog: getSchemaPath(Dog),
      },
    },
  },
})
@ApiForbiddenResponse({ description: 'Forbidden' })
@ApiBadRequestResponse({ description: 'Bad Request' })
```

The `@ApiBody()` and `@ApiOkResponse` decorators use the [Schema Object](https://swagger.io/specification/#schemaObject), which defines the input and output data types. The allowed data types are defined by the `Cat` and `Dog` data transfer objects (DTO) schema. A DTO schema defines how data will be sent over the network.

Now, run the NestJS HTTP server and open `http://localhost:3000/api-yaml/`. You'll see the OpenAPI endpoints description is more fleshed out.

The POST request originally looked like the following:

```yaml
/pets:
  post:
    operationId: PetsController_create
    parameters: []
    responses:
      "201":
        description: ""
```

It should now look as follows:

```yaml focus=6:38
/pets:
  post:
    operationId: PetsController_create
    summary: Create pet
    parameters: []
    requestBody:
      required: true
      description: Create a pet cat or dog
      content:
        application/json:
          schema:
            oneOf:
              - $ref: "#/components/schemas/Cat"
              - $ref: "#/components/schemas/Dog"
            discriminator:
              propertyName: type
              mapping:
                cat: "#/components/schemas/Cat"
                dog: "#/components/schemas/Dog"
    responses:
      "200":
        description: ""
        content:
          application/json:
            schema:
              oneOf:
                - $ref: "#/components/schemas/Cat"
                - $ref: "#/components/schemas/Dog"
              discriminator:
                propertyName: type
                mapping:
                  cat: "#/components/schemas/Cat"
                  dog: "#/components/schemas/Dog"
      "400":
        description: Bad Request
      "403":
        description: Forbidden
```

The [Reference Object](https://swagger.io/specification/#reference-object) (`$ref`) is a reference identifier that specifies the location, as a URI, of the value being referenced. It references the `schemas` field of the [Components Object](https://swagger.io/specification/#components-object), which holds reusable schema objects.

If you look at the `components` schema, you'll see the `properties` objects are empty.

```yaml mark=5,8
components:
  schemas:
    Cat:
      type: object
      properties: {}
    Dog:
      type: object
      properties: {}
```

To make the model properties visible to the `SwaggerModule`, we can annotate each property using the `@ApiProperty()` decorator. For example:

```typescript cat.entity.ts mark=1
@ApiProperty({ example: 'Panama', description: 'The name of the cat' })
@IsString()
readonly name: string;
```

This can be tedious, especially with medium- to large-sized projects. You can use the NestJS [Swagger CLI plugin](https://docs.nestjs.com/openapi/cli-plugin#cli-plugin) to automate this annotation.

To enable the plugin, open your `nest-cli.json` file, add the following `plugins` configuration, and restart the server:

```json nest-cli.json mark=7
{
  "$schema": "https://json.schemastore.org/nest-cli",
  "collection": "@nestjs/schematics",
  "sourceRoot": "src",
  "compilerOptions": {
    "deleteOutDir": true,
    "plugins": ["@nestjs/swagger"]
  }
}
```

You'll now see that the `properties` fields are populated as follows:

```yaml focus=5:24,27:47
components:
  schemas:
    Cat:
      type: object
      properties:
        type:
          type: string
        name:
          type: string
        age:
          type: number
        breed:
          type: string
        environment:
          type: string
          enum:
            - indoor
            - outdoor
      required:
        - type
        - name
        - age
        - breed
        - environment
    Dog:
      type: object
      properties:
        type:
          type: string
        name:
          type: string
        age:
          type: number
        breed:
          type: string
        size:
          type: string
          enum:
            - small
            - medium
            - large
      required:
        - type
        - name
        - age
        - breed
        - size
```

The plugin annotates all DTO properties with the `@ApiProperty` decorator, sets the `type` or `enum` property depending on the type, sets validation rules based on `class-validator` decorators, and carries out various other [automated actions](https://docs.nestjs.com/openapi/cli-plugin#overview).

You can generate descriptions for properties and endpoints, and create example values for properties based on comments:

```typescript cat.entity.ts mark=1:4
  /**
   * The type of pet
   * @example 'cat'
   */
  @IsEnum(['cat'])
  readonly type: 'cat';
```

For this to work, `introspectComments` must be set to `true` in the `options` property of the plugin:

```json nest-cli.json
"plugins": [
  {
    "name": "@nestjs/swagger",
    "options": {
      "introspectComments": true
    }
  }
]
```

The example and description will then be added to the OpenAPI document `components` schema:

```yaml focus=8:9
components:
  schemas:
    Cat:
      type: object
      properties:
        type:
          type: string
          description: The type of pet
          example: cat
```

Add comments that provide a description and example value for each property of the `Cat` and `Dog` entities.

The Scalar UI will allow you to access the example value for the request body and a successful response. Click on the **Test Request** button of the request to display a modal, where you can try a request to the endpoint:

![Scalar UI Try Request](./assets/nestjs/scalar-ui-try-request.png)

You can see an example of a request body in the **Body** section of the modal:

![Scalar UI example request body](./assets/nestjs/scalar-ui-example-req-body.png)

By toggling the **200** option under **Responses**, you can also see the details of the example data schemas:

![Scalar UI example schema](./assets/nestjs/scalar-ui-example-schema.png)

## Customizing the OpenAPI `operationId` with NestJS

In the OpenAPI document, each HTTP request has an `operationId` that identifies the operation. In SDKs, the `operationId` is also used to generate method names and documentation.

By default, the NestJS OpenAPI (Swagger) module uses the NestJS `controllerKey` and `methodKey` to name the `operationID` something like `PetsController_findOneDog`.

A long operation name is not ideal. We can use the `operationIdFactory` method in the [Swagger document options](https://docs.nestjs.com/openapi/introduction#document-options) to instruct the module to generate more concise names using only the `methodKey`.

Define the following `options` in the `bootstrap` function:

```typescript main.ts
const options: SwaggerDocumentOptions = {
  operationIdFactory: (controllerKey: string, methodKey: string) => methodKey,
};
```

Pass the `options` to the `SwaggerModule` as follows:

```typescript main.ts
const document = SwaggerModule.createDocument(app, config, options);
```

Import `SwaggerDocumentOptions` from `@nestjs/swagger`:

```typescript main.ts focus=4
import {
  SwaggerModule,
  DocumentBuilder,
  SwaggerDocumentOptions,
} from '@nestjs/swagger';
```

## Adding OpenAPI tags to NestJS routes

Whether you're building a big application or only have a handful of operations, we recommend adding tags to all your NestJS routes so you can group them by tag in the generated SDK code and documentation.

### Adding tags

To add an OpenAPI tag to a route in NestJS, add the `@ApiTags` decorator:

```typescript pets.controller.ts
@Get('cats/:id')
@ApiTags('cats')
```

### Adding metadata to tags

We've already added metadata to the `@ApiTags('cats')` decorator using other decorators provided by `@nestjs/swagger`, such as `@ApiOperation` and `@ApiResponse`.

We can add metadata to the root tag field in the OpenAPI document.

Add the following to the `config` section of the OpenAPI document:

```typescript main.ts
.addTag('Pets', 'Pets operations', {
  url: 'https://example.com/api',
  description: 'Operations API endpoint',
})
```

You can add more than one tag by using additional `.addTag()` method calls:

```typescript main.ts
.addTag('cats')
.addTag('dogs')
```

## Adding a list of servers to the NestJS OpenAPI document

When validating an OpenAPI document, Speakeasy expects a list of servers at the root of the OpenAPI document. We'll add a server using the `DocumentBuilder` method, `addServer()`.

Insert the `addServer()` method in the `config` of the OpenAPI document:

```typescript main.ts
.addServer('http://localhost:3000/', 'Development server')
```

## Adding retries to your SDK with `x-speakeasy-retries`

[OpenAPI document extensions](/openapi/extensions) allow us to add vendor-specific functionality to the OpenAPI document.

- Extension fields must be prefixed with `x-`.
- Speakeasy uses extensions that start with `x-speakeasy-`.

Let's use a Speakeasy extension that adds retries to requests from Speakeasy SDKs by adding a top-level `x-speakeasy-retries` schema to our OpenAPI document. We can also override the retry strategy per operation.

### Adding global retries

Apply the Speakeasy retries extension globally by adding the `addExtension()` method from `DocumentBuilder` to the `config` section of the OpenAPI document:

```typescript main.ts
.addExtension('x-speakeasy-retries', {
  strategy: 'backoff',
  backoff: {
    initialInterval: 500,
    maxInterval: 60000,
    maxElapsedTime: 3600000,
    exponent: 1.5,
  },
  statusCodes: ['5XX'],
  retryConnectionErrors: true,
})
```

### Adding retries per method

To create a unique retry strategy for a single route, use the `ApiExtension` decorator to add `x-speakeasy-retries` to a NestJS controller route handler as follows:

```typescript pets.controller.ts
@ApiExtension('x-speakeasy-retries', {
  strategy: 'backoff',
  backoff: {
    initialInterval: 1000,
    maxInterval: 80000,
    maxElapsedTime: 3600000,
    exponent: 1.5,
  },
  statusCodes: ['5XX'],
  retryConnectionErrors: true,
})
```

##  Generating an SDK based on your OpenAPI document

Before creating an SDK, we need to save the NestJS-generated OpenAPI document to a file. We'll use JS-YAML to do this.

### Saving the OpenAPI document to a YAML file

Add the following imports to your application entry file:

```typescript main.ts
import * as yaml from 'js-yaml';
import { writeFileSync } from 'fs';
```

In the `bootstrap` function, convert the OpenAPI document to a YAML string and save it as a file:

```typescript main.ts
const yamlString = yaml.dump(document);
writeFileSync('openapi.yaml', yamlString);
```

When you run the NestJS dev server, an `openapi.yaml` file will be generated in your root directory.

### Linting the OpenAPI document with Speakeasy

The Speakeasy CLI has an OpenAPI [linting](/docs/linting) command that checks the OpenAPI document for errors and style issues.

Run the linting command:

```bash Terminal
speakeasy lint openapi --schema ./openapi.yaml
```

A lint report will be displayed in the terminal, showing errors, warnings, and hints:

![Speakeasy Lint report](./assets/nestjs/speakeasy-lint-report.png)

The Speakeasy Linter uses a [recommended set of rules](/docs/linting/linting#speakeasy-recommended), which you can [configure](/docs/linting#configuration).

### Generating an SDK from the Speakeasy CLI

We'll use the [`quickstart`](/docs/speakeasy-cli/quickstart) command for a guided SDK setup.

Run the command using the Speakeasy CLI:

```bash Terminal
speakeasy quickstart
```

Following the prompts, provide the OpenAPI document location, name the SDK `SDK`, and select `TypeScript` as the SDK language.

In the terminal, you'll see the steps taken by Speakeasy to generate the SDK.

```txt
│ Workflow - success                             
│ └─Target: sdk - success                        
│   └─Source: SDK-OAS - success                  
│     └─Validating Document - success            
│     └─Diagnosing OpenAPI - success             
│     └─Tracking OpenAPI Changes - success       
│       └─Snapshotting OpenAPI Revision - success
│       └─Storing OpenAPI Revision - success     
│     └─Computing Document Changes - success     
│       └─Downloading prior revision - success   
│       └─Computing changes - success            
│       └─Uploading changes report - success     
│   └─Validating gen.yaml - success              
│   └─Generating Typescript SDK - success        
│     └─Setup Environment - success              
│     └─Load and Validate Document - success     
│     └─Generate SDK - success                   
│     └─Compile SDK - success                    
│     └─Setup Environment - success              
│     └─Load and Validate Document - success     
│     └─Generate SDK - success                   
│   └─Generating Code Samples - success          
│     └─Snapshotting Code Samples - success      
│       └─Snapshotting Code Samples - success    
│       └─Uploading Code Samples - success       
```

Speakeasy [validates](/docs/concepts#validation) the OpenAPI document to check that it's ready for code generation. Validation issues will be printed in the terminal. The generated SDK will be saved as a folder in your project.

## Adding SDK generation to your GitHub Actions

The Speakeasy [`sdk-generation-action`](https://github.com/speakeasy-api/sdk-generation-action) repository provides workflows for integrating the Speakeasy CLI into CI/CD pipelines to automatically regenerate SDKs when the OpenAPI document changes.

You can set up Speakeasy to automatically push a new branch to your SDK repositories so that your engineers can review and merge the SDK changes.

For an overview of how to set up automation for your SDKs, see the Speakeasy [SDK Workflow Matrix](/docs/workflow-reference/generation-reference).

## Using your SDK

Once you've generated your SDK, you can [publish](/docs/publish-sdk) it for use. For TypeScript, you can publish it as an npm package.

A quick, non-production-ready way to see your SDK in action is to copy your SDK folder to a frontend TypeScript project and use it there.

For example, you can create a Vite project that uses TypeScript:

```bash Terminal
npm create vite@latest
```

Copy the SDK folder from your NestJS app to the `src` directory of your TypeScript Vite project.

Delete the SDK folder in your NestJS project.

In the SDK `README.md` file, you'll find documentation about your Speakeasy SDK.

Note that the SDK is not ready for production use. To get it production-ready, follow the steps outlined in your Speakeasy workspace.

The SDK has Zod as a peer dependency, as can be seen in the `sdk-typescript/package.json` file.

Install the required Zod version:

```bash Terminal
npm i zod
```

Replace the code in the `src/main.ts` file with the following lines of code:

```typescript main.ts
import { SDK } from './sdk-typescript/src/'; // Adjust the path as necessary eg if your generated SDK has a different name
import { catsFindOneCat } from './sdk-typescript/src/funcs/catsFindOneCat';

const sdk = new SDK();
async function run() {
  const res = await catsFindOneCat(sdk, {
    id: "0",
  });

  if (!res.ok) {
    throw res.error;
  }

  const { value: result } = res;

  // Handle the result
  console.log(result);
}

run();
```

Run the Vite dev server:

```bash Terminal
npm run dev
```

Enable CORS in your NestJS dev server by adding the following configuration to the `bootstrap` function above the `await app.listen(3000);` line:

```typescript main.ts
app.enableCors({
  origin: 'http://localhost:5173', // Vite's default port
  methods: 'GET,POST,PUT,DELETE,OPTIONS',
  allowedHeaders: 'Content-Type, Authorization',
  credentials: true,
});
```

Run the NestJS dev server as well:

```bash Terminal
npm run start:dev
```

You'll see the following logged in your browser dev tools console:

```javascript
{type: 'cat', name: 'Shadow', age: 8, breed: 'Bombay', environment: 'indoor'}
```

The SDK functions are type safe and include TypeScript autocompletion for arguments and outputs.

If you try to use an incorrect type for an argument:

```typescript main.ts
const res = await catsFindOneCat(sdk, {
  id: 1,
});
```

You'll get a TypeScript error:

```
Type 'number' is not assignable to type 'string'
```

## Further reading

This guide covered the basics of generating an OpenAPI document using NestJS. Here are some resources to help you learn more about OpenAPI, the NestJS OpenAPI module, and Speakeasy:

- [NestJS OpenAPI (Swagger) module documentation](https://typespec.io/docs): Learn more about generating an OpenAPI document using NestJS. The topics covered include types and parameters, operations, security, mapped types, and decorators.
- [Speakeasy documentation](/docs): Speakeasy has extensive documentation covering how to generate SDKs from OpenAPI documents, customize SDKs, and more.
- [Speakeasy OpenAPI reference](/openapi): View a detailed reference for the OpenAPI Specification.


 This is the content for the doc openapi/frameworks/pydantic.mdx 

 ---
title: How To Generate an OpenAPI Spec with Pydantic V2
description: "How to generate OpenAPI schemas and great SDK clients for your Pydantic V2 Models"
---

import { ScrollyCoding } from "~/components/codehike/Scrollycoding";

# How to generate an OpenAPI/Swagger spec with Pydantic V2

[Pydantic](https://docs.pydantic.dev/latest/) is considered by many API developers to be the best data validation library for Python, and with good reason. By defining an application's models in Pydantic, developers benefit from a vastly improved development experience, runtime data validation and serialization, and automatic OpenAPI schema generation.

However, many developers don't realize they can generate OpenAPI schemas from their Pydantic models, which they can then use to create SDKs, documentation, and server stubs.

In this guide, you'll learn how to create new Pydantic models, generate an OpenAPI schema from them, and use the generated schema to create an SDK for your API. We'll start with the simplest possible Pydantic model and gradually add more features to show how Pydantic models translate to OpenAPI schemas.

## Prerequisites

Before we get started, make sure you have [Python](https://www.python.org/downloads/) 3.8 or higher installed on your machine. Check your Python version by running the following command:

```bash Terminal
python --version
```

We use Python 3.12.4 in this guide, but any version of Python 3.8 or higher should work.

You can clone our [example repository from GitHub](https://github.com/speakeasy-api/speakeasy-pydantic-openapi/) to follow along with the code snippets in this guide, or you can create a new Python project and install the required libraries as we go.

## Create a New Python Project

First, create a new Python project and install the Pydantic library:

```bash Terminal
# Create and open a new directory for the project
mkdir pydantic-openapi
cd pydantic-openapi

# Create a new virtual environment
python -m venv venv

# Activate the virtual environment
source venv/bin/activate
```

## Install the Required Libraries

We'll install Pydantic and PyYAML to generate and pretty-print the OpenAPI schema:

```bash Terminal
# Install the Pydantic library
pip install pydantic

# Install the PyYAML library for pretty-printing the OpenAPI schema
pip install pyyaml
```

## Pydantic to OpenAPI Schema Walkthrough

Let's follow a step-by-step process to generate an OpenAPI schema from a Pydantic model without any additional libraries.

<ScrollyCoding className="ch-scrollycoding-full-height ch-scrollycoding-force-focus-scroll" fullHeight>

### !!steps Define a Simple Pydantic Model

Create a new Python file called `models.py` and define a simple Pydantic model.

In this example, we define a Pydantic model called `Pet` with three fields: `id`, `name`, and `breed`. The `id` field is an integer, and the `name` and `breed` fields are strings.

```python ! models.py
from pydantic import BaseModel


class Pet(BaseModel):
    id: int
    name: str
    breed: str
```

---

### !!steps Generate JSON Schema for the Pydantic Model

Add a new function called `print_json_schema` to the `models.py` file that prints the JSON schema for the `Pet` model.

This function uses the `model_json_schema` method provided by Pydantic to generate the JSON schema, which Python then prints to the console as YAML. We use YAML for readability, but the output is still a valid JSON schema.

```python ! models.py
# !focus(1,11:16)
import yaml
from pydantic import BaseModel


class Pet(BaseModel):
    id: int
    name: str
    breed: str


def print_json_schema():
    print(yaml.dump(Pet.model_json_schema()))


if __name__ == "__main__":
    print_json_schema()
```

---

## !!steps

Run `python models.py` to generate the JSON schema for the `Pet` model and print it as YAML:

```yaml ! Output
properties:
  breed:
    title: Breed
    type: string
  id:
    title: Id
    type: integer
  name:
    title: Name
    type: string
required:
  - id
  - name
  - breed
title: Pet
type: object
```

---

## !!steps Multiple Pydantic Models

Let's add another Pydantic model called `Owner` to the `models.py` file.

The `Owner` model has two fields: `id` and `name`. Both fields are integers. Additionally, the `Owner` model has a list of `Pet` objects.

```python ! models.py
# !focus(11,14:18)
import yaml
from pydantic import BaseModel


class Pet(BaseModel):
    id: int
    name: str
    breed: str


class Owner(BaseModel):
    id: int
    name: str
    pets: list[Pet]


def print_json_schema():
    print(yaml.dump(Pet.model_json_schema()))


if __name__ == "__main__":
    print_json_schema()
```

---

## !!steps Generate JSON Schema for Multiple Pydantic Models

Update the `print_json_schema` function to print the JSON schema for both the `Pet` and `Owner` models.

Note that we're now calling the [`models_json_schema`](https://docs.pydantic.dev/2.7/api/json_schema/#pydantic.json_schema.models_json_schema) function from `pydantic.json_schema` instead of the `model_json_schema` method.

```python ! models.py
# !focus(3)
# !focus(18:22)
# !focus(26[23:34])
import yaml
from pydantic import BaseModel
from pydantic.json_schema import models_json_schema


class Pet(BaseModel):
    id: int
    name: str
    breed: str


class Owner(BaseModel):
    id: int
    name: str
    pets: list[Pet]


def print_json_schema(models):
    _, schemas = models_json_schema(
        [(model, "validation") for model in models],
    )
    print(yaml.dump(schemas))


if __name__ == "__main__":
    print_json_schema([Pet, Owner])
```

---

## !!steps

Run `python models.py` to generate the JSON schema for both the `Pet` and `Owner` models and print it as YAML:

```yaml ! Output
$defs:
  Owner:
    properties:
      id:
        title: Id
        type: integer
      name:
        title: Name
        type: string
      pets:
        items:
          $ref: "#/$defs/Pet"
        title: Pets
        type: array
    required:
      - id
      - name
      - pets
    title: Owner
    type: object
  Pet:
    properties:
      breed:
        title: Breed
        type: string
      id:
        title: Id
        type: integer
      name:
        title: Name
        type: string
    required:
      - id
      - name
      - breed
    title: Pet
    type: object
```

---

## !!steps

The generated schema includes definitions for both the `Pet` and `Owner` models. The `Owner` model has a reference to the `Pet` model, indicating that the `Owner` model contains a list of `Pet` objects.

Note that the root of the schema includes a `$defs` key that contains the definitions for both models, and the `Owner` model references the `Pet` model using the `$ref` keyword.

```yaml ! Output
# !focus(1,12)
$defs:
  Owner:
    properties:
      id:
        title: Id
        type: integer
      name:
        title: Name
        type: string
      pets:
        items:
          $ref: "#/$defs/Pet"
        title: Pets
        type: array
    required:
      - id
      - name
      - pets
    title: Owner
    type: object
  Pet:
    properties:
      breed:
        title: Breed
        type: string
      id:
        title: Id
        type: integer
      name:
        title: Name
        type: string
    required:
      - id
      - name
      - breed
    title: Pet
    type: object
```

---

## !!steps Customize Pydantic JSON Schema Generation

Let's customize the generated JSON schema to reference the `Pet` model using the `#/components/schemas` path instead of `$defs`.

We'll use the `ref_template` parameter of the `models_json_schema` function to specify the reference template.

```python ! models.py
# !focus(21)
import yaml
from pydantic import BaseModel
from pydantic.json_schema import models_json_schema


class Pet(BaseModel):
    id: int
    name: str
    breed: str


class Owner(BaseModel):
    id: int
    name: str
    pets: list[Pet]


def print_json_schema(models):
    _, schemas = models_json_schema(
        [(model, "validation") for model in models],
        ref_template="#/components/schemas/{model}",
    )
    print(yaml.dump(schemas))


if __name__ == "__main__":
    print_json_schema([Pet, Owner])
```

---

## !!steps

Next, we'll update the `print_json_schema` function to print a JSON schema that resembles an OpenAPI schema's `components` section.

```python ! models.py
# !focus(23,27,28[21:34])
import yaml
from pydantic import BaseModel
from pydantic.json_schema import models_json_schema


class Pet(BaseModel):
    id: int
    name: str
    breed: str


class Owner(BaseModel):
    id: int
    name: str
    pets: list[Pet]


def print_json_schema(models):
    _, schemas = models_json_schema(
        [(model, "validation") for model in models],
        ref_template="#/components/schemas/{model}",
    )
    openapi_schema = {
        "components": {
            "schemas": schemas.get('$defs'),
        }
    }
    print(yaml.dump(openapi_schema))


if __name__ == "__main__":
    print_json_schema([Pet, Owner])
```

---

## !!steps

Run `python models.py` to generate the OpenAPI schema for both the `Pet` and `Owner` models.

The generated OpenAPI schema includes the `components` section, with definitions for both the `Pet` and `Owner` models.

```yaml ! Output
# !focus(1:2,13)
components:
  schemas:
    Owner:
      properties:
        id:
          title: Id
          type: integer
        name:
          title: Name
          type: string
        pets:
          items:
            $ref: "#/components/schemas/Pet"
          title: Pets
          type: array
      required:
        - id
        - name
        - pets
      title: Owner
      type: object
    Pet:
      properties:
        breed:
          title: Breed
          type: string
        id:
          title: Id
          type: integer
        name:
          title: Name
          type: string
      required:
        - id
        - name
        - breed
      title: Pet
      type: object
```

---

## !!steps

The JSON Schema we generated resembles an OpenAPI schema's `components` section, but to generate a valid OpenAPI schema, we need to add the `openapi` and `info` sections.

Edit the `print_json_schema` function in `models.py` to include the `openapi` and `info` sections in the generated OpenAPI schema.

```python ! models.py
# !focus(24:28)
import yaml
from pydantic import BaseModel
from pydantic.json_schema import models_json_schema


class Pet(BaseModel):
    id: int
    name: str
    breed: str


class Owner(BaseModel):
    id: int
    name: str
    pets: list[Pet]


def print_json_schema(models):
    _, schemas = models_json_schema(
        [(model, "validation") for model in models],
        ref_template="#/components/schemas/{model}",
    )
    openapi_schema = {
        "openapi": "3.1.0",
        "info": {
            "title": "Pet Sitter API",
            "version": "0.0.1",
        },
        "components": {
            "schemas": schemas.get('$defs'),
        }
    }
    print(yaml.dump(openapi_schema))


if __name__ == "__main__":
    print_json_schema([Pet, Owner])
```

---

## !!steps

Run `python models.py` to generate the complete OpenAPI schema for both the `Pet` and `Owner` models.

The generated OpenAPI schema includes the `openapi`, `info`, and `components` sections with definitions for both the `Pet` and `Owner` models.

```yaml ! Output
# !focus(1:4)
openapi: 3.1.0
info:
  title: Pet Sitter API
  version: 0.0.1
components:
  schemas:
    Owner:
      properties:
        id:
          title: Id
          type: integer
        name:
          title: Name
          type: string
        pets:
          items:
            $ref: "#/components/schemas/Pet"
          title: Pets
          type: array
      required:
        - id
        - name
        - pets
      title: Owner
      type: object
    Pet:
      properties:
        id:
          title: Id
          type: integer
        name:
          title: Name
          type: string
        breed:
          title: Breed
          type: string
      required:
        - id
        - name
        - breed
      title: Pet
      type: object
```

---

Now we have a complete OpenAPI document that we can use to generate SDK clients for our API. However, the generated OpenAPI schema does not contain descriptions or example values for the models. We can add these details to the Pydantic models to improve the generated OpenAPI schema.

---

## !!steps Add Descriptions to Pydantic Models

Let's add docstrings to the `Pet` and `Owner` models to include additional information in the generated OpenAPI schema.

```python ! models.py
# !focus(7:13,20:26)
import yaml
from pydantic import BaseModel
from pydantic.json_schema import models_json_schema


class Pet(BaseModel):
    """
    A Pet in the system.

    ID is unique.
    Can have multiple owners.
    """

    id: int
    name: str
    breed: str


class Owner(BaseModel):
    """
    An Owner of Pets in the system.

    ID is unique.
    Can have multiple pets.
    """

    id: int
    name: str
    pets: list[Pet]


def print_json_schema(models):
    _, schemas = models_json_schema(
        [(model, "validation") for model in models],
        ref_template="#/components/schemas/{model}",
    )
    openapi_schema = {
        "openapi": "3.1.0",
        "info": {
            "title": "Pet Sitter API",
            "version": "0.0.1",
        },
        "components": {
            "schemas": schemas.get("$defs"),
        },
    }
    print(yaml.dump(openapi_schema, sort_keys=False))


if __name__ == "__main__":
    print_json_schema([Pet, Owner])
```

---

## !!steps

If we run `python models.py`, we see that our `Owner` schema now includes a description field, derived from the docstring we added to the `Owner` Pydantic model.

```yaml ! Output
# !focus(8:13)
openapi: 3.1.0
info:
  title: Pet Sitter API
  version: 0.0.1
components:
  schemas:
    Owner:
      description: "An Owner of Pets in the system.


        ID is unique.

        Can have multiple pets."
      properties:
        id:
          title: Id
          type: integer
        name:
          title: Name
          type: string
        pets:
          items:
            $ref: "#/components/schemas/Pet"
          title: Pets
          type: array
      required:
        - id
        - name
        - pets
      title: Owner
      type: object
    Pet:
      description: "A Pet in the system.


        ID is unique.

        Can have multiple owners."
      properties:
        id:
          title: Id
          type: integer
        name:
          title: Name
          type: string
        breed:
          title: Breed
          type: string
      required:
        - id
        - name
        - breed
      title: Pet
      type: object
```

---

## !!steps

The `Pet` schema now also includes a description field, derived from the docstring we added to the `Pet` Pydantic model.

```yaml ! Output
# !focus(33:38)
openapi: 3.1.0
info:
  title: Pet Sitter API
  version: 0.0.1
components:
  schemas:
    Owner:
      description: 'An Owner of Pets in the system.


        ID is unique.

        Can have multiple pets.'
      properties:
        id:
          title: Id
          type: integer
        name:
          title: Name
          type: string
        pets:
          items:
            $ref: '#/components/schemas/Pet'
          title: Pets
          type: array
      required:
      - id
      - name
      - pets
      title: Owner
      type: object
    Pet:
      description: 'A Pet in the system.


        ID is unique.

        Can have multiple owners.'
      properties:
        id:
          title: Id
          type: integer
        name:
          title: Name
          type: string
        breed:
          title: Breed
          type: string
      required:
      - id
      - name
      - breed
      title: Pet
      type: object
```

---

## !!steps Add OpenAPI Titles and Descriptions to Pydantic Fields

Let's add titles and descriptions to the fields of the `Pet` and `Owner` models to include additional information in the generated OpenAPI schema.

We'll use the `Field` class from Pydantic to add descriptions to the fields.

```python ! models.py
# !mark(2,14:16)
# !focus(2[33:37],14[15:83],15[17:75],16[18:78])
import yaml
from pydantic import BaseModel, Field
from pydantic.json_schema import models_json_schema


class Pet(BaseModel):
    """
    A Pet in the system.

    ID is unique.
    Can have multiple owners.
    """

    id: int = Field(..., title="Pet ID", description="The pet's unique identifier")
    name: str = Field(..., title="Pet Name", description="Name of the pet")
    breed: str = Field(..., title="Pet Breed", description="Breed of the pet")


class Owner(BaseModel):
    """
    An Owner of Pets in the system.

    ID is unique.
    Can have multiple pets.
    """

    id: int = Field(..., title="Owner ID", description="Owner's unique identifier")
    name: str = Field(..., title="Owner Name", description="The owner's full name")
    pets: list[Pet] = Field(
        ..., title="Owner's Pets", description="The pets that belong to this owner"
    )


def print_json_schema(models):
    _, schemas = models_json_schema(
        [(model, "validation") for model in models],
        ref_template="#/components/schemas/{model}",
    )
    openapi_schema = {
        "openapi": "3.1.0",
        "info": {
            "title": "Pet Sitter API",
            "version": "0.0.1",
        },
        "components": {
            "schemas": schemas.get("$defs"),
        },
    }
    print(yaml.dump(openapi_schema, sort_keys=False))


if __name__ == "__main__":
    print_json_schema([Pet, Owner])
```

---

## !!steps

If we run `python models.py`, we see that our `Pet` schema now includes descriptions for each field.

```yaml ! Output
# !focus(44:45,48:49,52:53)
openapi: 3.1.0
info:
  title: Pet Sitter API
  version: 0.0.1
components:
  schemas:
    Owner:
      description: "An Owner of Pets in the system.


        ID is unique.

        Can have multiple pets."
      properties:
        id:
          description: Owner's unique identifier
          title: Owner ID
          type: integer
        name:
          description: The owner's full name
          title: Owner Name
          type: string
        pets:
          description: The pets that belong to this owner
          items:
            $ref: "#/components/schemas/Pet"
          title: Owner's Pets
          type: array
      required:
        - id
        - name
        - pets
      title: Owner
      type: object
    Pet:
      description: "A Pet in the system.


        ID is unique.

        Can have multiple owners."
      properties:
        id:
          description: The pet's unique identifier
          title: Pet ID
          type: integer
        name:
          description: Name of the pet
          title: Pet Name
          type: string
        breed:
          description: Breed of the pet
          title: Pet Breed
          type: string
      required:
        - id
        - name
        - breed
      title: Pet
      type: object
```

---

## !!steps Add OpenAPI Example Values to Pydantic Models

Examples help API users understand your API's data structures, and some SDK and documentation generators use OpenAPI example values to generate useful code snippets and documentation.

Let's add example values to the `Pet` and `Owner` Pydantic models. Once again, we'll use the `Field` class from Pydantic to add example values to the fields.

Note that the examples are added as a list per field, using the `examples` parameter.

```python ! models.py
# !focus(18[9:20],24[9:25],30[9:60])
import yaml
from pydantic import BaseModel, Field
from pydantic.json_schema import models_json_schema


class Pet(BaseModel):
    """
    A Pet in the system.

    ID is unique.
    Can have multiple owners.
    """

    id: int = Field(
        ...,
        title="Pet ID",
        description="The pet's unique identifier",
        examples=[1],
    )
    name: str = Field(
        ...,
        title="Pet Name",
        description="Name of the pet",
        examples=["Fido"],
    )
    breed: str = Field(
        ...,
        title="Pet Breed",
        description="Breed of the pet",
        examples=["Golden Retriever", "Siamese", "Parakeet"],
    )


class Owner(BaseModel):
    """
    An Owner of Pets in the system.

    ID is unique.
    Can have multiple pets.
    """

    id: int = Field(
        ...,
        title="Owner ID",
        description="Owner's unique identifier",
        examples=[1],
    )
    name: str = Field(
        ...,
        title="Owner Name",
        description="The owner's full name",
        examples=["John Doe"],
    )
    pets: list[Pet] = Field(
        ...,
        title="Owner's Pets",
        description="The pets that belong to this owner",
        examples=[{"id": 1}],
    )


def print_json_schema(models):
    _, schemas = models_json_schema(
        [(model, "validation") for model in models],
        ref_template="#/components/schemas/{model}",
    )
    openapi_schema = {
        "openapi": "3.1.0",
        "info": {
            "title": "Pet Sitter API",
            "version": "0.0.1",
        },
        "components": {
            "schemas": schemas.get("$defs"),
        },
    }
    print(yaml.dump(openapi_schema, sort_keys=False))


if __name__ == "__main__":
    print_json_schema([Pet, Owner])
```

---

## !!steps

If we run `python models.py`, we see that our `Pet` schema now includes example values for each field.

```yaml ! Output
# !focus(51:52,57:58,63:66)
openapi: 3.1.0
info:
  title: Pet Sitter API
  version: 0.0.1
components:
  schemas:
    Owner:
      description: "An Owner of Pets in the system.


        ID is unique.

        Can have multiple pets."
      properties:
        id:
          description: Owner's unique identifier
          examples:
            - 1
          title: Owner ID
          type: integer
        name:
          description: The owner's full name
          examples:
            - John Doe
          title: Owner Name
          type: string
        pets:
          description: The pets that belong to this owner
          examples:
            - id: 1
          items:
            $ref: "#/components/schemas/Pet"
          title: Owner's Pets
          type: array
      required:
        - id
        - name
        - pets
      title: Owner
      type: object
    Pet:
      description: "A Pet in the system.


        ID is unique.

        Can have multiple owners."
      properties:
        id:
          description: The pet's unique identifier
          examples:
            - 1
          title: Pet ID
          type: integer
        name:
          description: Name of the pet
          examples:
            - Fido
          title: Pet Name
          type: string
        breed:
          description: Breed of the pet
          examples:
            - Golden Retriever
            - Siamese
            - Parakeet
          title: Pet Breed
          type: string
      required:
        - id
        - name
        - breed
      title: Pet
      type: object
```

---

## !!steps Marking Fields as Optional in Pydantic Models

By default, Pydantic marks all fields as required. You can mark a field as optional by setting the `default` parameter to `None`.

Let's mark the `breed` field in the `Pet` model as optional by setting the `default` parameter to `None`.

```python ! models.py
# !focus(26[16:21],27[9:12])
import yaml
from pydantic import BaseModel, Field
from pydantic.json_schema import models_json_schema


class Pet(BaseModel):
    """
    A Pet in the system.

    ID is unique.
    Can have multiple owners.
    """

    id: int = Field(
        ...,
        title="Pet ID",
        description="The pet's unique identifier",
        examples=[1],
    )
    name: str = Field(
        ...,
        title="Pet Name",
        description="Name of the pet",
        examples=["Fido"],
    )
    breed: str | None = Field(
        None,
        title="Pet Breed",
        description="Breed of the pet",
        examples=["Golden Retriever", "Siamese", "Parakeet"],
    )


class Owner(BaseModel):
    """
    An Owner of Pets in the system.

    ID is unique.
    Can have multiple pets.
    """

    id: int = Field(
        ...,
        title="Owner ID",
        description="Owner's unique identifier",
        examples=[1],
    )
    name: str = Field(
        ...,
        title="Owner Name",
        description="The owner's full name",
        examples=["John Doe"],
    )
    pets: list[Pet] = Field(
        ...,
        title="Owner's Pets",
        description="The pets that belong to this owner",
        examples=[{"id": 1}],
    )


def print_json_schema(models):
    _, schemas = models_json_schema(
        [(model, "validation") for model in models],
        ref_template="#/components/schemas/{model}",
    )
    openapi_schema = {
        "openapi": "3.1.0",
        "info": {
            "title": "Pet Sitter API",
            "version": "0.0.1",
        },
        "components": {
            "schemas": schemas.get("$defs"),
        },
    }
    print(yaml.dump(openapi_schema, sort_keys=False))


if __name__ == "__main__":
    print_json_schema([Pet, Owner])
```

---

## !!steps

If we run `python models.py`, we see that the `breed` field in the `Pet` schema now has two types: `string` and `null`, and it has been removed from the `required` list. Only `id` and `name` are required fields after marking `breed` as optional.

```yaml ! Output
# !focus(61:74)
openapi: 3.1.0
info:
  title: Pet Sitter API
  version: 0.0.1
components:
  schemas:
    Owner:
      description: "An Owner of Pets in the system.


        ID is unique.

        Can have multiple pets."
      properties:
        id:
          description: Owner's unique identifier
          examples:
            - 1
          title: Owner ID
          type: integer
        name:
          description: The owner's full name
          examples:
            - John Doe
          title: Owner Name
          type: string
        pets:
          description: The pets that belong to this owner
          examples:
            - id: 1
          items:
            $ref: "#/components/schemas/Pet"
          title: Owner's Pets
          type: array
      required:
        - id
        - name
        - pets
      title: Owner
      type: object
    Pet:
      description: "A Pet in the system.


        ID is unique.

        Can have multiple owners."
      properties:
        id:
          description: The pet's unique identifier
          examples:
            - 1
          title: Pet ID
          type: integer
        name:
          description: Name of the pet
          examples:
            - Fido
          title: Pet Name
          type: string
        breed:
          anyOf:
            - type: string
            - type: "null"
          default: null
          description: Breed of the pet
          examples:
            - Golden Retriever
            - Siamese
            - Parakeet
          title: Pet Breed
      required:
        - id
        - name
      title: Pet
      type: object
```

---

## !!steps Adding Enums to OpenAPI using Pydantic Models

Enums in OpenAPI are useful for defining a set of possible values for a field.

Let's add an enum called `PetType` to the `Pet` model to represent different types of pets.

```python ! models.py
# !focus(1[1:24],25:30,7:14)
from enum import StrEnum
import yaml
from pydantic import BaseModel, Field
from pydantic.json_schema import models_json_schema


class PetType(StrEnum):
    """
    An enumeration of pet types.
    """

    DOG = "dog"
    CAT = "cat"
    BIRD = "bird"


class Pet(BaseModel):
    """
    A Pet in the system.

    ID is unique.
    Can have multiple owners.
    """

    pet_type: PetType = Field(
        ...,
        title="Pet Type",
        description="Type of pet",
        examples=["dog", "cat", "bird"],
    )
    id: int = Field(
        ...,
        title="Pet ID",
        description="The pet's unique identifier",
        examples=[1],
    )
    name: str = Field(
        ...,
        title="Pet Name",
        description="Name of the pet",
        examples=["Fido"],
    )
    breed: str | None = Field(
        None,
        title="Pet Breed",
        description="Breed of the pet",
        examples=["Golden Retriever", "Siamese", "Parakeet"],
    )


class Owner(BaseModel):
    """
    An Owner of Pets in the system.

    ID is unique.
    Can have multiple pets.
    """

    id: int = Field(
        ...,
        title="Owner ID",
        description="Owner's unique identifier",
        examples=[1],
    )
    name: str = Field(
        ...,
        title="Owner Name",
        description="The owner's full name",
        examples=["John Doe"],
    )
    pets: list[Pet] = Field(
        ...,
        title="Owner's Pets",
        description="The pets that belong to this owner",
        examples=[{"id": 1}],
    )


def print_json_schema(models):
    _, schemas = models_json_schema(
        [(model, "validation") for model in models],
        ref_template="#/components/schemas/{model}",
    )
    openapi_schema = {
        "openapi": "3.1.0",
        "info": {
            "title": "Pet Sitter API",
            "version": "0.0.1",
        },
        "components": {
            "schemas": schemas.get("$defs"),
        },
    }
    print(yaml.dump(openapi_schema, sort_keys=False))


if __name__ == "__main__":
    print_json_schema([Pet, Owner])
```

---

## !!steps

In our generated OpenAPI schema, we have a new `pet_type` field in the `Pet` schema.

```yaml ! Output
# !focus(49:57)
openapi: 3.1.0
info:
  title: Pet Sitter API
  version: 0.0.1
components:
  schemas:
    Owner:
      description: "An Owner of Pets in the system.


        ID is unique.

        Can have multiple pets."
      properties:
        id:
          description: Owner's unique identifier
          examples:
            - 1
          title: Owner ID
          type: integer
        name:
          description: The owner's full name
          examples:
            - John Doe
          title: Owner Name
          type: string
        pets:
          description: The pets that belong to this owner
          examples:
            - id: 1
          items:
            $ref: "#/components/schemas/Pet"
          title: Owner's Pets
          type: array
      required:
        - id
        - name
        - pets
      title: Owner
      type: object
    Pet:
      description: "A Pet in the system.


        ID is unique.

        Can have multiple owners."
      properties:
        pet_type:
          allOf:
            - $ref: "#/components/schemas/PetType"
          description: Type of pet
          examples:
            - dog
            - cat
            - bird
          title: Pet Type
        id:
          description: The pet's unique identifier
          examples:
            - 1
          title: Pet ID
          type: integer
        name:
          description: Name of the pet
          examples:
            - Fido
          title: Pet Name
          type: string
        breed:
          anyOf:
            - type: string
            - type: "null"
          default: null
          description: Breed of the pet
          examples:
            - Golden Retriever
            - Siamese
            - Parakeet
          title: Pet Breed
      required:
        - pet_type
        - id
        - name
      title: Pet
      type: object
    PetType:
      description: An enumeration of pet types.
      enum:
        - dog
        - cat
        - bird
      title: PetType
      type: string
```

---

This enum is represented as a separate schema in the OpenAPI document.

</ScrollyCoding>

## Adding Paths and Operations to the OpenAPI Schema

Now that we have generated an OpenAPI schema from our Pydantic models, we can use the schema to generate SDK clients for our API.

However, the OpenAPI document we generated, while valid, does not include the `paths` section, which defines the API endpoints and operations.

When using Pydantic with FastAPI, you can define your API endpoints and operations directly in your FastAPI application. [FastAPI automatically generates the OpenAPI schema for your API](./fastapi.mdx), including the `paths` section.

Let's see how we can define API endpoints and operations in a framework-agnostic way and add them to the OpenAPI schema.

### Install openapi-pydantic

We'll use the [`openapi-pydantic`](https://github.com/mike-oakley/openapi-pydantic/) library to define a complete OpenAPI schema with paths and operations.

The benefit of using `openapi-pydantic` is that it allows you to define the API endpoints and operations in a Python dictionary, while still getting the benefit of Pydantic's IDE support and type checking.

The library includes convenience methods to convert Pydantic models to OpenAPI schema components and add them to the OpenAPI schema.

Install the `openapi-pydantic` library:

```bash Terminal
pip install openapi-pydantic
```

<ScrollyCoding className="ch-scrollycoding-full-height ch-scrollycoding-force-focus-scroll">

## !!steps

Create a new Python file called `api.py` and define the API endpoints and operations using the `openapi-pydantic` library.

The `api.py` file saves the complete OpenAPI schema to a file named `openapi.yaml`.

```python ! api.py
from typing import List
import yaml

from pydantic import BaseModel, Field

from openapi_pydantic.v3 import OpenAPI, Info, PathItem, Operation
from openapi_pydantic.util import PydanticSchema, construct_open_api_with_schema_class

from models import Pet, Owner


class PetsResponse(BaseModel):
    """A response containing a list of pets"""

    pets: List[Pet] = Field(..., description="List of pets")


class OwnersResponse(BaseModel):
    """A response containing a list of owners"""

    owners: List[Owner] = Field(..., description="List of owners")


def construct_base_open_api() -> OpenAPI:
    return OpenAPI(
        openapi="3.1.0",
        info=Info(
            title="Pet Sitter API",
            version="0.0.1",
        ),
        servers=[
            {
                "url": "http://127.0.0.1:4010",
                "description": "Local prism server",
            },
        ],
        paths={
            "/pets": PathItem(
                get=Operation(
                    operationId="listPets",
                    description="List all pets",
                    responses={
                        "200": {
                            "description": "A list of pets",
                            "content": {
                                "application/json": {
                                    "schema": PydanticSchema(schema_class=PetsResponse)
                                }
                            },
                        }
                    },
                ),
                post=Operation(
                    operationId="createPet",
                    description="Create a pet",
                    requestBody={
                        "content": {
                            "application/json": {
                                "schema": PydanticSchema(schema_class=Pet)
                            }
                        }
                    },
                    responses={
                        "201": {
                            "description": "Pet created",
                            "content": {
                                "application/json": {
                                    "schema": PydanticSchema(schema_class=Pet)
                                }
                            },
                        }
                    },
                ),
            ),
            "/pets/{pet_id}": PathItem(
                get=Operation(
                    operationId="getPetById",
                    description="Get a pet by ID",
                    parameters=[
                        {
                            "name": "pet_id",
                            "in": "path",
                            "description": "ID of pet to return",
                            "required": True,
                            "schema": {
                                "type": "integer",
                                "format": "int64",
                            },
                            "examples": {"1": {"value": 1}},
                        },
                    ],
                    responses={
                        "200": {
                            "description": "A pet",
                            "content": {
                                "application/json": {
                                    "schema": PydanticSchema(schema_class=Pet)
                                }
                            },
                        }
                    },
                ),
            ),
            "/owners": PathItem(
                get=Operation(
                    operationId="listOwners",
                    description="List all owners",
                    responses={
                        "200": {
                            "description": "A list of owners",
                            "content": {
                                "application/json": {
                                    "schema": PydanticSchema(
                                        schema_class=OwnersResponse
                                    )
                                }
                            },
                        }
                    },
                ),
            ),
        },
    )


open_api = construct_base_open_api()
open_api = construct_open_api_with_schema_class(open_api)

if __name__ == "__main__":
    with open("openapi.yaml", "w") as file:
        file.write(
            yaml.dump(
                open_api.model_dump(
                    by_alias=True,
                    mode="json",
                    exclude_none=True,
                    exclude_unset=True,
                ),
                sort_keys=False,
            )
        )
```

---

## !!steps

Run `python api.py` to generate the complete OpenAPI schema with paths and operations and save it to a file named `openapi.yaml`.

```yaml ! openapi.yaml
openapi: 3.1.0
info:
  title: Pet Sitter API
  version: 0.0.1
servers:
  - url: http://127.0.0.1:4010
    description: Local prism server
paths:
  /pets:
    get:
      description: List all pets
      operationId: listPets
      responses:
        "200":
          description: A list of pets
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/PetsResponse"
      deprecated: false
    post:
      description: Create a pet
      operationId: createPet
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/Pet"
        required: false
      responses:
        "201":
          description: Pet created
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/Pet"
      deprecated: false
  /pets/{pet_id}:
    get:
      description: Get a pet by ID
      operationId: getPetById
      parameters:
        - description: ID of pet to return
          required: true
          deprecated: false
          explode: false
          schema:
            type: integer
            format: int64
          examples:
            "1":
              value: 1
          name: pet_id
          in: path
          allowEmptyValue: false
          allowReserved: false
      responses:
        "200":
          description: A pet
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/Pet"
      deprecated: false
  /owners:
    get:
      description: List all owners
      operationId: listOwners
      responses:
        "200":
          description: A list of owners
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/OwnersResponse"
      deprecated: false
components:
  schemas:
    Owner:
      properties:
        id:
          type: integer
          title: Owner ID
          description: Owner's unique identifier
          examples:
            - 1
        name:
          type: string
          title: Owner Name
          description: The owner's full name
          examples:
            - John Doe
        pets:
          items:
            $ref: "#/components/schemas/Pet"
          type: array
          title: Owner's Pets
          description: The pets that belong to this owner
          examples:
            - id: 1
      type: object
      required:
        - id
        - name
        - pets
      title: Owner
      description: "An Owner of Pets in the system.


        ID is unique.

        Can have multiple pets."
    OwnersResponse:
      properties:
        owners:
          items:
            $ref: "#/components/schemas/Owner"
          type: array
          title: Owners
          description: List of owners
      type: object
      required:
        - owners
      title: OwnersResponse
      description: A response containing a list of owners
    Pet:
      properties:
        pet_type:
          allOf:
            - $ref: "#/components/schemas/PetType"
          title: Pet Type
          description: Type of pet
          examples:
            - dog
            - cat
            - bird
        id:
          type: integer
          title: Pet ID
          description: The pet's unique identifier
          examples:
            - 1
        name:
          type: string
          title: Pet Name
          description: Name of the pet
          examples:
            - Fido
        breed:
          anyOf:
            - type: string
            - type: "null"
          title: Pet Breed
          description: Breed of the pet
          examples:
            - Golden Retriever
            - Siamese
            - Parakeet
      type: object
      required:
        - pet_type
        - id
        - name
      title: Pet
      description: "A Pet in the system.


        ID is unique.

        Can have multiple owners."
    PetType:
      type: string
      enum:
        - dog
        - cat
        - bird
      title: PetType
      description: An enumeration of pet types.
    PetsResponse:
      properties:
        pets:
          items:
            $ref: "#/components/schemas/Pet"
          type: array
          title: Pets
          description: List of pets
      type: object
      required:
        - pets
      title: PetsResponse
      description: A response containing a list of pets
```

---

## !!steps

Our `api.py` file imports `Pet` and `Owner` models from `models.py`.

```python ! api.py
# !focus(1:9)
# !mark(9)
```

---

## !!steps

We'll use the `models.py` file from the previous steps to define the Pydantic models for `Pet` and `Owner`.

```python ! models.py
# !focus(17:48)
from enum import StrEnum
import yaml
from pydantic import BaseModel, Field
from pydantic.json_schema import models_json_schema


class PetType(StrEnum):
    """
    An enumeration of pet types.
    """

    DOG = "dog"
    CAT = "cat"
    BIRD = "bird"


class Pet(BaseModel):
    """
    A Pet in the system.

    ID is unique.
    Can have multiple owners.
    """

    pet_type: PetType = Field(
        ...,
        title="Pet Type",
        description="Type of pet",
        examples=["dog", "cat", "bird"],
    )
    id: int = Field(
        ...,
        title="Pet ID",
        description="The pet's unique identifier",
        examples=[1],
    )
    name: str = Field(
        ...,
        title="Pet Name",
        description="Name of the pet",
        examples=["Fido"],
    )
    breed: str | None = Field(
        None,
        title="Pet Breed",
        description="Breed of the pet",
        examples=["Golden Retriever", "Siamese", "Parakeet"],
    )


class Owner(BaseModel):
    """
    An Owner of Pets in the system.

    ID is unique.
    Can have multiple pets.
    """

    id: int = Field(
        ...,
        title="Owner ID",
        description="Owner's unique identifier",
        examples=[1],
    )
    name: str = Field(
        ...,
        title="Owner Name",
        description="The owner's full name",
        examples=["John Doe"],
    )
    pets: list[Pet] = Field(
        ...,
        title="Owner's Pets",
        description="The pets that belong to this owner",
        examples=[{"id": 1}],
    )


def print_json_schema(models):
    _, schemas = models_json_schema(
        [(model, "validation") for model in models],
        ref_template="#/components/schemas/{model}",
    )
    openapi_schema = {
        "openapi": "3.1.0",
        "info": {
            "title": "Pet Sitter API",
            "version": "0.0.1",
        },
        "components": {
            "schemas": schemas.get("$defs"),
        },
    }
    print(yaml.dump(openapi_schema, sort_keys=False))


if __name__ == "__main__":
    print_json_schema([Pet, Owner])
```

---

## !!steps

In `api.py`, we then define two response schemas as Pydantic models: `PetsResponse` and `OwnersResponse`.

Defining response schemas as Pydantic models allows us to reuse them in multiple operations, and to use them for validation and serialization in our API request handlers.

```python ! api.py
# !focus(12:21)

```

---

## !!steps

We'll start by defining a function called `construct_base_open_api` that returns an `OpenAPI` object with the base configuration for our API.

The function defines the API title, version, and servers, and includes the paths for the `/pets`, `/pets/{pet_id}`, and `/owners` endpoints.

```python ! api.py
# !focus(24:36)
```

---

## !!steps

The `/pets` path includes two operations: `GET` to list all pets and `POST` to create a pet.

The `GET` operation returns a list of pets using the `PetsResponse` schema.

```python ! api.py
# !focus(38:52)
```

---

## !!steps

Note that we added `operationId` and `description` fields to the operations to provide additional information about the operation.

Clear operation IDs and descriptions help API users understand the purpose of each operation and allow SDK generators to create more informative client code.

```python ! api.py
# !focus(38:52)
# !mark(40:41)

```

---

## !!steps

The `POST` operation creates a pet using the `Pet` schema as the request body and returns the created pet using the `Pet` schema.

We use the `PydanticSchema` class from `openapi-pydantic` to reference the Pydantic model in the OpenAPI schema.

In a real-world application, you would likely not include the pet's ID in the request body as the server would generate the ID, but for simplicity, we include it here.

```python ! api.py
# !focus(53:73)
# !mark(59,68)

```

---

## !!steps

This translates to the following OpenAPI operation:

```yaml ! openapi.yaml
# !focus(21:37)
```

---

## !!steps

The `/pets/{pet_id}` path includes a `GET` operation to get a pet by ID.

The operation includes a path parameter `pet_id` to specify the ID of the pet to retrieve.

```python ! api.py
# !focus(75:102)
```

---

## !!steps

The `GET` operation's `parameters` field includes the path parameter `pet_id` with a description, required flag, and schema definition.

The `responses` field includes a `200` response with the `Pet` schema as the response body.

```python ! api.py
# !focus(75:102)
# !mark(79:91)

```

---

## !!steps

This translates to the following OpenAPI operation.

Note how the generated schema closely resembles the Pydantic model.

```yaml ! openapi.yaml
# !focus(38:64)
```

---

## !!steps

We'll leave the rest of the `openapi.yaml` file, as it is similar to the components generated in the previous section.

```python ! openapi.yaml

```

</ScrollyCoding>

## Generating an SDK from the OpenAPI Schema

Now that we have a complete OpenAPI schema with paths and operations, we can use it to generate an SDK client for our API.

### Prerequisites for SDK Generation

Install Speakeasy by following the [Speakeasy installation instructions](/docs/speakeasy-cli/getting-started#install).

On macOS, you can install Speakeasy using Homebrew:

```bash Terminal
brew install speakeasy-api/homebrew-tap/speakeasy
```

Authenticate with Speakeasy using the following command:

```bash Terminal
speakeasy auth login
```

### Generate an SDK Using Speakeasy

Run the following command to generate an SDK from the `openapi.yaml` file:

```bash Terminal
speakeasy quickstart
```

Follow the onscreen prompts to provide the necessary configuration details for your new SDK such as the name, schema location and output path. Enter `openapi.yaml` when prompted for the OpenAPI document location and select TypeScript when prompted for which language you would like to generate.

### Adding Speakeasy Extensions to the OpenAPI Schema

Speakeasy uses [OpenAPI extensions](../../openapi/extensions.md) to provide additional information for generating SDKs.

We can add extensions using [OpenAPI Overlays](../../openapi/overlays.mdx), which are YAML files that [Speakeasy overlays on top of the OpenAPI schema](/docs/prep-openapi/overlays/create-overlays).

Alternatively, you can add extensions directly to the OpenAPI schema using the `x-` prefix.

For example, you can add the [`x-speakeasy-retries` extension](../../docs/customize-sdks/retries.mdx) to have Speakeasy generate retry logic in the SDK.

<ScrollyCoding className="ch-scrollycoding-full-height ch-scrollycoding-force-focus-scroll">

## !!steps

Import the `Dict` and `Any` types from the `typing` module in `api.py`, and `ConfigDict` from `pydantic`.

We'll use these types to define the `x-speakeasy-retries` extension in the OpenAPI schema.

```python ! api.py
# !focus(1[24:34],4[40:49])
from typing import List, Dict, Any
import yaml

from pydantic import BaseModel, Field, ConfigDict

from openapi_pydantic.v3 import OpenAPI, Info, PathItem, Operation
from openapi_pydantic.util import PydanticSchema, construct_open_api_with_schema_class

from models import Pet, Owner


class PetsResponse(BaseModel):
    """A response containing a list of pets"""

    pets: List[Pet] = Field(..., description="List of pets")


class OwnersResponse(BaseModel):
    """A response containing a list of owners"""

    owners: List[Owner] = Field(..., description="List of owners")


class OpenAPIwithRetries(OpenAPI):
    """
    OpenAPI with xSpeakeasyRetries extension

    This class extends the OpenAPI model to include the x-speakeasy-retries extension.
    """

    xSpeakeasyRetries: Dict[str, Any] = Field(
        ...,
        description="Retry configuration for the API",
        alias="x-speakeasy-retries",
    )

    model_config = ConfigDict(
        populate_by_name=True,
    )


def construct_base_open_api() -> OpenAPIwithRetries:
    return OpenAPIwithRetries(
        openapi="3.1.0",
        info=Info(
            title="Pet Sitter API",
            version="0.0.1",
        ),
        servers=[
            {
                "url": "http://127.0.0.1:4010",
                "description": "Local prism server",
            },
        ],
        xSpeakeasyRetries={
            "strategy": "backoff",
            "backoff": {
                "initialInterval": 500,
                "maxInterval": 60000,
                "maxElapsedTime": 3600000,
                "exponent": 1.5,
            },
            "statusCodes": ["5XX"],
            "retryConnectionErrors": True,
        },
        paths={
            "/pets": PathItem(
                get=Operation(
                    operationId="listPets",
                    description="List all pets",
                    responses={
                        "200": {
                            "description": "A list of pets",
                            "content": {
                                "application/json": {
                                    "schema": PydanticSchema(schema_class=PetsResponse)
                                }
                            },
                        }
                    },
                ),
                post=Operation(
                    operationId="createPet",
                    description="Create a pet",
                    requestBody={
                        "content": {
                            "application/json": {
                                "schema": PydanticSchema(schema_class=Pet)
                            }
                        }
                    },
                    responses={
                        "201": {
                            "description": "Pet created",
                            "content": {
                                "application/json": {
                                    "schema": PydanticSchema(schema_class=Pet)
                                }
                            },
                        }
                    },
                ),
            ),
            "/pets/{pet_id}": PathItem(
                get=Operation(
                    operationId="getPetById",
                    description="Get a pet by ID",
                    parameters=[
                        {
                            "name": "pet_id",
                            "in": "path",
                            "description": "ID of pet to return",
                            "required": True,
                            "schema": {
                                "type": "integer",
                                "format": "int64",
                            },
                            "examples": {"1": {"value": 1}},
                        },
                    ],
                    responses={
                        "200": {
                            "description": "A pet",
                            "content": {
                                "application/json": {
                                    "schema": PydanticSchema(schema_class=Pet)
                                }
                            },
                        }
                    },
                ),
            ),
            "/owners": PathItem(
                get=Operation(
                    operationId="listOwners",
                    description="List all owners",
                    responses={
                        "200": {
                            "description": "A list of owners",
                            "content": {
                                "application/json": {
                                    "schema": PydanticSchema(
                                        schema_class=OwnersResponse
                                    )
                                }
                            },
                        }
                    },
                ),
            ),
        },
    )


open_api = construct_base_open_api()
open_api = construct_open_api_with_schema_class(open_api)

if __name__ == "__main__":
    with open("openapi.yaml", "w") as file:
        file.write(
            yaml.dump(
                open_api.model_dump(
                    by_alias=True,
                    mode="json",
                    exclude_none=True,
                    exclude_unset=True,
                ),
                sort_keys=False,
            )
        )
```

---

## !!steps

In the `OpenAPIwithRetries` class, we define the `x-speakeasy-retries` extension.

Note that we need to use the `alias` parameter to define the extension with the `x-` prefix, then allow ourselves to use the `xSpeakeasyRetries` attribute in the class by setting `populate_by_name=True` in the `model_config`.

```python ! api.py
# !focus(24:39)
# !mark(34[9:36],37:39)

```

---

## !!steps

We then update the `construct_base_open_api` function to return an `OpenAPIwithRetries` object.

```python ! api.py
# !focus(42[34:51],43[12:29])
```

---

## !!steps

Add `xSpeakeasyRetries` to the `OpenAPIwithRetries` object in the `construct_base_open_api` function.

```python ! api.py
# !focus(55:65)
```

---

## !!steps

This translates to the following OpenAPI schema:

```yaml ! openapi.yaml
x-speakeasy-retries:
  strategy: backoff
  backoff:
    initialInterval: 500
    maxInterval: 60000
    maxElapsedTime: 3600000
    exponent: 1.5
  statusCodes:
    - 5XX
  retryConnectionErrors: true
```

</ScrollyCoding>

### Add Tags to the OpenAPI Schema

To group operations in the OpenAPI schema, you can use tags. This also allows Speakeasy to structure the generated SDK code and documentation logically.

Add a `tags` field to the `OpenAPIwithRetries` object, then add a `tags` field to each operation in the `construct_base_open_api` function:

```python api.py mark=4:13,18
def construct_base_open_api() -> OpenAPIwithRetries:
    return OpenAPIwithRetries(
        # ...
        tags=[
            {
                "name": "pets",
                "description": "Operations about pets",
            },
            {
                "name": "owners",
                "description": "Operations about owners",
            },
        ],
        paths={
            "/pets": PathItem(
                get=Operation(
                    # ...
                    tags=["pets"],
                ),
                # ...
            ),
            # ...
        },
        # ...
    )
```

Run `python api.py` to update the `openapi.yaml` file with the `tags` field, then regenerate the SDK using Speakeasy.

```bash Terminal
python api.py
speakeasy quickstart
```

Speakeasy will detect the changes to your OpenAPI schema, generate the SDK with the updated tags, and automatically increment the SDK's version number.

Take a look at the generated SDK to see how Speakeasy groups operations by tags.

## We Can Help Get Your Pydantic Models Ready for SDK Generation

In this tutorial, we learned how to generate an OpenAPI schema from Pydantic models and use it to generate an SDK client using Speakeasy.

If you would like to discuss how to get your Pydantic models ready for SDK generation, give us feedback, or shoot the breeze about all things OpenAPI and SDKs, [join our Slack](https://join.slack.com/t/speakeasy-dev/shared_invite/zt-1cwb3flxz-lS5SyZxAsF_3NOq5xc8Cjw).


 This is the content for the doc openapi/frameworks/springboot.mdx 

 ---
title: How to generate an OpenAPI/Swagger document with Spring Boot
description: "Generating an OpenAPI specification with Spring Boot and using it to create SDKs with Speakeasy."
---

import { ScrollyCoding } from "~/components/codehike/Scrollycoding";
import { Callout } from '~/components';

# Generating an OpenAPI document and SDK from Spring Boot

You have a Spring Boot API and need to generate SDKs or API documentation for other teams. Rather than writing and maintaining separate OpenAPI specs, we will walk through how to generate them directly from your Spring Boot code, and then use them to create and customize an SDK.

We'll work with real code you can run locally, building a simple bookstore API to demonstrate how to properly document API structures, including inheritance between models, endpoint definitions, response types, and error handling. The examples illustrate how Spring Boot annotations map to OpenAPI concepts, so you can see how your code translates into API specifications.


<Callout title="Example repository" variant="info">
  The example below will guide you through the process of creating a Spring Boot project, adding the necessary dependencies, writing Spring Boot controllers with OpenAPI annotations, and generating an OpenAPI document from it.
  To skip this setup and follow along with our example, clone the [example application](https://github.com/speakeasy-api/spring-boot-openapi-example).
</Callout>


## Step 1: Set up a Spring Boot project

First, create a new Spring Boot project using [Spring Initializr](https://start.spring.io/). Select the following options:

- Project: Maven
- Language: Java
- Spring Boot: 2.7.x (or the latest stable version)
- Project Metadata: Fill in as appropriate
- Dependencies: Spring Web

Download the project and extract it to your preferred directory.

## Step 2: Add OpenAPI dependencies

Open the `pom.xml` file and add the following dependency:

```xml pom.xml
<dependency>
    <groupId>org.springdoc</groupId>
    <artifactId>springdoc-openapi-starter-webmvc-ui</artifactId>
    <version>2.1.0</version>
</dependency>
```

## Step 3: Configure application properties

Open the `src/main/resources/application.properties` file and add the following configuration:

```properties application.properties
# Specify the path of the OpenAPI documentation
springdoc.api-docs.path=/api-docs

springdoc.api-docs.version=OPENAPI_3_1

# Specify the path of the Swagger UI
springdoc.swagger-ui.path=/swagger-ui.html
```

These properties configure the application name that identifies your service, the endpoint where the OpenAPI document will be available (`/api-docs`), the version of the OpenAPI document to generate, and the URL path where you can access the Swagger UI documentation (`/swagger-ui.html`).

After starting your application, you can view the OpenAPI document at `http://localhost:8080/api-docs` and access the interactive Swagger UI at `http://localhost:8080/swagger-ui.html`.

## Step 4: Write a Spring Boot application

All the code in this step can be found in our example application.

Open the `src/main/java/com/bookstore/BookstoreApplication.java` file in your text editor to see where to begin when adding OpenAPI annotations to your project.

<ScrollyCoding fullHeight>

## !!steps

The `BookstoreApplication` class is the entry point for the API. Similarly, we define the entry point to the OpenAPI document.

```java ! BookstoreApplication.java focus=1:34
!from ./assets/springboot/BookstoreApplication.java.txt
```


---

## !!steps

The `@OpenAPIDefinition` annotation populates the OpenAPI document with essential context for anyone who wants to use the API. This tells developers what the API does and how they can use it.

Use the `title`, `version`, and `description` fields to describe what the API does, its current state, and how it can be used.

```java !! BookstoreApplication.java focus=14:34 mark=16:18
!from ./assets/springboot/BookstoreApplication.java.txt
```


---

## !!steps

The `@Server` annotation defines any available endpoints for the API. In the example, there are two options: A production server at `https://api.bookstore.example.com` that uses live data, and a localhost server at `http://localhost:8080` for testing with sample data.

```java !! BookstoreApplication.java focus=30:33
!from ./assets/springboot/BookstoreApplication.java.txt
```


---

## !!steps

Open the `Models.java` file to see how you can use OpenAPI annotations to describe API data structures.

```java ! Models.java focus=1:206
!from ./assets/springboot/Models.java.txt
```


---

## !!steps

The `@Schema` annotation can be used at both the class and field levels to describe data structures in the OpenAPI documentation.

At the class level, `@Schema` describes what a `Publication`, `Book`, or `Magazine` represents in the API.

At the field level, fields like `id` and `author` are documented with a description of the field's purpose and an example of the value that API users should provide or expect to receive.

```java !! Models.java focus=13:71 mark=15,25,28,31,34
!from ./assets/springboot/Models.java.txt
```


---

## !!steps

The `Publication` class acts as the base schema in the OpenAPI specification.

By using `@JsonTypeInfo` and `@JsonSubTypes`, we tell OpenAPI that a `Publication` can be either a `Book` or `Magazine`. This polymorphism is reflected in the OpenAPI document as a `oneOf` schema, where each endpoint that works with publications can accept or return either type.

API clients will see that when working with publications, they need to include a `type` field set to either `BOOK` or `MAGAZINE` to properly identify the publication type.

```java !! Models.java focus=13:71 mark=19:22
!from ./assets/springboot/Models.java.txt
```


---

## !!steps

The `Order` class uses the `@Schema` annotation to document the `items` field, which references the `Publication` schema.

This tells OpenAPI that `Orders` can contain an array of either books or magazines, using the polymorphic structure we defined earlier.

```java !! Models.java focus=135:174 mark=135,143
!from ./assets/springboot/Models.java.txt
```


---

## !!steps

To document the available statuses of an `Order`, we annotate an enum with `@Schema`.

In the OpenAPI specification, this appears as a string field specifying a set of allowed values.

```java !! Models.java focus=176:182 mark=176
!from ./assets/springboot/Models.java.txt
```


---

## !!steps

We annotate the `ErrorResponse` class with `@Schema` to describe any errors users might run into when using the API endpoints.

```java !! Models.java focus=184:206 mark=184,186,189
!from ./assets/springboot/Models.java.txt
```


---

## !!steps

The next step is to define the API endpoints. We will go through the `PublicationsController.java` file to see how to map a Spring Boot controller to OpenAPI.

```java ! PublicationsController.java focus=1:94
!from ./assets/springboot/PublicationsController.java.txt
```


---

## !!steps

The `@Tag` annotation groups the operations in the controller under "Publications" in the OpenAPI document. Combined with `@RequestMapping("/publications")`, it tells API consumers that these endpoints handle publication-related operations.

```java !! PublicationsController.java focus=22:23 mark=23
!from ./assets/springboot/PublicationsController.java.txt
```


---

## !!steps

On each method, you can use the `@Operation` and `@ApiResponses` annotations to document what the endpoint does and what responses to expect.

For example, `getPublication` has been annotated to show that it returns a publication successfully (`200` status) or an error (`404` status) if the publication isn't found.

```java !! PublicationsController.java focus=48:54 mark=48,49
!from ./assets/springboot/PublicationsController.java.txt
```


---

## !!steps

Use the `@Parameter` annotation to describe the requirements for input parameters.

```java !! PublicationsController.java focus=74:90 mark=76
!from ./assets/springboot/PublicationsController.java.txt
```


</ScrollyCoding>


## Step 5: View the generated OpenAPI document

Now that we've built the Spring Boot application, let's generate and examine the OpenAPI document to understand how the Java code translates into API specifications.

First, install the necessary dependencies in the project and start the application with the following commands:

```bash Terminal
./mvnw clean install
./mvnw spring-boot:run
```

Download the OpenAPI document while running the application:

```bash Terminal
curl http://localhost:8080/api-docs.yaml -o openapi.yaml
```

This command saves the OpenAPI document as `openapi.yaml` in your current directory.


<ScrollyCoding fullHeight>


## !!steps

Let's scroll through the generated OpenAPI document to see how our Spring Boot annotations were translated into an OpenAPI specification.

```java ! BookstoreApplication.java
!from ./assets/springboot/BookstoreApplication.java.txt
```

```yaml ! openapi.yaml
!from ./assets/springboot/openapi.yaml.txt
```


---

## !!steps

The OpenAPI document begins with version information.

This version is determined by the `springdoc-openapi` library we're using. Simple, but important - it tells API consumers which OpenAPI spec version to expect.

```java !! BookstoreApplication.java focus=13 mark=13
!from ./assets/springboot/BookstoreApplication.java.txt
```

```yaml !! openapi.yaml focus=1
!from ./assets/springboot/openapi.yaml.txt
```


---

## !!steps

Next comes the `info` object, which is generated from the `@OpenAPIDefinition` annotation.

This Java annotation transforms directly into the corresponding OpenAPI structure.

Notice how each field in the annotation maps directly to its counterpart in the OpenAPI document output. This one-to-one mapping makes it easy to understand how your code affects the final API documentation.

```java !! BookstoreApplication.java focus=15:29
!from ./assets/springboot/BookstoreApplication.java.txt
```

```yaml !! openapi.yaml focus=2:13
!from ./assets/springboot/openapi.yaml.txt
```


---

## !!steps

Server configurations defined with `@Server` annotations appear in the servers array.

These annotations generate the following OpenAPI structure.

```java !! BookstoreApplication.java focus=30:33
!from ./assets/springboot/BookstoreApplication.java.txt
```

```yaml !! openapi.yaml focus=14:18
!from ./assets/springboot/openapi.yaml.txt
```


---

## !!steps

One of the more complex aspects of the API is how polymorphic models are represented.

The `Publication` class has been translated into a schema that supports polymorphism through a discriminator.

A few key things to notice:

- The `@Schema` annotations provide descriptions and examples
- The `@JsonTypeInfo` annotation determines the discriminator property
- The `@JsonSubTypes` annotation defines the possible concrete implementations


```java !! Models.java focus=15:24
!from ./assets/springboot/Models.java.txt
```

```yaml !! openapi.yaml focus=336:379 mark=337:338,347,377:379
!from ./assets/springboot/openapi.yaml.txt
```


---

## !!steps

Finally, let's examine how controller methods translate into API endpoints.

The `@Operation` annotation provides the summary and description.

Each `@ApiResponse` maps to an entry in the responses object.

The `@Parameter` annotation documents the path parameter.


```java !! PublicationsController.java focus=48:55
!from ./assets/springboot/PublicationsController.java.txt
```

```yaml !! openapi.yaml focus=199:227
!from ./assets/springboot/openapi.yaml.txt
```


</ScrollyCoding>

# Create an SDK from the OpenAPI document

Now that we have an OpenAPI document for the Spring Boot API, we can create an SDK using Speakeasy.

First, make sure you have Speakeasy installed:

```bash Terminal
speakeasy --version
```

Now, generate a TypeScript SDK using the following command:

```bash Terminal
speakeasy quickstart
```

Follow the onscreen prompts to provide the configuration details for the new SDK such as the name, schema location, and output path. Enter `openapi.yaml` when prompted for the OpenAPI document location and select your preferred language, for example, TypeScript, when prompted for which language you would like to generate.

After running this command, you'll find the generated SDK code in the specified output directory. This SDK can be used by clients to interact with your Spring Boot API in a type-safe manner.

# Customize the SDK

Let's add retry logic to the SDK's `listPublications` operation to handle network errors gracefully. We'll do this using an OpenAPI extension that [Speakeasy provides](/docs/customize-sdks/retries), `x-speakeasy-retries`.

Instead of modifying the OpenAPI document directly, we'll add this extension to the Spring Boot controller and regenerate the OpenAPI document and SDK.

First, add these imports to `src/main/java/com/bookstore/PublicationsController.java`:


```java PublicationsController.java
import io.swagger.v3.oas.annotations.extensions.Extension;
import io.swagger.v3.oas.annotations.extensions.ExtensionProperty;
```

Then modify the `listPublications` operation to include the retry configuration:


```java PublicationsController.java mark=2:7
    @Operation(summary = "List all publications", description = "Get a list of all publications in the store", extensions = {
        @Extension(name = "x-speakeasy-retries", properties = {
            @ExtensionProperty(name = "strategy", value = "backoff"),
            @ExtensionProperty(name = "backoff", parseValue = true, value = "{\"initialInterval\":500,\"maxInterval\":60000,\"maxElapsedTime\":3600000,\"exponent\":1.5}"),
            @ExtensionProperty(name = "statusCodes", parseValue = true, value = "[\"5XX\"]"),
            @ExtensionProperty(name = "retryConnectionErrors", parseValue = true, value = "true")
        })
    })
    @ApiResponses(value = {
        @ApiResponse(responseCode = "200", description = "Successful operation",
                     content = @Content(array = @ArraySchema(schema = @Schema(implementation = PublicationListItem.class)))),
    })
    @GetMapping
    public ResponseEntity<List<Publication>> listPublications() {
        // This is a mock implementation. In a real application, you would fetch this from a database.
        List<Publication> publications = new ArrayList<>();
        publications.add(new Book(UUID.randomUUID().toString(), "Spring Boot in Action", "2015-10-01", 39.99f, "Craig Walls", "978-1617292545"));
        publications.add(new Magazine(UUID.randomUUID().toString(), "National Geographic", "2023-06-01", 9.99f, 6, "National Geographic Society"));
        return ResponseEntity.ok(publications);
    }
```

Now that we've added the `x-speakeasy-retries` extension to the `listPublications` operation, we can regenerate the OpenAPI document:

```bash Terminal
curl http://localhost:8080/api-docs.yaml -o openapi.yaml
```

The OpenAPI document will include the retry configuration for the `listPublications` operation:

```yaml openapi.yaml
x-speakeasy-retries:
  statusCodes:
  - 5XX
  backoff:
    initialInterval: 500
    maxInterval: 60000
    maxElapsedTime: 3600000
    exponent: 1.5
  strategy: backoff
  retryConnectionErrors: true
```

Now we can use Speakeasy to recreate the SDK:

```bash
speakeasy quickstart
```

The created SDK will now include retry logic for the `listPublications` operation, automatically handling network errors and `5XX` responses.


### Issues and feedback

Need some assistance or have a suggestion? Reach out to our team at [support@speakeasy.com](mailto:support@speakeasy.com).



 This is the content for the doc openapi/frameworks/trpc.mdx 

 ---
title: How To Generate an OpenAPI Spec With tRPC
description: "How to use tRPC to create an OpenAPI spec and create an SDK for it with Speakeasy."
---

import { Callout } from "~/components";

# How to generate an OpenAPI/Swagger spec with tRPC

In this tutorial, we'll explore how to generate an OpenAPI document for our [tRPC](https://trpc.io/) API, and then we'll use this document to create an SDK using Speakeasy.

Here's what we'll cover:

1.  Adding `trpc-openapi` to a tRPC project.
2.  Generating an OpenAPI specification using `trpc-openapi`.
3.  Improving the generated OpenAPI specification for better downstream SDK generation.
4.  Using the Speakeasy CLI to create an SDK based on the generated OpenAPI specification.
5.  Using the Speakeasy OpenAPI extensions to improve created SDKs.
6.  Automating this process as part of a CI/CD pipeline.

<Callout title="TIP" variant="success">
  If you want to follow along, you can use the [**tRPC Speakeasy Bar example
  repository**](https://github.com/speakeasy-api/speakeasy-trpc-example).
</Callout>

## The SDK Creation Pipeline

tRPC does not natively export OpenAPI documents, but the [`trpc-openapi`](https://github.com/jlalmes/trpc-openapi/) package adds this functionality. We'll start this tutorial by adding `trpc-openapi` to a project, and then we'll add a script to generate an OpenAPI schema and save it as a file.

The quality of your OpenAPI specification will ultimately determine the quality of created SDKs and documentation, so we'll dive into ways you can improve the generated specification.

With our new and improved OpenAPI specification in hand, we'll take a look at how to create SDKs using Speakeasy.

Finally, we'll add this process to a CI/CD pipeline so that Speakeasy automatically creates fresh SDKs whenever your tRPC API changes in the future.

## Requirements

To follow along with this tutorial, you will need:

- An existing tRPC app, or you can clone our example application.
- Some familiarity with tRPC.
- [Node.js](https://nodejs.org/en/download) installed (we used Node v20.5.1).
- The [Speakeasy CLI](/docs/speakeasy-cli/) installed. You'll use the CLI to create the SDK once you have generated your OpenAPI spec.

## Supported OpenAPI Versions

Speakeasy supports OpenAPI v3 and v3.1. As of October 2023, `trpc-openapi` can generate schemas that adhere to the [OpenAPI v3.0.3 specification](https://spec.openapis.org/oas/v3.0.3).

This OpenAPI version is not a limitation, but it is important to keep the versions used in mind when debugging code generation. Refer to the OpenAPI Initiative for an overview of the [differences between OpenAPI 3.0 and 3.1.0](https://www.openapis.org/blog/2021/02/16/migrating-from-openapi-3-0-to-3-1-0).

## Generate an OpenAPI/Swagger spec with tRPC

We'll use [`trpc-openapi`](https://github.com/jlalmes/trpc-openapi/) to create REST endpoints for our tRPC procedures and then create the OpenAPI spec that describes these endpoints.

To generate an OpenAPI spec for tRPC, we'll use [trpc-openapi](https://github.com/jlalmes/trpc-openapi/) to create REST endpoints for our tRPC procedures, then create an OpenAPI document that describes these endpoints.

### Add trpc-openapi to a Project

Install `trpc-openapi`:

```bash
npm install trpc-openapi
```

Use `initTRPC.meta<OpenApiMeta>()` to create a new tRPC instance with OpenAPI support:

```typescript router.ts
// !focus(2,4)
import { initTRPC } from "@trpc/server";
import { OpenApiMeta } from "trpc-openapi";

const t = initTRPC.meta<OpenApiMeta>().create();
```

Add OpenAPI meta to a procedure by passing an `openapi` object to the `meta` function. This object contains the HTTP method and path for the generated REST endpoint.

```typescript router.ts
// !focus(9)
import { initTRPC } from "@trpc/server";
import { OpenApiMeta } from "trpc-openapi";
import { z } from "zod";

const t = initTRPC.meta<OpenApiMeta>().create();

export const appRouter = t.router({
  findByProductCode: t.procedure
    .meta({ openapi: { method: "GET", path: "/find" } })
    .input(z.object({ code: z.string() }))
    .output(z.object({ drink: z.object({ name: z.string() }) }))
    .query(async ({ input }) => {
      const drink = {
        name: "Old Fashioned",
      }
      return { drink: drink };
    }),
});
```

Add a new script to generate an OpenAPI document based on the tRPC router:

```typescript openapi.ts
import { generateOpenApiDocument } from "trpc-openapi";

import { appRouter } from "./router";

export const openApiDocument = generateOpenApiDocument(appRouter, {
  title: 'tRPC OpenAPI',
  version: '1.0.0',
  baseUrl: 'http://localhost:3000',
});
```

Add a script to save the generated OpenAPI document to a file:

```typescript generateOpenApi.ts
import { openApiDocument } from "./openapi";

console.log(JSON.stringify(openApiDocument, null, 2));
```

Run the script to generate an OpenAPI document:

```bash
ts-node generateOpenApi.ts > openapi-spec.json
```

Add this document to the `package.json` file as a script:

```json package.json
{
  "scripts": {
    "generate-openapi": "ts-node generateOpenApi.ts > openapi-spec.json"
  }
}
```

From now on, we can generate an OpenAPI document by running `npm run generate-openapi`.

When we inspect the generated OpenAPI document, we can see that it contains a single endpoint for the `findByProductCode` procedure, but it's missing a lot of information.

Let's see how we can improve this document.

## How To Improve the OpenAPI Info Section

The OpenAPI info section contains information about the API, such as the title, description, and version. If you use Speakeasy later, it will use this information to create documentation and SDKs.

The `GenerateOpenApiDocumentOptions` type from `trpc-openapi` allows us to add this information to our OpenAPI document:

```typescript node_modules/trpc-openapi/dist/generator/index.d.ts
export type GenerateOpenApiDocumentOptions = {
    title: string;
    description?: string;
    version: string;
    baseUrl: string;
    docsUrl?: string;
    tags?: string[];
    securitySchemes?: OpenAPIV3.ComponentsObject['securitySchemes'];
};
```

We can add this information to our `generateOpenApiDocument` call:

```typescript openapi.ts
// !focus(6:11)
import { generateOpenApiDocument } from "trpc-openapi";

import { appRouter } from "./router";

export const openApiDocument = generateOpenApiDocument(appRouter, {
  title: "Speakeasy Bar API",
  description: "An API to order drinks from the Speakeasy Bar",
  version: "1.0.0",
  baseUrl: "http://localhost:3000",
  docsUrl: "http://example.com/docs",
  tags: ["drinks"],
});
```

Run `npm run generate-openapi` and see how this information is added to the OpenAPI document:

```json openapi-spec.json
{
  "openapi": "3.0.3",
  "info": {
    "title": "Speakeasy Bar API",
    "description": "An API to order drinks from the Speakeasy Bar",
    "version": "1.0.0"
  },
  "servers": [
    {
      "url": "http://localhost:3000"
    }
  ],
  "tags": [
    {
      "name": "drinks"
    }
  ],
  "externalDocs": {
    "url": "http://example.com/docs"
  }
  // ...
}
```

## Improving the OpenAPI Paths

We can improve our OpenAPI document by adding fields to the procedure's input and output schemas, and by adding examples, documentation, and metadata.

### Expanding the Procedure’s Input and Output Schemas

Let's create a `Drink` model and add a few field types to see how these are represented in the OpenAPI document.

Create a new file called `models.ts` and specify a `Drink` model using Zod:

```typescript models.ts
import { z } from "zod";

const DrinkType = z.enum([
    "NON_ALCOHOLIC",
    "BEER",
    "WINE",
    "SPIRIT",
    "OTHER",
]).describe('The type of drink');
type DrinkType = z.infer<typeof DrinkType>;

export const ProductCode = z.string().describe('The product code of the drink');
export type ProductCode = z.infer<typeof ProductCode>;

export const DrinkSchema = z.object({
    name: z.string().describe('The name of the drink'),
    type: DrinkType,
    price: z.number().describe('The price of the drink'),
    stock: z.number().describe('The number of drinks in stock'),
    productCode: ProductCode,
    description: z.string().nullable().describe('A description of the drink'),
});

export type Drink = z.infer<typeof DrinkSchema>;
```

Back in the `router.ts` file, import these models and update the procedure's input and output schemas. In the example app, we also added a mock database.

```typescript router.ts
// !focus(5:6)
// !focus(13:14)
import { initTRPC } from "@trpc/server";
import { OpenApiMeta } from "trpc-openapi";
import { z } from "zod";

import { ProductCode, DrinkSchema } from "./models";
import { db } from "./db";  // Mock database

const t = initTRPC.meta<OpenApiMeta>().create();

export const appRouter = t.router({
  findByProductCode: t.procedure
    .meta({ openapi: { method: "GET", path: "/find" } })
    .input(z.object({ code: ProductCode }))
    .output(z.object({ drink: DrinkSchema.optional() }))
    .query(async ({ input }) => {
      const drink = await db.drink.findByProductCode(input.code);
      return { drink: drink };
    }),
});
```

If we regenerate the OpenAPI document, we can see that the `Drink` model is now included in the document with all of its fields:

```json openapi-spec.json
{
  "paths": {
    "/find": {
      "get": {
        "operationId": "findByProductCode",
        "summary": "Find a drink by product code",
        "description": "Pass the product code of the drink to search for",
        "tags": ["drinks"],
        "parameters": [
          {
            "name": "code",
            "in": "query",
            "required": true,
            "schema": {
              "type": "string"
            },
            "description": "The product code of the drink",
            "example": "1234"
          }
        ],
        "responses": {
          "200": {
            "description": "Successful response",
            "content": {
              "application/json": {
                "schema": {
                  "type": "object",
                  "properties": {
                    "drink": {
                      "type": "object",
                      "properties": {
                        "name": {
                          "type": "string",
                          "description": "The name of the drink"
                        },
                        "type": {
                          "type": "string",
                          "enum": [
                            "NON_ALCOHOLIC",
                            "BEER",
                            "WINE",
                            "SPIRIT",
                            "OTHER"
                          ],
                          "description": "The type of drink"
                        },
                        "price": {
                          "type": "number",
                          "description": "The price of the drink"
                        },
                        "stock": {
                          "type": "number",
                          "description": "The number of drinks in stock"
                        },
                        "productCode": {
                          "type": "string",
                          "description": "The product code of the drink"
                        },
                        "description": {
                          "type": "string",
                          "nullable": true,
                          "description": "A description of the drink"
                        }
                      },
                      "required": [
                        "name",
                        "type",
                        "price",
                        "stock",
                        "productCode",
                        "description"
                      ],
                      "additionalProperties": false
                    }
                  },
                  "additionalProperties": false
                },
                "example": {
                  "drink": {
                    "name": "Beer",
                    "type": "BEER",
                    "price": 5,
                    "stock": 10,
                    "productCode": "1234",
                    "description": "A nice cold beer"
                  }
                }
              }
            }
          },
          "default": {
            "$ref": "#/components/responses/error"
          }
        }
      }
    }
  }
  // ...
}
```

Speakeasy will use the descriptions in these fields to create documentation for the SDK.

### OpenAPI Model Schemas in tRPC

At Speakeasy, we recommend using OpenAPI model schemas so that schemas are reusable across multiple procedures. This simplifies SDK code creation, makes it easier to maintain your OpenAPI document, and provides a better developer experience for your users.

At the time of writing, there is an [open issue on the tRPC repository](https://github.com/jlalmes/trpc-openapi/issues/157) to add support for OpenAPI model schemas. Until this is implemented, we'll need to be content with the duplication of schemas across procedures.

Under the hood, `trpc-openapi` uses the [Zod to Json Schema](https://www.npmjs.com/package/zod-to-json-schema) package, which supports custom strategies for generating references to schemas, but this functionality is not yet exposed in `trpc-openapi`.

### Adding a Summary, Description, Examples, and Tags to a Procedure

We can enrich our OpenAPI document by adding a summary, description, examples, and tags to our procedure's metaobject.

The `trpc-openapi` package uses these fields to generate the `summary`, `description`, `example`, and `tags` fields in the OpenAPI document.

The `example` field is also used to add examples to the input schema.

```typescript router.ts
// !focus(19:33)
import { initTRPC } from "@trpc/server";
import { OpenApiMeta } from "trpc-openapi";
import { z } from "zod";

import { ProductCode, DrinkSchema } from "./models";
import { db } from "./db";

const t = initTRPC.meta<OpenApiMeta>().create();

export const appRouter = t.router({
  findByProductCode: t.procedure
    .meta({
      openapi: {
        method: "GET",
        path: "/find",
        summary: "Find a drink by product code",
        description: "Pass the product code of the drink to search for",
        tags: ["drinks"],
        example: {
          request: {
            code: "1234",
          },
          response: {
            drink: {
              name: "Beer",
              type: "BEER",
              price: 5.0,
              stock: 10,
              productCode: "1234",
              description: "A nice cold beer",
            },
          },
        },
      },
    })
    .input(z.object({ code: ProductCode }))
    .output(z.object({ drink: DrinkSchema.optional() }))
    .query(async ({ input }) => {
      const drink = await db.drink.findByProductCode(input.code);
      return { drink: drink };
    }),
});
```

If we regenerate the OpenAPI document now, we can see that the `summary`, `description`, and `example` fields have been added to it.

### Add Metadata to Tags

The `trpc-openapi` package defines tags as a list of strings, but OpenAPI allows you to add metadata to tags. For example, you can add a description or a link to documentation to a tag.

Since `trpc-openapi` uses the [`openapi-types` package](https://www.npmjs.com/package/openapi-types) `OpenAPIV3.Document` type, which allows tags defined as a list of strings or a list of objects, we can extend our document to include tag objects with metadata even though `trpc-openapi` uses a list of strings.

Let's add a description to the `drinks` tag:

```typescript openapi.ts
import { generateOpenApiDocument } from "trpc-openapi";

import { appRouter } from "./router";

const openApiDocument = generateOpenApiDocument(appRouter, {
  title: "Speakeasy Bar API",
  description: "An API to order drinks from the Speakeasy Bar",
  version: "1.0.0",
  baseUrl: "http://localhost:3000",
  docsUrl: "http://example.com/docs",
  tags: ["drinks"],
});

// add metadata to tags
openApiDocument.tags = [
  {
    name: "drinks",
    description: "Operations related to drinks",
  },
];

export { openApiDocument };
```

Now we can see that the `description` field has been added to the `drinks` tag in the generated OpenAPI document:

```json openapi-spec.json
{
  "tags": [
    {
      "name": "drinks",
      "description": "Operations related to drinks"
    }
  ]
}
```

### Add Speakeasy Extensions to Methods

The OpenAPI vocabulary can sometimes be insufficient for your code creation needs. For these situations, Speakeasy provides a set of OpenAPI extensions. For example, you may want to give an SDK method a different name from the `OperationId`. You can use the Speakeasy `x-speakeasy-name-override` extension to do so.

This time, unfortunately, the [`openapi-types` package](https://www.npmjs.com/package/openapi-types) `OperationObject` type does not allow for custom extensions, so we need to add the extension to the generated OpenAPI document manually.

Ideally, we would create a new type that extends `OpenAPIV3.Document` and adds the `x-speakeasy-name-override` extension to the `OperationObject` type, but for this tutorial, we'll keep it simple and add the extension by casting the path item to `any`.

Let's add an `x-speakeasy-name-override` extension to the `findByProductCode` procedure.

First, we extend the `OpenAPIV3.OperationObject` and `OpenAPIV3.Document` types to add the `x-speakeasy-name-override` and other extensions:

```typescript extended-types.ts
import { OpenAPIV3 } from 'openapi-types';

export type IExtensionName = `x-${string}`;
export type IExtensionType = any;
export type ISpecificationExtension = {
    [extensionName: IExtensionName]: IExtensionType;
};

export type ExtendedDocument = OpenAPIV3.Document & ISpecificationExtension;
export type ExtendedOperationObject = OpenAPIV3.OperationObject<ISpecificationExtension>;
```

Then we import our extended operation type and add the `x-speakeasy-name-override` extension to the `findByProductCode` procedure:

```typescript openapi.ts
// !focus(3,23:31)
import { generateOpenApiDocument } from "trpc-openapi";

import { ExtendedOperationObject } from "./extended-types";
import { appRouter } from "./router";

const openApiDocument = generateOpenApiDocument(appRouter, {
  title: "Speakeasy Bar API",
  description: "An API to order drinks from the Speakeasy Bar",
  version: "1.0.0",
  baseUrl: "http://localhost:3000",
  docsUrl: "http://example.com/docs",
  tags: ["drinks"],
});

// add metadata to tags
openApiDocument.tags = [
  {
    name: "drinks",
    description: "Operations related to drinks",
  },
];

if (
  openApiDocument.paths &&
  openApiDocument.paths["/find"] &&
  openApiDocument.paths["/find"].get
) {
  (openApiDocument.paths["/find"].get as ExtendedOperationObject)[
    "x-speakeasy-name-override"
  ] = "searchDrink";
}

export { openApiDocument };
```

## Add Retries to an SDK With `x-speakeasy-retries`

Speakeasy can create SDKs that follow custom rules for retrying failed requests. For instance, if your server fails to return a response within a specified time, you may want your users to retry their request without clobbering your server.

Add retries to Speakeasy-created SDKs by adding a top-level `x-speakeasy-retries` schema to your OpenAPI spec. You can also override the retry strategy per operation by adding `x-speakeasy-retries`.

### Adding Global Retries and Retries per Endpoint

Let's add a global retry strategy to our OpenAPI document and override it for our `findByProductCode` procedure.

```typescript openapi.ts
// !focus(3)
// !focus(23:33)
// !focus(43:55)
import { generateOpenApiDocument } from "trpc-openapi";

import { ExtendedDocument, ExtendedOperationObject } from "./extended-types";
import { appRouter } from "./router";

const openApiDocument = generateOpenApiDocument(appRouter, {
  title: "Speakeasy Bar API",
  description: "An API to order drinks from the Speakeasy Bar",
  version: "1.0.0",
  baseUrl: "http://localhost:3000",
  docsUrl: "http://example.com/docs",
  tags: ["drinks"],
});

// add metadata to tags
openApiDocument.tags = [
  {
    name: "drinks",
    description: "Operations related to drinks",
  },
];

(openApiDocument as ExtendedDocument)["x-speakeasy-retries"] = {
  strategy: "backoff",
  backoff: {
    initialInterval: 500,
    maxInterval: 60000,
    maxElapsedTime: 3600000,
    exponent: 1.5,
  },
  statusCodes: ["5XX"],
  retryConnectionErrors: true,
};

if (
  openApiDocument.paths &&
  openApiDocument.paths["/find"] &&
  openApiDocument.paths["/find"].get
) {
  (openApiDocument.paths["/find"].get as ExtendedOperationObject)[
    "x-speakeasy-name-override"
  ] = "searchDrink";
  (openApiDocument.paths["/find"].get as ExtendedOperationObject)[
    "x-speakeasy-retries"
  ] = {
    strategy: "backoff",
    backoff: {
      initialInterval: 500,
      maxInterval: 60000,
      maxElapsedTime: 3600000,
      exponent: 1.5,
    },
    statusCodes: ["5XX"],
    retryConnectionErrors: true,
  };
}

export { openApiDocument };
```

Regenerate the OpenAPI document and you can see that the `x-speakeasy-retries` field has been added to the document.

```json openapi-spec.json
{
  "x-speakeasy-retries": {
    "strategy": "backoff",
    "backoff": {
      "initialInterval": 500,
      "maxInterval": 60000,
      "maxElapsedTime": 3600000,
      "exponent": 1.5
    },
    "statusCodes": ["5XX"],
    "retryConnectionErrors": true
  }
  // ...
}
```

## Why Speakeasy and tRPC?

tRPC's focus on type safety and developer experience sets it apart from other TypeScript API frameworks. By using TypeScript's type system along with a schema library like Zod, tRPC allows your server and client code to share types.

One of tRPC's stated goals is to cut down on the need for codegen, but we believe there is still a place for code generation in the tRPC ecosystem. While tRPC's [default client](https://trpc.io/docs/client/vanilla/setup) is useful for writing internal clients in a monorepo where a client can import the server's `AppRouter`, it does not make it easy to publish production-ready SDKs for use by internal and external developers. Nor does tRPC's type-safety extend to SDKs in languages other than TypeScript.

Speakeasy can help you create type-safe, production-ready SDKs for your tRPC API in various languages so that you can focus on building your API, confident that your users will have a great developer experience.

## How To Create an SDK Based on the OpenAPI Spec

After following the steps above, we have an OpenAPI spec that is ready to use as the basis for a new SDK. Now we'll use Speakeasy to create an SDK.

In the root directory of your project, run the following:

```bash
speakeasy quickstart
```

Follow the onscreen prompts to provide the necessary configuration details for your new SDK such as the name, schema location and output path. Enter `openapi-spec.json` when prompted for the OpenAPI document location and select TypeScript when prompted for which language you would like to generate.

## Add SDK Creation to GitHub Actions

The Speakeasy [`sdk-generation-action`](https://github.com/speakeasy-api/sdk-generation-action) repository provides workflows to integrate the Speakeasy CLI in your CI/CD pipeline so that your client SDKs are recreated when your OpenAPI spec changes.

You can set up Speakeasy to automatically push a new branch to your SDK repositories so that your engineers can review and merge the SDK changes.

For an overview of how to set up automation for your SDKs, see the Speakeasy [SDK Generation Action and Workflows](/docs/workflow-reference) documentation.


 This is the content for the doc openapi/frameworks/tsoa.mdx 

 ---
title: How To Generate an OpenAPI spec with tsoa
description: "How to generate an OpenAPI spec with tsoa and use Speakeasy to generate client SDKs."
---

import { Callout } from "~/components";

# How to generate an OpenAPI/Swagger spec with tsoa

In this tutorial, we'll learn how to create an OpenAPI schema using [tsoa (TypeScript OpenAPI)](https://tsoa-community.github.io/docs/introduction.html).

<Callout title="TIP" variant="success">
  If you want to follow along, you can use the [**tsoa Speakeasy Bar example
  repository**](https://github.com/speakeasy-api/speakeasy-tsoa-example)
</Callout>

## How to generate an OpenAPI/Swagger spec with tsoa

To [generate an OpenAPI spec using tsoa](https://tsoa-community.github.io/docs/generating.html), we can use the tsoa CLI or call tsoa's `generateSpec` function. tsoa saves the spec as `swagger.json` by default, but we can customize the base filename using the configuration option `specFileBaseName`.

### Generating an OpenAPI Spec Using the tsoa CLI

[Generate an OpenAPI spec](https://tsoa-community.github.io/docs/generating.html#using-cli) by running the following command in the terminal:

```bash
# generate OpenAPI spec
npx tsoa spec
```

By default, tsoa will use the configuration from the `tsoa.json` file with your generated routes and metadata to generate an OpenAPI spec.

In our example app, the relevant `tsoa.json` config is as follows:

```json tsoa.json
{
  "spec": {
    "outputDirectory": "build",
    "specVersion": 3
  }
}
```

This configures tsoa to output the generated OpenAPI spec in the `build` directory and to use OpenAPI version 3.

### Programmatically Generate an OpenAPI Spec Using tsoa

To generate an OpenAPI spec using the OpenAPI [internal generator functions](https://tsoa-community.github.io/docs/generating.html#programmatic), import `generateSpec` and call this function by passing a spec config of type `ExtendedSpecConfig` from `tsoa`.

<Callout title="CAUTION" variant="warning">
  The recommended way to generate an OpenAPI Spec is via the CLI as tsoa
  [warns](https://tsoa-community.github.io/docs/generating.html#programmatic)
  that `generateSpec` and `ExtendedSpecConfig` can change in minor or patch
  releases of tsoa. The example below is illustrative and not included in the
  example app.
</Callout>

```typescript
import { generateSpec, ExtendedSpecConfig } from "tsoa";

(async () => {
  const specOptions: ExtendedSpecConfig = {
    basePath: "/api",
    entryFile: "./api/server.ts",
    specVersion: 3,
    outputDirectory: "./build",
    controllerPathGlobs: ["./routeControllers/**/*Controller.ts"],
  };

  await generateSpec(specOptions);
})();
```

Add the code above to a TypeScript file and run it to generate an OpenAPI spec using the custom configuration defined in `specOptions`.

## Supported OpenAPI Versions

As of August 2023, tsoa can generate OpenAPI version 2 and version 3 specifications. Speakeasy supports OpenAPI version 3 and version 3.1. To use Speakeasy, make sure to configure tsoa to generate OpenAPI v3.

To set the OpenAPI version, add `spec.specVersion=3` to your `tsoa.json` configuration file:

```json tsoa.json
{
  "spec": {
    "specVersion": 3
  }
}
```

## How tsoa Generates OpenAPI `info`

When generating an OpenAPI spec, tsoa tries to guess your API's title, description, and contact details based on values in your project `package.json` file.

<Callout title="TIP" variant="success">
  Values in `tsoa.json` take precedence over those in `package.json` when
  configured.
</Callout>

### Set OpenAPI `info` in `package.json`

Take this snippet from our example app's `package.json` file:

```json package.json
{
  "name": "speakeasy-bar-tsoa",
  "version": "1.0.0",
  "description": "Speakeasy Bar API",
  "author": "Speakeasy Support <support@speakeasy.bar> (https://support.speakeasy.bar)",
  "license": "Apache-2.0"
}
```

By default, tsoa will generate the following spec based on the values above:

```yaml build/swagger.yaml
info:
  title: speakeasy-bar-tsoa
  version: 1.0.0
  license:
    name: Apache-2.0
  contact:
    name: "Speakeasy Support "
    email: support@speakeasy.bar
    url: "https://support.speakeasy.bar"
```

tsoa uses the package author as the contact person by default, extracting the author's email address and optional URL from the [person format defined by npm](https://docs.npmjs.com/cli/v9/configuring-npm/package-json#people-fields-author-contributors).

### Set OpenAPI Info Using tsoa Configuration

To manually configure your OpenAPI info section, configure tsoa using the `tsoa.json` file:

```json tsoa.json
{
  "spec": {
    "name": "Custom API Name",
    "description": "Custom API Description",
    "license": "MIT",
    "version": "1.0.0",
    "contact": {
      "name": "API Contact",
      "email": "help@example.com",
      "url": "http://example.com"
    }
  }
}
```

After adding this custom configuration, tsoa will use these values instead of those from `package.json` when generating a spec.

## Update tsoa to Generate OpenAPI Component Schemas

Let's see how we can help tsoa generate separate and reusable component schemas for a request body.

Consider the following drink model:

```typescript src/drinks/drink.ts
/**
 * The type of drink.
 */
export enum DrinkType {
  COCKTAIL = "cocktail",
  NON_ALCOHOLIC = "non-alcoholic",
  BEER = "beer",
  WINE = "wine",
  SPIRIT = "spirit",
  OTHER = "other",
}

export interface Drink {
  /**
   * The name of the drink.
   * @example "Old Fashioned"
   * @example "Manhattan"
   * @example "Negroni"
   */
  name: string;
  type?: DrinkType;

  /**
   * The price of one unit of the drink in US cents.
   * @isInt
   * @example 1000
   * @example 1200
   * @example 1500
   */
  price: number;

  /**
   * The number of units of the drink in stock, only available when authenticated.
   * @isInt
   * @example 102
   * @example 10
   * @example 0
   */
  stock?: number;

  /**
   * The product code of the drink, only available when authenticated.
   * @example "SP-001"
   * @example "CK-001"
   * @example "CK-002"
   */
  productCode?: string;
}
```

We'd like to write a controller that updates the `name` and `price` fields. The controller should take both fields as body parameters.

We'll start with the example controller below. Note how the body parameters `drinkName` and `price` are defined by passing the `@BodyProp` decorator to the controller function multiple times.

```typescript src/drinks/drinksController.ts mark=6:7
@Route("drink")
export class DrinkController extends Controller {
  @Put("{productCode}")
  public async updateDrink(
    @Path() productCode: string,
    @BodyProp() drinkName?: string,
    @BodyProp() price?: number
  ): Promise<Drink> {
    const drink = new DrinksService().updateDrink(
      productCode,
      drinkName,
      price
    );

    return drink;
  }
}
```

This would generate inline parameters without documentation for the `UpdateDrink` operation in OpenAPI, as shown in the snippet below:

```yaml build/swagger.yaml
requestBody:
  required: true
  content:
    application/json:
      schema:
        properties:
          drinkName:
            type: string
          price:
            type: integer
        type: object
```

While perfectly valid, this schema is not reusable and excludes the documentation and examples from our model definition.

We recommend picking fields from the model interface directly and exporting a new interface. We could use the TypeScript utility types `Pick` and `Partial` to pick the `name` and `price` fields and make both optional:

```typescript src/drinks/drinksService.ts
export interface DrinkUpdateParams
  extends Partial<Pick<Drink, "name" | "price">> {}
```

In our controller, we can now use `DrinkUpdateParams` as follows:

```typescript src/drinks/drinksController.ts mark=6
@Route("drink")
export class DrinkController extends Controller {
  @Put("{productCode}")
  public async updateDrink(
    @Path() productCode: string,
    @Body() requestBody: DrinkUpdateParams
  ): Promise<Drink> {
    const drink = new DrinksService().updateDrink(productCode, requestBody);

    return drink;
  }
}
```

## Customizing OpenAPI `operationId` Using tsoa

When generating an OpenAPI spec, tsoa adds an `operationId` to each operation.

We can customize the `operationId` in three ways:

- Using the `@OperationId` decorator.
- Using the default tsoa `operationId` generator.
- Creating a custom `operationId` template.

### Using the `@OperationId` Decorator

The most straightforward way to customize the `operationId` is to add the `@OperationId` decorator to each operation.

In the example below, the custom `operationId` is `updateDrinkNameOrPrice`:

```typescript src/drinks/drinksController.ts mark=7
@Route("drink")
export class DrinkController extends Controller {
  @OperationId("updateDrinkNameOrPrice")
  @Put("{productCode}")
  public async updateDrink(
    @Path() productCode: string,
    @Body() requestBody: DrinkUpdateParams
  ): Promise<Drink> {
    const drink = new DrinksService().updateDrink(productCode, requestBody);

    return drink;
  }
}
```

### Using the Default tsoa `operationId` Generator

If a controller method is not decorated with the `OperationId` decorator, tsoa generates the `operationId` by converting the method name to title case using the following Handlebars template:

```handlebars
{{titleCase method.name}}
```

### Creating a Custom `operationId` Template

To create a custom `operationId` for all operations without the `@OperationId` decorator, tsoa allows us to specify a Handlebars template in `tsoa.json`. tsoa adds two helpers to Handlebars: `replace` and `titleCase`. The method object and controller name get passed to the template as `method` and `controllerName`.

The following custom `operationId` template prepends the controller name and removes underscores from the method name:

```json tsoa.json
{
  "spec": {
    "operationIdTemplate": "{{controllerName}}-{{replace method.name '_' ''}}"
  }
}
```

## Add OpenAPI Tags to tsoa Methods

At Speakeasy, whether you're building a big application or only have a handful of operations, we recommend adding tags to all operations so you can group them by tag in generated SDK code and documentation.

### Add Tags to Operations Using Decorators

tsoa provides the `@Tags()` decorator for controllers and controller methods. The decorator accepts one or more strings as input.

```typescript src/drinks/drinksController.ts mark=6
@Route("drink")
@Tags("drinks", "bar")
export class DrinkController extends Controller {
  @OperationId("updateDrinkNameOrPrice")
  @Put("{productCode}")
  @Tags("Drink")
  public async updateDrink(
    @Path() productCode: string,
    @Body() requestBody: DrinkUpdateParams
  ): Promise<Drink> {
    const drink = new DrinksService().updateDrink(productCode, requestBody);

    return drink;
  }
}
```

Contrary to the illustrative example above, we recommend adding a single tag per method or controller to ensure that the generated SDK is split into logical units.

### Add Metadata to Tags

To add metadata to tags, add a `tags` object to your `tsoa.json`:

```json tsoa.json
{
  "spec": {
    "tags": [
      {
        "name": "drinks",
        "description": "Operations related to drinks",
        "externalDocs": {
          "description": "Find out more about drinks",
          "url": "http://example.com"
        }
      },
      {
        "name": "bar",
        "description": "Operations related to the bar"
      },
      {
        "name": "update",
        "description": "Update operations"
      }
    ]
  }
}
```

### Add Speakeasy Extensions to Methods

Sometimes OpenAPI's vocabulary is insufficient for your generation needs. For these situations, Speakeasy provides a set of OpenAPI extensions. For example, you may want to give an SDK method a name different from the `OperationId`. To cover this use case, we provide an `x-speakeasy-name-override` extension.

To add these custom extensions to your OpenAPI spec, you can make use of tsoa's `@Extension()` decorator:

```typescript src/drinks/drinksController.ts mark=5
@Route("drink")
@Tags("drinks", "bar")
export class DrinkController extends Controller {
  @OperationId("updateDrinkNameOrPrice")
	@Extension({"x-speakeasy-name-override":"update"})
  @Put("{productCode}")
  @Tags("update")
  public async updateDrink(
    @Path() productCode: string,
    @Body() requestBody: DrinkUpdateParams
  ): Promise<Drink> {
    const drink = new DrinksService().updateDrink(productCode, requestBody);

    return drink;
  }
}
```

## Add Retries to Your SDK With `x-speakeasy-retries`

Speakeasy can generate SDKs that follow custom rules for retrying failed requests. For instance, if your server fails to return a response within a specified time, you may want your users to retry their request without clobbering your server.

Add retries to SDKs generated by Speakeasy by adding a top-level `x-speakeasy-retries` schema to your OpenAPI spec. You can also override the retry strategy per operation by adding `x-speakeasy-retries`.

### Adding Global Retries

To add a top-level retries extension to your OpenAPI spec, add a new `spec` schema to the `spec` configuration in `tsoa.json`:

```json tsoa.json
{
  "spec": {
    "spec": {
      "x-speakeasy-retries": {
        "strategy": "backoff",
        "backoff": {
          "initialInterval": 500,
          "maxInterval": 60000,
          "maxElapsedTime": 3600000,
          "exponent": 1.5
        },
        "statusCodes": ["5XX"],
        "retryConnectionErrors": true
      }
    }
  }
}
```

### Adding Retries per Method

To add retries to individual methods, use the tsoa `@Extension` decorator.

In the example below, we add `x-speakeasy-retries` to the `updateDrink` method:

```typescript src/drinks/drinksController.ts mark=4:14
@Route("drink")
export class DrinkController extends Controller {
  @Put("{productCode}")
  @Extension("x-speakeasy-retries", {
    strategy: "backoff",
    backoff: {
      initialInterval: 500,
      maxInterval: 60000,
      maxElapsedTime: 3600000,
      exponent: 1.5,
    },
    statusCodes: ["5XX"],
    retryConnectionErrors: true,
  })
  public async updateDrink(
    @Path() productCode: string,
    @Body() requestBody: DrinkUpdateParams,
  ): Promise<Drink> {
    const drink = new DrinksService().updateDrink(productCode, requestBody);

    return drink;
  }
}
```

## How To Generate an SDK Based on Your OpenAPI Spec

Once you have an OpenAPI spec, use Speakeasy to generate an SDK by calling the following in the terminal:

```bash
speakeasy quickstart
```

Follow the onscreen prompts to provide the necessary configuration details for your new SDK such as the name, schema location and output path. Enter `build/swagger.json` when prompted for the OpenAPI document location and select TypeScript when prompted for which language you would like to generate.

You can generate SDKs using Speakeasy when your API definition in tsoa changes. Many Speakeasy users [add SDK generation to their CI workflows](/docs/workflow-reference) to ensure their SDKs are always up to date.

## Summary

This tutorial explored different configurations and customizations available for the OpenAPI specification generation using tsoa. We've also learned how to assign and customize OpenAPI `operationId` and OpenAPI tags to our tsoa methods. Finally, we demonstrated how to add retries to your SDKs using `x-speakeasy-retries`. With this knowledge, you should now be able to leverage tsoa, OpenAPI, and Speakeasy more effectively for your API.

Take a look at our [Speakeasy Bar (tsoa) example repository](https://github.com/speakeasy-api/speakeasy-tsoa-example) containing all the code from this article.


 This is the content for the doc openapi/frameworks/typespec.mdx 

 ---
title: How To Generate an OpenAPI Spec With TypeSpec
description: "How to create OpenAPI schemas and SDKs from TypeSpec"
---

import { ScrollyCoding } from "~/components/codehike/Scrollycoding";

# How to Create OpenAPI Schemas and SDKs With TypeSpec

[TypeSpec](https://typespec.io/) is a brand-new domain-specific language (DSL) used to describe APIs. As the name implies you describe your API using a TypeScript-like type system, with language constructs such as `model` for the structure or schema of your API's data, or `op` for operations in your API. If you've used [OpenAPI](/openapi), these concepts likely sound familiar – this is because TypeSpec is also influenced by and generates OpenAPI.

So something that is _like_ OpenAPI, and also generates OpenAPI specifications? You may be asking yourself, why does TypeSpec exist? Like many people, our initial reaction to TypeSpec was to reference the iconic XKCD strip:

<div align="center">
  <br />
  <img src="https://imgs.xkcd.com/comics/standards_2x.png" width="70%" />
</div>

However, after spending some time with it, we've come to understand the justification for a new DSL - we'll cover some of that shortly. We also ran into this young language's rough edges, and we'll cover those in detail, too.

Our end goal with this article is to create a high-quality TypeScript SDK. However, before we create an SDK, we'll need to learn how to generate an OpenAPI document based on a TypeSpec specification. For that, we need to learn TypeSpec, and there is no better way to get started learning a new language than by asking _why_ it exists in the first place.

## The Problem TypeSpec Solves

Code generation is a force multiplier in API design and development. When an executive unironically asks, "How do we 10x API creation?", the unironic answer is, " API-first design + Code generation."

API-first means specifying exactly what your application's programming interface will look like before anything gets built, code generation means using that definition to create documentation, server (stubs) and client libraries (SDKs).

As mentioned previously,OpenAPI is widely used for exactly this reason – it provides a human-readable (as YAML) specification format for APIs, and comes with a thriving ecosystem of tools and code generators. So if OpenAPI exists, what can TypeSpec add?

The fundamental problem TypeSpec aims to solve is that writing OpenAPI documents by hand is complex, tedious, and error-prone. The complexity often leads to teams to abandon an API-first approach and instead start by coding their API, and then extracting OpenAPI from the codebase when they get to the point where they need documentation and SDKs – a quasi-API-first approach.

Ultimately, OpenAPI isn't for everyone. Neither is TypeSpec for that matter. But for those who are immersed in the TypeScript ecosystem, TypeSpec may be a more natural fit than OpenAPI. And the more tools we have to help businesses create great APIs, the better.

## TypeSpec Development Status

Before you trade in your OpenAPI YAML for TypeSpec, know that at the time of writing, TypeSpec is nowhere near as feature-rich and stable as OpenAPI. If you're designing a new API from scratch, taking the time to learn OpenAPI will benefit your team, even if TypeSpec one day becomes the most popular API specification language.

## TypeSpec Libraries and Emitters

Developers can extend the capabilities of TypeSpec by creating and using libraries. These libraries can provide additional functionality, such as decorators, types, and operations, that are not part of the core TypeSpec language.

A special type of library in TypeSpec is an emitter. Emitters are used to generate output from a TypeSpec specification. For example, the `@typespec/openapi3` library provides an emitter that generates an OpenAPI document from a TypeSpec specification.

When targeting a specific output format, such as OpenAPI, you can use the corresponding emitter library to generate the desired output. This allows you to write your API specification in TypeSpec and then generate the output in the desired format.

## A Brief Introduction to TypeSpec Syntax

This guide won't give a complete introduction or overview of TypeSpec, but we'll take a brief look at the language's structure and important concepts in the context of generating SDKs.

### Modularity in TypeSpec

The main entry point in TypeSpec is the `main.tsp` file. This file has the same role as the `index.ts` file in a TypeScript project.

Just like in TypeScript, we can organize code into files, folders, and modules, then [import](https://typespec.io/docs/language-basics/imports) these using the `import` statement. This helps split large API specifications into smaller, more manageable parts. The difference between TypeScript and TypeSpec in this regard is that TypeSpec imports files, not code.

Here's an example of how you can import files, folders, and modules in TypeSpec:

```typescript main.tsp
import "./books.tsp"; // Import a file
import "./books"; // Import main.tsp in a folder
import "/books"; // Import a TypeSpec module's main.tsp file
```

We can install modules using npm, and use the `import` statement to import them into our TypeSpec project.

[Namespaces](https://typespec.io/docs/language-basics/namespaces), another TypeScript feature that TypeSpec borrows, allow you to group types and avoid naming conflicts. This is especially useful when importing multiple files that define types with the same name. Just like with TypeScript, namespaces may be nested and span multiple files.

Namespaces are defined using the `namespace` keyword, followed by the namespace name and a block of type definitions. Here's an example:

```typescript
namespace MyNamespace {
  model User {
    id: string;
    name: string;
  }
}
```

They may also be defined at the file level, using the `namespace` keyword followed by the namespace name and a block of type definitions. Here's an example:

```typescript
namespace MyNamespace;

model User {
    id: string;
    name: string;
}

model Post {
    id: string;
    title: string;
    content: string;
}
```

### Models in TypeSpec

[Models](https://typespec.io/docs/language-basics/models) in TypeSpec are similar to OpenAPI's `schema` objects. They define the structure of the data that will be sent and received by your API. We define models using the `model` keyword, followed by the model name and a block of properties. Here's an example:

```typescript main.tsp
model User {
    id: string;
    name: string;
    email: string;
}
```

Models are composable and extensible. You can reference other models within a model definition, extend a model with additional properties, and compose multiple models into a single model. Here's an example of model composition:

```typescript main.tsp
namespace WithComposition {
    model User {
        id: string;
        name: string;
        email: string;
    }

    model HasRole {
        role: string;
    }

    model Admin is User { // Copies the properties and decorators from User
        ...HasRole; // Extends the User model with the properties from the HasRole model
        level: number; // Adds a new property to the Admin model
    }
}

// The Admin model above will have the following properties:
namespace WithoutComposition {
    model Admin {
        id: string;
        name: string;
        email: string;
        role: string;
        level: number;
    }
}
```

The equivalent OpenAPI specification for the `User` model above would look like this:

```yaml openapi.yaml
components:
  schemas:
    User:
      type: object
      properties:
        id:
          type: string
        name:
          type: string
        email:
          type: string
```

### Operations in TypeSpec

[Operations](https://typespec.io/docs/language-basics/operations) in TypeSpec are similar to OpenAPI operations. They describe the methods that users can call in your API. We define operations using the `op` keyword, followed by the operation name. Here's an example:

```typescript main.tsp
op listUsers(): User[]; // Defaults to GET
op getUser(id: string): User; // Defaults to GET
op createUser(@body user: User): User; // Defaults to POST with a body parameter
```

### Interfaces in TypeSpec

[Interfaces](https://typespec.io/docs/language-basics/interfaces) in TypeSpec group related operations together, similar to OpenAPI's `paths` object. We define interfaces using the `interface` keyword, followed by the interface name and a block of operations. Here's an example:

```typescript main.tsp
@route("/users")
interface Users {
    op listUsers(): User[]; // Defaults to GET /users
    op getUser(id: string): User; // Defaults to GET /users/{id}
    op createUser(@body user: User): User; // Defaults to POST /users
}
```

The equivalent OpenAPI specification for the `Users` interface above would look like this:

```yaml openapi.yaml
paths:
  /users:
    get:
      operationId: listUsers
      responses:
        200:
          description: OK
          content:
            application/json:
              schema:
                type: array
                items:
                  $ref: "#/components/schemas/User"
    post:
      operationId: createUser
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/User"
      responses:
        200:
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/User"
  /users/{id}:
    get:
      operationId: getUser
      parameters:
        - name: id
          in: path
          required: true
          schema:
            type: string
      responses:
        200:
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/User"
```

### Decorators in TypeSpec

[Decorators](https://typespec.io/docs/language-basics/decorators) in TypeSpec add metadata to models, operations, and interfaces. They start with the `@` symbol followed by the decorator name. Here's an example of the `@doc` decorator:

```typescript main.tsp mark=1,3,6,9
@doc("A user in the system")
model User {
    @doc("The unique identifier of the user")
    id: string;

    @doc("The name of the user")
    name: string;

    @doc("The email address of the user")
    email: string;
}
```

Decorators allow you to add custom behavior to your TypeSpec definitions using JavaScript functions. You can [define your own decorators](https://typespec.io/docs/extending-typespec/create-decorators) or use built-in decorators provided by TypeSpec or third-party libraries.

### Learn More About TypeSpec

The language features above should be enough to help you find your way around a TypeSpec specification.

If you're interested in learning more about the TypeSpec language, see the [official documentation](https://typespec.io/docs/language-basics/overview).

We'll cover more detailed examples of TypeSpec syntax in our full example below.

## Generating an OpenAPI Document from TypeSpec

Now that we have a basic understanding of TypeSpec syntax, let's generate an OpenAPI document from a TypeSpec specification.

The example below will guide you through the process of creating a TypeSpec project, writing a TypeSpec specification, and generating an OpenAPI document from it.

For a speedrun, we've published the full example in a [GitHub repository](https://github.com/speakeasy-api/typespec-openapi-example).

### Step 1: Install the TypeSpec Compiler CLI

Install `tsp` globally using npm:

```bash Terminal
npm install -g @typespec/compiler
```

### Step 2: Create a TypeSpec Project

Create a new directory for your TypeSpec project and navigate into it:

```bash Terminal
mkdir typespec-example-speakeasy
cd typespec-example-speakeasy
```

Run the following command to initialize a new TypeSpec project:

```bash Terminal
tsp init
```

This will prompt you to select a template for your project. Choose the `Generic REST API` template and press enter. Press enter repeatedly to select the defaults until the project is initialized.

### Step 3: Install the TypeSpec Dependencies

Install the TypeSpec dependencies using `tsp`:

```bash Terminal
tsp install
```

We'll need to install the `@typespec/versioning` and `@typespec/openapi` modules to generate an OpenAPI document. Run the following commands to install these modules:

```bash Terminal
npm install @typespec/versioning @typespec/openapi
```

### Step 4: Write Your TypeSpec Specification

Open the `main.tsp` file in your text editor and write your TypeSpec specification. Here's an example of a simple TypeSpec specification:

<ScrollyCoding className="ch-scrollycoding-full-height  ch-scrollycoding-force-focus-scroll" fullHeight>

## !!steps

We start by importing the necessary TypeSpec modules.

These modules are provided by the TypeSpec project, but are not part of the core TypeSpec language. They extend the capabilities of TypeSpec for specific use cases.

```typescript ! main.tsp focus=1:4
!from ./assets/typespec/main.tsp
```

---

## !!steps

By writing three [`using` statements](https://typespec.io/docs/language-basics/namespaces), we expose the contents of the `Http`, `OpenAPI`, and `Versioning` modules to the current file. This allows us to use the functionality provided by these modules in our TypeSpec specification with less code.

Without these statements, we can still access the functionality of the modules by using the fully qualified names of the types and functions they provide.

For example, instead of writing `@operationId`, we could write `TypeSpec.OpenAPI.operationId` to access the `operationId` decorator provided by the `OpenAPI` module.

```typescript ! main.tsp focus=6:8
!from ./assets/typespec/main.tsp
```

---

## !!steps

Next, we define the `BookStore` namespace, which will contain all the models, interfaces, and operations related to the bookstore API. Namespaces are used to group related types and operations together, and avoid naming conflicts.

This is a file-level namespace (it has no code block delimiters – no `{` and `}`), which means it spans the entire file.

```typescript ! main.tsp focus=28
!from ./assets/typespec/main.tsp
```

---

## !!steps

Taking a step back, we see that the `BookStore` namespace is decorated with the [`@service` decorator](https://typespec.io/docs/standard-library/built-in-decorators#@service) from the TypeSpec core library.

The `@service` decorator marks the namespace as a service, and provides the API's title.

```typescript ! main.tsp focus=10:12
!from ./assets/typespec/main.tsp
```

---

## !!steps

We decorate the `BookStore` namespace with the [`@info` decorator](https://typespec.io/docs/libraries/openapi/reference/decorators#@TypeSpec.OpenAPI.info) from the `@TypeSpec.OpenAPI` library to provide information for the OpenAPI document's `info` object.

```typescript ! main.tsp focus=13:24
!from ./assets/typespec/main.tsp
```

---

## !!steps

TypeSpec's [`@versioned` decorator](https://typespec.io/docs/libraries/versioning/reference/decorators#@TypeSpec.Versioning.versioned) from the `@TypeSpec.Versioning` library specifies the versions of the API.

We define a single version, `1.0.0`, for the API, but you can define multiple versions if needed.

```typescript ! main.tsp focus=25,30:32
!from ./assets/typespec/main.tsp
```

---

## !!steps

We add a `@server` decorator to the `BookStore` namespace, which specifies the base URL of the API server: `http://127.0.0.1:4010`.

This is the default [Prism](https://docs.stoplight.io/docs/prism/) server URL here, but you can replace this with the actual base URL of your API server.

```typescript ! main.tsp focus=26
!from ./assets/typespec/main.tsp
```

---

## !!steps

Finally, our `BookStore` namespace is decorated with the [`@doc` decorator](https://typespec.io/docs/standard-library/built-in-decorators#@doc) from the TypeSpec core library, which provides a description of the API.

In the OpenAPI 3 emitter, this description will be used as the `description` field in the OpenAPI document's `info` object.

```typescript ! main.tsp focus=27
!from ./assets/typespec/main.tsp
```

---

## !!steps

This brings us to our first model, `PublicationBase`, which represents the base model for books and magazines in the store.

Here we see how models are defined in TypeSpec using the `model` keyword, followed by the model name and a block of properties.

Property types are similar to those in OpenAPI, but with some nuances. For example, `float32` is used instead of `number`, and `utcDateTime` is used for date-time values.

See the [TypeSpec data types documentation](https://typespec.io/docs/language-basics/built-in-types) for more information on the available data types. We should also educate ourselves about how these data types are [represented in the OpenAPI document](https://typespec.io/docs/getting-started/typespec-for-openapi-dev#type-and-format).

The `type` property is defined as an [`enum`](https://typespec.io/docs/language-basics/enums) to represent the type of publication. This is a custom enum defined within the `BookStore` namespace.

```typescript ! main.tsp focus=34:56
!from ./assets/typespec/main.tsp
```

---

## !!steps

Next, we define constants, `BookExample1` and `BookExample2`, using the `#{}` syntax. We'll use these examples to demonstrate the structure of the `Book` model.

On their own, these constants are not part of the model, nor will they be emitted by the OpenAPI emitter. We have to pass them as values in the `@example` decorator to include them in the OpenAPI document.

```typescript ! main.tsp focus=58:76
!from ./assets/typespec/main.tsp
```

---

## !!steps

This is the `Book` model, which extends the `PublicationBase` model. We use the `@example` decorator to provide an example value for the model.

The `extends` keyword causes the `Book` model to inherit properties from the `PublicationBase` model, with the ability to add additional properties specific to books, or override existing properties.

```typescript ! main.tsp focus=78:88
!from ./assets/typespec/main.tsp
```

---

## !!steps

Magazines are represented by the `Magazine` model, which also extends the `PublicationBase` model. We provide example values for the `Magazine` model using the `@example` decorator.

Note how the `Magazine` model adds properties specific to magazines, such as `issueNumber` and `publisher`.

```typescript ! main.tsp focus=110:120
!from ./assets/typespec/main.tsp
```

---

## !!steps

To represent both books and magazines in a single model, we define a `Publication` [union type](https://typespec.io/docs/language-basics/unions). The `Publication` model is a union of the `Book` and `Magazine` models, with a discriminator property `type` to differentiate between the two.

The `@discriminator` decorator specifies the property that will be used to determine the type of the publication.

The [`@oneOf` decorator](https://typespec.io/docs/emitters/openapi3/reference/decorators#@TypeSpec.OpenAPI.oneOf) is specific to the OpenAPI 3 emitter, and indicates that the `Publication` schema should reference the `Book` and `Magazine` schemas using the `oneOf` keyword instead of `allOf`.

```typescript ! main.tsp focus=122:132
!from ./assets/typespec/main.tsp
```

---

## !!steps

The `Order` model represents an order for publications in the store. It contains familiar properties much like those of the `Publication` models, except for a reference to the `Publication` model in the `items` property.

The `items` property is an array of publications, which can contain both books and magazines.

```typescript ! main.tsp focus=150:167 mark=160
!from ./assets/typespec/main.tsp
```

---

## !!steps

Moving on to operations, let's start with the `Publications` interface, which wraps operations for managing publications in the store.

```typescript ! main.tsp focus=169:190
!from ./assets/typespec/main.tsp
```

---

## !!steps

We decorate the `Publications` interface with the [`@tag` decorator](https://typespec.io/docs/standard-library/built-in-decorators#@tag) from the standard library to specify the tag for the operations in the interface. Tags are used to group related operations in the OpenAPI document, and can be applied to interfaces, operations, and namespaces.

Since we are using the OpenAPI 3 emitter, the `@tag` decorator will be used to generate the `tags` field in the OpenAPI document.

```typescript ! main.tsp focus=169:190 mark=170
!from ./assets/typespec/main.tsp
```

---

## !!steps

The [`@route` decorator](https://typespec.io/docs/libraries/http/reference/decorators#@TypeSpec.Http.route) provided by the `@TypeSpec.Http` library specifies the path prefix for the operations in the `Publications` interface.

```typescript ! main.tsp focus=169:190 mark=171
!from ./assets/typespec/main.tsp
```

---

## !!steps

In the `Publications` interface, we define three operations: `list`, `get`, and `create`.

```typescript ! main.tsp
// !focus(169:190)
// !mark(176,181,189)
```

---

## !!steps

Let's focus for a moment on what we _don't_ see in the operation definitions.

Note how the `op` keyword is optional when defining operations within an interface. The operations are defined directly within the interface block, without the need for the `op` keyword.

The operations are also defined without an HTTP method, such as `GET` or `POST`. This is because the default HTTP method for an operation is determined by the operation's parameters.

If an operation contains a `@body` parameter, it defaults to `POST`. Any operation without a `@body` parameter defaults to `GET`.

```typescript ! main.tsp focus=169:190
!from ./assets/typespec/main.tsp
```

---

## !!steps

The `get` operation in the `Publications` interface takes a `string` parameter `id` and returns a `Publication` or an `Error`.

Note how the `@path` decorator is used to specify that the `id` parameter is part of the path in the URL.

This operation will have the path `/publications/{id}` in the OpenAPI document. TypeSpec will automatically generate the path parameter for the `id` parameter.

```typescript ! main.tsp focus=178:181
!from ./assets/typespec/main.tsp
```

---

## !!steps

Examples for operation parameters and return types are provided using the `@opExample` decorator from the standard library. These examples will be included in the OpenAPI document to demonstrate the structure of the request and response payloads.

Note that this functionality, at the time of writing (with TypeSpec 0.58.1), is not yet fully implemented in the OpenAPI emitter.

The best part of the `@opExample` decorator is that it allows you to provide example values for the operation parameters and return types directly in the TypeSpec specification, and that these values are typed.

This enables code editors and IDEs to provide autocompletion and type-checking for the example values, making it easier to write and maintain the examples.

This also means TypeSpec forces you to keep examples up to date with the actual data structures, the lack of which is a common source of errors in API documentation.

```typescript ! main.tsp focus=178:181 mark=178
!from ./assets/typespec/main.tsp
```

---

## !!steps

To generate useful operation IDs in the OpenAPI document, we use the [`@operationId` decorator](https://typespec.io/docs/libraries/openapi/reference/decorators#@TypeSpec.OpenAPI.operationId) from the `@TypeSpec.OpenAPI` library.

Without this decorator, TypeSpec will still derive operation IDs from the operation names, but using the decorator allows us to provide more descriptive and meaningful operation IDs.

Keep in mind that specifying manual operation IDs can lead to duplicate IDs.

```typescript ! main.tsp focus=178:181 mark=180
!from ./assets/typespec/main.tsp
```

---

## !!steps

That concludes our tour of the `BookStore` namespace. We've defined models for publications, orders, and errors, as well as interfaces for managing publications and orders.

```typescript ! main.tsp
!from ./assets/typespec/main.tsp
```

</ScrollyCoding>

### Step 5: Generate the OpenAPI Document

Now that we've written our TypeSpec specification, we can generate an OpenAPI document from it using the `tsp` compiler.

Run the following command to generate an OpenAPI document:

```bash Terminal
tsp compile main.tsp --emit @typespec/openapi3
```

The `tsp compile` command creates a new directory called `tsp-output`, then the `@typespec/openapi3` emitter creates the directories `@typespec/openapi3` within. If we were to use other emitters, such as protobuf, we would see `@typespec/protobuf` directories instead.

Because we're using the versioning library, the OpenAPI document will be generated for the specified version of the API. In our case, the file generated by the OpenAPI 3 emitter will be named `openapi.yaml`.

### Step 6: View the Generated OpenAPI Document

Open the generated OpenAPI document in your text editor or a YAML viewer to see the API specification.

<ScrollyCoding className="ch-scrollycoding-full-height  ch-scrollycoding-force-focus-scroll" fullHeight>

## !!steps

Let's scroll through the generated OpenAPI document to see how our TypeSpec specification was translated into an OpenAPI specification.

```typescript !! main.tsp
!from ./assets/typespec/main.tsp
```

---

```yaml !! openapi.yaml
!from ./assets/typespec/openapi.yaml
```

---

## !!steps

The OpenAPI document starts with the `openapi` field, which specifies the version of the OpenAPI specification used in the document. In this case, it's version 3.0.0.

This version is determined by the emitter we used to generate the OpenAPI document. The `@typespec/openapi3` emitter generates OpenAPI 3.0 documents.

```typescript !! main.tsp focus=3
!from ./assets/typespec/main.tsp 1:20
```

---

```yaml !! openapi.yaml focus=1
!from ./assets/typespec/openapi.yaml 1:20
```

---

## !!steps

The `info` field contains metadata about the API, such as the title, terms of service, contact information, license, and description. This information is provided by the `@service` and `@info` decorators in the TypeSpec specification.

```typescript !! main.tsp
!from ./assets/typespec/main.tsp 10:25
```

---

```yaml !! openapi.yaml
!from ./assets/typespec/openapi.yaml 2:13
```

---

## !!steps

Let's take a closer look at the `placeOrder` operation in the OpenAPI document. The operation is defined under the `/orders` path and uses the `POST` method.

```typescript !! main.tsp
!from ./assets/typespec/main.tsp 192:216
```

---

```yaml !! openapi.yaml
!from ./assets/typespec/openapi.yaml 17:54
```

---

## !!steps

Firstly, we see that the operation's `operationId` is set to `placeOrder`, which is the same as the `@operationId` decorator in the TypeSpec specification.

```typescript !! main.tsp mark=10
!from ./assets/typespec/main.tsp 192:216
```

---

```yaml !! openapi.yaml mark=6
!from ./assets/typespec/openapi.yaml 17:54
```

---

## !!steps

The operation is tagged with the `orders` tag, which is specified by the `@tag` decorator in the TypeSpec specification. In this case, we tagged the `Orders` interface with the `orders` tag, instead of the individual operations.

The tags still apply to individual operations in the OpenAPI document, as seen here.

```typescript !! main.tsp mark=2
!from ./assets/typespec/main.tsp 192:216
```

---

```yaml !! openapi.yaml mark=4:5
!from ./assets/typespec/openapi.yaml 17:54
```

---

## !!steps

Instead of parameters, this operation uses a `requestBody` field to specify the request payload. The `@body` parameter in the TypeSpec specification corresponds to the `requestBody` field in the OpenAPI document.

```typescript !! main.tsp mark=11
!from ./assets/typespec/main.tsp 192:216
```

---

```yaml !! openapi.yaml
!from ./assets/typespec/openapi.yaml 40:54
```

---

## !!steps

Of particular interest is the `example` field in the `requestBody` object. This field provides an example value for the request payload, demonstrating the structure of the data expected by the API.

The current implementation of the OpenAPI emitter supports the `@opExample` decorator for operation examples, but does not yet support extended models or unions. This shows up in the generated OpenAPI document as empty objects in the `items` array for the `order` example.

```typescript !! main.tsp
!from ./assets/typespec/main.tsp 142:148
```

---

```yaml !! openapi.yaml mark=6:7
!from ./assets/typespec/openapi.yaml 46:54
```

---

## !!steps

Next, let's look at how the OpenAPI document represents our polymorphic `Publication` model.

```typescript !! main.tsp mark=5:11
!from ./assets/typespec/main.tsp 122:132
```

---

```yaml !! openapi.yaml
!from ./assets/typespec/openapi.yaml 305:314
```

---

## !!steps

Because the `Publication` model is a union of the `Book` and `Magazine` models, and we decorated this union with `@oneOf` in TypeSpec, the OpenAPI document uses the `oneOf` keyword to represent the union.

```typescript !! main.tsp mark=7:11
!from ./assets/typespec/main.tsp 122:132
```

---

```yaml !! openapi.yaml mark=2:9
!from ./assets/typespec/openapi.yaml 305:314
```

---

## !!steps

Unfortunately, as of version 0.58.1 of TypeSpec, the OpenAPI emitter also seems to fail to include the example values for the `Publication` model in the OpenAPI document.

```typescript !!  main.tsp mark=1
!from ./assets/typespec/main.tsp 122:132
```

---

```yaml !! openapi.yaml mark=10
!from ./assets/typespec/openapi.yaml 305:314
```

---

## !!steps

Likewise, the `Book` schema's example is incomplete in the OpenAPI document. The emitter does not show the example values for the `PublicationBase` properties, such as `id`, `title`, `publishDate`, and `price`.

```yaml ! openapi.yaml focus=22:25
!from ./assets/typespec/openapi.yaml 192:217
```

---

## !!steps

In the `Book` schema, we also see how the `allOf` keyword is used to combine the properties of the `PublicationBase` model with the additional properties of the `Book` model.

```yaml ! openapi.yaml focus=20:22
!from ./assets/typespec/openapi.yaml 192:217
```

---

## !!steps

Problems with examples aside, the OpenAPI document provides a clear representation of the API we defined in our TypeSpec specification.

```yaml ! openapi.yaml
!from ./assets/typespec/openapi.yaml
```

</ScrollyCoding>

### Step 7: Generate an SDK from the OpenAPI Document

Now that we have an OpenAPI document for our API, we can generate an SDK using Speakeasy.

Make sure you have [Speakeasy installed](/docs/speakeasy-cli/getting-started):

```bash Terminal
speakeasy --version
```

Then, generate a TypeScript SDK using the following command:

```bash Terminal
speakeasy generate sdk \
  --schema tsp-output/@typespec/openapi3/openapi.yaml \
  --lang typescript \
  --out ./sdks/bookstore-ts
```

This command generates a TypeScript SDK for the API defined in the OpenAPI document. The SDK will be placed in the `sdks/bookstore-ts` directory.

### Step 8: Customize the SDK

We'd like to add retry logic to the SDK's `listPublications` to handle network errors gracefully. We'll do this by using an OpenAPI extension that [Speakeasy provides](/docs/customize-sdks/retries), `x-speakeasy-retries`.

Instead of modifying the OpenAPI document directly, we'll add this extension to the TypeSpec specification and regenerate the OpenAPI document and SDK.

<ScrollyCoding className="ch-scrollycoding-full-height  ch-scrollycoding-force-focus-scroll" fullHeight>

## !!steps

Let's add the `x-speakeasy-retries` extension to the `listPublications` operation in the TypeSpec specification.

Do this by adding the @extension decorator to the `listPublications` operation, then specifying the `x-speakeasy-retries` extension.

```typescript ! main.tsp mark=2:12
interface Publications {
  @extension("x-speakeasy-retries", {
    strategy: "backoff",
    backoff: {
      initialInterval: 500,
      maxInterval: 60000,
      maxElapsedTime: 3600000,
      exponent: 1.5,
    },
    statusCodes: ["5XX"],
    retryConnectionErrors: true
  })
  @opExample(#{ returnType: #[BookExample1, MagazineExample1] })
  @doc("List all publications")
  @operationId("listPublications")
  list(): Publication[];
```

---

## !!steps

Now that we've added the `x-speakeasy-retries` extension to the `BookStore` namespace, we can regenerate the OpenAPI document:

```yaml !! openapi.yaml focus=21:30
paths:
  /publications:
    get:
      tags:
        - publications
      operationId: listPublications
      description: List all publications
      parameters: []
      responses:
        "200":
          description: The request has succeeded.
          content:
            application/json:
              schema:
                type: array
                items:
                  $ref: "#/components/schemas/Publication"
              example:
                - {}
                - {}
      x-speakeasy-retries:
        strategy: backoff
        backoff:
          initialInterval: 500
          maxInterval: 60000
          maxElapsedTime: 3600000
          exponent: 1.5
        statusCodes:
          - 5XX
        retryConnectionErrors: true
```

```bash !! Terminal
tsp compile main.tsp --emit @typespec/openapi3
```

</ScrollyCoding>

Now that we've added the `x-speakeasy-retries` extension to the `listPublications` operation in the TypeSpec specification, we can use Speakeasy to recreate the SDK:

```bash Terminal
speakeasy generate sdk \
  --schema tsp-output/@typespec/openapi3/openapi.yaml \
  --lang typescript \
  --out ./sdks/bookstore-ts
```

## Common TypeSpec Pitfalls and Possible Solutions

While working with TypeSpec version 0.58.1, we encountered a few limitations and pitfalls that you should be aware of.

### 1. Limited Support for Model and Operation Examples

Examples only shipped as part of TypeSpec version 0.58.0, and the OpenAPI emitter is still in development. This means that the examples provided in the TypeSpec specification may not be included in the generated OpenAPI document.

To work around this limitation, you can provide examples directly in the OpenAPI document, preferably by using an [OpenAPI Overlay](/docs/prep-openapi/overlays/create-overlays).

Here's an overlay, saved as `bookstore-overlay.yaml`, that adds examples to the `Book` and `Magazine` models in the OpenAPI document:

```yaml bookstore-overlay.yaml
overlay: 1.0.0
info:
  title: Add Examples to Book and Magazine Models
  version: 1.0.0
actions:
  - target: $.components.schemas.Book
    update:
      example:
        id: "1"
        title: "The Great Gatsby"
        publishDate: "2022-01-01T00:00:00Z"
        price: 19.99
  - target: $.components.schemas.Magazine
    update:
      example:
        id: "2"
        title: "National Geographic"
        publishDate: "2022-01-01T00:00:00Z"
        price: 5.99
```

Validate the overlay using Speakeasy:

```bash Terminal
speakeasy overlay validate -o bookstore-overlay.yaml
```

Then apply the overlay to the OpenAPI document:

```bash Terminal
speakeasy overlay apply -s tsp-output/@typespec/openapi3/openapi.yaml -o bookstore-overlay.yaml > combined-openapi.yaml
```

If we look at the `combined-openapi.yaml` file, we should see the examples added to the `Book` and `Magazine` models, for example:

```yaml combined-openapi.yaml
example:
  type: Magazine
  issueNumber: 1
  publisher: Publisher Name
  id: "2"
  title: "National Geographic"
  publishDate: "2022-01-01T00:00:00Z"
  price: 5.99
```

### 2. Only Single Examples Supported

At the time of writing, the OpenAPI emitter only supports a single example for each operation or model. If you provide multiple examples using the `@opExample` decorator in the TypeSpec specification, only the last example will be included in the OpenAPI document.

OpenAPI version 3.0.0 introduced support for multiple examples using the `examples` field, and since OpenAPI 3.1.0, the singular `example` field is marked as deprecated in favor of multiple `examples`.

### 3. No Extensions at the Namespace Level

We found that the `x-speakeasy-retries` extension could not be added at the namespace level in the TypeSpec specification, even though Speakeasy supports this extension at the operation level.

The TypeSpec documentation on the [@extension](https://typespec.io/docs/libraries/openapi/reference/decorators#@TypeSpec.OpenAPI.extension) decorator does not mention any restrictions on where extensions can be applied, so this may be a bug or an undocumented limitation.

To work around this limitation, you can add the `x-speakeasy-retries` extension directly to the OpenAPI document using an overlay, as shown in the previous example, or by adding it to each operation individually in the TypeSpec specification.

### 4. No Support for Webhooks or Callbacks

TypeSpec does not yet support webhooks or callbacks, which are common in modern APIs. This means you cannot define webhook operations or callback URLs in your TypeSpec specification and generate OpenAPI documents for them.

To work around this limitation, you can define webhooks and callbacks directly in the OpenAPI document using an overlay, or by adding them to the OpenAPI document manually.

### 5. OpenAPI 3.0.0 Only

TypeSpec's OpenAPI emitter currently only supports OpenAPI version 3.0.0. We much prefer OpenAPI 3.1.0, which introduced several improvements over 3.0.0.

## The TypeSpec Playground

To help you experiment with TypeSpec and see how it translates to OpenAPI, the Microsoft team created a [TypeSpec Playground](https://typespec.io/playground).

We added our [TypeSpec specification](https://typespec.io/playground?e=%40typespec%2Fopenapi3&options=%7B%7D&c=aW1wb3J0ICJAdHlwZXNwZWMvaHR0cCI7CtIZb3BlbmFwadwcM9UddmVyc2lvbmluZyI7Cgp1c2luZyBUeXBlU3BlYy5IdHRwO9AVT3BlbkFQSdEYVslKOwoKQHNlcnZpY2UoewogIHRpdGxlOiAiQm9vayBTdG9yZSBBUEkiLAp9KQpAaW5mb8YmZXJtc09mU8Y5OiAi5ADtczovL2Jvb2tzxDYuZXhhbXBsZS5jb20vxS8iLAogIGNvbnRhY3Q6IMRGICBuYW3EPkFQSSBTdXDkAPDFJiAgdXJs31ZtL3PNMmVtYWnENMcWQNU0xSx9xAVsaWNlbnNl8ACJcGFjaGUgMi4w9QCId3d3LmHFIy5vcmcvx0RzL0xJQ0VOU0UtMi4wLmh0bWzIZ%2BQBNOcBtWVkKOcBdXMp5gFyZXIoxVk6Ly8xMjcuMC4wLjE6NDAxMCIs8AF%2FIHYxIikKQGRvYyjlASxmb3IgbWFuYWfkAdVhIOQA6yDlAOwgaW52ZW50b3J5IGFuZCBvcmRlcnMiKQrkAN9zcGFjZSDEWcVYOwoKZW51bSDoAJblAQlgMeQAiGAsCn3HHlB1YmxpY2F0aW9u5AI9xSXEQ%2BQA4U1hZ2F6aW5lxS7mAJ1CYXNlIG1vZGVs5QCk5QGE5QCKbccs5ACNxiDLWsU2xFrGRVVuaXF1ZSBpZGVudGlmaWVyIinEHGtleQogIGlkOiBzdHLmArrIMlTkArUgb2YgdGhlIHDKWcU55wLS0TXrAIEgZGF0ZcUtxT1zaERhdGU6IHV0Y8QJVGlt5AEuyThyaWPkAWkgVVNExjTEETogZmxvYXQzMssq5QEyb2byAJJ5cGU68AFbO%2BQBRmNvbnN05QFhReYCtTEgPSAj5AEb5AD4IjEyM%2BUCW%2B0DpeUA%2FcUX%2BAC9LmZyb21JU08oIjIwMjAtMDEtMDFUMDA6xQNaIinFPOYAxTE5Ljk5xWP0AKQu6AH7YXV0aG9y5AMxxQkgTmFt5gCDaXNibuYAqTQ1Njc4OeQDSH078wDZMu0A2TQ1Nu0A2UFub3RoZXLFMf8A4fQA4TL6AOEyNP8A4fAA4ecAiuYA6ewA5DA5ODc2NTQzMjHnAORA5wRpKOwBwOgDt1JlcHJlc2VudHPoA7FpbuUCr%2BUDuOkDFsQ7IGV4dGVuZHP1AyP6ALfrAnnnAZbnAxHEbuUCeOgA1fEDC0lTQk7RLuYA58gs6QKd6AP29QKhNzg57QHIyC3%2FAcT0AcQz%2BgHE%2FgKkyHTEImlzc3VlTnVtYmVyOiAxy3%2FEEOYEAsQM6ALA6gKq7wDm7gKuMDEy9QKu%2FwDu%2FADuNPoA7jf%2FAO73AO4yy3%2FEEOkApukA9vACt%2FAB2vUCu%2BgFyfYCv8hD%2FwLD%2FADJ7AKX5ADQIG7lANHoAp%2FoAIDnAqPrAPFpbu4FfuoB3tQ76wEa8QLj6wCb6wLm7APW6QIo0ivkAivwAUrsAWbTXeQBaWlzY3JpbWluYXRvcigi5AEj5Afyb25lT2YKdW7kBqTLOeUBR%2BQDqTrpB43oAN069AeXUG9zc2libOQBrmF0dXNlc%2BUHnmFu5gghIinmB%2BxPxA1TxSLFYVBlbmRpbmfEXlNoaXBwZWTEC0RlbGl2ZXLGDUNhbmNlbGzEDeoDPMVI9QQfYWJj5goGdXN0b21lcknsBtVpdGVtczogI1vsAWks8QFMXcQsdG90YWzlB4k6IDI5Ljk4xBXmAN067ADILukAxO0C6u0AovQC5%2BcBGuUBJ%2BsHvuoIvsVC%2FAi0xTvkAnboAWP3CLtD5wELIHdobyBwbGFjZWTPN%2BwBLdE%2FTGlzdO8IY3PoA5vLeuYBW%2BsCQltdy0VU5AFO5gRv6AMsyjzsAWvyCOPnAi%2FRNvMBjOUDYcY2T3BlcucArO0Ky%2B8Ba0B0YWcoItAVcm91dGUoIi%2FPGGludGVyZuQK4%2BsA5%2BYCyUDlBI7kCuYoIngtc3BlYWtlYXN5LXJldHJpZXMiLMUm5AC1cmF0ZWd5OiAiYmFja29mZucMBscO6AwtICBpbml0aWFsScR0dmFsOiA1MDDGK%2BQDinjKGDYwMM0aRWxhcHNlZOQGAzogM8UeyR9leHBvbmVudDogMS41xhXlDKvoAU5Db2RlczogWyI1WFgi5QMHICDkAMN5Q29ubmVj5QRScnJvcnM6IHRydWXkDIPlCzlvcOcC6ygje8QxdXLlBXL%2FA2vkA2vHQeoCamFsbPABpcVh5wHPSWQoImxpc3TsAYLFI8QVKCn1AoLtAJ5wYXJhbWV0ZeQAxCN76gr1IH0s7QC67Qsi6wClR2V0IGEg5A8taWZpY%2BwAqyBieSBJ5guw7gCwZ2XsAK%2FFIWdldChAcGF0aOsDs%2B4AvSB8IOUBa%2FIAw%2BUBlu8Ax%2BsAh%2FAAu%2BkBxvUA28Qe6wDeQ3JlYXRlIGEgbmV3zFXzANZjxSvwANnGFihAYm9kecxB7QDc%2BADq%2FwO%2BZ%2BoObuYDuMoP6AOyyRLqA6zlBCDnA6b%2FAUfGYOcEU%2FwBQs0h7wFDUOQFYucBQuoEru4BPOUFhsVFxR3KD%2BcBOewAiCnHCPoCEf8C1PcAt%2FEC1egGkvsCx%2BoAs8gN9ALG%2FwCv9AF56g589Qdk5wgd%2FwGL8QGLVXDkD3bnCkXoBkbrCJTwAOJ1xTDLecUkxhbGEfEA7ywg5gGy8wC28gEK5ALg6AghI3sgY29kZTogNDA0LCBtZXNzYWfkC%2BrsAxlub3QgZm91bmQi5ADWQGXERucDIsVSIHJlc3BvbnPqCx7GF%2BoINcYQxGnmA57FcvAKx8Yl5wCDxSjHDOwKuQ%3D%3D) to the playground. You can view the generated OpenAPI document and SDK, or browse a generated Swagger UI for the API.

## Further Reading

This guide barely scratches the surface of what you can do with TypeSpec. This small language is evolving rapidly, and new features are being added all the time.

Here are some resources to help you learn more about TypeSpec and how to use it effectively:

- [TypeSpec Documentation](https://typespec.io/docs): The official TypeSpec documentation provides detailed information on the TypeSpec language, standard library, and emitters.
- [TypeSpec Releases](https://github.com/microsoft/typespec/releases): Keep up with the latest TypeSpec releases and updates on GitHub.
- [TypeSpec Playground](https://typespec.io/playground): Worth mentioning again: experiment with TypeSpec in the browser, generate OpenAPI documents, and view the resulting Swagger UI.
- [Speakeasy Documentation](/docs): Speakeasy has extensive documentation on how to generate SDKs from OpenAPI documents, customize SDKs, and more.
- [Speakeasy OpenAPI Reference](/openapi): For a detailed reference on the OpenAPI specification.


 This is the content for the doc openapi/frameworks/zod.mdx 

 ---
title: How To Generate an OpenAPI Spec with Zod
description: "How to generate OpenAPI schemas and great SDK clients for your Zod-validated API"
---

import { ScrollyCoding } from "~/components/codehike/Scrollycoding";
import { Callout } from "~/components";

# How to generate an OpenAPI/Swagger spec with Zod

Zod is a powerful and flexible schema validation library for TypeScript. Many users define their TypeScript data parsing schemes using it.

In this tutorial, we'll take a detailed look at how to set up Zod OpenAPI to generate an OpenAPI schema based on Zod schemas. Then we'll use Speakeasy to read our generated OpenAPI schema and generate a production-ready client SDK.

## An Example Schema: Burgers and Orders

We'll start with a tiny example schema describing two main types: Burgers and Orders. A burger is a menu item with an ID, name, and description. An order has an ID, a non-empty list of burger IDs, the time the order was placed, a table number, a status, and an optional note for the kitchen.

Anticipating our CRUD app, we'll also add additional schemas describing fields for creating new objects without IDs or updating existing objects where all fields are optional.

<Callout title="Example code" variant="info">
  If you want to follow along with the example code in this tutorial, you can
  clone the [Speakeasy Zod OpenAPI example
  repo](https://github.com/speakeasy-api/speakeasy-zod-openapi).
</Callout>

## An Overview of Zod OpenAPI

[Zod OpenAPI](https://github.com/samchungy/zod-openapi) is a TypeScript library that helps developers define OpenAPI schemas as Zod schemas. The stated goal of the project is to cut down on code duplication, and it does a wonderful job of this.

Zod schemas map to OpenAPI schemas well, and the changes required to extract OpenAPI documents from a schema defined in Zod are often small.

Zod OpenAPI is maintained by one of the contributors to an earlier library called [Zod to OpenAPI](https://github.com/asteasolutions/zod-to-openapi). If you already use Zod to OpenAPI, the syntax will be familiar and you should be able to use either library. If you'd like to convert your _Zod to OpenAPI_ code to _Zod OpenAPI_ code, the _Zod OpenAPI_ library provides helpful [documentation for migrating code](https://github.com/samchungy/zod-openapi#migration).

## Step-by-Step Tutorial: From Zod to OpenAPI to an SDK

Now let's walk through the process of generating an OpenAPI schema and SDK for our Burgers and Orders API.

### 1. Create Your Zod Project

If you would like to follow along, start by creating a new directory for your project. We'll call ours `zod-burgers`.

Then, initialize a new npm project and install Zod:

```bash Terminal
mkdir zod-burgers
cd zod-burgers
npm init -y
npm install zod
```

### 2. Install the Zod OpenAPI Library

Use npm to install `zod-openapi`:

```bash Terminal
npm install zod-openapi yaml
```

<ScrollyCoding className="ch-scrollycoding-full-height" fullHeight>
### !!steps 3. Create Your App's First Zod Schema

Save this TypeScript code in a new file called `index.ts`.

```typescript ! index.ts
import { z } from "zod";

const burgerSchema = z.object({
  id: z.number().min(1),
  name: z.string().min(1).max(50),
  description: z.string().max(255).optional(),
});
```

---

### !!steps 4. Extend Zod With OpenAPI

We'll add the `openapi` method to Zod by calling `extendZodWithOpenApi` once. Update `index.ts` to import `extendZodWithOpenApi` from `zod-openapi`, then call `extendZodWithOpenApi`.

```typescript ! index.ts
// !mark(3:4)
import { z } from "zod";

import { extendZodWithOpenApi } from "zod-openapi";
extendZodWithOpenApi(z);

const burgerSchema = z.object({
  id: z.number().min(1),
  name: z.string().min(1).max(50),
  description: z.string().max(255).optional(),
});
```

---

### !!steps 5. Register and Generate a Component Schema

Next, we'll use the new `openapi` method provided by `extendZodWithOpenApi` to register an OpenAPI schema for the `burgerSchema`. Edit `index.ts` and add `.openapi({ref: "Burger"}` to the `burgerSchema` schema object.

We'll also add an OpenAPI generator, `OpenApiGeneratorV31`, and log the generated component to the console as YAML.

```typescript ! index.ts
// !mark(12)
import { z } from "zod";

import { extendZodWithOpenApi } from "zod-openapi";
extendZodWithOpenApi(z);

const burgerSchema = z.object({
  id: z.number().min(1),
  name: z.string().min(1).max(50),
  description: z.string().max(255).optional(),
});

burgerSchema.openapi({ ref: "Burger" });
```

---

### !!steps 6. Add Metadata to Components

To generate an SDK that offers great developer experience, we recommend adding descriptions and examples to all fields in OpenAPI components.

With Zod OpenAPI, we'll call the `.openapi` method on each field, and add an example and description to each field.

We'll also add a description to the `Burger` component itself.

{/* Speakeasy will generate documentation and usage examples based on the descriptions and examples we added, but first, we'll need to generate an OpenAPI schema. */}

Edit `index.ts` and edit `burgerSchema` to add OpenAPI metadata.

```typescript ! index.ts
// !mark(7:19,22:23)
import { z } from "zod";

import { extendZodWithOpenApi } from "zod-openapi";
extendZodWithOpenApi(z);

const burgerSchema = z.object({
  id: z.number().min(1).openapi({
    description: "The unique identifier of the burger.",
    example: 1,
  }),
  name: z.string().min(1).max(50).openapi({
    description: "The name of the burger.",
    example: "Veggie Burger",
  }),
  description: z.string().max(255).optional().openapi({
    description: "The description of the burger.",
    example: "A delicious bean burger with avocado.",
  }),
});

burgerSchema.openapi({
  ref: "Burger",
  description: "A burger served at the restaurant.",
});
```

---

### !!steps 7. Prepare to Generate an OpenAPI Document

Now that we know how to register components with metadata for our OpenAPI schema, let's generate a complete schema document.

Import `yaml` and `createDocument`.

```typescript ! index.ts
// !mark(1,7)
import * as yaml from "yaml";

import { z } from "zod";

import {
  extendZodWithOpenApi,
  createDocument
} from "zod-openapi";
extendZodWithOpenApi(z);

const burgerSchema = z.object({
  id: z.number().min(1).openapi({
    description: "The unique identifier of the burger.",
    example: 1,
  }),
  name: z.string().min(1).max(50).openapi({
    description: "The name of the burger.",
    example: "Veggie Burger",
  }),
  description: z.string().max(255).optional().openapi({
    description: "The description of the burger.",
    example: "A delicious bean burger with avocado.",
  }),
});

burgerSchema.openapi({
  ref: "Burger",
  description: "A burger served at the restaurant.",
});
```

---

### !!steps 8. Generate an OpenAPI Document

We'll use the `createDocument` method to generate an OpenAPI document. We'll pass in the `burgerSchema` and a title for the document.

```typescript ! index.ts
// !mark(31:49,51)
import * as yaml from "yaml";

import { z } from "zod";

import {
  extendZodWithOpenApi,
  createDocument
} from "zod-openapi";
extendZodWithOpenApi(z);

const burgerSchema = z.object({
  id: z.number().min(1).openapi({
    description: "The unique identifier of the burger.",
    example: 1,
  }),
  name: z.string().min(1).max(50).openapi({
    description: "The name of the burger.",
    example: "Veggie Burger",
  }),
  description: z.string().max(255).optional().openapi({
    description: "The description of the burger.",
    example: "A delicious bean burger with avocado.",
  }),
});

burgerSchema.openapi({
  ref: "Burger",
  description: "A burger served at the restaurant.",
});

const document = createDocument({
  openapi: "3.1.0",
  info: {
    title: "Burger Restaurant API",
    description: "An API for managing burgers at a restaurant.",
    version: "1.0.0",
  },
  servers: [
    {
      url: "https://example.com",
      description: "The production server.",
    },
  ],
  components: {
    schemas: {
      burgerSchema,
    },
  },
});

console.log(yaml.stringify(document));
```

---

### !!steps 9. Run the Code

Run the code in the terminal:

```yaml !! Output
openapi: 3.1.0
info:
  title: Burger Restaurant API
  description: An API for managing burgers at a restaurant.
  version: 1.0.0
servers:
  - url: https://example.com
    description: The production server.
components:
  schemas:
    Burger:
      type: object
      properties:
        id:
          type: number
          minimum: 1
          description: The unique identifier of the burger.
          example: 1
        name:
          type: string
          minLength: 1
          maxLength: 50
          description: The name of the burger.
          example: Veggie Burger
        description:
          type: string
          maxLength: 255
          description: The description of the burger.
          example: A delicious bean burger with avocado.
      required:
        - id
        - name
      description: A burger served at the restaurant.
```

```bash Terminal
npx ts-node index.ts
```

---

### !!steps 10. Add a Burger ID Schema

To make the burger ID available to other schemas, we'll define a burger ID schema. We'll also use this schema to define a path parameter for the burger ID later on.

Let's create the burger ID schema now.

```typescript ! index.ts
// !mark(11:22)
import * as yaml from "yaml";

import { z } from "zod";

import {
  extendZodWithOpenApi,
  createDocument
} from "zod-openapi";
extendZodWithOpenApi(z);

const BurgerIdSchema = z
  .number()
  .min(1)
  .openapi({
    ref: "BurgerId",
    description: "The unique identifier of the burger.",
    example: 1,
    param: {
      in: "path",
      name: "id",
    },
  });

const burgerSchema = z.object({
  id: BurgerIdSchema,
  name: z.string().min(1).max(50).openapi({
    description: "The name of the burger.",
    example: "Veggie Burger",
  }),
  description: z.string().max(255).optional().openapi({
    description: "The description of the burger.",
    example: "A delicious bean burger with avocado.",
  }),
});

burgerSchema.openapi({
  ref: "Burger",
  description: "A burger served at the restaurant.",
});

const document = createDocument({
  openapi: "3.1.0",
  info: {
    title: "Burger Restaurant API",
    description: "An API for managing burgers at a restaurant.",
    version: "1.0.0",
  },
  servers: [
    {
      url: "https://example.com",
      description: "The production server.",
    },
  ],
  components: {
    schemas: {
      burgerSchema,
    },
  },
});

console.log(yaml.stringify(document));
```

---

### !!steps 11. Replace the Burger ID Field With a Reference

We'll replace the burger ID field with a reference to the burger ID schema.

```typescript ! index.ts
// !mark(25,11:20)
import * as yaml from "yaml";

import { z } from "zod";

import {
  extendZodWithOpenApi,
  createDocument
} from "zod-openapi";
extendZodWithOpenApi(z);

const BurgerIdSchema = z
  .number()
  .min(1)
  .openapi({
    ref: "BurgerId",
    description: "The unique identifier of the burger.",
    example: 1,
    param: {
      in: "path",
      name: "id",
    },
  });

const burgerSchema = z.object({
  id: BurgerIdSchema,
  name: z.string().min(1).max(50).openapi({
    description: "The name of the burger.",
    example: "Veggie Burger",
  }),
  description: z.string().max(255).optional().openapi({
    description: "The description of the burger.",
    example: "A delicious bean burger with avocado.",
  }),
});

burgerSchema.openapi({
  ref: "Burger",
  description: "A burger served at the restaurant.",
});

const document = createDocument({
  openapi: "3.1.0",
  info: {
    title: "Burger Restaurant API",
    description: "An API for managing burgers at a restaurant.",
    version: "1.0.0",
  },
  servers: [
    {
      url: "https://example.com",
      description: "The production server.",
    },
  ],
  components: {
    schemas: {
      burgerSchema,
    },
  },
});

console.log(yaml.stringify(document));
```

---

### !!steps 12. Add a Schema for Creating Burgers

We'll add a schema for creating burgers that doesn't include an ID. We'll use this schema to define the request body for the create burger path.

```typescript ! index.ts
// !mark(41:44)
import * as yaml from "yaml";

import { z } from "zod";

import {
  extendZodWithOpenApi,
  createDocument
} from "zod-openapi";
extendZodWithOpenApi(z);

const BurgerIdSchema = z
  .number()
  .min(1)
  .openapi({
    ref: "BurgerId",
    description: "The unique identifier of the burger.",
    example: 1,
    param: {
      in: "path",
      name: "id",
    },
  });

const burgerSchema = z.object({
  id: BurgerIdSchema,
  name: z.string().min(1).max(50).openapi({
    description: "The name of the burger.",
    example: "Veggie Burger",
  }),
  description: z.string().max(255).optional().openapi({
    description: "The description of the burger.",
    example: "A delicious bean burger with avocado.",
  }),
});

burgerSchema.openapi({
  ref: "Burger",
  description: "A burger served at the restaurant.",
});

const burgerCreateSchema = burgerSchema.omit({ id: true }).openapi({
  ref: "BurgerCreate",
  description: "A burger to create.",
});

const document = createDocument({
  openapi: "3.1.0",
  info: {
    title: "Burger Restaurant API",
    description: "An API for managing burgers at a restaurant.",
    version: "1.0.0",
  },
  servers: [
    {
      url: "https://example.com",
      description: "The production server.",
    },
  ],
  components: {
    schemas: {
      burgerSchema,
    },
  },
});

console.log(yaml.stringify(document));
```

---

### !!steps 13. Add Paths

Paths define the endpoints of your API. For our burger restaurant, we might define endpoints for creating, reading, updating, and deleting burgers and orders.

To register paths and webhooks, we'll define paths as objects of type `ZodOpenApiOperationObject`, then add our paths and webhooks to the document definition.

Start by importing `ZodOpenApiOperationObject` from `zod-openapi`.

```typescript ! index.ts
// !mark(7)
import * as yaml from "yaml";

import { z } from "zod";

import {
  extendZodWithOpenApi,
  ZodOpenApiOperationObject,
  createDocument
} from "zod-openapi";
extendZodWithOpenApi(z);

const BurgerIdSchema = z
  .number()
  .min(1)
  .openapi({
    ref: "BurgerId",
    description: "The unique identifier of the burger.",
    example: 1,
    param: {
      in: "path",
      name: "id",
    },
  });

const burgerSchema = z.object({
  id: BurgerIdSchema,
  name: z.string().min(1).max(50).openapi({
    description: "The name of the burger.",
    example: "Veggie Burger",
  }),
  description: z.string().max(255).optional().openapi({
    description: "The description of the burger.",
    example: "A delicious bean burger with avocado.",
  }),
});

burgerSchema.openapi({
  ref: "Burger",
  description: "A burger served at the restaurant.",
});

const burgerCreateSchema = burgerSchema.omit({ id: true }).openapi({
  ref: "BurgerCreate",
  description: "A burger to create.",
});

const document = createDocument({
  openapi: "3.1.0",
  info: {
    title: "Burger Restaurant API",
    description: "An API for managing burgers at a restaurant.",
    version: "1.0.0",
  },
  servers: [
    {
      url: "https://example.com",
      description: "The production server.",
    },
  ],
  components: {
    schemas: {
      burgerSchema,
    },
  },
});

console.log(yaml.stringify(document));
```

---

### !!steps 14. Add a Create Burger Path

We'll add a path for creating a new burger. We'll use the `ZodOpenApiOperationObject` type to define the path.

```typescript ! index.ts
// !mark(47:69)
import * as yaml from "yaml";

import { z } from "zod";

import {
  extendZodWithOpenApi,
  ZodOpenApiOperationObject,
  createDocument
} from "zod-openapi";
extendZodWithOpenApi(z);

const BurgerIdSchema = z
  .number()
  .min(1)
  .openapi({
    ref: "BurgerId",
    description: "The unique identifier of the burger.",
    example: 1,
    param: {
      in: "path",
      name: "id",
    },
  });

const burgerSchema = z.object({
  id: BurgerIdSchema,
  name: z.string().min(1).max(50).openapi({
    description: "The name of the burger.",
    example: "Veggie Burger",
  }),
  description: z.string().max(255).optional().openapi({
    description: "The description of the burger.",
    example: "A delicious bean burger with avocado.",
  }),
});

burgerSchema.openapi({
  ref: "Burger",
  description: "A burger served at the restaurant.",
});

const burgerCreateSchema = burgerSchema.omit({ id: true }).openapi({
  ref: "BurgerCreate",
  description: "A burger to create.",
});

const createBurger: ZodOpenApiOperationObject = {
  operationId: "createBurger",
  summary: "Create a new burger",
  description: "Creates a new burger in the database.",
  requestBody: {
    description: "The burger to create.",
    content: {
      "application/json": {
        schema: burgerCreateSchema,
      },
    },
  },
  responses: {
    "201": {
      description: "The burger was created successfully.",
      content: {
        "application/json": {
          schema: burgerSchema,
        },
      },
    },
  },
};

const document = createDocument({
  openapi: "3.1.0",
  info: {
    title: "Burger Restaurant API",
    description: "An API for managing burgers at a restaurant.",
    version: "1.0.0",
  },
  servers: [
    {
      url: "https://example.com",
      description: "The production server.",
    },
  ],
  components: {
    schemas: {
      burgerSchema,
    },
  },
});

console.log(yaml.stringify(document));
```

---

### !!steps 15. Add a Read Burger Path

We'll add a path for fetching a burger by ID. We'll use the `ZodOpenApiOperationObject` type to define the path.

```typescript ! index.ts
// !mark(71:88)
import * as yaml from "yaml";

import { z } from "zod";

import {
  extendZodWithOpenApi,
  ZodOpenApiOperationObject,
  createDocument
} from "zod-openapi";
extendZodWithOpenApi(z);

const BurgerIdSchema = z
  .number()
  .min(1)
  .openapi({
    ref: "BurgerId",
    description: "The unique identifier of the burger.",
    example: 1,
    param: {
      in: "path",
      name: "id",
    },
  });

const burgerSchema = z.object({
  id: BurgerIdSchema,
  name: z.string().min(1).max(50).openapi({
    description: "The name of the burger.",
    example: "Veggie Burger",
  }),
  description: z.string().max(255).optional().openapi({
    description: "The description of the burger.",
    example: "A delicious bean burger with avocado.",
  }),
});

burgerSchema.openapi({
  ref: "Burger",
  description: "A burger served at the restaurant.",
});

const burgerCreateSchema = burgerSchema.omit({ id: true }).openapi({
  ref: "BurgerCreate",
  description: "A burger to create.",
});

const createBurger: ZodOpenApiOperationObject = {
  operationId: "createBurger",
  summary: "Create a new burger",
  description: "Creates a new burger in the database.",
  requestBody: {
    description: "The burger to create.",
    content: {
      "application/json": {
        schema: burgerCreateSchema,
      },
    },
  },
  responses: {
    "201": {
      description: "The burger was created successfully.",
      content: {
        "application/json": {
          schema: burgerSchema,
        },
      },
    },
  },
};

const getBurger: ZodOpenApiOperationObject = {
  operationId: "getBurger",
  summary: "Get a burger",
  description: "Gets a burger from the database.",
  requestParams: {
    path: z.object({ id: BurgerIdSchema }),
  },
  responses: {
    "200": {
      description: "The burger was retrieved successfully.",
      content: {
        "application/json": {
          schema: burgerSchema,
        },
      },
    },
  },
};

const document = createDocument({
  openapi: "3.1.0",
  info: {
    title: "Burger Restaurant API",
    description: "An API for managing burgers at a restaurant.",
    version: "1.0.0",
  },
  servers: [
    {
      url: "https://example.com",
      description: "The production server.",
    },
  ],
  components: {
    schemas: {
      burgerSchema,
    },
  },
});

console.log(yaml.stringify(document));
```

---

### !!steps 16. Add a Webhook That Runs When a Burger Is Created

We'll add a webhook that runs when a burger is created. We'll use the `ZodOpenApiOperationObject` type to define the webhook.

```typescript ! index.ts
// !mark(90:107)
import * as yaml from "yaml";

import { z } from "zod";

import {
  extendZodWithOpenApi,
  ZodOpenApiOperationObject,
  createDocument
} from "zod-openapi";
extendZodWithOpenApi(z);

const BurgerIdSchema = z
  .number()
  .min(1)
  .openapi({
    ref: "BurgerId",
    description: "The unique identifier of the burger.",
    example: 1,
    param: {
      in: "path",
      name: "id",
    },
  });

const burgerSchema = z.object({
  id: BurgerIdSchema,
  name: z.string().min(1).max(50).openapi({
    description: "The name of the burger.",
    example: "Veggie Burger",
  }),
  description: z.string().max(255).optional().openapi({
    description: "The description of the burger.",
    example: "A delicious bean burger with avocado.",
  }),
});

burgerSchema.openapi({
  ref: "Burger",
  description: "A burger served at the restaurant.",
});

const burgerCreateSchema = burgerSchema.omit({ id: true }).openapi({
  ref: "BurgerCreate",
  description: "A burger to create.",
});

const createBurger: ZodOpenApiOperationObject = {
  operationId: "createBurger",
  summary: "Create a new burger",
  description: "Creates a new burger in the database.",
  requestBody: {
    description: "The burger to create.",
    content: {
      "application/json": {
        schema: burgerCreateSchema,
      },
    },
  },
  responses: {
    "201": {
      description: "The burger was created successfully.",
      content: {
        "application/json": {
          schema: burgerSchema,
        },
      },
    },
  },
};

const getBurger: ZodOpenApiOperationObject = {
  operationId: "getBurger",
  summary: "Get a burger",
  description: "Gets a burger from the database.",
  requestParams: {
    path: z.object({ id: BurgerIdSchema }),
  },
  responses: {
    "200": {
      description: "The burger was retrieved successfully.",
      content: {
        "application/json": {
          schema: burgerSchema,
        },
      },
    },
  },
};

const createBurgerWebhook: ZodOpenApiOperationObject = {
  operationId: "createBurgerWebhook",
  summary: "New burger webhook",
  description: "A webhook that is called when a new burger is created.",
  requestBody: {
    description: "The burger that was created.",
    content: {
      "application/json": {
        schema: burgerSchema,
      },
    },
  },
  responses: {
    "200": {
      description: "The webhook was processed successfully.",
    },
  },
};

const document = createDocument({
  openapi: "3.1.0",
  info: {
    title: "Burger Restaurant API",
    description: "An API for managing burgers at a restaurant.",
    version: "1.0.0",
  },
  servers: [
    {
      url: "https://example.com",
      description: "The production server.",
    },
  ],
  components: {
    schemas: {
      burgerSchema,
    },
  },
});

console.log(yaml.stringify(document));
```

---

### !!steps 17. Register Paths and Webhooks

We'll register our paths and webhooks by adding them to the document definition.

```typescript ! index.ts
// !mark(116:128)
import * as yaml from "yaml";

import { z } from "zod";

import {
  extendZodWithOpenApi,
  ZodOpenApiOperationObject,
  createDocument
} from "zod-openapi";
extendZodWithOpenApi(z);

const BurgerIdSchema = z
  .number()
  .min(1)
  .openapi({
    ref: "BurgerId",
    description: "The unique identifier of the burger.",
    example: 1,
    param: {
      in: "path",
      name: "id",
    },
  });

const burgerSchema = z.object({
  id: BurgerIdSchema,
  name: z.string().min(1).max(50).openapi({
    description: "The name of the burger.",
    example: "Veggie Burger",
  }),
  description: z.string().max(255).optional().openapi({
    description: "The description of the burger.",
    example: "A delicious bean burger with avocado.",
  }),
});

burgerSchema.openapi({
  ref: "Burger",
  description: "A burger served at the restaurant.",
});

const burgerCreateSchema = burgerSchema.omit({ id: true }).openapi({
  ref: "BurgerCreate",
  description: "A burger to create.",
});

const createBurger: ZodOpenApiOperationObject = {
  operationId: "createBurger",
  summary: "Create a new burger",
  description: "Creates a new burger in the database.",
  requestBody: {
    description: "The burger to create.",
    content: {
      "application/json": {
        schema: burgerCreateSchema,
      },
    },
  },
  responses: {
    "201": {
      description: "The burger was created successfully.",
      content: {
        "application/json": {
          schema: burgerSchema,
        },
      },
    },
  },
};

const getBurger: ZodOpenApiOperationObject = {
  operationId: "getBurger",
  summary: "Get a burger",
  description: "Gets a burger from the database.",
  requestParams: {
    path: z.object({ id: BurgerIdSchema }),
  },
  responses: {
    "200": {
      description: "The burger was retrieved successfully.",
      content: {
        "application/json": {
          schema: burgerSchema,
        },
      },
    },
  },
};

const createBurgerWebhook: ZodOpenApiOperationObject = {
  operationId: "createBurgerWebhook",
  summary: "New burger webhook",
  description: "A webhook that is called when a new burger is created.",
  requestBody: {
    description: "The burger that was created.",
    content: {
      "application/json": {
        schema: burgerSchema,
      },
    },
  },
  responses: {
    "200": {
      description: "The webhook was processed successfully.",
    },
  },
};

const document = createDocument({
  openapi: "3.1.0",
  info: {
    title: "Burger Restaurant API",
    description: "An API for managing burgers at a restaurant.",
    version: "1.0.0",
  },
  paths: {
    "/burgers": {
      post: createBurger,
    },
    "/burgers/{id}": {
      get: getBurger,
    },
  },
  webhooks: {
    "/burgers": {
      post: createBurgerWebhook,
    },
  },
  servers: [
    {
      url: "https://example.com",
      description: "The production server.",
    },
  ],
  components: {
    schemas: {
      burgerSchema,
    },
  },
});

console.log(yaml.stringify(document));
```

---

### !!steps 18. Run the Code

Run the code in the terminal:

```yaml !! Output
openapi: 3.1.0
info:
  title: Burger Restaurant API
  description: An API for managing burgers at a restaurant.
  version: 1.0.0
servers:
  - url: https://example.com
    description: The production server.
paths:
  /burgers:
    post:
      operationId: createBurger
      summary: Create a new burger
      description: Creates a new burger in the database.
      requestBody:
        description: The burger to create.
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/BurgerCreate"
      responses:
        "201":
          description: The burger was created successfully.
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/burgerSchema"
  "/burgers/{id}":
    get:
      operationId: getBurger
      summary: Get a burger
      description: Gets a burger from the database.
      parameters:
        - in: path
          name: id
          schema:
            $ref: "#/components/schemas/BurgerId"
          required: true
      responses:
        "200":
          description: The burger was retrieved successfully.
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/burgerSchema"
webhooks:
  /burgers:
    post:
      operationId: createBurgerWebhook
      summary: New burger webhook
      description: A webhook that is called when a new burger is created.
      requestBody:
        description: The burger that was created.
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/burgerSchema"
      responses:
        "200":
          description: The webhook was processed successfully.
components:
  schemas:
    burgerSchema:
      type: object
      properties:
        id:
          $ref: "#/components/schemas/BurgerId"
        name:
          type: string
          minLength: 1
          maxLength: 50
          description: The name of the burger.
          example: Veggie Burger
        description:
          type: string
          maxLength: 255
          description: The description of the burger.
          example: A delicious bean burger with avocado.
      required:
        - id
        - name
    BurgerCreate:
      type: object
      properties:
        name:
          type: string
          minLength: 1
          maxLength: 50
          description: The name of the burger.
          example: Veggie Burger
        description:
          type: string
          maxLength: 255
          description: The description of the burger.
          example: A delicious bean burger with avocado.
      required:
        - name
      description: A burger to create.
    BurgerId:
      type: number
      minimum: 1
      description: The unique identifier of the burger.
      example: 1
```

```bash Terminal
npx ts-node index.ts
```

</ScrollyCoding>

### 19. Generate an SDK

With our OpenAPI schema complete, we can now generate an SDK using the Speakeasy SDK generator. We'll follow the instructions in the Speakeasy documentation to [generate SDKs for various platforms](/docs/create-client-sdks).

First, write your YAML schema to a new file called `openapi.yaml`. Run the following in the terminal:

```bash Terminal
npx ts-node index.ts > openapi.yaml
```

Then, log in to your Speakeasy account or use the [Speakeasy CLI](/docs/speakeasy-cli/getting-started/) to generate a new SDK.

Here's how to use the CLI. In the terminal, run:

```bash Terminal
speakeasy quickstart
```

Follow the onscreen prompts to provide the necessary configuration details for your new SDK such as the name, schema location and output path. Enter `openapi.yaml` when prompted for the OpenAPI document location and select Python when prompted for which language you would like to generate.

## Example Zod Schema and SDK Generator

The source code for our complete example is available in the [`zod-burgers`](https://github.com/speakeasy-api/speakeasy-zod-openapi) repository.

The repository contains a pre-generated Python SDK with instructions on how to generate more SDKs.

You can clone this repository to test how changes to the Zod schema definition result in changes to the generated SDK.

## Summary

In this tutorial, we learned how to generate OpenAPI schemas from Zod and create client SDKs with Speakeasy.

By following these steps, you can ensure that your API is well-documented, easy to use, and offers a great developer experience.


 This is the content for the doc openapi/index.mdx 

 ---
title: OpenAPI Reference
description: Documentation of the OpenAPI Specification
---

import { ScrollyCoding } from "~/components/codehike/Scrollycoding";
import { Callout, Separator } from "~/components";
import { GenerateSDK } from "~/features/docs/home/recipes/ProductGrid/GenerateSDK";
import { IconGrid } from "~/features/shared/recipes/IconGrid/IconGrid";
import { FrameworkGuidesData } from "~/data/shared/frameworkGuides";
import {
  CardsSection,
  Hero,
  QuickLinks,
} from "~/features/openapi";
import { Faq } from "~/features/pricing/recipes";

<Callout title="Contribute to this page" variant="success-gradient" fullWidth>
  This documentation is Open source. If you have any feedback, suggestions, or
  want to contribute, check out our [GitHub
  repo](https://github.com/speakeasy-api/openapi-reference-documentation).
</Callout>

<Hero
  title="OpenAPI Hub"
  description="The all in one resource for understanding the OpenAPI Specification."
/>

<IconGrid {...FrameworkGuidesData} buttonText="See all" buttonUrl="/openapi/frameworks" />

<Separator className="opacity-10" />

### OpenAPI Overview

<ScrollyCoding>

## !!steps \`openapi`

The version of the OpenAPI Specification that the document conforms to, should be one of the [supported versions](https://github.com/OAI/OpenAPI-Specification/tree/main/versions).

**Note**: Speakeasy tooling currently only supports OpenAPI Specification versions 3.0.x and 3.1.x.

```yaml ! openapi.yaml
# !focus(1)
openapi: 3.1.0
info:
  title: The Speakeasy Bar
  version: 1.0.0
servers:
  - url: https://speakeasy.bar
    description: The production server
security:
  - apiKey: []
tags:
  - name: drinks
    description: Operations related to drinks
paths:
  /drinks:
    get:
      tags:
        - drinks
      operationId: listDrinks
      summary: Get a list of drinks
      responses:
        "200":
          description: A list of drinks
          content:
            application/json:
              schema:
                type: array
                items:
                  $ref: "#/components/schemas/Drink"
components:
  schemas:
    Drink:
      type: object
      title: Drink
      properties:
        name:
          type: string
        price:
          type: number
  securitySchemes:
    apiKey:
      type: apiKey
      name: Authorization
      in: header
```

---

## !!steps \`info`

Contains information about the document including fields like `title`, `version`, and `description` that help to identify the purpose and owner of the document.

```yaml ! openapi.yaml
# !focus(2:4)
```

---

## !!steps \`servers`

Contains an optional list of servers the API is available on. If not provided, the default URL is assumed to be `/`, a path relative to where the OpenAPI document is hosted.

```yaml ! openapi.yaml
# !focus(5:7)
```

---

## !!steps \`security`

Contains an optional list of security requirements that apply to all operations in the API. If not provided, the default security requirements are assumed to be `[]`, an empty array.

```yaml ! openapi.yaml
# !focus(8:9)
```

---

## !!steps \`tags`

Contains an optional list of tags that are generally used to group or categorize a set of [Operations](/openapi/paths/operations).

```yaml ! openapi.yaml
# !focus(10:12,16:17)
```

---

## !!steps \`paths`

Contains the paths and operations available within the API.

```yaml ! openapi.yaml
# !focus(13:28)
```

---

## !!steps \`components`

Contains an optional list of reusable schemas that can be referenced from other parts of the document. This improves the readability and maintainability of the document by allowing common schemas to be defined once and reused in multiple places.

```yaml ! openapi.yaml
# !focus(29:42)
```

---

</ScrollyCoding>

<Separator className="opacity-10" />

<CardsSection
  title="The OpenAPI Ecosystem"
  description="Understand the different specifications that make up the OpenAPI ecosystem"
  items={[
    {
      icon: "code",
      title: "OpenAPI Overlays",
      description: "Describe customization to your OpenAPI",
      link: { href: "/openapi/overlays", text: "Read docs" },
    },
    {
      icon: "terminal",
      title: "OpenAPI 3.1",
      description: "Describe your API interface",
      link: { href: "/openapi/info", text: "Read docs" },
    },
    {
      icon: "diagram",
      title: "Arazzo Workflows",
      description: "Describe your API workflows",
      link: { href: "/openapi/arazzo", text: "Read docs" },
    },
  ]}
/>

<Faq
  className="_pb-20"
  title="FAQ"
  items={[
    {
      question: "What's the difference between OpenAPI & Swagger?",
      answer:
        "Swagger refers to a set of commonly used tools for working with the OpenAPI Specification, whereas OpenAPI is the specification itself. People commonly say Swagger when they mean OpenAPI.",
    },
    {
      question: "How different are OpenAPI 3.0 and 3.1?",
      answer:
        "The biggest difference is that OpenAPI 3.1 introduces support for JSON Schema draft 2020-12. The other big change was the inclusion of webhooks. Otherwise they are very similar. This guide is based on 3.1. You should use 3.1 if you're starting a new project.",
    },
    {
      question: "Should I handwrite or generate OpenAPI?",
      answer:
        "That's a contentious topic, and there's no right answer. Typically startups with small technical teams generate their OpenAPI document from code. At larger companies where API design includes non-technical staff, handwriting the document is typically preferred. Find something that works for your team and don't listen to the noise.",
    },
  ]}
/>


 This is the content for the doc openapi/info.md 

 # Info Object in OpenAPI

The document's `info` object contains information about the document, including fields like `title`, `version`, and `description` that help to identify the purpose and owner of the document.

Example:

```yaml
openapi: 3.1.0
info:
  title: The Speakeasy Bar
  version: 1.0.0
  summary: A bar that serves drinks
  description: A secret underground bar that serves drinks to those in the know.
  contact:
    name: Speakeasy Support
    url: https://support.speakeasy.bar
    email: support@speakeasy.bar
  license:
    name: Apache 2.0
    url: https://www.apache.org/licenses/LICENSE-2.0.html
  termsOfService: https://speakeasy.bar/terms
```

| Field            |               Type                | Required | Description                                                                                                                                                                       |
| ---------------- | :-------------------------------: | :------: | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `title`          |              String               |    ✅    | A name for the API contained within the document.                                                                                                                                 |
| `version`        |              String               |    ✅    | The version of this OpenAPI document, _not_ the version of the API or the OpenAPI Specification used. This is recommended to be a [Semantic Version](https://semver.org/).        |
| `summary`        |              String               |          | **(Available in OpenAPI 3.1.x ONLY)**<br />A short sentence summarizing the API contained with the document.                                                                      |
| `description`    |              String               |          | A longer description of the API contained within the document. This may contain [CommonMark syntax](https://spec.commonmark.org/) to provide a rich description.                  |
| `contact`        | [Contact Object](#contact-object) |          | Contact information for the maintainer of the API.<br /><br /> **Note:** Currently not supported by Speakeasy tooling.                                                            |
| `license`        | [License Object](#license-object) |          | The license the API is made available under.                                                                                                                                      |
| `termsOfService` |              String               |          | A URL to the terms of service for the API.                                                                                                                                        |
| `x-*`            |     [Extensions](/openapi/extensions)     |          | Any number of extension fields can be added to the info object that can be used by tooling and vendors to add additional metadata and functionality to the OpenAPI Specification. |

The above order of fields is recommended (but is not required by the OpenAPI specification) as it puts the most important information first and allows the reader to get a quick overview of the document and API.

## Contact Object in OpenAPI

Contact information for the maintainer of the API.

| Field   |           Type            | Required | Description                                                                                                |
| ------- | :-----------------------: | :------: | ---------------------------------------------------------------------------------------------------------- |
| `name`  |          String           |          | The name of a contact that could be approached, for example, for support.                                  |
| `url`   |          String           |          | A URL to a website or similar providing contact information.                                               |
| `email` |          String           |          | An email address for the contact.                                                                          |
| `x-*`   | [Extensions](/openapi/extensions) |          | Any number of extension fields can be added to the contact object that can be used by tooling and vendors. |

## License Object in OpenAPI

The license the API is made available under.

| Field        |           Type            |      Required      | Description                                                                                                                                   |
| ------------ | :-----------------------: | :----------------: | --------------------------------------------------------------------------------------------------------------------------------------------- |
| `name`       |          String           | ✅ | The name of the license.                                                                                                                      |
| `identifier` |          String           |  | **(Available in OpenAPI 3.1.x ONLY)**<br/>An [SPDX identifier](https://spdx.org/licenses/) for the license. Provided only if `url` isn't set. |
| `url`        |          String           |  | A URL to the license information. Provided only if `identifier` isn't set.                                                                    |
| `x-*`        | [Extensions](/openapi/extensions) |  | Any number of extension fields can be added to the license object that can be used by tooling and vendors.                                    |


 This is the content for the doc openapi/overlays.mdx 

 import { ScrollyCoding } from "~/components/codehike/Scrollycoding";
import { Callout } from "~/components";

# OpenAPI Overlays

Overlays allow us to modify an existing OpenAPI document without directly editing the original document. An overlay is a separate document that contains instructions for updating the original OpenAPI document.

<Callout title="Active Development" variant="warning">
  The [OpenAPI Overlay
  Specification](https://github.com/OAI/Overlay-Specification) has now reached a stable [1.0.0](https://github.com/OAI/Overlay-Specification/releases/tag/1.0.0) release.
  Speakeasy toolchain utilises a homegrown and OSS implementation. Source code is available [here](https://github.com/speakeasy-api/openapi-overlay). Contributions are welcome!
</Callout>

Overlays are useful for:

- Separating concerns between the original API definition and modifications required by different consumers or use cases.
- Avoiding direct modification of the original OpenAPI document, which may be managed by a separate team or process.
- Applying a set of common modifications to multiple OpenAPI documents.

## Overlay Document Structure in OpenAPI

An Overlay document is a separate document from the OpenAPI document it modifies. It contains an ordered list of [Action Objects](#action-object) that describe the modifications to be made to the original OpenAPI document.

<ScrollyCoding>
## !!steps `overlay`
| Field Name | Type     | Required  |
|------------|----------|-----------|
| `overlay`  | String   | ✅ |

The version of the Overlay Specification that the document uses. The value must be a supported [version number](#overlay-specification-versions)

```yaml ! overlay.yaml
# !focus(1)
overlay: 1.0.0
info:
  title: Overlay to fix the Speakeasy bar
  version: 0.0.1
actions:
  - target: "$.tags"
    description: Add a Snacks tag to the global tags list
    update:
      - name: Snacks
        description: All methods related to serving snacks
  - target: "$.paths['/dinner']"
    description: Remove all paths related to serving dinner
    remove: true
```

---

## !!steps `info`

| Field Name | Type                                | Required |
| ---------- | ----------------------------------- | -------- |
| `info`     | [Info Object](#overlay-info-object) | ✅       |

Provides metadata about the Overlay document.

```yaml ! overlay.yaml
# !focus(2:4)
overlay: 1.0.0
info:
  title: Overlay to fix the Speakeasy bar
  version: 0.0.1
actions:
  - target: "$.tags"
    description: Add a Snacks tag to the global tags list
    update:
      - name: Snacks
        description: All methods related to serving snacks
  - target: "$.paths['/dinner']"
    description: Remove all paths related to serving dinner
    remove: true
```

---

## !!steps `title`

| Field Name | Type   | Required |
| ---------- | ------ | -------- |
| `title`    | String | ✅       |

A human-readable title describing the purpose of the Overlay document.

```yaml ! overlay.yaml
# !focus(3)
```

---

## !!steps `version`

| Field Name | Type   | Required |
| ---------- | ------ | -------- |
| `version`  | String | ✅       |

A version identifier indicating the version of the Overlay document.

```yaml ! overlay.yaml
# !focus(4)
```

---

## !!steps `actions`

| Field Name | Type                              | Required |
| ---------- | --------------------------------- | -------- |
| `actions`  | [[Action Object](#action-object)] | ✅       |

An ordered list of [Action Objects](#action-object) to be applied to the original OpenAPI document. The list must contain at least one [Action Object](#action-object).

```yaml ! overlay.yaml
# !focus(5:13)
```

---

## !!steps `target`

| Field Name | Type   | Required |
| ---------- | ------ | -------- |
| `version`  | String | ✅       |

A [JSONPath](https://datatracker.ietf.org/wg/jsonpath/documents/) expression that specifies the location in the original OpenAPI document where the change should be made. See [Action Targets](#action-targets).

```yaml ! overlay.yaml
# !focus(6)
```

---

## !!steps `description`

| Field Name | Type   | Required |
| ---------- | ------ | -------- |
| `version`  | String |          |

A description of the action. This may contain [CommonMark syntax](https://spec.commonmark.org/) to provide a rich description.

```yaml ! overlay.yaml
# !focus(7)
```

---

## !!steps `update`

| Field Name | Type   | Required |
| ---------- | ------ | -------- |
| `version`  | String |          |

An object containing the properties and values to be merged with the objects referenced by the `target`. This field has no effect if the `remove` field is `true`.

```yaml ! overlay.yaml
# !focus(8:10)
```

---

## !!steps `remove`

| Field Name | Type   | Required |
| ---------- | ------ | -------- |
| `version`  | String |          |

If `true`, the objects referenced by the `target` are removed from the original document. If `false` or not provided, the objects are not removed. This field takes precedence over the `update` field.

```yaml ! overlay.yaml
# !focus(13)
```

---

</ScrollyCoding>

| Field Name | Type                                | Required | Description                                                                                                                                                                                      |
| ---------- | ----------------------------------- | -------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| `overlay`  | String                              | ✅       | The version of the Overlay Specification that the document uses. The value must be a supported [version number](#overlay-specification-versions).                                                |
| `info`     | [Info Object](#overlay-info-object) | ✅       | Provides metadata about the Overlay document.                                                                                                                                                    |
| `extends`  | String                              |          | A URL to the original OpenAPI document this overlay applies to.                                                                                                                                  |
| `actions`  | [[Action Object](#action-object)]   | ✅       | An ordered list of [Action Objects](#action-object) to be applied to the original OpenAPI document. The list must contain at least one [Action Object](#action-object).                          |
| `x-*`      | [Extensions](#extensions)           |          | Any number of extension fields can be added to the Overlay document that can be used by tooling and vendors. When provided at this level, the extensions generally apply to the entire document. |

The `extends` field is optional. If not provided, it is the responsibility of tooling to determine which OpenAPI documents the overlay should be applied to.

## Overlay Specification Versions

The `overlay` field contains the version number of the Overlay Specification that the document conforms to. Tooling should use this value to interpret the document correctly.

The current version of the Overlay Specification is `1.0.0`, but keep in mind that the specification is still under development.

## Overlay Info Object in OpenAPI

Provides metadata about the Overlay document.

| Field Name | Type   | Required | Description                                                                          |
| ---------- | ------ | -------- | ------------------------------------------------------------------------------------ |
| `title`    | String | ✅       | A human-readable title describing the purpose of the Overlay document.               |
| `version`  | String | ✅       | A version identifier indicating the version of the Overlay document.                 |
| `x-*`      | Any    |          | Any number of extension fields can be added that can be used by tooling and vendors. |

## Action Object in OpenAPI

Each Action Object represents at least one change to be made to the original OpenAPI document at the location specified by the `target` field.

| Field Name    | Type    | Required | Description                                                                                                                                                                                                       |
| ------------- | ------- | -------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `target`      | String  | ✅       | A [JSONPath](https://datatracker.ietf.org/wg/jsonpath/documents/) expression that specifies the location in the original OpenAPI document where the change should be made. See [Action Targets](#action-targets). |
| `description` | String  |          | A description of the action. This may contain [CommonMark syntax](https://spec.commonmark.org/) to provide a rich description.                                                                                    |
| `update`      | Any     |          | An object containing the properties and values to be merged with the objects referenced by the `target`. This field has no effect if the `remove` field is `true`.                                                |
| `remove`      | Boolean |          | If `true`, the objects referenced by the `target` are removed from the original document. If `false` or not provided, the objects are not removed. This field takes precedence over the `update` field.           |
| `x-*`         | Any     |          | Any number of extension fields can be added to the Action Object that can be used by tooling and vendors.                                                                                                         |

## Action Targets in OpenAPI

The `target` field of an [Action Object](#action-object) is a [JSONPath](https://goessner.net/articles/JsonPath/) expression that specifies the locations in the original OpenAPI document where the change should be made.

JSONPath expressions allow you to select and manipulate specific parts of a JSON or YAML document using an intuitive syntax. The expressions are similar to XPath for XML, allowing you to traverse the document tree and select elements based on various criteria.

JSONPath is [implemented differently](https://cburgmer.github.io/json-path-comparison/) across tooling languages and among individual tools. Speakeasy uses [VMware Labs YAML JSONPath](https://github.com/vmware-labs/yaml-jsonpath) to parse JSONPath.

Here are some examples of JSONPath expressions relevant to OpenAPI documents:

| JSONPath Expression                                                                        | Description                                                                 |
| ------------------------------------------------------------------------------------------ | --------------------------------------------------------------------------- |
| `$.info.title`                                                                             | Selects the `title` field of the `info` object.                             |
| `$.servers[0].url`                                                                         | Selects the `url` field of the first server in the `servers` array.         |
| `$.paths['/drinks'].get.parameters`                                                        | Selects the `parameters` of the `get` operation on the `/drinks` path.      |
| `$.paths..parameters[?(@.in=='query')]`                                                    | Selects all query parameters across all paths.                              |
| `$.paths.*[?(@..parameters.*[?(@.in=='query')])]`                                          | Selects all operations that have one or more query parameters.              |
| `$.paths.*[?(@..parameters.*[?(@.in=='query')])]['post','get','put','path','delete'].tags` | Selects tags of specific operations that have one or more query parameters. |
| `$.components.schemas.Drink`                                                               | Selects the `Drink` schema from the `components.schemas` object.            |

When selecting the object to target for different types of updates, consider the following:

| Type of Update                                       | Target Object         |
| ---------------------------------------------------- | --------------------- |
| Updating a primitive value (string, number, boolean) | The containing object |
| Updating an object                                   | The object itself     |
| Updating an array                                    | The array itself      |
| Adding a new property to an object                   | The object itself     |
| Adding a new item to an array                        | The array itself      |
| Removing a property from an object                   | The object itself     |
| Removing an item from an array                       | The array itself      |

For example, to update the `description` field of the `info` object, you would target the `info` object itself:

```yaml
overlay: 1.0.0
info:
  title: Update Speakeasy API description
  version: 1.0.0
actions:
  - target: $.info
    update:
      description: The Speakeasy Bar API is a secret underground bar that serves drinks to those in the know.
```

To remove a specific path, such as `/oldDrinks`, from the `paths` object, you would target that path directly:

```yaml
overlay: 1.0.0
info:
  title: Remove deprecated drinks path
  version: 1.0.0
actions:
  - target: $.paths['/oldDrinks']
    remove: true
```

## Applying an Overlay in OpenAPI

When an overlay is applied, the `update` object is merged with the targeted objects. Any properties present in both the `update` object and the targeted objects will be replaced with the values from the `update` object. New properties from the `update` object will be added to the targeted objects.

The Overlay document is processed in the following order:

1. Tooling locates the original OpenAPI document to modify. This is based on the `extends` field if provided, otherwise determined by the tooling.

2. Each [Action Object](#action-object) is applied to the OpenAPI documents in the order they appear in the `actions` array.

   For each action:

   1. The `target` JSONPath expression is evaluated against the OpenAPI document to locate the objects to modify.

   2. If the `remove` field is `true`, the targeted objects are removed from the OpenAPI document.

   3. If the `remove` field is `false` or not provided and an `update` object is specified, the `update` object is merged with each of the targeted objects.

## OpenAPI Overlay Examples

Here are some examples of overlays that could be applied to the Speakeasy Bar OpenAPI document:

## Updating Info and Servers

This example demonstrates updating the `info` and `servers` objects in the original OpenAPI document.

```yaml
overlay: 1.0.0
info:
  title: Update Speakeasy Bar Info and Servers
  version: 1.0.0
actions:
  - target: $.info
    update:
      description: The Speakeasy Bar API is a secret underground bar that serves drinks to those in the know.
      contact:
        name: Speakeasy Bar Support
        email: support@speakeasy.bar
  - target: $.servers
    update:
      - url: https://staging.speakeasy.bar/v1
        description: Staging server
      - url: https://api.speakeasy.bar/v1
        description: Production server
```

## Adding Tags and Updating Drink Responses

This example demonstrates adding tags to the OpenAPI document and updating response objects for operations related to drinks.

```yaml
overlay: 1.0.0
info:
  title: Add Tags and Update Drink Responses
  version: 1.0.0
actions:
  - target: $.tags
    update:
      - name: Drinks
        description: Operations related to managing drinks
      - name: Orders
        description: Operations related to order processing
  - target: $.paths['/drinks'].get.responses[200].content['application/json'].schema
    update:
      $ref: "#/components/schemas/DrinkList"
  - target: $.paths['/drinks/{drinkId}'].get.responses[200].content['application/json'].schema
    update:
      $ref: "#/components/schemas/Drink"
```

## Adding Query Parameter Tags

This example demonstrates adding a tag to all operations that have query parameters.

```yaml
overlay: 1.0.0
info:
  title: Add Query Parameter Tags
  version: 1.0.0
actions:
  - target: $.paths.*[?(@..parameters.*[?(@.in=='query')])]['post','get','put','path','delete'].tags
    update:
      - hasQueryParameters
```

## Removing Deprecated Drink Operations

This example demonstrates removing operations related to drinks that have been marked as deprecated.

```yaml
overlay: 1.0.0
info:
  title: Remove Deprecated Drink Operations
  version: 1.0.0
actions:
  - target: $.paths['/drinks'].*.deprecated
    remove: true
  - target: $.paths['/drinks/{drinkId}'].*.deprecated
    remove: true
```

<Callout title="Overlay Creation Tool" variant="info">
  Check out <a href="https://overlay.speakeasy.com/" target="_blank" rel="noopener noreferrer">overlay.speakeasy.com</a> to create and edit your overlays visually.
</Callout>


 This is the content for the doc openapi/paths.md 

 # Paths Object in OpenAPI

The `paths` object is a map of [Path Item Objects](/openapi/paths#path-item-object) that describes the available paths and operations for the API.

Each path is a relative path to the servers defined in the [Servers](/openapi/servers) object, either at the document, path, or operation level. For example, if a server is defined as `https://speakeasy.bar/api` and a path is defined as `/drinks`, the full URL to the path would be `https://speakeasy.bar/api/drinks`, where the path is appended to the server URL.

Example:

```yaml
paths:
  /drinks:
    get: ... # operation definition
  /drink:
    get: ... # operation definition
    put: ... # operation definition
    post: ... # operation definition
    delete: ... # operation definition
```

| Field     |                 Type                  | Required | Description                                                                                              |
| --------- | :-----------------------------------: | :------: | -------------------------------------------------------------------------------------------------------- |
| `/{path}` | [Path Item Object](/openapi/paths#path-item-object) |          | A relative path to an individual endpoint, where the path **_must_** begin with a `/`.                   |
| `x-*`     |       [Extensions](/openapi/extensions)       |          | Any number of extension fields can be added to the paths object that can be used by tooling and vendors. |

## Path Item Object in OpenAPI

A Path Item Object describes the operations available on a single path. This is generally a map of HTTP methods to [Operation Objects](/openapi/paths/operations) that describe the operations available.

It is possible to override the [Servers](/openapi/servers) defined at the document level for a specific path by providing a list of [Server Objects](/openapi/servers) at the path level.

It is also possible to provide a list of [Parameters](/openapi/paths/parameters) that are common to all operations defined on the path.

Example:

```yaml
paths:
  /drinks:
    summary: Various operations for browsing and searching drinks
    description:
    servers: # Override the servers defined at the document level and apply to all operations defined on this path
      - url: https://drinks.speakeasy.bar
        description: The drinks server
    parameters: # Define a list of parameters that are common to all operations defined on this path
      - name: type
        in: query
        schema:
          type: string
          enum:
            - cocktail
            - mocktail
            - spirit
            - beer
            - wine
            - cider
    get: ... # operation definition
```

Or:

```yaml
paths:
  /drinks:
    $ref: "#/components/pathItems/drinks" # Reference a Path Item Object defined in the Components Object allowing for reuse in different paths
components:
  pathItems:
    drinks:
      servers:
        - url: https://drinks.speakeasy.bar
          description: The drinks server
      parameters:
        - name: type
          in: query
          schema:
            type: string
            enum:
              - cocktail
              - mocktail
              - spirit
              - beer
              - wine
              - cider
      get: ... # operation definition
```

| Field         |                 Type                  | Required | Description                                                                                                                                                                                |
| ------------- | :-----------------------------------: | :------: | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| `$ref`        |                String                 |          | Allows for referencing a [Path Item Object](/openapi/paths#path-item-object) defined in the [Components Object](/openapi/components) under the `pathItems` field. If used, no other fields should be set. |
| `summary`     |                String                 |          | A short summary of what the path item represents. This may contain [CommonMark syntax](https://spec.commonmark.org/) to provide a rich description.                                        |
| `description` |                String                 |          | A description of the path item. This may contain [CommonMark syntax](https://spec.commonmark.org/) to provide a rich description.                                                          |
| `servers`     |          [Servers](/openapi/servers)          |          | A list of [Server Objects](/openapi/servers) that override the servers defined at the document level. Applies to all operations defined on this path.                                        |
| `parameters`  |       [Parameters](/openapi/paths/parameters)       |          | A list of [Parameter Objects](/openapi/paths/parameters#parameter-object) that are common to all operations defined on this path.                                                                                   |
| `get`         | [Operation Object](/openapi/paths/operations) |          | An operation associated with the [`GET` HTTP method](https://developer.mozilla.org/en-US/docs/Web/HTTP/Methods/GET).                                                                       |
| `put`         | [Operation Object](/openapi/paths/operations) |          | An operation associated with the [`PUT` HTTP method](https://developer.mozilla.org/en-US/docs/Web/HTTP/Methods/PUT).                                                                       |
| `post`        | [Operation Object](/openapi/paths/operations) |          | An operation associated with the [`POST` HTTP method](https://developer.mozilla.org/en-US/docs/Web/HTTP/Methods/POST).                                                                     |
| `delete`      | [Operation Object](/openapi/paths/operations) |          | An operation associated with the [`DELETE` HTTP method](https://developer.mozilla.org/en-US/docs/Web/HTTP/Methods/DELETE).                                                                 |
| `options`     | [Operation Object](/openapi/paths/operations) |          | An operation associated with the [`OPTIONS` HTTP method](https://developer.mozilla.org/en-US/docs/Web/HTTP/Methods/OPTIONS).                                                               |
| `head`        | [Operation Object](/openapi/paths/operations) |          | An operation associated with the [`HEAD` HTTP method](https://developer.mozilla.org/en-US/docs/Web/HTTP/Methods/HEAD).                                                                     |
| `patch`       | [Operation Object](/openapi/paths/operations) |          | An operation associated with the [`PATCH` HTTP method](https://developer.mozilla.org/en-US/docs/Web/HTTP/Methods/PATCH).                                                                   |
| `trace`       | [Operation Object](/openapi/paths/operations) |          | An operation associated with the [`TRACE` HTTP method](https://developer.mozilla.org/en-US/docs/Web/HTTP/Methods/TRACE).                                                                   |
| `x-*`         |       [Extensions](/openapi/extensions)       |          | Any number of extension fields can be added to the Path Item Object that can be used by tooling and vendors.                                                                               |

The order of fields above is recommended but is not significant to the order in which the endpoints should be used.

 This is the content for the doc openapi/paths/operations.md 

 # The OpenAPI Operation Object

An operation object describes a single API operation within a path, including all its possible inputs and outputs and the configuration required to make a successful request.

Each operation object corresponds to an HTTP verb, such as `get`, `post`, or `delete`.

Example:

```yaml
paths:
  /drinks:
    get:
      # The Operation Object
      operationId: listDrinks
      summary: Get a list of drinks.
      description: Get a list of drinks, if authenticated this will include stock levels and product codes otherwise it will only include public information.
      security:
        - {}
      tags:
        - drinks
      parameters:
        - name: type
          in: query
          description: The type of drink to filter by. If not provided all drinks will be returned.
          required: false
          schema:
            $ref: "#/components/schemas/DrinkType"
      responses:
        "200":
          description: A list of drinks.
          content:
            application/json:
              schema:
                type: array
                items:
                  $ref: "#/components/schemas/Drink"
```

| Field         |                    Type                     | Required | Description                                                                                                                                                                                        |
| ------------- | :-----------------------------------------: | :------: | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `operationId` |                   String                    |          | A unique identifier for the operation, this **_must_** be unique within the document, and is **_case sensitive_**. It is **_recommended_** to always define an `operationId`, but is not required. |
| `deprecated`  |                   Boolean                   |          | Whether the operation is deprecated or not. Defaults to `false`.                                                                                                                                   |
| `summary`     |                   String                    |          | A short summary of what the operation does. This may contain [CommonMark syntax](https://spec.commonmark.org/) to provide a rich description.                                                      |
| `description` |                   String                    |          | A detailed description of the operation, what it does, and how to use it. This may contain [CommonMark syntax](https://spec.commonmark.org/) to provide a rich description.                        |
| `servers`     |             [Servers](/openapi/servers)             |          | A list of [Server Objects](/openapi/servers) that override the servers defined at the document and path levels and apply to this operation.                                                          |
| `security`    |            [Security](/openapi/security)            |          | A list of [Security Requirement Objects](/openapi/security#security-requirement-object) that override the security requirements defined at the document and path levels and apply to this operation.                |
| `x-*`         |          [Extensions](/openapi/extensions)          |          | Any number of extension fields can be added to the operation object that can be used by tooling and vendors.                                                                                       |
| `parameters`  |          [Parameters](/openapi/paths/parameters)          |          | A list of [Parameter Objects](/openapi/paths/parameters#parameter-object) that are available to this operation. The parameters defined here merge with any defined at the path level, overriding any duplicates.            |
| `requestBody` | [Request Body Object](/openapi/paths/operations/requests) |          | The request body for this operation where the [HTTP method supports a request body](https://httpwg.org/specs/rfc7231.html). Otherwise, this field is ignored.                                      |
| `responses`   |           [Responses](/openapi/paths/operations/responses)           |    ✅    | A map of [Response Objects](/openapi/paths/operations/responses#response-object) that define the possible responses from executing this operation.                                                                                    |
| `callbacks`   |           [Callbacks](/openapi/paths/operations/callbacks)           |          | A map of [Callback Objects](/openapi/paths/operations/callbacks#callback-object) that define possible callbacks that may be executed as a result of this operation.                                                                   |

The above order of fields is recommended for defining the fields in the document to help set the stage for the operation and provide a clear understanding of what it does.

 This is the content for the doc openapi/paths/operations/callbacks.md 

 # Callbacks in OpenAPI

A map of [Callback Objects](/openapi/paths/operations/callbacks#callback-object) or [References](/openapi/references) that define incoming requests that may be triggered by the parent operation and the expected responses to be returned. The key is a unique identifier for the collection of callbacks contained within.

**Note: Callbacks are only valid on operations that also pass the required URL to call the callback on, in either the parameters or the request body of the parent operation. In the event that a request from the API is sent in reaction to calling the parent operation but the callback URL is provided elsewhere, use [webhooks](/openapi/webhooks) to document the callback instead (webhooks only available in OpenAPI 3.1.x)**

For example:

```yaml
/order:
  post:
    operationId: createOrder
    summary: Create an order.
    description: Create an order for a drink.
    tags:
      - orders
    parameters:
      - name: callback_url
        in: query
        description: The url to call when the order is updated.
        required: false
        schema:
          type: string
    requestBody:
      required: true
      content:
        application/json:
          schema:
            $ref: "#/components/schemas/Order"
    responses:
      "200":
        description: The order was created successfully.
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/Order"
      "5XX":
        $ref: "#/components/responses/APIError"
      default:
        $ref: "#/components/responses/UnknownError"
    callbacks:
      orderUpdate:
        "{$request.query.callback_url}":
          post:
            summary: Receive order updates.
            description: Receive order updates from the supplier, this will be called whenever the status of an order changes.
            tags:
              - orders
            requestBody:
              required: true
              content:
                application/json:
                  schema:
                    type: object
                    properties:
                      order:
                        $ref: "#/components/schemas/Order"
            responses:
              "200":
                description: The order update was received successfully.
              "5XX":
                $ref: "#/components/responses/APIError"
              default:
                $ref: "#/components/responses/UnknownError"
```

## Callback Object in OpenAPI

A map of [Runtime Expressions](/openapi/references#runtime-expression) (that represent URLs the callback request is sent to) to a [Path Item Object](/openapi/paths#path-item-object) or [Reference](/openapi/references) that defines a request to be initiated by the API provider and a potential response to be returned.

The expression when evaluated at runtime will resolve to a URL either represented in the parameters, request body, or response body of the parent operation.

Examples:

`{$request.query.callback_url}` will resolve to the value sent in the `callback_url` query parameter sent in the parent operation.

`{$request.body#/asyncURL}` will resolve to the value of the `asyncURL` property in the request body of the parent operation.

`{$response.body#/success/progressEndpoint}` will resolve to the value of the `progressEndpoint` property within the `success` object in the response body of the parent operation.

Any number of [extension](/openapi/extensions) fields can be added to the Callback Object that can be used by tooling and vendors.

 This is the content for the doc openapi/paths/operations/content.mdx 

 import { Callout } from 'nextra/components'

# Content and Media Types in OpenAPI

In OpenAPI 3.1, the `content` keyword indicates the media types required in request bodies or returned by responses. Media types are often referred to as content types or MIME types, but we'll use media types in this document.

Media types in OpenAPI inform the client how to interpret data received from the server, and which data types the server expects from the client.

Common examples of media types include:

- `application/json` for JSON objects.
- `text/plain` for plain text.
- `image/png` for PNG image files.
- `application/xml` for XML files.
- `multipart/form-data` for form data that can include files.

## Content Map in OpenAPI

The `content` object is a map of key-value pairs.

Each key in the map is a [media or MIME type](https://developer.mozilla.org/en-US/docs/Web/HTTP/Basics_of_HTTP/MIME_types) like `application/json`, `text/plain`, or `image/png`.

The value associated with each key is a [Media Type Object](#media-type-object) that describes the structure and other relevant details for its corresponding media type.

Media type keys can include wildcards indicating a range of media types they cover. For example, `application/*` would match `application/json`, `application/xml`, and so on. It can be explicitly defined to match only a single media type, for example, `application/json; charset=utf-8`.

<Callout type="warning" emoji="⚠️">
**Avoid wildcard media types where possible:** While using wildcards in defining content types is convenient, it might lead to ambiguous results if the client and server do not handle the same range of media types. Use specific media types where possible to avoid ambiguity.
</Callout>

Where both a wildcard and a specific media type are defined, the specific media type definition takes precedence.

The example below shows a `content` map with four media types:

```yaml
content:
  application/json: # JSON formatted content
    schema:
      $ref: "#/components/schemas/Drink"
  img/*: # Image formatted content of any type
    schema:
      type: string
      format: binary
  text/*: # Text-based content of any type
    schema:
      type: string
  text/csv: # CSV formatted content (this will take precedence over text/*)
    schema:
      $ref: "#/components/schemas/Drink"
```

In this example, the server expects one of the following types:

- A JSON object representing a drink.
- Any image file in binary format.
- A CSV file representing a drink.
- Any text file.

## Content Negotiation

When the client sends a request to the server, it includes a `Content-Type` HTTP header in the request, indicating to the server how to interpret the data in the body of the request.

Likewise, the server includes a `Content-Type` HTTP header in its response, which the client should use to interpret the data in the response.

The client may also include an `Accept` HTTP header in a request, indicating to the server which content types the client can handle. The server should then send a response with a `Content-Type` header that matches one of the accepted types. This exchange is known as [content negotiation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Content_negotiation).

The diagram below illustrates the headers sent by the client and server during content negotiation:

```mermaid
sequenceDiagram
  participant C as Client
  participant S as Server
  Note over C,S: Establish Connection
  C->>S: Request with Headers
  Note over C: Request headers include:
  Note over C: Content-Type: text/csv
  Note over C: Accept: application/json, application/xml
  S->>C: Response with Headers
  Note over S: Response headers include:
  Note over S: Content-Type: application/json
```

Note that the request and response content types do not need to match. For example, in the diagram above, the client sends a request as CSV but expects JSON or XML in response.

## Media Type Object

A Media Type Object describes the request or response for a media type, with optional examples and extensions.

| Field      | Type                                                                                                                         | Required | Description                                                                                                                                                                                                                                                                                                                                                                      |
| ---------- | ---------------------------------------------------------------------------------------------------------------------------- | -------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `schema`   | [Schema Object](../../schemas.md)                                                                                            |          | A schema that describes the request or response content.                                                                                                                                                                                                                                                                                                                         |
| `examples` | Map[string, [Example Object](../../examples.md) \| [OpenAPI Reference Object](../../references.md#openapi-reference-object)] |          | Optional examples of the media type. These examples override any examples from the [Schema Object](../../schemas.md) in the `schema` field. Mutually exclusive with the `example` field.                                                                                                                                                                                         |
| `example`  | Any                                                                                                                          |          | An optional example of the media type. This example overrides any examples from the [Schema Object](../../schemas.md) in the `schema` field. Mutually exclusive with the `examples` field. Deprecated in OpenAPI 3.1 in favor of `examples`.                                                                                                                                     |
| `encoding` | Map[string, [Encoding Object](./requests.md#encoding-object)]                                           |          | An optional map of [Encoding Objects](./requests.md#encoding-object). Each Encoding Object's key should match one of the properties from the [Schema Object](../../schemas.md) in the `schema` field. Only applies to [Request Body Objects](./requests.md) when the media type is `multipart` or `application/x-www-form-urlencoded`. |
| `x-*`      | [Extensions](../../extensions.md)                                                                                            |          | Any number of extension fields as required by tooling and vendors.                                                                                                                                                                                                                                                                                                               |

## Media Type Examples

The examples below illustrate the use of the `content` object with different media types.

### JSON Media Type

The example below shows a `content` object with a JSON media type:

```yaml
content:
  application/json:
    schema:
      $ref: "#/components/schemas/Drink"
    examples:
      mojito:
        value:
          name: "Mojito"
          ingredients:
            - name: "White Rum"
              quantity: 50
            - name: "Lime Juice"
              quantity: 20
            - name: "Mint Leaves"
              quantity: 10
```

In this example, the server expects a JSON object representing a drink. The `examples` field provides an [Example Object](../../examples.md) of the expected JSON object.

The curl command below sends a request to the server with a JSON object in the body:

```bash
curl -X POST "https://api.example.com/drinks" \
     -H "Content-Type: application/json" \
     -d '{
           "name": "Mojito",
           "ingredients": [
             {
               "name": "White Rum",
               "quantity": 50
             },
             {
               "name": "Lime Juice",
               "quantity": 20
             },
             {
               "name": "Mint Leaves",
               "quantity": 10
             }
           ]
         }'
```

### Image Media Type

The example below shows a `content` object with an image media type:

```yaml
content:
  image/png:
    schema:
      type: string
      format: binary
```

In this example, the server expects an image file in binary format.

The curl command below sends a request to the server with an image file in the body:

```bash
curl -X POST "https://api.example.com/images" \
     -H "Content-Type: image/png" \
     --data-binary @image.png
```

### Text Media Type

The example below shows a `content` object with a text media type:

```yaml
content:
  text/plain:
    schema:
      type: string
```

In this example, the server expects a plain text file.

The curl command below sends a request to the server with a text file in the body:

```bash
curl -X POST "https://api.example.com/text" \
     -H "Content-Type: text/plain" \
     -d "Hello, World!"
```

### CSV Media Type

The example below shows a `content` object with a CSV media type:

```yaml
content:
  text/csv:
    schema:
      $ref: "#/components/schemas/Drink"
```

In this example, the server expects a CSV file representing a drink.

The curl command below sends a request to the server with a CSV file in the body:

```bash
curl -X POST "https://api.example.com/csv" \
     -H "Content-Type: text/csv" \
     -d "Mojito,White Rum,50,Lime Juice,20,Mint Leaves,10"
```

### Multipart Form Data

The example below shows a `content` object with a multipart form data media type:

```yaml
content:
  multipart/form-data:
    schema:
      properties:
        photo:
          description: A photo of the drink.
          type: string
          format: binary
        recipe:
          description: The recipe for the drink.
          type: string
        name:
          description: The name of the drink.
          type: string
    encoding:
      photo:
        contentType: image/jpeg, image/png
        headers:
          Content-Disposition:
            description: Specifies the disposition of the file (attachment and file name).
            schema:
              type: string
              default: 'form-data; name="photo"; filename="default.jpg"'
        allowReserved: false
      recipe:
        contentType: text/plain
        headers:
          Content-Disposition:
            description: Specifies the disposition of the file (attachment and file name).
            schema:
              type: string
              default: 'form-data; name="recipe"; filename="default.txt"'
        allowReserved: false
      name:
        contentType: text/plain
        headers:
          Content-Disposition:
            description: Specifies the disposition of the field.
            schema:
              type: string
              default: 'form-data; name="name"'
        allowReserved: false
```

In this example, the server expects a form data request with a photo of the drink, the recipe for the drink, and the name of the drink. The `encoding` field provides additional information about each part, such as the content type, headers, and whether reserved characters are allowed.

The curl command below sends a request to the server with a photo file, a recipe file, and the name of the drink in the body:

```bash
curl -X POST "https://api.example.com/drinks" \
     -F "photo=@photo.jpg;type=image/jpeg" \
     -F "recipe=@recipe.txt;type=text/plain" \
     -F "name=Mocktail"
```

## OpenAPI Content Best Practices

When designing APIs with OpenAPI, consider the following best practices for content and media types:

- Where possible, use the most specific media type for your content. For example, prefer `application/json` over `application/*` if your content is JSON.
- When using OpenAPI 3.1, provide at least one example for each media type using the `examples` keyword to help clients understand the expected content and enrich the API documentation.


 This is the content for the doc openapi/paths/operations/requests.md 

 # Request Body Object in OpenAPI

The request body is used to describe the body of the request for operations that support a request body.

| Field         |           Type            | Required | Description                                                                                                                          |
| ------------- | :-----------------------: | :------: | ------------------------------------------------------------------------------------------------------------------------------------ |
| `description` |          String           |          | A description of the request body. This may contain [CommonMark syntax](https://spec.commonmark.org/) to provide a rich description. |
| `content`     |    [Content](/openapi/paths/operations/content)    |    ✅    | A map of [Media Type Objects](/openapi/paths/operations/content#media-type-object) that defines the possible media types that can be used for the request body.       |
| `required`    |          Boolean          |          | Whether the request body is required. Defaults to `false`.                                                                           |
| `x-*`         | [Extensions](/openapi/extensions) |          | Any number of extension fields can be added to the Request Body Object that can be used by tooling and vendors.                      |

## Encoding Object

Only applicable to `requestBody` where the media type is `multipart` or `application/x-www-form-urlencoded`. An encoding object describes the encoding of a single property in the request schema.

| Field           | Type                                                                                          | Required | Description                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |
| --------------- | --------------------------------------------------------------------------------------------- | -------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `contentType`   | String                                                                                        |          | The content type of the field. If the field is an `object`, the default is `application/json`. If the field is an array, the default is based on the inner type. Otherwise, the default is `application/octet-stream`. Valid values are either a media type (for example, `application/json`), a wildcard media type (for example, `image/*`), or a comma-separated list of media types and wildcard media types (for example, `image/png, application/*`).                      |
| `headers`       | Map[string, [Header Object](/openapi/paths/operations/responses/headers) \| [Reference Object](/openapi/references#openapi-reference-object)] |          | Only applies to `multipart` requests. Allows additional headers related to the field. For example, if the client needs to add a `Content-Disposition` for an uploaded file. A `Content-Type` header in this map will be ignored, in favor of the `contentType` field of the encoding object.                                                                                                                                                                                     |
| `style`         | String                                                                                        |          | Can take one of the following values: `form`, `spaceDelimited`, `pipeDelimited`, or `deepObject`. Specifies the style of the field's serialization only in requests with media type `multipart/form-data` or `application/x-www-form-urlencoded`. See the description of `style` under [Query Parameters](/openapi/paths/parameters/query-parameters).                                                                                                                                                    |
| `explode`       | Boolean                                                                                       |          | Only applies to requests with media type `multipart/form-data` or `application/x-www-form-urlencoded` and fields with `array` or `object` types. If `style` is `form`, the default is `true`, otherwise the default is `false`.                                                                                                                                                                                                                                                  |
| `allowReserved` | Boolean                                                                                       |          | Only applies to requests with media type `application/x-www-form-urlencoded`. Determines whether reserved characters (those allowed in literals but with reserved meanings) are allowed in the parameter's content. The default is `false`. When `true`, it allows reserved characters as defined by [RFC 3986](https://datatracker.ietf.org/doc/html/rfc3986#section-2.2) to be included without percent-encoding. This can be useful for parameters with content such as URLs. |

```yaml
paths:
  /drinks:
    post:
      requestbody:
        content:
          multipart/form-data:
            schema:
              properties:
                # ... other properties ...
                photo:
                  description: A photo of the drink.
                  type: string
                  format: binary
            encoding:
              photo:
                contentType: image/jpeg, image/png
                headers:
                  Content-Disposition:
                    description: Specifies the disposition of the file (attachment and file name).
                    schema:
                      type: string
                      default: 'form-data; name="photo"; filename="default.jpg"'
                allowReserved: false
                # style: form - not applicable to strings
                # explode: false - not applicable to strings
```

 This is the content for the doc openapi/paths/operations/responses.md 

 # OpenAPI Responses

The Responses Object is a map of [Response Objects](/openapi/paths/operations/responses#response-object) or [References](/openapi/references) to [Response Objects](/openapi/paths/operations/responses#response-object) that define the possible responses that can be returned from executing the operation.

The keys in the map represent any known HTTP status codes that the API may return. The HTTP status codes can be defined like below:

- Numeric Status Code - for example, `200`, `404`, or `500`. HTTP status codes are defined in [RFC 9110](https://httpwg.org/specs/rfc9110.html#overview.of.status.codes).
- Status Code Wildcards - for example, `1XX`, `2XX`, `3XX`, `4XX`, or `5XX`. A wildcard that matches any status code in the range of its significant digit, for example, `2XX` represents status codes `200` to `299` inclusive.
- `default` - A catch-all identifier for any other status codes not defined in the map.

The map **_must_** contain at least one successful response code.

All values **_must_** be defined as explicit strings (for example,`"200"`) to allow for compatibility between JSON and YAML.

For example:

```yaml
paths:
  /drinks:
    get:
      operationId: listDrinks
      summary: Get a list of drinks.
      description: Get a list of drinks, if authenticated this will include stock levels and product codes otherwise it will only include public information.
      tags:
        - drinks
      parameters:
        - name: type
          in: query
          description: The type of drink to filter by. If not provided all drinks will be returned.
          required: false
          schema:
            $ref: "#/components/schemas/DrinkType"
      responses:
        "200":
          description: A list of drinks.
          content:
            application/json:
              schema:
                type: array
                items:
                  $ref: "#/components/schemas/Drink"
        "5XX":
          description: An error occurred interacting with the API.
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/APIError"
        default:
          description: An unknown error occurred interacting with the API.
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/Error"
```

Any number of [extension](/openapi/extensions) fields can be added to the responses object that can be used by tooling and vendors.

## Response Object in OpenAPI

The Response Object describes a single response that can be returned from executing an [operation](/openapi/paths/operations).

| Field         |           Type            | Required | Description                                                                                                                                           |
| ------------- | :-----------------------: | :------: | ----------------------------------------------------------------------------------------------------------------------------------------------------- |
| `description` |          String           |    ✅    | A description of the response. This may contain [CommonMark syntax](https://spec.commonmark.org/) to provide a rich description.                      |
| `headers`     |    [Headers](/openapi/paths/operations/responses/headers)    |          | A map of [Header Objects](/openapi/paths/operations/responses/headers) that defines the headers that can be returned from executing this operation.                                |
| `content`     |    [Content](/openapi/paths/operations/content)    |          | A map of [Media Type Objects](/openapi/paths/operations/content#media-type-object) that defines the possible media types that can be returned from executing this operation.           |
| `links`       |      [Links](/openapi/paths/operations/responses/links)      |          | A map of [Link Objects](/openapi/paths/operations/responses/links#link-object) or [References](/openapi/references) that define the possible links that can be returned from executing this operation. |
| `x-*`         | [Extensions](/openapi/extensions) |          | Any number of extension fields can be added to the response object that can be used by tooling and vendors.                                           |

 This is the content for the doc openapi/paths/operations/responses/headers.md 

 # OpenAPI Headers

A map of header names to [Header Objects](/openapi/paths/operations/responses/headers) or [References](/openapi/references) that define headers in [Response Objects](/openapi/paths/operations/responses#response-object) or [Encoding Objects](/openapi/paths/operations/requests#encoding-object).

In this simplified example, the server returns three [Header Objects](/openapi/paths/operations/responses/headers) with the names `X-RateLimit-Remaining`, `Last-Modified`, and `Cache-Control`:

```yaml
paths:
  /drinks/{productCode}:
    get:
      responses:
        "200"
          description: A drink.
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/Drink"
          headers:
            X-RateLimit-Remaining:
              description: The number of requests left for the time window.
              schema:
                type: integer
                example: 99
            Last-Modified:
              description: The time at which the information was last modified.
              schema:
                type: string
                format: date-time
                example: '2024-01-26T18:25:43.511Z'
            Cache-Control:
              description: Instructions for caching mechanisms in both requests and responses.
              schema:
                type: string
                example: no-cache
```

## Header Object in OpenAPI

Describes a single header.

The name of a header is determined by the header's key in a `headers` map.

| Field         | Type                                                 | Required | Description                                                                                                                                                                                                                                                                                                                    |
| ------------- | ---------------------------------------------------- | -------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| `description` | String                                               |          | A description of the header. This may contain [CommonMark syntax](https://spec.commonmark.org/) to provide a rich description.                                                                                                                                                                                                 |
| `required`    | Boolean                                              |          | Whether the header is required. Defaults to `false`.                                                                                                                                                                                                                                                                           |
| `deprecated`  | Boolean                                              |          | Whether the header is deprecated. Defaults to `false`.                                                                                                                                                                                                                                                                         |
| `schema`      | [Schema Object](/openapi/schemas)                      |          | A schema or reference to a schema that defines the type of the header. This is **_required_** unless `content` is defined.<br/><br/>**Note: OpenAPI 3.0.x supports [OpenAPI Reference Objects](/openapi/references#openapi-reference-object) here as a value. OpenAPI 3.1.x uses the [JSON Schema Referencing](/openapi/schemas#json-schema--openapi) format.** |
| `content`     | Map[string, [Media Type Object](/openapi/paths/operations/content#media-type-object)] |          | A map of [Media Type Objects](/openapi/paths/operations/content#media-type-object) that define the possible media types that can be used for the header. This is **_required_** unless `schema` is defined.                                                                                                                                                     |
| `x-*`         | [Extensions](/openapi/extensions)                            |          | Any number of extension fields can be added to the header object to be used by tooling and vendors.                                                                                                                                                                                                                            |

 This is the content for the doc openapi/paths/operations/responses/links.md 

 # OpenAPI Links

The Links object is a map of [Link Objects](/openapi/paths/operations/responses/links#link-object) or [References](/openapi/references) to [Link Objects](/openapi/paths/operations/responses/links#link-object) that allows for describing possible API-use scenarios between different operations. For example, if a response returns a `Drink` object, and the `Drink` object has an `ingredients` property that is a list of `Ingredient` objects, then a link can be defined to the `listIngredients` operation showing how the ingredients can be used as an input to the `listIngredients` operation.

For example:

```yaml
/drink/{name}:
  get:
    operationId: getDrink
      summary: Get a drink.
      description: Get a drink by name, if authenticated this will include stock levels and product codes otherwise it will only include public information.
      tags:
        - drinks
      parameters:
        - name: name
          in: path
          required: true
          schema:
            type: string
      responses:
    responses:
      "200":
        description: A drink.
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/Drink"
        links:
          listIngredients:
            operationId: listIngredients
            parameters:
              ingredients: $response.body#/ingredients
            description: The list of ingredients returned by the `getDrink` operation can be used as an input to the `listIngredients` operation, to retrieve additional details about the ingredients required to make the drink.
/ingredients:
    get:
      operationId: listIngredients
      summary: Get a list of ingredients.
      description: Get a list of ingredients, if authenticated this will include stock levels and product codes otherwise it will only include public information.
      tags:
        - ingredients
      parameters:
        - name: ingredients
          in: query
          description: A list of ingredients to filter by. If not provided all ingredients will be returned.
          required: false
          style: form
          explode: false
          schema:
            type: array
            items:
              type: string
      responses:
        "200":
          description: A list of ingredients.
          content:
            application/json:
              schema:
                type: array
                items:
                  $ref: "#/components/schemas/Ingredient"
        "5XX":
          $ref: "#/components/responses/APIError"
        default:
          $ref: "#/components/responses/UnknownError"
```

## Link Object in OpenAPI

The Link Object represents a possible link that can be followed from the response.

| Field          |                       Type                        | Required | Description                                                                                                                                                                                                                                                                                                                                   |
| -------------- | :-----------------------------------------------: | :------: | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `operationId`  |                      String                       |    ✅    | The `operationId` of an [operation](/openapi/paths/operations) that exists in the document. Use either this field or the `operationRef` field, not both.                                                                                                                                                                                              |
| `operationRef` |                      String                       |    ✅    | Either a [Relative Reference](/openapi/references#relative-references) or [Absolute Reference](/openapi/references#absolute-references) to an [operation](/openapi/paths/operations) that exists in the document. Use either this field or the `operationId` field, not both.                                                                                                                                 |
| `description`  |                      String                       |          | A description of the link and intentions for its use. This may contain [CommonMark syntax](https://spec.commonmark.org/) to provide a rich description.                                                                                                                                                                                       |
| `parameters`   | Map[string, any \| [\{Expression\}](/openapi/references#runtime-expression)] |          | A map of parameters to pass to the linked operation. The key is the name of the parameter and the value is either a constant value or an [Expression](/openapi/references#runtime-expression) that will be evaluated.<br/><br/>The parameter name can also be qualified with the location of the parameter, for example, `path.parameter_name` or `query.parameter_name` |
| `requestBody`  |       Any \| [\{Expression\}](/openapi/references#runtime-expression)        |          | A constant value or [Expression](/openapi/references#runtime-expression) that will be used as the request body when calling the linked operation.                                                                                                                                                                                                                        |
| `server`       |          [Server Object](/openapi/servers)          |          | An optional server to be used by the linked operation.                                                                                                                                                                                                                                                                                        |
| `x-*`          |             [Extensions](/openapi/extensions)             |          | Any number of extension fields can be added to the link object that can be used by tooling and vendors.                                                                                                                                                                                                                                       |

An example of `OperationRef`:

```yaml
links:
  listIngredients:
    operationRef: "#/paths/~1ingredients/get"
    parameters:
      ingredients: $response.body#/ingredients

# or

links:
  listIngredients:
    operationRef: "https://speakeasy.bar/#/paths/~1ingredients/get"
    parameters:
      ingredients: $response.body#/ingredients
```


 This is the content for the doc openapi/paths/parameters.md 

 # OpenAPI Parameters

Parameters are used to describe inputs to an operation. Parameters can be defined at the path or operation level and are merged with any duplicates at the operation level, overriding any defined at the path level.

Each parameter needs to be uniquely identified by a combination of its `name` and `in` fields in an [operation](/openapi/paths/operations).

A parameter in the list can either be a [Parameter Object](/openapi/paths/parameters#parameter-object) or a [Reference](/openapi/references) to a [Parameter Object](/openapi/paths/parameters#parameter-object) defined in the [Components Object](/openapi/components) under the `parameters` field.

Parameters can represent a number of different input types, including:

- Path Parameters
- Query Parameters
- Headers
- Cookies

Example:

```yaml
paths:
  /drinks/{type}:
    parameters:
      - name: type
        in: path
        description: The type of drink to filter by.
        required: true
        schema:
          $ref: "#/components/schemas/DrinkType"
      - name: Cache-Control
        in: header
        description: The cache control header.
        required: false
        schema:
          type: string
          enum:
            - no-cache
            - no-store
            - must-revalidate
            - max-age=0
            - max-age=3600
            - max-age=86400
            - max-age=604800
            - max-age=2592000
            - max-age=31536000
    get:
      operationId: listDrinks
      summary: Get a list of drinks.
      description: Get a list of drinks, if authenticated this will include stock levels and product codes otherwise it will only include public information.
      security:
        - {}
      tags:
        - drinks
      parameters:
        - name: limit
          in: query
          description: The maximum number of drinks to return.
          required: false
          schema:
            type: integer
            minimum: 1
            maximum: 100
      responses:
        "200":
          description: A list of drinks.
          content:
            application/json:
              schema:
                type: array
                items:
                  $ref: "#/components/schemas/Drink"
```

## Parameter Object

| Field             |              Type               | Required | Description                                                                                                                                                                                                                                                                                                                                                                                                                                                |
| ----------------- | :-----------------------------: | :------: | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `name`            |             String              |    ✅    | The **case sensitive** name of the parameter. This **_must_** be unique when combined with the `in` field.<br/><br/>If the `in` field is `path`, then this field **_must_** be referenced in the owning path.                                                                                                                                                                                                                                              |
| `in`              |             String              |    ✅    | The type or location of the parameter. The available types are:<br/><ul><li>`path` - A templated parameter defined within the path.</li><li>`query` - A query parameter passed via the URL.</li><li>`header` - A header parameter passed via HTTP headers.</li><li>`cookie` - A cookie parameter passed via HTTP cookies.</li></ul>                                                                                                                        |
| `description`     |             String              |          | A description of the parameter. This may contain [CommonMark syntax](https://spec.commonmark.org/) to provide a rich description.                                                                                                                                                                                                                                                                                                                          |
| `required`        |             Boolean             |          | Whether the parameter is required. If the `in` field is `path`, then this field is **always** required and **_must_** be `true`. Defaults to `false`.                                                                                                                                                                                                                                                                                                      |
| `deprecated`      |             Boolean             |          | Whether the parameter is deprecated. Defaults to `false`.                                                                                                                                                                                                                                                                                                                                                                                                  |
| `style`           |             String              |          | Describes how the parameter value will be serialized depending on the `in` field. The available styles are `matrix`, `label`, `form`, `simple`, `spaceDelimited`, `pipeDelimited`, and `deepObject`.<br/><br/>The default style depends on the `in` field:<br/><ul><li>`path` - `simple`</li><li>`query` - `form`</li><li>`header` - `simple`</li><li>`cookie` - `form`</li></ul>See the [path](https://www.speakeasy.com/openapi/paths/parameters/path-parameters), [header](https://www.speakeasy.com/openapi/paths/parameters/header-parameters), [query](https://www.speakeasy.com/openapi/paths/parameters/query-parameters), and [cookie](https://www.speakeasy.com/openapi/paths/parameters/cookie-parameters) parameter sections for more details. |
| `explode`         |             Boolean             |          | Whether the parameter value will be exploded, based on the parameter type. Defaults to `true` when `style` is `form`, otherwise `false`.<br /><br/>See the [path](https://www.speakeasy.com/openapi/paths/parameters/path-parameters), [header](https://www.speakeasy.com/openapi/paths/parameters/header-parameters), [query](https://www.speakeasy.com/openapi/paths/parameters/query-parameters), and [cookie](https://www.speakeasy.com/openapi/paths/parameters/cookie-parameters) parameter sections for more details.                                                                                                                                                                                                                             |
| `schema`          | [Schema Object](/openapi/schemas) |          | A schema or reference to a schema that defines the type of the parameter. This is **_required_** unless `content` is defined.<br/><br/>**Note: OpenAPI 3.0.x supports [OpenAPI Reference Objects](/openapi/references#openapi-reference-object) here as the value. OpenAPI 3.1.x uses the [JSON Schema Referencing](/openapi/schemas#json-schema--openapi) format.**                                                                                                                        |
| `content`         |       [Content](/openapi/paths/operations/content)       |          | A map of [Media Type Objects](/openapi/paths/operations/content#media-type-object) that defines the possible media types that can be used for the parameter. This is **_required_** unless `schema` is defined.                                                                                                                                                                                                                                                                             |
| `allowEmptyValue` |             Boolean             |          | Whether the parameter value can be empty. Only used if `in` is `query`. Defaults to `false`.                                                                                                                                                                                                                                                                                                                                                               |
| `allowReserved`   |             Boolean             |          | Whether the parameter value can contain reserved characters as defined by [RFC 3986](https://www.rfc-editor.org/rfc/rfc3986). Only used if `in` is `query`. Defaults to `false`.                                                                                                                                                                                                                                                                           |
| `example`         |               Any               |          | An example of the parameter's value. This is ignored if the `examples` field is defined.                                                                                                                                                                                                                                                                                                                                                                   |
| `examples`        |      [Examples])examples)      |          | A map of [Example Objects](/openapi/examples) and/or [OpenAPI Reference Objects](/openapi/references#openapi-reference-object) that define the possible examples of the parameter's value.                                                                                                                                                                                                                                                                                      |
| `x-*`             |    [Extensions](/openapi/extensions)    |          | Any number of extension fields can be added to the parameter object that can be used by tooling and vendors.                                                                                                                                                                                                                                                                                                                                               |

The order of fields above is recommended for defining fields in the document.

## Parameter Serialization

Depending on the parameter's `in`, `style`, and `explode` fields and schema type, the parameter value will be serialized in different ways. Some combinations of schema type and parameter serialization are not valid and should be avoided.

The `content` field can be used instead to define complex serialization scenarios for a parameter such as serializing an object to a JSON string for including in a query parameter in the URL.


 This is the content for the doc openapi/paths/parameters/cookie-parameters.md 

 # Cookie Parameters in OpenAPI

Cookie parameters are serialized at runtime to an HTTP cookie header. Types are generally serialized to a string representation, and only `form` style is available.

Currently, cookies are not well supported by OpenAPI and this may change in the future, so using the default `style: form` and `explode: true` values results in serialization incompatible with most cookie parsers.

Therefore, it is recommended to only use cookies for primitive types or arrays with `explode: false`, but the current serialization behaviors are included below for completeness.

If using cookies for authentication, it is recommended to use the OpenAPI [`security`](/openapi/security) field to document a security scheme instead of a cookie parameter.

## Primitive Types As Cookies in OpenAPI

Primitive types such as `string`, `number`, `integer`, and `boolean` are serialized as a string.

For the example below, we will use a cookie parameter named `drink-limit` with a value of `5`.

| Style  |         Explode == `true`         |   Explode == `false`    |
| ------ | :-------------------------------: | :---------------------: |
| `form` | `Cookie: drink-limit=5` (default) | `Cookie: drink-limit=5` |

## Simple Arrays As Cookies in OpenAPI

For simple arrays of primitive types such as `string`, `number`, `integer`, and `boolean`, serialization will vary depending on the `explode` field.

For the example below, we will use a cookie parameter named `drink-types` with a value of `["gin", "vodka", "rum"]`.

| Style  |                           Explode == `true`                           |         Explode == `false`          |
| ------ | :-------------------------------------------------------------------: | :---------------------------------: |
| `form` | `Cookie: drink-types=gin&drink-types=vodka&drink-types=rum` (default) | `Cookie: drink-types=gin,vodka,rum` |

## Simple Objects As Cookies in OpenAPI

For simple objects whose fields are primitive types such as `string`, `number`, `integer`, and `boolean`, serialization will vary depending on the `explode` field.

For the example below, we will use a cookie parameter named `drink-filter` with a value of `{"type": "cocktail", "strength": 5}`.

| Style  |              Explode == `true`               |               Explode == `false`                |
| ------ | :------------------------------------------: | :---------------------------------------------: |
| `form` | `Cookie: type=cocktail&strength=5` (default) | `Cookie: drink-filter=type,cocktail,strength,5` |

## Complex Objects and Arrays As Cookies in OpenAPI

For complex objects and arrays, serialization in a cookie parameter is only really possible using `content` and not any `style` options.

For example, to serialize using JSON, the following:

```yaml
parameters:
  - name: drink-filter
    in: cookie
    content:
      application/json:
        schema:
          type: object
          properties:
            type:
              type: array
              items:
                type: string
            strength:
              type: array
              items:
                type: integer
```

Would serialize to `Cookie: drink-filter={"type":["cocktail","mocktail"],"strength":[5,10]}`.

 This is the content for the doc openapi/paths/parameters/header-parameters.md 

 # OpenAPI Header Parameters

Header parameters are serialized at runtime to the HTTP headers of the request. Types are generally serialized to a string representation, and only `simple` style is available.

Explode defaults to `false`.

There are a few reserved headers that cannot be used as parameter names and are enabled by other OpenAPI features:

- `Accept` - Defining content types in the [Response Object](/openapi/paths/operations/responses#response-object) `content` field, documents the available values for the `Accept` header.
- `Authorization` - Defining security requirements in the [Security Requirement Object](/openapi/security#security-requirement-object) `security` field, documents that the `Authorization` header is required.
- `Content-Type` - Defining content types in the [Request Body Object](/openapi/paths/operations/requests) `content` field, documents that the `Content-Type` header is required and the acceptable values.

If using headers for authentication, it is recommended to use the OpenAPI [`security`](/openapi/security) field to document a security scheme instead of a header parameter.

## Primitive Types As Headers in OpenAPI

Primitive types such as `string`, `number`, `integer`, and `boolean` are serialized as a string.

For the example below, we will use a header parameter named `X-Drink-Limit` with a value of `5`.

| Style    | Explode == `true` |     Explode == `false`      |
| -------- | :---------------: | :-------------------------: |
| `simple` | `X-Drink-Type: 5` | `X-Drink-Type: 5` (default) |

## Simple Arrays As Headers in OpenAPI

For simple arrays of primitive types such as `string`, `number`, `integer`, and `boolean`, the `style` and `explode` fields have little effect on the serialization.

For the example below, we will use a header parameter named `X-Drink-Types` with a value of `["gin", "vodka", "rum"]`.

| Style    |       Explode == `true`       |           Explode == `false`            |
| -------- | :---------------------------: | :-------------------------------------: |
| `simple` | `X-Drink-Type: gin,vodka,rum` | `X-Drink-Type: gin,vodka,rum` (default) |

## Simple Objects As Headers in OpenAPI

For simple objects whose fields are primitive types such as `string`, `number`, `integer`, and `boolean`, serialization will vary depending on the `explode` field.

For the example below, we will use a header parameter named `X-Drink-Filter` with a value of `{"type": "cocktail", "strength": 5}`.

| Style    |            Explode == `true`             |                 Explode == `false`                 |
| -------- | :--------------------------------------: | :------------------------------------------------: |
| `simple` | `X-Drink-Type: type=cocktail,strength=5` | `X-Drink-Type: type,cocktail,strength,5` (default) |

## Complex Objects and Arrays As Headers in OpenAPI

For complex objects and arrays, serialization in a header parameter is only really possible using `content` and not any `style` options.

For example, to serialize using JSON, the following:

```yaml
parameters:
  - name: X-Drink-Filter
    in: header
    content:
      application/json:
        schema:
          type: object
          properties:
            type:
              type: array
              items:
                type: string
            strength:
              type: array
              items:
                type: integer
```

Would serialize to `X-Drink-Filter: {"type":["cocktail","mocktail"],"strength":[5,10]}`.

 This is the content for the doc openapi/paths/parameters/path-parameters.md 

 
# OpenAPI path parameters

Path parameters are serialized at runtime to the path of the URL, meaning they are generally serialized to a string representation and must adhere to the [RFC 3986](https://www.rfc-editor.org/rfc/rfc3986) specification. Reserved characters are percent-encoded (for example, `?` becomes `%3F`).

By default, path parameters are serialized using `style: simple` and `explode: false`, but several different serialization options are available:

- `style: simple` - Simple style serialization is the default serialization for path parameters, using commas (`,`) to separate multiple values. Defined by [RFC 6570](https://tools.ietf.org/html/rfc6570#section-3.2.7).
- `style: label` - Label-style serialization uses dots (`.`) to separate multiple values. Defined by [RFC 6570](https://tools.ietf.org/html/rfc6570#section-3.2.6).
- `style: matrix` - Matrix-style serialization uses semicolons (`;`) to separate multiple values. Defined by [RFC 6570](https://tools.ietf.org/html/rfc6570#section-3.2.5).

## Primitive types as path parameters in OpenAPI

Primitive types such as `string`, `number`, `integer`, and `boolean` are serialized as strings. The `style` and `explode` fields generally determine the prefix for the value.

For the examples below, we will use a path parameter named `type` with a value of `cocktail` for a path-templated URL of `/drinks/{type}`.

| Style    |    Explode == `true`     |    Explode == `false`    |
| -------- | :----------------------: | :----------------------: |
| `simple` |    `/drinks/cocktail`    |    `/drinks/cocktail`    |
| `label`  |   `/drinks/.cocktail`    |   `/drinks/.cocktail`    |
| `matrix` | `/drinks/;type=cocktail` | `/drinks/;type=cocktail` |

## Simple arrays as path parameters in OpenAPI

For simple arrays of primitive types such as `string`, `number`, `integer`, and `boolean`, serialization will vary depending on the `style` and `explode` fields.

For the examples below, we will use a path parameter named `types` with a value of `["gin", "vodka", "rum"]` for a path-templated URL of `/drinks/{types}`.

| Style    |             Explode == `true`              |        Explode == `false`         |
| -------- | :----------------------------------------: | :-------------------------------: |
| `simple` |          `/drinks/gin,vodka,rum`           | `/drinks/gin,vodka,rum` (default) |
| `label`  |          `/drinks/.gin.vodka.rum`          |     `/drinks/.gin,vodka,rum`      |
| `matrix` | `/drinks/;types=gin;types=vodka;types=rum` |  `/drinks/;types=gin,vodka,rum`   |

## Simple objects as path parameters in OpenAPI

For simple objects whose fields are primitive types such as `string`, `number`, `integer`, and `boolean`, serialization will vary depending on the `style` and `explode` fields.

For the examples below, we will use a path parameter named `filter` with a value of `{"type": "cocktail", "strength": 5}` for a path-templated URL of `/drinks/{filter}`.

| Style    |          Explode == `true`          |              Explode == `false`              |
| -------- | :---------------------------------: | :------------------------------------------: |
| `simple` | `/drinks/type=cocktail,strength=5`  | `/drinks/type,cocktail,strength,5` (default) |
| `label`  | `/drinks/.type=cocktail.strength=5` |     `/drinks/.type,cocktail,strength,5`      |
| `matrix` | `/drinks/;type=cocktail;strength=5` |  `/drinks/;filter=type,cocktail,strength,5`  |

## Complex objects and arrays as path parameters in OpenAPI

For complex objects and arrays, serialization in a path parameter is only possible using `content` and not any `style` options.

For example, to serialize using JSON, you can define a parameter in the following way:

```yaml
parameters:
  - name: filter
    in: path
    content:
      application/json:
        schema:
          type: object
          properties:
            type:
              type: array
              items:
                type: string
            strength:
              type: array
              items:
                type: integer
```

This configuration would serialize to `/drinks/%7B%22type%22%3A%5B%22cocktail%22%2C%22mocktail%22%5D%2C%22strength%22%3A%5B5%2C10%5D%7D`, which is the equivalent of `/drinks/{"type":["cocktail","mocktail"],"strength":[5,10]}` unencoded.

## How to override path parameter encoding

By default, the characters `:/?#[]@!$&'()*+,;=` are encoded when present in the value of a path parameter. To render these characters unencoded in a request URL, use the `x-speakeasy-param-encoding-override: allowReserved` extension. Read more about parameter encoding in the ([docs](/docs/sdk-design/java/param-encoding)).


 This is the content for the doc openapi/paths/parameters/query-parameters.md 

 # OpenAPI Query Parameters

Query parameters are serialized at runtime to the query string of the URL, meaning they are generally serialized to a string representation and must adhere to the [RFC 3986](https://www.rfc-editor.org/rfc/rfc3986) specification. By default, reserved characters are percent-encoded (for example, `?` becomes `%3F`) but this can be disabled by setting `allowReserved` to `true`.

By default, query parameters are serialized using `style: form` and `explode: true` but there are a number of different serialization options available:

- `style: form` - Form style serialization is the default serialization for query parameters. It generally uses ampersands (`&`) to separate multiple values and equals (`=`) to separate the key and value. Defined by [RFC 6570](https://tools.ietf.org/html/rfc6570#section-3.2.8).
- `style: pipeDelimited` - Pipe-delimited serialization uses pipes (`|`) to separate multiple values.
- `style: spaceDelimited` - Space-delimited serialization uses percent-encoded spaces (`%20`) to separate multiple values.
- `style: deepObject` - Deep-object serialization uses nested objects to represent the parameter value.

## Primitive Types As Query Parameters in OpenAPI

For primitive types such as `string`, `number`, `integer,` and `boolean`, the serialization is straightforward and the value is serialized as a string. The `style` and `explode` fields have little effect on the serialization.

For the examples below, we will use a query parameter named `limit` with a value of `10`.

| Style            |      Explode == `true`      | Explode == `false` |
| ---------------- | :-------------------------: | :----------------: |
| `form`           | `/query?limit=10` (default) | `/query?limit=10`  |
| `pipeDelimited`  |      `/query?limit=10`      | `/query?limit=10`  |
| `spaceDelimited` |      `/query?limit=10`      | `/query?limit=10`  |
| `deepObject`     |        **NOT VALID**        |   **NOT VALID**    |

## Simple Arrays As Query Parameters in OpenAPI

For simple arrays of primitive types such as `string`, `number`, `integer`, and `boolean`, serialization will vary depending on the `style` and `explode` fields.

For the examples below, we will use a query parameter named `terms` with a value of `["gin", "vodka", "rum"]`.

| Style            |                 Explode == `true`                  |        Explode == `false`        |
| ---------------- | :------------------------------------------------: | :------------------------------: |
| `form`           | `/query?terms=gin&terms=vodka&terms=rum` (default) |   `/query?terms=gin,vodka,rum`   |
| `pipeDelimited`  |      `/query?terms=gin&terms=vodka&terms=rum`      |  `/query?terms=gin\|vodka\|rum`  |
| `spaceDelimited` |      `/query?terms=gin&terms=vodka&terms=rum`      | `/query?terms=gin%20vodka%20rum` |
| `deepObject`     |                   **NOT VALID**                    |          **NOT VALID**           |

## Simple Objects As Query Parameters in OpenAPI

For simple objects whose fields are primitive types such as `string`, `number`, `integer`, and `boolean`, serialization will vary depending on the `style` and `explode` fields.

For the examples below, we will use a query parameter named `filter` with a value of `{"type": "cocktail", "strength": 5}`.

| Style            |                 Explode == `true`                 |               Explode == `false`               |
| ---------------- | :-----------------------------------------------: | :--------------------------------------------: |
| `form`           |    `/query?type=cocktail&strength=5` (default)    |    `/query?filter=type,cocktail,strength,5`    |
| `pipeDelimited`  |         `/query?type=cocktail&strength=5`         |  `/query?filter=type\|cocktail\|strength\|5`   |
| `spaceDelimited` |         `/query?type=cocktail&strength=5`         | `/query?filter=type%20cocktail%20strength%205` |
| `deepObject`     | `/query?filter[type]=cocktail&filter[strength]=5` |                 **NOT VALID**                  |

There is a special case for simple objects with fields that are an array of primitive types such as `string`, `number`, `integer`, and `boolean` that can be handled by `style: deepObject` and `explode: true`. For example, for a query parameter named `filter` with a value of `{"type": ["cocktail", "mocktail"], "strength": [5, 10]}`, this will be serialized like `/query?filter[type]=cocktail&filter[type]=mocktail&filter[strength]=5&filter[strength]=10`.

## Complex Objects and Arrays As Query Parameters in OpenAPI

For complex objects and arrays, serialization in a query parameter is only really possible using `content` and not any `style` options.

For example, to serialize using JSON, the following:

```yaml
parameters:
  - name: filter
    in: query
    content:
      application/json:
        schema:
          type: object
          properties:
            type:
              type: array
              items:
                type: string
            strength:
              type: array
              items:
                type: integer
```

Would serialize to `/query?filter=%7B%22type%22%3A%5B%22cocktail%22%2C%22mocktail%22%5D%2C%22strength%22%3A%5B5%2C10%5D%7D`, which is the equivalent of `/query?filter={"type":["cocktail","mocktail"],"strength":[5,10]}` unencoded.


 This is the content for the doc openapi/references.md 

 # References ($ref) in OpenAPI

While creating an OpenAPI schema, you might notice duplicated parts in your document. Using references in OpenAPI helps you define a schema once and reuse it elsewhere in the document. This approach minimizes duplication and makes your OpenAPI document more readable and maintainable.

To reference a schema, use the `$ref` keyword followed by the path to the schema. The path can be an absolute or relative URI and can also refer to objects in different files.

## OpenAPI Reference Object

Any object supported by the [Components Object](./components.md) can be replaced by an OpenAPI Reference Object. A Reference Object points to a component using the `$ref` field, which is itself a [JSON Schema Reference](#json-schema-references) and can optionally override the `summary` or `description` of the referenced object.

| Field         | Type   | Required | Description                                                                                                                                                                                                                                                                                |
| ------------- | ------ | -------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| `$ref`        | String | ✅       | A [JSON Schema reference](#json-schema-references) to a component.                                                                                                                                                                                                                         |
| `summary`     | String |          | A summary that overrides the referenced component's `summary` field. This field is ignored if the referenced component's type does not support the `summary` field.                                                                                                                        |
| `description` | String |          | A detailed description that overrides the referenced component's `description` field. This field is ignored if the referenced component's type does not support the `description` field. This may contain [CommonMark syntax](https://spec.commonmark.org/) to provide a rich description. |

In the example below, we define a `Drink` schema in the `components` section:

```yaml  openapi.yaml mark=3:11
components:
  schemas:
    Drink:
      type: object
      summary: A drink in the bar
      description: A drink that can be ordered in the bar
      properties:
        name:
          type: string
        recipe:
          type: string
```

We can reference this component in API paths using a Reference Object:

```yaml openapi.yaml mark=10:11
paths:
  /drinks:
    post:
      summary: Create a new drink
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/Drink" # References the Drink schema
              summary: A drink to add to the bar # Overrides the Drink schema summary
      responses:
        "200":
          description: OK
```

In this example, the `Drink` schema is referenced in the `requestBody` of the `POST /drinks` operation. The `summary` field in the Reference Object overrides the `summary` field of the `Drink` schema.

## JSON Schema References in OpenAPI

OpenAPI inherits the flexible JSON Schema `$ref` keyword. A JSON Schema reference is an absolute or relative URI that points to a property in the current schema or an external schema. Relative references are resolved using the current document's location as the base URI. Paths inside `$ref` use JSON Pointer syntax (JSON Pointer is different from JSONPath, which is not part of JSON Schema).

The JSON Schema `$ref` can reference elements within the same schema or external schemas, or the path defined inside an object's `$id` field. By contrast, OpenAPI Reference Objects are focused on referencing components defined within the `components` section of an OpenAPI document and allow for overriding the `summary` and `description` metadata of the referenced component.

The `$id` field in JSON Schema provides a unique identifier for a schema that `$ref` can reference. The `$id` field must be a URI.

Most objects in a schema are themselves valid schemas and can thus have an `$id` field. Note that `$id`, not `id`, is a keyword in JSON schema and should be used for references.

## JSON Schema Reference Escape Characters

The `/` character separates segments in a JSON Pointer, for instance, `$ref: "#/components/schemas/Drink"`.

To refer to a property that contains the `/` character in its name, escape `/` in the `$ref` using `~1`. Since `~` is the escape character in paths, `~` must be escaped as `~0`.

For example, consider the JSON object below:

```json example.json
{"a/b": { "c~d": "value" }}
```

To create a pointer to `value`, you would need to use the string `/a~1b/c~0d`.

## Types of References in OpenAPI

References in OpenAPI can be relative or absolute. Relative references point to elements within the same API description, while absolute references point to elements in external documents. Absolute references can also point to external resources like online JSON files. Runtime expressions are another type of reference that allows for dynamic values during API execution.

| `$ref` string                       | Description                                                                                                    |
| ----------------------------------- | -------------------------------------------------------------------------------------------------------------- |
| `#/components/schemas/Drink`        | References the `Drink` schema in the `components` section of the current file.                                 |
| `./person.yaml`                     | References the entire `person.yaml` file. The entire content of `person.yaml` is used.                         |
| `../person.yaml`                    | References the `person.yaml` file in the parent directory. The entire content of `person.yaml` is used.        |
| `./people.yaml#/Person`             | References the `Person` schema in the `people.yaml` file. Only the `Person` schema from `people.yaml` is used. |
| `https://pastebin.com/raw/LAvtwJn6` | References an external schema stored online. The entire content of the external schema is used.                |
| `$request.path.orderId`             | A runtime expression that passes the `orderId` from the parent operation.                                      |


### Relative References in OpenAPI

Relative references specify a location based on the current document and are useful for referencing elements within the same API description.

In the example below, the reference points to the `Drink` schema defined within the `components` section of the current OpenAPI document:

```yaml openapi.yaml mark=9
paths:
  /order:
    post:
      summary: Place an order for a drink
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/Drink" # Relative reference to the Drink schema
```

### Absolute References in OpenAPI

Absolute references include a protocol like `http://` or `https://` followed by the rest of the URI.

The example below references an `Ingredient` component in a remote OpenAPI document:

```yaml openapi.yaml mark=13:14
paths:
  /drinks:
    get:
      summary: Get ingredients
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                type: array
                items:
                  # Absolute reference to an external schema
                  $ref: "https://speakeasy.bar/schemas/ingredients.yaml#/components/schemas/Ingredient"
```

### Runtime Expressions in OpenAPI

Runtime expressions allow for dynamically determining values during API execution. These expressions add flexibility and reduce the need for hard coding details in an API description.

Expressions in OpenAPI always begin with the dollar sign `$` and indicate the string that follows must be calculated from the HTTP request or response. To embed an expression in another string, wrap it in `{}`.

Runtime expressions are commonly used in [Link Objects](./paths/operations/responses/links.md#link-object) and [Callbacks Objects](./paths/operations/callbacks.md#callback-object) to pass dynamic values to linked operations or callbacks. An example is:

```yaml openapi.yaml mark=9
paths:
  /orders/{orderId}:
    get:
      # ...
    links:
      viewItems:
        operationId: getOrderItems
        parameters:
          orderId: $request.path.orderId # Pass orderId from the parent operation
```

## Additional Syntax

The following sections show some more advanced ways of using references to structure an API neatly.

As the basis of the examples to follow, the following `openapi.yaml` describes a single operation that takes a person's ID and returns their name:

```yaml openapi.yaml mark=5:25
openapi: 3.1.0
info:
  title: Person API
  version: 1.0.0
paths:
  /persons/{id}:
    get:
      parameters:
        - name: id
          in: path
          required: true
          schema:
            type: string
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                type: object
                properties:
                  id:
                    type: string
                  name:
                    type: string
```

### Local File References

The definition of the type that is returned can be moved into its own file so that other operations or other files can use it, too. The operation's `responses` object in `openapi.yaml` now has a `$ref` field:

```yaml openapi.yaml mark=7
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: 'person.yaml' # Reference to the person schema in a separate file
```

In this example, the `$ref` uses a relative path that points to the entire `person.yaml` file in the same folder with the following content:

```yaml person.yaml
type: object
properties:
  id:
    type: string
  name:
    type: string
```

### Online File References in OpenAPI

Schemas can be stored online, for example, in [Pastebin](https://pastebin.com). The reference in `openapi.yaml` can refer to the online `Person` definition:

```yaml openapi.yaml mark=7
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: "https://pastebin.com/raw/LAvtwJn6"
```

The content of the `Person` schema is stored in the Pastebin link `https://pastebin.com/raw/LAvtwJn6`:

```yaml https://pastebin.com/raw/LAvtwJn6
type: object
properties:
  id:
    type: string
  name:
    type: string
```

### Organize Schemas and Components in Files in OpenAPI

While it is common practice to define an OpenAPI document's schemas and components in a single file, a schema _may_ be split across multiple files using references.

In a JSON schema file containing multiple objects, the `Person` object might look like this:

```yaml people.yaml mark=1:7
Person:
  type: object
  properties:
    id:
      type: string
    name:
      type: string

Employee:
  ...

Student:
  ...
```

The `openapi.yaml` OpenAPI document can reference the `Person` schema from `people.yaml` using the filename and path:

```yaml openapi.yaml mark=7
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: "people.yaml#/Person"
```

### Nested References in OpenAPI

References can be nested so that a schema can reference another schema that references a third schema. In the example below, the `Person` schema references the `Address` schema, which in turn references the `Country` schema:

```yaml openapi.yaml mark=11,20
components:
  schemas:
    Person:
      type: object
      properties:
        id:
          type: string
        name:
          type: string
        address:
          $ref: "#/components/schemas/Address"
    Address:
      type: object
      properties:
        street:
          type: string
        city:
          type: string
        country:
          $ref: "#/components/schemas/Country"
    Country:
      type: string
```

### Circular References in OpenAPI

Circular references are valid in OpenAPI and useful to define recursive objects. In the example below, the `Person` component is redefined to have an array of children, with each child a circular reference to `Person`.

```yaml openapi.yaml mark=10:13
components:
  schemas:
    Person:
      type: object
      properties:
        id:
          type: string
        name:
          type: string
        children:
          type: array
          items:
            $ref: '#/components/schemas/Person'
```

Although tooling may pass a schema as syntactically valid, it could still be logically unusable. For example, code generation tools that generate SDKs or example requests and responses will fail when used on the schema below that has an infinitely recursive reference:

```yaml infinite-recursion.yaml
components:
  schemas:
    Person:
      $ref: '#/components/schemas/Human'
    Human:
      $ref: '#/components/schemas/Person'
```

### Composition in OpenAPI

The `$ref` keyword can be used to compose schemas of multiple objects.

Using composition in schemas is described in [`allOf`, `anyOf`, and `oneOf`](./schemas/objects/polymorphism.md).

The `$ref` keywords used in the examples in that explanation could be external file references instead of component references.

### Arrays and Objects in OpenAPI

The `$ref` keyword can be used to replace an entire array or individual items in the array.

However, some fields in an OpenAPI schema require each array item or object property to be referenced individually and the entire field may not be replaced with one `$ref`. The fields that must list each item separately are `servers`, `tags`, `paths`, `security`, `securitySchemes/scopes`, and `components`.

## Object Type Examples in OpenAPI

This section gives examples for all the places `$ref` can be used.

Objects referenced can be in a `components` section of the schema or a separate file. The first example below shows both options, the rest of the examples illustrate referencing objects in the `components` section only.

### Referencing Parameters in OpenAPI

The parameters for the operation `listDrinks`:

```yaml openapi.yaml
      parameters:
        - name: type
          in: query
          description: The type of drink to filter by. If not provided all drinks will be returned.
          required: false
          schema:
            $ref: "#/components/schemas/DrinkType"
```

The same schema with a reference to the `components` section:

```yaml openapi.yaml
      parameters:
        - $ref: '#/components/parameters/DrinkTypeParameter'
# ...
components:
  parameters:
    DrinkTypeParameter:
      name: type
      in: query
      description: The type of drink to filter by. If not provided all drinks will be returned.
      required: false
      schema:
        $ref: '#/components/schemas/DrinkType'
  schemas:
    DrinkType:
# ...
```

The schema using an external file reference instead of `components`:

```yaml openapi.yaml
      parameters:
        - $ref: 'parameters.yaml#/DrinkTypeParameter'
```

The contents of the referenced `parameters.yaml` file (note that the main schema file is referenced in turn from the `openapi.yaml` file):

```yaml parameters.yaml
DrinkTypeParameter:
  name: type
  in: query
  description: The type of drink to filter by. If not provided all drinks will be returned.
  required: false
  schema:
    $ref: 'openapi.yaml#/components/schemas/DrinkType'
```

### Referencing Request Bodies in OpenAPI

The `requestBody` for the operation `authenticate`:

```yaml openapi.yaml
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              properties:
                username:
                  type: string
                password:
                  type: string
```

The same schema using a reference to the `components` section:

```yaml openapi.yaml
      requestBody:
        $ref: '#/components/requestBodies/UserCredentials'
# ...
components:
  requestBodies:
    UserCredentials:
      required: true
      content:
        application/json:
          schema:
            type: object
            properties:
              username:
                type: string
              password:
                type: string
```

### Referencing Error Types in OpenAPI

All operations in the Bar schema already use references for error types:

```yaml openapi.yaml
      responses:
        "200":
          description: The api key to use for authenticated endpoints.
          content:
            application/json:
              schema:
                type: object
                properties:
                  token:
                    type: string
        "401":
          description: Invalid credentials provided.
        "5XX":
          $ref: "#/components/responses/APIError"
        default:
          $ref: "#/components/responses/UnknownError"
...
components:
  responses:
    APIError:
      description: An error occurred interacting with the API.
      content:
        application/json:
          schema:
            $ref: "#/components/schemas/APIError"
    UnknownError:
      description: An unknown error occurred interacting with the API.
      content:
        application/json:
          schema:
            $ref: "#/components/schemas/Error"
```

### Referencing Security Schemes in OpenAPI

Security schemes automatically reference `components` and do not need `$ref`:

```yaml openapi.yaml
paths
  /drinks:
    post:
      operationId: createDrink
      summary: Create a drink.
      description: Create a drink. Only available when authenticated.
      security:
        - apiKey: []
...
components:
  securitySchemes:
    apiKey:
      type: apiKey
      name: Authorization
      in: header
```

Referencing schemes in a separate file:

```yaml
components:
  securitySchemes:
    $ref: 'securitySchemes.yaml'
```

### Referencing Schema Examples in OpenAPI

In the `responses` section of the `listDrinks` operation, `examples` use `$ref`:

```yaml
      responses:
        "200":
          description: A list of drinks.
          content:
            application/json:
              schema:
                type: array
                items:
                  oneOf:
                    - $ref: "#/components/schemas/Drink"
                    - $ref: "#/components/schemas/PublicDrink"
                  discriminator:
                    propertyName: dataLevel
                    mapping:
                      unauthenticated: "#/components/schemas/PublicDrink"
                      authenticated: "#/components/schemas/Drink"
              examples:
                unauthenticated_drinks:
                  $ref: "#/components/examples/unauthenticated_drinks"
...
components:
  examples:
    unauthenticated_drinks:
      summary: A list of drinks for unauthenticated users
      value:
        [
          {
            "name": "Old Fashioned",
            "type": "cocktail",
            "price": 1000,
            "photo": "https://speakeasy.bar/drinks/old_fashioned.jpg",
            "dataLevel": "unauthenticated",
          },
          ...
        ]
```

The schemes in a separate file can be referenced like this:

```yaml
components:
  examples:
    $ref: 'examples.yaml'
```

### Discriminators in OpenAPI

[Discriminators](./schemas/objects/polymorphism.md#discriminator-object) can be used to differentiate between different schemas in a `oneOf` array.

The `mapping` object in a discriminator maps values to schemas. The references in these mappings are similar to the values used in `$ref`.

In the example below, the drinks returned by the `listDrinks` operation can be either `Cocktail` or `Beer`:

```yaml openapi.yaml mark=14:16
      responses:
        "200":
          description: A list of drinks.
          content:
            application/json:
              schema:
                type: array
                items:
                  oneOf:
                    - $ref: "#/components/schemas/Cocktail"
                    - $ref: "#/components/schemas/Beer"
                  discriminator:
                    propertyName: category
                    mapping:
                      cocktail: "#/components/schemas/Cocktail"
                      beer: "#/components/schemas/Beer"
```

## References Best Practices in OpenAPI

There are no syntactical or functional differences between a schema in one file or split into multiple files using `$ref`. But splitting a large schema into separate files implements the principle of modularity, which holds several advantages for users:

- Readability: Multiple shorter files with appropriate names are easier to navigate and understand than one massive file.
- Reusability: Multiple top-level schemas that are unrelated can reuse lower-level schemas stored in shared external files.
- Collaboration: Programmers can more easily edit smaller files in their area of focus in an API without version control conflicts.

A minor disadvantage of using multiple files is increased administration. Deployments need to carefully validate and distribute multiple files with interdependencies instead of just one file. The separate files may be stored in different locations on a network and have complicated URI resolutions, though this is usually unnecessary.

Given that splitting a schema into several files is beneficial, let's consider how to do it. Here are some principles to consider:

### Use External Files Sparingly

A potential downside of separating your OpenAPI documents into multiple files with references is that online validators can't validate multiple files at once. When using multiple documents, you can validate your OpenAPI schema using local validators. For example:

```sh
npx swagger-cli validate openapi.yaml
```

If both files are present and valid, the validator will return `openapi.yaml is valid`.

### Use Components When Necessary

Don't waste time on premature optimization or modularization. If you're using a type only once, don't bother moving it into components. But as soon as you use a type twice, use two `$ref` keywords in your main schema, and move the type definition down into `components`. Now if you want to split your file into multiple files, your types are already modules.

When should you break your `components` section into multiple files? Either when the file becomes too large to be easily readable, or when you start writing another API that reuses the same components as your original one.

### Design Versioning Carefully

It is important to specify the version number of your schemas so that customers can be certain they are calling the correct API for the code they have written. As well as having a version number in your YAML, you should also number your schema filenames or use Git release numbers:

```txt
├── schema-v1.yaml
├── schema-v2.yaml
```

When you split your schema into multiple files, it's easier to do versioning at the folder level:

```txt
├── api
    ├── v1
    |   ├── openapi.yaml
    |   └── person.yaml
    └── v2
        ├── openapi.yaml
        └── person.yaml
```

Even if only `openapi.yaml` changes when releasing a new version, and `person.yaml` remains the same, it is simpler to copy all files into the new version folder rather than referencing the old `person.yaml` from both `openapi.yaml` files. There is too much risk of making a change in one version of a file that breaks other files depending on it.

If multiple APIs share common components, versioning becomes more complex. Consider the example below.

```txt
├── api
|   ├── v1
|   |   ├── bar-schema.yaml
|   |   └── employee-schema.yaml
|   └── v2
|       ├── bar-schema.yaml
|       └── employee-schema.yaml
|
└── shared
    ├── v1
    |   └── person.yaml
    └── v2
        └── person.yaml
```

Two APIs, Bar and Employee, use the person schema kept in a shared folder. When version 1 of the person schema is updated for the Bar API, you need to either:
- The Employee API must be updated and a new version released. Since there have been no functional changes to the API, there is no benefit to customers updating their code that uses the API. This is a poor solution.
- The file should no longer be shared. Different versions of the `person.yaml` file should be moved into the Bar and Employee folders and deleted from the `shared` folder. This solution discards the modularity and reusability of shared files.
- The Bar API version 2 should point to the person schema version 2, and the Employee API version 1 should point to the person schema version 1.

The final solution makes the most sense, but is dangerous. You'll need to keep track of which versions of the APIs point to which version of the shared schema, and further changes to `person.yaml` version 1 could cause it to diverge from version 2, and you'll need to implement one of the three solutions above again.

Note that `$ref` has no version checking. You need to create your own scripts to validate the versioning system and folder structure your company decides to use.

### How To Structure Your Files

In general, choose filenames that match the file contents, such as `parameters.yaml`, `responses.yaml`, or `securitySchemes.yaml`. Group each type of object into a single file, such as `schemas`, `examples`, and so on.

A simple folder structure might look like this:

```txt
/api
  openapi.yaml
  /components
    schemas.yaml
    responses.yaml
    parameters.yaml
    examples.yaml
    security.yaml
  /paths
    users.yaml
    products.yaml
```

When referencing external files, use clear and relative paths that make it easy to understand where the referenced file is located relative to the current file. Don't chain references more than two levels. Deep nesting is difficult to understand.

Each file should be alphabetically structured to make finding elements easy.


 This is the content for the doc openapi/schemas.md 

 # Schema Object in OpenAPI

The Schema Object represents any data type used as input or output in OpenAPI. Data types can be objects, arrays, or primitives such as `string`, `number`, `integer`, and `boolean`.

Schema objects are sometimes referred to as _models_, _data types_, or simply, _schemas_. This is because schema types are used to model complex data types used by an API.

The Schema Object is based on and extends the [JSON Schema Specification Draft 2020-12](https://datatracker.ietf.org/doc/html/draft-bhutton-json-schema-00).

OpenAPI 3.1 uses all vocabularies from JSON Schema 2020-12, except for Format Assertion.

For an overview of all JSON Schema properties, see [JSON Schema Docs > JSON Schema 2020-12](https://www.learnjsonschema.com/2020-12/).

OpenAPI 3.1 changes the definition of two JSON Schema properties:

- `description` - In OpenAPI this property may contain [CommonMark syntax](https://spec.commonmark.org/) to provide a rich description.
- `format` - OpenAPI extends JSON Schema data types by adding additional formats. See [Data Type Formats](/openapi/schemas/dataTypes).

OpenAPI adds another vocabulary to JSON Schema with the following properties:

| Field Name           | Type                                                            | Description                                                                                                                                                                                            |
| -------------------- | --------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| `discriminator`      | [Discriminator Object](/openapi/schemas/objects/polymorphism#discriminator-object)                   | A discriminator object describes how to differentiate between related schemas based on the value of a field in a request or response. See [Composition and Inheritance](/openapi/schemas/objects/polymorphism). |
| `xml`                | [XML Object](/openapi/schemas/objects/xml)                                       | Adds details about how the schema should be represented as XML.                                                                                                                                        |
| `externalDocs`       | [External Documentation Object](/openapi/external-documentation) | Points to external documentation for this schema.                                                                                                                                                      |
| `example`            | Any                                                             | An example that satisfies this schema. **Deprecated:** Although valid, the use of `example` is discouraged. Use [Examples](/openapi/examples) instead.                                                         |
| `x-`                 | [Extensions](/openapi/extensions)                                       | Any number of extension fields can be added to the schema that can be used by tooling and vendors.                                                                                                     |
| Arbitrary properties | Any                                                             | The schema object supports arbitrary properties without the `x-` prefix. This is discouraged in favor of [Extensions](/openapi/extensions).                                                                    |

The example below illustrates three schema objects: `IngredientProductCode`, `Ingredient`, and `IngredientType`.

```yaml
components:
  schemas:
    IngredientProductCode:
      description: The product code of an ingredient, only available when authenticated.
      type: string
      examples:
        - "AC-A2DF3"
        - "NAC-3F2D1"
        - "APM-1F2D3"
    Ingredient:
      type: object
      properties:
        name:
          description: The name of the ingredient.
          type: string
          examples:
            - Sugar Syrup
            - Angostura Bitters
            - Orange Peel
        type:
          $ref: "#/components/schemas/IngredientType"
        stock:
          description: The number of units of the ingredient in stock, only available when authenticated.
          type: integer
          examples:
            - 10
            - 5
            - 0
          readOnly: true
        productCode:
          $ref: "#/components/schemas/IngredientProductCode"
        photo:
          description: A photo of the ingredient.
          type: string
          format: uri
          examples:
            - https://speakeasy.bar/ingredients/sugar_syrup.jpg
            - https://speakeasy.bar/ingredients/angostura_bitters.jpg
            - https://speakeasy.bar/ingredients/orange_peel.jpg
      required:
        - name
        - type
    IngredientType:
      description: The type of ingredient.
      type: string
      enum:
        - fresh
        - long-life
        - packaged
```

## JSON Schema and OpenAPI

OpenAPI 3.0 was not totally compatible with JSON schema. That caused, and continues to cause, issues in tooling support. Fortunately, OpenAPI 3.1 is now a superset of JSON Schema, meaning compatibility with any valid JSon Schema document.


 This is the content for the doc openapi/schemas/arrays.md 

 # array

The **array** type provides a way of defining a list of other types through providing an **items** attribute that represents the schema of the type contained in the array.

```yaml
# An array of string
schema:
    type: array
    items:
        type: string

# An array of objects
schema:
    type: array
    items:
        type: object
        properties:
            name:
                type: string
            age:
                type: integer

# An array of arbitrary things
schema:
    type: array
    items: {}
```

The **array** type will support any schema that describes any other type in its items attribute including types using **oneOf/anyOf/allOf** attributes. The **array** type also has some optional attributes for additional validation:

- **minItems** \- The minimum number of items the array must contain.
- **maxItems** \- The maximum number of items the array must contain.
- **uniqueItems** \- The array must contain only unique items.

```yaml
# An array of floats that must contain at least 1 element.
schema:
    type: array
    items:
        type: number
        format: float
    minItems: 1

# An array of strings that must contain at most 10 elements.
schema:
    type: array
    items:
        type: string
    maxItems: 10

# An array of booleans that must contain exactly 3 elements.
schema:
    type: array
    items:
        type: boolean
    minItems: 3
    maxItems: 3

# An array of strings that must contain only unique elements.
schema:
    type: array
    items:
        type: string
    uniqueItems: true
```


 This is the content for the doc openapi/schemas/booleans.md 

 # boolean

The boolean type is simple; it represents either **true** or **false**. Be aware that it doesn't support other truthy/falsy values like: **1** or **0**, an empty string “” or **null**. It has no additional attributes to control its format or validation.

```yaml
# A boolean type
schema:
    type: boolean
```


 This is the content for the doc openapi/schemas/dataTypes.md 

 # OpenAPI Data Types

The OpenAPI standard supports the following data types:

- [Strings](/openapi/schemas/strings) - A sequence of characters. (dates, times, passwords, byte, and binary data are considered strings)
- [Numbers](/openapi/schemas/numbers) - A number, either integer or floating-point.
- [Booleans](/openapi/schemas/booleans) - A true or false value.
- [Arrays](/openapi/schemas/arrays) - A collection of other data types.
- [Objects](/openapi/schemas/objects) - A collection of key-value pairs.
- [Enums](/openapi/schemas/enums) - A fixed list of possible values.
- [Null](/openapi/schemas/null) - A null value.


 This is the content for the doc openapi/schemas/enums.md 

 # Enums in OpenAPI

The OpenAPI Specification (OAS) version 3.x supports the `enum` (enumerated list) keyword for all `schemaObject` object properties, including parameters, request bodies, and responses. The OAS defines an `enum` according to the JSON Schema Specification. The `enum` keyword restricts the value of a JSON property to a fixed set of values. The value must be an array with at least one element and each element must be unique.

For example, the following code defines a property called `status` that must have a value of `pending`, `approved`, or `rejected`:

```json
{
  "type": "object",
  "properties": {
    "status": {
      "type": "string",
      "enum": ["pending", "approved", "rejected"]
    }
  },
  "required": ["status"]
}
```

Any JSON instance validated against this schema must have a `status` property with one of the three allowed values, case sensitive, or the validation will fail.

The `enum` keyword can be used with any JSON data type, including strings, numbers, objects, arrays, booleans, and the `null` type. The `enum` keyword is often used with the base `string` and `integer` types. The `boolean` type is constrained to `true` and `false` values and possibly `null` for a tri-state `boolean`. Using an `enum` with floating point number types typically doesn't make much sense.

Here is an OpenAPI schema defining a `status` parameter that must have a value of `pending`, `approved`, or `rejected`:

**YAML**

```yaml
parameters:
  status:
    in: query
    name: status
    required: true
    schema:
      type: string
      enum:
        - pending
        - approved
        - rejected
```

Any API request that includes this `status` parameter must have a value that is one of the three allowed values or the request will be rejected.

## Defaults

Use `default` to let clients omit a field when calling your service. For example, if a client orders a drink without specifying a cup size, they'll get a medium cup.

```yaml
openapi: 3.1.0
info:
  title: Bar API
  version: 1.0.0
paths:
  /orderDrink:
    post:
      operationId: orderDrink
      requestBody:
        content:
          application/json:
            schema:
              type: object
              properties:
                cupSize:
                  type: string
                  enum:
                    - small
                    - medium
                    - large
                  default: medium
      responses:
        "200":
          description: Order placed successfully
```

If you use `default`, remember to omit `required: true` from the field.

## Enums With Names and Values

A common requirement using enums is to specify a human-readable name for the enum label and an integer for the enum value. For example, in C#:

```c#
public enum CupSize
{
    SMALL = 10
    MEDIUM = 20
    LARGE = 50
}
```

This is not possible using the `enum` keyword in OpenAPI, as OpenAPI enums allow only a list of values. If you want your schema's enums to have both names and values, you can combine `oneOf` and `const`. This works only in OpenAPI version 3.1 and later. OpenAPI version 3.0 does not support `const`.

Below is an example where a client can order a drink with one of three cup sizes:

```yaml
openapi: 3.1.0
info:
  title: Bar API
  version: 1.0.0
paths:
  /orderDrink:
    post:
      summary: Order a drink with a specified cup size
      operationId: orderDrink
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              properties:
                cupSize:
                  $ref: "#/components/schemas/CupSize"
      responses:
        "200":
          description: Order placed successfully
components:
  schemas:
    CupSize:
      description: Size of the cup to order, represented by a code and label.
      oneOf:
        - description: Small cup size
          type: object
          properties:
            size:
              type: integer
              const: 10
            label:
              type: string
              const: "Small"
        - description: Medium cup size
          type: object
          properties:
            size:
              type: integer
              const: 20
            label:
              type: string
              const: "Medium"
        - description: Large cup size
          type: object
          properties:
            size:
              type: integer
              const: 50
            label:
              type: string
              const: "Large"
```

Below is an example call to this API:

```json
{
  "cupSize": {
    "size": 20,
    "label": "Medium"
  }
}
```

In this `oneOf` solution, the client has to supply the label and the value, defeating the purpose of using an enum, where the label serves as a human-readable alias for the actual value. This `oneOf` solution illustrates your options for including exact values. You'll need to decide in your design whether you want a simple `enum` or a more descriptive `oneOf`.

If you are using OpenAPI 3.0 or want to use `enum`, you can use an extension attribute to give labels to enum values. Different code generators and OpenAPI tools use different extension names. Below is an example using the Speakeasy extension field:

```yaml
components:
  schemas:
    CupSize:
      description: Size of the cup to order, represented by a numeric code with a corresponding label.
      type: integer
      enum:
        - 10
        - 20
        - 50
      x-speakeasy-enums:
        - Small
        - Medium
        - Large
```

Or you can use a simple text description to prioritize human understanding over tooling support:

```yaml
components:
  schemas:
    CupSize:
      type: integer
      enum:
        - 10
        - 20
        - 50
      description: Small Medium Large
```

## Constants for Single Value Enums

Before JSON Schema 2019 was included in OpenAPI 3.1, using an enum with a single value was the only way to specify a constant. If you are still using OpenAPI 3.0, the example below shows how to specify that a constant string is returned in a response:

```yaml
openapi: 3.0.0
info:
  title: Bar API
  version: 1.0.0
paths:
  /orderDrink:
    get:
      operationId: orderDrink
      responses:
        "200":
          description: Get a drink
          content:
            application/json:
              schema:
                enum:
                  - Here is your beverage
```

When using OpenAPI 3.1, you can use the `const` keyword whose name more clearly matches its intention than `enum` does:

```yaml
openapi: 3.1.0
info:
  title: Bar API
  version: 1.0.0
paths:
  /orderDrink:
    get:
      operationId: orderDrink
      responses:
        "200":
          description: Get a drink
          content:
            application/json:
              schema:
                const: Here is your beverage
```

## Nullable Enums

### OpenAPI 3.0

In OpenAPI 3.0 you can use the `nullable` keyword to specify `null` as an accepted value in an enum. In the example below, a client can order a drink with one of three cup sizes or no cup size specified at all:

```yaml
# !focus(6)
components:
  schemas:
    CupSize:
      description: Size of the cup to order, represented by a numeric code with a corresponding label.
      type: string
      nullable: true
      enum:
        - SMALL
        - MEDIUM
        - LARGE
```

### OpenAPI 3.1

OpenAPI 3.1 more closely aligns with the JSON Schema standard. As a result, the way to specify nullable types differs from OpenAPI 3.0. Instead of using the `nullable` attribute, OpenAPI 3.1 uses the JSON Schema approach with an array of types - including the `null` type. Here's the same example adapted for OpenAPI 3.1:

```yaml
# !focus(5,10)
components:
  schemas:
    CupSize:
      description: Size of the cup to order, represented by a numeric code with a corresponding label.
      type: [string, null]
      enum:
        - SMALL
        - MEDIUM
        - LARGE
        - null
```

## Open Enums

Traditionally enums are closed, meaning that only the values listed in the enum are allowed. In contrast, open enums allow additional values beyond those explicitly defined in the spec. Open Enums are useful when your API is evolving to support new use cases. In that scenario, you can let clients send values that aren't defined yet because their usage is on the edge of your API's capabilities.

OpenAPI 3.x currently does not natively support the description open enums directly. However, check if your tooling supports `x-` extension attributes. For example, [the Speakeasy extension `x-speakeasy-unknown-values`](/docs/customize-sdks/enums#open-vs-closed-enums) lets you define an enum with additional values beyond those listed.

```yaml
# !focus(6)
components:
  schemas:
    CupSize:
      description: Size of the cup to order, represented by a numeric code with a corresponding label.
      type: [string, null]
      x-speakeasy-unknown-values: allow
      enum:
        - SMALL
        - MEDIUM
        - LARGE
        - null
```

## Examples

Below is an example from the `components` of an API for ordering drinks showing all the different data types you can use with `enum`:

```yaml
components:
  schemas:
    Orders:
      type: object
      properties:
        cupSize:
          type: string
          enum:
            - small
            - medium
            - large
        sugarNumbers:
          type: integer
          enum:
            - 0
            - 1
            - 2
            - 3
        strength:
          type: number
          enum:
            - 0.25
            - 0.5
            - 0.75
            - 1.0
        decaffeinated:
          type: boolean
          enum:
            - true
            - false
        teaOrigin:
          type: object
          enum:
            - { country: India, region: Assam, address: { name: "The farm" } }
            - { country: China, region: Fujian }
            - { country: Japan, region: Shizuoka }
            - { country: Sri Lanka, region: Nuwara Eliya }
        sizeRange:
          type: array
          enum:
            - [1, 10]
            - [11, 20]
```

Date objects are not directly supported. Export your dates to ISO strings before using them in an API.

## Best Practices

Enums are simple, so there are only a few things to consider when using them in your schema:

- **Naming conventions**: Be consistent throughout your schema. If you use uppercase, like `NEW`, then stick to uppercase for all values in all enums.
- **Document values**: Ensure that your description field explains exactly what the purpose of each enum value is. If two values are similar, differentiate them carefully. A few extra explanatory lines in your schema can save you days of customer support queries.
- **Plan for extension**: Have you designed your schema and your server to easily adapt to adding new values to an enum? How much work will clients have to do to use the new values? What about removing values or renaming them? Consider how this affects the versioning of your API and you will explain it to clients.
- **Tool support**: Which tools, such as code generators, will you use with your schema? Do they support `enum` and `const`? Do they require extension attributes? Research this before writing your schema.
- **Default value**: Provide default values for enums with an obvious default, but avoid them where you need the client to consider their choice. For example, for an API that creates a web server, you would want the client to think carefully about the server size as it costs the client money. In comparison, operating system versions can default to the latest version without the same level of ramifications.


 This is the content for the doc openapi/schemas/null.md 

 # null

## OpenAPI 3.0.X

OpenAPI 3.0.X doesn't support a `null` type but instead allows you to mark a schema as being `nullable`. This allows that type to either contain a valid value or null.  

```yaml
# A nullable string
schema:
    type: string
    nullable: true

# A nullable integer
schema:
    type: integer
    format: int32
    nullable: true

# A nullable boolean
schema:
    type: boolean
    nullable: true

# A nullable array
schema:
    type: array
    items:
        type: string
    nullable: true

# A nullable object
schema:
    type: object
    properties:
        foo:
            type: string
    nullable: true
```

## OpenAPI 3.1.X

OpenAPI 3.1 aligned describing `null` with JSON Schema. This allows for more precise API definitions, especially for APIs that need to explicitly support null values as valid inputs or outputs.

To specify that a property, item, or response can be `null`, you can use the `type` keyword with a value of `null` or combine null with other types using the `oneOf` or type array syntax. This flexibility makes it easier to accurately model your data.

```yaml
# A nullable string using array syntax
schema:
    type: [ 'null', 'string' ]

# A nullable field using an array
schema:
    type: object
    properties:
        foo:    
            type: ['null', 'string']

# A nullable field using oneOf
schema:
    type: object
    properties:
        foo:    
            oneOf:
                - type: null
                - type: string
```


 This is the content for the doc openapi/schemas/numbers.md 

 # numbers and integers

The **number/integer** types allows the describing of various number formats through a combination of the **type** and **format** attribute, along with a number of attributes for validating the data, the spec should cover most use cases.  
  
Available formats are:

| Type | Format | Explanation | Example |
| --- | --- | --- | --- |
| number |     | Any number integer/float at any precision. | **10** or **1.9** or **9223372036854775807** |
| number | float | 32-bit floating point number. | **1.9** |
| number | double | 64-bit floating point number. | **1.7976931348623157** |
| integer |     | Any integer number. | **2147483647** or **9223372036854775807** |
| integer | int32 | 32-bit integer. | **2147483647** |
| integer | int64 | 64-bit integer. | 9223372036854775807 |

Below are some examples of defining **number/integer** types:

```yaml
# Any number
schema:
    type: number

# A 32-bit floating point number
schema:
    type: number
    format: float

# A 64-bit floating point number
schema:
    type: number
    format: double

# Any integer
schema:
    type: integer

# A 32-bit integer
schema:
    type: integer
    format: int32

# A 64-bit integer
schema:
    type: integer
    format: int64
```

Various tools may treat a **number/integer** without a format attribute as a type capable of holding the closest representation of that number in the target language. For example, a **number** might be represented by a **double,** and an **integer** by an **int64.** Therefore, it's recommended that you **be explicit with the format of your number type and always populate the format attribute**.

The **number** type also has some optional attributes for additional validation:

- **minimum** \- The **minimum** inclusive number the value should contain.
- **maximum** \- The **maximum** inclusive number the value should contain.
- **exclusiveMinimum** \- Make the **minimum** number exclusive.
- **exclusiveMaximum** \- Make the **maximum** number exclusive.
- **multipleOf** \- Specify the **number/integer** is a multiple of the provided value.

Some examples are below:

```yaml
# An integer with a minimum inclusive value of 0
schema:
    type: integer
    format: int32
    minimum: 10

# An integer with a minimum exclusive value of 0
schema:
    type: integer
    format: int32
    minimum: 0
    exclusiveMinimum: true

# A float with a range between 0 and 1
schema:
    type: number
    format: float
    minimum: 0
    maximum: 1

# A double with an exclusive maximum of 100
schema:
    type: number
    format: double
    maximum: 100
    exclusiveMaximum: true

# An 64 but integer that must be a multiple of 5
schema:
    type: integer
    format: int64
    multipleOf: 5
```


 This is the content for the doc openapi/schemas/objects.md 

 # object

The **object** type allows simple and complex objects, dictionaries and free form objects, along with a number of attributes to control validation.

## Fully typed object

Fully typed objects can be described by providing a properties attribute that lists each property of the object and its associated type.

```yaml
# A fully typed object
schema:
    type: object
    properties:
        name:
            type: string
        age:
            type: integer
            format: int32
        active:
            type: boolean

# A fully typed object with a nested object
schema:
    type: object
    properties:
        name:
            type: string
        age:
            type: integer
            format: int32
        active:
            type: boolean
        address:
            type: object
            properties:
                street:
                    type: string
                city:
                    type: string
                state:
                    type: string
                zip:
                    type: string
```

Objects with properties have access to some additional attributes that allow the objects to be validated in various ways:

- **required** \- A list of properties that are required. Specified at the object level.
- **readOnly** \- A property that is only available in a response.
- **writeOnly** \- A property that is only available in a request.

```yaml
# A fully typed object with all fields required
schema:
    type: object
    properties:
        name:
            type: string
        age:
            type: integer
            format: int32
        active:
            type: boolean
    required:
        - name
        - age
        - active

# A fully typed object with only one field required
schema:
    type: object
    properties:
        name:
            type: string
        age:
            type: integer
            format: int32
        active:
            type: boolean
    required:
        - name

# A fully typed object with some field as read only
schema:
    type: object
    properties:
        name:
            type: string
        age:
            type: integer
            format: int32
        active:
            type: boolean
            readOnly: true # This field is only returned in a response
    required:
        - name
        - age
        - active # This field will only be required in a response

# A fully typed object with some field as write only
schema:
    type: object
    properties:
        name:
            type: string
        age:
            type: integer
            format: int32
        active:
            type: boolean
        isHuman:
            type: boolean
            writeOnly: true # This field is only required in a request
    required:
        - name
        - age
        - active
        - isHuman # This field will only be required in a request
```

## Using Object for Dictionaries

The **object** type can also be used to describe dictionaries/maps/etc that use strings for keys and support any value type that can be described by the OpenAPI Spec.

```yaml
# A dictionary of string values
schema:
    type: object
    additionalProperties:
        type: string

# A dictionary of objects
schema:
    type: object
    additionalProperties:
        type: object
        properties:
            name:
                type: string
            age:
                type: integer
                format: int32
```

You can also describe dictionaries that will contain certain keys

```yaml
# A dictionary that must contain at least the specified keys 
schema:
    type: object
    properties:
        name:
            type: string # Must match type of additionalProperties
    required:
        - name        
    additionalProperties:
        type: string
```

When using the **additionalProperties** attribute you can also specify additional attributes to validate the number of properties in the object:

- **minProperties** \- The minimum number of properties allowed in the object.
- **maxProperties** \- The maximum number of properties allowed in the object.

For example:

```yaml
# A dictionary of string values that has at least one key.
schema:
    type: object
    additionalProperties:
        type: string
    minProperties: 1

# A dictionary of string values that has at most 10 keys.
schema:
    type: object
    additionalProperties:
        type: string
    maxProperties: 10

# A dictionary of string values that has 1 key.
schema:
    type: object
    additionalProperties:
        type: string
    minProperties: 1
    maxProperties: 1
```

## Free form objects

The **object** type can also be used to describe any arbitrary key/value pair (where the keys are still required to be strings).

```yaml
# An arbitrary object/dictionary that can contain any value.
schema:
    type: object
    additionalProperties: true

# An alternate way to specify an arbitrary object/dictionary that can contain any value.
schema:
    type: object
    additionalProperties: {}
```

 This is the content for the doc openapi/schemas/objects/polymorphism.md 

 # Composition and Inheritance in OpenAPI

OpenAPI allows us to combine object schemas using the keywords `allOf`, `anyOf`, and `oneOf`.

These keywords correspond to the following logical operators:

| Keyword | Operator | Description                                                                      | How to use                                                |
| ------- | -------- | -------------------------------------------------------------------------------- | --------------------------------------------------------- |
| `oneOf` | `XOR`    | An exclusive disjunction. Instances must satisfy **exactly one of** A, B, or C.  | Use for describing Union Types         |
| `allOf` | `AND`    | A union of all subschemas. Instances must satisfy **all of** A, B, and C.        | Use for describing model composition: the creation of complex schemas via the composition of simpler schemas. |
| `anyOf` | `OR`     | An inclusive disjunction. Instances must satisfy **at least one of** A, B, or C. | There is no established convention about how anyOf should be interpreted. **Use with extreme caution**        |

The example below illustrates the different composition keywords:

```yaml
components:
  schemas:
    # ... Other schemas ...
    Negroni:
      description: A Negroni cocktail. Contains gin, vermouth and campari.
      allOf:
        - $ref: "#/components/schemas/Vermouth"
        - $ref: "#/components/schemas/Gin"
        - $ref: "#/components/schemas/Campari"
    Martini:
      description: A Martini cocktail. Contains gin and vermouth, or vodka and vermouth.
      oneOf:
        - $ref: "#/components/schemas/Vodka"
        - $ref: "#/components/schemas/Gin"
      - $ref: "#/components/schemas/Vermouth"
    Punch:
      description: A Punch cocktail. Contains any combination of alcohol.
      anyOf:
        - $ref: "#/components/schemas/Rum"
        - $ref: "#/components/schemas/Brandy"
        - $ref: "#/components/schemas/Whisky"
        - $ref: "#/components/schemas/Vodka"
        - $ref: "#/components/schemas/Gin"
```

## Discriminator Object in OpenAPI

When using `oneOf` to indicate that a request body or response contains exactly one of multiple [Schema Objects](/openapi/schemas), a discriminator object can help the client or server figure out which schema is included in the request or response.

The discriminator object in OpenAPI tells a client or server which field can be used to discriminate between different schemas.

| Field          | Type                      | Required | Description                                                                                                      |
| -------------- | ------------------------- | -------- | ---------------------------------------------------------------------------------------------------------------- |
| `propertyName` | String                    | ✅       | The property name used to discriminate between schemas.                                                          |
| `mapping`      | Map[string, string]       |          | An optional map of values and schema reference strings.                                                          |
| `x-*`          | [Extensions](/openapi/extensions) |          | Any number of extension fields can be added to the discriminator object that can be used by tooling and vendors. |

In the example below, the Speakeasy Bar can receive one of two order types: A drink order with a bar-counter reference or an ingredient order with a delivery address:

```yaml
components:
  responses:
    OrderResponse:
      oneOf:
        - $ref: "#/components/schemas/DrinkOrder"
        - $ref: "#/components/schemas/IngredientOrder"
```

If we include a discriminator object, the client can indicate the order type so that the server does not need to figure that out:

```yaml
components:
  responses:
    OrderResponse:
      oneOf:
        - $ref: "#/components/schemas/DrinkOrder"
        - $ref: "#/components/schemas/IngredientOrder"
      discriminator:
        propertyName: orderType
```

In the previous example, the value of the `orderType` property will determine the order type. The value of `orderType` must match one of the schema components, so must be either `DrinkOrder` or `IngredientOrder`.

To use values that don't match a schema key, a discriminator object can include a `mapping` property that maps values to schemas. Here's an example:

```yaml
components:
  responses:
    OrderResponse:
      oneOf:
        - $ref: "#/components/schemas/DrinkOrder"
        - $ref: "#/components/schemas/IngredientOrder"
      discriminator:
        propertyName: orderType
        mapping:
          drink: "#/components/schemas/DrinkOrder"
          ingredient: "#/components/schemas/IngredientOrder"
```

 This is the content for the doc openapi/schemas/objects/xml.md 

 # XML Object in OpenAPI

The XML Object allows us to add details about how the schema should be represented as XML.

This is useful because XML has different data types and structures compared to JSON.

For example, in JSON, an array is a list of values only, while in XML, array values are represented as elements with names.

| Field       | Type                      | Required | Description                                                                                                                                                                                                                 |
| ----------- | ------------------------- | -------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `name`      | String                    |          | The name of the element when the property is represented in XML. When used in `items`, the name applies to each element in the XML array.                                                                                   |
| `namespace` | String                    |          | The absolute URL of the XML namespace.                                                                                                                                                                                      |
| `prefix`    | String                    |          | A prefix for the element's name.                                                                                                                                                                                            |
| `attribute` | Boolean                   |          | Whether the property should be represented as an XML attribute (`<drink id="3" />`) instead of an XML element (`<drink><id>3</id></drink>`). Defaults to `false`, so each property is represented as an element by default. |
| `wrapped`   | Boolean                   |          | Whether array elements should be wrapped in a container element. Defaults to `false`, so array elements are not wrapped by default. Only applies to arrays.                                                                 |
| `x-*`       | [Extensions](/openapi/extensions) |          | Any number of extension fields can be added to the XML object that can be used by tooling and vendors.                                                                                                                      |

The examples below illustrate how XML Objects can be used:

```yaml
components:
  schemas:
    Drink:
      type: object
      properties:
        name:
          type: string
          xml:
            name: drinkName
            namespace: http://speakeasy.bar/schemas
            prefix: se
        ingredients:
          type: array
          items:
            $ref: "#/components/schemas/Ingredient"
          xml:
            name: ingredients
            wrapped: true
            namespace: http://speakeasy.bar/schemas
            prefix: se
    Ingredient:
      type: object
      properties:
        id:
          type: number
          xml:
            name: ingredientId
            namespace: http://speakeasy.bar/schemas
            prefix: se
            attribute: true
        name:
          type: string
          xml:
            name: ingredientName
            namespace: http://speakeasy.bar/schemas
            prefix: se
```

The example above translates to the following XML example:

```xml
<se:drink xmlns:se="http://speakeasy.bar/schemas">
  <se:drinkName>Mojito</se:drinkName>
  <se:ingredients>
    <se:ingredient se:id="1">
      <se:ingredientName>Sugar</se:ingredientName>
    </se:ingredient>
    <se:ingredient se:id="2">
      <se:ingredientName>Lime</se:ingredientName>
    </se:ingredient>
    <se:ingredient se:id="3">
      <se:ingredientName>Mint</se:ingredientName>
    </se:ingredient>
  </se:ingredients>
</se:drink>
```

 This is the content for the doc openapi/schemas/strings.md 

 # strings

Of the primitive types (ignoring the **object** type) , the **string** type is the most flexible type available. In addition to being able to be used to represent other types (such as “true”, “100”, “{\\“some\\”: \\”object\\”}”), it supports a number of formats that overlay constraints to the type of data represented. This is useful for mapping to types in various languages if you are using the OpenAPI spec for code generation.

## Formats

The string type via the OpenAPI Specification officially supports the below formats:

| Type   | Format    | Explanation                                                                                 | Example                                                |
| ------ | --------- | ------------------------------------------------------------------------------------------- | ------------------------------------------------------ |
| string | date      | An [RFC3339](https://www.rfc-editor.org/rfc/rfc3339#section-5.6) formatted date string      | “2022-01-30”                                           |
| string | date-time | An [RFC3339](https://www.rfc-editor.org/rfc/rfc3339#section-5.6) formatted date-time string | “2019-10-12T07:20:50.52Z”                              |
| string | password  | Provides a hint that the string may contain sensitive information.                          | “mySecretWord1234”                                     |
| string | byte      | Base-64 encoded data.                                                                       | “U3BlYWtlYXN5IG1ha2VzIHdvcmtpbmcgd2l0aCBBUElzIGZ1biE=” |
| string | binary    | Binary data, used to represent the contents of a file.                                      | “01010101110001”                                       |

The **format** attribute can also be used to describe a number of other formats the string might represent but outside the official list above, those formats might not be supported by tooling that works with the OpenAPI Spec, meaning that they would be provided more as hints to end-users of the API:

- email
- uuid
- uri
- hostname
- ipv4 & ipv6
- and others

Below are some examples of describing various string types:

```yaml
# A basic string
schema:
    type: string

# A string that represents a RFC3339 formatted date-time string
schema:
    type: string
    format: date-time

# A string that represents a enum with the specified values
schema:
    type: string
    enum:
      - "one"
      - "two"
      - "three"

# A string that represents a file
schema:
    type: string
    format: binary
```

## Patterns

The **string** type also has an associated **pattern** attribute that can be provided to define a regular expression that should be matched by any string represented by that type. **The format of the regular expression is based on** [**Javascript**](https://262.ecma-international.org/5.1/#sec-15.10.1) and therefore could describe regular expressions that might not be supported by various tools or target languages, so **make sure to check the compatibility with your intended targets**.

Example of a string defined with a regex pattern:

```yaml
# A string that must match the specified pattern
schema:
  type: string
  pattern: ^[a-zA-Z0-9_]*$
```


 This is the content for the doc openapi/security.md 

 # OpenAPI Security 

When designing an API, it is important to consider the security requirements for accessing the API. OpenAPI 3.1 provides a way to define security requirements at both the document and operation levels. 

Security requirements are defined as a list of [Security Requirement Objects](/openapi/security#security-requirement-object) in the `security` section. Each object in the list represents a set of security requirements that must be satisfied to access the API.

To add security to an API as a whole, the `security` keyword must be defined at the [document](/openapi#openapi-document-structure) level.

Likewise, to add security to a specific operation, the `security` keyword must be defined at the [operation](/openapi/paths/operations) level.

Security requirements defined at the operation level override the security requirements defined at the document level.

If not provided at the document level, the default security requirements are assumed to be `[]`, an empty array, meaning no security is required to access the API.

The following example requires an API key to access the API:

```yaml
security:
  - apiKey: []
components:
  securitySchemes:
    apiKey:
      type: apiKey
      name: Authorization
      in: header
```

In valid OpenAPI 3.1, the [Security Requirement Objects](/openapi/security#security-requirement-object) listed in `security` sections may only reference [Security Scheme Objects](/openapi/security/security-schemes) that are defined in the [Components Object](/openapi/components) under the `securitySchemes` field. In other words, the `security` section may not contain inline security schemes, and it may not contain security schemes that are not defined yet.

## Security Requirement Object

A Security Requirement Object defines a map of security scheme names to [scopes or roles](#security-requirement-scopes-or-roles) that are required to access the API. The names **_must_** match the names of [Security Scheme Objects](/openapi/security/security-schemes) defined in the [Components Object](/openapi/components) under the `securitySchemes` field.

| Field                  |      Type      | Required | Description                                                                                                                                                                                                                                                                                                                                                  |
| ---------------------- | :------------: | :------: | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| `{securitySchemeName}` | List\<string\> |          | A list of [scopes or roles](#security-requirement-scopes-or-roles) required for the security scheme. If the security scheme type is `oauth2` or `openIdConnect`, this is a list of scope names required by the API consumer to be able to access or use the API. For any other type, this could contain a list of roles or similar required for the API consumer to obtain to authenticate with the API. |

## Supported Security Schemes in OpenAPI

Before referencing a [Security Scheme](./security/security-schemes.md) as a requirement in the `security` section, it must be defined in the [Components Object](/openapi/components) under the `securitySchemes` field.

OpenAPI 3.1 supports the following security schemes:

- [API Key](./security/security-schemes/security-api-key.md)
- [Basic HTTP](./security/security-schemes/security-basic.md)
- [Bearer Token](./security/security-schemes/security-bearer.md)
- [OAuth 2.0](./security/security-schemes/security-oauth2.md)
- [OpenID Connect](./security/security-schemes/security-openid.md)
- Digest
- Mutual TLS

## Expressing Security Requirements in OpenAPI

The `security` keyword can be used in the following ways to express security requirements.

### Disabling Security in OpenAPI

Security can be _disabled_ for a specific operation by providing an empty array (`[]`) in the list of security requirements.

In this example, the `POST` operation in the `/auth` path does not require security:

```yaml
paths:
  /auth:
    post:
      operationId: authenticate
      summary: Authenticate with the API
      security: [] # Disable security for this operation
      # ...
```

### Optional Security

Security can also be made optional by providing an empty object (`{}`) in the list of security requirements.

In this example, the API may be accessed with or without an API key:

```yaml
security:
  - apiKey: []
  - {}
```

### Adding Optional Security to a Specific Operation 

Security can be made _optional_ for a specific operation by providing an empty object (`{}`) in the list of security requirements.

This does not disable the security requirements defined at the document level, but makes them optional for this specific operation.

In this example, the `GET` operation in the `/drinks` path _may_ be accessed with or without an API key, but if authenticated, the response will include additional information:

```yaml
paths:
  /drinks:
    get:
      operationId: listDrinks
      summary: Get a list of drinks, if authenticated this will include stock levels and product codes otherwise it will only include public information
      security:
        - {} # Make security optional for this operation
      # ...
```

### Allowing a Choice of Security Schemes

To allow users to choose between multiple different security requirements, define the `security` keyword as a list of [Security Requirement Objects](/openapi/security#security-requirement-object). The API consumer can choose one of the requirements to authenticate.

In this example, the API may be accessed with an API key **OR** OAuth 2.0:

```yaml
security: # apiKey OR oauth2 can be used
  - apiKey: []
  - oauth2:
      - read
      - write
```

### Requiring Multiple Security Schemes Together

If multiple schemes are required together, then the [Security Requirement Object](/openapi/security#security-requirement-object) should be defined with multiple security schemes.

In this example, both an API key **AND** basic auth are required to access the API:

```yaml
security: # both apiKey AND basic is required
  - apiKey: []
    basic: []
```

### Complex Authorization Scenarios

This **AND**/**OR** logic along with optional (`{}`) security can be used in any combination to express complex authorization scenarios.

In this example, the API may be accessed with an API key **AND** OAuth 2.0 **OR** with basic authentication:

```yaml
security: # apiKey AND oauth2 OR basic
  - apiKey: []
    oauth2:
      - read
      - write
  - basic: []
```

## Security Requirement Scopes or Roles in OpenAPI

When defining an OAuth 2.0 or OpenID Connect [Security Requirement Object](/openapi/security#security-requirement-object) for an operation, the `{securitySchemeName}` field should contain a list of scopes or roles required for the security scheme.

For example, the following security requirement object requires the `read` and `write` scopes for the `oauth2` security scheme:

```yaml
paths:
  /drinks:
    get:
      operationId: listDrinks
      summary: Get a list of drinks
      # Operation requires read and write scopes
      security:
        - oauth2:
            - read
            - write
      # ...
```


 This is the content for the doc openapi/security/security-schemes.md 

 # Security Scheme Objects in OpenAPI

Security scheme objects are defined in the [Components Object](../components.md) under the `securitySchemes` field. Each security scheme object has a unique key. [Security Requirement Objects](../security.md#security-requirement-object) elsewhere in the document reference security scheme objects by their keys.

The following example requires a basic authentication scheme to access the `/drinks` endpoint:

```yaml
paths:
  /drinks:
    get:
      security:
        - MyScheme17: []
components:
  securitySchemes:
    MyScheme17:
      type: http
      scheme: basic
```

The `type` field is the overall category of authentication. The value of `type` determines the other fields the security object needs.

To decide which authentication type to choose, see our article [OpenAPI Tips - How to Handle Auth](/post/openapi-tips-auth).

## OpenAPI-Supported Authentication Types

The following authentication types are supported in the OpenAPI Specification:

- [API Key](/openapi/security/security-schemes/security-api-key)
- [Basic HTTP](/openapi/security/security-schemes/security-basic)
- [Bearer Token](/openapi/security/security-schemes/security-bearer)
- [OAuth 2.0](/openapi/security/security-schemes/security-oauth2)
- [OpenID Connect](/openapi/security/security-schemes/security-openid)
- Digest
- Mutual TLS

## OpenAPI Example Security Scheme Schema

Below is an example security schemes object with every possible field besides extensions.

```yaml
components:
  securitySchemes:
    # apiKey ------------
    auth1:
      description: Recommended authenticator
      type: apiKey
      in: query
      name: key

    auth2:
      type: apiKey
      in: header
      name: X-API-Key

    auth3:
      type: apiKey
      in: cookie
      name: key

    # http ------------
    auth4:
      type: http
      scheme: basic

    auth5:
      type: http
      scheme: bearer
      bearerFormat: JWT

    auth6:
      type: http
      scheme: digest # not supported by Speakeasy

    # mutualTLS ------------
    auth7:
      type: mutualTLS # not supported by Speakeasy

    # openIdConnect ------------
    auth8:
      type: openIdConnect
      openIdConnectUrl: https://example.com/openidconfig.json

    # oauth2 ------------
    auth9:
      type: oauth2
      flows:
        authorizationCode:
          scopes:
            read: Grants read access
            write: Grants write access
          authorizationUrl: https://test.com/oauth/authorize
          tokenUrl: https://test.com/oauth/token
          refreshUrl: https://test.com/oauth/refresh
        clientCredentials:
          scopes:
            read: Grants read access
            write: Grants write access
          tokenUrl: https://test.com/oauth/token
          refreshUrl: https://test.com/oauth/refresh
        implicit:
          scopes:
            read: Grants read access
            write: Grants write access
          authorizationUrl: https://test.com/oauth/authorize
          refreshUrl: https://test.com/oauth/refresh
        password:
          scopes:
            read: Grants read access
            write: Grants write access
          tokenUrl: https://test.com/oauth/token
          refreshUrl: https://test.com/oauth/refresh
```


 This is the content for the doc openapi/security/security-schemes/security-api-key.md 

 # API Key Security Scheme in OpenAPI

An API Key security scheme is the most common form of authentication for machine-to-machine APIs and supports passing a pre-shared secret in several ways. The secret can be passed either via the Authorization header (or another custom header), as a query parameter, or via a cookie.

While this is probably the most commonly used mechanism, it is generally one of the least secure. This is especially true if the key is passed outside of headers or cookies (that is, via query params, as various logging mechanisms normally store query param information).

The biggest security flaw is that most pre-shared secrets are long-lived and if intercepted, can be used until they are either revoked or expire (generally in months or years). This risk is normally tolerated for machine-to-machine applications as the chance of interception (especially when using private VPCs/TLS and other mechanisms) is relatively low compared to a key from a user’s device traveling on a public network.

The fields for an API Key security scheme are as follows:

| Field         | Type                              | Required | Description                                                                                                                                                                           |
| ------------- | --------------------------------- | -------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `type`        | String                            | ✅       | `apiKey`                                                                                                                                                                              |
| `description` | String                            |          | Human-readable information. This may contain [CommonMark syntax](https://spec.commonmark.org/) to provide a rich description.                                                         |
| `in`          | String                            | ✅       | The location of the API key in the request. Valid values are `query`, `header`, or `cookie`.                                                                                          |
| `name`        | String                            | ✅       | The name of the key parameter in the location.                                                                                                                                        |
| `x-*`         | [Extensions](/openapi/extensions) |          | Any number of extension fields can be added to the security scheme object to be used by tooling and vendors. |

```yaml
components:
  securitySchemes:
    api_key:
      type: apiKey
      name: api_key
      in: header
security:
  - api_key: []
```


 This is the content for the doc openapi/security/security-schemes/security-basic.md 

 # Basic Security Scheme in OpenAPI

A Basic security scheme is a simple authentication mechanism baked into the HTTP protocol that supports sending an Authorization header containing an encoded username and password.

A Basic security scheme can be a relatively simple mechanism to get started with, but risks leaking easy-to-decode passwords if used incorrectly.

Basic security also shares the downside of API keys in that the password is generally long-lived and if intercepted, can be used until it is either revoked or expires.

The fields for a Basic security scheme are as follows:

| Field         | Type                              | Required | Description                                                                                                                                                                           |
| ------------- | --------------------------------- | -------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `type`        | String                            | ✅       | `http`                                                                                                                                                                                |
| `description` | String                            |          | Human-readable information. This may contain [CommonMark syntax](https://spec.commonmark.org/) to provide a rich description.                                                         |
| `scheme`      | String                            | ✅       | `basic`                                                                                                                                                                               |
| `x-*`         | [Extensions](/openapi/extensions) |          | Any number of extension fields can be added to the security scheme object to be used by tooling and vendors. |

```yaml
components:
  securitySchemes:
    auth:
      type: http
      scheme: basic
security:
  - auth: []
```


 This is the content for the doc openapi/security/security-schemes/security-bearer.md 

 # Bearer Security Scheme in OpenAPI

The Bearer security scheme allows passing a token (most commonly a JWT) in the Authorization header.

A Bearer security scheme is generally used for short-lived tokens granted to your API users through an additional login mechanism. Using a JWT allows for storing additional metadata within the token, which can be helpful for some use cases, such as storing scopes for permissions models.

The fields for a Bearer security scheme are as follows:

| Field         | Type                              | Required | Description                                                                                                                                                                           |
| ------------- | --------------------------------- | -------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `type`        | String                            | ✅       | `http`                                                                                                                                                                              |
| `description` | String                            |          | Human-readable information. This may contain [CommonMark syntax](https://spec.commonmark.org/) to provide a rich description.                                                         |
| `scheme`      | String                            | ✅       | `bearer`                                                                                                                                                                              |
| `bearerFormat` | String                            |          | A hint to the client to identify how the bearer token is formatted. Bearer tokens are usually generated by an authorization server, so this information is primarily for documentation purposes. |
| `x-*`         | [Extensions](/openapi/extensions) |          | Any number of extension fields can be added to the security scheme object to be used by tooling and vendors. |

```yaml
components:
  securitySchemes:
    auth:
      type: http
      scheme: bearer
      bearerFormat: JWT
security:
  - auth: []
```


 This is the content for the doc openapi/security/security-schemes/security-oauth2.md 

 # OAuth 2.0 Security Scheme in OpenAPI

OAuth 2.0 is a popular open authentication mechanism that supports an authentication flow allowing servers to authenticate on behalf of a user or organization.

While more generally used for authenticating clients and end-users, it is sometimes used in machine-to-machine applications, but is less popular than other security schemes due to the added complexity of the authentication flows.

OAuth 2.0 is considered more secure than other mechanisms due to its granted privileges through short-lived tokens that limit damage from intercepted tokens.

The OAuth 2.0 protocol defines multiple ways of building a request against the `tokenUrl` endpoint.

## OAuth 2.0 Security Scheme Object in OpenAPI

The fields for an OAuth 2.0 security scheme are as follows:

| Field         | Type                                                | Required | Description                                                                                                                                                                           |
| ------------- | --------------------------------------------------- | -------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `type`        | String                                              | ✅       | `oauth2`                                                                                                                                                                              |
| `description` | String                                              |          | Human-readable information. This may contain [CommonMark syntax](https://spec.commonmark.org/) to provide a rich description.                                                         |
| `flows`       | Map[{key}, [OAuth Flow Object](#oauth-flow-object)] | ✅       | An object containing configuration for the available OAuth 2.0 flows. Valid keys are `implicit`, `password`, `clientCredentials`, and `authorizationCode`.                            |
| `x-*`         | [Extensions](/openapi/extensions)                   |          | Any number of extension fields can be added to the security scheme object to be used by tooling and vendors. |

Below is an example of an OAuth 2.0 security scheme using the `clientCredentials` flow:

```yaml
components:
  securitySchemes:
    clientCredentials:
      type: oauth2
      flows:
        clientCredentials:
          tokenUrl: https://speakeasy.bar/oauth2/token/
          scopes: {}
security:
  - clientCredentials: []
```

## OAuth Flow Object in OpenAPI

The value of the `flows` object is a map of OAuth 2.0 flow objects.

The four supported OAuth 2.0 flows are:

- `implicit` - [Implicit Flow Object](#implicit-flow-object)
- `password` - [Password Flow Object](#password-flow-object)
- `clientCredentials` (previously, `application` in OpenAPI 2.0) - [Client Credentials Flow Object](#client-credentials-flow-object)
- `authorizationCode` (previously, `accessCode` in OpenAPI 2.0) - [Authorization Code Flow Object](#authorization-code-flow-object)

Each flow object has its own configuration parameters, as described below.

### Implicit Flow Object in OpenAPI

The Implicit flow is generally used for single-page applications that can't keep a client secret as all the application code is available to the user.

| Field              | Type                              | Required | Description                                                                                                                                                                       |
| ------------------ | --------------------------------- | -------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `authorizationUrl` | String                            | ✅       | The authorization URL to be used for this flow.                                                                                                                                   |
| `refreshUrl`       | String                            |          | The URL to be used for refreshing the token. No refresh URL means the token is not refreshable.                                                                                   |
| `scopes`           | Map[String, String]               | ✅       | The available scopes for the OAuth 2.0 flow, with a description for each scope. Although the specification requires this field, it can be an empty object.                         |
| `x-*`              | [Extensions](/openapi/extensions) |          | Any number of extension fields can be added to an OAuth Flow object to be used by tooling and vendors to add additional metadata and functionality to the OpenAPI Specification. |

The example below shows an OAuth 2.0 security scheme using the `implicit` flow:

```yaml
components:
  securitySchemes:
    implicit:
      type: oauth2
      flows:
        implicit:
          authorizationUrl: https://speakeasy.bar/oauth2/authorize/
          refreshUrl: https://speakeasy.bar/oauth2/refresh/
          scopes:
            read: Grants read access
            write: Grants write access
```

### Password Flow Object in OpenAPI

The Password flow is generally used for trusted first-party clients that can securely store the client secret.

| Field        | Type                              | Required | Description                                                                                                                                                                       |
| ------------ | --------------------------------- | -------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `tokenUrl`   | String                            | ✅       | The token URL to be used for this flow.                                                                                                                                           |
| `refreshUrl` | String                            |          | The URL to be used for refreshing the token. No refresh URL means the token is not refreshable.                                                                                   |
| `scopes`     | Map[String, String]               | ✅       | The available scopes for the OAuth 2.0 flow, with a description for each scope. Although the specification requires this field, it can be an empty object.                         |
| `x-*`        | [Extensions](/openapi/extensions) |          | Any number of extension fields can be added to an OAuth Flow object to be used by tooling and vendors to add additional metadata and functionality to the OpenAPI Specification. |

The example below shows an OAuth 2.0 security scheme using the `password` flow:

```yaml
components:
  securitySchemes:
    password:
      type: oauth2
      flows:
        password:
          tokenUrl: https://speakeasy.bar/oauth2/token/
          refreshUrl: https://speakeasy.bar/oauth2/refresh/
          scopes:
            read: Grants read access
            write: Grants write access
```

### Client Credentials Flow Object in OpenAPI

The Client Credentials flow is generally used for machine-to-machine communication where a specific user's permission is not required.

| Field        | Type                              | Required | Description                                                                                                                                                                       |
| ------------ | --------------------------------- | -------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `tokenUrl`   | String                            | ✅       | The token URL to be used for this flow.                                                                                                                                           |
| `refreshUrl` | String                            |          | The URL to be used for refreshing the token. No refresh URL means the token is not refreshable.                                                                                   |
| `scopes`     | Map[String, String]               | ✅       | The available scopes for the OAuth 2.0 flow, with a description for each scope. Although the specification requires this field, it can be an empty object.                         |
| `x-*`        | [Extensions](/openapi/extensions) |          | Any number of extension fields can be added to an OAuth Flow object to be used by tooling and vendors to add additional metadata and functionality to the OpenAPI Specification. |

The example below shows an OAuth 2.0 security scheme using the `clientCredentials` flow:

```yaml
components:
  securitySchemes:
    clientCredentials:
      type: oauth2
      flows:
        clientCredentials:
          tokenUrl: https://speakeasy.bar/oauth2/token/
          refreshUrl: https://speakeasy.bar/oauth2/refresh/
          scopes:
            read: Grants read access
            write: Grants write access
```

### Authorization Code Flow Object in OpenAPI

The Authorization Code flow is generally used for server-side applications where the client secret can be securely stored.

| Field              | Type                              | Required | Description                                                                                                                                                                       |
| ------------------ | --------------------------------- | -------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `authorizationUrl` | String                            | ✅       | The authorization URL to be used for this flow.                                                                                                                                   |
| `tokenUrl`         | String                            | ✅       | The token URL to be used for this flow.                                                                                                                                           |
| `refreshUrl`       | String                            |          | The URL to be used for refreshing the token. No refresh URL means the token is not refreshable.                                                                                   |
| `scopes`           | Map[String, String]               | ✅       | The available scopes for the OAuth 2.0 flow, with a description for each scope. Although the specification requires this field, it can be an empty object.                         |
| `x-*`              | [Extensions](/openapi/extensions) |          | Any number of extension fields can be added to an OAuth Flow object to be used by tooling and vendors to add additional metadata and functionality to the OpenAPI Specification. |

The example below shows an OAuth 2.0 security scheme using the `authorizationCode` flow:

```yaml
components:
  securitySchemes:
    authorizationCode:
      type: oauth2
      flows:
        authorizationCode:
          authorizationUrl: https://speakeasy.bar/oauth2/authorize/
          tokenUrl: https://speakeasy.bar/oauth2/token/
          refreshUrl: https://speakeasy.bar/oauth2/refresh/
          scopes:
            read: Grants read access
            write: Grants write access
```

## OAuth 2.0 Security Scheme With Multiple Flows in OpenAPI

You can define an OAuth 2.0 security scheme with multiple flows by specifying each flow in the `flows` object.

The example below shows an OAuth 2.0 security scheme using the `authorizationCode` and `clientCredentials` flows:

```yaml
components:
  securitySchemes:
    oauth2:
      type: oauth2
      flows:
        authorizationCode:
          authorizationUrl: https://speakeasy.bar/oauth2/authorize/
          tokenUrl: https://speakeasy.bar/oauth2/token/
          refreshUrl: https://speakeasy.bar/oauth2/refresh/
          scopes:
            read: Grants read access
            write: Grants write access
        clientCredentials:
          tokenUrl: https://speakeasy.bar/oauth2/token/
          refreshUrl: https://speakeasy.bar/oauth2/refresh/
          scopes:
            read: Grants read access
            write: Grants write access
security:
  - oauth2: []
```

## Scopes in OAuth 2.0 in OpenAPI

Scopes are used to define the permissions that a client has when accessing a resource. The scopes are defined in the `scopes` object of the OAuth flow object.

The scopes required for a specific operation are defined in the `security` object of the operation.

The example below shows an OAuth 2.0 security scheme with scopes:

```yaml
components:
  securitySchemes:
    oauth2:
      type: oauth2
      flows:
        authorizationCode:
          authorizationUrl: https://speakeasy.bar/oauth2/authorize/
          tokenUrl: https://speakeasy.bar/oauth2/token/
          refreshUrl: https://speakeasy.bar/oauth2/refresh/
          scopes:
            read: Grants read access
            write: Grants write access
paths:
  /drinks:
    get:
      operationId: listDrinks
      summary: Get a list of drinks
      # Operation requires read scope
      security:
        - oauth2:
            - read
```


 This is the content for the doc openapi/security/security-schemes/security-openid.md 

 # OpenID Connect Security Scheme in OpenAPI

The OpenID Connect security scheme allows for the discovery of configuration values for an OpenID Connect provider. This is generally used for authentication mechanisms based on the OpenID Connect protocol.

The fields for an OpenID Connect security scheme are as follows:

| Field              | Type                              | Required | Description                                                                                                                                                                           |
| ------------------ | --------------------------------- | -------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `type`             | String                            | ✅       | `openIdConnect`                                                                                                                                                                       |
| `description`      | String                            |          | Human-readable information. This may contain [CommonMark syntax](https://spec.commonmark.org/) to provide a rich description.                                                         |
| `openIdConnectUrl` | String                            | ✅       | The URL must point to a JSON OpenID Connect Discovery document.                                                                                                                       |
| `x-*`              | [Extensions](/openapi/extensions) |          | Any number of extension fields can be added to the security scheme object to be used by tooling and vendors. |

The following is an example of an OpenID Connect security scheme:

```yaml
components:
  securitySchemes:
    openid_connect:
      type: openIdConnect
      openIdConnectUrl: https://example.com/.well-known/openid-configuration
security:
  - openid_connect:
    - read
    - write
paths:
  /drinks:
    get:
      operationId: listDrinks
      summary: Get a list of drinks
      # Operation requires read scope
      security:
        - openid_connect:
          - read:drink
    post:
      operationId: createDrink
      summary: Create a new drink
      # Operation requires write scope
      security:
        - openid_connect:
          - write:drink
```

## Scopes in OpenID Connect

When specifying the required security schemes for an operation, you can also specify the required scopes for that operation. This is done by adding the required scopes as an array of strings to the security scheme object.

In the example above, the `listDrinks` operation requires the `read:drink` scope, and the `createDrink` operation requires the `write:drink` scope. This allows for fine-grained control over the permissions required to access different parts of the API.


 This is the content for the doc openapi/server-sent-events.mdx 

 # Server-sent events in OpenAPI

Server-sent events (SSE) allow servers to push real-time updates to clients over a single HTTP connection. This protocol is widely used for scenarios requiring steady updates, such as notifications, live data feeds, or chat applications. While SSE shares some conceptual similarities with the WebSocket protocol, SSE differs significantly as it is a one-way communication from the server to the client, whereas the WebSocket protocol supports full-duplex communication.

The following table summarizes the main differences between SSE and WebSockets.

| Feature                 | Server-sent events (SSE)                                               | WebSockets                                              |
|-------------------------|------------------------------------------------------------------------|---------------------------------------------------------|
| **Connection**          | Persistent, maintained by the client                                   | Persistent, maintained by both client and server        |
| **Direction**           | One-way: Server to Client                                              | Two-way: Bidirectional communication                    |
| **Initiator**           | Client initiates the connection                                        | Client initiates a WebSocket handshake                  |
| **Use case**            | Real-time updates (for example, stock prices)                                 | Interactive applications (e.g., chat, gaming)           |
| **Data push mechanism** | Server streams events continuously                                     | Both server and client can push messages                |
| **Protocol**            | Single HTTP connection (`text/event-stream`)                             | WebSocket protocol (`ws://` or `wss://`)                    |
| **Client role**         | Opens and maintains the connection                                     | Maintains and interacts with the connection             |
| **Reconnection**        | Handled by the browser or client-side code using the `EventSource` API | Managed by custom reconnection logic in the application |

SSE is ideal for simple, efficient, one-way server-to-client communication scenarios. The WebSocket protocol is better suited to applications that require interactive, low-latency, two-way communication between the client and server.

## Defining SSE in OpenAPI documents

Server-sent events (SSE) are not natively supported in OpenAPI but can be represented as an endpoint using the `text/event-stream` MIME type to indicate the data format. 

The event stream format is a UTF-8-encoded text stream with messages separated by a newline (`\n`). Each message may include up to four fields:

- `event`: A string specifying the event type.
- `data`: The payload, often a JSON object or plain text.
- `id`: An optional unique identifier for resuming streams after disconnection.
- `retry`: An optional integer defining reconnection delay in milliseconds.

Depending on application needs, messages can include only the `data` field, only the `event` field, or a combination of fields. This flexibility allows for tailored implementations, for example, a data-only stream for updates or an event-only stream for simple notifications.

This example SSE endpoint notifies the client about stock price updates and includes only the `id`, `event`, and `data` fields:

```yaml openapi.yaml
paths:
  /stock-updates:
    get:
      tags:
        - ServerSentEvents
      summary: Subscribe to real-time stock market updates
      description: >
       This endpoint streams real-time stock updates to the client using server-sent events (SSE).
       The client must establish a persistent HTTP connection to receive updates.
      responses:
        '200':
          description: Stream of real-time stock updates
          content:
            text/event-stream:
              schema:
                $ref: '#/components/schemas/StockStream'
        '400':
          description: Invalid request
        '500':
          description: Internal server error
components:
  schemas:
    StockStream:
      type: object
      description: A server-sent event containing stock market update content
      required: [id, event, data]
      properties:
        id:
          type: string
          description: Unique identifier for the stock update event
        event:
          type: string
          const: stock_update
          description: Event type
        data:
          $ref: '#/components/schemas/StockUpdate'

    StockUpdate:
      type: object
      properties:
        symbol:
          type: string
          description: Stock ticker symbol
        price:
          type: string
          description: Current stock price
          example: "100.25"
```

A JavaScript client can subscribe to the endpoint using the `EventSource` API:

```javascript
const eventSource = new EventSource('https:://api.example.com/stock-updates');

eventSource.onmessage = function(event) {
  // The event has the following format as example:
  // {"id":"1","event":"stock_update","data":{"symbol":"AAPL","price":"100.25"}}
  const stockUpdate = JSON.parse(event).data;
  console.log(`Stock Update: ${stockUpdate.symbol} is now ${stockUpdate.price}`);
};

eventSource.onerror = function(error) {
  console.error('Error occurred:', error);
};
```

## Best practices for SSE design and OpenAPI integration

Here are some best practices for handling server-sent events and including them in an OpenAPI document.

### Improve reliability with heartbeats

Sending a heartbeat every few seconds is recommended to improve reliability by keeping the connection alive. Heartbeats can also help detect network issues and prompt the client to reconnect.

If you implement heartbeats, your SSE APIs can send multiple types of events, allowing you to use the `oneOf` keyword to describe the heartbeat message format.

```yaml openapi.yaml
components:
  schemas:
    StockStream:
      oneOf:
        - $ref: '#/components/schemas/HeartbeatEvent'
        - $ref: '#/components/schemas/StockUpdateEvent'
      discriminator:
        propertyName: event
        mapping:
          ping: '#/components/schemas/HeartbeatEvent'
          stock_update: '#/components/schemas/StockUpdateEvent'

    HeartbeatEvent:
      description: A server-sent event indicating that the server is still processing the request
      type: object
      required: [event]
      properties:
        event:
          type: string
          const: "ping"
        timestamp:
          type: string
          format: date-time
          description: Timestamp of the heartbeat

    StockUpdateEvent:
      description: A server-sent event containing stock market update content
      type: object
      required: [id, event, data]
      properties:
        id:
          type: string
          description: Unique identifier for the stock update event
        event:
          type: string
          const: stock_update  
```


### Include event identification in the event payload

Include an `id` or `sequence` property in the event payload to ensure that the client receives events in the correct order and avoid missing or out-of-order updates.

### Implement a retry mechanism 

To prevent data loss when an API fails to send an event, implement a retry mechanism such as introducing a delay before retrying or using exponential backoff.

### Use sentinel events to signal a closed connection

Sending a sentinel event can be helpful to indicate that the connection is closed or the server is no longer available. This is useful for error handling or notifying the client that there is no more data to be received.

The following example schema for a sentinel event demonstrates how a client can terminate a connection when it receives the `CLOSED` sentinel event:


```yaml openapi.yaml
paths:
  /stock-updates:
    get:
      summary: Subscribe to real-time stock market updates
      operationId: stockUpdates
      tags:
        - ServerSentEvents
      responses:
        '200':
          description: Stream of real-time stock updates
          content:
            text/event-stream:
              x-sse-sentinel: 'CLOSED'
              schema:
                $ref: '#/components/schemas/StockUpdateEvent'
```


For each event received, the client can check the `X-SSE-Sentinel` header to determine whether the connection has closed or if no more data needs to be received.

### Handle SSE errors effectively

To handle errors in SSE effectively, servers can send specific error events within the stream that include an error field detailing the issue. For non-critical errors, custom headers like `X-SSE-Error` can communicate problems without interrupting the event flow. 

Specific error events in the stream can be defined using a structured schema, as demonstrated below.

```yaml openapi.yaml
components:
  schemas:
    ErrorEvent:
      description: A server-sent error event
      type: object
      required: [event, message]
      properties:
        event:
          type: string
          const: error
        message:
          type: string
          description: Description of the error
```

For critical errors, use a sentinel event as described in the previous section.


 This is the content for the doc openapi/servers.md 

 # OpenAPI Servers

A list of [Server Objects](/openapi/servers) that either the entire API or a specific path or operation is available on. Servers can be defined at the [Document](/openapi#openapi-document-structure) level, the [Path](/openapi/paths) level, or the [Operation](/openapi/paths/operations) level.

Servers are optional in the OpenAPI specification. If not provided, the default URL is assumed to be `/`, a path relative to where the OpenAPI document is hosted.

Generally, the first server in the list is considered to be the default server to use, with logic to select other servers to use left up to tooling or the API consumer.

Example:

```yaml
servers:
  - url: https://speakeasy.bar
    description: The production server
  - url: https://staging.speakeasy.bar
    description: The staging server
```

If a list of servers is provided at the `paths` level, the servers will override any servers provided at the document level. If a list of servers is provided at the `operation` level, the servers will override any servers provided at the `paths` and document levels.

## Server Object in OpenAPI

A Server Object describes a single server that is available for the API.

| Field         |                         Type                          | Required | Description                                                                                                                                                                                                                                                                                               |
| ------------- | :---------------------------------------------------: | :------: | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `url`         |                        String                         |    ✅    | A URL to the server. This can be an absolute URL or a relative URL to the hosted location of the OpenAPI document. The URL also supports variable substitutions via [Templating](/openapi/servers/server-variables).                                                                                      |
| `description` |                        String                         |          | A description of the server. [CommonMark syntax](https://spec.commonmark.org/) can be used to provide a rich description.                                                                                                                                                                                 |
| `variables`   | [Server Variables](/openapi/servers/server-variables) |          | A map of variable names to [Server Variable Objects](/openapi/servers/server-variables#server-variable-object) that can be used for variable substitution via [Templating](/openapi/servers/server-variables).                                                                                            |
| `x-*`         |           [Extensions](/openapi/extensions)           |          | Any number of extension fields can be added to the Server Object ([for example, `x-speakeasy-server-id`](/docs/customize-sdks/servers#managing-multiple-servers-with-ids) that allows IDs to be assigned to each server for easier selection via Speakeasy SDKs) that can be used by tooling and vendors. |

If the URL is an absolute path, it **_must_** conform to [RFC 3986](https://datatracker.ietf.org/doc/html/rfc3986) (`schema://host{:port}{/path}`) and not include the query string, and **_must_** be URL encoded (except for the templating delimiters `{}` if not part of the URL).

The URL can also be a relative path to where the OpenAPI document is hosted (`/api`). For a document hosted at `https://speakeasy.bar/openapi.yaml`, the resulting URL will be `https://speakeasy.bar/api`.

The URL may also contain fragments (for example, `https://speakeasy.bar/drinks#mocktails`) allowing for repeated URLs with different fragments to be defined in the same document and the definition of multiple operations with the same URL and HTTP method but different operation definitions.

For example, the below document is not valid as it defines two operations with the same URL and HTTP method:

```yaml
paths:
  /drinks:
    get:
      operationId: listCocktails
      summary: Get a list of cocktails
      parameters:
        - name: type
          in: query
          schema:
            type: string
            const: cocktail
      responses:
        "200":
          description: A list of cocktails
          content:
            application/json:
              schema:
                type: array
                items:
                  $ref: "#/components/schemas/Cocktail"
  /drinks:
    get:
      operationId: listMocktails
      summary: Get a list of mocktails
      parameters:
        - name: type
          in: query
          schema:
            type: string
            const: mocktail
      responses:
        "200":
          description: A list of mocktails
          content:
            application/json:
              schema:
                type: array
                items:
                  $ref: "#/components/schemas/Mocktail"
```

However, the below document is valid as it defines two operations with the same URL and HTTP method but different fragments, making the paths unique:

```yaml
paths:
  /drinks#cocktails:
    get:
      operationId: listCocktails
      summary: Get a list of cocktails
      parameters:
        - name: type
          in: query
          schema:
            type: string
            const: cocktail
      responses:
        "200":
          description: A list of cocktails
          content:
            application/json:
              schema:
                type: array
                items:
                  $ref: "#/components/schemas/Cocktail"
  /drinks#mocktails:
    get:
      operationId: listMocktails
      summary: Get a list of mocktails
      parameters:
        - name: type
          in: query
          schema:
            type: string
            const: mocktail
      responses:
        "200":
          description: A list of mocktails
          content:
            application/json:
              schema:
                type: array
                items:
                  $ref: "#/components/schemas/Mocktail"
```

**Note:** The above API can also be achieved using [`oneOf`](/openapi/schemas/objects/polymorphism) in a single operation definition, but depending on the use case, this may not be desirable.


 This is the content for the doc openapi/servers/server-variables.md 

 # Server Variables in OpenAPI

Server variables are a map of variable names (string) to [Server Variable Objects](/openapi/servers/server-variables#server-variable-object) that can be used for variable substitution via Templating.

## Server Variable Object in OpenAPI

A Server Variable Object describes a single variable that is optionally part of the URL in a [Server Object](/openapi/servers). The value of a variable can be any arbitrary string value unless a list of allowed values is provided via the `enum` field.

| Field         |           Type            | Required | Description                                                                                                                                              |
| ------------- | :-----------------------: | :------: | -------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `description` |          String           |          | A description of the variable. [CommonMark syntax](https://spec.commonmark.org/) can be used to provide a rich description.                              |
| `default`     |          String           |    ✅    | The default value of the variable. A variable is always of type _string_. If `enum` is provided this **_must_** be one of the values in the `enum` list. |
| `enum`        |      List\<string\>       |          | A list of allowed string values for the variable.                                                                                                        |
| `x-*`         | [Extensions](/openapi/extensions) |          | Any number of extension fields can be added to the Server Variable Object that can be used by tooling and vendors.                                       |

Example:

```yaml
servers:
  - url: https://{organization}.{environment}.speakeasy.bar
    description: A per-organization and per-environment API
    variables:
      organization:
        description: The organization name. Defaults to a generic organization.
        default: api
      environment:
        description: The environment name. Defaults to the production environment.
        default: prod
        enum:
          - prod
          - staging
          - dev
```

Any variable delimited by `{}` in the `url` field declares a part of the URL that **_must_** be replaced with a value and references a variable that **_must_** be defined in the `variables` map. It is the API consumer's responsibility to replace these variables (including the delimiters) with values to create a valid URL before making a request to the API. The defined `default` should be used if no other value is provided.

 This is the content for the doc openapi/tags.md 

 # OpenAPI Tags

The document-level `tags` field contains a list of [tag](/openapi/tags#tag-object) definitions that may be used to categorize or group operations in the API. Tags can be referenced by [operations](/openapi/paths/operations) via the operations-level `tags` field.

Tag definitions at the document level are optional, even if an undefined tag is referenced in an [operation](/openapi/paths/operations), but it is recommended that all tags used are defined here to provide useful documentation and intent for the tags.

Tag names **_must_** be unique in the document.

Example:

```yaml
tags:
  - name: drinks
    description: The drinks endpoints.
  - name: authentication
    description: The authentication endpoints.
```

## Tag Object in OpenAPI

A Tag Object defines a single tag that can be used to categorize or group operations in the API.

| Field          |                              Type                               | Required | Description                                                                                                                 |
| -------------- | :-------------------------------------------------------------: | :------: | --------------------------------------------------------------------------------------------------------------------------- |
| `name`         |                             String                              |    ✅    | The name of the tag. **_Must_** be unique in the document.                                                                  |
| `description`  |                             String                              |          | A description of the tag. This may contain [CommonMark syntax](https://spec.commonmark.org/) to provide a rich description. |
| `externalDocs` | [External Documentation Object](/openapi/external-documentation) |          | Additional external documentation for this tag.                                                                             |
| `x-*`          |                    [Extensions](/openapi/extensions)                    |          | Any number of extension fields can be added to the tag object that can be used by tooling and vendors.                      |

## Multiple Namespaces in OpenAPI

If you want to add a method to multiple namespaces, list multiple values in tags. It accepts an array of values:

```yaml
paths:
  /drinks:
    get:
      operationId: listDrinks
      tags:
        - drinks
        - beverages
```

 This is the content for the doc openapi/webhooks.md 

 # Webhooks in OpenAPI

**(Available in OpenAPI 3.1.x ONLY)**

`webhooks` are a mechanism that allows an API to send real-time data to a user as soon as an event occurs (without requiring the user to take any action). The user simply needs to subscribe to the event stream and provide a URL to start receiving data.

The `webhooks` element has identical syntax to the `paths` element. Both are lists of [Path Item Objects](/openapi/paths#path-item-object). (This makes sense if you consider that a webhook is like a reverse path: Just as paths describe endpoints on the server's API, webhooks describe endpoints on the user's API.)

This means a webhook has all the following path properties available to it: `$ref`, `summary`, `description`, `get`, `put`, `post`, `delete`, `options`, `head`, `patch`, `trace`, `servers`, and `parameters`.

For example:

```yaml
webhooks:
  stockUpdate:
    post:
      summary: Receive stock updates.
      description: Receive stock updates from the bar, this will be called whenever the stock levels of a drink or ingredient change.
      tags:
        - drinks
        - ingredients
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              properties:
                drink:
                  $ref: "#/components/schemas/Drink"
                ingredient:
                  $ref: "#/components/schemas/Ingredient"
      responses:
        "200":
          description: The stock update was received successfully.
        "5XX":
          $ref: "#/components/responses/APIError"
        default:
          $ref: "#/components/responses/UnknownError"
```

## The AsyncAPI Standard?

OpenAPI is a general-purpose API specification that can be used for asynchronous APIs, but it is not necessarily optimized for them. If you find that OpenAPI is insufficient for your use case, you should check out [AsyncAPI](https://www.asyncapi.com/). Just be aware that AsyncAPI is still in the early stages of development and is not yet widely supported by the tooling ecosystem.